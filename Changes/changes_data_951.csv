id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fopenstack-manuals~stable%2Fmitaka~I0e9d65895dcf0132a6c7be39731cae8f44e8418e,openstack/openstack-manuals,stable/mitaka,I0e9d65895dcf0132a6c7be39731cae8f44e8418e,Provide exact and direct link for 'instance does not launch',MERGED,2016-05-11 09:54:24.000000000,2016-05-11 18:13:42.000000000,2016-05-11 18:13:41.000000000,"[{'_account_id': 3}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 16237}, {'_account_id': 20156}]","[{'number': 1, 'created': '2016-05-11 09:54:24.000000000', 'files': ['doc/install-guide/source/launch-instance-selfservice.rst', 'doc/install-guide/source/launch-instance-provider.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab8313ebe871f4269f5c3b1dede1446c96b1684c', 'message': ""Provide exact and direct link for 'instance does not launch'\n\n\nChange-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e\n(cherry picked from commit e5960bc5f971f52e7d5ae484c5f704f4e1ce9c34)\n""}]",0,314940,ab8313ebe871f4269f5c3b1dede1446c96b1684c,9,5,1,16237,,,0,"Provide exact and direct link for 'instance does not launch'


Change-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e
(cherry picked from commit e5960bc5f971f52e7d5ae484c5f704f4e1ce9c34)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/314940/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/launch-instance-selfservice.rst', 'doc/install-guide/source/launch-instance-provider.rst']",2,ab8313ebe871f4269f5c3b1dede1446c96b1684c,vm_fail_link,`Instance Boot Failures <http://docs.openstack.org/openstack-ops/content/instances.html#instance_boot_failures>`__ section in OpenStack Operations Guide for more information or use one of the :doc:`many other options <common/app_support>`,`OpenStack Operations Guide <http://docs.openstack.org/ops>`__ for more information or use one of the :doc:`many other options <common/app_support>`,8,4
openstack%2Fopenstack-manuals~stable%2Fmitaka~If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817,openstack/openstack-manuals,stable/mitaka,If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817,[install-guide] Add ipset installation in compute node,MERGED,2016-05-11 09:27:53.000000000,2016-05-11 18:09:47.000000000,2016-05-11 18:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 9382}]","[{'number': 1, 'created': '2016-05-11 09:27:53.000000000', 'files': ['doc/install-guide/source/neutron-compute-install.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5c070bcf0b1714b9e1f511d3374a81802a155be9', 'message': '[install-guide] Add ipset installation in compute node\n\nIn some case, host may lack ipset utility(e.g., due to a\ndependency issue). This will cause create vm failed if we\nenable Neutron securitygroup in compute node.\n\nWe had already fixed in Neutron side, we using neutron-sanity-check\ntool for check ipset installation. But this is insufficiency,\nsome guys may not know that tool.\n\nSo we install ipset in compute node.\n\n\nChange-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817\nRelated-Bug: #1510680\n(cherry picked from commit 8a4ffb4224d438d68d642f93269002b06bf63502)\n'}]",0,314927,5c070bcf0b1714b9e1f511d3374a81802a155be9,7,3,1,16237,,,0,"[install-guide] Add ipset installation in compute node

In some case, host may lack ipset utility(e.g., due to a
dependency issue). This will cause create vm failed if we
enable Neutron securitygroup in compute node.

We had already fixed in Neutron side, we using neutron-sanity-check
tool for check ipset installation. But this is insufficiency,
some guys may not know that tool.

So we install ipset in compute node.


Change-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817
Related-Bug: #1510680
(cherry picked from commit 8a4ffb4224d438d68d642f93269002b06bf63502)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/314927/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/neutron-compute-install.rst'],1,5c070bcf0b1714b9e1f511d3374a81802a155be9,add_ipset, .. todo: https://bugzilla.redhat.com/show_bug.cgi?id=1334626 # yum install openstack-neutron-linuxbridge ebtables ipset, # yum install openstack-neutron-linuxbridge ebtables,5,1
openstack%2Fnetworking-ovn~master~I2533e92b3daba0347e7439ea9837abfacdc36799,openstack/networking-ovn,master,I2533e92b3daba0347e7439ea9837abfacdc36799,DNM: Commit to test for regressions in devstack refator,ABANDONED,2016-05-05 20:59:32.000000000,2016-05-11 17:55:47.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 8410}, {'_account_id': 14957}]","[{'number': 1, 'created': '2016-05-05 20:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b7626a2be7894fd135b297910d6b1d8f47b71205', 'message': ""DNM: Commit to test for regressions in devstack refator\n\nIdeally, all the work Sean is doing shouldn't break lib/neutron-legacy\n\nThis patch tests, to ensure He doesn't.\n\nChange-Id: I2533e92b3daba0347e7439ea9837abfacdc36799\nDepends-On: I31b6362c6d9992f425f2dedbbeff2568390a93da\n""}, {'number': 2, 'created': '2016-05-06 17:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7c2d46778b40db4167e16ed5b74f0093ea452f19', 'message': ""DNM: Commit to test for regressions in devstack refator\n\nIdeally, all the work Sean is doing shouldn't break lib/neutron-legacy\n\nThis patch tests, to ensure He doesn't.\n\nChange-Id: I2533e92b3daba0347e7439ea9837abfacdc36799\nDepends-On: I31b6362c6d9992f425f2dedbbeff2568390a93da\n""}, {'number': 3, 'created': '2016-05-10 16:52:06.000000000', 'files': ['networking_ovn/_i18n.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/78cf6b1f884ce6efe8f464dd34a930b998ba7642', 'message': ""DNM: Commit to test for regressions in devstack refator\n\nIdeally, all the work Sean is doing shouldn't break lib/neutron-legacy\n\nThis patch tests, to ensure He doesn't.\n\nChange-Id: I2533e92b3daba0347e7439ea9837abfacdc36799\nDepends-On: I31b6362c6d9992f425f2dedbbeff2568390a93da\n""}]",0,313157,78cf6b1f884ce6efe8f464dd34a930b998ba7642,19,4,3,748,,,0,"DNM: Commit to test for regressions in devstack refator

Ideally, all the work Sean is doing shouldn't break lib/neutron-legacy

This patch tests, to ensure He doesn't.

Change-Id: I2533e92b3daba0347e7439ea9837abfacdc36799
Depends-On: I31b6362c6d9992f425f2dedbbeff2568390a93da
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/57/313157/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/_i18n.py'],1,b7626a2be7894fd135b297910d6b1d8f47b71205,neutron-refactor,# tickle tickle,,1,0
openstack%2Fironic~master~I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334,openstack/ironic,master,I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334,Allow configuring shred's final overwrite with zeros,MERGED,2016-04-11 12:47:06.000000000,2016-05-11 17:46:41.000000000,2016-05-11 17:46:41.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6637}, {'_account_id': 6773}, {'_account_id': 7080}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 7933}, {'_account_id': 8106}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 12459}, {'_account_id': 13362}, {'_account_id': 14525}, {'_account_id': 14760}, {'_account_id': 16530}, {'_account_id': 17998}, {'_account_id': 18893}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-04-11 12:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/92ac264ac8c75332806310f7075984cfd6bab867', 'message': 'Default shred iterations to 0. Always zeroize.\n\n[deploy] erase_devices_iterations setting controls the number of random\niterations to run on the block device. Clarify the meaning of the setting\nand default it to 0. The device always gets a zero pass last.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\n'}, {'number': 2, 'created': '2016-04-11 12:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/43204d5f9e2c0ff84b89e5377e7b9cdf31cabca7', 'message': 'Default shred iterations to 0. Always zeroize.\n\n[deploy] erase_devices_iterations setting controls the number of random\niterations to run on the block device. Clarify the meaning of the setting\nand default it to 0. The device always gets a zero pass last.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\n'}, {'number': 3, 'created': '2016-04-11 12:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7ebd1aed0e4d7002e0b198bc68fae0cfa1152b59', 'message': 'Default shred iterations to 0. Always zeroize.\n\n[deploy] erase_devices_iterations setting controls the number of\nrandom iterations to run on the block device. Clarify the meaning of\nthe setting and default it to 0. The device always gets a zero pass\nlast.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\n'}, {'number': 4, 'created': '2016-04-12 11:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/094d5ea26a7fec7bed4fc6f114fcebdb51479fc7', 'message': 'Default shred iterations to 0. Always zeroize.\n\n[deploy] erase_devices_iterations setting controls the number of\nrandom iterations to run on the block device. Clarify the meaning of\nthe setting and default it to 0. The device always gets a zero pass\nlast.\n\n  $ shred --force --zero --verbose --iterations 0 my_block_device\n  shred: my_block_device: pass 1/1 (000000)...\n\n  $ shred --force --zero --verbose --iterations 1 my_block_device\n  shred: my_block_device: pass 1/2 (random)...\n  shred: my_block_device: pass 2/2 (000000)...\n\nManpage for shred [1]\n  -z, --zero\n    add a final overwrite with zeros to hide shredding\n\n[1] http://linux.die.net/man/1/shred\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\n'}, {'number': 5, 'created': '2016-04-12 13:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0b943abaa959538285096e575e6d9805f8a8e66f', 'message': ""Allow shred's zeroize pass to be configurable\n\nIntroduce a new configuration option to control whether devices will\nreceive a final overwrite with zeros during cleaning. Additionally,\nrename erase_devices_iterations to erase_devices_random_iterations to\nclarify the true meaning of this configuration option.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 6, 'created': '2016-04-12 13:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/057b4abb026b2eb8a102d3adf2a752ae8d59ebd1', 'message': ""Allow shred's zeroize pass to be configurable\n\nIntroduce a new configuration option to control whether devices will\nreceive a final overwrite with zeros during cleaning. Additionally,\nrename erase_devices_iterations to erase_devices_random_iterations to\nclarify the true meaning of this configuration option.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 7, 'created': '2016-04-12 19:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8fe406bc2236af6052bc3b1cb1cda0d5b0df2c08', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce a new configuration option to control whether devices will\nreceive a final overwrite with zeros during cleaning. Additionally,\nrename erase_devices_iterations to shred_random_overwrite_iterations to\nclarify the true meaning of this configuration option.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 8, 'created': '2016-04-12 20:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9d953476e2ff14cab1587037bf2f54d9dde6cf41', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce a new configuration option to control whether devices will\nreceive a final overwrite with zeros during cleaning. Additionally,\nrename erase_devices_iterations to shred_random_overwrite_iterations to\nclarify the true meaning of this configuration option.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 9, 'created': '2016-04-13 18:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b6aaee2434a153c9c4958d405d7963b56f582f84', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce a new configuration option to control whether devices will\nreceive a final overwrite with zeros during cleaning. Additionally,\nrename erase_devices_iterations to shred_random_overwrite_iterations to\nclarify the true meaning of this configuration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security violation of running cleaning with iterations=0\nand overwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 10, 'created': '2016-04-14 13:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/af242d77a3374d8fe5a864c745a7eea984355b91', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce a new configuration option to control whether devices will\nreceive a final overwrite with zeros during cleaning. Additionally,\nrename erase_devices_iterations to shred_random_overwrite_iterations to\nclarify the true meaning of this configuration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 11, 'created': '2016-04-18 13:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e615922f1da94777e33e59c8ad207f030e2a1e45', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 12, 'created': '2016-04-21 12:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ffd96fb0f9d076c2a27be67459a7a0401aeddec3', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 13, 'created': '2016-04-21 17:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/66c59d403fd0142f64daba1336870a36bb33173f', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 14, 'created': '2016-04-21 17:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/969bceb559468d390cebf42c714a2beca0e43e34', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 15, 'created': '2016-05-09 12:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4517184bad6ff0ed4e58007a558a1847de0ba11f', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 16, 'created': '2016-05-10 18:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/228efc775ecee90c36f0a27f5b3a9e2911c6f2b7', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}, {'number': 17, 'created': '2016-05-10 19:13:41.000000000', 'files': ['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/deploy_utils.py', 'releasenotes/notes/shred-final-overwrite-with-zeros-50b5ba5b19c0da27.yaml', 'ironic/tests/unit/drivers/modules/test_deploy_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c47c6d2ab54f88a054c9e1566c02c219bd1a79c0', 'message': ""Allow configuring shred's final overwrite with zeros\n\nIntroduce shred_final_overwrite_with_zeros, a new configuration option\nto control whether devices will receive a final overwrite with zeros\nduring cleaning. Additionally, rename erase_devices_iterations to\nshred_random_overwrite_iterations to clarify the true meaning of this\nconfiguration option.\n\nAlso, ensure a warning is raised in the logs to raise awareness around\nthe potential security risk of running cleaning with iterations=0 and\noverwrite_with_zeros=False.\n\nChange-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334\nCloses-Bug: #1568811\nDepends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83\n""}]",59,304101,c47c6d2ab54f88a054c9e1566c02c219bd1a79c0,143,23,17,7080,,,0,"Allow configuring shred's final overwrite with zeros

Introduce shred_final_overwrite_with_zeros, a new configuration option
to control whether devices will receive a final overwrite with zeros
during cleaning. Additionally, rename erase_devices_iterations to
shred_random_overwrite_iterations to clarify the true meaning of this
configuration option.

Also, ensure a warning is raised in the logs to raise awareness around
the potential security risk of running cleaning with iterations=0 and
overwrite_with_zeros=False.

Change-Id: I0dd3f488ab2cd0df778f34a5a23948fa0c6c4334
Closes-Bug: #1568811
Depends-On: I7053034f5b5bc6737b535ee601e6fb71284d4a83
",git fetch https://review.opendev.org/openstack/ironic refs/changes/01/304101/13 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1568811-50b5ba5b19c0da27.yaml', 'etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/deploy_utils.py', 'ironic/tests/unit/drivers/modules/test_deploy_utils.py']",4,92ac264ac8c75332806310f7075984cfd6bab867,bug/1568811," 'agent_erase_devices_iterations'), 0)"," 'agent_erase_devices_iterations'), 1)",15,6
openstack%2Fpython-monascaclient~master~I45dc7e4d7af4b9b47646b4882a30c1678e16aecd,openstack/python-monascaclient,master,I45dc7e4d7af4b9b47646b4882a30c1678e16aecd,Add support for group_by to measurements and statistics resources,MERGED,2016-03-09 18:01:28.000000000,2016-05-11 17:39:58.000000000,2016-05-11 17:39:58.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 18179}]","[{'number': 1, 'created': '2016-03-09 18:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/49d8db0551295edb81c43766149d502a586bfab8', 'message': 'Add support for multiple_metrics to measurements and statistics resources\n\nChange-Id: I45dc7e4d7af4b9b47646b4882a30c1678e16aecd\n'}, {'number': 2, 'created': '2016-03-15 19:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/d0704294cb880aa081c577501c1e4f235174d387', 'message': 'Add support for group_by to measurements and statistics resources\n\nChange-Id: I45dc7e4d7af4b9b47646b4882a30c1678e16aecd\n'}, {'number': 3, 'created': '2016-05-10 16:09:50.000000000', 'files': ['monascaclient/v2_0/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/5758fe3a3b51b278f068e580ef243ba043ffc45b', 'message': 'Add support for group_by to measurements and statistics resources\n\nChange-Id: I45dc7e4d7af4b9b47646b4882a30c1678e16aecd\n'}]",0,290730,5758fe3a3b51b278f068e580ef243ba043ffc45b,14,5,3,2419,,,0,"Add support for group_by to measurements and statistics resources

Change-Id: I45dc7e4d7af4b9b47646b4882a30c1678e16aecd
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/30/290730/3 && git format-patch -1 --stdout FETCH_HEAD,['monascaclient/v2_0/shell.py'],1,49d8db0551295edb81c43766149d502a586bfab8,metrics,"@utils.arg('--multiple_metrics', action='store_const', const=True, help='Allow multiple metrics to be returned.') if args.multiple_metrics: fields['multiple_metrics'] = args.multiple_metrics@utils.arg('--multiple_metrics', action='store_const', const=True, help='Allow multiple metrics to be returned.') if args.multiple_metrics: fields['multiple_metrics'] = args.multiple_metrics",,10,0
openstack%2Fvirtualbmc~master~I0ec638d586a65c319b51da530090e7718442869b,openstack/virtualbmc,master,I0ec638d586a65c319b51da530090e7718442869b,"Add ""cover"" to .gitignore",MERGED,2016-05-11 16:33:49.000000000,2016-05-11 17:38:47.000000000,2016-05-11 17:38:47.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 7080}, {'_account_id': 18893}]","[{'number': 1, 'created': '2016-05-11 16:33:49.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/b71669a826a4340670eb5f254aa95d3249dfd79c', 'message': 'Add ""cover"" to .gitignore\n\nThis patch is adding ""cover"" to the .gitignore file since we should keep\ntrack of results of tests coverage.\n\nChange-Id: I0ec638d586a65c319b51da530090e7718442869b\n'}]",0,315154,b71669a826a4340670eb5f254aa95d3249dfd79c,8,4,1,6773,,,0,"Add ""cover"" to .gitignore

This patch is adding ""cover"" to the .gitignore file since we should keep
track of results of tests coverage.

Change-Id: I0ec638d586a65c319b51da530090e7718442869b
",git fetch https://review.opendev.org/openstack/virtualbmc refs/changes/54/315154/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,b71669a826a4340670eb5f254aa95d3249dfd79c,ignore-conver,cover,,1,0
openstack%2Fneutron~master~I57d0a4cb37c74d248b14a1ba361a0571d4da9bde,openstack/neutron,master,I57d0a4cb37c74d248b14a1ba361a0571d4da9bde,Fix invalid subnetpool id when _validate_address_scope_id,ABANDONED,2016-05-11 02:57:14.000000000,2016-05-11 17:38:32.000000000,,"[{'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-05-11 02:57:14.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cbca33572170a84963c939cb81f1b72671596c6e', 'message': ""Fix invalid subnetpool id when _validate_address_scope_id\n\nWhen validate address scope id in the create_subnetpool function,\nthe subnetpool_id params is set to'id' which is not the right\nsubnetpool id but a <build-in-function>.\n\nChange-Id: I57d0a4cb37c74d248b14a1ba361a0571d4da9bde\n""}]",0,314839,cbca33572170a84963c939cb81f1b72671596c6e,9,7,1,16242,,,0,"Fix invalid subnetpool id when _validate_address_scope_id

When validate address scope id in the create_subnetpool function,
the subnetpool_id params is set to'id' which is not the right
subnetpool id but a <build-in-function>.

Change-Id: I57d0a4cb37c74d248b14a1ba361a0571d4da9bde
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/314839/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,cbca33572170a84963c939cb81f1b72671596c6e,," sp_reader.id, sp_reader.prefixes,"," id, sp_reader.prefixes,",1,1
openstack%2Ffuel-library~master~Ib81b800504baa968a08278e5adc3fdf6fb0975c0,openstack/fuel-library,master,Ib81b800504baa968a08278e5adc3fdf6fb0975c0,Update stdlib to 4.12.0,MERGED,2016-05-11 15:30:12.000000000,2016-05-11 17:37:51.000000000,2016-05-11 17:33:51.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 8971}, {'_account_id': 13344}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-11 15:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6112c04689816f38658a79642176910ed8ec240b', 'message': 'Quick fix for CI fail related to radosgw\n\nThis quick fix passes top_scope variable from modular task\nto rgw manifest. In nearest future this variable must come\nfrom facter or we should change radosgw sysv script to match\nceph repo.\n\nChange-Id: Ib81b800504baa968a08278e5adc3fdf6fb0975c0\n'}, {'number': 2, 'created': '2016-05-11 15:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ed96dab5e83bf652c8b189683c3f7c5139a30008', 'message': 'Quick fix for CI fail related to radosgw\n\nThis quick fix passes top_scope variable from modular task\nto rgw manifest. In nearest future this variable must come\nfrom facter or we should change radosgw sysv script to match\nceph repo.\n\nChange-Id: Ib81b800504baa968a08278e5adc3fdf6fb0975c0\nCloses-Bug: 1580656\n'}, {'number': 3, 'created': '2016-05-11 15:47:18.000000000', 'files': ['deployment/Puppetfile'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2b3d445f75985ba8508d514c13876f3b80eb4e21', 'message': 'Update stdlib to 4.12.0\n\nThe upstream puppet-ceph module is leveraging the service_provider fact\nwhich was added to stdlib as part of 4.10.0. This is causing the wrong\nservice start method to be used for radosgw.  This change updates stdlib\nto pull in the service_provider fact so the correct service management\nmethod is used.\n\nChange-Id: Ib81b800504baa968a08278e5adc3fdf6fb0975c0\nCloses-Bug: 1580656\n'}]",3,315123,2b3d445f75985ba8508d514c13876f3b80eb4e21,56,9,3,13344,,,0,"Update stdlib to 4.12.0

The upstream puppet-ceph module is leveraging the service_provider fact
which was added to stdlib as part of 4.10.0. This is causing the wrong
service start method to be used for radosgw.  This change updates stdlib
to pull in the service_provider fact so the correct service management
method is used.

Change-Id: Ib81b800504baa968a08278e5adc3fdf6fb0975c0
Closes-Bug: 1580656
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/23/315123/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp'],1,6112c04689816f38658a79642176910ed8ec240b,bug/1580656,$service_provider = 'upstart' ,,2,0
openstack%2Fnetworking-hyperv~stable%2Fkilo~If6ac53656b18d4698953e8357030d59723aad2dc,openstack/networking-hyperv,stable/kilo,If6ac53656b18d4698953e8357030d59723aad2dc,Fixes bug: AttributeError when trying to use local_network_vswitch,MERGED,2015-11-10 11:50:42.000000000,2016-05-11 17:37:49.000000000,2016-05-11 17:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 8213}, {'_account_id': 9656}, {'_account_id': 12604}]","[{'number': 1, 'created': '2015-11-10 11:50:42.000000000', 'files': ['hyperv/tests/unit/neutron/test_hyperv_neutron_agent.py', 'hyperv/neutron/hyperv_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/a01ebd53075d8c6662a6d5752915d164a6122816', 'message': 'Fixes bug: AttributeError when trying to use local_network_vswitch\n\nThe attribute named _local_network_vswitch was called as local_network_vswitch\nin the agent resulting in an AttributeError.\n\nThis fix adds the propper naming, _local_network_vswitch.\n\nChange-Id: If6ac53656b18d4698953e8357030d59723aad2dc\nCloses-Bug: #1514313\n(cherry picked from commit 9767ce67fbdc7b128601c8cfb96c5e8008a2c956)\n'}]",0,243548,a01ebd53075d8c6662a6d5752915d164a6122816,30,5,1,8213,,,0,"Fixes bug: AttributeError when trying to use local_network_vswitch

The attribute named _local_network_vswitch was called as local_network_vswitch
in the agent resulting in an AttributeError.

This fix adds the propper naming, _local_network_vswitch.

Change-Id: If6ac53656b18d4698953e8357030d59723aad2dc
Closes-Bug: #1514313
(cherry picked from commit 9767ce67fbdc7b128601c8cfb96c5e8008a2c956)
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/48/243548/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/tests/unit/neutron/test_hyperv_neutron_agent.py', 'hyperv/neutron/hyperv_neutron_agent.py']",2,a01ebd53075d8c6662a6d5752915d164a6122816,, vswitch_name = self._local_network_vswitch, vswitch_name = self.local_network_vswitch,18,1
openstack%2Fnova~master~I03e76a3a45f2d59c8fb01610cbd751d5b91f5964,openstack/nova,master,I03e76a3a45f2d59c8fb01610cbd751d5b91f5964,Remove 404 for list and details actions of servers,MERGED,2016-05-10 00:44:51.000000000,2016-05-11 17:36:54.000000000,2016-05-10 09:55:58.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2016-05-10 00:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/758efd646f7312e6f6503c0867dcede59956751e', 'message': ""Remove 404 for list and details action servers\n\nJust found when the marker can't be found, we won't return 404,\ninstead of we will return 400. This patch removes the 404 code from\nlist and details doc.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I03e76a3a45f2d59c8fb01610cbd751d5b91f5964\n""}, {'number': 2, 'created': '2016-05-10 02:37:59.000000000', 'files': ['api-ref/source/servers.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/1fce522362f1e958cd3187ff5703f134c9026944', 'message': ""Remove 404 for list and details actions of servers\n\nJust found when the marker can't be found, we won't return 404,\ninstead of we will return 400. This patch removes the 404 code from\nlist and details doc.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I03e76a3a45f2d59c8fb01610cbd751d5b91f5964\n""}]",0,314355,1fce522362f1e958cd3187ff5703f134c9026944,19,8,2,5754,,,0,"Remove 404 for list and details actions of servers

Just found when the marker can't be found, we won't return 404,
instead of we will return 400. This patch removes the 404 code from
list and details doc.

Part of bp:api-ref-in-rst

Change-Id: I03e76a3a45f2d59c8fb01610cbd751d5b91f5964
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/314355/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/servers.inc'],1,758efd646f7312e6f6503c0867dcede59956751e,bp/api-ref-in-rst,forbidden(403)forbidden(403),"forbidden(403), itemNotFound(404)forbidden(403), itemNotFound(404)",2,2
openstack%2Fkolla~master~Iea824e8fc6489d8222e089199161ca3fb30a8310,openstack/kolla,master,Iea824e8fc6489d8222e089199161ca3fb30a8310,Update liberty deployment warning,MERGED,2016-05-11 16:01:12.000000000,2016-05-11 17:30:21.000000000,2016-05-11 17:30:21.000000000,"[{'_account_id': 3}, {'_account_id': 13039}, {'_account_id': 13642}]","[{'number': 1, 'created': '2016-05-11 16:01:12.000000000', 'files': ['doc/liberty-deployment-warning.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f6e1786563dda98f39190f5e1844eea1bea2812c', 'message': 'Update liberty deployment warning\n\nTell folks about the state of liberty 1.0.0 and to use\n1.1.0 for production deployments.\n\nChange-Id: Iea824e8fc6489d8222e089199161ca3fb30a8310\n'}]",0,315144,f6e1786563dda98f39190f5e1844eea1bea2812c,8,3,1,2834,,,0,"Update liberty deployment warning

Tell folks about the state of liberty 1.0.0 and to use
1.1.0 for production deployments.

Change-Id: Iea824e8fc6489d8222e089199161ca3fb30a8310
",git fetch https://review.opendev.org/openstack/kolla refs/changes/44/315144/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/liberty-deployment-warning.rst'],1,f6e1786563dda98f39190f5e1844eea1bea2812c,,"Please use Liberty 1.1.0 tag or later when using Kolla. No data loss occurs with this version. stable/liberty is also fully functional and suffers no data loss. Data loss with 1.0.0 --------------------To rectify this problem, the OpenStack release and infrastructure teams in coordination with the Kolla team executed the following actions: * Deleted the stable/liberty branch (where 1.0.0 was tagged from) * Created a tag liberty-early-demise at the end of the broken stable/liberty branch development. * Created a new stable/liberty branch based upon stable/mitaka. * Corrected stable/liberty to deploy Liberty. * Released Kolla 1.1.0 from the newly created stable/liberty branch. End Result ---------- A fully functional Liberty OpenStack deployment based upon the two years of testing that went into the development that went into stable/mitaka. The docker-engine 1.10.0 or later is required.","To rectify this problem, we plan to have a release of 1.1.0-rc1 on April 1st, 2016. We plan our final releae of 1.1.0 on April 15th, 2016. The work going into this version will be: * Move forward to Docker 1.10.z as a minimum dependency. * Move to named volumes to remove data loss scenario. * Backport upgrade playbooks from Mitaka so Operators may effectively manage OSSA and CVE advisories in their OpenStack cloud without being forced to migrate to Mitaka. * Backport thin-containers for Neutron agents. * Backport Kolla's docker integration module to remove the hard pin on Docker 1.8.2. * The Kolla community expects the docker containers themselves to be minimally modified.",21,13
openstack%2Fproject-config~master~Ia60a1445ad2fa48a9667b00bce8a0f67a87f5f0c,openstack/project-config,master,Ia60a1445ad2fa48a9667b00bce8a0f67a87f5f0c,Add js-generator-openstack to OpenStack-Infra,MERGED,2016-05-09 19:07:33.000000000,2016-05-11 17:27:29.000000000,2016-05-11 17:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 9717}]","[{'number': 1, 'created': '2016-05-09 19:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ee3ae6df35487bd14ec6f3f250f6e34e350cedfb', 'message': 'Add js-generator-openstack to OpenStack-Infra\n\nThis repository is a project template for the Yeoman project\nscaffolding and maintenance framework, which is the JavaScript\nequivalent of python\'s cookiecutter. Its purpose is to handle the\nquestion of ""How does OpenStack do JavaScript"".\n\nThe charter of this project is to roll up several project\nmaintenance concerns which, in our Python projects, are spread\nbetween cookiecutter, requirement management, and infra. The justification\nis both usability and usage. Usability, so that creating and/or updating\na new JavaScript project is simple, and to create \'one place\' from which\nwe publish changes. Usage, because placing more concerns into one project\nwill be easier to manage for today\'s limited number of JavaScript devs.\n\nThe goal is that at any point, an engineer may run `yo openstack` at the\nroot level of an existing (or new) javascript project, and expect their\nproject to be updated to the latest requirements, tools, and expected\nminimum gate criteria.\n\nBecause this project includes the concerns of several teams, it has been\nproposed under the OpenStack-Infra program. The reason is that of the\nthree major concerns - requirements, CTI, and templating - the first is\nslated to be moved under the infra banner now that it\'s stable, and the\nsecond is already under the infra banner.\n\nChange-Id: Ia60a1445ad2fa48a9667b00bce8a0f67a87f5f0c\nNeeded-by: Ia4c1e1b210b6bf9c973f4f83ca3856d83ca28824\n'}, {'number': 2, 'created': '2016-05-10 13:08:12.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/acls/openstack-infra/js-generator-openstack.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/78bce69b48254d183ceef5a10c771a5e9c1f31d4', 'message': 'Add js-generator-openstack to OpenStack-Infra\n\nThis repository is a project template for the Yeoman project\nscaffolding and maintenance framework, which is the JavaScript\nequivalent of python\'s cookiecutter. Its purpose is to handle the\nquestion of ""How does OpenStack do JavaScript"".\n\nThe charter of this project is to roll up several project\nmaintenance concerns which, in our Python projects, are spread\nbetween cookiecutter, requirement management, and infra. The justification\nis both usability and usage. Usability, so that creating and/or updating\na new JavaScript project is simple, and to create \'one place\' from which\nwe publish changes. Usage, because placing more concerns into one project\nwill be easier to manage for today\'s limited number of JavaScript devs.\n\nThe goal is that at any point, an engineer may run `yo openstack` at the\nroot level of an existing (or new) javascript project, and expect their\nproject to be updated to the latest requirements, tools, and expected\nminimum gate criteria.\n\nBecause this project includes the concerns of several teams, it has been\nproposed under the OpenStack-Infra program. The reason is that of the\nthree major concerns - requirements, CTI, and templating - the first is\nslated to be moved under the infra banner now that it\'s stable, and the\nsecond is already under the infra banner.\n\nChange-Id: Ia60a1445ad2fa48a9667b00bce8a0f67a87f5f0c\nNeeded-by: Ia4c1e1b210b6bf9c973f4f83ca3856d83ca28824\n'}]",3,314240,78bce69b48254d183ceef5a10c771a5e9c1f31d4,16,4,2,9717,,,0,"Add js-generator-openstack to OpenStack-Infra

This repository is a project template for the Yeoman project
scaffolding and maintenance framework, which is the JavaScript
equivalent of python's cookiecutter. Its purpose is to handle the
question of ""How does OpenStack do JavaScript"".

The charter of this project is to roll up several project
maintenance concerns which, in our Python projects, are spread
between cookiecutter, requirement management, and infra. The justification
is both usability and usage. Usability, so that creating and/or updating
a new JavaScript project is simple, and to create 'one place' from which
we publish changes. Usage, because placing more concerns into one project
will be easier to manage for today's limited number of JavaScript devs.

The goal is that at any point, an engineer may run `yo openstack` at the
root level of an existing (or new) javascript project, and expect their
project to be updated to the latest requirements, tools, and expected
minimum gate criteria.

Because this project includes the concerns of several teams, it has been
proposed under the OpenStack-Infra program. The reason is that of the
three major concerns - requirements, CTI, and templating - the first is
slated to be moved under the infra banner now that it's stable, and the
second is already under the infra banner.

Change-Id: Ia60a1445ad2fa48a9667b00bce8a0f67a87f5f0c
Needed-by: Ia4c1e1b210b6bf9c973f4f83ca3856d83ca28824
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/314240/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/acls/openstack-infra/js-generator-openstack.config', 'gerrit/projects.yaml', 'gerrit/acls/openstack-infra/infra-javascript.config', 'zuul/layout.yaml']",6,ee3ae6df35487bd14ec6f3f250f6e34e350cedfb,neverland, - name: openstack-infra/js-generator-openstack template: - name: merge-check - name: javascript-jobs - name: publish-to-npm ,,52,0
openstack%2Ftripleo-ui~master~I02fce1d6a3b879d265cd3f2c76899a6464f7d329,openstack/tripleo-ui,master,I02fce1d6a3b879d265cd3f2c76899a6464f7d329,Refactor Plans actions and reducer,MERGED,2016-05-03 10:01:24.000000000,2016-05-11 17:27:10.000000000,2016-05-11 17:27:10.000000000,"[{'_account_id': 3}, {'_account_id': 7509}, {'_account_id': 10112}, {'_account_id': 17888}, {'_account_id': 20970}]","[{'number': 1, 'created': '2016-05-03 10:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/5a2eb834ca1ed0574e0660b1b0072fdb5ab9a773', 'message': 'Refactor Plans actions and reducer\n\nThis change splits Current plan and Stacks into separate\nactions and action creators\n\nChange-Id: I02fce1d6a3b879d265cd3f2c76899a6464f7d329\n'}, {'number': 2, 'created': '2016-05-03 14:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/bcfc20dd888da6e637e013a0d2936f2f47b4537a', 'message': 'Refactor Plans actions and reducer\n\nThis change splits Current plan and Stacks into separate\nactions and action creators\n\nChange-Id: I02fce1d6a3b879d265cd3f2c76899a6464f7d329\n'}, {'number': 3, 'created': '2016-05-09 09:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/391742d4135cee7dc50b8b30b27c6fa733a905f8', 'message': 'Refactor Plans actions and reducer\n\nThis change splits Current plan and Stacks into separate\nactions and action creators\n\nChange-Id: I02fce1d6a3b879d265cd3f2c76899a6464f7d329\n'}, {'number': 4, 'created': '2016-05-11 15:49:09.000000000', 'files': ['src/__tests__/actions/PlansActions.tests.js', 'src/js/reducers/stacksReducer.js', 'src/__tests__/selectors/stacks.tests.js', 'src/__tests__/actions/StacksActions.tests.js', 'src/js/constants/PlansConstants.js', 'src/__tests__/reducers/currentPlanReducer.tests.js', 'src/js/index.js', 'src/js/reducers/currentPlanReducer.js', 'src/js/actions/CurrentPlanActions.js', 'src/js/reducers/plansReducer.js', 'src/js/components/deployment_plan/DeploymentPlan.js', 'src/js/actions/StacksActions.js', 'src/js/reducers/appReducer.js', 'src/__tests__/selectors/plans.tests.js', 'src/js/immutableRecords/currentPlan.js', 'src/js/immutableRecords/stacks.js', 'src/__tests__/components/deployment_plan/deploymentPlan.tests.js', 'src/js/selectors/stacks.js', 'src/js/components/plan/ListPlans.js', 'src/js/actions/PlansActions.js', 'src/__tests__/reducers/plansReducer.tests.js', 'src/js/immutableRecords/plans.js', 'src/js/selectors/plans.js', 'src/js/components/environment_configuration/EnvironmentConfiguration.js', 'src/js/constants/StacksConstants.js', 'src/__tests__/reducers/stacksReducer.tests.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/0a375d7b87dadc59c9f2abaea4d1308d9e69af88', 'message': 'Refactor Plans actions and reducer\n\nThis change splits Current plan and Stacks into separate\nactions and action creators\n\nChange-Id: I02fce1d6a3b879d265cd3f2c76899a6464f7d329\n'}]",5,312007,0a375d7b87dadc59c9f2abaea4d1308d9e69af88,27,5,4,7509,,,0,"Refactor Plans actions and reducer

This change splits Current plan and Stacks into separate
actions and action creators

Change-Id: I02fce1d6a3b879d265cd3f2c76899a6464f7d329
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/07/312007/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/__tests__/actions/PlansActions.tests.js', 'src/js/reducers/stacksReducer.js', 'src/__tests__/selectors/stacks.tests.js', 'src/__tests__/actions/StacksActions.tests.js', 'src/js/constants/PlansConstants.js', 'src/__tests__/reducers/currentPlanReducer.tests.js', 'src/js/index.js', 'src/js/reducers/currentPlanReducer.js', 'src/js/actions/CurrentPlanActions.js', 'src/js/reducers/plansReducer.js', 'src/js/actions/StacksActions.js', 'src/js/reducers/appReducer.js', 'src/__tests__/selectors/plans.tests.js', 'src/js/immutableRecords/stacks.js', 'src/__tests__/components/deployment_plan/deploymentPlan.tests.js', 'src/js/selectors/stacks.js', 'src/js/components/plan/ListPlans.js', 'src/js/actions/PlansActions.js', 'src/__tests__/reducers/plansReducer.tests.js', 'src/js/immutableRecords/plans.js', 'src/js/selectors/plans.js', 'src/js/components/deployment-plan/DeploymentPlan.js', 'src/js/components/environment_configuration/EnvironmentConfiguration.js', 'src/js/constants/StacksConstants.js', 'src/__tests__/reducers/stacksReducer.tests.js']",25,5a2eb834ca1ed0574e0660b1b0072fdb5ab9a773,register_nodes,"import { Map } from 'immutable'; import matchers from 'jasmine-immutable-matchers'; import { StacksState, Stack } from '../../js/immutableRecords/stacks'; import StacksActions from '../../js/actions/StacksActions'; import stacksReducer from '../../js/reducers/stacksReducer'; describe('stacksReducer state', () => { beforeEach(() => { jasmine.addMatchers(matchers); }); describe('default state', () => { let state; beforeEach(() => { state = stacksReducer(undefined, {type: 'undefined-action'}); }); it('`isFetching` is false', () => { expect(state.isFetching).toBe(false); }); it('`isLoaded` is false', () => { expect(state.get('isLoaded')).toBe(false); }); it('`stacks` is empty', () => { expect(state.get('stacks').size).toEqual(0); }); }); describe('Stack status', () => { describe('fetchStacksPending', () => { it('sets isFetching to true', () => { expect(stacksReducer(undefined, StacksActions.fetchStacksPending()).isFetching) .toBe(true); }); }); describe('fetchStacksSuccess', () => { let state; beforeEach(() => { state = stacksReducer( new StacksState({ isFetching: true }), StacksActions.fetchStacksSuccess([ { stack_name: 'overcloud', stack_status: 'CREATE_COMPLETE' } ]) ); }); it('sets isLoaded to true', () => { expect(state.isFetching).toBe(false); }); it('sets isFetching to false', () => { expect(state.isFetching).toBe(false); }); it('sets stacks in state', () => { expect(state.stacks).toEqualImmutable(Map({ overcloud: new Stack({ stack_name: 'overcloud', stack_status: 'CREATE_COMPLETE' }) })); }); }); describe('fetchStacksFailed', () => { let state; beforeEach(() => { state = stacksReducer( new StacksState({ isFetching: true }), StacksActions.fetchStacksFailed() ); }); it('sets isFetching to false', () => { expect(state.isFetching).toBe(false); }); it('sets stacks in state to an empty Map', () => { expect(state.stacks).toEqualImmutable(Map()); }); }); }); }); ",,547,391
openstack%2Fneutron~stable%2Fmitaka~Idb3c54cd0aa7a8d60886c920ae2e60b2a2df7220,openstack/neutron,stable/mitaka,Idb3c54cd0aa7a8d60886c920ae2e60b2a2df7220,DVR: Ensure fpr and rfp devices are configured correctly,ABANDONED,2016-05-10 20:46:16.000000000,2016-05-11 17:25:16.000000000,,"[{'_account_id': 1131}, {'_account_id': 10692}]","[{'number': 1, 'created': '2016-05-10 20:46:16.000000000', 'files': ['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/20ae6320e6f07a0af799db879d93daa0dc5a64cd', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exist.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\n(cherry picked from commit a47d22942a46cf12589cee6353dc2b6deb58f178)\n\nChange-Id: Idb3c54cd0aa7a8d60886c920ae2e60b2a2df7220\n'}]",0,314767,20ae6320e6f07a0af799db879d93daa0dc5a64cd,3,2,1,7016,,,0,"DVR: Ensure fpr and rfp devices are configured correctly

Restarting the l3-agent when creating the fip namespace may
leave rfp and fpr devices with no IP addresses, since we will
not try and configure them if the devices already exist.

Fix this by always trying to configure the IP addresses,
even if the devices already exist.

Closes-Bug: #1566383
(cherry picked from commit a47d22942a46cf12589cee6353dc2b6deb58f178)

Change-Id: Idb3c54cd0aa7a8d60886c920ae2e60b2a2df7220
",git fetch https://review.opendev.org/openstack/neutron refs/changes/67/314767/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py']",2,20ae6320e6f07a0af799db879d93daa0dc5a64cd,bug/ensure_ip_fpr_rfp_1566383," def _test_create_rtr_2_fip_link(self, dev_exists, addr_exists, IPDevice, IPWrapper): device.addr.list.return_value = addr_exists if not addr_exists: expected = [mock.call(str(addr_pair[0]), add_broadcast=False), mock.call(str(addr_pair[1]), add_broadcast=False)] device.addr.add.assert_has_calls(expected) self.assertEqual(2, device.addr.add.call_count) self._test_create_rtr_2_fip_link(False, False) self._test_create_rtr_2_fip_link(True, False) def test_create_rtr_2_fip_link_and_addr_already_exist(self): self._test_create_rtr_2_fip_link(True, True)"," def _test_create_rtr_2_fip_link(self, dev_exists, IPDevice, IPWrapper): self._test_create_rtr_2_fip_link(False) self._test_create_rtr_2_fip_link(True)",17,3
openstack%2Finstack~master~Idc2a2c3eb7db9f1fa357e3838bc968502faa2766,openstack/instack,master,Idc2a2c3eb7db9f1fa357e3838bc968502faa2766,Correct example url in README,MERGED,2016-05-06 06:02:33.000000000,2016-05-11 17:24:08.000000000,2016-05-11 17:24:08.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}, {'_account_id': 11105}, {'_account_id': 16237}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-06 06:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack/commit/a5042384c2ea5faab1787fbfb722c5bfc550d02c', 'message': 'Correct example url in README\n\nChange-Id: Idc2a2c3eb7db9f1fa357e3838bc968502faa2766\n'}, {'number': 2, 'created': '2016-05-06 06:05:51.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/instack/commit/3fab413a582c277c7d7c26430e666cdae999c1c1', 'message': 'Correct example url in README\n\nTrivialFix\nChange-Id: Idc2a2c3eb7db9f1fa357e3838bc968502faa2766\n'}]",0,313235,3fab413a582c277c7d7c26430e666cdae999c1c1,18,6,2,19472,,,0,"Correct example url in README

TrivialFix
Change-Id: Idc2a2c3eb7db9f1fa357e3838bc968502faa2766
",git fetch https://review.opendev.org/openstack/instack refs/changes/35/313235/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,a5042384c2ea5faab1787fbfb722c5bfc550d02c,update-readme,https://github.com/openstack/instack-undercloud/blob/master/json-files/centos7-undercloud-packages.json,https://github.com/rdo-management/instack-undercloud/blob/master/json-files/fedora-20-undercloud-packages.json,1,1
openstack%2Ffuel-specs~master~Ia501754922b3272acd1a865513d5dffa17981331,openstack/fuel-specs,master,Ia501754922b3272acd1a865513d5dffa17981331,Use docutils AST for making smart checks,MERGED,2016-04-18 13:34:47.000000000,2016-05-11 17:23:52.000000000,2016-05-11 17:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8392}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 11090}, {'_account_id': 12817}, {'_account_id': 13505}]","[{'number': 1, 'created': '2016-04-18 13:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/38f53549dd80b76bf6aa9f9e4da134135885147f', 'message': ""Use reStructuredText for making smart checks\n\nTrying to enable testing specs for 9.0, we've encountered different\nunavoidable problems with existing checks. For example, it was\nimpossible to have code blocks with line length more than 80 characters.\n\nThis commit uses docutils and make those changes using AST, so we can\navoid some checks for code-blocks or long links.\n\nChange-Id: Ia501754922b3272acd1a865513d5dffa17981331\n""}, {'number': 2, 'created': '2016-04-19 07:30:38.000000000', 'files': ['specs/9.0/expose-serialized-graph.rst', 'specs/6.1/dry-run-deploy.rst', 'tests/test_titles.py', 'specs/9.0/remove-centos-bootstrap-from-fuel.rst', 'specs/9.0/unify-the-input-data.rst', 'specs/6.1/cinder-vmdk-role.rst', 'specs/7.0/ui-functional-tests-with-intern.rst', 'specs/9.0/execute-custom-graph.rst', 'specs/9.0/graceful-stop-restart-deployment.rst', 'specs/9.0/support-hugepages.rst', 'specs/5.1/upgrade-lrzip.rst', 'specs/9.0/tasks-computable-fields-with-yaql.rst', 'specs/9.0/fuel-remove-conflict-openstack.rst', 'specs/9.0/fuel-aodh-integration.rst', 'specs/9.0/get-rid-docker-containers.rst', 'specs/9.0/network-config-refactoring.rst', 'specs/9.0/fc-multipath-disks.rst', 'tests/base.py', 'specs/9.0/switch-to-centos-7-2.rst', 'specs/9.0/set-vip-address-via-api.rst', 'specs/9.0/store-deployment-tasks-history.rst', 'specs/6.1/reboot-task-type-for-plugin-developers.rst', 'specs/7.0/upgrade-openstack-puppet-modules.rst', 'specs/9.0/component-registry-improvements.rst', 'specs/9.0/cgroups.rst', 'specs/9.0/support-sriov.rst', 'specs/6.1/support-infiniband-network.rst', 'specs/9.0/support-qos.rst', 'specs/9.0/refactor-osnailyfacter-to-be-compatible-with-puppet-master.rst', 'specs/6.1/fuel-master-separate-logs.rst', 'specs/8.0/multi-rack-static.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6ec0b000dd70080b434a3434a284d233123372b4', 'message': ""Use docutils AST for making smart checks\n\nTrying to enable testing specs for 9.0, we've encountered different\nunavoidable problems with existing checks. For example, it was\nimpossible to have code blocks with line length more than 80 characters.\n\nThis commit uses docutils and make those changes using AST, so we can\navoid some checks for code-blocks or long links.\n\nCloses-Bug: #1569929\nChange-Id: Ia501754922b3272acd1a865513d5dffa17981331\n""}]",2,307180,6ec0b000dd70080b434a3434a284d233123372b4,13,8,2,10391,,,0,"Use docutils AST for making smart checks

Trying to enable testing specs for 9.0, we've encountered different
unavoidable problems with existing checks. For example, it was
impossible to have code blocks with line length more than 80 characters.

This commit uses docutils and make those changes using AST, so we can
avoid some checks for code-blocks or long links.

Closes-Bug: #1569929
Change-Id: Ia501754922b3272acd1a865513d5dffa17981331
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/80/307180/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/9.0/expose-serialized-graph.rst', 'specs/6.1/dry-run-deploy.rst', 'tests/test_titles.py', 'specs/9.0/remove-centos-bootstrap-from-fuel.rst', 'specs/9.0/unify-the-input-data.rst', 'specs/6.1/cinder-vmdk-role.rst', 'specs/7.0/ui-functional-tests-with-intern.rst', 'specs/9.0/execute-custom-graph.rst', 'specs/9.0/graceful-stop-restart-deployment.rst', 'specs/9.0/support-hugepages.rst', 'specs/5.1/upgrade-lrzip.rst', 'specs/9.0/fuel-remove-conflict-openstack.rst', 'specs/9.0/fuel-aodh-integration.rst', 'specs/9.0/get-rid-docker-containers.rst', 'specs/9.0/network-config-refactoring.rst', 'specs/9.0/fc-multipath-disks.rst', 'tests/base.py', 'specs/9.0/switch-to-centos-7-2.rst', 'specs/9.0/set-vip-address-via-api.rst', 'specs/9.0/store-deployment-tasks-history.rst', 'specs/6.1/reboot-task-type-for-plugin-developers.rst', 'specs/7.0/upgrade-openstack-puppet-modules.rst', 'specs/9.0/component-registry-improvements.rst', 'specs/9.0/cgroups.rst', 'specs/9.0/support-sriov.rst', 'specs/6.1/support-infiniband-network.rst', 'specs/9.0/support-qos.rst', 'specs/9.0/refactor-osnailyfacter-to-be-compatible-with-puppet-master.rst', 'specs/6.1/fuel-master-separate-logs.rst', 'specs/8.0/multi-rack-static.rst']",30,38f53549dd80b76bf6aa9f9e4da134135885147f,bug/1569929,controller nodes. See https://blueprints.launchpad.net/fuel/+spec/test-custom-nodegroup-controllersthem. See https://blueprints.launchpad.net/fuel/+spec/test-nodegroups-share-networksinterface for admin/pxe network. See https://bugs.launchpad.net/fuel/+bug/1513159new features. See https://blueprints.launchpad.net/fuel/+spec/align-nodegroups-tests,controller nodes. See https://blueprints.launchpad.net/fuel/+spec/test-custom-nodegroup-controllersthem. See https://blueprints.launchpad.net/fuel/+spec/test-nodegroups-share-networksinterface for admin/pxe network. See https://bugs.launchpad.net/fuel/+bug/1513159new features. See https://blueprints.launchpad.net/fuel/+spec/align-nodegroups-tests,383,157
openstack%2Fneutron~stable%2Fmitaka~Icecf303c4fb1751d1042b1572fdeb987e57379b4,openstack/neutron,stable/mitaka,Icecf303c4fb1751d1042b1572fdeb987e57379b4,DVR: Ensure fpr and rfp devices are configured correctly,ABANDONED,2016-05-10 20:34:37.000000000,2016-05-11 17:23:43.000000000,,"[{'_account_id': 1131}, {'_account_id': 10692}]","[{'number': 1, 'created': '2016-05-10 20:34:37.000000000', 'files': ['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a189cf42f441865dbf2c4bbd2c6712bf847d8485', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exist.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\n(cherry picked from commit a47d22942a46cf12589cee6353dc2b6deb58f178)\n\nConflicts:\n\tneutron/tests/unit/agent/l3/test_dvr_fip_ns.py\n\nChange-Id: Icecf303c4fb1751d1042b1572fdeb987e57379b4\n'}]",0,314762,a189cf42f441865dbf2c4bbd2c6712bf847d8485,3,2,1,7016,,,0,"DVR: Ensure fpr and rfp devices are configured correctly

Restarting the l3-agent when creating the fip namespace may
leave rfp and fpr devices with no IP addresses, since we will
not try and configure them if the devices already exist.

Fix this by always trying to configure the IP addresses,
even if the devices already exist.

Closes-Bug: #1566383
(cherry picked from commit a47d22942a46cf12589cee6353dc2b6deb58f178)

Conflicts:
	neutron/tests/unit/agent/l3/test_dvr_fip_ns.py

Change-Id: Icecf303c4fb1751d1042b1572fdeb987e57379b4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/314762/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py']",2,a189cf42f441865dbf2c4bbd2c6712bf847d8485,bug/use-existing-ip-device-1566383," def _test_create_rtr_2_fip_link(self, dev_exists, IPDevice, IPWrapper): addr_pair = pair.get_pair() device = IPDevice() device.exists.return_value = dev_exists if not addr_exists: expected = [mock.call(str(addr_pair[0]), add_broadcast=False), mock.call(str(addr_pair[1]), add_broadcast=False)] device.addr.add.assert_has_calls(expected) self.assertEqual(2, device.addr.add.call_count) def test_create_rtr_2_fip_link(self): self._test_create_rtr_2_fip_link(False) def test_create_rtr_2_fip_link_already_exists(self): self._test_create_rtr_2_fip_link(True) def test_create_rtr_2_fip_link_and_addr_already_exist(self): self._test_create_rtr_2_fip_link(True, True) >>>>>>> a47d229... DVR: Ensure fpr and rfp devices are configured correctly"," @mock.patch.object(ip_lib, 'device_exists') def test_create_rtr_2_fip_link(self, device_exists, IPDevice, IPWrapper): device_exists.return_value = False device = IPDevice() device.link.set_mtu.assert_called_with(2000) self.assertEqual(2, device.link.set_mtu.call_count) @mock.patch.object(ip_lib, 'IPWrapper') @mock.patch.object(ip_lib, 'IPDevice') @mock.patch.object(ip_lib, 'device_exists') def test_create_rtr_2_fip_link_already_exists(self, device_exists, IPDevice, IPWrapper): ri = mock.Mock() ri.router_id = _uuid() ri.rtr_fip_subnet = None device_exists.return_value = True self.fip_ns.local_subnets = allocator = mock.Mock() pair = lla.LinkLocalAddressPair('169.254.31.28/31') allocator.allocate.return_value = pair self.fip_ns.create_rtr_2_fip_link(ri) ip_wrapper = IPWrapper() self.assertFalse(ip_wrapper.add_veth.called)",23,26
openstack%2Fheat-specs~master~Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656,openstack/heat-specs,master,Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656,backlog spec directory,MERGED,2015-12-22 05:13:43.000000000,2016-05-11 17:19:44.000000000,2016-05-11 17:19:44.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8399}, {'_account_id': 12363}, {'_account_id': 12404}]","[{'number': 1, 'created': '2015-12-22 05:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/4ac7fe8a454bb108eb311a39076ff296e52f65ed', 'message': 'backlog spec directory\n\nCreate backlog spec directory for store all specs that been approved but\nunder any reasons can not be implemented under this release will be moved to\nbacklog directory, and will be move to any release directory if it is\nimplemented.\n\nChange-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656\n'}, {'number': 2, 'created': '2015-12-22 05:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/6ef98a7172e2f34cc3aa764751309b0f82945194', 'message': 'backlog spec directory\n\nCreate backlog spec directory for store all specs that been approved but\nunder any reasons can not be implemented under this release will be moved to\nbacklog directory, and will be move to any release directory if it is\nimplemented.\n\nChange-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656\n'}, {'number': 3, 'created': '2015-12-28 09:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/17139769b50a73f45721adf2cb87854ac79af870', 'message': 'backlog spec directory\n\nCreate backlog spec directory for store all specs that been approved but\nunder any reasons can not be implemented under this release will be moved to\nbacklog directory, and will be move to any release directory if it is\nimplemented.\n\nChange-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656\n'}, {'number': 4, 'created': '2015-12-28 09:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/0f81ee84317cdcf1b0936f9dc8d6dccfe95cee3c', 'message': 'backlog spec directory\n\nCreate backlog spec directory for store all specs that been approved but\nunder any reasons can not be implemented under this release will be\nmoved to backlog directory, and will be move to any release directory if\nit is implemented.\nChange-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656\n'}, {'number': 5, 'created': '2016-01-17 05:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/7e2dc0ab3a43c1749d72ad3d7503b2a184ca0f4f', 'message': 'backlog spec directory\n\nCreate backlog spec directory for store all specs that been approved but\nunder any reasons can not be implemented under this release will be\nmoved to backlog directory, and will be move to any release directory if\nit is implemented.\nChange-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656\n'}, {'number': 6, 'created': '2016-01-17 05:55:58.000000000', 'files': ['specs/backlog/.placeholder', 'specs/templates/backlog-template.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/ff4ba0357b0c94cdd9e19cf31ad7e21d219af595', 'message': 'backlog spec directory\n\nCreate backlog spec directory for store all specs that been approved but\nunder any reasons can not be implemented under this release will be\nmoved to backlog directory, and will be move to any release directory if\nit is implemented.\nChange-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656\nDepends-On: Ibc0c77642bb40303606047a54e3e198e7ef5a962\n'}]",0,260320,ff4ba0357b0c94cdd9e19cf31ad7e21d219af595,26,7,6,12404,,,0,"backlog spec directory

Create backlog spec directory for store all specs that been approved but
under any reasons can not be implemented under this release will be
moved to backlog directory, and will be move to any release directory if
it is implemented.
Change-Id: Ib125ab7164ed48bfc3a35d6cab6ce0c69aa06656
Depends-On: Ibc0c77642bb40303606047a54e3e198e7ef5a962
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/20/260320/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/.placeholder'],1,4ac7fe8a454bb108eb311a39076ff296e52f65ed,refactor-specs,,,0,0
openstack%2Fneutron~stable%2Fmitaka~I38500cb9b2aea534d4c45e48219c3abcc563a0f9,openstack/neutron,stable/mitaka,I38500cb9b2aea534d4c45e48219c3abcc563a0f9,DVR: Use existing IPDevice to add address on FIP VETH,ABANDONED,2016-05-10 18:52:39.000000000,2016-05-11 17:19:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 10692}, {'_account_id': 14208}]","[{'number': 1, 'created': '2016-05-10 18:52:39.000000000', 'files': ['neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9da45617a678df42a2829f83d3998cf01ed30d2c', 'message': ""DVR: Use existing IPDevice to add address on FIP VETH\n\ncreate_rtr_2_fip_link() has IPDevice instances for each\nend of the VETH pair it created, just use them to add the\nlink-local IP to each one.  Because this is a point-to-point\nlink, we don't add the broadcast address when we assign the IP,\nso add a flag to IpAddrCommand() class to accomodate us.\nThis is also setup for a follow-on patch.\n\nPartial-Bug: #1566383\n(cherry picked from commit 17cfffbbfa57ccec54c7e06518b5e7e8a00e0c51)\n\nConflicts:\n\tneutron/agent/l3/dvr_fip_ns.py\n\nChange-Id: I38500cb9b2aea534d4c45e48219c3abcc563a0f9\n""}]",0,314722,9da45617a678df42a2829f83d3998cf01ed30d2c,7,6,1,7016,,,0,"DVR: Use existing IPDevice to add address on FIP VETH

create_rtr_2_fip_link() has IPDevice instances for each
end of the VETH pair it created, just use them to add the
link-local IP to each one.  Because this is a point-to-point
link, we don't add the broadcast address when we assign the IP,
so add a flag to IpAddrCommand() class to accomodate us.
This is also setup for a follow-on patch.

Partial-Bug: #1566383
(cherry picked from commit 17cfffbbfa57ccec54c7e06518b5e7e8a00e0c51)

Conflicts:
	neutron/agent/l3/dvr_fip_ns.py

Change-Id: I38500cb9b2aea534d4c45e48219c3abcc563a0f9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/314722/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py']",3,9da45617a678df42a2829f83d3998cf01ed30d2c,bug/1566383," def test_add_address_no_broadcast(self): self.addr_cmd.add('192.168.45.100/24', add_broadcast=False) self._assert_sudo([4], ('add', '192.168.45.100/24', 'scope', 'global', 'dev', 'tap0')) ",,20,20
openstack%2Fpuppet-designate~master~If65cd0afc6275348acf1f198679c0d8ec05f7e37,openstack/puppet-designate,master,If65cd0afc6275348acf1f198679c0d8ec05f7e37,Fix markdown format typo,MERGED,2016-05-10 15:58:45.000000000,2016-05-11 17:19:04.000000000,2016-05-11 17:19:04.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-10 15:58:45.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/03ef641fef9a163c9821f86d2cbf5fca08697a4b', 'message': 'Fix markdown format typo\n\nChange-Id: If65cd0afc6275348acf1f198679c0d8ec05f7e37\n'}]",0,314649,03ef641fef9a163c9821f86d2cbf5fca08697a4b,7,3,1,9414,,,0,"Fix markdown format typo

Change-Id: If65cd0afc6275348acf1f198679c0d8ec05f7e37
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/49/314649/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,03ef641fef9a163c9821f86d2cbf5fca08697a4b,fix-doc-typo,```shell```,``shell``,2,2
openstack%2Fnova~master~Ic3b44ace349b23f9ecf32fa450ae4552c6420fe2,openstack/nova,master,Ic3b44ace349b23f9ecf32fa450ae4552c6420fe2,api-ref: Method verification for floating-ip-pools,ABANDONED,2016-05-10 22:41:51.000000000,2016-05-11 17:09:50.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 18335}]","[{'number': 1, 'created': '2016-05-10 22:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cbe824cc8e26f05a1576360ad17ffbcb84751003', 'message': 'api-ref: Method verification for floating-ip-pools\n\nVerify and update the response codes for the API document\nos-floating-ip-pools.inc based on what is in the code.\n\npart of blueprint: api-ref-in-rstwq\n\nChange-Id: Ic3b44ace349b23f9ecf32fa450ae4552c6420fe2\n'}, {'number': 2, 'created': '2016-05-10 22:44:47.000000000', 'files': ['api-ref/source/os-floating-ip-pools.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/69d35d9e0c8d3591c110f4a0781836e66917e308', 'message': 'api-ref: Method verification for floating-ip-pools\n\nVerify and update the response codes for the API document\nos-floating-ip-pools.inc based on what is in the code.\n\npart of blueprint: api-ref-in-rst\n\nChange-Id: Ic3b44ace349b23f9ecf32fa450ae4552c6420fe2\n'}]",0,314798,69d35d9e0c8d3591c110f4a0781836e66917e308,17,10,2,18335,,,0,"api-ref: Method verification for floating-ip-pools

Verify and update the response codes for the API document
os-floating-ip-pools.inc based on what is in the code.

part of blueprint: api-ref-in-rst

Change-Id: Ic3b44ace349b23f9ecf32fa450ae4552c6420fe2
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/314798/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-floating-ip-pools.inc'],1,cbe824cc8e26f05a1576360ad17ffbcb84751003,bp/api-ref-in-rst,"Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: unauthorized(401), forbidden(403), itemNotFound(404)",".. needs:method_verificationPolicy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",4,4
openstack%2Fnova-specs~master~I6083ce789a26e8ce4073ae887f1df2071dd03054,openstack/nova-specs,master,I6083ce789a26e8ce4073ae887f1df2071dd03054,Add spec for lower case metadata keys only,MERGED,2016-04-30 17:06:11.000000000,2016-05-11 17:08:52.000000000,2016-05-06 14:53:50.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 10962}, {'_account_id': 17714}]","[{'number': 1, 'created': '2016-04-30 17:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9b4d23d3ccc8c8d71172ca14c02b6eebc608eeb7', 'message': 'Add spec for lower case metadata keys only\n\nChange-Id: I6083ce789a26e8ce4073ae887f1df2071dd03054\n'}, {'number': 2, 'created': '2016-05-03 13:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/576d7fd5d709df4d1bcbc3f5936799422bc0473c', 'message': 'Add spec for lower case metadata keys only\n\nThis proposes the newest attempt to get to consistent metadata\nhandling in Nova given differences in backend storage.\n\nChange-Id: I6083ce789a26e8ce4073ae887f1df2071dd03054\n'}, {'number': 3, 'created': '2016-05-04 11:31:22.000000000', 'files': ['specs/newton/approved/lowercase-metadata-keys.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7e7999c226e6282a0fea2db75c4b97b7f502e8f2', 'message': 'Add spec for lower case metadata keys only\n\nThis proposes the newest attempt to get to consistent metadata\nhandling in Nova given differences in backend storage.\n\nAPIImpact\n\nChange-Id: I6083ce789a26e8ce4073ae887f1df2071dd03054\n'}]",45,311529,7e7999c226e6282a0fea2db75c4b97b7f502e8f2,29,8,3,2750,,,0,"Add spec for lower case metadata keys only

This proposes the newest attempt to get to consistent metadata
handling in Nova given differences in backend storage.

APIImpact

Change-Id: I6083ce789a26e8ce4073ae887f1df2071dd03054
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/29/311529/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/approved/lowercase_metadata_keys_only.rst'],1,9b4d23d3ccc8c8d71172ca14c02b6eebc608eeb7,lowercase-metadata-keys,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Restrict valid characters for metadata keys =========================================== https://blueprints.launchpad.net/nova/+spec/lowercase-metadata-keys Change API validation to require metadata keys are only lower case ascii with a limited number of symbols to ensure consistent opperation regardless of database backend. Problem description =================== Metadata keys throughout Nova (as used by aggregates, flavors) have no restrictions on their content. Then end up stored in a database as columns. By default, MySQL does case *insensitive* equality. This leads to bugs of the following type: 1. If we have unique constraints on a column 1. Add key to a resource of name 'foo' 1. Add key to a resource of name 'Foo' - explodes as a constraint violation 1. If we don't have unique constraints on a column 1. Add keys to a resource named 'foo', 'Foo', 'FOO'. 1. Delete key 'foo' 1. All of 'foo', 'Foo', 'FOO' are deleted Up until this point there have been some complicated fixes that are largely whack a mole working around this by doing a second round of select / delete / update in python to make up for the case insensitivity issues. Proposed change =============== Create an API microversion after which point only a lower case ascii string (also including the characters '-', '_', ':') can be used as a key value. This will be enforced by the jsonschema validation extremely early in the API call. Update documentation to say that's all that is supported. In requests before the microversion we will not change behavior, however we will also close all bugs related to this as Won't Fix. A nova manage command for auditing and squashing existing metadata keys into the new storage format will be provided. Alternatives ------------ * Firey ball of suck Just keep glomming on more python hot fixes to try to approximate the behavior we want. This is unlikely to really converge to the point where we don't have bugs. * Force consistent behavior in database We could force MySQL to be case sensitive here which would remove a class of stack traces. However the becomes a potentially expensive migration, and means we have to care about all potential backends behaving correctly Data model impact ----------------- No data model changes will be made until we uplift microversion to the point where the old code is not supported. REST API impact --------------- No change to resources or attributes, however we'll now be returning 400 via the validation framework. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- There will now be metadata keys that won't be accessable via the API after the microversion. If other items such as scheduler filters or higher level orchestration trigger off these values there may need to be changes to them. A nova-manage command should be provided to audit and fold old keys into this new key structure. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: auggy Other contributors: sdague Work Items ---------- * Determine what symbols beyond [a-z] are required for metadata keys by asking on the operator list. * Implement jsonschema using this for a new microversion Dependencies ============ None Testing ======= Testing will be done with in tree functional testing as this is all just API and API <-> DB code paths. Documentation Impact ==================== API Reference site will be updated with new microversion. We will update the default documentation to say that the API only supports this subset of characters. This will hopefully get people using old versions to self reduce to this new character set. References ========== TODO (ML links, etherpad links) History ======= Optional section for Mitaka intended to be used each time the spec is updated to describe new design, API or any database schema updated. Useful to let reader understand what's happened along the time. .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Mitaka - Introduced ",,180,0
openstack%2Fpython-ironicclient~stable%2Fmitaka~I7cfaa5ab34633380dd1088ca27c8a5146a4b91a7,openstack/python-ironicclient,stable/mitaka,I7cfaa5ab34633380dd1088ca27c8a5146a4b91a7,Updated from global requirements,MERGED,2016-04-29 22:40:45.000000000,2016-05-11 17:08:11.000000000,2016-05-11 17:08:11.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-04-29 22:40:45.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8a637d0a15c80d59d334c24626a645ab60956ee9', 'message': 'Updated from global requirements\n\nChange-Id: I7cfaa5ab34633380dd1088ca27c8a5146a4b91a7\n'}]",0,311340,8a637d0a15c80d59d334c24626a645ab60956ee9,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I7cfaa5ab34633380dd1088ca27c8a5146a4b91a7
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/40/311340/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,8a637d0a15c80d59d334c24626a645ab60956ee9,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3 # BSD,1,1
openstack%2Fopenstack-ansible~kilo~I1d6db661b7d0958e1ba888770e3ce789d7cb4a76,openstack/openstack-ansible,kilo,I1d6db661b7d0958e1ba888770e3ce789d7cb4a76,Fix configuration string for haproxy,MERGED,2016-04-18 12:47:46.000000000,2016-05-11 17:00:51.000000000,2016-05-11 17:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-04-18 12:47:46.000000000', 'files': ['playbooks/roles/haproxy_server/templates/haproxy.cfg.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e85cb008ddb2d9124b2234cc8759dbcd286e6a3c', 'message': 'Fix configuration string for haproxy\n\nUse user and group configuration option, uid and gid need a number\ninstead of a name. Specifying a name for uid/gid attributes will make\nhaproxy run under the root user.\n\nChange-Id: I1d6db661b7d0958e1ba888770e3ce789d7cb4a76\n(cherry picked from commit a2c1d8ca2cc2d67e91f269c712781ae93d6903b0)\n'}]",0,307157,e85cb008ddb2d9124b2234cc8759dbcd286e6a3c,13,5,1,13095,,,0,"Fix configuration string for haproxy

Use user and group configuration option, uid and gid need a number
instead of a name. Specifying a name for uid/gid attributes will make
haproxy run under the root user.

Change-Id: I1d6db661b7d0958e1ba888770e3ce789d7cb4a76
(cherry picked from commit a2c1d8ca2cc2d67e91f269c712781ae93d6903b0)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/57/307157/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/haproxy_server/templates/haproxy.cfg.j2'],1,e85cb008ddb2d9124b2234cc8759dbcd286e6a3c,fix_haproxy_uid-gid, user haproxy group haproxy, uid haproxy gid haproxy,2,2
openstack%2Fkeystoneauth~master~I0b1247c7eb64224137e0321313b4d2e4fefe64d8,openstack/keystoneauth,master,I0b1247c7eb64224137e0321313b4d2e4fefe64d8,Updated from global requirements,MERGED,2016-05-11 13:58:39.000000000,2016-05-11 17:00:36.000000000,2016-05-11 17:00:36.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14614}]","[{'number': 1, 'created': '2016-05-11 13:58:39.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/01904a222fe62700b10483819dd749593f76306e', 'message': 'Updated from global requirements\n\nChange-Id: I0b1247c7eb64224137e0321313b4d2e4fefe64d8\n'}]",0,315058,01904a222fe62700b10483819dd749593f76306e,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I0b1247c7eb64224137e0321313b4d2e4fefe64d8
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/58/315058/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,01904a222fe62700b10483819dd749593f76306e,openstack/requirements, oauthlib>=0.6 # BSD, oauthlib>=0.6 # BSD,1,1
openstack%2Frequirements~master~I1b75478cdf13b6164b35df49cfc986607abe5f3c,openstack/requirements,master,I1b75478cdf13b6164b35df49cfc986607abe5f3c,Remove Ceilometer from projects,MERGED,2016-05-03 08:26:44.000000000,2016-05-11 16:59:46.000000000,2016-05-11 16:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6593}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 8290}, {'_account_id': 9562}, {'_account_id': 10384}, {'_account_id': 11564}, {'_account_id': 13560}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-05-03 08:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1564b75e2ee57d72a641020fb7b0e275f3d35249', 'message': 'Remove Ceilometer from projects\n\nAll other telemetry projects never participated in this repository. It\nactually turned out to be better, and now we wish to move on for\nCeilometer also.\n\nChange-Id: I1b75478cdf13b6164b35df49cfc986607abe5f3c\n'}, {'number': 2, 'created': '2016-05-06 14:24:06.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/24f4f1729278a27822fe8b115f1a2aa869e987ee', 'message': 'Remove Ceilometer from projects\n\nAll other telemetry projects never participated in this repository. It\nactually turned out to be better, and now we wish to move on for\nCeilometer also.\n\nChange-Id: I1b75478cdf13b6164b35df49cfc986607abe5f3c\n'}]",0,311989,24f4f1729278a27822fe8b115f1a2aa869e987ee,24,17,2,1669,,,0,"Remove Ceilometer from projects

All other telemetry projects never participated in this repository. It
actually turned out to be better, and now we wish to move on for
Ceilometer also.

Change-Id: I1b75478cdf13b6164b35df49cfc986607abe5f3c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/89/311989/2 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,1564b75e2ee57d72a641020fb7b0e275f3d35249,jd/remove-ceilo,,openstack/ceilometer,0,1
openstack%2Fmonasca-analytics~master~I8ae4ad840c86dcfb5a4c0146e7a54149bf7aa9a3,openstack/monasca-analytics,master,I8ae4ad840c86dcfb5a4c0146e7a54149bf7aa9a3,added pyparsing dependency,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:58:01.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/9540c899870bbc6c0ef8dea1531aabab8c3fb964', 'message': 'added pyparsing dependency\n\nChange-Id: I8ae4ad840c86dcfb5a4c0146e7a54149bf7aa9a3\n'}]",0,313467,9540c899870bbc6c0ef8dea1531aabab8c3fb964,2,0,1,21739,,,0,"added pyparsing dependency

Change-Id: I8ae4ad840c86dcfb5a4c0146e7a54149bf7aa9a3
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/67/313467/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,9540c899870bbc6c0ef8dea1531aabab8c3fb964,," ""kafka-python"", ""pyparsing"""," ""kafka-python""",2,1
openstack%2Fmonasca-analytics~master~I7f61ff9dc3b8990500def4adb5a8477fc13d8f60,openstack/monasca-analytics,master,I7f61ff9dc3b8990500def4adb5a8477fc13d8f60,implemented and tested the config manipulation logic,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:57:57.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/config/dsl.py', 'test/config/test_dsl.py', 'main/exception/dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3dcf60e0f972b576d9c652c621c8d9a9accede7e', 'message': 'implemented and tested the config manipulation logic\n\nChange-Id: I7f61ff9dc3b8990500def4adb5a8477fc13d8f60\n'}]",0,313452,3dcf60e0f972b576d9c652c621c8d9a9accede7e,2,0,1,21739,,,0,"implemented and tested the config manipulation logic

Change-Id: I7f61ff9dc3b8990500def4adb5a8477fc13d8f60
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/52/313452/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/config/dsl.py', 'test/config/test_dsl.py', 'main/exception/dsl.py']",3,3dcf60e0f972b576d9c652c621c8d9a9accede7e,,"#!/usr/bin/env python """"""DSL Error classes."""""" from abc import ABCMeta, abstractmethod class DSLException(Exception): __metaclass__ = ABCMeta @abstractmethod def __str__(self): pass class DSLExistingConnection(DSLException): def __init__(self, value): self._value = value def __str__(self): DSLException.__str__(self) return repr(self._value) class DSLInexistentComponent(DSLException): def __init__(self, value): self._value = value def __str__(self): DSLException.__str__(self) return repr(self._value) class DSLInvalidConnection(DSLException): def __init__(self, value): self._value = value def __str__(self): DSLException.__str__(self) return repr(self._value) ",,246,27
openstack%2Fmonasca-analytics~master~Ic70a8486407bcbd605874a76a46e0a553dfeff86,openstack/monasca-analytics,master,Ic70a8486407bcbd605874a76a46e0a553dfeff86,documented teh IPTables anomaly detection example,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:57:51.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/images/iptables_arch.png', 'doc/examples.md', 'doc/images/iptables_src.png'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/cb384474690e6332a43e8f7ea5a78417b5130a9e', 'message': 'documented teh IPTables anomaly detection example\n\nChange-Id: Ic70a8486407bcbd605874a76a46e0a553dfeff86\n'}]",0,313448,cb384474690e6332a43e8f7ea5a78417b5130a9e,2,0,1,21739,,,0,"documented teh IPTables anomaly detection example

Change-Id: Ic70a8486407bcbd605874a76a46e0a553dfeff86
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/48/313448/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/images/iptables_arch.png', 'doc/examples.md', 'doc/images/iptables_src.png']",3,cb384474690e6332a43e8f7ea5a78417b5130a9e,,,,140,1
openstack%2Fmonasca-analytics~master~I6a7b4326ab6370df08e19a4bcd64453479ee5a20,openstack/monasca-analytics,master,I6a7b4326ab6370df08e19a4bcd64453479ee5a20,added timestamp in the test,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:57:45.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/a92cd43c9a5928517e4229c489e28a32d2daad77', 'message': 'added timestamp in the test\n\nChange-Id: I6a7b4326ab6370df08e19a4bcd64453479ee5a20\n'}]",0,313444,a92cd43c9a5928517e4229c489e28a32d2daad77,2,0,1,21739,,,0,"added timestamp in the test

Change-Id: I6a7b4326ab6370df08e19a4bcd64453479ee5a20
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/44/313444/1 && git format-patch -1 --stdout FETCH_HEAD,['test/ingestor/test_iptables_ingestor.py'],1,a92cd43c9a5928517e4229c489e28a32d2daad77,," ""ping1"", ""ping2"", ""ping3"", ""time""]) processed, np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1460401152]))"," ""ping1"", ""ping2"", ""ping3""]) processed, np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]))",3,2
openstack%2Fmonasca-analytics~master~Ie5a536affce6a49cb4ac51ad77700ee54527cf0d,openstack/monasca-analytics,master,Ie5a536affce6a49cb4ac51ad77700ee54527cf0d,implemented the iptalbes ingestor and its test,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:57:36.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'main/ingestor/iptables_ingestor.py', 'test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/6b986c929c000c45e387f4cd0b31f559a99f52c1', 'message': 'implemented the iptalbes ingestor and its test\n\nChange-Id: Ie5a536affce6a49cb4ac51ad77700ee54527cf0d\n'}]",0,313443,6b986c929c000c45e387f4cd0b31f559a99f52c1,2,0,1,21739,,,0,"implemented the iptalbes ingestor and its test

Change-Id: Ie5a536affce6a49cb4ac51ad77700ee54527cf0d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/43/313443/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'main/ingestor/iptables_ingestor.py', 'test/ingestor/test_iptables_ingestor.py']",3,6b986c929c000c45e387f4cd0b31f559a99f52c1,,"import json from logging.config import dictConfig import unittest import os import numpy as np from main.ingestor.iptables_ingestor import IptablesIngestor class TestIptablesIngestor(unittest.TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def setUp(self): self.setup_logging() self.rdd_entry = { ""ctime"": ""Mon Apr 11 19:59:12 2016"", ""events"": [ { ""msg"": ""OUTPUT -p icmp --icmp-type echo-request -j ACCEPT"", ""id"": ""1""}, { ""msg"": ""OUTPUT -o eth0 -p tcp --sport 80 -j ACCEPT"", ""id"": ""1""} ] } self.ip_ing = IptablesIngestor(""fake_id"", {""module"": ""fake_config""}) self.ip_ing.set_feature_list([""ssh0"", ""ssh1"", ""ip0"", ""ip1"", ""ip2"", ""ip3"", ""http0"", ""http1"", ""ping0"", ""ping1"", ""ping2"", ""ping3""]) def tearDown(self): pass def test_parse_timestamp(self): t = self.ip_ing._parse_timestamp(self.rdd_entry[""ctime""]) self.assertEqual(type(t), int) self.assertEqual(1460401152, t) def test_process_data(self): rdd_str = '{""ctime"": ""Mon Apr 11 19:59:12 2016"",""events"": [{""msg"": ' +\ '""OUTPUT -p icmp --icmp-type echo-request -j ACCEPT"",""id"": ""1""}' +\ ',{""msg"": ""OUTPUT -o eth0 -p tcp --sport 80 -j ACCEPT"",""id"": ' +\ '""1""}]}' processed = self.ip_ing._process_data(rdd_str, self.ip_ing._features) np.testing.assert_array_equal( processed, np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])) ",,132,41
openstack%2Fmonasca-analytics~master~I802c65fb5583ee88fa5d7e4e2742f896aca96dd6,openstack/monasca-analytics,master,I802c65fb5583ee88fa5d7e4e2742f896aca96dd6,Fix py4j environment for vagrant and pep8 installation.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:57:29.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['fetch-deps.sh'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/fe0702ce664e3b89e45da008e99af19852b758fa', 'message': 'Fix py4j environment for vagrant and pep8 installation.\n\nChange-Id: I802c65fb5583ee88fa5d7e4e2742f896aca96dd6\n'}]",0,313441,fe0702ce664e3b89e45da008e99af19852b758fa,2,0,1,21739,,,0,"Fix py4j environment for vagrant and pep8 installation.

Change-Id: I802c65fb5583ee88fa5d7e4e2742f896aca96dd6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/41/313441/1 && git format-patch -1 --stdout FETCH_HEAD,['fetch-deps.sh'],1,fe0702ce664e3b89e45da008e99af19852b758fa,, # Python dependencies sudo -E apt-get -y install python-pip python-setuptools sudo -E pip install pep8 echo 'export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH' >> $HOME/.profile, # Python dependencies sudo -E apt-get -y install python-pip python-setuptools sudo -E pip install pep8 echo 'export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.8.2.1-src.zip:$PYTHONPATH' >> $HOME/.profile,5,5
openstack%2Fmonasca-analytics~master~I02c039cce017dcd9f574b12f9720f7c7241d97a6,openstack/monasca-analytics,master,I02c039cce017dcd9f574b12f9720f7c7241d97a6,Move to spark-1.6.1.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:57:17.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['fetch-deps.sh', 'Makefile', 'doc/getting_started.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b46ceb37ffe14842064bc6e3e15c857bb526fed9', 'message': 'Move to spark-1.6.1.\n\nChange-Id: I02c039cce017dcd9f574b12f9720f7c7241d97a6\n'}]",0,313439,b46ceb37ffe14842064bc6e3e15c857bb526fed9,2,0,1,21739,,,0,"Move to spark-1.6.1.

Change-Id: I02c039cce017dcd9f574b12f9720f7c7241d97a6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/39/313439/1 && git format-patch -1 --stdout FETCH_HEAD,"['fetch-deps.sh', 'Makefile', 'doc/getting_started.md']",3,b46ceb37ffe14842064bc6e3e15c857bb526fed9,,* Apache Spark (>= v.1.6.1),* Apache Spark (>= v.1.4.1),17,16
openstack%2Fmonasca-analytics~master~I81387c1d5967e3e2ba1246db4b10e56f881e2068,openstack/monasca-analytics,master,I81387c1d5967e3e2ba1246db4b10e56f881e2068,Working-ish solution for phase 2. The NullPointerException needs more investigation.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:54.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['run.py', 'Vagrantfile', 'main/source/markov_chain/base.py', 'main/spark/driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/533764a10c4f089bda295bd470e6c92744335aab', 'message': 'Working-ish solution for phase 2. The NullPointerException needs more investigation.\n\nChange-Id: I81387c1d5967e3e2ba1246db4b10e56f881e2068\n'}]",0,313433,533764a10c4f089bda295bd470e6c92744335aab,2,0,1,21739,,,0,"Working-ish solution for phase 2. The NullPointerException needs more investigation.

Change-Id: I81387c1d5967e3e2ba1246db4b10e56f881e2068
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/33/313433/1 && git format-patch -1 --stdout FETCH_HEAD,"['Vagrantfile', 'main/source/markov_chain/base.py', 'run.py', 'main/spark/driver.py']",4,533764a10c4f089bda295bd470e6c92744335aab,," self._ssc.awaitTermination() logger.debug(""Phase 2: Stop SparkStreamingContext."") self._ssc.stop(False, False) logger.debug(""Phase 2: Await termination."") self._ssc.awaitTermination() logger.debug(""Phase 2: Stop sources"") logger.debug(""Phase 2: Create new connections"") self._prepare_phase(self._connect_dependents_phase2) self._ssc.start()"," self._sc = SparkContext(appName=_config[""spark_config""][""appName""]) self._ssc.stop(True, False) logger.debug(""Phase 2: Stop current pipeline"") self._ssc.stop(True, False) logger.debug(""Phase 2: Create new connections"") self._prepare_phase(self._connect_dependents_phase2)",19,11
openstack%2Fmonasca-analytics~master~If277e4416829ddc4b689527812618133bfcdd9ab,openstack/monasca-analytics,master,If277e4416829ddc4b689527812618133bfcdd9ab,added tests and fixed common_util tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:51.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source/test_iptables_markov_chain.py', 'test/util/test_common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/329e06f99c23c9e95a922872113661345457c64a', 'message': 'added tests and fixed common_util tests\n\nChange-Id: If277e4416829ddc4b689527812618133bfcdd9ab\n'}]",0,313436,329e06f99c23c9e95a922872113661345457c64a,2,0,1,21739,,,0,"added tests and fixed common_util tests

Change-Id: If277e4416829ddc4b689527812618133bfcdd9ab
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/36/313436/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source/test_iptables_markov_chain.py', 'test/util/test_common_util.py']",2,329e06f99c23c9e95a922872113661345457c64a,," 'CloudMarkovChainSource', 'IPTablesSource'], ['CloudIngestor', 'IptablesIngestor'],"," 'CloudMarkovChainSource'], ['CloudIngestor'],",113,2
openstack%2Fmonasca-analytics~master~Iadd60ef0997542d2d4b7e803c5e5705e8e329857,openstack/monasca-analytics,master,Iadd60ef0997542d2d4b7e803c5e5705e8e329857,Add section to explain Makefile.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:47.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/dev_guide.md', 'doc/getting_started.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/26690729645daf6e9b78088bdadf25aa3e381db7', 'message': 'Add section to explain Makefile.\n\nChange-Id: Iadd60ef0997542d2d4b7e803c5e5705e8e329857\n'}]",0,313440,26690729645daf6e9b78088bdadf25aa3e381db7,2,0,1,21739,,,0,"Add section to explain Makefile.

Change-Id: Iadd60ef0997542d2d4b7e803c5e5705e8e329857
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/40/313440/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/dev_guide.md', 'doc/getting_started.md']",2,26690729645daf6e9b78088bdadf25aa3e381db7,,### Everything on VM ,### Everything else on VM,35,3
openstack%2Fmonasca-analytics~master~I508c42b1deb0949a4ac747740d66394a272d55f0,openstack/monasca-analytics,master,I508c42b1deb0949a4ac747740d66394a272d55f0,"removed time zone dependency, assuming the times are in UTC",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:44.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ingestor/iptables_ingestor.py', 'test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b8a3375e0274103b0e1fae140c4ed32803bc741a', 'message': 'removed time zone dependency, assuming the times are in UTC\n\nChange-Id: I508c42b1deb0949a4ac747740d66394a272d55f0\n'}]",0,313445,b8a3375e0274103b0e1fae140c4ed32803bc741a,2,0,1,21739,,,0,"removed time zone dependency, assuming the times are in UTC

Change-Id: I508c42b1deb0949a4ac747740d66394a272d55f0
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/45/313445/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ingestor/iptables_ingestor.py', 'test/ingestor/test_iptables_ingestor.py']",2,b8a3375e0274103b0e1fae140c4ed32803bc741a,," self.assertEqual(1460404752, t) 1460404752]))"," self.assertEqual(1460401152, t) 1460401152]))",5,5
openstack%2Fmonasca-analytics~master~I359fbc16004916ad95705c34016d890ec76bf281,openstack/monasca-analytics,master,I359fbc16004916ad95705c34016d890ec76bf281,tmp,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:40.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/resources/test_json.json', 'main/config/dsl.py', 'test/config/test_dsl.py', 'main/config/const.py', 'main/util/common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e006aea7e8db78e456c4b36fad91f5af23142131', 'message': 'tmp\n\nChange-Id: I359fbc16004916ad95705c34016d890ec76bf281\n'}]",0,313450,e006aea7e8db78e456c4b36fad91f5af23142131,2,0,1,21739,,,0,"tmp

Change-Id: I359fbc16004916ad95705c34016d890ec76bf281
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/50/313450/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/config/dsl.py', 'test/resources/test_json.json', 'test/config/test_dsl.py', 'main/config/const.py', 'main/util/common_util.py']",5,e006aea7e8db78e456c4b36fad91f5af23142131,,"from main.config import const if not class_type or class_type == const.SOURCES: _classes[const.SOURCES] = get_available_inherited_classes(source, BaseSource) if not class_type or class_type == const.INGESTORS: _classes[const.INGESTORS] = \ if not class_type or class_type == const.SMLS: _classes[const.SMLS] = get_available_inherited_classes(sml, BaseSML) if not class_type or class_type == const.VOTERS: _classes[const.VOTERS] = get_available_inherited_classes(voter, BaseVoter) if not class_type or class_type == const.SINKS: _classes[const.SINKS] = get_available_inherited_classes(sink, BaseSink) if not class_type or class_type == const.LDPS: _classes[const.LDPS] = \def get_component_type(class_name): for cls_type in const.components_types: names = get_available_class_names(const.SOURCES) if class_name in names: return cls_type if class_type: clazz = filter(lambda t_class: t_class.__name__ == class_name, classes[class_type]) else: for c_type in classes.keys(): clazz = filter(lambda t_class: t_class.__name__ == class_name, classes[c_type]) if clazz: break return get_class_by_name(class_name, const.SOURCES) return get_available_class_names(const.SOURCES) return get_class_by_name(class_name, const.INGESTORS) return get_available_class_names(const.INGESTORS) return get_class_by_name(class_name, const.SMLS) return get_available_class_names(const.SMLS) return get_class_by_name(class_name, const.VOTERS) return get_available_class_names(const.VOTERS) return get_available_class_names(const.LDPS)","from main.config import validation as mod if not class_type or class_type == mod.SOURCES: _classes[mod.SOURCES] = get_available_inherited_classes(source, BaseSource) if not class_type or class_type == mod.INGESTORS: _classes[mod.INGESTORS] = \ if not class_type or class_type == mod.SMLS: _classes[mod.SMLS] = get_available_inherited_classes(sml, BaseSML) if not class_type or class_type == mod.VOTERS: _classes[mod.VOTERS] = get_available_inherited_classes(voter, BaseVoter) if not class_type or class_type == mod.SINKS: _classes[mod.SINKS] = get_available_inherited_classes(sink, BaseSink) if not class_type or class_type == mod.LDPS: _classes[mod.LDPS] = \ clazz = filter(lambda t_class: t_class.__name__ == class_name, classes[class_type]) return get_class_by_name(class_name, mod.SOURCES) return get_available_class_names(mod.SOURCES) return get_class_by_name(class_name, mod.INGESTORS) return get_available_class_names(mod.INGESTORS) return get_class_by_name(class_name, mod.SMLS) return get_available_class_names(mod.SMLS) return get_class_by_name(class_name, mod.VOTERS) return get_available_class_names(mod.VOTERS) return get_available_class_names(mod.LDPS)",161,28
openstack%2Fmonasca-analytics~master~Iedbb1796d47c312fc98fa37201dcabef8262d90b,openstack/monasca-analytics,master,Iedbb1796d47c312fc98fa37201dcabef8262d90b,implemented the save configuration function,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:36.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/config/dsl.py', 'test/config/test_dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/51c9c4acf17db76e36faaffbe1093f9c589af31c', 'message': 'implemented the save configuration function\n\nChange-Id: Iedbb1796d47c312fc98fa37201dcabef8262d90b\n'}]",0,313454,51c9c4acf17db76e36faaffbe1093f9c589af31c,2,0,1,21739,,,0,"implemented the save configuration function

Change-Id: Iedbb1796d47c312fc98fa37201dcabef8262d90b
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/54/313454/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/config/dsl.py', 'test/config/test_dsl.py']",2,51c9c4acf17db76e36faaffbe1093f9c589af31c,," self.tmp_file = ""tmp_config_file.json"" if os.path.exists(self.tmp_file): os.remove(self.tmp_file) def test_save_configuration_overwrite_no_file(self): self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=True)) self.dsl._config = None self.dsl.load_configuration(self.tmp_file) self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_not_overwrite_no_file(self): self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=False)) self.dsl._config = None self.dsl.load_configuration(self.tmp_file) self.assertEqual(self.original_config, self.dsl._config) def _create_dirty_fyle(self, fname): with open(fname, ""w"") as f: f.write(""This content may be overwritten"") def test_save_configuration_overwrite_file(self): self._create_dirty_fyle(self.tmp_file) self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=True)) self.dsl._config = None self.dsl.load_configuration(""tmp_config_file.json"") self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_not_overwrite_file(self): self._create_dirty_fyle(self.tmp_file) old_size = os.stat(self.tmp_file).st_size self.assertFalse( self.dsl.save_configuration(self.tmp_file, overwrite_file=False)) self.assertEqual(old_size, os.stat(self.tmp_file).st_size)", pass,55,4
openstack%2Fmonasca-analytics~master~I331f004bc567d514ecff6004be2db2a14141f90c,openstack/monasca-analytics,master,I331f004bc567d514ecff6004be2db2a14141f90c,fixed unit tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:33.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/sml_mocks.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/658a3afa34cfce8caefcb449c870832dfcd22476', 'message': 'fixed unit tests\n\nChange-Id: I331f004bc567d514ecff6004be2db2a14141f90c\n'}]",0,313458,658a3afa34cfce8caefcb449c870832dfcd22476,2,0,1,21739,,,0,"fixed unit tests

Change-Id: I331f004bc567d514ecff6004be2db2a14141f90c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/58/313458/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/sml_mocks.py', 'test/spark/test_driver.py']",2,658a3afa34cfce8caefcb449c870832dfcd22476,," self.assertEqual(9, len(sml_mocks.sml_mocks.classes_got_by_name)) self.assertIn([""IPTablesSource"", mod.SOURCES], sml_mocks.sml_mocks.classes_got_by_name)"," self.assertEqual(8, len(sml_mocks.sml_mocks.classes_got_by_name))",13,1
openstack%2Fmonasca-analytics~master~I49338f8bf968153221730179e10cf0a6562fb652,openstack/monasca-analytics,master,I49338f8bf968153221730179e10cf0a6562fb652,"implemented save option with no parameter, using last loaded or saved confg file",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:29.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/dsl/test_interpreter.py', 'main/dsl/interpreter.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ce3879cc9a6cddfe9a7186cf29becc0e18255580', 'message': 'implemented save option with no parameter, using last loaded or saved confg file\n\nChange-Id: I49338f8bf968153221730179e10cf0a6562fb652\n'}]",0,313461,ce3879cc9a6cddfe9a7186cf29becc0e18255580,2,0,1,21739,,,0,"implemented save option with no parameter, using last loaded or saved confg file

Change-Id: I49338f8bf968153221730179e10cf0a6562fb652
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/61/313461/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/dsl/test_interpreter.py', 'main/dsl/interpreter.py']",2,ce3879cc9a6cddfe9a7186cf29becc0e18255580,," self.file_in_use = None self.dsl.load_configuration(filepath) self.file_in_use = filepath if not filepath: filepath = self.file_in_use saved = self.dsl.save_configuration(filepath, overwrite_file=True) if saved: self.file_in_use = filepath return saved"," return self.dsl.load_configuration(filepath) return self.dsl.save_configuration(filepath, overwrite_file=True)",19,7
openstack%2Fmonasca-analytics~master~If8af68515980a0e61566fa62a6dae92a35208df5,openstack/monasca-analytics,master,If8af68515980a0e61566fa62a6dae92a35208df5,tmp,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:25.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/dsl/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/d72315044ff90d2cf5638a1a5bef558a1bb43dff', 'message': 'tmp\n\nChange-Id: If8af68515980a0e61566fa62a6dae92a35208df5\n'}]",0,313465,d72315044ff90d2cf5638a1a5bef558a1bb43dff,2,0,1,21739,,,0,"tmp

Change-Id: If8af68515980a0e61566fa62a6dae92a35208df5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/65/313465/1 && git format-patch -1 --stdout FETCH_HEAD,['test/dsl/__init__.py'],1,d72315044ff90d2cf5638a1a5bef558a1bb43dff,,,,0,0
openstack%2Fmonasca-analytics~master~I09e8a4940fde24f0abeb02bddfd8bff8d912a3ec,openstack/monasca-analytics,master,I09e8a4940fde24f0abeb02bddfd8bff8d912a3ec,"added jenkins dependency, and imported it to check if that was the reason",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:21.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['jenkins.sh'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/55e0bead07ee1e8093811c03bb978b058cfd0c1e', 'message': 'added jenkins dependency, and imported it to check if that was the reason\n\nChange-Id: I09e8a4940fde24f0abeb02bddfd8bff8d912a3ec\n'}]",0,313466,55e0bead07ee1e8093811c03bb978b058cfd0c1e,2,0,1,21739,,,0,"added jenkins dependency, and imported it to check if that was the reason

Change-Id: I09e8a4940fde24f0abeb02bddfd8bff8d912a3ec
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/66/313466/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins.sh'],1,55e0bead07ee1e8093811c03bb978b058cfd0c1e,,sudo -E apt-get -y install python-numpy python-scipy ipython python-pyparsing,sudo -E apt-get -y install python-numpy python-scipy ipython,1,1
openstack%2Fmonasca-analytics~master~I824c7d60e5b3de6683050ed001983c7f5c1c244d,openstack/monasca-analytics,master,I824c7d60e5b3de6683050ed001983c7f5c1c244d,added the new md files,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:17.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/configuration.md', 'doc/dsl.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/82b3ab121233ab8a32cce26b70817fdaba4f91cc', 'message': 'added the new md files\n\nChange-Id: I824c7d60e5b3de6683050ed001983c7f5c1c244d\n'}]",0,313470,82b3ab121233ab8a32cce26b70817fdaba4f91cc,2,0,1,21739,,,0,"added the new md files

Change-Id: I824c7d60e5b3de6683050ed001983c7f5c1c244d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/70/313470/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/configuration.md', 'doc/dsl.md']",2,82b3ab121233ab8a32cce26b70817fdaba4f91cc,,"# Domain Specific Language (DSL) for configuration handling A simple DSL language, accessible from a command line tool, has been implemented in order to manage configurations in an easier way. This section explains what operations are available, and how to use them. > Note: Please refer to [Monasca/Configuration](configuration.md) to understand the structure of the configuration. ## Usage * Start Mananas DSL tool ```bash python $MONANAS_HOME/config_dsl.py ``` After running this command, a simple empty orchestration configuration will be created, which you can then modify running operations according to your needs. ## Config manipulation operations You can run the following operations from the DSL command line in order to create, remove, connect, disconnect and modify components in the configuration. ###Create component * Create a component and assign it to a variable ```bash >> A = IPTablesSource ``` This command adds a new source of type IPTablesSource to the configuration, assigning it its default configuration. It links the source component to variable A, and returns a unique ID. You can either use the variable or the ID in order to reference the instance of IPTablesSource you just created. ### Remove component * Remove a component using its ID or variable name ```bash >> rm A ``` This command removes the component referenced by A from the configuration. The parameter can either be a variable or an ID associated to a component in the configuration. The component will only be removed if it is not connected to any other component. ### Connect components * Connect two components in the configuration ```bash >> A -> B ``` This command connects the component referenced by A with the component referenced by B. Both A and B can be variables or IDs, and the connection is directional from A to B. The connection will only be performed if the components exist and their connection is allowed. For example, connecting a source with an ingestor is allowed, but connecting a source with a voter is not. ### Disconnect components * Disconnect two components in the configuration ```bash >> A !-> B ``` This command disconnects the component A from component B. Both A and B can be variables or IDs, and the connection is directional from A to B. If the connection didn't exist, nothing will happen. ### Modify component * Modify values of the configuration of a component ```bash >> A.params.subparam1.subparam2 = value ``` This command modifies the value of the configuration parameter at the end of the path defined by the dot notation. The configuration is validated before being modified, hence if the modification results in an invalid configuration, it will not be performed. A can either be a variable or an ID. ## Config presentation operations You can run the following operations from the DSL command line in order to view the current configuration, sub-configurations, and available components that you can instantiate. ### Print * Print the full configuration ```bash >> print ``` This command displays the full configuration in json format to your screen. * Print component type sub-configuration ```bash >> print connections ``` If you pass a parameter to the print command that corresponds to a component type, or, in general, a first level key of the configuration, only the relevant sub-configuration that you selected will be displayed to your screen. * Print a particular component sub-configuration ```bash >> print A ``` If you pass a parameter to the print command that corresponds to a variable or an ID associated to a particular component, only its configuration will be displayed to your screen. ### List * Print all available components ```bash >> list ``` This command displays all available components that you can add to your configuration, organized by type. * Print all available components of a particular type ```bash >> list smls ``` If you pass the type as a parameter to the list command, only the available components of that type will be listed. ## Config storage operations You can run the following operations from the DSL command line in order to load and save configurations from/to files. ### Load * Load a configuration from a file ```bash >> load filename ``` This command loads the configuration stored in the file 'filename', overriding the existing configuration you were handling before. ### Save * Save a configuration to a file ```bash >> save filename ``` This command saves the configuration being currently handled to the file 'filename', overriding the file if it existed before. * Save a configuration to the last file ```bash >> save ``` If no parameter is provided, the save operation saves the current configuration being handled to the last file you loaded from or saved to. ",,252,0
openstack%2Fnova~master~I9357377750e7c373c283edd73cbf65ad42c22e66,openstack/nova,master,I9357377750e7c373c283edd73cbf65ad42c22e66,method verification of os-assisted-volume-snapshots,MERGED,2016-05-10 23:05:38.000000000,2016-05-11 16:56:15.000000000,2016-05-11 16:56:14.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6873}, {'_account_id': 10385}, {'_account_id': 15286}]","[{'number': 1, 'created': '2016-05-10 23:05:38.000000000', 'files': ['api-ref/source/os-assisted-volume-snapshots.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/fcce6781e25efd22323cdf5655e2eb6d43528c66', 'message': 'method verification of os-assisted-volume-snapshots\n\nVerified the API document for os-assisted-volume-snapshots\nwith source for methods available and response codes.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I9357377750e7c373c283edd73cbf65ad42c22e66\n'}]",0,314802,fcce6781e25efd22323cdf5655e2eb6d43528c66,13,5,1,18339,,,0,"method verification of os-assisted-volume-snapshots

Verified the API document for os-assisted-volume-snapshots
with source for methods available and response codes.

Part of bp:api-ref-in-rst

Change-Id: I9357377750e7c373c283edd73cbf65ad42c22e66
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/314802/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-assisted-volume-snapshots.inc'],1,fcce6781e25efd22323cdf5655e2eb6d43528c66,bp/api-ref-in-rst,"Error response codes: badRequest(400),unauthorized(401), forbidden(403)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)",".. needs:method_verificationError response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",3,5
openstack%2Fmonasca-analytics~master~I795afc2db1bc3fb91363c3ba482c6d40e1bc3734,openstack/monasca-analytics,master,I795afc2db1bc3fb91363c3ba482c6d40e1bc3734,fixed the conflict,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:14.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/test_common_util.py', 'test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/48827e079234b1082fce8a3cf21e3beccbc80f61', 'message': 'fixed the conflict\n\nChange-Id: I795afc2db1bc3fb91363c3ba482c6d40e1bc3734\n'}]",0,313474,48827e079234b1082fce8a3cf21e3beccbc80f61,2,0,1,21739,,,0,"fixed the conflict

Change-Id: I795afc2db1bc3fb91363c3ba482c6d40e1bc3734
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/74/313474/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/test_common_util.py', 'test/ingestor/test_iptables_ingestor.py']",2,48827e079234b1082fce8a3cf21e3beccbc80f61,,"from main.source.iptables_markov_chain import iptables self.ip_ing.set_feature_list([""ssh"", ""ip"", ""http"", ""ping""]) rdd_str = '{""ctime"": ""Mon Apr 11 19:59:12 2016"",""events"": [' for iptable in iptables: rdd_str += '{""msg"": ""' + iptable + '"",""id"": ""1""}, ' rdd_str = rdd_str[:-2] + ']}' print rdd_str processed, np.array([2, 4, 2, 4]))"," self.ip_ing.set_feature_list([""ssh0"", ""ssh1"", ""ip0"", ""ip1"", ""ip2"", ""ip3"", ""http0"", ""http1"", ""ping0"", ""ping1"", ""ping2"", ""ping3"", ""time""]) rdd_str = '{""ctime"": ""Mon Apr 11 19:59:12 2016"",""events"": [{""msg"": ' +\ '""OUTPUT -p icmp --icmp-type echo-request -j ACCEPT"",""id"": ""1""}' +\ ',{""msg"": ""OUTPUT -o eth0 -p tcp --sport 80 -j ACCEPT"",""id"": ' +\ '""1""}]}' processed, np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1460404752]))",9,10
openstack%2Fmonasca-analytics~master~If8d75a423522724587b8dba32842e9153f6e2627,openstack/monasca-analytics,master,If8d75a423522724587b8dba32842e9153f6e2627,added one class SVM as anomaly detection for iptables triggering. Also modified the featuers grouping IPTables by types,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:10.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'config/iptables_anomalies.json', 'main/ingestor/iptables.py', 'main/sml/svm_one_class.py', 'test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/67b1fda76025f72d4973805072b5c96bb3d25a8b', 'message': 'added one class SVM as anomaly detection for iptables triggering. Also modified the featuers grouping IPTables by types\n\nChange-Id: If8d75a423522724587b8dba32842e9153f6e2627\n'}]",0,313473,67b1fda76025f72d4973805072b5c96bb3d25a8b,2,0,1,21739,,,0,"added one class SVM as anomaly detection for iptables triggering. Also modified the featuers grouping IPTables by types

Change-Id: If8d75a423522724587b8dba32842e9153f6e2627
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/73/313473/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'config/iptables_anomalies.json', 'main/ingestor/iptables.py', 'main/sml/svm_one_class.py', 'test/ingestor/test_iptables_ingestor.py']",5,67b1fda76025f72d4973805072b5c96bb3d25a8b,,from main.ingestor.iptables import IptablesIngestor,from main.ingestor.iptables_ingestor import IptablesIngestor,90,23
openstack%2Fmonasca-analytics~master~Ie6ecfe29d19891e916d4605c058366dc77b4e95f,openstack/monasca-analytics,master,Ie6ecfe29d19891e916d4605c058366dc77b4e95f,implemented the anomaly detection in iptalbes_LDP,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:06.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e59c48827cc252405239a89312ec511a20078532', 'message': 'implemented the anomaly detection in iptalbes_LDP\n\nChange-Id: Ie6ecfe29d19891e916d4605c058366dc77b4e95f\n'}]",0,313476,e59c48827cc252405239a89312ec511a20078532,2,0,1,21739,,,0,"implemented the anomaly detection in iptalbes_LDP

Change-Id: Ie6ecfe29d19891e916d4605c058366dc77b4e95f
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/76/313476/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py']",2,e59c48827cc252405239a89312ec511a20078532,," logger.info(""Found "" + str(num_anomalies) + "" anomalies in testing set"")"," logger.info(""Found "" + str(num_anomalies) + "" anomalies in testing set"")",35,8
openstack%2Fmonasca-analytics~master~I9d3aafccc1ae5957f72b7183e4f9a7acfd6ec798,openstack/monasca-analytics,master,I9d3aafccc1ae5957f72b7183e4f9a7acfd6ec798,"created base and iptables sqlite sink, and started implementing unit tests",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:56:02.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/base_sqlite.py', 'test/sink/test_iptables_sqlite.py', 'test/sink/test_base_sqlite.py', 'main/sink/iptables_sqlite.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b31a352da1beafff41bb312849506b631f20ca87', 'message': 'created base and iptables sqlite sink, and started implementing unit tests\n\nChange-Id: I9d3aafccc1ae5957f72b7183e4f9a7acfd6ec798\n'}]",0,313480,b31a352da1beafff41bb312849506b631f20ca87,2,0,1,21739,,,0,"created base and iptables sqlite sink, and started implementing unit tests

Change-Id: I9d3aafccc1ae5957f72b7183e4f9a7acfd6ec798
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/80/313480/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/sink/base_sqlite.py', 'test/sink/test_iptables_sqlite.py', 'test/sink/test_base_sqlite.py', 'main/sink/iptables_sqlite.py']",4,b31a352da1beafff41bb312849506b631f20ca87,,"#!/usr/bin/env python from base_sqlite import BaseSQLiteSink class IptablesSQLiteSink(BaseSQLiteSink): def _rdds_table_create_query(self): return """"""CREATE TABLE IF NOT EXISTS rdds (msg TEXT, anomalous TEXT, msg_id TEXT, ctime TEXT)"""""" def _rdd_insert_query(self, rdd_json): return ('INSERT INTO rdds VALUES(""' + str(rdd_json[""msg""]) + '"", ""' + str(rdd_json[""anomalous""]) + '"", ""' + str(rdd_json[""id""]) + '"", ""' + str(rdd_json[""ctime""]) + '"")') ",,162,0
openstack%2Fmonasca-analytics~master~Ie31bcd43c8a08583d7934e67d2424357169f3fe9,openstack/monasca-analytics,master,Ie31bcd43c8a08583d7934e67d2424357169f3fe9,implemented the bind test for kafka_source using Mocks,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:55:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/ml_mocks.py', 'test/source_manager/source/file_source_test.py', 'test/source_manager/source/kafka_source_test.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2a9d353155b686cfef6b58213d092c653ce65ab3', 'message': 'implemented the bind test for kafka_source using Mocks\n\nChange-Id: Ie31bcd43c8a08583d7934e67d2424357169f3fe9\n'}]",0,313336,2a9d353155b686cfef6b58213d092c653ce65ab3,3,1,1,21739,,,0,"implemented the bind test for kafka_source using Mocks

Change-Id: Ie31bcd43c8a08583d7934e67d2424357169f3fe9
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/36/313336/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/ml_mocks.py', 'test/source_manager/source/file_source_test.py', 'test/source_manager/source/kafka_source_test.py']",3,2a9d353155b686cfef6b58213d092c653ce65ab3,,"from main.source_manager.source import kafka_sourcefrom test.mocks.ml_mocks import MockKafkaUtils from test.mocks.ml_mocks import MockStreamingContext def _mock_functions(self): kafka_source.KafkaUtils = MockKafkaUtils self._mock_functions() self.ks = kafka_source.KafkaSource(""fake_id"", self.valid_config) def test_before_bind_source_dstream_created(self): ssc = MockStreamingContext(None, None) self.ks.before_bind_source(ssc) self.assertIsNotNone(self.ks._dstream)","from main.source_manager.source.kafka_source import KafkaSource self.ks = KafkaSource(""fake_id"", self.valid_config) #def test_before_bind_source_dstream_created(self): # ssc = StreamingContext(None, None) # self.ks.before_bind_source(ssc) # self.assertEqual(1, ssc.file_stream_cnt) # self.assertIsNotNone(self.ks._dstream)",21,9
openstack%2Fnova~master~I57a7cc1585d15307688165f11e3a3868e5b1887e,openstack/nova,master,I57a7cc1585d15307688165f11e3a3868e5b1887e,Move config options from nova/api directory (4),MERGED,2016-04-21 21:48:32.000000000,2016-05-11 16:55:06.000000000,2016-05-11 16:55:05.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19590}]","[{'number': 1, 'created': '2016-04-21 21:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13601039fb6542c2b41c6320aaadc4beb0d583d8', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth and final patch moving config options from the\nnova/api directory. In this patch, the options from the legacy_v2\ndirectory have been moved; the deprecated ones are in\nnova/conf/legacy_v2.py, while the rest are in nova/conf/api.py. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}, {'number': 2, 'created': '2016-04-22 03:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2faf9a6a6ab6c9a02132bf0792f65ae15fa6afba', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth and final patch moving config options from the\nnova/api directory. In this patch, the options from the legacy_v2\ndirectory have been moved; the deprecated ones are in\nnova/conf/legacy_v2.py, while the rest are in nova/conf/api.py. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}, {'number': 3, 'created': '2016-04-27 09:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9e34dbe63d1c7463cac6f43e8eff150f7183252', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth and final patch moving config options from the\nnova/api directory. In this patch, the options from the legacy_v2\ndirectory have been moved; the deprecated ones are in\nnova/conf/legacy_v2.py, while the rest are in nova/conf/api.py. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}, {'number': 4, 'created': '2016-04-28 16:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cc36e3bd273eefd5b490b4d6900724de10d02bb', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth and final patch moving config options from the\nnova/api directory. In this patch, the options from the legacy_v2\ndirectory have been moved; the deprecated ones are in\nnova/conf/legacy_v2.py, while the rest are in nova/conf/api.py. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}, {'number': 5, 'created': '2016-05-06 18:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2033499a24d47963700c66168dcb5084555bc984', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth and final patch moving config options from the\nnova/api directory. In this patch, the options from the legacy_v2\ndirectory have been moved; the deprecated ones are in\nnova/conf/legacy_v2.py, while the rest are in nova/conf/api.py. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}, {'number': 6, 'created': '2016-05-09 20:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec3d9aa3b3370c9206ee638416e894fd11d480ae', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth patch moving config options from the nova/api\ndirectory. In this patch, the still-valid options from the legacy_v2\ndirectory have been moved to nova/conf/api.py; the deprecated ones will\nbe moved in the next patch. A subsequent patch will enhance the help\ntext for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}, {'number': 7, 'created': '2016-05-09 21:24:00.000000000', 'files': ['nova/api/openstack/compute/legacy_v2/servers.py', 'nova/api/opts.py', 'nova/api/openstack/compute/tenant_networks.py', 'nova/conf/__init__.py', 'nova/api/openstack/compute/evacuate.py', 'nova/conf/api.py', 'nova/api/openstack/compute/legacy_v2/contrib/os_tenant_networks.py', 'nova/api/openstack/compute/rescue.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/82b0129f398817c03a9b8d43838a44646330c383', 'message': 'Move config options from nova/api directory (4)\n\nThis is the fourth patch moving config options from the nova/api\ndirectory. In this patch, the still-valid options from the legacy_v2\ndirectory have been moved to nova/conf/api.py; the deprecated ones will\nbe moved in the next patch. A subsequent patch will enhance the help\ntext for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e\n'}]",2,309198,82b0129f398817c03a9b8d43838a44646330c383,92,18,7,1063,,,0,"Move config options from nova/api directory (4)

This is the fourth patch moving config options from the nova/api
directory. In this patch, the still-valid options from the legacy_v2
directory have been moved to nova/conf/api.py; the deprecated ones will
be moved in the next patch. A subsequent patch will enhance the help
text for these options.

Blueprint centralize-config-options-newton

Change-Id: I57a7cc1585d15307688165f11e3a3868e5b1887e
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/309198/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/test_hide_server_addresses.py', 'nova/tests/functional/api_sample_tests/test_security_group_default_rules.py', 'nova/tests/functional/api_sample_tests/test_flavor_access.py', 'nova/tests/functional/api_sample_tests/test_block_device_mapping_boot.py', 'nova/tests/functional/api_sample_tests/test_limits.py', 'nova/tests/functional/api_sample_tests/test_networks.py', 'nova/tests/functional/api_sample_tests/test_flavor_manage.py', 'nova/tests/functional/api_sample_tests/test_server_password.py', 'nova/tests/functional/api_sample_tests/test_admin_actions.py', 'nova/api/openstack/compute/legacy_v2/contrib/__init__.py', 'nova/tests/functional/api_sample_tests/test_remote_consoles.py', 'nova/tests/functional/api_sample_tests/test_multinic.py', 'nova/tests/functional/api_sample_tests/test_server_external_events.py', 'nova/api/openstack/compute/legacy_v2/servers.py', 'nova/tests/functional/api_sample_tests/test_multiple_create.py', 'nova/tests/functional/api_sample_tests/test_servers_ips.py', 'nova/tests/functional/api_sample_tests/test_floating_ip_pools.py', 'nova/tests/functional/api_sample_tests/test_evacuate.py', 'nova/tests/functional/api_sample_tests/test_used_limits.py', 'nova/tests/functional/api_sample_tests/test_availability_zone.py', 'nova/conf/api.py', 'nova/tests/functional/api_sample_tests/test_server_groups.py', 'nova/tests/functional/api_sample_tests/test_pause_server.py', 'nova/tests/functional/api_sample_tests/test_simple_tenant_usage.py', 'nova/tests/functional/api_sample_tests/test_server_diagnostics.py', 'nova/tests/functional/api_sample_tests/test_config_drive.py', 'nova/tests/functional/api_sample_tests/test_agents.py', 'nova/conf/legacy_api.py', 'nova/tests/functional/api_sample_tests/test_deferred_delete.py', 'nova/tests/functional/api_sample_tests/test_tenant_networks.py', 'nova/tests/functional/api_sample_tests/test_extended_volumes.py', 'nova/tests/functional/api_sample_tests/test_console_auth_tokens.py', 'nova/api/openstack/compute/tenant_networks.py', 'nova/tests/functional/api_sample_tests/test_hypervisors.py', 'nova/tests/functional/api_sample_tests/test_suspend_server.py', 'nova/api/openstack/compute/legacy_v2/contrib/os_tenant_networks.py', 'nova/api/openstack/compute/rescue.py', 'nova/tests/functional/api_sample_tests/test_access_ips.py', 'nova/tests/functional/api_sample_tests/test_services.py', 'nova/tests/functional/api_sample_tests/test_servers.py', 'nova/api/opts.py', 'nova/conf/__init__.py', 'nova/tests/functional/api_sample_tests/test_floating_ip_dns.py', 'nova/tests/functional/api_sample_tests/test_quota_sets.py', 'nova/tests/functional/api_sample_tests/test_quota_classes.py', 'setup.cfg', 'nova/tests/functional/api_sample_tests/test_extension_info.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/tests/functional/api_sample_tests/test_extended_status.py', 'nova/tests/functional/api_sample_tests/test_extended_server_attributes.py', 'nova/tests/functional/api_sample_tests/test_hosts.py', 'nova/tests/functional/api_sample_tests/test_scheduler_hints.py', 'nova/tests/functional/api_sample_tests/test_cloudpipe.py', 'nova/tests/functional/api_sample_tests/test_networks_associate.py', 'nova/api/openstack/compute/legacy_v2/extensions.py', 'nova/tests/functional/api_sample_tests/test_migrations.py', 'nova/tests/functional/api_sample_tests/test_user_data.py', 'nova/api/openstack/compute/evacuate.py', 'nova/tests/functional/api_sample_tests/test_assisted_volume_snapshots.py', 'nova/tests/functional/api_sample_tests/test_disk_config.py', 'nova/tests/functional/api_sample_tests/test_flavors.py', 'nova/tests/functional/api_sample_tests/test_aggregates.py', 'nova/tests/functional/api_sample_tests/test_baremetal_nodes.py', 'nova/tests/functional/api_sample_tests/test_floating_ips_bulk.py', 'nova/tests/functional/api_sample_tests/test_instance_usage_audit_log.py', 'nova/tests/functional/api_sample_tests/test_attach_interfaces.py', 'nova/tests/functional/api_sample_tests/test_preserve_ephemeral_rebuild.py', 'nova/tests/functional/api_sample_tests/test_floating_ips.py', 'nova/tests/functional/api_sample_tests/test_flavor_extraspecs.py', 'nova/tests/functional/api_sample_tests/test_volumes.py', 'nova/tests/functional/api_sample_tests/test_virtual_interfaces.py', 'nova/tests/functional/api_sample_tests/test_cells.py', 'nova/tests/functional/api_sample_tests/test_security_groups.py', 'nova/tests/functional/api_sample_tests/test_rescue.py', 'nova/tests/functional/api_sample_tests/test_admin_password.py', 'nova/tests/functional/api_sample_tests/test_lock_server.py', 'nova/tests/functional/api_sample_tests/test_keypairs.py', 'nova/tests/functional/api_sample_tests/test_console_output.py', 'nova/tests/functional/api_sample_tests/test_fping.py', 'nova/tests/functional/api_sample_tests/test_extended_availability_zone.py', 'nova/tests/functional/api_sample_tests/test_migrate_server.py', 'nova/tests/functional/api_sample_tests/test_fixed_ips.py', 'nova/tests/functional/api_sample_tests/test_create_backup.py', 'nova/tests/functional/api_sample_tests/test_server_usage.py', 'nova/api/openstack/compute/servers.py', 'nova/tests/unit/api/openstack/compute/test_server_password.py', 'nova/tests/functional/api_sample_tests/test_instance_actions.py', 'nova/tests/functional/api_sample_tests/test_certificates.py', 'nova/tests/functional/api_sample_tests/test_images.py', 'nova/tests/functional/api_sample_tests/test_server_metadata.py', 'nova/tests/functional/api_sample_tests/test_flavor_rxtx.py', 'nova/tests/functional/api_sample_tests/test_shelve.py']",92,13601039fb6542c2b41c6320aaadc4beb0d583d8,bp/centralize-config-options-newton,,"CONF.import_opt('osapi_compute_extension', 'nova.api.openstack.compute.legacy_v2.extensions')",236,572
openstack%2Fmonasca-analytics~master~Ie09e7151891710109bc918944b0d8073435592f6,openstack/monasca-analytics,master,Ie09e7151891710109bc918944b0d8073435592f6,fixed ml_framework and common_util,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:48.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/exception/ml_framework_error.py', 'main/util/common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/7d898dc3a25b0972142fbaf370efddceab95bc4e', 'message': 'fixed ml_framework and common_util\n\nChange-Id: Ie09e7151891710109bc918944b0d8073435592f6\n'}]",0,313327,7d898dc3a25b0972142fbaf370efddceab95bc4e,3,1,1,21739,,,0,"fixed ml_framework and common_util

Change-Id: Ie09e7151891710109bc918944b0d8073435592f6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/27/313327/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/exception/ml_framework_error.py', 'main/util/common_util.py']",3,7d898dc3a25b0972142fbaf370efddceab95bc4e,,"def get_available_classes(class_type=None): @param class_type: if provided, only this type of classes will be returned if not class_type or class_type == data_sources: from main.source_manager.source.base_source import BaseSource _classes[data_sources] = _get_available_classes(source, BaseSource) if not class_type or class_type == data_ingestors: from main.data_ingestion_manager.data_ingestion.base_data_ingestor\ import BaseDataIngestor _classes[data_ingestors] = _get_available_classes(data_ingestion, BaseDataIngestor) if not class_type or class_type == aggregators: from main.data_aggregation_manager.data_agregator.base_data_aggregator\ import BaseDataAggregator _classes[aggregators] = _get_available_classes(data_agregator, BaseDataAggregator) if not class_type or class_type == learners: from main.machine_learning_manager.machine_learning.\ base_machine_learning import BaseMachineLearning _classes[learners] = _get_available_classes(machine_learning, BaseMachineLearning) if not class_type or class_type == voters: from main.voter_manager.voter.base_voter import BaseVoter _classes[voters] = _get_available_classes(voter, BaseVoter) if not class_type or class_type == sinks: from main.sink_manager.sink.base_sink import BaseSink _classes[sinks] = _get_available_classes(sink, BaseSink) classes = get_available_classes(class_type) classes[class_type]) classes = get_available_classes(class_type) return [Clazz.__name__ for Clazz in classes[class_type]] """"""Gets the source class by class name. @type class_name: String @param class_name: Name of the source class requested. @raise MlfNoSuchDataIngestorError: If no source class found. @raise MlfDuplicateDataIngestorError: If the system has multiple source of the same class name. """""" """""" Gets available source class names. @return: list: A list of available source class names. """""" return get_available_class_names(data_sources) Gets the data_ingestor class by class name. @type class_name: String @param class_name: Name of the data_ingestor class requested. @raise MlfNoSuchDataIngestorError: If no data_ingestor class found. @raise MlfDuplicateDataIngestorError: If the system has multiple data_ingestors of the same class name. """""" return get_class_by_name(class_name, data_ingestors) Gets available data_ingestor class names. @return: list: A list of available data_ingestor class names. """""" return get_available_class_names(data_ingestors) Gets the data_aggregator class by class name. @type class_name: String @param class_name: Name of the data_aggregator class requested. @raise MlfNoSuchDataIngestorError: If no data_aggregator class found. @raise MlfDuplicateDataIngestorError: If the system has multiple data_aggregator of the same class name. """""" return get_class_by_name(class_name, aggregators) """""" Gets available data_aggregator class names. @return: list: A list of available data_aggregator class names. """""" return get_available_class_names(aggregators) Gets the machine_learning class by class name. @type class_name: String @param class_name: Name of the machine_learning class requested. @raise MlfNoSuchDataIngestorError: If no machine_learning class found. @raise MlfDuplicateDataIngestorError: If the system has multiple machine_learning of the same class name. """""" return get_class_by_name(class_name, learners) Gets available machine_learning class names. @return: list: A list of available machine_learning class names. """""" return get_available_class_names(learners) """""" Gets the voter class by class name. @type class_name: String @param class_name: Name of the voter class requested. @raise MlfNoSuchDataIngestorError: If no voter class found. @raise MlfDuplicateDataIngestorError: If the system has multiple voter of the same class name. """""" return get_class_by_name(class_name, voters) """""" Gets available voter class names. @return: list: A list of available voter class names. """""" return get_available_class_names(voters)","from main.source_manager.source.base_source import BaseSourcefrom main.data_ingestion_manager.data_ingestion.base_data_ingestor\ import BaseDataIngestorfrom main.machine_learning_manager.machine_learning.base_machine_learning\ import BaseMachineLearningfrom main.data_aggregation_manager.data_agregator.base_data_aggregator\ import BaseDataAggregatorfrom main.voter_manager.voter.base_voter import BaseVoterfrom main.sink_manager.sink.base_sink import BaseSinkdef get_available_classes(): """""" @return: Dictionary of all available classes, where each key is a class type and the values are lists of classes """""" if not available_classes: available_classes = _create_classes_dict() return available_classes def _create_classes_dict(): _classes[data_sources] = _get_available_classes(source, BaseSource) _classes[data_ingestors] = _get_available_classes(data_ingestion, BaseDataIngestor) _classes[aggregators] = _get_available_classes(data_agregator, BaseDataAggregator) _classes[learners] = _get_available_classes(machine_learning, BaseMachineLearning) _classes[voters] = _get_available_classes(voter, BaseVoter) _classes[sinks] = _get_available_classes(sink, BaseSink) if not available_classes: available_classes = _create_classes_dict() available_classes[class_type]) if not available_classes: available_classes = _create_classes_dict() return [Clazz.__name__ for Clazz in available_classes[class_type]] get_available_class_names(data_sources) # TODO once get_class_by_name, and get_available_class_names, # replace all the functions below """"""Gets the data_ingestor class by class name. Args: class_name: A class name. Returns: class: A data_ingestor class requested. Raises: MlfNoSuchDataIngestorError: If no source class found. MlfDuplicateDataIngestorError: If the system has multiple data_ingestors of the same class name. available_ingestors = get_available_inherited_classes(data_ingestion, BaseDataIngestor) clazz = filter(lambda source_class: source_class.__name__ == class_name, available_ingestors) if not clazz: raise err.MlfNoSuchDataIngestorError(class_name) elif len(clazz) > 1: raise err.MlfDuplicateDataIngestorError(class_name) else: return clazz[0] """"""Gets available data_ingestor class names. Returns: list: A list of available data_ingestor class names. available_sources = get_available_inherited_classes(data_ingestion, BaseDataIngestor) return [Clazz.__name__ for Clazz in available_sources] """"""Gets the data_aggregator class by class name. Args: class_name: A class name. Returns: class: A data_aggregator class requested. Raises: MlfNoSuchDataAggregatorError: If no data_aggregator class found. MlfDuplicateDataAggregatorError: If the system has multiple data_aggregator items of the same class name. available_aggr = get_available_inherited_classes(data_agregator, BaseDataAggregator) clazz = filter(lambda aggr_class: aggr_class.__name__ == class_name, available_aggr) if not clazz: raise err.MlfNoSuchDataAggregatorError(class_name) elif len(clazz) > 1: raise err.MlfDuplicateDataAggregatorError(class_name) else: return clazz[0] pass """"""Gets the machine_learning class by class name. Args: class_name: A class name. Returns: class: A machine_learning class requested. Raises: MlfNoSuchMachineLearningError: If no machine_learning class found. MlfDuplicateMachineLearningError: If the system has multiple machine_learning items of the same class name. available_ml = get_available_inherited_classes(machine_learning, BaseMachineLearning) clazz = filter(lambda ml_class: ml_class.__name__ == class_name, available_ml) if not clazz: raise err.MlfNoSuchMachineLearningError(class_name) elif len(clazz) > 1: raise err.MlfDuplicateMachineLearningError(class_name) else: return clazz[0] """"""Gets available machine_learning class names. Returns: list: A list of available machine_learning class names. available_mls = get_available_inherited_classes(machine_learning, BaseMachineLearning) return [Clazz.__name__ for Clazz in available_mls] pass pass",132,190
openstack%2Fmonasca-analytics~master~I63204910a3d15bb8fd2c69c2f0483918f63f64c5,openstack/monasca-analytics,master,I63204910a3d15bb8fd2c69c2f0483918f63f64c5,renamed tests according to new convention (start with test_),ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source_manager/source/test_file_source.py', 'test/mocks/ml_mocks.py', 'test/source_manager/source/test_base_source.py', 'test/util/test_common_util.py', 'test/source_manager/source/test_kafka_source.py', 'test/test_ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/9f3b4ebdd13ca0653bcf5b347bfc293c3f6e11db', 'message': 'renamed tests according to new convention (start with test_)\n\nChange-Id: I63204910a3d15bb8fd2c69c2f0483918f63f64c5\n'}]",0,313337,9f3b4ebdd13ca0653bcf5b347bfc293c3f6e11db,3,1,1,21739,,,0,"renamed tests according to new convention (start with test_)

Change-Id: I63204910a3d15bb8fd2c69c2f0483918f63f64c5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/37/313337/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source_manager/source/test_file_source.py', 'test/mocks/ml_mocks.py', 'test/source_manager/source/test_base_source.py', 'test/util/test_common_util.py', 'test/source_manager/source/test_kafka_source.py', 'test/test_ml_framework.py']",6,9f3b4ebdd13ca0653bcf5b347bfc293c3f6e11db,,,,0,1
openstack%2Fmonasca-analytics~master~I341026a38aa116726ab48a0ba48bbb116ff6ec6a,openstack/monasca-analytics,master,I341026a38aa116726ab48a0ba48bbb116ff6ec6a,Add very basic ingestor for the hard-coded model of the markov chain source.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:39.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/data_ingestion_manager/data_ingestion/fake_host_switch_web_service_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3b380174261e167ace43247cdc64c32b625ab91f', 'message': 'Add very basic ingestor for the hard-coded model of the markov chain source.\n\nChange-Id: I341026a38aa116726ab48a0ba48bbb116ff6ec6a\n'}]",0,313350,3b380174261e167ace43247cdc64c32b625ab91f,3,1,1,21739,,,0,"Add very basic ingestor for the hard-coded model of the markov chain source.

Change-Id: I341026a38aa116726ab48a0ba48bbb116ff6ec6a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/50/313350/1 && git format-patch -1 --stdout FETCH_HEAD,['main/data_ingestion_manager/data_ingestion/fake_host_switch_web_service_ingestor.py'],1,3b380174261e167ace43247cdc64c32b625ab91f,,"#!/usr/bin/env python from abc import ABCMetaimport json __metaclass__ = ABCMeta json_value = json.loads(rdd_entry) vectors.append(FakeHostSwitchWebServiceIngestor._parse_and_vectorize(json_value)) @staticmethod def _parse_and_vectorize(json_value): # Features: time | host | web_service | switch | support feature_vec = [json_value[""ctime""], 0, 0, 0, 0] for e in json_value[""events""]: if ""host"" in e[""id""]: feature_vec[1] += 1 elif ""webs"" in e[""id""]: feature_vec[2] += 1 elif ""switch"" in e[""id""]: feature_vec[3] += 1 elif ""support"" in e[""id""]: feature_vec[4] += 1 return feature_vec "," pass # parsed_regs = parser.parse_data(rdd_entry) # vectors.append(data_vectorizer.vectorize_registers( # parsed_regs, # self._independend_regs, # self._skip_zeros))",22,6
openstack%2Fmonasca-analytics~master~I35fa471ce0a2c15884c2ac34f807719654f8d1b2,openstack/monasca-analytics,master,I35fa471ce0a2c15884c2ac34f807719654f8d1b2,Fix pep8 new checks.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:35.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/data_ingestion_manager/data_ingestion/fake_host_switch_web_service_ingestor.py', 'main/source_manager/source/markov_chain_source.py', 'Makefile', 'test/source_manager/source/test_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f19a10e217101e31f76bd029ec3c2ea2531bf642', 'message': 'Fix pep8 new checks.\n\nChange-Id: I35fa471ce0a2c15884c2ac34f807719654f8d1b2\n'}]",0,313351,f19a10e217101e31f76bd029ec3c2ea2531bf642,3,1,1,21739,,,0,"Fix pep8 new checks.

Change-Id: I35fa471ce0a2c15884c2ac34f807719654f8d1b2
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/51/313351/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/data_ingestion_manager/data_ingestion/fake_host_switch_web_service_ingestor.py', 'main/source_manager/source/markov_chain_source.py', 'Makefile', 'test/source_manager/source/test_markov_chain_source.py']",4,f19a10e217101e31f76bd029ec3c2ea2531bf642,," self.assertTrue(nb_iter < 10, msg=""Next state for"" "" FakePowerEl is broken"")"," self.assertTrue(nb_iter < 10, msg=""Next state for FakePowerEl is broken"")",54,24
openstack%2Fmonasca-analytics~master~Ia40675137bcbbaf95b8f3b9913b9962a3f538af8,openstack/monasca-analytics,master,Ia40675137bcbbaf95b8f3b9913b9962a3f538af8,"improved config, created an empty config file, which is the skeleton to be used by any config, and redesigned base_source",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:25.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/empty_config.json', 'main/source_manager/source/base_source.py', 'config/arc_config.json', 'main/exception/ml_framework_error.py', 'test/source_manager/__init__.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ce82633ff0e5e4b5828c0882933b666e26bc7e6b', 'message': 'improved config, created an empty config file, which is the skeleton to be used by any config, and redesigned base_source\n\nChange-Id: Ia40675137bcbbaf95b8f3b9913b9962a3f538af8\n'}]",0,313324,ce82633ff0e5e4b5828c0882933b666e26bc7e6b,3,1,1,21739,,,0,"improved config, created an empty config file, which is the skeleton to be used by any config, and redesigned base_source

Change-Id: Ia40675137bcbbaf95b8f3b9913b9962a3f538af8
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/24/313324/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/empty_config.json', 'main/source_manager/source/base_source.py', 'config/arc_config.json', 'main/exception/ml_framework_error.py', 'test/source_manager/__init__.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py']",6,ce82633ff0e5e4b5828c0882933b666e26bc7e6b,, #self.voter.attach(), self.voter.attach(),159,58
openstack%2Fmonasca-analytics~master~Ia86a2c66ed37a15929c5ce35137f6b3d2abb4744,openstack/monasca-analytics,master,Ia86a2c66ed37a15929c5ce35137f6b3d2abb4744,implemented the connection logic,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/util/common_util_test.py', 'test/resources/test_json.json', 'main/source_manager/source/base_source.py', 'config/arc_config.json', 'main/buffer_streamer/__init__.py', 'main/voter_manager/voter/base_voter.py', 'config/empty_config.json', 'test/ml_mocks.py', 'config/config_template.json', 'main/buffer_streamer/buffer_streamer.py', 'test/ml_framework_test.py', 'main/sink_manager/sink/base_sink.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2d75da0b86ccaf42b955d088a50711db2f5b5367', 'message': 'implemented the connection logic\n\nChange-Id: Ia86a2c66ed37a15929c5ce35137f6b3d2abb4744\n'}]",0,313330,2d75da0b86ccaf42b955d088a50711db2f5b5367,3,1,1,21739,,,0,"implemented the connection logic

Change-Id: Ia86a2c66ed37a15929c5ce35137f6b3d2abb4744
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/30/313330/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/util/common_util_test.py', 'test/resources/test_json.json', 'main/source_manager/source/base_source.py', 'config/arc_config.json', 'main/buffer_streamer/__init__.py', 'main/voter_manager/voter/base_voter.py', 'config/empty_config.json', 'test/ml_mocks.py', 'config/config_template.json', 'main/buffer_streamer/buffer_streamer.py', 'test/ml_framework_test.py', 'main/sink_manager/sink/base_sink.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py']",15,2d75da0b86ccaf42b955d088a50711db2f5b5367,," def __init__(self, _id, _config): self._id = _id self._config = _config self._voter = None def set_buffer_streamer(self, buffer_streamer): self._buffer_streamer = buffer_streamer def unset_buffer_streamer(self): self._buffer_streamer = None def set_voter(self, voter): self._voter = voter def unset_voter(self): self._voter = None def append_sink(self, sink): """""" Add the sink to the sinks list """""" self._sinks.append(sink) def remove_sink(self, sink): """""" Remove the sink from the sinks list """""" self._sinks.remove(sink) def set_sinks(self, sink): """""" Replace the sinks list with the one passed as parameter """""" self._sinks = sink def clean_sinks(self): """""" Remove all sinks from the list """""" self._sinks = []"," def __init__(self, ml_config, ml_model_name, voter): self._config = ml_config self._source_model_name = ml_model_name self._voter = voter def __del__(self): self.voter.detach()",546,177
openstack%2Fmonasca-analytics~master~Iceb11b6a895f20620ab1f8ac8e08cef959b5c77f,openstack/monasca-analytics,master,Iceb11b6a895f20620ab1f8ac8e08cef959b5c77f,Add validate links step.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/markov_source_config.json', 'config/config_template.json', 'main/config/config.py', 'main/config/connection.py', 'main/config/validation.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/318d73081a4ffe3d130c02e0715cb320da6bfd6d', 'message': 'Add validate links step.\n\nChange-Id: Iceb11b6a895f20620ab1f8ac8e08cef959b5c77f\n'}]",0,313424,318d73081a4ffe3d130c02e0715cb320da6bfd6d,3,1,1,21739,,,0,"Add validate links step.

Change-Id: Iceb11b6a895f20620ab1f8ac8e08cef959b5c77f
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/24/313424/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/markov_source_config.json', 'config/config_template.json', 'main/config/config.py', 'main/config/connection.py', 'main/config/validation.py']",5,318d73081a4ffe3d130c02e0715cb320da6bfd6d,,"def validate_links(links): """""" Validate links to make sure, nothing is missing. @type links: dict """""" missing = set([]) all_keys = set(links.keys()) for connections in links.values(): for component in connections: if component not in all_keys: missing.add(component.id()) if len(missing) > 0: raise SchemaError([ ""In connections section, the following components are not "" ""connected\n\t{}\n"" ""please modify the configuration so that their list of "" ""connections is at least '[]'"".format("", "".join(missing))], []) ",,25,3
openstack%2Fnova~master~If04f732a04588f070920bbd918531faf28fb4de4,openstack/nova,master,If04f732a04588f070920bbd918531faf28fb4de4,Move config options from nova/api directory (3),MERGED,2016-04-21 21:48:32.000000000,2016-05-11 16:54:08.000000000,2016-05-11 16:54:07.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-04-21 21:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a4b2d232ecb7af1d7d1cb66e50dac68621478a1', 'message': 'Move config options from nova/api directory (3)\n\nThis is the third patch moving config options from the nova/api\ndirectory. In this patch, several of the compute api options are moved.\nA subsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If04f732a04588f070920bbd918531faf28fb4de4\n'}, {'number': 2, 'created': '2016-04-22 03:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7c560d4b8e4dcc0729fe4a0476ffe2d0f793c8a', 'message': 'Move config options from nova/api directory (3)\n\nThis is the third patch moving config options from the nova/api\ndirectory. In this patch, several of the compute api options are moved.\nA subsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If04f732a04588f070920bbd918531faf28fb4de4\n'}, {'number': 3, 'created': '2016-04-27 09:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1c60313897c66a7e08254dae452bef3e19ba6d4', 'message': 'Move config options from nova/api directory (3)\n\nThis is the third patch moving config options from the nova/api\ndirectory. In this patch, several of the compute api options are moved.\nA subsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If04f732a04588f070920bbd918531faf28fb4de4\n'}, {'number': 4, 'created': '2016-04-28 16:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb3e2a599b5901da7c1cd6b6f7a1d9671bd762cb', 'message': 'Move config options from nova/api directory (3)\n\nThis is the third patch moving config options from the nova/api\ndirectory. In this patch, several of the compute api options are moved.\nA subsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If04f732a04588f070920bbd918531faf28fb4de4\n'}, {'number': 5, 'created': '2016-05-06 18:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77c2c71a1c36e31838c138ac8d431d0a510eabaf', 'message': 'Move config options from nova/api directory (3)\n\nThis is the third patch moving config options from the nova/api\ndirectory. In this patch, several of the compute api options are moved.\nA subsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If04f732a04588f070920bbd918531faf28fb4de4\n'}, {'number': 6, 'created': '2016-05-09 20:11:09.000000000', 'files': ['nova/tests/functional/api_sample_tests/test_hide_server_addresses.py', 'nova/api/opts.py', 'nova/api/openstack/compute/hide_server_addresses.py', 'nova/api/openstack/compute/__init__.py', 'nova/conf/api.py', 'nova/api/openstack/compute/fping.py', 'nova/api/openstack/compute/legacy_v2/contrib/fping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a74fd109ab10054b546580433093813b787dfee2', 'message': 'Move config options from nova/api directory (3)\n\nThis is the third patch moving config options from the nova/api\ndirectory. In this patch, several of the compute api options are moved.\nA subsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If04f732a04588f070920bbd918531faf28fb4de4\n'}]",9,309196,a74fd109ab10054b546580433093813b787dfee2,75,17,6,1063,,,0,"Move config options from nova/api directory (3)

This is the third patch moving config options from the nova/api
directory. In this patch, several of the compute api options are moved.
A subsequent patch will enhance the help text for these options.

Blueprint centralize-config-options-newton

Change-Id: If04f732a04588f070920bbd918531faf28fb4de4
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/309196/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/test_hide_server_addresses.py', 'nova/api/opts.py', 'nova/api/openstack/compute/hide_server_addresses.py', 'nova/api/openstack/compute/__init__.py', 'nova/conf/api.py', 'nova/api/openstack/compute/fping.py', 'nova/api/openstack/compute/legacy_v2/contrib/fping.py']",7,0a4b2d232ecb7af1d7d1cb66e50dac68621478a1,bp/centralize-config-options-newton,import nova.conf CONF = nova.conf.CONF,"from oslo_config import cfgfping_opts = [ cfg.StrOpt(""fping_path"", default=""/usr/sbin/fping"", help=""Full path to fping.""), ] CONF = cfg.CONF CONF.register_opts(fping_opts)",32,38
openstack%2Fmonasca-analytics~master~I35281e979333c65471aa0a16ebf2fa41b53d2066,openstack/monasca-analytics,master,I35281e979333c65471aa0a16ebf2fa41b53d2066,"if wrong class or wrong connection defined in config, now we raise an exception and finish the execution",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/config/test_create_components.py', 'main/spark/driver.py', 'test/util/test_common_util.py', 'test/source/test_base.py', 'test/test_monanas.py', 'test/mocks/sml_mocks.py', 'main/web_service/request_handler.py', 'main/config/config.py', 'main/config/creation.py', 'main/monanas.py', 'main/config/connection.py', 'main/exception/monanas.py', 'main/util/common_util.py', 'main/source/random.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3a297638d91b906dd7e19317283e58713e7937c2', 'message': 'if wrong class or wrong connection defined in config, now we raise an exception and finish the execution\n\nChange-Id: I35281e979333c65471aa0a16ebf2fa41b53d2066\n'}]",0,313428,3a297638d91b906dd7e19317283e58713e7937c2,3,1,1,21739,,,0,"if wrong class or wrong connection defined in config, now we raise an exception and finish the execution

Change-Id: I35281e979333c65471aa0a16ebf2fa41b53d2066
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/28/313428/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/config/test_create_components.py', 'main/spark/driver.py', 'test/util/test_common_util.py', 'test/source/test_base.py', 'test/test_monanas.py', 'test/mocks/sml_mocks.py', 'main/web_service/request_handler.py', 'main/config/config.py', 'main/config/creation.py', 'main/monanas.py', 'main/config/connection.py', 'main/exception/monanas.py', 'main/util/common_util.py', 'main/source/random.py', 'test/spark/test_driver.py']",15,3a297638d91b906dd7e19317283e58713e7937c2,,,from main.exception import mlf as err,48,29
openstack%2Fmonasca-analytics~master~Id9fc9d4b9e71ea734137e63ba23d0de5ef6eccd5,openstack/monasca-analytics,master,Id9fc9d4b9e71ea734137e63ba23d0de5ef6eccd5,Fix tests and style issues.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:54:03.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/spark/test_driver.py', 'main/spark/aggregator.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/bd7dcc72e1df25542d6abd3b9060d0425c76f02f', 'message': 'Fix tests and style issues.\n\nChange-Id: Id9fc9d4b9e71ea734137e63ba23d0de5ef6eccd5\n'}]",0,313431,bd7dcc72e1df25542d6abd3b9060d0425c76f02f,2,0,1,21739,,,0,"Fix tests and style issues.

Change-Id: Id9fc9d4b9e71ea734137e63ba23d0de5ef6eccd5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/31/313431/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/spark/test_driver.py', 'main/spark/aggregator.py']",2,bd7dcc72e1df25542d6abd3b9060d0425c76f02f,," self._combined_stream.foreachRDD( lambda _, rdd: self._processRDD(rdd))"," self._combined_stream.foreachRDD(lambda _, rdd: self._processRDD(rdd))",3,2
openstack%2Fmonasca-analytics~master~I848ca420e55375b0649163357b3a0e525169d905,openstack/monasca-analytics,master,I848ca420e55375b0649163357b3a0e525169d905,Add LiNGAM and connect learner to voter to transformer.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:53:39.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/machine_learning/test_lingam.py', 'main/voter/base_voter.py', 'main/transformer/base_transformer.py', 'main/machine_learning/base_learner.py', 'main/util/common_util.py', 'main/machine_learning/lingam.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/593a6bc34d323a73422dc01b749d6a754b44c728', 'message': 'Add LiNGAM and connect learner to voter to transformer.\n\nChange-Id: I848ca420e55375b0649163357b3a0e525169d905\n'}]",0,313379,593a6bc34d323a73422dc01b749d6a754b44c728,3,1,1,21739,,,0,"Add LiNGAM and connect learner to voter to transformer.

Change-Id: I848ca420e55375b0649163357b3a0e525169d905
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/79/313379/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/machine_learning/test_lingam.py', 'main/voter/base_voter.py', 'main/transformer/base_transformer.py', 'main/machine_learning/base_learner.py', 'main/util/common_util.py', 'main/machine_learning/lingam.py']",6,593a6bc34d323a73422dc01b749d6a754b44c728,,"from schema import Schema, Andfrom sklearn.decomposition import fastica from math import factorial import logging import numpy as np logger = logging.getLogger(__name__) def validate_config(self, _config): return Schema({ ""module"": And(basestring, lambda i: not any(c.isspace() for c in i)), ""params"": { ""threshold"": float } }).validate(_config) def number_of_samples_required(self): return 3000 def learn_structure(self, samples): threshold = self._config[""params""][""threshold""] causality_matrix, _ = LiNGAM._discover_structure(samples) n = causality_matrix.shape[0] edges = [] for i in range(n): for j in range(n): if causality_matrix[i, j] > threshold: edges.append([self._features[i], self._features[j]]) self._structure = Structure(V=self._features, E=edges) logger.debug(""Causality Matrix: {0}"".format(causality_matrix)) logger.debug(""Vertices: {0}"".format(self._structure.V)) logger.debug(""Edges: {0}"".format(self._structure.E)) @staticmethod def _discover_structure(data): # Add a random noise uniformly distributed to avoid singularity # when performing the ICA data += np.random.random_sample(data.shape) # Create the ICA node to get the inverse of the mixing matrix k, w, _ = fastica(data.transpose()) w = np.dot(w, k) n = w.shape[0] best_nzd = float(""inf"") best_slt = float(""inf"") best_w_permuted = w causality_matrix = None causal_perm = None if n < 9: perm = LiNGAM._perms(n) for i in range(perm.shape[1]): perm_matrix = np.eye(n) perm_matrix = perm_matrix[:, perm[:, i]] w_permuted = perm_matrix.dot(w) cost = LiNGAM._cost_non_zero_diag(w_permuted) if cost < best_nzd: best_nzd = cost best_w_permuted = w_permuted w_opt = best_w_permuted w_opt = w_opt / np.diag(w_opt).reshape((n, 1)) b_matrix = np.eye(n) - w_opt best_b_permuted = b_matrix best_i = 0 for i in range(perm.shape[1]): b_permuted = b_matrix[:, perm[:, i]][perm[:, i], :] cost = LiNGAM._cost_strictly_lower_triangular( b_permuted) if cost < best_slt: best_slt = cost best_i = i best_b_permuted = b_permuted causal_perm = perm[:, best_i] causality_matrix = b_matrix percent_upper = best_slt / np.sum(best_b_permuted ** 2) if percent_upper > 0.2: # TODO: Change that code to raise an exception instead logger.error(""LiNGAMCruncher failed to run on the data set"") logger.error( ""--> B permuted matrix is at best {}% lower triangular"" .format(percent_upper)) return causality_matrix, causal_perm @staticmethod def _cost_strictly_lower_triangular(b): return np.sum((np.tril(b, -1) - b) ** 2) @staticmethod def _cost_non_zero_diag(w): return np.sum(1 / np.abs(np.diag(w))) @staticmethod def _perms(n): k = 1 p = np.empty((2 * n - 1, factorial(n)), np.uint8) for i in range(n): p[i, :k] = i p[i + 1:2 * i + 1, :k] = p[:i, :k] for j in range(i): p[:i + 1, k * (j + 1):k * (j + 2)] = p[j + 1:j + i + 2, :k] k *= i + 1 return p[:n, :]"," def learn(self, data): pass",293,8
openstack%2Fmonasca-analytics~master~Ie356a399ff383db7a4145052e13d28d0e39b598e,openstack/monasca-analytics,master,Ie356a399ff383db7a4145052e13d28d0e39b598e,added tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:53:23.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/machine_learning_manager/machine_learning/anomaly_detection/__init__.py', 'test/__init__.py', 'test/data_aggregation_manager/data_agregator/__init__.py', 'test/data_ingestion_manager/data_ingestion/arc_parser/__init__.py', 'test/machine_learning_manager/machine_learning/classifiers/__init__.py', 'test/data_ingestion_manager/data_ingestion/arc_vectorizer/__init__.py', 'test/data_buffer_stream/__init__.py', 'test/data_ingestion_manager/__init__.py', 'test/data_aggregation_manager/__init__.py', 'test/machine_learning_manager/__init__.py', 'test/data_ingestion_manager/data_ingestion/__init__.py', 'test/machine_learning_manager/machine_learning/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2c02bddd845289fe421cbe76069156bb5cccf741', 'message': 'added tests\n\nChange-Id: Ie356a399ff383db7a4145052e13d28d0e39b598e\n'}]",0,313322,2c02bddd845289fe421cbe76069156bb5cccf741,3,1,1,21739,,,0,"added tests

Change-Id: Ie356a399ff383db7a4145052e13d28d0e39b598e
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/22/313322/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/machine_learning_manager/machine_learning/anomaly_detection/__init__.py', 'test/__init__.py', 'test/data_aggregation_manager/data_agregator/__init__.py', 'test/data_ingestion_manager/data_ingestion/arc_parser/__init__.py', 'test/machine_learning_manager/machine_learning/classifiers/__init__.py', 'test/data_ingestion_manager/data_ingestion/arc_vectorizer/__init__.py', 'test/data_buffer_stream/__init__.py', 'test/data_ingestion_manager/__init__.py', 'test/data_aggregation_manager/__init__.py', 'test/machine_learning_manager/__init__.py', 'test/data_ingestion_manager/data_ingestion/__init__.py', 'test/machine_learning_manager/machine_learning/__init__.py']",12,2c02bddd845289fe421cbe76069156bb5cccf741,,,,0,0
openstack%2Fmonasca-analytics~master~Ibbd8c892635d46706681f696d8658f3bba87c44c,openstack/monasca-analytics,master,Ibbd8c892635d46706681f696d8658f3bba87c44c,"added most of ARC classes, still not fully compatible with new model",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:53:19.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/machine_learning_manager/machine_learning/anomaly_detection/__init__.py', 'main/machine_learning_manager/machine_learning/classifiers/__init__.py', 'main/data_ingestion_manager/data_ingestion/arc_parser/__init__.py', 'setup.py', 'main/data_ingestion_manager/data_ingestion/arc_vectorizer/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/96beeeccbc73c69df348c3f51506c8eb3905880b', 'message': 'added most of ARC classes, still not fully compatible with new model\n\nChange-Id: Ibbd8c892635d46706681f696d8658f3bba87c44c\n'}]",0,313321,96beeeccbc73c69df348c3f51506c8eb3905880b,3,1,1,21739,,,0,"added most of ARC classes, still not fully compatible with new model

Change-Id: Ibbd8c892635d46706681f696d8658f3bba87c44c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/21/313321/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/machine_learning_manager/machine_learning/anomaly_detection/__init__.py', 'main/machine_learning_manager/machine_learning/classifiers/__init__.py', 'main/data_ingestion_manager/data_ingestion/arc_parser/__init__.py', 'setup.py', 'main/data_ingestion_manager/data_ingestion/arc_vectorizer/__init__.py']",5,96beeeccbc73c69df348c3f51506c8eb3905880b,,,,2,1
openstack%2Fmonasca-analytics~master~I9fac68ce3cb9240fa68e6c605fd22d57c76b66f0,openstack/monasca-analytics,master,I9fac68ce3cb9240fa68e6c605fd22d57c76b66f0,fixed incorrect exception names,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:53:16.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source_manager/source/random_source.py', 'main/source_manager/source/file_source.py', 'main/source_manager/source/kafka_source.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/5e58bfc9f3b3390eb9ab25383eb8335c21dbceda', 'message': 'fixed incorrect exception names\n\nChange-Id: I9fac68ce3cb9240fa68e6c605fd22d57c76b66f0\n'}]",0,313325,5e58bfc9f3b3390eb9ab25383eb8335c21dbceda,3,1,1,21739,,,0,"fixed incorrect exception names

Change-Id: I9fac68ce3cb9240fa68e6c605fd22d57c76b66f0
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/25/313325/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source_manager/source/random_source.py', 'main/source_manager/source/file_source.py', 'main/source_manager/source/kafka_source.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py']",4,5e58bfc9f3b3390eb9ab25383eb8335c21dbceda,, # self.voter.attach(), #self.voter.attach(),7,8
openstack%2Fmonasca-analytics~master~Id36835fbaf041f4447889411bb416d38d30431d2,openstack/monasca-analytics,master,Id36835fbaf041f4447889411bb416d38d30431d2,"added testing classes and mocks for ML_Framework, refactored it a bit, and moved test_json.json to test/resources",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:53:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/util/common_util_test.py', 'test/resources/test_json.json', 'config/logging.json', 'config/arc_config.json', 'test/ml_mocks.py', 'main/util/common_util.py', 'test/ml_framework_test.py', 'main/voter_manager/voter/identity.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ee50a67966df6413782cfed3af0bba0b9989238d', 'message': 'added testing classes and mocks for ML_Framework, refactored it a bit, and moved test_json.json to test/resources\n\nChange-Id: Id36835fbaf041f4447889411bb416d38d30431d2\n'}]",0,313328,ee50a67966df6413782cfed3af0bba0b9989238d,3,1,1,21739,,,0,"added testing classes and mocks for ML_Framework, refactored it a bit, and moved test_json.json to test/resources

Change-Id: Id36835fbaf041f4447889411bb416d38d30431d2
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/28/313328/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/util/common_util_test.py', 'test/resources/test_json.json', 'config/logging.json', 'config/arc_config.json', 'test/ml_mocks.py', 'main/util/common_util.py', 'test/ml_framework_test.py', 'main/voter_manager/voter/identity.py']",9,ee50a67966df6413782cfed3af0bba0b9989238d,,"from main.voter_manager.voter.base_voter import BaseVoter import logging logger = logging.getLogger(__name__) class FileSource(BaseVoter): def __init__(self, config): super.__init__() ",,249,47
openstack%2Fmonasca-analytics~master~I2f265cd82f23d7fae7e688b7884380b838037020,openstack/monasca-analytics,master,I2f265cd82f23d7fae7e688b7884380b838037020,added tests for the elements connection,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:53:10.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/util/common_util_test.py', 'test/resources/test_json.json', 'test/ml_mocks.py', 'test/resources/logging.json', 'test/ml_framework_test.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3d03e0ff73fec58be8118651a7ef0a34b407bfdb', 'message': 'added tests for the elements connection\n\nChange-Id: I2f265cd82f23d7fae7e688b7884380b838037020\n'}]",0,313331,3d03e0ff73fec58be8118651a7ef0a34b407bfdb,3,1,1,21739,,,0,"added tests for the elements connection

Change-Id: I2f265cd82f23d7fae7e688b7884380b838037020
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/31/313331/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/util/common_util_test.py', 'test/resources/test_json.json', 'test/ml_mocks.py', 'test/resources/logging.json', 'test/ml_framework_test.py']",6,3d03e0ff73fec58be8118651a7ef0a34b407bfdb,,"import json from logging.config import dictConfigfrom main.buffer_streamer.buffer_streamer import BufferStreamer class MlFrameworkTest(unittest.TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) self.setup_logging() self._backup_functions() self._restore_functions() def _backup_functions(self): self.original_validate_config_file = ml.ML_Framework.\ _validate_config_file self.original_get_class_by_name = cu.get_class_by_name def _restore_functions(self): ml.ML_Framework._validate_config_file = ml_mocks.ml_mocks.\ mock_validate_config_file def assert_instantiated_classes_once(self): for n in ml_mocks.ml_mocks.instantiated.keys(): self.assertEqual(1, len(ml_mocks.ml_mocks.instantiated[n])) def assert_instantiated_no_classes(self): for n in ml_mocks.ml_mocks.instantiated.keys(): self.assertEqual(0, len(ml_mocks.ml_mocks.instantiated[n])) self.assertEqual(1, len(ml_mocks.ml_mocks.instantiated[name])) for n in ml_mocks.ml_mocks.instantiated.keys(): if n != name: self.assertEqual(0, len(ml_mocks.ml_mocks.instantiated[n])) self.assert_instantiated_classes_once() self.assert_instantiated_no_classes() self.assert_instantiated_no_classes() self.assert_instantiated_no_classes() def assert_src_ingestors_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""ingestor_module""], ml_mocks.ml_mocks.instantiated[""src_module1""][0]._ingestors) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""src_module1""][0]._ingestors) def assert_ingestors_aggregator_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""aggr_module""][0], ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]._aggregator) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]._aggregator) def assert_ingestors_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""ingestor_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""ingestor_module""][0]._sinks) def assert_aggregator_buffer_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""aggr_module""][0]._buffer_streamer, BufferStreamer)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""aggr_module""][0]._buffer_streamer) def assert_aggregator_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._sinks) def assert_buffer_learners_connection(self, connected=True): # TODO implement buffer learners mock def assert_learners_buffer_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._buffer_streamer, BufferStreamer)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._buffer_streamer) def assert_learners_voter_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._voter, ml_mocks.MockClass_voter_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._voter) def assert_learners_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""learner_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""learner_module""][0]._sinks) def assert_voter_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module2""], ml_mocks.ml_mocks.instantiated[""voter_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""voter_module""][0]._sinks) def assert_sinks_learners_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""learner_module""], ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._learners) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._learners) self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""sink_module2""][0]._learners) def assert_sinks_voter_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""sink_module2""][0]._voter, ml_mocks.MockClass_voter_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[""sink_module2""][0]._voter) self.assertEqual( None, ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._voter) def test_connect_ingestors(self): ml_mocks.ml_mocks.reset_connections() self.mlf._connect_ingestors() self.assert_src_ingestors_connection(True) self.assert_ingestors_aggregator_connection(True) self.assert_ingestors_sinks_connection(True) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_aggregator(self): ml_mocks.ml_mocks.reset_connections() self.mlf._connect_aggregator() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(True) self.assert_aggregator_sinks_connection(True) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) ml_mocks.ml_mocks.reset_connections() self.mlf._connect_learners() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(True) self.assert_learners_buffer_connection(True) self.assert_learners_voter_connection(True) self.assert_learners_sinks_connection(True) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) ml_mocks.ml_mocks.reset_connections() self.mlf._connect_voter() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(True) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) ml_mocks.ml_mocks.reset_connections() self.mlf._connect_sinks() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(True) self.assert_sinks_voter_connection(True) def test_all_connections(self): self.assert_src_ingestors_connection(True) self.assert_ingestors_aggregator_connection(True) self.assert_ingestors_sinks_connection(True) self.assert_aggregator_buffer_connection(True) self.assert_aggregator_sinks_connection(True) self.assert_buffer_learners_connection(True) self.assert_learners_buffer_connection(True) self.assert_learners_voter_connection(True) self.assert_learners_sinks_connection(True) self.assert_voter_sinks_connection(True) self.assert_sinks_learners_connection(True) self.assert_sinks_voter_connection(True)"," class AnomalyDetectionTest(unittest.TestCase): self.original_validate_config_file =\ ml.ML_Framework._validate_config_file self.original_get_class_by_name = cu.get_class_by_name ml.ML_Framework._validate_config_file =\ ml_mocks.ml_mocks.mock_validate_config_file def assert_created_classes_once(self): for n in ml_mocks.ml_mocks.instantiation_cnt.keys(): self.assertEqual(1, ml_mocks.ml_mocks.instantiation_cnt[n]) def assert_created_no_classes(self): for n in ml_mocks.ml_mocks.instantiation_cnt.keys(): self.assertEqual(0, ml_mocks.ml_mocks.instantiation_cnt[n]) self.assertEqual(1, ml_mocks.ml_mocks.instantiation_cnt[name]) for n in ml_mocks.ml_mocks.instantiation_cnt.keys(): if n != name: self.assertEqual(0, ml_mocks.ml_mocks.instantiation_cnt[n]) self.assert_created_classes_once() self.assert_created_no_classes() self.assert_created_no_classes() self.assert_created_no_classes() def test_connect_ingestors(self): def test_connect_aggregator(self): pass pass pass pass",330,52
openstack%2Fkeystone~master~I0351dddc49da5908f46e09e22467f6fb112593dd,openstack/keystone,master,I0351dddc49da5908f46e09e22467f6fb112593dd,Make keystone exit when fernet keys don't exist,MERGED,2016-05-02 18:58:29.000000000,2016-05-11 16:53:09.000000000,2016-05-11 16:53:08.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 8866}, {'_account_id': 11022}, {'_account_id': 17860}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-05-02 18:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8236897f0e1f4697ebd308319bfab3ff3b2c4c62', 'message': ""Make keystone exit when fernet keys don't exist\n\nAn outcome of some of the token discussions in Austin was that when Fernet is\nthe configured token provider, Keystone should fail on start up if there are no\nkeys in the key repository or if the repository doesn't exist.\n\nChange-Id: I0351dddc49da5908f46e09e22467f6fb112593dd\n""}, {'number': 2, 'created': '2016-05-03 19:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9143687fe1749eefa2150c7b0255d79bc498a281', 'message': ""Make keystone exit when fernet keys don't exist\n\nAn outcome of some of the token discussions in Austin was that when Fernet is\nthe configured token provider, Keystone should fail on start up if there are no\nkeys in the key repository or if the repository doesn't exist.\n\nChange-Id: I0351dddc49da5908f46e09e22467f6fb112593dd\n""}, {'number': 3, 'created': '2016-05-04 13:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/849484760fed421c99c30765f8c0fbec3749a4c6', 'message': ""Make keystone exit when fernet keys don't exist\n\nAn outcome of some of the token discussions in Austin was that when Fernet is\nthe configured token provider, Keystone should fail on start up if there are no\nkeys in the key repository or if the repository doesn't exist.\n\nCloses-Bug: 1576315\n\nChange-Id: I0351dddc49da5908f46e09e22467f6fb112593dd\n""}, {'number': 4, 'created': '2016-05-04 17:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ed74e19f5aa10b5b9c53e4a2e97e3922d70218e4', 'message': ""Make keystone exit when fernet keys don't exist\n\nAn outcome of some of the token discussions in Austin was that when Fernet is\nthe configured token provider, Keystone should fail on start up if there are no\nkeys in the key repository or if the repository doesn't exist.\n\nCloses-Bug: 1576315\n\nChange-Id: I0351dddc49da5908f46e09e22467f6fb112593dd\n""}, {'number': 5, 'created': '2016-05-04 19:45:16.000000000', 'files': ['keystone/tests/unit/test_v2.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/token/providers/fernet/core.py', 'keystone/tests/unit/test_token_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/971ba5fa4522349d8c24a318fd6f0701ff0668f4', 'message': ""Make keystone exit when fernet keys don't exist\n\nAn outcome of some of the token discussions in Austin was that when Fernet is\nthe configured token provider, Keystone should fail on start up if there are no\nkeys in the key repository or if the repository doesn't exist.\n\nCloses-Bug: 1576315\n\nChange-Id: I0351dddc49da5908f46e09e22467f6fb112593dd\n""}]",6,311811,971ba5fa4522349d8c24a318fd6f0701ff0668f4,34,8,5,5046,,,0,"Make keystone exit when fernet keys don't exist

An outcome of some of the token discussions in Austin was that when Fernet is
the configured token provider, Keystone should fail on start up if there are no
keys in the key repository or if the repository doesn't exist.

Closes-Bug: 1576315

Change-Id: I0351dddc49da5908f46e09e22467f6fb112593dd
",git fetch https://review.opendev.org/openstack/keystone refs/changes/11/311811/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/token/providers/fernet/core.py'],1,8236897f0e1f4697ebd308319bfab3ff3b2c4c62,bug/1576315,"import os from keystone.i18n import _ if not os.path.exists(CONF.fernet_tokens.key_repository): # bail here because we can't do anything without a key_repository subs = {'key_repo': CONF.fernet_tokens.key_repository} raise SystemExit(_('%(key_repo)s does not exist') % subs) if not os.listdir(CONF.fernet_tokens.key_repository): # bail here because we can't do anything without keys subs = {'key_repo': CONF.fernet_tokens.key_repository} raise SystemExit(_('%(key_repo)s does not contain keys, use ' 'keystone-manage fernet_setup to create ' 'Fernet keys.') % subs) ",,14,0
openstack%2Fmonasca-analytics~master~I9652716f9b2b6d28bda4cf24be052b3405d21ea5,openstack/monasca-analytics,master,I9652716f9b2b6d28bda4cf24be052b3405d21ea5,"tested base_source, and created a new folder for mocks",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/__init__.py', 'test/source_manager/source/base_source_test.py', 'test/mocks/ingestors.py', 'test/mocks/ml_mocks.py', 'main/source_manager/source/base_source.py', 'test/ml_framework_test.py', 'test/source_manager/source/__init__.py', 'test/mocks/sources.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/8858a11bbd0a39c20a52b5876e9ae9b63fcc76cb', 'message': 'tested base_source, and created a new folder for mocks\n\nChange-Id: I9652716f9b2b6d28bda4cf24be052b3405d21ea5\n'}]",0,313333,8858a11bbd0a39c20a52b5876e9ae9b63fcc76cb,3,1,1,21739,,,0,"tested base_source, and created a new folder for mocks

Change-Id: I9652716f9b2b6d28bda4cf24be052b3405d21ea5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/33/313333/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/__init__.py', 'test/source_manager/source/base_source_test.py', 'test/mocks/ingestors.py', 'test/mocks/ml_mocks.py', 'main/source_manager/source/base_source.py', 'test/ml_framework_test.py', 'test/source_manager/source/__init__.py', 'test/mocks/sources.py']",8,8858a11bbd0a39c20a52b5876e9ae9b63fcc76cb,,"from main.source_manager.source.base_source import BaseSource class MockBaseSource(BaseSource): def __init__(self, _id, _config): super(MockBaseSource, self).__init__(_id, _config) self.before_binding_cnt = 0 self.after_binding_cnt = 0 self.before_unbinding_cnt = 0 self.after_unbinding_cnt = 0 def before_bind_source(self, scc): self.before_binding_cnt += 1 def after_bind_source(self, scc): self.after_binding_cnt += 1 def before_unbind_source(self): self.before_unbinding_cnt += 1 def after_unbind_source(self): self.after_unbinding_cnt += 1 def terminate_source(self): pass ",,123,6
openstack%2Fmonasca-analytics~master~I704734b71c53a1a62281f0c330ea8ca3dfbf5cd1,openstack/monasca-analytics,master,I704734b71c53a1a62281f0c330ea8ca3dfbf5cd1,"done the Source extensions and added tests. Some tests involving spark are still failing. We may want to use mocks instead, and test the real streams at integration",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:38.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source_manager/source/base_source_test.py', 'main/source_manager/source/base_source.py', 'main/source_manager/source/random_source.py', 'test/resources/fake_data_files/fake_data.txt', 'main/exception/ml_framework_error.py', 'main/source_manager/source/file_source.py', 'test/ml_framework_test.py', 'main/source_manager/source/kafka_source.py', 'test/mocks/sources.py', 'test/source_manager/source/file_source_test.py', 'test/source_manager/source/kafka_source_test.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ee737a67dafc1fbde680dd3387c6fde8b87d9ace', 'message': 'done the Source extensions and added tests. Some tests involving spark are still failing. We may want to use mocks instead, and test the real streams at integration\n\nChange-Id: I704734b71c53a1a62281f0c330ea8ca3dfbf5cd1\n'}]",0,313334,ee737a67dafc1fbde680dd3387c6fde8b87d9ace,3,1,1,21739,,,0,"done the Source extensions and added tests. Some tests involving spark are still failing. We may want to use mocks instead, and test the real streams at integration

Change-Id: I704734b71c53a1a62281f0c330ea8ca3dfbf5cd1
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/34/313334/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source_manager/source/base_source_test.py', 'main/source_manager/source/base_source.py', 'main/source_manager/source/random_source.py', 'test/resources/fake_data_files/fake_data.txt', 'main/exception/ml_framework_error.py', 'main/source_manager/source/file_source.py', 'test/ml_framework_test.py', 'main/source_manager/source/kafka_source.py', 'test/mocks/sources.py', 'test/source_manager/source/file_source_test.py', 'test/source_manager/source/kafka_source_test.py']",11,ee737a67dafc1fbde680dd3387c6fde8b87d9ace,,"import os import json from logging.config import dictConfig import unittest from main.source_manager.source.kafka_source import KafkaSource from schema import SchemaError from pyspark.streaming import StreamingContext class KafkaSourceTest(unittest.TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def setupClass(self): self.setup_logging() def setUp(self): self.valid_config = { ""module"": ""kafka_source"", ""params"": { ""zk_host"": ""my_host"", ""zk_port"": 1234, ""group_id"": ""my_group_id"", ""topics"": {""topic1"": 1, ""topic2"": 2} } } self.config_extra_param = { ""module"": ""kafka_source"", ""params"": { ""zk_host"": ""my_host"", ""zk_port"": 1234, ""group_id"": ""my_group_id"", ""topics"": {""topic1"": 1, ""topic2"": 2}, ""infiltrated"": ""wrong_param"" } } self.config_missing_param = { ""module"": ""kafka_source"", ""params"": { ""zk_host"": ""my_host"", ""group_id"": ""my_group_id"", ""topics"": {""topic1"": 1, ""topic2"": 2} } } self.config_wrong_type = { ""module"": 123, ""params"": { ""zk_host"": ""my_host"", ""zk_port"": 1234, ""group_id"": ""my_group_id"", ""topics"": {""topic1"": 1, ""topic2"": 2} } } self.config_missing_params = {""module"": ""file_source""} self.ks = KafkaSource(""fake_id"", self.valid_config) def tearDown(self): pass def test_validate_valid_config(self): self.assertEqual(self.valid_config, self.ks._config) def test_validate_config_extra_param(self): self.assertRaises( SchemaError, self.ks.validate_config, self.config_extra_param) def test_validate_config_missing_dir(self): self.assertRaises( SchemaError, self.ks.validate_config, self.config_missing_param) def test_validate_config_wrong_type(self): self.assertRaises( SchemaError, self.ks.validate_config, self.config_wrong_type) def test_validate_config_missing_params(self): self.assertRaises( SchemaError, self.ks.validate_config, self.config_missing_params) #def test_before_bind_source_dstream_created(self): # ssc = StreamingContext(None, None) # self.ks.before_bind_source(ssc) # self.assertEqual(1, ssc.file_stream_cnt) # self.assertIsNotNone(self.ks._dstream) ",,597,242
openstack%2Fmonasca-analytics~master~If1b3824a934efa40434de52dac1994b171e8f59d,openstack/monasca-analytics,master,If1b3824a934efa40434de52dac1994b171e8f59d,using MockSparkContext instead of real Spark in the unit test,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:34.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source_manager/source/base_source_test.py', 'test/mocks/ml_mocks.py', 'test/ml_framework_test.py', 'test/source_manager/source/file_source_test.py', 'test/source_manager/source/kafka_source_test.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/393a867427d085e80ca0eef9007f13b967e57b08', 'message': 'using MockSparkContext instead of real Spark in the unit test\n\nChange-Id: If1b3824a934efa40434de52dac1994b171e8f59d\n'}]",0,313335,393a867427d085e80ca0eef9007f13b967e57b08,3,1,1,21739,,,0,"using MockSparkContext instead of real Spark in the unit test

Change-Id: If1b3824a934efa40434de52dac1994b171e8f59d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/35/313335/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source_manager/source/base_source_test.py', 'test/mocks/ml_mocks.py', 'test/ml_framework_test.py', 'test/source_manager/source/file_source_test.py', 'test/source_manager/source/kafka_source_test.py']",5,393a867427d085e80ca0eef9007f13b967e57b08,," ""../../resources/logging.json"") def setUp(self): self.setup_logging()","from pyspark.streaming import StreamingContext ""resources/logging.json"") def setupClass(self): self.setup_logging() def setUp(self):",16,33
openstack%2Fmonasca-analytics~master~I50802893f6cf6acf35313b570008582c8c636f6d,openstack/monasca-analytics,master,I50802893f6cf6acf35313b570008582c8c636f6d,Fix maven error and add missing SPARK_HOME variable.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['fetch-deps.sh'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/c7447a313d24dfc28f1b08dfc0c93ec3cfa1e91b', 'message': 'Fix maven error and add missing SPARK_HOME variable.\n\nChange-Id: I50802893f6cf6acf35313b570008582c8c636f6d\n'}]",0,313339,c7447a313d24dfc28f1b08dfc0c93ec3cfa1e91b,3,1,1,21739,,,0,"Fix maven error and add missing SPARK_HOME variable.

Change-Id: I50802893f6cf6acf35313b570008582c8c636f6d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/39/313339/1 && git format-patch -1 --stdout FETCH_HEAD,['fetch-deps.sh'],1,c7447a313d24dfc28f1b08dfc0c93ec3cfa1e91b,," mkdir ~/.m2 LENGTH_FOR_HOST=`expr match ""$HTTP_PROXY"" 'http://[\.A-Za-z\-]*'`-7 <host>${HTTP_PROXY:7:$LENGTH_FOR_HOST}</host> cd ~/tmp sudo -E apt-get -y install python-numpy python-scipy ipython # Environment setup set -v echo 'export SPARK_HOME=~/spark' >> $HOME/.profile set +v ", <host>${HTTP_PROXY:7:-6}</host> sudo -E apt-get -y install python-numpy python-scipy python-mdp,10,2
openstack%2Fmonasca-analytics~master~I2ce146b07f145afd772267b28ed72d804615c195,openstack/monasca-analytics,master,I2ce146b07f145afd772267b28ed72d804615c195,"uncommented conneciton logic from ml_framework, fixed tests and separated mocked ingestor from abstract instantiation of ingestor to test it",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:26.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/mocks/ingestors.py', 'test/source_manager/source/test_file_source.py', 'test/source_manager/source/test_base_source.py', 'test/source_manager/source/test_kafka_source.py', 'test/test_ml_framework.py', 'test/data_ingestion_manager/data_ingestion/test_base_data_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2920dcc4db108bf5771420be337df3a0c9fbcc51', 'message': 'uncommented conneciton logic from ml_framework, fixed tests and separated mocked ingestor from abstract instantiation of ingestor to test it\n\nChange-Id: I2ce146b07f145afd772267b28ed72d804615c195\n'}]",0,313342,2920dcc4db108bf5771420be337df3a0c9fbcc51,3,1,1,21739,,,0,"uncommented conneciton logic from ml_framework, fixed tests and separated mocked ingestor from abstract instantiation of ingestor to test it

Change-Id: I2ce146b07f145afd772267b28ed72d804615c195
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/42/313342/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/mocks/ingestors.py', 'test/source_manager/source/test_file_source.py', 'test/source_manager/source/test_base_source.py', 'test/source_manager/source/test_kafka_source.py', 'test/test_ml_framework.py', 'test/data_ingestion_manager/data_ingestion/test_base_data_ingestor.py']",7,2920dcc4db108bf5771420be337df3a0c9fbcc51,,"from test.mocks.ingestors import DataIngestorBasicChild self.bi = DataIngestorBasicChild(""fake_id"", ""fake_config"")","from test.mocks.ingestors import MockDataIngestor self.bi = MockDataIngestor(""fake_id"", ""fake_config"")",40,22
openstack%2Fmonasca-analytics~master~I9a4edfc43ba117f1c27d0b77fb9a4c05155bbd83,openstack/monasca-analytics,master,I9a4edfc43ba117f1c27d0b77fb9a4c05155bbd83,Fix missing deps for VM. Add a makefile to simplify workflow.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:23.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['fetch-deps.sh', 'Makefile'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/12d1e01a62c11ac459c0981f323ef98ae53d84e0', 'message': 'Fix missing deps for VM. Add a makefile to simplify workflow.\n\nChange-Id: I9a4edfc43ba117f1c27d0b77fb9a4c05155bbd83\n'}]",0,313343,12d1e01a62c11ac459c0981f323ef98ae53d84e0,3,1,1,21739,,,0,"Fix missing deps for VM. Add a makefile to simplify workflow.

Change-Id: I9a4edfc43ba117f1c27d0b77fb9a4c05155bbd83
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/43/313343/1 && git format-patch -1 --stdout FETCH_HEAD,"['fetch-deps.sh', 'Makefile']",2,12d1e01a62c11ac459c0981f323ef98ae53d84e0,,PYTHON = python all: test style test: $(PYTHON) -m unittest discover -v clean: find . -type f -name '*.pyc' -exec rm {} + style: find . -type f -name '*.py' -exec pep8 --max-line-length 120 {} + .PHONY: all test clean style ,,16,0
openstack%2Fmonasca-analytics~master~Ibee36190f6baaf93e6e96f6ef76640d7e32a9e82,openstack/monasca-analytics,master,Ibee36190f6baaf93e6e96f6ef76640d7e32a9e82,AI-184: Add a markov chain source to model a more realistic random data source.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:19.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/markov_source_config.json', 'main/data_ingestion_manager/data_ingestion/fake_host_switch_web_service_ingestor.py', 'test/mocks/spark_mocks.py', 'main/source_manager/source/markov_chain_source.py', 'test/util/test_common_util.py', 'test/source_manager/source/test_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/625381970adc6f813dda67260832f24cf5d76c75', 'message': 'AI-184: Add a markov chain source to model a more realistic random data source.\n\nChange-Id: Ibee36190f6baaf93e6e96f6ef76640d7e32a9e82\n'}]",0,313345,625381970adc6f813dda67260832f24cf5d76c75,3,1,1,21739,,,0,"AI-184: Add a markov chain source to model a more realistic random data source.

Change-Id: Ibee36190f6baaf93e6e96f6ef76640d7e32a9e82
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/45/313345/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/markov_source_config.json', 'main/data_ingestion_manager/data_ingestion/fake_host_switch_web_service_ingestor.py', 'test/mocks/spark_mocks.py', 'main/source_manager/source/markov_chain_source.py', 'test/util/test_common_util.py', 'test/source_manager/source/test_markov_chain_source.py']",6,625381970adc6f813dda67260832f24cf5d76c75,,"import os import json from logging.config import dictConfig import unittest from main.source_manager.source.markov_chain_source import MarkovChainSource from main.source_manager.source.markov_chain_source import FakeHost, FakeSwitch from schema import SchemaError from test.mocks.spark_mocks import MockStreamingContext class MarkovChainSourceTest(unittest.TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def setUp(self): self.setup_logging() params = { ""webservice"": { ""run_to_slow"": { 0: 0.01, 8: 0.2, 12: 0.7, 14: 0.7, 22: 0.3, 24: 0.1 }, ""slow_to_run"": { 0: 1, 8: 0.7, 12: 0.1, 14: 0.1, 22: 0.8, 24: 0.99 }, ""stop_to_run"": 0.5 }, ""switch"": { ""on_to_off"": 0.1, ""off_to_on"": 0.5 }, ""host"": { ""on_to_off"": 0.5, ""off_to_on"": 0.1 }, ""support"": { ""get_called"": 0.5 }, ""server_sleep_in_seconds"": 0.1 } self.valid_config = { ""module"": ""markov_chain_source"", ""params"": dict(params), ""graph"": { ""h1:host"": [""s1""], ""h2:host"": [""s1""], ""s1:switch"": [], ""w1:web_service"": [""h1""], ""w2:web_service"": [""h2""] } } self.config_extra_param = dict(self.valid_config) self.config_extra_param[""params""] = dict(params) self.config_extra_param[""params""][""extra_param""] = ""john doe"" self.config_missing_param = dict(self.valid_config) self.config_missing_param[""params""] = dict(params) self.config_missing_param[""params""].pop(""host"") self.config_wrong_type = { ""module"": 123, ""params"": dict(self.valid_config[""params""]), ""graph"": {} } self.mcs = MarkovChainSource(""fake_id"", self.valid_config) def tearDown(self): pass def test_validate_valid_config(self): self.assertEqual(self.valid_config, self.mcs._config) def test_validate_config_extra_param(self): self.assertRaises( SchemaError, self.mcs.validate_config, self.config_extra_param) def test_validate_config_missing_param(self): self.assertRaises( SchemaError, self.mcs.validate_config, self.config_missing_param) def test_validate_config_wrong_type(self): self.assertRaises( SchemaError, self.mcs.validate_config, self.config_wrong_type) def test_next_state_switch(self): sw = FakeSwitch({""switch"": {""on_to_off"": 0.5, ""off_to_on"": 0.5}}) nb_iter = 0 while not sw._state == ""off"" and nb_iter < 10: nb_iter += 1 sw.next_state(1) self.assertTrue(nb_iter < 10, msg=""Next state for FakePowerEl is broken"") def test_next_state_switch_block_host(self): sw = FakeSwitch({""switch"": {""on_to_off"": 1, ""off_to_on"": 1}}) hs = FakeHost({""host"": {""on_to_off"": 0, ""off_to_on"": 0}}) hs.set_switch(sw) hour_of_day = 1 sw.next_state(hour_of_day) self.assertEqual(sw._state, ""off"") self.assertIsNotNone(hs.collect_event(hour_of_day)) sw.next_state(hour_of_day) self.assertEqual(sw._state, ""on"") self.assertIsNone(hs.collect_event(hour_of_day)) def test_before_bind_source_dstream_created(self): ssc = MockStreamingContext(None, None) self.mcs.before_bind_source(ssc) self.mcs.terminate_source() h, p = self.mcs._dstream self.assertEqual(h, ""localhost"") ",,619,2
openstack%2Fmonasca-analytics~master~I7a21a76012eeebc67ba50a06c1e9ca865d97f8ed,openstack/monasca-analytics,master,I7a21a76012eeebc67ba50a06c1e9ca865d97f8ed,Fix pep8 issue.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:16.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2d11a32c0d0a466addd34254734072f63cbd37a8', 'message': 'Fix pep8 issue.\n\nChange-Id: I7a21a76012eeebc67ba50a06c1e9ca865d97f8ed\n'}]",0,313347,2d11a32c0d0a466addd34254734072f63cbd37a8,3,1,1,21739,,,0,"Fix pep8 issue.

Change-Id: I7a21a76012eeebc67ba50a06c1e9ca865d97f8ed
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/47/313347/1 && git format-patch -1 --stdout FETCH_HEAD,['main/ml_framework.py'],1,2d11a32c0d0a466addd34254734072f63cbd37a8,, # config = validate_config_file(sys.argv[1]) # source_config_files = sys.argv[3:] # if not source_config_files:, #config = validate_config_file(sys.argv[1]) #source_config_files = sys.argv[3:] #if not source_config_files:,3,3
openstack%2Fmonasca-analytics~master~I31f5128ab2d27e9317055139f4fa9951e22bf84a,openstack/monasca-analytics,master,I31f5128ab2d27e9317055139f4fa9951e22bf84a,Add more test and add proper interpolation of values to determine probability for a particular hour.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/util/math.py', 'test/util/test_math.py', 'config/markov_source_config.json', 'main/source_manager/source/markov_chain_source.py', 'test/source_manager/source/test_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/1098f77b0be5c6c0e96efbb5f6b5b876d21f4963', 'message': 'Add more test and add proper interpolation of values to determine probability for a particular hour.\n\nChange-Id: I31f5128ab2d27e9317055139f4fa9951e22bf84a\n'}]",0,313348,1098f77b0be5c6c0e96efbb5f6b5b876d21f4963,3,1,1,21739,,,0,"Add more test and add proper interpolation of values to determine probability for a particular hour.

Change-Id: I31f5128ab2d27e9317055139f4fa9951e22bf84a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/48/313348/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/util/math.py', 'test/util/test_math.py', 'config/markov_source_config.json', 'main/source_manager/source/markov_chain_source.py', 'test/source_manager/source/test_markov_chain_source.py']",5,1098f77b0be5c6c0e96efbb5f6b5b876d21f4963,,"#!/usr/bin/env python from unittest import main, TestCaseclass MarkovChainSourceTest(TestCase): ""get_called"": { 0: 0.1, 8: 0.2, 12: 0.8, 14: 0.8, 22: 0.5, 24: 0.0 } def test_prepare_config(self): fake_sys = self.mcs._prepare_config() self.assertEqual(len(fake_sys._hosts), 2) self.assertEqual(len(fake_sys._swits), 1) self.assertEqual(len(fake_sys._webss), 2) for h in fake_sys._hosts: self.assertEqual(h._switch, fake_sys._swits[0]) for h, w in zip(fake_sys._hosts, fake_sys._webss): self.assertEqual(h, w._host) if __name__ == ""__main__"": main()","import unittestclass MarkovChainSourceTest(unittest.TestCase): ""get_called"": 0.5",104,11
openstack%2Fmonasca-analytics~master~I6067b0e4a4a82f73a47e42a0c672b9ddbb8cf74b,openstack/monasca-analytics,master,I6067b0e4a4a82f73a47e42a0c672b9ddbb8cf74b,Fix pep8 issues.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/util/test_common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/96874299c88778064722bb1e5c6d6112b4b070fa', 'message': 'Fix pep8 issues.\n\nChange-Id: I6067b0e4a4a82f73a47e42a0c672b9ddbb8cf74b\n'}]",0,313353,96874299c88778064722bb1e5c6d6112b4b070fa,3,1,1,21739,,,0,"Fix pep8 issues.

Change-Id: I6067b0e4a4a82f73a47e42a0c672b9ddbb8cf74b
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/53/313353/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/util/test_common_util.py']",2,96874299c88778064722bb1e5c6d6112b4b070fa,," self.assertItemsEqual( ['RandomSource', 'FileSource', 'KafkaSource', 'MarkovChainSource'], names) self.assertItemsEqual( ['ArcDataIngestor', 'FakeHostSwitchWebServiceIngestor'], names)"," self.assertItemsEqual(['RandomSource', 'FileSource', 'KafkaSource', 'MarkovChainSource'], names) self.assertItemsEqual(['ArcDataIngestor', 'FakeHostSwitchWebServiceIngestor'], names)",9,5
openstack%2Fmonasca-analytics~master~Ifabb257600d47d13512352ca58f4dc5d7e60c2f4,openstack/monasca-analytics,master,Ifabb257600d47d13512352ca58f4dc5d7e60c2f4,modified the config file and added transformer package,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/resources/test_json.json', 'main/transformer_manager/transformer/__init__.py', 'main/transformer_manager/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/1b170e75427ecdde61cc8c796234e4308ef25cb7', 'message': 'modified the config file and added transformer package\n\nChange-Id: Ifabb257600d47d13512352ca58f4dc5d7e60c2f4\n'}]",0,313358,1b170e75427ecdde61cc8c796234e4308ef25cb7,3,1,1,21739,,,0,"modified the config file and added transformer package

Change-Id: Ifabb257600d47d13512352ca58f4dc5d7e60c2f4
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/58/313358/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/resources/test_json.json', 'main/transformer_manager/transformer/__init__.py', 'main/transformer_manager/__init__.py']",3,1b170e75427ecdde61cc8c796234e4308ef25cb7,,,,17,24
openstack%2Fmonasca-analytics~master~I619571d4447f05fd92683fe9c991f14e093757f6,openstack/monasca-analytics,master,I619571d4447f05fd92683fe9c991f14e093757f6,centralized the model constant strings into config_model,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:52:00.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/util/common_util.py', 'main/util/config_model.py', 'test/test_ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/bb457a1d00c00ebcb7ae2bc4a2026afc47b8c4f5', 'message': 'centralized the model constant strings into config_model\n\nChange-Id: I619571d4447f05fd92683fe9c991f14e093757f6\n'}]",0,313360,bb457a1d00c00ebcb7ae2bc4a2026afc47b8c4f5,3,1,1,21739,,,0,"centralized the model constant strings into config_model

Change-Id: I619571d4447f05fd92683fe9c991f14e093757f6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/60/313360/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/util/common_util.py', 'main/util/config_model.py', 'test/test_ml_framework.py']",4,bb457a1d00c00ebcb7ae2bc4a2026afc47b8c4f5,,"import main.util.config_model as mod del self.mlf._config[mod.CONNECTIONS][""ing1""] self.mlf._config[mod.CONNECTIONS][""ing1""] = [] del self.mlf._config[mod.CONNECTIONS][""agg1""] self.mlf._config[mod.CONNECTIONS][""agg1""] = [] del self.mlf._config[mod.CONNECTIONS][""lrn1""] self.mlf._config[mod.CONNECTIONS][""lrn1""] = [] del self.mlf._config[mod.CONNECTIONS][""vot1""] self.mlf._config[mod.CONNECTIONS][""vot1""] = [] del self.mlf._config[mod.CONNECTIONS][""sin1""] del self.mlf._config[mod.CONNECTIONS][""sin2""] self.mlf._config[mod.CONNECTIONS][""sin1""] = [] self.mlf._config[mod.CONNECTIONS][""sin2""] = []"," del self.mlf._config[cu.connections][""ing1""] self.mlf._config[cu.connections][""ing1""] = [] del self.mlf._config[cu.connections][""agg1""] self.mlf._config[cu.connections][""agg1""] = [] del self.mlf._config[cu.connections][""lrn1""] self.mlf._config[cu.connections][""lrn1""] = [] del self.mlf._config[cu.connections][""vot1""] self.mlf._config[cu.connections][""vot1""] = [] del self.mlf._config[cu.connections][""sin1""] del self.mlf._config[cu.connections][""sin2""] self.mlf._config[cu.connections][""sin1""] = [] self.mlf._config[cu.connections][""sin2""] = []",101,98
openstack%2Fmonasca-analytics~master~I562e371b03e04614ef774d9b0074b7636f96cb30,openstack/monasca-analytics,master,I562e371b03e04614ef774d9b0074b7636f96cb30,"new model config validation in place, and tested",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:51:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/test_config_model.py', 'test/resources/test_json.json', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/util/config_model.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/36f08a3181c5c0b9ed79064e22fe6ce519bd5b34', 'message': 'new model config validation in place, and tested\n\nChange-Id: I562e371b03e04614ef774d9b0074b7636f96cb30\n'}]",0,313359,36f08a3181c5c0b9ed79064e22fe6ce519bd5b34,3,1,1,21739,,,0,"new model config validation in place, and tested

Change-Id: I562e371b03e04614ef774d9b0074b7636f96cb30
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/59/313359/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/test_config_model.py', 'test/resources/test_json.json', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/util/config_model.py']",5,36f08a3181c5c0b9ed79064e22fe6ce519bd5b34,,"import logging logger = logging.getLogger(__name__) valid_connection_types = { ""sources"": [""ingestors""], ""ingestors"": [""aggregators"", ""transformers"", ""sinks""], ""aggregators"": [""learners"", ""sinks""], ""learners"": [""voters"", ""sinks""], ""voters"": [""transformers"", ""sinks""], ""transformers"": [""sinks""], ""sinks"": [] } valid_feedback_connection_types = { ""sources"": [], ""ingestors"": [], ""aggregators"": [], ""learners"": [], ""voters"": [], ""transformers"": [], ""sinks"": [""voters"", ""learners""] } ""server"": { ""port"": int, ""debug"": bool }, ""sources"": { ""ingestors"": { ""aggregators"": { ""voters"": { ""transformers"": { basestring: {basestring: object} }, }, ""feedback"": { basestring: [basestring] if len(config[""aggregators""]) > 1: if len(config[""voters""]) > 1: for comp_type in valid_connection_types.keys(): logger.debug(""validating connection ""+from_id+"" --> ""+to_id) break from_id + "" connected to a wrong component: "" + to_id + "". It should be connected only to any of : "" + str(expected_types)], []) for comp_type in valid_connection_types.keys():def _validate_from_dictionary(config, conf_key, validation_dict): """""" Validates connections defined in config[conf_key], checking they are allowed by validation_dict. @type config: Dictionary @param config: Config model for the whole system @type conf_key: String @param conf_key: Key of the config dictionary where the connections to be checked are defined. @type config: Dictionary @param config: keys are source types, and values are lists of allowed destination types for that particular source type """""" for from_id in config[conf_key].keys(): _validate_existing_id(config, from_id) to_ids = config[conf_key][from_id] for comp_type in validation_dict.keys(): if from_id in config[comp_type].keys(): _validate_expected_dest_type( config, from_id, to_ids, validation_dict[comp_type]) Validates the components connections, and feedback connections, checking that only connections that make sense are defined. _validate_from_dictionary(config, ""connections"", valid_connection_types) _validate_from_dictionary(config, ""feedback"", valid_feedback_connection_types)"," comp_types = [""data_models"", ""data_sources"", ""data_ingestors"", ""aggregator"", ""learners"", ""voter"", ""sinks""] }, ""server"": { ""port"": int, ""debug"": bool ""data_models"": { ""data_sources"": { ""data_ingestors"": { basestring: {basestring: object} }, ""aggregator"": { ""voter"": { if len(config[""aggregator""]) > 1: if len(config[""voter""]) > 1: for comp_type in comp_types: from_id + "" connected to a wrong component:"" + to_id + ""It should be connected only to "" + expected_type], []) for comp_type in comp_types: Validates the connections, checking that only connections that make sense are defined. for from_id in config[""connections""].keys(): _validate_existing_id(config, from_id) to_ids = config[""connections""][from_id] if from_id in config[""data_models""].keys(): raise SchemaError(['Data models should not define connections'], []) if from_id in config[""data_sources""].keys(): _validate_expected_dest_type(config, from_id, to_ids, [""data_ingestors""]) continue if from_id in config[""data_ingestors""].keys() or\ from_id in config[""aggregator""].keys() or\ from_id in config[""learners""].keys() or\ from_id in config[""voter""].keys(): _validate_expected_dest_type(config, from_id, to_ids, [""sinks""]) continue if from_id in config[""sinks""].keys(): _validate_expected_dest_type(config, from_id, to_ids, [""voter"", ""learners""]) continue",155,167
openstack%2Fmonasca-analytics~master~I0b7cb8987e015eaab36f0f87d5082b3396b25a84,openstack/monasca-analytics,master,I0b7cb8987e015eaab36f0f87d5082b3396b25a84,"Removed buffer streamer, adapted classes to new connections definitions, added transformer, and refactored conection logic in ml_framework",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:51:54.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'main/transformer_manager/transformer/base_transformer.py', 'main/buffer_streamer/__init__.py', 'main/voter_manager/voter/base_voter.py', 'test/mocks/ml_mocks.py', 'main/buffer_streamer/buffer_streamer.py', 'main/util/config_model.py', 'test/test_ml_framework.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/fc6a1ffb12729c19b7785f4ed215cddcbd4b92a3', 'message': 'Removed buffer streamer, adapted classes to new connections definitions, added transformer, and refactored conection logic in ml_framework\n\nChange-Id: I0b7cb8987e015eaab36f0f87d5082b3396b25a84\n'}]",0,313361,fc6a1ffb12729c19b7785f4ed215cddcbd4b92a3,3,1,1,21739,,,0,"Removed buffer streamer, adapted classes to new connections definitions, added transformer, and refactored conection logic in ml_framework

Change-Id: I0b7cb8987e015eaab36f0f87d5082b3396b25a84
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/61/313361/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'main/transformer_manager/transformer/base_transformer.py', 'main/buffer_streamer/__init__.py', 'main/voter_manager/voter/base_voter.py', 'test/mocks/ml_mocks.py', 'main/buffer_streamer/buffer_streamer.py', 'main/util/config_model.py', 'test/test_ml_framework.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py']",12,fc6a1ffb12729c19b7785f4ed215cddcbd4b92a3,," self._aggregator = None self._sinks = [] def set_aggregator(self, aggregator): """""" Sets the aggregator. @type aggregator: BaseDataAggregator subclass object @param aggregator: Aggregator object that will be used """""" self._aggregator = aggregator def unset_aggregator(self): """""" Unsets the aggregator used by this ingestor """""" self._aggregator = None ",,291,513
openstack%2Fmonasca-analytics~master~I011021265b85088ed7f4d09d4ffa023b214d2fbb,openstack/monasca-analytics,master,I011021265b85088ed7f4d09d4ffa023b214d2fbb,Add transitions and dep checks.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:51:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/util/math.py', 'main/source_manager/source/monasca_markov_chain_source.py', 'main/source_manager/source/markov_chain/transistion.py', 'main/source_manager/source/markov_chain/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e5023521c6dfc5f4abcdf6a0cee19cffd10ced82', 'message': 'Add transitions and dep checks.\n\nChange-Id: I011021265b85088ed7f4d09d4ffa023b214d2fbb\n'}]",0,313362,e5023521c6dfc5f4abcdf6a0cee19cffd10ced82,3,1,1,21739,,,0,"Add transitions and dep checks.

Change-Id: I011021265b85088ed7f4d09d4ffa023b214d2fbb
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/62/313362/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/util/math.py', 'main/source_manager/source/monasca_markov_chain_source.py', 'main/source_manager/source/markov_chain/transistion.py', 'main/source_manager/source/markov_chain/base.py']",4,e5023521c6dfc5f4abcdf6a0cee19cffd10ced82,,"#!/usr/bin/env python from itertools import count from abc import ABCMeta, abstractmethod from main.source_manager.source.base_source import BaseSource from schema import And, Schema, Use, Or from threading import Thread from SocketServer import ThreadingTCPServer, BaseRequestHandler from datetime import datetime, timedelta from main.util.math import interpolate_1d import random import logging import time import json logger = logging.getLogger(__name__) class MarkovChainSource(BaseSource): """""" A markov chain model baked by a finite state machine to model more realistic scenario with optional confounding variables. This source is useful to see how causality is discovered in the presence of confounding variable as well as scenario where some alert appears only in a deterministic fashion. """""" @abstractmethod def validate_config(self, _config): pass def before_bind_source(self, ssc): """""" The _dstream object is created before this source is bound to the consumers. It uses a socketTextStream, to read data from the ThreadingTCPServer. @type ssc: pyspark.streaming.StreamingContext @param ssc: Spark Streaming Context that provides the data input """""" fake_system = self._prepare_config() port = self._start_thread(fake_system) self._dstream = ssc.socketTextStream( ""localhost"", port) def after_bind_source(self, ssc): pass def before_unbind_source(self): pass def after_unbind_source(self): pass def terminate_source(self): self._server.terminate = True # This is to allow all the messages # being sent by the handler to clear up. time.sleep(0.2) self._server.server_close() def _prepare_config(self): transitions = self._config[""transitions""] graph = self._config[""graph""] nodes = dict() for k in graph.keys(): node_name, node_type = k.split("":"") if node_type == ""host"": nodes[node_name] = FakeHost(transitions) elif node_type == ""switch"": nodes[node_name] = FakeSwitch(transitions) elif node_type == ""web_service"": nodes[node_name] = FakeWebService(transitions) for k, v in graph.iteritems(): node_name, _ = k.split("":"") for depend_on in v: if depend_on not in nodes: logger.warn( ""Configuration error: '{}' is not a proper dependency "" ""of '{}'"".format(depend_on, node_name)) else: n = nodes[node_name] o = nodes[depend_on] if type(n) == FakeHost and\ type(o) == FakeSwitch: n.set_switch(o) elif type(n) == FakeWebService and\ type(o) == FakeHost: n.set_host(o) else: logger.warn( ""Configuration error: '{}' doesn't"" "" have a suitable "" ""type for '{}'"".format( depend_on, node_name)) return FakeMonitoringSystem(nodes.values(), transitions) def _start_thread(self, fake_system): self._server = ThreadingTCPServer( ("""", 0), # Let the OS pick a port for us FMSTCPHandler, # Handler of the False) self._server.allow_reuse_address = True self._server.server_bind() self._server.server_activate() self._server.terminate = False self._server.fake_system = fake_system self._server.sleep_in_seconds = self._config[ ""params""][""server_sleep_in_seconds""] self._server_thread = Thread(target=self._serve_forever) self._server_thread.start() port_used = self._server.socket.getsockname()[1] return port_used def _serve_forever(self): try: self._server.serve_forever() except IOError: logger.debug(""Markov chain source's server stopped."") class MetaId(ABCMeta): def __new__(mcs, name, bases, namespace): cls = super(ABCMeta, mcs).__new__(mcs, name, bases, namespace) cls.ids = count(1) return cls class StateNode(object): """""" This class describes a particular node in the dependency graph. It holds the state information relative to that node and the dependencies with the other nodes. The Markov It is managed by one instance of a StateDescriptor. """""" __metaclass__ = MetaId def __init__(self, initial_state, markov_chain): self._id = next(self.__class__.ids) self.state = initial_state self._markov_chain = markov_chain self.dependencies = [] def next_state(self, hour_of_day): """""" Move this element to the next state. In practice this will affect child that depends on this element. @param hour_of_day: An integer in the range of 0 to 24 to express the hour of the day. """""" self._markov_chain.apply_on(self, hour_of_day) def collect_event(self, hour_of_day): """""" Collect event triggered for the next burst. @param hour_of_day: An integer in the range of 0 to 24 to express the hour of the day. @return: Event: The event for this step or None """""" pass",,295,1
openstack%2Fmonasca-analytics~master~I7ad30fe35e7e09d321487fec45584cce2e045bc6,openstack/monasca-analytics,master,I7ad30fe35e7e09d321487fec45584cce2e045bc6,Add more doc and some tests for dep checks.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:51:48.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source_manager/source/markov_chain/__init__.py', 'main/source_manager/source/markov_chain/__init__.py', 'main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/markov_chain/test_transition.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/67084b7c63941d8afc385cf12fdbedb7a6cbfddf', 'message': 'Add more doc and some tests for dep checks.\n\nChange-Id: I7ad30fe35e7e09d321487fec45584cce2e045bc6\n'}]",0,313363,67084b7c63941d8afc385cf12fdbedb7a6cbfddf,3,1,1,21739,,,0,"Add more doc and some tests for dep checks.

Change-Id: I7ad30fe35e7e09d321487fec45584cce2e045bc6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/63/313363/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source_manager/source/markov_chain/__init__.py', 'main/source_manager/source/markov_chain/__init__.py', 'main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/markov_chain/test_transition.py']",4,67084b7c63941d8afc385cf12fdbedb7a6cbfddf,,"#!/usr/bin/env python import os import json from logging.config import dictConfig from unittest import main, TestCase import main.source_manager.source.markov_chain.transistion as T class DummyState(object): def __init__(self, state=0): self.state = state self.dependencies = [] class MarkovChainSourceTest(TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../../../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def setUp(self): self.setup_logging() def tearDown(self): pass def test_first_order_dep_check(self): state = DummyState() state.dependencies.append(DummyState(1)) dc = T.FirstOrderDepCheck(1) self.assertTrue(dc(state)) state = DummyState() self.assertFalse(dc(state)) state = DummyState() state.dependencies.append(DummyState(2)) self.assertFalse(dc(state)) def test_second_order_dep_check(self): state = DummyState() state1 = DummyState() state.dependencies.append(state1) state1.dependencies.append(DummyState(1)) dc = T.SecondOrderDepCheck(1) self.assertTrue(dc(state)) state = DummyState() self.assertFalse(dc(state)) self.assertFalse(dc(state1)) def test_combiner_and_dep_check(self): state = DummyState() state1 = DummyState(1) state.dependencies.append(state1) state1.dependencies.append(DummyState(2)) dc = T.CombinerDepCheck(dpc1=T.FirstOrderDepCheck(1), dpc2=T.SecondOrderDepCheck(2), op=""and"") self.assertTrue(dc(state)) self.assertFalse(dc(state1)) state1.state = 2 self.assertFalse(dc(state)) state1.state = 1 state1.dependencies[0].state = 1 self.assertFalse(dc(state)) state = DummyState() self.assertFalse(dc(state)) def test_combiner_or_dep_check(self): state = DummyState() state1 = DummyState(1) state.dependencies.append(state1) state1.dependencies.append(DummyState(2)) dc = T.CombinerDepCheck(dpc1=T.FirstOrderDepCheck(1), dpc2=T.SecondOrderDepCheck(2), op=""or"") self.assertTrue(dc(state)) self.assertFalse(dc(state1)) state1.dependencies[0].state = 1 self.assertTrue(dc(state)) self.assertTrue(dc(state1)) state1.state = 2 self.assertFalse(dc(state)) state = DummyState() self.assertFalse(dc(state)) if __name__ == ""__main__"": main() ",,116,2
openstack%2Fmonasca-analytics~master~Ie65581fb0c42f71d3c1c20dd7a592ebbb9896cd5,openstack/monasca-analytics,master,Ie65581fb0c42f71d3c1c20dd7a592ebbb9896cd5,Add more test for the MarkovChain configuration.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:51:02.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/markov_chain/test_transition.py', 'main/source_manager/source/markov_chain/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/c86ae139da92c01e9a6e257bb1d90bc0a6a0cef3', 'message': 'Add more test for the MarkovChain configuration.\n\nChange-Id: Ie65581fb0c42f71d3c1c20dd7a592ebbb9896cd5\n'}]",0,313364,c86ae139da92c01e9a6e257bb1d90bc0a6a0cef3,3,1,1,21739,,,0,"Add more test for the MarkovChain configuration.

Change-Id: Ie65581fb0c42f71d3c1c20dd7a592ebbb9896cd5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/64/313364/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/markov_chain/test_transition.py', 'main/source_manager/source/markov_chain/base.py']",3,c86ae139da92c01e9a6e257bb1d90bc0a6a0cef3,, pass , pass,78,14
openstack%2Fmonasca-analytics~master~I1beb207b333d1d473988c11bb1699067a121a313,openstack/monasca-analytics,master,I1beb207b333d1d473988c11bb1699067a121a313,Fix tests.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/test_common_util.py', 'main/util/common_util.py', 'test/source_manager/source/test_markov_chain_source.py', 'main/source_manager/source/cloud_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2bec9ddc5d699959af6f9ba18e61f7acc72375b3', 'message': 'Fix tests.\n\nChange-Id: I1beb207b333d1d473988c11bb1699067a121a313\n'}]",0,313367,2bec9ddc5d699959af6f9ba18e61f7acc72375b3,3,1,1,21739,,,0,"Fix tests.

Change-Id: I1beb207b333d1d473988c11bb1699067a121a313
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/67/313367/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/test_common_util.py', 'main/util/common_util.py', 'test/source_manager/source/test_markov_chain_source.py', 'main/source_manager/source/cloud_markov_chain_source.py']",4,2bec9ddc5d699959af6f9ba18e61f7acc72375b3,," ""web_service"": {"," ""webservice"": {",17,24
openstack%2Fmonasca-analytics~master~If4d66ffac51869e57308d0c7e884d760af9b62c9,openstack/monasca-analytics,master,If4d66ffac51869e57308d0c7e884d760af9b62c9,Fix pep8 issues.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:54.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source_manager/source/markov_chain/test_events.py', 'test/source_manager/source/markov_chain/test_base.py', 'test/util/test_common_util.py', 'main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/test_markov_chain_source.py', 'main/source_manager/source/cloud_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/65a7ea8ba013f47e9d52f97e375ebccb37ccb490', 'message': 'Fix pep8 issues.\n\nChange-Id: If4d66ffac51869e57308d0c7e884d760af9b62c9\n'}]",0,313368,65a7ea8ba013f47e9d52f97e375ebccb37ccb490,3,1,1,21739,,,0,"Fix pep8 issues.

Change-Id: If4d66ffac51869e57308d0c7e884d760af9b62c9
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/68/313368/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source_manager/source/markov_chain/test_events.py', 'test/source_manager/source/markov_chain/test_base.py', 'test/util/test_common_util.py', 'main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/test_markov_chain_source.py', 'main/source_manager/source/cloud_markov_chain_source.py']",6,65a7ea8ba013f47e9d52f97e375ebccb37ccb490,,"from main.source_manager.source.markov_chain.base import MarkovChainSource from main.source_manager.source.markov_chain.base import StateNode from main.source_manager.source.markov_chain.events import Trigger from main.source_manager.source.markov_chain.events import EventBuilder support_node = StateNode(None, markov_chains[""support""], triggers[""support""]) nodes[node_name] = StateNode(""on"", markov_chains[""host""], triggers[""host""]) elif node_type == ""switch"": nodes[node_name] = StateNode(""on"", markov_chains[""switch""], triggers[""switch""]) elif node_type == ""web_service"": webs = StateNode(""run"", markov_chains[""web_service""], triggers[""web_service""]) ""Configuration error: '{}'"" "" is not a proper dependency"" "" of '{}'"".format(depend_on, node_name)) event_builder=EventBuilder( ""User complained for poor web service"")) node_check=dck.OrCheck(dck.EqCheck(""off""), dck.DepCheck(dck.EqCheck(""off""))),","from main.source_manager.source.markov_chain.base import MarkovChainSource, StateNode from main.source_manager.source.markov_chain.events import Trigger, EventBuilder support_node = StateNode(None, markov_chains[""support""], triggers[""support""]) nodes[node_name] = StateNode(""on"", markov_chains[""host""], triggers[""host""]) elif node_type == ""switch"": nodes[node_name] = StateNode(""on"", markov_chains[""switch""], triggers[""switch""]) elif node_type == ""web_service"": webs = StateNode(""run"", markov_chains[""web_service""], triggers[""web_service""]) ""Configuration error: '{}' is not a proper dependency "" ""of '{}'"".format(depend_on, node_name)) event_builder=EventBuilder(""User complained for poor web service"")) node_check=dck.OrCheck(dck.EqCheck(""off""), dck.DepCheck(dck.EqCheck(""off""))),",32,17
openstack%2Fmonasca-analytics~master~Ie27a936dda88afb4da1151df790470492be02f6a,openstack/monasca-analytics,master,Ie27a936dda88afb4da1151df790470492be02f6a,Refactor *_manager into *. Fix typos.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/machine_learning_manager/__init__.py', 'test/resources/test_json.json', 'test/source/markov_chain/__init__.py', 'main/source/markov_chain/events.py', 'main/voter/identity.py', 'test/data_ingestion/arc_vectorizer/__init__.py', 'test/data_ingestion/test_base_data_ingestor.py', 'main/transformer_manager/transformer/__init__.py', 'test/source/test_markov_chain_source.py', 'test/data_ingestion_manager/__init__.py', 'main/source/random_source.py', 'test/data_aggregation_manager/__init__.py', 'main/sink/__init__.py', 'main/voter_manager/__init__.py', 'main/voter/base_voter.py', 'main/voter/__init__.py', 'main/data_agregator/__init__.py', 'main/sink_manager/__init__.py', 'main/data_ingestion/arc_parser/__init__.py', 'test/source/test_base_source.py', 'test/data_ingestion/arc_parser/__init__.py', 'test/source/test_file_source.py', 'main/data_aggregation_manager/__init__.py', 'main/data_agregator/concatenation_aggregator.py', 'main/source/source_model.py', 'main/transformer/base_transformer.py', 'main/source/markov_chain/__init__.py', 'main/source/file_source.py', 'main/util/common_util.py', 'main/util/config_model.py', 'test/data_ingestion/__init__.py', 'main/source/__init__.py', 'main/ml_framework.py', 'main/source/base_source.py', 'main/source/kafka_source.py', 'main/source/markov_chain/prob_checks.py', 'test/mocks/ingestors.py', 'main/machine_learning/__init__.py', 'test/data_agregator/test_concatenation_aggregator.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py', 'main/data_ingestion/fake_host_switch_web_service_ingestor.py', 'test/mocks/ml_mocks.py', 'main/data_ingestion/__init__.py', 'main/source/markov_chain/base.py', 'main/transformer/__init__.py', 'test/machine_learning/__init__.py', 'main/machine_learning/base_machine_learning.py', 'test/mocks/sources.py', 'test/source_manager/__init__.py', 'test/test_ml_framework.py', 'main/source/monasca_markov_chain_source.py', 'main/source/cloud_markov_chain_source.py', 'main/data_ingestion_manager/__init__.py', 'main/source/markov_chain/transistion.py', 'test/mocks/aggregator.py', 'test/data_agregator/__init__.py', 'test/util/test_common_util.py', 'main/data_agregator/base_data_aggregator.py', 'test/source/test_kafka_source.py', 'test/source/markov_chain/test_transition.py', 'main/source/markov_chain/state_check.py', 'main/sink/base_sink.py', 'main/source_manager/__init__.py', 'test/source/__init__.py', 'main/data_ingestion/arc_vectorizer/__init__.py', 'test/machine_learning_manager/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/661d52c09471b881aea30fbf58c65fc2505ec6a8', 'message': 'Refactor *_manager into *. Fix typos.\n\nChange-Id: Ie27a936dda88afb4da1151df790470492be02f6a\n'}]",0,313369,661d52c09471b881aea30fbf58c65fc2505ec6a8,3,1,1,21739,,,0,"Refactor *_manager into *. Fix typos.

Change-Id: Ie27a936dda88afb4da1151df790470492be02f6a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/69/313369/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/machine_learning_manager/__init__.py', 'test/resources/test_json.json', 'test/source/markov_chain/__init__.py', 'main/source/markov_chain/events.py', 'main/voter/identity.py', 'test/data_ingestion/arc_vectorizer/__init__.py', 'test/data_ingestion/test_base_data_ingestor.py', 'main/transformer_manager/transformer/__init__.py', 'test/source/test_markov_chain_source.py', 'test/data_ingestion_manager/__init__.py', 'main/source/random_source.py', 'test/data_aggregation_manager/__init__.py', 'main/sink/__init__.py', 'main/voter_manager/__init__.py', 'main/voter/base_voter.py', 'main/voter/__init__.py', 'main/data_agregator/__init__.py', 'main/sink_manager/__init__.py', 'main/data_ingestion/arc_parser/__init__.py', 'test/source/test_base_source.py', 'test/data_ingestion/arc_parser/__init__.py', 'test/source/test_file_source.py', 'main/data_aggregation_manager/__init__.py', 'main/data_agregator/concatenation_aggregator.py', 'main/source/source_model.py', 'main/transformer/base_transformer.py', 'main/source/markov_chain/__init__.py', 'main/source/file_source.py', 'main/util/common_util.py', 'main/util/config_model.py', 'test/data_ingestion/__init__.py', 'main/source/__init__.py', 'main/ml_framework.py', 'main/source/base_source.py', 'main/source/kafka_source.py', 'main/source/markov_chain/prob_checks.py', 'test/mocks/ingestors.py', 'main/machine_learning/__init__.py', 'test/data_agregator/test_concatenation_aggregator.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py', 'main/data_ingestion/fake_host_switch_web_service_ingestor.py', 'test/mocks/ml_mocks.py', 'main/data_ingestion/__init__.py', 'main/source/markov_chain/base.py', 'main/transformer/__init__.py', 'test/machine_learning/__init__.py', 'main/machine_learning/base_machine_learning.py', 'test/mocks/sources.py', 'test/source_manager/__init__.py', 'test/test_ml_framework.py', 'main/source/monasca_markov_chain_source.py', 'main/source/cloud_markov_chain_source.py', 'main/data_ingestion_manager/__init__.py', 'main/source/markov_chain/transistion.py', 'test/mocks/aggregator.py', 'test/data_agregator/__init__.py', 'test/util/test_common_util.py', 'main/data_agregator/base_data_aggregator.py', 'test/source/test_kafka_source.py', 'test/source/markov_chain/test_transition.py', 'main/source/markov_chain/state_check.py', 'main/sink/base_sink.py', 'main/source_manager/__init__.py', 'test/source/__init__.py', 'main/data_ingestion/arc_vectorizer/__init__.py', 'test/machine_learning_manager/__init__.py']",67,661d52c09471b881aea30fbf58c65fc2505ec6a8,,,,160,144
openstack%2Fmonasca-analytics~master~Idd659078af77e39c5ccc8f27033234d469414357,openstack/monasca-analytics,master,Idd659078af77e39c5ccc8f27033234d469414357,Add type hints. Simplify MlFramework logic.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:49.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/aggregator/__init__.py', 'main/ml_framework.py', 'main/pipeline/executor.py', 'main/source/base_source.py', 'main/source/markov_chain/prob_checks.py', 'main/util/math.py', 'main/aggregator/concatenation_aggregator.py', 'config/arc_config.json', 'main/aggregator/base_aggregator.py', 'test/mocks/aggregator.py', 'test/data_agregator/test_concatenation_aggregator.py', 'main/source/markov_chain/events.py', 'main/machine_learning/lingam.py', 'config/config_template.json', 'main/source/markov_chain/base.py', 'main/util/common_util.py', 'main/machine_learning/base_machine_learning.py', 'main/pipeline/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/833abc53adcb198700359982d1037cf167de72ad', 'message': 'Add type hints. Simplify MlFramework logic.\n\nRun-time configuration changes will be handle differently. We want\nto treat them as configuration changes. This implies that the API\nis more likely to be vastly different.\n\nThus, this commit removes the hacky code for sources. The full feature\nwill be added later with a more flexible API.\n\nChange-Id: Idd659078af77e39c5ccc8f27033234d469414357\n'}]",0,313370,833abc53adcb198700359982d1037cf167de72ad,3,1,1,21739,,,0,"Add type hints. Simplify MlFramework logic.

Run-time configuration changes will be handle differently. We want
to treat them as configuration changes. This implies that the API
is more likely to be vastly different.

Thus, this commit removes the hacky code for sources. The full feature
will be added later with a more flexible API.

Change-Id: Idd659078af77e39c5ccc8f27033234d469414357
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/70/313370/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/aggregator/__init__.py', 'main/ml_framework.py', 'main/pipeline/executor.py', 'main/source/base_source.py', 'main/source/markov_chain/prob_checks.py', 'main/util/math.py', 'main/aggregator/concatenation_aggregator.py', 'config/arc_config.json', 'main/aggregator/base_aggregator.py', 'test/mocks/aggregator.py', 'test/data_agregator/test_concatenation_aggregator.py', 'main/source/markov_chain/events.py', 'main/machine_learning/lingam.py', 'config/config_template.json', 'main/source/markov_chain/base.py', 'main/util/common_util.py', 'main/machine_learning/base_machine_learning.py', 'main/pipeline/__init__.py']",18,833abc53adcb198700359982d1037cf167de72ad,,,,118,94
openstack%2Fmonasca-analytics~master~I4de9b1ad59d322e238a2a9f5bf092dfe5abf7a73,openstack/monasca-analytics,master,I4de9b1ad59d322e238a2a9f5bf092dfe5abf7a73,Remove join(). DStream aggregation is a bit unclear.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/aggregator/base_aggregator.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/1bd26ffac2475943afef02f73b90da75ff34caf3', 'message': 'Remove join(). DStream aggregation is a bit unclear.\n\nThis requires more discussion to find a clean and understandable\nsolution.\n\nChange-Id: I4de9b1ad59d322e238a2a9f5bf092dfe5abf7a73\n'}]",0,313371,1bd26ffac2475943afef02f73b90da75ff34caf3,3,1,1,21739,,,0,"Remove join(). DStream aggregation is a bit unclear.

This requires more discussion to find a clean and understandable
solution.

Change-Id: I4de9b1ad59d322e238a2a9f5bf092dfe5abf7a73
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/71/313371/1 && git format-patch -1 --stdout FETCH_HEAD,['main/aggregator/base_aggregator.py'],1,1bd26ffac2475943afef02f73b90da75ff34caf3,," else: logger.warn(""Stream ignored! Multi-stream isn't supported yet"") @type timestamp:"," self._input_streams = [] self._input_streams.append(_stream) return if _stream not in self._input_streams: self._input_streams.append(_stream) self._aggregated_stream.join(_stream) return logger.warn(""Already aggregated Stream!"") @type timestamp: timestamp object",3,9
openstack%2Fmonasca-analytics~master~I417d94544c570b94cf41b8be143d7060607ab4fe,openstack/monasca-analytics,master,I417d94544c570b94cf41b8be143d7060607ab4fe,Rename BaseMachineLearning to BaseUnsupervisedLearner.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/aggregator/base_aggregator.py', 'main/machine_learning/base_unsupervised_learner.py', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/sink/base_sink.py', 'main/machine_learning/lingam.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/1337fa654e271ed1ddf1f8c5bc741695fdb01844', 'message': 'Rename BaseMachineLearning to BaseUnsupervisedLearner.\n\nChange-Id: I417d94544c570b94cf41b8be143d7060607ab4fe\n'}]",0,313372,1337fa654e271ed1ddf1f8c5bc741695fdb01844,3,1,1,21739,,,0,"Rename BaseMachineLearning to BaseUnsupervisedLearner.

Change-Id: I417d94544c570b94cf41b8be143d7060607ab4fe
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/72/313372/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/aggregator/base_aggregator.py', 'main/machine_learning/base_unsupervised_learner.py', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/sink/base_sink.py', 'main/machine_learning/lingam.py']",6,1337fa654e271ed1ddf1f8c5bc741695fdb01844,,from base_unsupervised_learner import BaseUnsupervisedLearner class LiNGAM(BaseUnsupervisedLearner):,from base_machine_learning import BaseMachineLearning class LiNGAM(BaseMachineLearning):,46,22
openstack%2Fmonasca-analytics~master~I6e3525a4a5bc2c69582fda1467897d398cef528f,openstack/monasca-analytics,master,I6e3525a4a5bc2c69582fda1467897d398cef528f,Remove dead code.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/machine_learning/base_unsupervised_learner.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/cd6eba0728c9627ccdc76be5f4697d812623e712', 'message': 'Remove dead code.\n\nChange-Id: I6e3525a4a5bc2c69582fda1467897d398cef528f\n'}]",0,313373,cd6eba0728c9627ccdc76be5f4697d812623e712,3,1,1,21739,,,0,"Remove dead code.

Change-Id: I6e3525a4a5bc2c69582fda1467897d398cef528f
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/73/313373/1 && git format-patch -1 --stdout FETCH_HEAD,['main/machine_learning/base_unsupervised_learner.py'],1,cd6eba0728c9627ccdc76be5f4697d812623e712,,," self._buffer_streamer = None def set_buffer_streamer(self, buffer_streamer): self._buffer_streamer = buffer_streamer def unset_buffer_streamer(self): self._buffer_streamer = None ",0,7
openstack%2Fmonasca-analytics~master~Id28934d5e1466a53ef97cf7b70fb232b402b1566,openstack/monasca-analytics,master,Id28934d5e1466a53ef97cf7b70fb232b402b1566,Connect aggregator to learners.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/aggregator/base_aggregator.py', 'main/machine_learning/base_unsupervised_learner.py', 'main/util/common_util.py', 'main/source/markov_chain/events.py', 'main/machine_learning/lingam.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b5510a34bd37ab549869e39eaa54a3b551acf37f', 'message': 'Connect aggregator to learners.\n\nChange-Id: Id28934d5e1466a53ef97cf7b70fb232b402b1566\n'}]",0,313374,b5510a34bd37ab549869e39eaa54a3b551acf37f,3,1,1,21739,,,0,"Connect aggregator to learners.

Change-Id: Id28934d5e1466a53ef97cf7b70fb232b402b1566
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/74/313374/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/aggregator/base_aggregator.py', 'main/machine_learning/base_unsupervised_learner.py', 'main/util/common_util.py', 'main/source/markov_chain/events.py', 'main/machine_learning/lingam.py']",5,b5510a34bd37ab549869e39eaa54a3b551acf37f,, pass , pass,52,18
openstack%2Fmonasca-analytics~master~I25f50d11b88f136c13179f6ccad27bdc81f53b38,openstack/monasca-analytics,master,I25f50d11b88f136c13179f6ccad27bdc81f53b38,Fix tests.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:34.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/spark_mocks.py', 'main/aggregator/base_aggregator.py', 'main/machine_learning/base_learner.py', 'main/util/common_util.py', 'main/machine_learning/lingam.py', 'test/test_ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/53d4ebdeea6972f58e3ce528cf59fdfe8f04ecb5', 'message': 'Fix tests.\n\nChange-Id: I25f50d11b88f136c13179f6ccad27bdc81f53b38\n'}]",0,313375,53d4ebdeea6972f58e3ce528cf59fdfe8f04ecb5,3,1,1,21739,,,0,"Fix tests.

Change-Id: I25f50d11b88f136c13179f6ccad27bdc81f53b38
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/75/313375/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/spark_mocks.py', 'main/aggregator/base_aggregator.py', 'main/machine_learning/base_learner.py', 'main/util/common_util.py', 'main/machine_learning/lingam.py', 'test/test_ml_framework.py']",6,53d4ebdeea6972f58e3ce528cf59fdfe8f04ecb5,,," def test_bind_sources_srcids_param(self): self.mlf._bind_sources(source_ids=[""src1""]) self.assertEqual( ml_mocks.ml_mocks.instantiated[""src_module1""], ml_mocks.ml_mocks.bound_sources) self.assertEqual(1, len(self.mlf._bound_source_ids)) self.assert_bound_src1(True) self.assert_bound_src2(False) def test_bind_sources_srcids_param_no_list(self): self.assertRaises(err.MlfBindSourcesError, self.mlf._bind_sources, source_ids=""src1"") self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assert_bound_src1(False) self.assert_bound_src2(False) def test_bind_sources_srcids_param_inexistent(self): self.assertRaises(err.MlfBindSourcesError, self.mlf._bind_sources, source_ids=[""src25""]) self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assert_bound_src1(False) self.assert_bound_src2(False) def test_bind_sources_mixed_existence(self): self.assertRaises(err.MlfBindSourcesError, self.mlf._bind_sources, source_ids=[""src2"", ""src25""]) self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assert_bound_src1(False) self.assert_bound_src2(False) def test_start_streaming_src1(self): self.mlf.start_streaming([""src1""]) self.assert_bound_src1(True) self.assert_bound_src2(False) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_src1_src2(self): self.mlf.start_streaming([""src1"", ""src2""]) self.assert_bound_src1(True) self.assert_bound_src2(True) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_streaming_err(self): def failed_bind(obj, scc): raise Exception(""Failed to bind"") ml_mocks.ml_mocks.instantiated[ ""src_module2""][0].bind_source = failed_bind self.assertRaises(err.MlfStreamingError, self.mlf.start_streaming, [""src2""]) self.assert_bound_src1(False) self.assert_bound_src2(False) self.assertEqual(0, self.mlf._ssc.started_cnt) self.assertFalse(self.mlf.is_streaming()) def test_start_streaming_streaming_err_inexistent(self): self.assertRaises(err.MlfStreamingError, self.mlf.start_streaming, [""src3""]) self.assert_bound_src1(False) self.assert_bound_src2(False) self.assertEqual(0, self.mlf._ssc.started_cnt) self.assertFalse(self.mlf.is_streaming()) def test_start_streaming_twice_err(self): self.mlf.start_streaming([""src1"", ""src2""]) self.assertRaises(err.MlfAlreadyStartedStreaming, self.mlf.start_streaming, [""src1""]) self.assert_bound_src1(True) self.assert_bound_src2(True) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_twice_different_src(self): self.mlf.start_streaming([""src1""]) self.assertRaises(err.MlfAlreadyStartedStreaming, self.mlf.start_streaming, [""src2""]) self.assert_bound_src1(True) self.assert_bound_src2(False) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) ",32,96
openstack%2Fmonasca-analytics~master~I92925dee50bec49c199290c5bd72c769e4d04238,openstack/monasca-analytics,master,I92925dee50bec49c199290c5bd72c769e4d04238,Add kafka-python dependency.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:31.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/96d83932daa077110a3cb537c99d6b2ca9159328', 'message': 'Add kafka-python dependency.\n\nChange-Id: I92925dee50bec49c199290c5bd72c769e4d04238\n'}]",0,313377,96d83932daa077110a3cb537c99d6b2ca9159328,3,2,1,21739,,,0,"Add kafka-python dependency.

Change-Id: I92925dee50bec49c199290c5bd72c769e4d04238
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/77/313377/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,96d83932daa077110a3cb537c99d6b2ca9159328,," ""sklearn"", ""kafka-python"""," ""sklearn""",2,1
openstack%2Fmonasca-analytics~master~Ibfc54f3e2b9727f8d32328f85f969ed9dcc7aeed,openstack/monasca-analytics,master,Ibfc54f3e2b9727f8d32328f85f969ed9dcc7aeed,Fix markov chain config example.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:27.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/markov_source_config.json'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b53ea2fefadbd74ad3527424740afc9212d5b574', 'message': 'Fix markov chain config example.\n\nChange-Id: Ibfc54f3e2b9727f8d32328f85f969ed9dcc7aeed\n'}]",0,313380,b53ea2fefadbd74ad3527424740afc9212d5b574,3,1,1,21739,,,0,"Fix markov chain config example.

Change-Id: Ibfc54f3e2b9727f8d32328f85f969ed9dcc7aeed
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/80/313380/1 && git format-patch -1 --stdout FETCH_HEAD,['config/markov_source_config.json'],1,b53ea2fefadbd74ad3527424740afc9212d5b574,," ""module"": ""CloudMarkovChainSource"","," ""module"": ""markov_chain_source"",",1,1
openstack%2Fmonasca-analytics~master~Iddc83ec9c285eb58341bb302b848b53da852c938,openstack/monasca-analytics,master,Iddc83ec9c285eb58341bb302b848b53da852c938,fixed unit tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:24.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/base_source.py', 'test/resources/test_json.json', 'test/mocks/spark_mocks.py', 'test/util/test_common_util.py', 'test/source/test_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/fe409d32db8ad1f0ee4ddc9fd598829732858e9c', 'message': 'fixed unit tests\n\nChange-Id: Iddc83ec9c285eb58341bb302b848b53da852c938\n'}]",0,313382,fe409d32db8ad1f0ee4ddc9fd598829732858e9c,3,1,1,21739,,,0,"fixed unit tests

Change-Id: Iddc83ec9c285eb58341bb302b848b53da852c938
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/82/313382/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/base_source.py', 'test/resources/test_json.json', 'test/mocks/spark_mocks.py', 'test/util/test_common_util.py', 'test/source/test_markov_chain_source.py']",5,fe409d32db8ad1f0ee4ddc9fd598829732858e9c,," self.assertEqual(ssc._host, ""localhost"")"," h, p = self.mcs._dstream self.assertEqual(h, ""localhost"")",6,6
openstack%2Fmonasca-analytics~master~Ia25743b5d3af3c3e7e00eafd6eb01a5b0f47371a,openstack/monasca-analytics,master,Ia25743b5d3af3c3e7e00eafd6eb01a5b0f47371a,Fix bug with cloud markov model.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e84671d4dfbb283ce91ac8238e639d00ce88a53f', 'message': 'Fix bug with cloud markov model.\n\nChange-Id: Ia25743b5d3af3c3e7e00eafd6eb01a5b0f47371a\n'}]",0,313384,e84671d4dfbb283ce91ac8238e639d00ce88a53f,3,1,1,21739,,,0,"Fix bug with cloud markov model.

Change-Id: Ia25743b5d3af3c3e7e00eafd6eb01a5b0f47371a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/84/313384/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py']",2,e84671d4dfbb283ce91ac8238e639d00ce88a53f,," """""" Abstract method that should be implemented by subclasses @rtype: list[StateNode] @return: Returns a list of StateNode that do not have any dependencies """""" @type initial_state: str | int | None", @type initial_state: str | int,8,2
openstack%2Fmonasca-analytics~master~I021ea05d7a88b46b2750a6c9e1f0ab59e87ffb28,openstack/monasca-analytics,master,I021ea05d7a88b46b2750a6c9e1f0ab59e87ffb28,Fix errors with markov chain and associated tests.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:17.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py', 'test/source/test_markov_chain_source.py', 'main/source/markov_chain/events.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2a9c5a1f912b34fb77775a42032cccde7b33010e', 'message': 'Fix errors with markov chain and associated tests.\n\nChange-Id: I021ea05d7a88b46b2750a6c9e1f0ab59e87ffb28\n'}]",0,313385,2a9c5a1f912b34fb77775a42032cccde7b33010e,3,1,1,21739,,,0,"Fix errors with markov chain and associated tests.

Change-Id: I021ea05d7a88b46b2750a6c9e1f0ab59e87ffb28
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/85/313385/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py', 'test/source/test_markov_chain_source.py', 'main/source/markov_chain/events.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py']",6,2a9c5a1f912b34fb77775a42032cccde7b33010e,," event_builder=EventBuilder(""test"", ""t"") self.assertEqual(events[0].msg, ""test"", ""a"")"," event_builder=EventBuilder(""test"") self.assertEqual(events[0].msg, ""test"")",23,12
openstack%2Fmonasca-analytics~master~I31e8d8623b98e08120d1f8f110165fc27c45c5a5,openstack/monasca-analytics,master,I31e8d8623b98e08120d1f8f110165fc27c45c5a5,Add documentation for the project.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:14.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/images/tags.png', 'doc/dev_guide.md', 'SUMMARY.md', 'doc/images/alert_fatigue_pipeline_with_markov.png', 'doc/images/alert_fatigue_pipeline.png', 'doc/getting_started.md', 'doc/design.md', 'doc/examples.md', 'doc/images/monanas-logo-small.png', 'doc/images/architecture.png', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/584324f86e81d996c301b0b28b5d355d0bb7e51f', 'message': 'Add documentation for the project.\n\nChange-Id: I31e8d8623b98e08120d1f8f110165fc27c45c5a5\n'}]",0,313386,584324f86e81d996c301b0b28b5d355d0bb7e51f,3,2,1,21739,,,0,"Add documentation for the project.

Change-Id: I31e8d8623b98e08120d1f8f110165fc27c45c5a5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/86/313386/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/dev_guide.md', 'doc/images/tags.png', 'SUMMARY.md', 'doc/images/alert_fatigue_pipeline.png', 'doc/images/alert_fatigue_pipeline_with_markov.png', 'doc/getting_started.md', 'doc/design.md', 'doc/examples.md', 'doc/images/monanas-logo-small.png', 'doc/images/architecture.png', 'README.md']",11,584324f86e81d996c301b0b28b5d355d0bb7e51f,,"# MoNanas - Monasca Analytics Framework ![MoNanas Logo](doc/images/monanas-logo-small.png) ## Overview Monasca Analytics (MoNanas) is a statistical/machine-learning ([SML](doc/design.md#sml)) [flow](doc/design.md#flow) composition engine. Users can compose a sequence of algorithms to be executed by just providing a description as an input to MoNanas. The data flow is automatically handled by the framework. Easy [flow](doc/design.md#flow) composition and reusability means that we can speed up the extraction of actionable infrastructure insight. ### Advantages :thumbsup: Decouple algorithm design from execution. :thumbsup: Reusable specification of the desired [flow](doc/design.md#flow). :thumbsup: Language independent [flow](doc/design.md#flow) definition. :thumbsup: Data source and format independent. :thumbsup: Easy to add new [SML](doc/design.md#sml) algorithms and # combine them with pre-existing ones in the [flow](doc/design.md#flow). :thumbsup: Transparently exploit data parallelism. ### Example Use Cases Below are few use cases that are relevant to OpenStack. However, MoNanas enables you to add your own [data ingestors](doc/dev_guide.md#ingestors). | Example | Alert Fatigue Management | Anomaly Detection | |:------------------------------|:-------------------------|:------------------| | **Dataset** | Synthetic, but representative, set of Monasca alerts that are processed in a stream manner. This alert set represents alerts that are seen in a data center consisting of several racks, enclosures and nodes. | `iptables` rules together with the number of times they are fired in a time period. | | **Parsing** | Monasca alert parser. | Simple parser extracting period and number of fire events per rule. | | **SML algorithm flow** | `filter(bad_formatted) -> filter(duplicates) -> aggregate() >> aggregator` aggregation can utilize conditional independence causality, score-based causality, linear algebra causality. | `detect_anomaly() >> aggregator` anomaly detection could be based on SVM, trend, etc. | | **Output** | Directed acyclic alert graph with potential root causes at the top. | Rule set with an anomalous number of firing times in a time period. | | **:information_source: Note** | Even though this could be consumed directly by devops, the usage of [Vitrage MoNanas Sink](doc/getting_started.md#vitrage_sink) is recommended. The output of this module can speed up creation of a [Vitrage](https://wiki.openstack.org/wiki/Vitrage) entity graph to do further analysis on it. | None. | `->` indicates a sequential operation in the flow. `//` indicates beginning of group of operations running in parallel. `-` indicates operations running in parallel. `>>` indicates end of group of operations running in parallel. ### Documentation * [MoNanas/GettingStarted](doc/getting_started.md): A starting point for users and developers of MoNanas. ### Presentations * Monasca Analytics Framework: https://github.hpe.com/labs/monanas/blob/master/doc/slides/monanas.pptx ### Repositories Core: https://github.hpe.com/labs/monanas/ ## MoNanas Design See: [MoNanas/Design](doc/design.md) for details on MoNanas's architecture, its functional requirements and core concepts. ## Technologies MoNanas uses a number of third-party technologies: * Apache Spark (http://spark.apache.org/): Apache Spark is a fast and general engine for large-scale data processing. * Apache Kafka (http://kafka.apache.org/): Used by Monasca and MoNanas's Kafka `source` and `sink`. * Apache ZooKeeper (https://zookeeper.apache.org/): Used by Kafka. ## Feature Release Schedule - [x] Basic SML flow. - [x] New algorithm ""add-on"" ability. - [x] Example datasets and SML flows. - [ ] Vitrage Sink. - [ ] Container-enabled testing/deployment for non-production environments. - [ ] Expanded orchestration abilities/expressiveness. ## Contributing There are multiple ways to contribute to the project. All are equally important to us! * You can have a look at the [issue tracker](https://github.hpe.com/labs/monanas/issues) for problems that needs to be solved, ask if anyone is already working on it, and take the issue assignment. * You can also help us to add [new learning algorithms](doc/dev_guide.md#add_new_algorithms). * Finally, we are very interested in having more data sources to experiment with. The source can either be from an existing data provider or randomly generated. The more, the better! :) If you are interested to work on that aspect, [you are welcome as well](doc/dev_guide.md#add_new_sources). For more information on setting up your development environment, see [MoNanas/DevGuide](doc/dev_guide.md). ## Contributors Suksant Sae Lor (Hui), David Subiros Perez, Joan Varvenne, Luis M. Vaquero ## License Copyright (c) 2016 Hewlett Packard Enterprise Development Company, L.P. Licensed under the Apache License, Version 2.0 (the ""License""); you may not used this file except in compliance with the License. You may obtain a copy of the License at:http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","# Machine Learning Framework, Actionable Insights ## Description This framework provides a structure to be able to process data, aggregate it, apply differnet machine learning algorithms, consum the generated results, and save any results at any step in different platforms. Furthermore, it can be executed in a distributted system, as it uses spark. ## Pre-requisites 1. Python (>= v.2.7.6) 2. Apache Spark (>= v.1.4.1) for streaming data. Please, compile from source code. More information in: http://spark.apache.org/downloads.html 3. Apache Kafka (>= v.0.8.2.1) for message queue. (Not needed atm) 4. From the framework's root directory, run `sudo python setup.py develop`. If there is a proxy problem, try to run `sudo -E -H python setup.py develop` instead. ## Usage 1. Start Apache Kafka. (if used) 2. Run `python run.py -p <spark's path> -c <config's path> -l <log's path>`. For example, ```bash python run.py -p ~/Applications/spark \ -c ~/ml_framework/arc-alc-design/config/config.json \ -l ~/ml_framework/arc-alc-design/config/logging.json will run the ML framework with `default_source_config.json` as a data source. To run with another source or multiple sources, use `-s` option followed by source config files. 4. For more usage information, run `python run.py -h`. ## Settings - The setup properties such as version string can be modified in `setup_property.py` - To disable console logs generated by pyspark, change `log4j.rootCategory=INFO, console` to `log4j.rootCategory=ERROR, console` in `conf/log4j.properties` in spark's path. ## Development If you want to contribute to the project, a `Vagrantfile` is provided that automatically starts a vm provisioned with all the pre-requisites. To use this solution you need first to install [vagrant](https://www.vagrantup.com/) on your local machine. Then, in this folder you run: ```bash vagrant up && vagrant sshThis will set up a vm using vmware or virtualbox and ssh on it. Once you have ssh-ed on the machine, to start the machine learning framework, do: ```bash To test the code, run `python -m discover -v` from the code's root directory. The test requires `SPARK_HOME` to be set as an environment variable. Note that, during the tests, some warnings might appear if external libraries could not find their dependencies. However, this can be ignored. # Run the Machine Learning framework python run.py -p ~/spark -c /vagrant/config/config.json \ -l /vagrant/config/logging.json ```",639,57
openstack%2Fmonasca-analytics~master~I88b0e44b7b823c8ec76e9f5f5aef76b16f061556,openstack/monasca-analytics,master,I88b0e44b7b823c8ec76e9f5f5aef76b16f061556,Add base transformer's interface.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:09.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/voter/base_voter.py', 'main/transformer/base_transformer.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/7b3fb237f6f08c74f9eaab70c5b1326972917524', 'message': ""Add base transformer's interface.\n\nChange-Id: I88b0e44b7b823c8ec76e9f5f5aef76b16f061556\n""}]",0,313388,7b3fb237f6f08c74f9eaab70c5b1326972917524,3,2,1,21739,,,0,"Add base transformer's interface.

Change-Id: I88b0e44b7b823c8ec76e9f5f5aef76b16f061556
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/88/313388/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/voter/base_voter.py', 'main/transformer/base_transformer.py']",2,7b3fb237f6f08c74f9eaab70c5b1326972917524,,"from abc import ABCMeta, abstractmethod """""" Base class for transformer. To be extended by concrete transformers. """""" __metaclass__ = ABCMeta def __init__(self, id, config): def set_voter_output(self, path, features, matrix): @type path: list[str] @type features: list[str] @type matrix: numpy.ndarray pass @abstractmethod def process_stream(self, dstream): pass"," def __init__(self, _id, _config): self._structure = None def set_structure(self, structure): Set the structure to be used by this transformer. This is directly called by the voter once the learners have learned a structure. @param structure: The learned structure @type: numpy.ndarray self._structure = structure",19,10
openstack%2Fmonasca-analytics~master~I781bf597ba1a7d23f6149a223faa05bd56520206,openstack/monasca-analytics,master,I781bf597ba1a7d23f6149a223faa05bd56520206,Add _id to sink's bases.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:04.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/ml/base_sink.py', 'main/transformer/base_transformer.py', 'main/sink/dstream/kafka_sink.py', 'main/sink/dstream/base_sink.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/dd5395507c9b4a4a7bb24e5edc06f31411a8f0f4', 'message': ""Add _id to sink's bases.\n\nChange-Id: I781bf597ba1a7d23f6149a223faa05bd56520206\n""}]",0,313389,dd5395507c9b4a4a7bb24e5edc06f31411a8f0f4,3,2,1,21739,,,0,"Add _id to sink's bases.

Change-Id: I781bf597ba1a7d23f6149a223faa05bd56520206
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/89/313389/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/sink/ml/base_sink.py', 'main/transformer/base_transformer.py', 'main/sink/dstream/kafka_sink.py', 'main/sink/dstream/base_sink.py']",4,dd5395507c9b4a4a7bb24e5edc06f31411a8f0f4,," def __init__(self, _id, _config): self._id = _id self._config = _config"," def __init__(self, config): self._config = config",9,7
openstack%2Fmonasca-analytics~master~I2431f5709039e5d4006ed583c04f229d89f88482,openstack/monasca-analytics,master,I2431f5709039e5d4006ed583c04f229d89f88482,Add skeleton code to causality transformer.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:50:00.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/transformer/base_transformer.py', 'main/transformer/causality_transformer.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/aff361b34a3d11f73d4fecabc48aef4be22d38ca', 'message': 'Add skeleton code to causality transformer.\n\nChange-Id: I2431f5709039e5d4006ed583c04f229d89f88482\n'}]",0,313390,aff361b34a3d11f73d4fecabc48aef4be22d38ca,3,2,1,21739,,,0,"Add skeleton code to causality transformer.

Change-Id: I2431f5709039e5d4006ed583c04f229d89f88482
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/90/313390/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/transformer/base_transformer.py', 'main/transformer/causality_transformer.py']",2,aff361b34a3d11f73d4fecabc48aef4be22d38ca,,"#!/usr/bin/env python import base_transformer class CausalityTransformer(base_transformer.BaseTransformer): """""" A causality transformer. """""" def __init__(self, _id, _config): base_transformer.BaseTransformer(_id, _config) def process_stream(self, dstream): """""" @type dstream: pyspark.streaming.DStream """""" if (self._config[""params""][""mode""] == ""aggregate""): self._sink(dstream.transform(lambda timestamp, rdd: self._aggregate(timestamp, rdd))) elif (self._config[""params""][""mode""] == ""filter""): self._sink(dstream.transform(lambda timestamp, rdd: self._filter(timestamp, rdd))) else: self._sink(dstream) def _aggregate(self, timestamp, rdd): if (not self._path or not self._features or not self._matrix): return self._sc.parallelize(rdd.collect()) else: pass def _filter(self, timestamp, rdd): if (not self._path or not self._features or not self._matrix): return self._sc.parallelize(rdd.collect()) else: pass def _sink(self, dstream): for sink in self._sinks: sink.sink(dstream) ",,50,2
openstack%2Fmonasca-analytics~master~Ibc0aaea2ce713650b1ce6fefea0fd4f11bfc8836,openstack/monasca-analytics,master,Ibc0aaea2ce713650b1ce6fefea0fd4f11bfc8836,Remove sink type and refactor it into a single base sink. Remove feedback-related methods in sinks. Add transformers code base.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:57.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/transformer/monasca_transformer/__init__.py', 'main/transformer/cloud_transformer/__init__.py', 'main/sink/kafka_sink.py', 'test/util/test_common_util.py', 'main/sink/sink_config_validator.py', 'main/transformer/cloud_transformer/causality_transformer.py', 'main/transformer/monasca_transformer/base_transformer.py', 'main/sink/ml/base_sink.py', 'main/sink/dstream/base_sink.py', 'main/sink/ml/__init__.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/util/common_util.py', 'main/sink/base_sink.py', 'test/sink/dstream_sink/test_sink_config_validator.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/5f70f4f0506929ea978b6f0cd11fd8cfb00768c3', 'message': 'Remove sink type and refactor it into a single base sink. Remove feedback-related methods in sinks. Add transformers code base.\n\nChange-Id: Ibc0aaea2ce713650b1ce6fefea0fd4f11bfc8836\n'}]",0,313391,5f70f4f0506929ea978b6f0cd11fd8cfb00768c3,3,2,1,21739,,,0,"Remove sink type and refactor it into a single base sink. Remove feedback-related methods in sinks. Add transformers code base.

Change-Id: Ibc0aaea2ce713650b1ce6fefea0fd4f11bfc8836
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/91/313391/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/transformer/monasca_transformer/__init__.py', 'main/transformer/cloud_transformer/__init__.py', 'main/sink/kafka_sink.py', 'test/util/test_common_util.py', 'main/sink/sink_config_validator.py', 'main/transformer/cloud_transformer/causality_transformer.py', 'main/transformer/monasca_transformer/base_transformer.py', 'main/sink/ml/base_sink.py', 'main/sink/dstream/base_sink.py', 'main/sink/ml/__init__.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/util/common_util.py', 'main/sink/base_sink.py', 'test/sink/dstream_sink/test_sink_config_validator.py']",14,5f70f4f0506929ea978b6f0cd11fd8cfb00768c3,,import main.sink.sink_config_validator as validator,"import main.sink.dstream.sink_config_validator as validator ""type"": ""dstream"", invalid_config[""type""] = ""invalid_type"" self.assertRaises(schema.SchemaError, kafka, invalid_config) invalid_config = self._valid_config",100,112
openstack%2Fmonasca-analytics~master~I8290d0f9dfaec9ee1b57357800e71b2a3a7f5400,openstack/monasca-analytics,master,I8290d0f9dfaec9ee1b57357800e71b2a3a7f5400,"Fix vectorize, changed sample config to a more realistic one.",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:54.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/markov_source_config.json', 'main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py', 'main/data_ingestion/cloud.py', 'main/source/markov_chain/events.py', 'main/data_ingestion/fake_host_switch_web_service_ingestor.py', 'main/machine_learning/lingam.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3f17b509d29ea9f2989d61b7589a3e8ab56965bd', 'message': 'Fix vectorize, changed sample config to a more realistic one.\n\nChange-Id: I8290d0f9dfaec9ee1b57357800e71b2a3a7f5400\n'}]",0,313394,3f17b509d29ea9f2989d61b7589a3e8ab56965bd,3,1,1,21739,,,0,"Fix vectorize, changed sample config to a more realistic one.

Change-Id: I8290d0f9dfaec9ee1b57357800e71b2a3a7f5400
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/94/313394/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/markov_source_config.json', 'main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py', 'main/data_ingestion/cloud.py', 'main/source/markov_chain/events.py', 'main/data_ingestion/fake_host_switch_web_service_ingestor.py', 'main/machine_learning/lingam.py']",7,3f17b509d29ea9f2989d61b7589a3e8ab56965bd,," structure = causality_matrix > threshold logger.debug(""Learned causality: {0}"".format(structure)) return structure"," n = causality_matrix.shape[0] edges = [] for i in range(n): for j in range(n): if causality_matrix[i, j] > threshold: edges.append([self._features[i], self._features[j]]) self._structure = Structure(V=self._features, E=edges) logger.debug(""Vertices: {0}"".format(self._structure.V)) logger.debug(""Edges: {0}"".format(self._structure.E))",92,88
openstack%2Fmonasca-analytics~master~Ieaf66a981f1fbb65e2cea45c4c36f4ebff560d84,openstack/monasca-analytics,master,Ieaf66a981f1fbb65e2cea45c4c36f4ebff560d84,Fix pep8 errors and broken test.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:50.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/cloud_markov_chain_source.py', 'test/data_ingestion/test_base_data_ingestor.py', 'main/data_ingestion/cloud.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/59701b8597999069bb06ff7f1f3aebf7008b5bc8', 'message': 'Fix pep8 errors and broken test.\n\nChange-Id: Ieaf66a981f1fbb65e2cea45c4c36f4ebff560d84\n'}]",0,313396,59701b8597999069bb06ff7f1f3aebf7008b5bc8,3,1,1,21739,,,0,"Fix pep8 errors and broken test.

Change-Id: Ieaf66a981f1fbb65e2cea45c4c36f4ebff560d84
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/96/313396/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/cloud_markov_chain_source.py', 'test/data_ingestion/test_base_data_ingestor.py', 'main/data_ingestion/cloud.py']",3,59701b8597999069bb06ff7f1f3aebf7008b5bc8,," lambda rdd_entry: CloudIngestor._process_data(rdd_entry, feature_list))"," lambda rdd_entry: CloudIngestor._process_data(rdd_entry, feature_list))",4,3
openstack%2Fmonasca-analytics~master~I9e4a249680e9ed9dbdcd71b35b23bf5b1a10062c,openstack/monasca-analytics,master,I9e4a249680e9ed9dbdcd71b35b23bf5b1a10062c,Implement end 2 end! :),ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:47.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/source/base_source.py', 'main/transformer/cloud_causality.py', 'main/voter/pick_index.py', 'main/aggregator/concatenation_aggregator.py', 'main/voter/base_voter.py', 'config/markov_source_config.json', 'main/source/cloud_markov_chain_source.py', 'main/aggregator/base_aggregator.py', 'main/data_ingestion/cloud.py', 'test/data_agregator/test_concatenation_aggregator.py', 'test/util/test_common_util.py', 'main/transformer/cloud_transformer/causality_transformer.py', 'main/machine_learning/lingam.py', 'main/voter/identity.py', 'main/transformer/base_transformer.py', 'main/machine_learning/base_learner.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/util/common_util.py', 'main/sink/base_sink.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/0161ebae924b9cb20b2cc395fae75f51572d720a', 'message': 'Implement end 2 end! :)\n\nChange-Id: I9e4a249680e9ed9dbdcd71b35b23bf5b1a10062c\n'}]",0,313397,0161ebae924b9cb20b2cc395fae75f51572d720a,3,1,1,21739,,,0,"Implement end 2 end! :)

Change-Id: I9e4a249680e9ed9dbdcd71b35b23bf5b1a10062c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/97/313397/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/source/base_source.py', 'main/transformer/cloud_causality.py', 'main/voter/pick_index.py', 'main/aggregator/concatenation_aggregator.py', 'main/voter/base_voter.py', 'config/markov_source_config.json', 'main/source/cloud_markov_chain_source.py', 'main/aggregator/base_aggregator.py', 'main/data_ingestion/cloud.py', 'test/data_agregator/test_concatenation_aggregator.py', 'test/util/test_common_util.py', 'main/transformer/cloud_transformer/causality_transformer.py', 'main/machine_learning/lingam.py', 'main/voter/identity.py', 'main/transformer/base_transformer.py', 'main/machine_learning/base_learner.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/util/common_util.py', 'main/sink/base_sink.py']",20,0161ebae924b9cb20b2cc395fae75f51572d720a,," def sink_ml(self, voter_id, matrix):"," def sink_ml(self, matrix):",264,160
openstack%2Fmonasca-analytics~master~I1b941392c5ff4242e4d85f079175b102c36cea6d,openstack/monasca-analytics,master,I1b941392c5ff4242e4d85f079175b102c36cea6d,deleted ARC specific classes,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/data_ingestion/arc_parser/__init__.py', 'test/data_ingestion/arc_vectorizer/__init__.py', 'test/util/test_common_util.py', 'main/data_ingestion/arc_vectorizer/__init__.py', 'main/data_ingestion/arc_parser/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/673363e6d4748090008e2040658ba2b3e09787d8', 'message': 'deleted ARC specific classes\n\nChange-Id: I1b941392c5ff4242e4d85f079175b102c36cea6d\n'}]",0,313399,673363e6d4748090008e2040658ba2b3e09787d8,3,1,1,21739,,,0,"deleted ARC specific classes

Change-Id: I1b941392c5ff4242e4d85f079175b102c36cea6d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/99/313399/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/data_ingestion/arc_parser/__init__.py', 'test/data_ingestion/arc_vectorizer/__init__.py', 'test/util/test_common_util.py', 'main/data_ingestion/arc_vectorizer/__init__.py', 'main/data_ingestion/arc_parser/__init__.py']",5,673363e6d4748090008e2040658ba2b3e09787d8,,,,1,6
openstack%2Fmonasca-analytics~master~I453df0db123dc9665cf3e11be4505c40a3faad26,openstack/monasca-analytics,master,I453df0db123dc9665cf3e11be4505c40a3faad26,"the optionality was already working. Implemeted tests for it, or renamed existing tests",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:39.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/data_ingestion/test_base_data_ingestor.py', 'test/voter/__init__.py', 'test/voter/test_base_voter.py', 'test/source/test_base_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/03c3a6149fee535d84fc57af6c8fb77adfcd1428', 'message': 'the optionality was already working. Implemeted tests for it, or renamed existing tests\n\nChange-Id: I453df0db123dc9665cf3e11be4505c40a3faad26\n'}]",0,313400,03c3a6149fee535d84fc57af6c8fb77adfcd1428,3,1,1,21739,,,0,"the optionality was already working. Implemeted tests for it, or renamed existing tests

Change-Id: I453df0db123dc9665cf3e11be4505c40a3faad26
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/00/313400/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/data_ingestion/test_base_data_ingestor.py', 'test/voter/__init__.py', 'test/voter/test_base_voter.py', 'test/source/test_base_source.py']",4,03c3a6149fee535d84fc57af6c8fb77adfcd1428,, def test_bind_before_after_called_no_ingestors(self):, def test_bind_before_after_called(self):,31,1
openstack%2Fmonasca-analytics~master~I1b139be796160c54ee67a5b4201bd17f9b2be958,openstack/monasca-analytics,master,I1b139be796160c54ee67a5b4201bd17f9b2be958,deleted stale code that was used by ARC,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:36.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/resources/fake_data_files/fake_data.txt', 'test/util/test_common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/7fc72de732496f0b65095f610f0f7464a8996405', 'message': 'deleted stale code that was used by ARC\n\nChange-Id: I1b139be796160c54ee67a5b4201bd17f9b2be958\n'}]",0,313401,7fc72de732496f0b65095f610f0f7464a8996405,3,1,1,21739,,,0,"deleted stale code that was used by ARC

Change-Id: I1b139be796160c54ee67a5b4201bd17f9b2be958
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/01/313401/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/resources/fake_data_files/fake_data.txt', 'test/util/test_common_util.py']",2,7fc72de732496f0b65095f610f0f7464a8996405,,"from main.machine_learning.lingam import LiNGAM ""LiNGAM"") self.assertEqual(clazz, LiNGAM) ['LiNGAM'],","from main.machine_learning.anomaly_detection_svm_one \ import AnomalyDetectionSvmOneClass ""AnomalyDetectionSvmOneClass"") self.assertEqual(clazz, AnomalyDetectionSvmOneClass) ['AnomalyDetectionSvmOneClass', 'LiNGAM'],",4,37
openstack%2Fmonasca-analytics~master~Ia223d58cbe9c63c441b0e472295e9ad0c1fd2b24,openstack/monasca-analytics,master,Ia223d58cbe9c63c441b0e472295e9ad0c1fd2b24,Fix running issues.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:33.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/markov_source_config.json', 'run.py', 'main/util/common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/da1abff585fcf79c08a1354389720cf08c284403', 'message': 'Fix running issues.\n\nChange-Id: Ia223d58cbe9c63c441b0e472295e9ad0c1fd2b24\n'}]",0,313402,da1abff585fcf79c08a1354389720cf08c284403,3,1,1,21739,,,0,"Fix running issues.

Change-Id: Ia223d58cbe9c63c441b0e472295e9ad0c1fd2b24
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/02/313402/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/markov_source_config.json', 'run.py', 'main/util/common_util.py']",3,da1abff585fcf79c08a1354389720cf08c284403,," logkafka = logging.getLogger(""kafka"") logkafka.setLevel(logging.ERROR)",,8,4
openstack%2Fmonasca-analytics~master~Ie2061fd61e46c9597776cbc03d34fe78e3db88e0,openstack/monasca-analytics,master,Ie2061fd61e46c9597776cbc03d34fe78e3db88e0,Update README.md and log level in LiNGAM.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:30.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/machine_learning/lingam.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/75424b3bdc6d626553774d2b0413bb5487be026c', 'message': 'Update README.md and log level in LiNGAM.\n\nChange-Id: Ie2061fd61e46c9597776cbc03d34fe78e3db88e0\n'}]",0,313403,75424b3bdc6d626553774d2b0413bb5487be026c,3,2,1,21739,,,0,"Update README.md and log level in LiNGAM.

Change-Id: Ie2061fd61e46c9597776cbc03d34fe78e3db88e0
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/03/313403/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/machine_learning/lingam.py', 'README.md']",2,75424b3bdc6d626553774d2b0413bb5487be026c,,"- [ ] Support end-to-end learning + data processing flows (currently, the latter part does not get updated due to Spark's immutability.) - [ ] Refactor codes to be consistent with terms used in the documentation. - [ ] Add a source, ingestor and transformer for Monasca. - [ ] Model connections as objects rather than references and have driver specifics in one place.- [ ] Container-enabled testing/deployment for non-production environments. - [ ] Add Vitrage Sink. - [ ] Add a ready-to-use virtual machine image (get rid of the fetch-deps.sh).",- [ ] Vitrage Sink. - [ ] Container-enabled testing/deployment for non-production environments.,9,4
openstack%2Fmonasca-analytics~master~Iba6da5d7937e408c5710bfbd924949141bbf43e0,openstack/monasca-analytics,master,Iba6da5d7937e408c5710bfbd924949141bbf43e0,Refactor configuration handling to prepare driver.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:26.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/util/test_config_model.py', 'main/util/util.py', 'main/spark/driver.py', 'main/sink/sink_config_validator.py', 'main/config/config.py', 'main/config/const.py', 'main/config/creation.py', 'main/config/__init__.py', 'main/config/connection.py', 'main/config/validation.py', 'main/spark/__init__.py', 'main/util/common_util.py', 'test/test_ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/044454dff49a4a085bbc6668750d22ceb8beefc3', 'message': 'Refactor configuration handling to prepare driver.\n\nChange-Id: Iba6da5d7937e408c5710bfbd924949141bbf43e0\n'}]",0,313404,044454dff49a4a085bbc6668750d22ceb8beefc3,3,1,1,21739,,,0,"Refactor configuration handling to prepare driver.

Change-Id: Iba6da5d7937e408c5710bfbd924949141bbf43e0
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/04/313404/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/util/test_config_model.py', 'main/util/util.py', 'main/spark/driver.py', 'main/sink/sink_config_validator.py', 'main/config/config.py', 'main/config/const.py', 'main/config/creation.py', 'main/config/__init__.py', 'main/config/connection.py', 'main/config/validation.py', 'main/spark/__init__.py', 'main/util/common_util.py', 'test/test_ml_framework.py']",14,044454dff49a4a085bbc6668750d22ceb8beefc3,,import json import osfrom logging.config import dictConfig import main.config.validation as modimport main.util.common_util as cu from main.exception import ml_framework_error as err,import main.util.common_util as cu import main.util.config_model as mod import os import json from logging.config import dictConfig from main.exception import ml_framework_error as err,273,185
openstack%2Fmonasca-analytics~master~Ie2ca95f5f9a9143b4c5fa1aaf07489720a0e9eb4,openstack/monasca-analytics,master,Ie2ca95f5f9a9143b4c5fa1aaf07489720a0e9eb4,Refactoring the way nodes are connected.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:23.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/source/base_source.py', 'main/component/base.py', 'main/voter/base_voter.py', 'main/aggregator/base_aggregator.py', 'main/spark/driver.py', 'main/component/__init__.py', 'main/transformer/base_transformer.py', 'main/config/config.py', 'main/config/connection.py', 'main/machine_learning/base_learner.py', 'main/sink/base_sink.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/67696311226673c400572a1dd92349b5b578dbf3', 'message': 'Refactoring the way nodes are connected.\n\nChange-Id: Ie2ca95f5f9a9143b4c5fa1aaf07489720a0e9eb4\n'}]",0,313405,67696311226673c400572a1dd92349b5b578dbf3,3,1,1,21739,,,0,"Refactoring the way nodes are connected.

Change-Id: Ie2ca95f5f9a9143b4c5fa1aaf07489720a0e9eb4
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/05/313405/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/source/base_source.py', 'main/component/base.py', 'main/voter/base_voter.py', 'main/aggregator/base_aggregator.py', 'main/spark/driver.py', 'main/component/__init__.py', 'main/transformer/base_transformer.py', 'main/config/config.py', 'main/config/connection.py', 'main/machine_learning/base_learner.py', 'main/sink/base_sink.py']",12,67696311226673c400572a1dd92349b5b578dbf3,,from main.component.base import BaseComponent class BaseSink(BaseComponent):," class BaseSink(object): def __init__(self, _id, _config): self._id = _id self._config = _config ",198,394
openstack%2Fmonasca-analytics~master~I7fa2fafac1492390e8884544bd211e04c882efa9,openstack/monasca-analytics,master,I7fa2fafac1492390e8884544bd211e04c882efa9,"Fix style, clean-up 'validate_config' definitions.",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:19.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/source/base_source.py', 'main/transformer/cloud_causality.py', 'main/component/base.py', 'main/transformer/cloud_transformer/__init__.py', 'main/data_ingestion/cloud.py', 'main/spark/driver.py', 'main/transformer/base_transformer.py', 'main/config/creation.py', 'main/source/markov_chain/base.py', 'main/config/connection.py', 'main/transformer/cloud_transformer/base_transformer.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/c8851ff10bc63475217ee01f03b74ac0d7d9df6e', 'message': ""Fix style, clean-up 'validate_config' definitions.\n\nConnections should now be working.\n\nChange-Id: I7fa2fafac1492390e8884544bd211e04c882efa9\n""}]",0,313406,c8851ff10bc63475217ee01f03b74ac0d7d9df6e,3,1,1,21739,,,0,"Fix style, clean-up 'validate_config' definitions.

Connections should now be working.

Change-Id: I7fa2fafac1492390e8884544bd211e04c882efa9
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/06/313406/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/source/base_source.py', 'main/transformer/cloud_causality.py', 'main/component/base.py', 'main/transformer/cloud_transformer/__init__.py', 'main/data_ingestion/cloud.py', 'main/spark/driver.py', 'main/transformer/base_transformer.py', 'main/config/creation.py', 'main/source/markov_chain/base.py', 'main/config/connection.py', 'main/transformer/cloud_transformer/base_transformer.py']",12,c8851ff10bc63475217ee01f03b74ac0d7d9df6e,,,"#!/usr/bin/env python import logging from abc import ABCMeta, abstractmethod from main.transformer import base_transformer logger = logging.getLogger(__name__) class BaseTransformer(base_transformer.BaseTransformer): """""" Base class for cloud transformer. To be extended by concrete cloud transformers. """""" __metaclass__ = ABCMeta def __init__(self, _id, _config): base_transformer.BaseTransformer.__init__(self, _id, _config) def _sink(self, dstream): logger.debug(""Piping into {} sinks"".format(len(self._sinks))) for sink in self._sinks: sink.sink_dstream(dstream) if len(self._sinks) == 0: dstream.pprint() ",60,114
openstack%2Fmonasca-analytics~master~I913fc007e05d6ac8d22088c78c40177a926a59dc,openstack/monasca-analytics,master,I913fc007e05d6ac8d22088c78c40177a926a59dc,Removed unusued files.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/util/source_config_model.py', 'main/util/util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/5545444edad65d3344816aa97e71f9ae01c476e4', 'message': 'Removed unusued files.\n\nChange-Id: I913fc007e05d6ac8d22088c78c40177a926a59dc\n'}]",0,313408,5545444edad65d3344816aa97e71f9ae01c476e4,3,1,1,21739,,,0,"Removed unusued files.

Change-Id: I913fc007e05d6ac8d22088c78c40177a926a59dc
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/08/313408/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/util/source_config_model.py', 'main/util/util.py']",3,5545444edad65d3344816aa97e71f9ae01c476e4,,,"#!/usr/bin/env python """"""Util module for Alert Crunchers."""""" import logging from schema import SchemaError from main.config import validation from main.util import source_config_model from main.util.common_util import get_available_source_class_names from main.util.common_util import parse_json_file logger = logging.getLogger(__name__) def validate_config_file(config_file): """"""Validates the configuration file. Args: config_file (string): Configuration filename. Raises: IOError: If config_file not found. ValueError: If config_file is not a valid json. SchemaError: If config_file has an invalid schema. """""" try: config = parse_json_file(config_file) return validation.validate_config(config) except IOError as e: raise e except SchemaError as e: raise e except ValueError as e: raise e def validate_source_config_file(source_config_file, config): """"""Validates the source configuration file. Args: source_config_file (str): Source config filename. config (dict): Alert Cruncher's config. Raises: IOError: If source_config_file not found. ValueError: If source_config_file is not a valid json. SchemaError: If source_config_file has an invalid schema. """""" available_source_class_names = get_available_source_class_names() try: source_config = parse_json_file(source_config_file) validated_source_config = source_config_model.validate_source_config( source_config, available_source_class_names, None, config) return validated_source_config except IOError as e: raise e except SchemaError as e: raise e except ValueError as e: raise e ",1,181
openstack%2Fmonasca-analytics~master~I6c44cadd8cf6ebf65df255a5909ac2b07b627147,openstack/monasca-analytics,master,I6c44cadd8cf6ebf65df255a5909ac2b07b627147,Update mocks to more interesting interaction.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/voter/base_voter.py', 'test/resources/test_json.json', 'test/mocks/ml_mocks.py', 'test/mocks/spark_mocks.py', 'main/machine_learning/base_learner.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/eb41b9192a197f799e83e271783d8c0a28df560f', 'message': 'Update mocks to more interesting interaction.\n\nChange-Id: I6c44cadd8cf6ebf65df255a5909ac2b07b627147\n'}]",0,313412,eb41b9192a197f799e83e271783d8c0a28df560f,3,1,1,21739,,,0,"Update mocks to more interesting interaction.

Change-Id: I6c44cadd8cf6ebf65df255a5909ac2b07b627147
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/12/313412/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/voter/base_voter.py', 'test/mocks/ml_mocks.py', 'test/resources/test_json.json', 'test/mocks/spark_mocks.py', 'main/machine_learning/base_learner.py', 'test/spark/test_driver.py']",6,eb41b9192a197f799e83e271783d8c0a28df560f,, def test_pipeline_connected(self): self.mlf.start_pipeline()," def assert_src_ingestors_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""ingestor_module""], ml_mocks.ml_mocks.instantiated[""src_module1""][0]._ingestors) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""src_module1""][0]._ingestors) def assert_src_transformers_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""transformer_module1""], ml_mocks.ml_mocks.instantiated[ ""src_module1""][0]._transformers) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[ ""src_module1""][0]._transformers) def assert_ingestors_aggregator_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""aggr_module""][0], ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]._aggregator) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]._aggregator) def assert_ingestors_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""ingestor_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""ingestor_module""][0]._sinks) def assert_aggregator_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._sinks) def assert_aggregator_learners_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""learner_module""], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._learners) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._learners) def assert_learners_aggregator_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._aggregator, ml_mocks.MockClass_aggr_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._aggregator) def assert_learners_voter_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._voter, ml_mocks.MockClass_voter_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._voter) def assert_learners_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""learner_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""learner_module""][0]._sinks) def assert_voter_transformers_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""transformer_module1""], ml_mocks.ml_mocks.instantiated[ ""voter_module""][0]._transformers) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[ ""voter_module""][0]._transformers) def assert_voter_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""voter_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""voter_module""][0]._sinks) def assert_transformers_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module2""], ml_mocks.ml_mocks.instantiated[ ""transformer_module1""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[ ""transformer_module1""][0]._sinks) def assert_sinks_learners_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""learner_module""], ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._learners) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._learners) self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""sink_module2""][0]._learners) def assert_sinks_voter_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""sink_module2""][0]._voter, ml_mocks.MockClass_voter_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[""sink_module2""][0]._voter) self.assertEqual( None, ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._voter)",61,242
openstack%2Fmonasca-analytics~master~I70087ae73fb76f70faef00ce8e0bbc90dc799697,openstack/monasca-analytics,master,I70087ae73fb76f70faef00ce8e0bbc90dc799697,Fix bug and add tests for connections.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:06.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/resources/test_json.json', 'test/mocks/ml_mocks.py', 'main/transformer/base_transformer.py', 'test/mocks/spark_mocks.py', 'main/aggregator/base_aggregator.py', 'main/config/config.py', 'main/spark/driver.py', 'main/config/connection.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/d15ad45be763871e4ca98f817f8d1e2eb77a7c8a', 'message': 'Fix bug and add tests for connections.\n\nChange-Id: I70087ae73fb76f70faef00ce8e0bbc90dc799697\n'}]",0,313413,d15ad45be763871e4ca98f817f8d1e2eb77a7c8a,3,1,1,21739,,,0,"Fix bug and add tests for connections.

Change-Id: I70087ae73fb76f70faef00ce8e0bbc90dc799697
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/13/313413/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/ml_mocks.py', 'test/resources/test_json.json', 'main/transformer/base_transformer.py', 'test/mocks/spark_mocks.py', 'main/aggregator/base_aggregator.py', 'main/config/config.py', 'main/config/connection.py', 'main/spark/driver.py', 'test/spark/test_driver.py']",9,d15ad45be763871e4ca98f817f8d1e2eb77a7c8a,,"from test.mocks.spark_mocks import MockDStream ml_mocks.ml_mocks.reset_connections() def assert_src_initialized(self, src): self.assertEqual(src.get_feature_list_cnt, 1) self.assertEqual(src.create_dstream_cnt, 1) def assert_src_termintated(self, src): self.assertEqual(src.terminate_source_cnt, 1) def assert_ingestor(self, ing): self.assertEqual(ing.map_dstream_cnt, 1) def assert_agg(self, agg): self.assertEqual(agg.accumulate_dstream_samples_cnt, 1) self.assertEqual(agg.append_learner_cnt, 1) def assert_lrn(self, lrn): self.assertEqual(lrn.learn_structure_cnt, 1) def assert_voter(self, voter): self.assertEqual(voter.elect_structure_cnt, 1) def assert_sink(self, sink): self.assertTrue(sink.sink_dstream_cnt + sink.sink_ml_cnt == 1) def assert_sink_dstream(self, sink): self.assertEqual(sink.sink_dstream_cnt, 1) def assert_sink_ml(self, sink): self.assertEqual(sink.sink_ml_cnt, 1) def assert_tr(self, tr): self.assertEqual(tr.map_dstream_cnt, 1) self.assert_src_initialized(ml_mocks.ml_mocks.instantiated[ ""src_module1""][0]) self.assert_src_initialized(ml_mocks.ml_mocks.instantiated[ ""src_module2""][0]) self.assert_ingestor(ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]) self.assert_agg(ml_mocks.ml_mocks.instantiated[""aggr_module""][0]) ml_mocks.ml_mocks.instantiated[ ""aggr_module""][0].accumulate_dstream_samples( MockDStream(None, None, None)) self.assert_lrn(ml_mocks.ml_mocks.instantiated[""learner_module""][0]) self.assert_voter(ml_mocks.ml_mocks.instantiated[""voter_module""][0]) self.assert_tr(ml_mocks.ml_mocks.instantiated[ ""transformer_module1""][0]) self.assert_sink(ml_mocks.ml_mocks.instantiated[ ""sink_module2""][0]) self.assert_sink_dstream(ml_mocks.ml_mocks.instantiated[ ""sink_module2""][0])",,79,22
openstack%2Fmonasca-analytics~master~I2cb53d9447096e2c95e936b19c349970854000e8,openstack/monasca-analytics,master,I2cb53d9447096e2c95e936b19c349970854000e8,Fix a few bugs in connection and add implement 'propagate_features'.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:49:02.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/component/base.py', 'main/transformer/base_transformer.py', 'main/config/config.py', 'main/spark/driver.py', 'main/config/connection.py', 'main/machine_learning/base_learner.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/dc01429b9fb28f80ce9772d8c39f0ae69a44c828', 'message': ""Fix a few bugs in connection and add implement 'propagate_features'.\n\nChange-Id: I2cb53d9447096e2c95e936b19c349970854000e8\n""}]",0,313411,dc01429b9fb28f80ce9772d8c39f0ae69a44c828,3,1,1,21739,,,0,"Fix a few bugs in connection and add implement 'propagate_features'.

Change-Id: I2cb53d9447096e2c95e936b19c349970854000e8
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/11/313411/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/component/base.py', 'main/transformer/base_transformer.py', 'main/config/config.py', 'main/config/connection.py', 'main/spark/driver.py', 'main/machine_learning/base_learner.py']",6,dc01429b9fb28f80ce9772d8c39f0ae69a44c828,,," def __hash__(self): return hash(self._id) def __eq__(self, other): return self._id == other._id def __ne__(self, other): return not(self == other) def __str__(self): return self._id",53,32
openstack%2Fmonasca-analytics~master~I070137e3b5fb167cb4a5e29939092f94a0db3a1c,openstack/monasca-analytics,master,I070137e3b5fb167cb4a5e29939092f94a0db3a1c,Address comments for the PR#37.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:59.000000000,,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16222}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/aggregator/base_aggregator.py', 'test/mocks/aggregator.py', 'main/config/const.py', 'main/spark/driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/23b97a0f4af7661cd5221095ca8b5c7ebdcf7f61', 'message': 'Address comments for the PR#37.\n\nChange-Id: I070137e3b5fb167cb4a5e29939092f94a0db3a1c\n'}]",0,313410,23b97a0f4af7661cd5221095ca8b5c7ebdcf7f61,4,4,1,21739,,,0,"Address comments for the PR#37.

Change-Id: I070137e3b5fb167cb4a5e29939092f94a0db3a1c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/10/313410/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/aggregator/base_aggregator.py', 'main/config/const.py', 'test/mocks/aggregator.py', 'main/spark/driver.py']",4,23b97a0f4af7661cd5221095ca8b5c7ebdcf7f61,, connected_node.accumulate_dstream_samples(dstream), connected_node.accumulate_dstream(dstream),4,8
openstack%2Fmonasca-analytics~master~I1d6a1a77621445a3f3e84bce10c1f5d330b7f8c3,openstack/monasca-analytics,master,I1d6a1a77621445a3f3e84bce10c1f5d330b7f8c3,"removed arc_config, and fixed config_template to match the new config structure (separate connections and feedback connections from elements definitions",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:55.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/arc_config.json', 'config/config_template.json'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/512ec3129c3b6432e5b1ab461f27d49c80546954', 'message': 'removed arc_config, and fixed config_template to match the new config structure (separate connections and feedback connections from elements definitions\n\nChange-Id: I1d6a1a77621445a3f3e84bce10c1f5d330b7f8c3\n'}]",0,313414,512ec3129c3b6432e5b1ab461f27d49c80546954,3,1,1,21739,,,0,"removed arc_config, and fixed config_template to match the new config structure (separate connections and feedback connections from elements definitions

Change-Id: I1d6a1a77621445a3f3e84bce10c1f5d330b7f8c3
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/14/313414/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/arc_config.json', 'config/config_template.json']",2,512ec3129c3b6432e5b1ab461f27d49c80546954,," ""appName"": ""testApp"", ""streaming"": { ""batch_interval"": 1 ""server"": { ""port"": 3000, ""debug"": false ""sources"": { ""src1"": { ""module"": ""my_src_module"" ""ingestors"": { ""ing1"": { ""module"": ""my_ingestor_module"" ""aggregators"": { ""agg1"": { ""module"": ""my_aggregator_module"" ""lea1"": { ""module"": ""my_learner_module"" ""voters"": { ""vot1"": { ""module"": ""my_voter_module"" ""snk1"": { ""module"": ""my_sink_module"" } }, ""transformers"": { ""tra1"": { ""module"": ""my_transformer_module"" } }, ""connections"": { ""src1"": [""ing1"", ""tra1""], ""ing1"": [""agg1""], ""agg1"": [""lea1""], ""lea1"": [""vot1""], ""vot1"": [""tra1""], ""tra1"": [""snk1""] }, ""feedback"": {}"," ""appName"": ""my_name"", ""streaming"": { ""batch_interval"": 1 # In seconds }, ""server"": { ""port"": 3000, ""debug"": true ""data_models"": { ""mod1"": { ""module"": ""model1"" } ""data_sources"": { ""src1"": { ""module"": ""my_data_src"", ""params"": {} ""data_ingestors"": { ""ing1"": { ""module"": ""my_data_ingestor"", ""sinks_ids"": [""sin1""], # Optional ""providers_ids"": [""src1""] # Optional ""aggregator"": { ""agg1"": { ""module"": ""my_data_aggregator"", ""sinks_ids"": [""sin1""], # Optional ""lrn1"": { ""module"": ""my_learner"", ""sinks_ids"": [""sin1""], # Optional ""voter"": { ""vot1"": { ""module"": ""my_voter"", ""sinks_ids"": [""sin1""], # Optional ""sin1"": { ""module"": ""sink_module1"" ""learners_ids"": [""lrn1""] # Optional ""voter_id"": ""vot1"" # Optional } }",32,61
openstack%2Fmonasca-analytics~master~I2f86e55795c42c616d3ad1bae0e2c23857e272bc,openstack/monasca-analytics,master,I2f86e55795c42c616d3ad1bae0e2c23857e272bc,"Refactor data_ingest{or,ion} and associated terms to ingestor.",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:50.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/ingestors.py', 'test/config/test_create_components.py', 'main/exception/ingestor_error.py', 'main/exception/ml_framework_error.py', 'main/spark/driver.py', 'test/ingestor/test_base_ingestor.py', 'test/util/test_common_util.py', 'test/source/test_base_source.py', 'main/ingestor/__init__.py', 'test/ingestor/__init__.py', 'test/mocks/ml_mocks.py', 'main/ingestor/base.py', 'main/config/creation.py', 'main/ingestor/cloud.py', 'main/util/common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/57236a474478faa54fbf62237ee211a792d158ee', 'message': 'Refactor data_ingest{or,ion} and associated terms to ingestor.\n\nChange-Id: I2f86e55795c42c616d3ad1bae0e2c23857e272bc\n'}]",0,313415,57236a474478faa54fbf62237ee211a792d158ee,3,2,1,21739,,,0,"Refactor data_ingest{or,ion} and associated terms to ingestor.

Change-Id: I2f86e55795c42c616d3ad1bae0e2c23857e272bc
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/15/313415/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/ingestors.py', 'test/config/test_create_components.py', 'main/exception/ingestor_error.py', 'main/exception/ml_framework_error.py', 'main/spark/driver.py', 'test/ingestor/test_base_ingestor.py', 'test/util/test_common_util.py', 'test/source/test_base_source.py', 'main/ingestor/__init__.py', 'test/ingestor/__init__.py', 'test/mocks/ml_mocks.py', 'main/ingestor/base.py', 'main/config/creation.py', 'main/ingestor/cloud.py', 'main/util/common_util.py']",15,57236a474478faa54fbf62237ee211a792d158ee,,"from main import ingestor from main.ingestor.base import BaseIngestor get_available_inherited_classes(ingestor, BaseIngestor) (e.g. data_sources, ingestors, etc.). @raise MlfNoSuchIngestorError: If no source class found. @raise MlfDuplicateIngestorError: If the system has multipledef get_ingestor_class_by_name(class_name): Gets the ingestor class by class name. @param class_name: Name of the ingestor class requested. @raise MlfNoSuchIngestorError: If no ingestor class found. @raise MlfDuplicateIngestorError: If the system has multiple ingestors of the same class name.def get_available_ingestor_class_names(): Gets available ingestor class names. @return: list: A list of available ingestor class names. @raise MlfNoSuchIngestorError: If no data_aggregator class found. @raise MlfDuplicateIngestorError: If the system has multiple @raise MlfNoSuchIngestorError: If no machine_learning class found. @raise MlfDuplicateIngestorError: If the system has multiple @raise MlfNoSuchIngestorError: If no voter class found. @raise MlfDuplicateIngestorError: If the system has multiple","from main import data_ingestion from main.data_ingestion.base_data_ingestor \ import BaseDataIngestor get_available_inherited_classes(data_ingestion, BaseDataIngestor) (e.g. data_sources, data_ingestors, etc.). @raise MlfNoSuchDataIngestorError: If no source class found. @raise MlfDuplicateDataIngestorError: If the system has multipledef get_data_ingestor_class_by_name(class_name): Gets the data_ingestor class by class name. @param class_name: Name of the data_ingestor class requested. @raise MlfNoSuchDataIngestorError: If no data_ingestor class found. @raise MlfDuplicateDataIngestorError: If the system has multiple data_ingestors of the same class name.def get_available_data_ingestor_class_names(): Gets available data_ingestor class names. @return: list: A list of available data_ingestor class names. @raise MlfNoSuchDataIngestorError: If no data_aggregator class found. @raise MlfDuplicateDataIngestorError: If the system has multiple @raise MlfNoSuchDataIngestorError: If no machine_learning class found. @raise MlfDuplicateDataIngestorError: If the system has multiple @raise MlfNoSuchDataIngestorError: If no voter class found. @raise MlfDuplicateDataIngestorError: If the system has multiple",79,55
openstack%2Fmonasca-analytics~master~I049dc3c374ff72c64e3207aeac5a67f4b092e615,openstack/monasca-analytics,master,I049dc3c374ff72c64e3207aeac5a67f4b092e615,"Refactor data_aggregator->aggregator, base_{x}->{x}, ml_framework->monanas, machine_learning->ml",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:46.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/ml/test_lingam.py', 'main/transformer/monasca/base.py', 'test/source/test_markov_chain.py', 'main/spark/driver.py', 'setup.py', 'main/ml/__init__.py', 'test/voter/test_base_voter.py', 'test/source/test_base.py', 'main/exception/ml.py', 'main/config/config.py', 'main/exception/aggregator.py', 'main/source/random.py', 'test/aggregator/__init__.py', 'main/exception/ingestor.py', 'main/exception/data_aggregator_error.py', 'test/source/test_kafka.py', 'main/web_service/request_handler.py', 'main/aggregator/concatenation.py', 'main/util/common_util.py', 'main/exception/sink.py', 'test/spark/test_driver.py', 'main/source/base.py', 'test/sink/dstream_sink/__init__.py', 'main/ml/base.py', 'main/ml_framework.py', 'main/voter/pick_index.py', 'test/config/test_create_components.py', 'test/aggregator/test_concatenation.py', 'main/source/cloud_markov_chain.py', 'test/sink/test_kafka.py', 'main/aggregator/base.py', 'main/transformer/monasca_transformer/base_transformer.py', 'main/source/kafka.py', 'test/test_monanas.py', 'test/ingestor/test_base.py', 'test/mocks/ml_mocks.py', 'main/config/creation.py', 'main/source/markov_chain/base.py', 'main/sink/base.py', 'main/exception/source_error.py', 'main/exception/mlf.py', 'test/machine_learning/__init__.py', 'test/aggregator/test_base.py', 'main/transformer/base.py', 'test/mocks/sources.py', 'main/transformer/cloud_causality.py', 'main/exception/ml_framework_error.py', 'run.py', 'test/mocks/aggregator.py', 'main/source/file.py', 'test/util/test_common_util.py', 'test/ml/__init__.py', 'main/source/monasca_markov_chain.py', 'main/exception/machine_learning_error.py', 'main/sink/kafka.py', 'main/monanas.py', 'main/voter/base.py', 'main/transformer/monasca/__init__.py', 'main/exception/source.py', 'main/ml/lingam.py', 'main/web_service/web_service.py', 'test/sink/test_sink_config_validator.py', 'test/source/test_file.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/4f9b18fcd9aa403fc42c554ee62ee8b78f72cc35', 'message': 'Refactor data_aggregator->aggregator, base_{x}->{x}, ml_framework->monanas, machine_learning->ml\n\nChange-Id: I049dc3c374ff72c64e3207aeac5a67f4b092e615\n'}]",0,313416,4f9b18fcd9aa403fc42c554ee62ee8b78f72cc35,3,2,1,21739,,,0,"Refactor data_aggregator->aggregator, base_{x}->{x}, ml_framework->monanas, machine_learning->ml

Change-Id: I049dc3c374ff72c64e3207aeac5a67f4b092e615
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/16/313416/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/ml/test_lingam.py', 'main/transformer/monasca/base.py', 'test/source/test_markov_chain.py', 'main/spark/driver.py', 'setup.py', 'main/ml/__init__.py', 'test/voter/test_base_voter.py', 'test/source/test_base.py', 'main/exception/ml.py', 'main/config/config.py', 'main/exception/aggregator.py', 'main/source/random.py', 'test/aggregator/__init__.py', 'main/exception/ingestor.py', 'main/exception/data_aggregator_error.py', 'test/source/test_kafka.py', 'main/web_service/request_handler.py', 'main/aggregator/concatenation.py', 'main/util/common_util.py', 'main/exception/sink.py', 'test/spark/test_driver.py', 'main/source/base.py', 'test/sink/dstream_sink/__init__.py', 'main/ml/base.py', 'main/ml_framework.py', 'main/voter/pick_index.py', 'test/config/test_create_components.py', 'test/aggregator/test_concatenation.py', 'main/source/cloud_markov_chain.py', 'test/sink/test_kafka.py', 'main/aggregator/base.py', 'main/transformer/monasca_transformer/base_transformer.py', 'main/source/kafka.py', 'test/test_monanas.py', 'test/ingestor/test_base.py', 'test/mocks/ml_mocks.py', 'main/config/creation.py', 'main/source/markov_chain/base.py', 'main/sink/base.py', 'main/exception/source_error.py', 'main/exception/mlf.py', 'test/machine_learning/__init__.py', 'test/aggregator/test_base.py', 'main/transformer/base.py', 'test/mocks/sources.py', 'main/transformer/cloud_causality.py', 'main/exception/ml_framework_error.py', 'run.py', 'test/mocks/aggregator.py', 'main/source/file.py', 'test/util/test_common_util.py', 'test/ml/__init__.py', 'main/source/monasca_markov_chain.py', 'main/exception/machine_learning_error.py', 'main/sink/kafka.py', 'main/monanas.py', 'main/voter/base.py', 'main/transformer/monasca/__init__.py', 'main/exception/source.py', 'main/ml/lingam.py', 'main/web_service/web_service.py', 'test/sink/test_sink_config_validator.py', 'test/source/test_file.py']",63,4f9b18fcd9aa403fc42c554ee62ee8b78f72cc35,,"from main.source.file import FileSource ""module"": ""file"", ""module"": ""file"", self.config_missing_params = {""module"": ""file""}","from main.source.file_source import FileSource ""module"": ""file_source"", ""module"": ""file_source"", self.config_missing_params = {""module"": ""file_source""}",574,524
openstack%2Fmonasca-analytics~master~I75825ebbb44a23b192524d81797f292f0ae1d368,openstack/monasca-analytics,master,I75825ebbb44a23b192524d81797f292f0ae1d368,Fix a bug: Producer was always None.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/kafkas.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/16adbc891abb9b1449c827c51ab28025ec010cf6', 'message': 'Fix a bug: Producer was always None.\n\nChange-Id: I75825ebbb44a23b192524d81797f292f0ae1d368\n'}]",0,313418,16adbc891abb9b1449c827c51ab28025ec010cf6,3,1,1,21739,,,0,"Fix a bug: Producer was always None.

Change-Id: I75825ebbb44a23b192524d81797f292f0ae1d368
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/18/313418/1 && git format-patch -1 --stdout FETCH_HEAD,['main/sink/kafkas.py'],1,16adbc891abb9b1449c827c51ab28025ec010cf6,," super(KafkaSink, self).__init__(_id, _config)"," super(KafkaSink, self).__init__(_id, _config)",1,1
openstack%2Fmonasca-analytics~master~I0ed20148f213578cad9dbec61c19e06040f7a16a,openstack/monasca-analytics,master,I0ed20148f213578cad9dbec61c19e06040f7a16a,Fix feature propagation and voter. This was causing problem with the ingestor.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:39.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/voter/pick_index.py', 'main/ingestor/base.py', 'main/spark/driver.py', 'main/ingestor/cloud.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/a972ed601973fea0494e4e59a8483c1863e027c7', 'message': 'Fix feature propagation and voter. This was causing problem with the ingestor.\n\nChange-Id: I0ed20148f213578cad9dbec61c19e06040f7a16a\n'}]",0,313420,a972ed601973fea0494e4e59a8483c1863e027c7,3,1,1,21739,,,0,"Fix feature propagation and voter. This was causing problem with the ingestor.

Change-Id: I0ed20148f213578cad9dbec61c19e06040f7a16a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/20/313420/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/voter/pick_index.py', 'main/ingestor/base.py', 'main/ingestor/cloud.py', 'main/spark/driver.py']",4,a972ed601973fea0494e4e59a8483c1863e027c7,," propagated = False if isinstance(connected_node, bi.BaseIngestor): connected_node.set_feature_list(features) propagated = True propagated = True if propagated:",,28,7
openstack%2Fmonasca-analytics~master~I8ff50099d2e5c02484b61b041caf92471151c867,openstack/monasca-analytics,master,I8ff50099d2e5c02484b61b041caf92471151c867,"Refactor learner->sml, transformer->ldp.",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:34.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/config/test_create_components.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'main/transformer/monasca/base.py', 'main/spark/driver.py', 'setup.py', 'main/aggregator/base.py', 'test/voter/test_base_voter.py', 'test/test_monanas.py', 'test/mocks/sml_mocks.py', 'main/ldp/__init__.py', 'main/ldp/monasca/__init__.py', 'main/transformer/__init__.py', 'main/exception/mlf.py', 'main/ldp/monasca/base.py', 'test/aggregator/test_base.py', 'main/source/random.py', 'test/sml/__init__.py', 'config/markov_source_config.json', 'main/ldp/base.py', 'test/util/test_common_util.py', 'test/sml/test_lingam.py', 'main/ldp/cloud_causality.py', 'main/web_service/request_handler.py', 'config/config_template.json', 'main/config/const.py', 'main/sml/base.py', 'main/voter/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/sml/lingam.py', 'main/util/common_util.py', 'main/sml/__init__.py', 'main/web_service/web_service.py', 'test/spark/test_driver.py', 'main/source/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/5578083a1e38c9524d989dd28c37c12708b10041', 'message': 'Refactor learner->sml, transformer->ldp.\n\nChange-Id: I8ff50099d2e5c02484b61b041caf92471151c867\n'}]",0,313421,5578083a1e38c9524d989dd28c37c12708b10041,3,2,1,21739,,,0,"Refactor learner->sml, transformer->ldp.

Change-Id: I8ff50099d2e5c02484b61b041caf92471151c867
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/21/313421/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/config/test_create_components.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'main/transformer/monasca/base.py', 'main/spark/driver.py', 'setup.py', 'main/aggregator/base.py', 'test/voter/test_base_voter.py', 'test/test_monanas.py', 'test/mocks/sml_mocks.py', 'main/ldp/__init__.py', 'main/ldp/monasca/__init__.py', 'main/transformer/__init__.py', 'main/exception/mlf.py', 'main/ldp/monasca/base.py', 'test/aggregator/test_base.py', 'main/source/random.py', 'test/sml/__init__.py', 'config/markov_source_config.json', 'main/ldp/base.py', 'test/util/test_common_util.py', 'test/sml/test_lingam.py', 'main/ldp/cloud_causality.py', 'main/web_service/request_handler.py', 'config/config_template.json', 'main/config/const.py', 'main/sml/base.py', 'main/voter/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/sml/lingam.py', 'main/util/common_util.py', 'main/sml/__init__.py', 'main/web_service/web_service.py', 'test/spark/test_driver.py', 'main/source/base.py']",36,5578083a1e38c9524d989dd28c37c12708b10041,, Create a dstream to be consumed by Monanas. @return: Returns a Spark dstream to be consumed by Monanas., Create a dstream to be consumed by the framework. @return: Returns a Spark dstream to be consumed by the framework.,318,320
openstack%2Fmonasca-analytics~master~I8f50100876947cc48e80f16fbacc3241da53b148,openstack/monasca-analytics,master,I8f50100876947cc48e80f16fbacc3241da53b148,Move aggregator logic into a unified Orchestrator.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/aggregator/__init__.py', 'main/pipeline/executor.py', 'config/markov_source_config.json', 'test/aggregator/test_concatenation.py', 'test/spark/test_aggregator.py', 'main/spark/driver.py', 'main/spark/aggregator.py', 'config/config_template.json', 'main/config/const.py', 'main/source/markov_chain/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/aggregator/concatenation.py', 'main/util/common_util.py', 'main/pipeline/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/396e3f7445d85889be9ad09d734a90e41f69f164', 'message': 'Move aggregator logic into a unified Orchestrator.\n\nChange-Id: I8f50100876947cc48e80f16fbacc3241da53b148\n'}]",0,313422,396e3f7445d85889be9ad09d734a90e41f69f164,3,1,1,21739,,,0,"Move aggregator logic into a unified Orchestrator.

Change-Id: I8f50100876947cc48e80f16fbacc3241da53b148
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/22/313422/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/aggregator/__init__.py', 'main/pipeline/executor.py', 'config/markov_source_config.json', 'test/aggregator/test_concatenation.py', 'test/spark/test_aggregator.py', 'main/spark/driver.py', 'main/spark/aggregator.py', 'config/config_template.json', 'main/config/const.py', 'main/source/markov_chain/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/aggregator/concatenation.py', 'main/util/common_util.py', 'main/pipeline/__init__.py']",15,396e3f7445d85889be9ad09d734a90e41f69f164,,,,146,216
openstack%2Fmonasca-analytics~master~I061f7906c38cd6e09c65e55d99e8c6713467c9d9,openstack/monasca-analytics,master,I061f7906c38cd6e09c65e55d99e8c6713467c9d9,Fix bug with cloud where a feature was present twice.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:26.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ingestor/cloud.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/7de512e129dd0b6b7654544d73fa120623a8ac9d', 'message': 'Fix bug with cloud where a feature was present twice.\n\nChange-Id: I061f7906c38cd6e09c65e55d99e8c6713467c9d9\n'}]",0,313423,7de512e129dd0b6b7654544d73fa120623a8ac9d,3,1,1,21739,,,0,"Fix bug with cloud where a feature was present twice.

Change-Id: I061f7906c38cd6e09c65e55d99e8c6713467c9d9
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/23/313423/1 && git format-patch -1 --stdout FETCH_HEAD,['main/ingestor/cloud.py'],1,7de512e129dd0b6b7654544d73fa120623a8ac9d,,," logger.info(""Cloud Ingestor: map stream"") res.append(values[""support_1""])",0,2
openstack%2Fmonasca-analytics~master~If33d81f8bcd8718ef4ba5e2dc6a5e4ab2708768b,openstack/monasca-analytics,master,If33d81f8bcd8718ef4ba5e2dc6a5e4ab2708768b,Fix tests.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/config/test_create_components.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'test/mocks/aggregator.py', 'test/spark/test_aggregator.py', 'main/spark/driver.py', 'test/util/test_common_util.py', 'test/test_monanas.py', 'test/ingestor/test_base.py', 'test/mocks/sml_mocks.py', 'main/config/validation.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ba0c4bd4b1670f5ddbd8a7ab432a7c90cf26a41f', 'message': 'Fix tests.\n\nChange-Id: If33d81f8bcd8718ef4ba5e2dc6a5e4ab2708768b\n'}]",0,313425,ba0c4bd4b1670f5ddbd8a7ab432a7c90cf26a41f,3,1,1,21739,,,0,"Fix tests.

Change-Id: If33d81f8bcd8718ef4ba5e2dc6a5e4ab2708768b
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/25/313425/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/config/test_create_components.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'test/mocks/aggregator.py', 'test/spark/test_aggregator.py', 'main/spark/driver.py', 'test/util/test_common_util.py', 'test/test_monanas.py', 'test/ingestor/test_base.py', 'test/mocks/sml_mocks.py', 'main/config/validation.py', 'test/spark/test_driver.py']",12,ba0c4bd4b1670f5ddbd8a7ab432a7c90cf26a41f,," self.original_Aggregator = driver.agg.Aggregator driver.agg.Aggregator = self.original_Aggregator driver.agg.Aggregator = sml_mocks.MockClass_aggr_module self.assertEqual(8, len(sml_mocks.sml_mocks.classes_got_by_name)) self.assertEqual(sink.sink_dstream_cnt + sink.sink_sml_cnt, 1) self.assert_agg(self.mlf._orchestrator) self.mlf._orchestrator.accumulate_dstream_samples( self.mlf._orchestrator.prepare_final_accumulate_stream_step() ""sink_module1""][0]) self.assert_sink_ml(sml_mocks.sml_mocks.instantiated[ ""sink_module1""][0]) def test_phase2(self): self.mlf.start_pipeline() self.assert_ldp(sml_mocks.sml_mocks.instantiated[ ""ldp_module1""][0]) self.assert_sink(sml_mocks.sml_mocks.instantiated[ ""sink_module2""][0]) self.assert_sink_dstream(sml_mocks.sml_mocks.instantiated[ ""sink_module2""][0])"," self.assertEqual(9, len(sml_mocks.sml_mocks.classes_got_by_name)) self.assertIn([""aggr_module"", mod.AGGREGATORS], sml_mocks.sml_mocks.classes_got_by_name) self.assertTrue(sink.sink_dstream_cnt + sink.sink_sml_cnt == 1) self.assert_agg(sml_mocks.sml_mocks.instantiated[""aggr_module""][0]) sml_mocks.sml_mocks.instantiated[ ""aggr_module""][0].accumulate_dstream_samples( self.assert_ldp(sml_mocks.sml_mocks.instantiated[ ""ldp_module1""][0]) ""sink_module2""][0]) self.assert_sink_dstream(sml_mocks.sml_mocks.instantiated[ ""sink_module2""][0])",49,62
openstack%2Fmonasca-analytics~master~Iaa50a61139f7249a22c8b00aad9851cbab429d10,openstack/monasca-analytics,master,Iaa50a61139f7249a22c8b00aad9851cbab429d10,Fix test and activate phase 2 when learning is done.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:17.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/sml_mocks.py', 'test/spark/test_aggregator.py', 'main/spark/driver.py', 'main/config/validation.py', 'main/sml/lingam.py', 'test/spark/test_driver.py', 'main/spark/aggregator.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3f6591fe47d049f82b99812bce40f92ec8b9aeb0', 'message': 'Fix test and activate phase 2 when learning is done.\n\nChange-Id: Iaa50a61139f7249a22c8b00aad9851cbab429d10\n'}]",0,313426,3f6591fe47d049f82b99812bce40f92ec8b9aeb0,3,1,1,21739,,,0,"Fix test and activate phase 2 when learning is done.

Change-Id: Iaa50a61139f7249a22c8b00aad9851cbab429d10
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/26/313426/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/sml_mocks.py', 'test/spark/test_aggregator.py', 'main/config/validation.py', 'main/spark/driver.py', 'main/sml/lingam.py', 'test/spark/test_driver.py', 'main/spark/aggregator.py']",7,3f6591fe47d049f82b99812bce40f92ec8b9aeb0,," def __init__(self, driver): @param driver: The driver that manage spark @type driver: main.spark.driver.DriverExecutor self._driver = driver if len(self._smls) == 0: self._driver.move_to_phase2()", def __init__(self):,45,15
openstack%2Fmonasca-analytics~master~I454a4d94f7675017524a42449887db1865637751,openstack/monasca-analytics,master,I454a4d94f7675017524a42449887db1865637751,Fix bug for phase2 and when no ingestor are present.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:48:11.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/markov_chain/base.py', 'main/spark/driver.py', 'main/spark/aggregator.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/53b72671cc78e7c4c75fd291a77238de2c001b3f', 'message': 'Fix bug for phase2 and when no ingestor are present.\n\nChange-Id: I454a4d94f7675017524a42449887db1865637751\n'}]",0,313430,53b72671cc78e7c4c75fd291a77238de2c001b3f,3,1,1,21739,,,0,"Fix bug for phase2 and when no ingestor are present.

Change-Id: I454a4d94f7675017524a42449887db1865637751
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/30/313430/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/markov_chain/base.py', 'main/spark/driver.py', 'main/spark/aggregator.py']",3,53b72671cc78e7c4c75fd291a77238de2c001b3f,," if self._combined_stream is not None: self._combined_stream.foreachRDD(lambda _, rdd: self._processRDD(rdd))"," self._combined_stream.foreachRDD(lambda _, rdd: self._processRDD(rdd))",13,5
openstack%2Fmonasca-analytics~master~I1f3fcde9024ab55a9480a408314c16bdabac5d7f,openstack/monasca-analytics,master,I1f3fcde9024ab55a9480a408314c16bdabac5d7f,Initial commit,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:47:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e1ea01687927471df7a1dbcf697b8d8a3a9b8d47', 'message': 'Initial commit\n\nChange-Id: I1f3fcde9024ab55a9480a408314c16bdabac5d7f\n'}]",0,313318,e1ea01687927471df7a1dbcf697b8d8a3a9b8d47,3,1,1,21739,,,0,"Initial commit

Change-Id: I1f3fcde9024ab55a9480a408314c16bdabac5d7f
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/18/313318/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,e1ea01687927471df7a1dbcf697b8d8a3a9b8d47,,# arc-alc-design Arc and Alert Cruncher project design repo ,,2,0
openstack%2Fpython-brick-cinderclient-ext~master~Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8,openstack/python-brick-cinderclient-ext,master,Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8,Introduce functional tests for python-brick-cinderclient-ext,MERGED,2016-01-11 13:02:32.000000000,2016-05-11 16:46:37.000000000,2016-05-11 16:46:37.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 7173}, {'_account_id': 10213}, {'_account_id': 11904}, {'_account_id': 16708}]","[{'number': 1, 'created': '2016-01-11 13:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/5c6989253d6733a908e8ffbc70c0907a18f8dcfe', 'message': ""Introduce functional tests for python-brick-cinderclient-ext\n\nThis patch adds new tox environment to run functional tests:\n    $ tox -e functional\n\nAll unit tests moved to 'unit' directory.\n\nChange-Id: Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8\n""}, {'number': 2, 'created': '2016-01-11 17:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/d2a5fa37a992a3110c20780885e4f84675cd79ae', 'message': ""Introduce functional tests for python-brick-cinderclient-ext\n\nThis patch adds new tox environment to run functional tests:\n    $ tox -e functional\n\nIt also adds 'post_test_hook.sh' script to run functional tests on\ngates.\n\nAll unit tests moved to 'unit' directory.\n\nChange-Id: Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8\n""}, {'number': 3, 'created': '2016-02-05 18:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/709150f96ca943f9bfb0e0b84b6c092087ffa217', 'message': ""Introduce functional tests for python-brick-cinderclient-ext\n\nThis patch adds new tox environment to run functional tests:\n    $ tox -e functional\n\nIt also adds 'post_test_hook.sh' script to run functional tests on\ngates.\n\nAll unit tests moved to 'unit' directory.\n\nChange-Id: Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8\n""}, {'number': 4, 'created': '2016-03-14 15:36:41.000000000', 'files': ['brick_cinderclient_ext/tests/functional/hooks/post_test_hook.sh', 'brick_cinderclient_ext/tests/functional/test_brick_client.py', 'brick_cinderclient_ext/tests/functional/__init__.py', '.testr.conf', 'brick_cinderclient_ext/tests/unit/test_brick_client.py', 'brick_cinderclient_ext/tests/unit/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/896f044d19d4cd69f8ae6b3f300930d99dd4c02d', 'message': ""Introduce functional tests for python-brick-cinderclient-ext\n\nThis patch adds new tox environment to run functional tests:\n    $ tox -e functional\n\nIt also adds 'post_test_hook.sh' script to run functional tests on\ngates.\n\nAll unit tests moved to 'unit' directory.\n\nChange-Id: Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8\n""}]",11,265811,896f044d19d4cd69f8ae6b3f300930d99dd4c02d,22,7,4,1736,,,0,"Introduce functional tests for python-brick-cinderclient-ext

This patch adds new tox environment to run functional tests:
    $ tox -e functional

It also adds 'post_test_hook.sh' script to run functional tests on
gates.

All unit tests moved to 'unit' directory.

Change-Id: Iac2f4c6d9d77e96d2478aa00632aad33fa6a22d8
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/11/265811/4 && git format-patch -1 --stdout FETCH_HEAD,"['brick_cinderclient_ext/tests/functional/test_brick_client.py', 'brick_cinderclient_ext/tests/functional/__init__.py', '.testr.conf', 'brick_cinderclient_ext/tests/unit/test_brick_client.py', 'brick_cinderclient_ext/tests/unit/__init__.py', 'tox.ini']",6,5c6989253d6733a908e8ffbc70c0907a18f8dcfe,,"install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} passenv = *_proxy *_PROXY deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = find . -type f -name ""*.pyc"" -delete python setup.py testr --testr-args='{posargs}' whitelist_externals = find[testenv:functional] setenv = OS_TEST_PATH=./brick_cinderclient_ext/tests/functional passenv = OS_* ",usedevelop = True install_command = constraints: {[testenv:common-constraints]install_command} pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} deps = -r{toxinidir}/test-requirements.txt commands = python setup.py test --slowest --testr-args='{posargs}',89,9
openstack%2Fsearchlight~master~I111ab809b949b12f0a83c85896cc146d972d4ac3,openstack/searchlight,master,I111ab809b949b12f0a83c85896cc146d972d4ac3,Hypervisor plugin,MERGED,2016-03-25 09:06:28.000000000,2016-05-11 16:45:09.000000000,2016-05-11 16:45:08.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 7665}, {'_account_id': 10063}]","[{'number': 1, 'created': '2016-03-25 09:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/ac5686cb9f42383d94a34c5c91fbffb1da8175c7', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 2, 'created': '2016-03-28 01:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/9049634ea14a9a233b03f495ec20202bdae9bb4f', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 3, 'created': '2016-04-07 02:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/b8b7ceba512f1959112405f6df26437502286b4f', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 4, 'created': '2016-04-12 06:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/f50eec63c8930deade9ba6524c7f5a2091086d30', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 5, 'created': '2016-04-13 02:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/bc8d7842af8ba7e3c16f2deae0195032fa66be41', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 6, 'created': '2016-04-13 03:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/7e9b9e32086a279f54a8ff3e2db9d9801bc36b54', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 7, 'created': '2016-05-05 01:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/6e32b36cefd246e17f06335c7eb90a54d1113ed3', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}, {'number': 8, 'created': '2016-05-09 01:22:01.000000000', 'files': ['doc/source/plugins.rst', 'searchlight/tests/unit/v1/test_search.py', 'devstack/local.conf', 'searchlight/elasticsearch/plugins/nova/hypervisors.py', 'releasenotes/notes/bp-hypervisor-plugin-5d17ed1005004b43.yaml', 'searchlight/elasticsearch/plugins/nova/servers.py', 'searchlight/elasticsearch/plugins/nova/notification_handler.py', 'searchlight/tests/functional/data/load/hypervisors.json', 'searchlight/tests/functional/__init__.py', 'searchlight/tests/functional/test_nova_plugin.py', 'searchlight/tests/unit/test_nova_hypervisor_plugin.py', 'setup.cfg', 'doc/source/plugins/nova.rst', 'searchlight/elasticsearch/plugins/nova/__init__.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/730f9f14ebd53386e26373de26dec8893078c651', 'message': 'Hypervisor plugin\n\nThis patch adds support for index hypervisor for nova without\nnotifications.\n\nImplement blueprint: hypervisor-plugin\n\nChange-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3\n'}]",53,297586,730f9f14ebd53386e26373de26dec8893078c651,35,4,8,4428,,,0,"Hypervisor plugin

This patch adds support for index hypervisor for nova without
notifications.

Implement blueprint: hypervisor-plugin

Change-Id: I111ab809b949b12f0a83c85896cc146d972d4ac3
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/86/297586/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/plugins.rst', 'searchlight/tests/unit/v1/test_search.py', 'searchlight/elasticsearch/plugins/nova/hypervisors.py', 'releasenotes/notes/bp-hypervisor-plugin-5d17ed1005004b43.yaml', 'searchlight/elasticsearch/plugins/nova/servers.py', 'searchlight/elasticsearch/plugins/nova/notification_handler.py', 'searchlight/tests/functional/data/load/hypervisors.json', 'searchlight/tests/functional/__init__.py', 'searchlight/tests/functional/test_nova_plugin.py', 'searchlight/tests/unit/test_nova_hypervisor_plugin.py', 'setup.cfg', 'doc/source/plugins/nova.rst', 'searchlight/elasticsearch/plugins/nova/__init__.py', 'etc/policy.json']",14,ac5686cb9f42383d94a34c5c91fbffb1da8175c7,bp/hypervisor-plugin," ""resource:OS::Nova::Hypervisor:allow"": ""role:admin"",",,376,5
openstack%2Fmonasca-analytics~master~I1f38d5b8796b9f5624b40ea96d881c650b01c090,openstack/monasca-analytics,master,I1f38d5b8796b9f5624b40ea96d881c650b01c090,initial commit with packages structure and some code from alert cruncher,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:44:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1861}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/machine_learning_manager/__init__.py', 'main/source_manager/source/__init__.py', 'main/util/singleton.py', 'setup.py', 'config/config.json', 'main/exception/data_ingestor_error.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py', 'main/voter_manager/__init__.py', 'main/exception/data_aggregator_error.py', 'main/sink_manager/sink/__init__.py', 'main/sink_manager/__init__.py', 'main/source_manager/source/kafka_source.py', 'README.md', 'main/util/__init__.py', 'main/data_aggregation_manager/__init__.py', 'main/web_service/request_handler.py', 'main/util/common_util.py', 'main/util/config_model.py', 'main/machine_learning_manager/machine_learning/__init__.py', 'main/voter_manager/voter/__init__.py', 'main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', '.gitignore', 'main/util/util.py', 'config/logging.json', 'main/exception/sink_error.py', 'main/__init__.py', 'main/voter_manager/voter/base_voter.py', 'setup_property.py', 'main/data_buffer_stream/__init__.py', 'Vagrantfile', 'main/exception/source_error.py', 'main/web_service/__init__.py', 'main/data_ingestion_manager/data_ingestion/__init__.py', '__init__.py', 'config/default_source_config.json', 'main/exception/__init__.py', 'main/util/source_config_model.py', 'main/source_manager/source/base_source.py', 'main/data_ingestion_manager/__init__.py', 'main/source_manager/source/random_source.py', 'main/exception/ml_framework_error.py', 'run.py', 'main/source_manager/source_model.py', 'main/exception/machine_learning_error.py', 'fetch-deps.sh', 'main/data_aggregation_manager/data_agregator/__init__.py', 'main/web_service/web_service_model.py', 'main/source_manager/__init__.py', 'main/web_service/web_service.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/d1f773f56cac2dbf4b8ce8f300804d8e4403d279', 'message': 'initial commit with packages structure and some code from alert cruncher\n\nChange-Id: I1f38d5b8796b9f5624b40ea96d881c650b01c090\n'}]",0,313319,d1f773f56cac2dbf4b8ce8f300804d8e4403d279,3,2,1,21739,,,0,"initial commit with packages structure and some code from alert cruncher

Change-Id: I1f38d5b8796b9f5624b40ea96d881c650b01c090
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/19/313319/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/machine_learning_manager/__init__.py', 'main/source_manager/source/__init__.py', 'main/util/singleton.py', 'setup.py', 'config/config.json', 'main/exception/data_ingestor_error.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py', 'main/voter_manager/__init__.py', 'main/exception/data_aggregator_error.py', 'main/sink_manager/sink/__init__.py', 'main/sink_manager/__init__.py', 'main/source_manager/source/kafka_source.py', 'README.md', 'main/util/__init__.py', 'main/data_aggregation_manager/__init__.py', 'main/web_service/request_handler.py', 'main/util/common_util.py', 'main/util/config_model.py', 'main/machine_learning_manager/machine_learning/__init__.py', 'main/voter_manager/voter/__init__.py', 'main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', '.gitignore', 'main/util/util.py', 'config/logging.json', 'main/exception/sink_error.py', 'main/__init__.py', 'main/voter_manager/voter/base_voter.py', 'setup_property.py', 'main/data_buffer_stream/__init__.py', 'Vagrantfile', 'main/exception/source_error.py', 'main/web_service/__init__.py', 'main/data_ingestion_manager/data_ingestion/__init__.py', '__init__.py', 'config/default_source_config.json', 'main/exception/__init__.py', 'main/util/source_config_model.py', 'main/source_manager/source/base_source.py', 'main/data_ingestion_manager/__init__.py', 'main/source_manager/source/random_source.py', 'main/exception/ml_framework_error.py', 'run.py', 'main/source_manager/source_model.py', 'main/exception/machine_learning_error.py', 'fetch-deps.sh', 'main/data_aggregation_manager/data_agregator/__init__.py', 'main/web_service/web_service_model.py', 'main/source_manager/__init__.py', 'main/web_service/web_service.py']",50,d1f773f56cac2dbf4b8ce8f300804d8e4403d279,,"#!/usr/bin/env python from main.web_service.request_handler import AlertCruncherHandler from tornado.web import Application class WebService(Application): """"""WebService serving REST API for Alert Cruncher."""""" def __init__(self, alert_cruncher, config): """"""WebService constructor."""""" self._alert_cruncher = alert_cruncher self._config = config handlers = [ (r""/"", AlertCruncherHandler, {""alert_cruncher"": self._alert_cruncher}) ] settings = {} Application.__init__(self, handlers, debug=config[""debug""], **settings)",,1519,2
openstack%2Fmonasca-analytics~master~Ic921eeb2fdc22faf6bf747bedb99787c7be890a2,openstack/monasca-analytics,master,Ic921eeb2fdc22faf6bf747bedb99787c7be890a2,pep8 compilant,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1861}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'main/util/source_config_model.py', 'main/util/util.py', 'main/source_manager/source/base_source.py', 'main/source_manager/source/random_source.py', 'main/util/singleton.py', 'main/exception/ml_framework_error.py', 'run.py', 'main/source_manager/source_model.py', 'setup.py', 'main/source_manager/source/kafka_source.py', 'main/voter_manager/voter/base_voter.py', 'setup_property.py', 'main/web_service/request_handler.py', 'main/exception/data_ingestor_error.py', 'main/web_service/web_service_model.py', 'main/util/common_util.py', 'main/util/config_model.py', 'main/web_service/web_service.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/11eb484d65be4edd8081926bb7ebccd38bbf34aa', 'message': 'pep8 compilant\n\nChange-Id: Ic921eeb2fdc22faf6bf747bedb99787c7be890a2\n'}]",0,313320,11eb484d65be4edd8081926bb7ebccd38bbf34aa,3,2,1,21739,,,0,"pep8 compilant

Change-Id: Ic921eeb2fdc22faf6bf747bedb99787c7be890a2
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/20/313320/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'main/util/source_config_model.py', 'main/util/util.py', 'main/source_manager/source/base_source.py', 'main/source_manager/source/random_source.py', 'main/util/singleton.py', 'main/exception/ml_framework_error.py', 'run.py', 'main/source_manager/source_model.py', 'setup.py', 'main/source_manager/source/kafka_source.py', 'main/voter_manager/voter/base_voter.py', 'setup_property.py', 'main/web_service/request_handler.py', 'main/exception/data_ingestor_error.py', 'main/web_service/web_service_model.py', 'main/util/common_util.py', 'main/util/config_model.py', 'main/web_service/web_service.py', 'main/machine_learning_manager/machine_learning/base_machine_learning.py']",21,11eb484d65be4edd8081926bb7ebccd38bbf34aa,," Interface implementable by any module that does machine learning data (SVM, decision tree, causality, etc)"," Interface implementable by any module that does machine learning data (SVM, decision tree, causality, etc) ",407,266
openstack%2Fmonasca-analytics~master~I5d6cf7a2173fce44b6db26ec68d6e8aa2bb28acf,openstack/monasca-analytics,master,I5d6cf7a2173fce44b6db26ec68d6e8aa2bb28acf,"created arc config, extended common_utils and created unit tests for it, also moved the machine learning algorithms to the machine_learning folder",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:56.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/common_util_test.py', 'config/arc_config.json', 'main/exception/ml_framework_error.py', 'test/util/test_json.json', 'main/source_manager/source_model.py', 'test/machine_learning_manager/machine_learning/classifiers/__init__.py', 'main/machine_learning_manager/machine_learning/anomaly_detection/__init__.py', 'main/machine_learning_manager/machine_learning/classifiers/__init__.py', 'main/source_manager/source/file_source.py', 'main/util/common_util.py', 'test/util/inheritance.py', 'test/util/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f3b3211e6c551e9075df41ba76b42a632e8ca9e3', 'message': 'created arc config, extended common_utils and created unit tests for it, also moved the machine learning algorithms to the machine_learning folder\n\nChange-Id: I5d6cf7a2173fce44b6db26ec68d6e8aa2bb28acf\n'}]",0,313323,f3b3211e6c551e9075df41ba76b42a632e8ca9e3,3,1,1,21739,,,0,"created arc config, extended common_utils and created unit tests for it, also moved the machine learning algorithms to the machine_learning folder

Change-Id: I5d6cf7a2173fce44b6db26ec68d6e8aa2bb28acf
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/23/313323/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/common_util_test.py', 'config/arc_config.json', 'main/exception/ml_framework_error.py', 'test/util/test_json.json', 'main/source_manager/source_model.py', 'test/machine_learning_manager/machine_learning/classifiers/__init__.py', 'main/machine_learning_manager/machine_learning/anomaly_detection/__init__.py', 'main/machine_learning_manager/machine_learning/classifiers/__init__.py', 'main/source_manager/source/file_source.py', 'main/util/common_util.py', 'test/util/inheritance.py', 'test/util/__init__.py']",12,f3b3211e6c551e9075df41ba76b42a632e8ca9e3,,,,513,29
openstack%2Fmonasca-analytics~master~I4e6337a0718a7bd33e547c6739aeba29d40109ea,openstack/monasca-analytics,master,I4e6337a0718a7bd33e547c6739aeba29d40109ea,"refactored the class by name logic, unifying several functions, modified ml_framework to create the classes at the begining, before binding anything",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:52.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'config/empty_config.json', 'config/arc_config.json', 'main/exception/ml_framework_error.py', 'main/util/common_util.py', 'config/config.json', 'main/sink_manager/sink/base_sink.py', 'config/default_source_config.json'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/80bd624b9a15ab2ed434b5e993b4d46a6e71e67d', 'message': 'refactored the class by name logic, unifying several functions, modified ml_framework to create the classes at the begining, before binding anything\n\nChange-Id: I4e6337a0718a7bd33e547c6739aeba29d40109ea\n'}]",0,313326,80bd624b9a15ab2ed434b5e993b4d46a6e71e67d,3,1,1,21739,,,0,"refactored the class by name logic, unifying several functions, modified ml_framework to create the classes at the begining, before binding anything

Change-Id: I4e6337a0718a7bd33e547c6739aeba29d40109ea
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/26/313326/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'config/empty_config.json', 'config/arc_config.json', 'main/exception/ml_framework_error.py', 'main/util/common_util.py', 'config/config.json', 'main/sink_manager/sink/base_sink.py', 'config/default_source_config.json']",8,80bd624b9a15ab2ed434b5e993b4d46a6e71e67d,,,"{ ""id"": ""random_source_1"", ""source"": { ""module"": ""RandomSource"", ""params"": { ""host"": ""localhost"", ""port"": 9999, ""model"": { ""name"": ""simple_model"", ""params"": { ""origin_types"": [ {""origin_type"": ""book"", ""weight"": 0.5}, {""origin_type"": ""enclosure"", ""weight"": 0.05}, {""origin_type"": ""fam"", ""weight"": 0.2}, {""origin_type"": ""node"", ""weight"": 0.1}, {""origin_type"": ""rack"", ""weight"": 0.025}, {""origin_type"": ""soc"", ""weight"": 0.125} ] } }, ""alerts_per_second"": 10, ""idle_time_between_bursts"": 2.0 } }, ""cruncher"": { ""module"": ""PGMLearnerCruncher"", ""params"": { ""window_duration"": 1, ""slide_duration"": 1, ""idle_time_between_bursts"": 0.5, ""sample_size"": 500, ""pvalparam"": 0.050000000000000003, ""indegree"": 1 } }, ""validate"": ""simple_model"" }",227,139
openstack%2Fmonasca-analytics~master~Ieccb6d00385624f6f6a3957b0e7c497f84ed69a6,openstack/monasca-analytics,master,Ieccb6d00385624f6f6a3957b0e7c497f84ed69a6,fixed and added tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:49.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/common_util_test.py', 'test/resources/test_json.json', 'test/ml_mocks.py', 'test/ml_framework_test.py', 'main/voter_manager/voter/identity.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/5030ee3168b2e5928e67491e780cebae137a5005', 'message': 'fixed and added tests\n\nChange-Id: Ieccb6d00385624f6f6a3957b0e7c497f84ed69a6\n'}]",0,313329,5030ee3168b2e5928e67491e780cebae137a5005,3,1,1,21739,,,0,"fixed and added tests

Change-Id: Ieccb6d00385624f6f6a3957b0e7c497f84ed69a6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/29/313329/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/common_util_test.py', 'test/resources/test_json.json', 'test/ml_mocks.py', 'test/ml_framework_test.py', 'main/voter_manager/voter/identity.py']",5,5030ee3168b2e5928e67491e780cebae137a5005,,class IdentityVoter(BaseVoter):,class FileSource(BaseVoter):,125,30
openstack%2Fmonasca-analytics~master~I394f8ccf193ac12f8aeae99e81549c561f6451b4,openstack/monasca-analytics,master,I394f8ccf193ac12f8aeae99e81549c561f6451b4,"tested lifecycle ml_framework functions, with mocks",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/resources/test_json.json', 'test/ml_mocks.py', 'config/config_template.json', 'test/ml_framework_test.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e8bdb3a7ca60304517ca5475d600cc158fcb3473', 'message': 'tested lifecycle ml_framework functions, with mocks\n\nChange-Id: I394f8ccf193ac12f8aeae99e81549c561f6451b4\n'}]",0,313332,e8bdb3a7ca60304517ca5475d600cc158fcb3473,3,1,1,21739,,,0,"tested lifecycle ml_framework functions, with mocks

Change-Id: I394f8ccf193ac12f8aeae99e81549c561f6451b4
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/32/313332/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/resources/test_json.json', 'test/ml_mocks.py', 'config/config_template.json', 'test/ml_framework_test.py']",5,e8bdb3a7ca60304517ca5475d600cc158fcb3473,," self.original_SparkContext = ml.SparkContext self.original_StreamingContext = ml.StreamingContext self.original_kill = ml.os.kill ml.SparkContext = self.original_SparkContext ml.StreamingContext = self.original_StreamingContext ml.os.kill = self.original_kill ml.SparkContext = ml_mocks.MockSparkContext ml.StreamingContext = ml_mocks.MockStreamingContext ml.os.kill = ml_mocks.mock_kill self.assertEqual(8, len(ml_mocks.ml_mocks.classes_got_by_name)) self.assertIn([""src_module2"", ""data_sources""], ml_mocks.ml_mocks.classes_got_by_name) def test_create_components_by_module(self): def assert_bound_src1(self, bound=True): if bound: self.assertIn(""src1"", self.mlf._bound_source_ids) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module1""][0].unbind_cnt) else: self.assertEqual( 0, ml_mocks.ml_mocks.instantiated[""src_module1""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module1""][0].unbind_cnt) def assert_bound_src2(self, bound=True): if bound: self.assertIn(""src2"", self.mlf._bound_source_ids) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module2""][0].unbind_cnt) else: self.assertEqual( 0, ml_mocks.ml_mocks.instantiated[""src_module2""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module2""][0].unbind_cnt) def test_bind_sources(self): self.mlf._bind_sources() self.assertEqual(2, len(ml_mocks.ml_mocks.bound_sources)) self.assertIn(ml_mocks.ml_mocks.instantiated[""src_module1""][0], ml_mocks.ml_mocks.bound_sources) self.assertIn(ml_mocks.ml_mocks.instantiated[""src_module2""][0], ml_mocks.ml_mocks.bound_sources) self.assertEqual(2, len(self.mlf._bound_source_ids)) self.assert_bound_src1(True) self.assert_bound_src2(True) def test_bind_sources_srcids_param(self): self.mlf._bind_sources(source_ids=[""src1""]) self.assertEqual( ml_mocks.ml_mocks.instantiated[""src_module1""], ml_mocks.ml_mocks.bound_sources) self.assertEqual(1, len(self.mlf._bound_source_ids)) self.assert_bound_src1(True) self.assert_bound_src2(False) def test_bind_sources_srcids_param_no_list(self): self.assertRaises(err.MlfBindSourcesError, self.mlf._bind_sources, source_ids=""src1"") self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assert_bound_src1(False) self.assert_bound_src2(False) def test_bind_sources_srcids_param_inexistent(self): self.assertRaises(err.MlfBindSourcesError, self.mlf._bind_sources, source_ids=[""src25""]) self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assert_bound_src1(False) self.assert_bound_src2(False) def test_bind_sources_mixed_existence(self): self.assertRaises(err.MlfBindSourcesError, self.mlf._bind_sources, source_ids=[""src2"", ""src25""]) self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assert_bound_src1(False) self.assert_bound_src2(False) self.mlf._bind_sources() self.mlf._unbind_sources() self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].unbind_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].unbind_cnt) self.mlf._terminate_sources() self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) # TODO test when implemented # todo test when implemented def test_start_streaming_src1(self): self.mlf.start_streaming([""src1""]) self.assert_bound_src1(True) self.assert_bound_src2(False) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_src1_src2(self): self.mlf.start_streaming([""src1"", ""src2""]) self.assert_bound_src1(True) self.assert_bound_src2(True) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_no_param(self): self.mlf.start_streaming() self.assert_bound_src1(True) self.assert_bound_src2(True) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_streaming_err(self): def failed_bind(obj, scc): raise Exception(""Failed to bind"") ml_mocks.ml_mocks.instantiated[ ""src_module2""][0].bind_source = failed_bind self.assertRaises(err.MlfStreamingError, self.mlf.start_streaming, [""src2""]) self.assert_bound_src1(False) self.assert_bound_src2(False) self.assertEqual(0, self.mlf._ssc.started_cnt) self.assertFalse(self.mlf.is_streaming()) def test_start_streaming_streaming_err_inexistent(self): self.assertRaises(err.MlfStreamingError, self.mlf.start_streaming, [""src3""]) self.assert_bound_src1(False) self.assert_bound_src2(False) self.assertEqual(0, self.mlf._ssc.started_cnt) self.assertFalse(self.mlf.is_streaming()) def test_start_streaming_twice_err(self): self.mlf.start_streaming([""src1"", ""src2""]) self.assertRaises(err.MlfAlreadyStartedStreaming, self.mlf.start_streaming, [""src1""]) self.assert_bound_src1(True) self.assert_bound_src2(True) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def test_start_streaming_twice_different_src(self): self.mlf.start_streaming([""src1""]) self.assertRaises(err.MlfAlreadyStartedStreaming, self.mlf.start_streaming, [""src2""]) self.assert_bound_src1(True) self.assert_bound_src2(False) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assertTrue(self.mlf.is_streaming()) def assert_stopped_streaming_state(self, ssc=None): self.assert_bound_src1(False) self.assert_bound_src2(False) if ssc: self.assertEqual(1, ssc.stopped_cnt) self.assertEqual(None, self.mlf._sc) self.assertEqual(None, self.mlf._ssc) self.assertFalse(self.mlf.is_streaming()) self.mlf.start_streaming() ssc = self.mlf._ssc self.mlf.stop_streaming() self.assert_stopped_streaming_state(ssc) def test_stop_streaming_no_streaming(self): self.mlf.start_streaming() ssc = self.mlf._ssc self.mlf.stop_streaming() self.assertRaises(err.MlfAlreadyStoppedStreaming, self.mlf.stop_streaming) self.assert_stopped_streaming_state(ssc) def test_stop_streaming_and_terminate_from_init_state(self): self.assertFalse(ml_mocks.ml_mocks.killed) self.mlf.stop_streaming_and_terminate() self.assertTrue(ml_mocks.ml_mocks.killed) self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) self.assert_stopped_streaming_state() def test_stop_streaming_and_terminate_from_streaming_state(self): self.assertFalse(ml_mocks.ml_mocks.killed) self.mlf.start_streaming() ssc = self.mlf._ssc self.mlf.stop_streaming_and_terminate() self.assertTrue(ml_mocks.ml_mocks.killed) self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) self.assert_stopped_streaming_state(ssc) def test_stop_streaming_and_terminate_from_stopped_state(self): self.assertFalse(ml_mocks.ml_mocks.killed) self.mlf.start_streaming() ssc = self.mlf._ssc self.mlf.stop_streaming() self.mlf.stop_streaming_and_terminate() self.assertTrue(ml_mocks.ml_mocks.killed) self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) self.assert_stopped_streaming_state(ssc)"," self.assertEqual(7, len(ml_mocks.ml_mocks.classes_got_by_name)) def test_create_components_by_module1(self): def test_create_components_by_module2(self): ml_mocks.ml_mocks.reset() self.mlf._create_components_by_module(""data_sources"") self.assert_only_instantiated(""src_module1"") def test_bind_sources(self): pass pass pass def test_start_streaming(self, source_ids=None): pass pass def test_stop_streaming_and_terminate(self): pass",311,43
openstack%2Fmonasca-analytics~master~I2cba549a32daca7e5e722c7b7b2270f7a164ff83,openstack/monasca-analytics,master,I2cba549a32daca7e5e722c7b7b2270f7a164ff83,Fix proxy problem with vagrant VM (joan),ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/35a20308c291c25805809a58484ac85acc7f1328', 'message': 'Fix proxy problem with vagrant VM (joan)\n\nChange-Id: I2cba549a32daca7e5e722c7b7b2270f7a164ff83\n'}]",0,313338,35a20308c291c25805809a58484ac85acc7f1328,3,1,1,21739,,,0,"Fix proxy problem with vagrant VM (joan)

Change-Id: I2cba549a32daca7e5e722c7b7b2270f7a164ff83
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/38/313338/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,35a20308c291c25805809a58484ac85acc7f1328,, config.proxy.http = ENV['HTTP_PROXY'] || ENV['http_proxy'] config.proxy.https = ENV['HTTPS_PROXY'] || ENV['https_proxy'], config.proxy.http = ENV['HTTP_PROXY'] config.proxy.https = ENV['HTTPS_PROXY'],2,2
openstack%2Fmonasca-analytics~master~Icb8547eb7756b9b10ad18058fccebec51aa8b324,openstack/monasca-analytics,master,Icb8547eb7756b9b10ad18058fccebec51aa8b324,"modified base_ingestor, arc_ingestor and added unit tests for both",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/mocks/ingestors.py', 'test/mocks/ml_mocks.py', 'test/mocks/spark_mocks.py', 'test/mocks/aggregator.py', 'test/data_ingestion_manager/data_ingestion/test_base_data_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3aac72543a21e9ef2b78380b70b17dafa0aa6fb2', 'message': 'modified base_ingestor, arc_ingestor and added unit tests for both\n\nChange-Id: Icb8547eb7756b9b10ad18058fccebec51aa8b324\n'}]",0,313341,3aac72543a21e9ef2b78380b70b17dafa0aa6fb2,3,1,1,21739,,,0,"modified base_ingestor, arc_ingestor and added unit tests for both

Change-Id: Icb8547eb7756b9b10ad18058fccebec51aa8b324
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/41/313341/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/mocks/ingestors.py', 'test/mocks/ml_mocks.py', 'test/mocks/spark_mocks.py', 'test/mocks/aggregator.py', 'test/data_ingestion_manager/data_ingestion/test_base_data_ingestor.py']",6,3aac72543a21e9ef2b78380b70b17dafa0aa6fb2,,"import os import json from logging.config import dictConfig import unittest from test.mocks.aggregator import MockDataAggregator from test.mocks.ingestors import MockDataIngestor class BaseDataIngestorTest(unittest.TestCase): """""" Class that tests the BaseDataIngestor. It uses the Mock as a testing target, because it extends the abstract class BaseDataIngestor, so the base logic can be tested. """""" def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def setUp(self): self.setup_logging() self.bi = MockDataIngestor(""fake_id"", ""fake_config"") self.set_mocks() def tearDown(self): pass def set_mocks(self): aggregator = MockDataAggregator(None, None) self.bi.set_aggregator(aggregator) def test_validate_called(self): self.assertEqual(1, self.bi.validation_cnt) def test_ingest_calls(self): self.bi.ingest(""dstream"", ""ssc"") self.assertEqual(1, self.bi.process_stream_cnt) self.assertIsNotNone(self.bi._dstream) self.assertIsNotNone(self.bi._ssc) self.assertEqual(1, self.bi._aggregator.aggregate_cnt) def test_stop_ingesting(self): self.bi.ingest(""dstream"", ""ssc"") self.bi.stop_ingesting() self.assertEqual(1, self.bi.before_stop_ingesting_cnt) ",,139,39
openstack%2Fmonasca-analytics~master~I471f689ee7d8f0ac5fb7bddecaf8e42eec45ffef,openstack/monasca-analytics,master,I471f689ee7d8f0ac5fb7bddecaf8e42eec45ffef,initial commit,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'config/logging.json', 'config/arc_config.json'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/a9adf543cad86a26a9ff03a0e560f5217fab22e5', 'message': 'initial commit\n\nChange-Id: I471f689ee7d8f0ac5fb7bddecaf8e42eec45ffef\n'}]",0,313340,a9adf543cad86a26a9ff03a0e560f5217fab22e5,3,1,1,21739,,,0,"initial commit

Change-Id: I471f689ee7d8f0ac5fb7bddecaf8e42eec45ffef
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/40/313340/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'config/logging.json', 'config/arc_config.json']",3,a9adf543cad86a26a9ff03a0e560f5217fab22e5,," ""appName"": ""testApp"", ""streaming"": { ""batch_interval"": 1 }, ""server"": { ""port"": 3000, ""debug"": true }, ""data_models"": {}, ""data_sources"": { ""src1"": { ""data_ingestors"": { ""ing1"": { ""module"": ""arc_data_ingestor"", ""providers_ids"": [""src1""] ""aggregator"": {}, ""learners"": {}, ""voter"": {}, ""sinks"": {}"," ""spark_config"": { ""appName"": ""AlertCruncher"", ""streaming"": { ""batch_interval"": 1 }, ""server"": { ""port"": 3000, ""debug"": true } }, ""data_models"": [], ""data_sources"": [ { ""id"": ""src1"", ], ""data_ingestors"": [ { ""module"": ""arc_data_ingestor"", ""id"": ""ing1"", ""params"": { ""sink_id"": 1 ""providers_ids"": [""src1""] } } ], ""aggregator"": { ""module"": ""parallel_agr"", ""id"": ""agg1"", ""params"": {} ""learners"": [ { ""module"": ""arc_learner"", ""id"": ""lrn1"", ""params"": {} } ], ""voter"": { ""module"": ""identity"", ""id"": ""vot1"", ""params"": { ""sink_id"": 2 ""sinks"": [ {""module"": ""asdf"", ""id"": ""sin1"", ""params"":{ ""learners_ids"": [] ""voter_id"": ""vot1"" } }, {""module"": ""asdf"", ""id"": ""sin2""} ]",31,61
openstack%2Fmonasca-analytics~master~I1c62de4e46faf1c11872bd42611ece3888a214a3,openstack/monasca-analytics,master,I1c62de4e46faf1c11872bd42611ece3888a214a3,"implemented the aggregation logic (needs to be tested with a real spark stream), and tests",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:34.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/mocks/spark_mocks.py', 'test/data_aggregation_manager/data_agregator/test_concatenation_aggregator.py', 'main/buffer_streamer/buffer_streamer.py', 'test/util/test_common_util.py', 'main/data_aggregation_manager/data_agregator/concatenation_aggregator.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/59bc880b7d95133321b72f76cb053c77474819c8', 'message': 'implemented the aggregation logic (needs to be tested with a real spark stream), and tests\n\nChange-Id: I1c62de4e46faf1c11872bd42611ece3888a214a3\n'}]",0,313344,59bc880b7d95133321b72f76cb053c77474819c8,3,1,1,21739,,,0,"implemented the aggregation logic (needs to be tested with a real spark stream), and tests

Change-Id: I1c62de4e46faf1c11872bd42611ece3888a214a3
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/44/313344/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/data_aggregation_manager/data_agregator/base_data_aggregator.py', 'test/mocks/spark_mocks.py', 'test/data_aggregation_manager/data_agregator/test_concatenation_aggregator.py', 'main/buffer_streamer/buffer_streamer.py', 'test/util/test_common_util.py', 'main/data_aggregation_manager/data_agregator/concatenation_aggregator.py']",6,59bc880b7d95133321b72f76cb053c77474819c8,,"from base_data_aggregator import BaseDataAggregator from schema import And, Schema, Optional class ConcatenationAggregator(BaseDataAggregator): def validate_config(self, _config): source_schema = Schema({ ""module"": And(basestring, lambda i: not any(c.isspace() for c in i)), Optional(""sinks_ids""): [basestring] }) return source_schema.validate(_config) def aggregation_logic(self, timestamp, rdd): """""" This aggregator doesn't do any logic, it just concatenates the RDDs, which is already what the Basic class does """""" return timestamp, rdd ",,153,13
openstack%2Fmonasca-analytics~master~Ibcfdefe4003a19ace96a6540e239c0ec09238df0,openstack/monasca-analytics,master,Ibcfdefe4003a19ace96a6540e239c0ec09238df0,Add possibility to run a specific test.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:31.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['Makefile'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ac0bd20f7ef0ad01dae9f9c44fed3e1f51a8ccaa', 'message': 'Add possibility to run a specific test.\n\nChange-Id: Ibcfdefe4003a19ace96a6540e239c0ec09238df0\n'}]",0,313346,ac0bd20f7ef0ad01dae9f9c44fed3e1f51a8ccaa,3,1,1,21739,,,0,"Add possibility to run a specific test.

Change-Id: Ibcfdefe4003a19ace96a6540e239c0ec09238df0
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/46/313346/1 && git format-patch -1 --stdout FETCH_HEAD,['Makefile'],1,ac0bd20f7ef0ad01dae9f9c44fed3e1f51a8ccaa,,"ifeq (testspec,$(firstword $(MAKECMDGOALS))) # use the rest as arguments for ""run"" TEST_ARGS := $(wordlist 2,$(words $(MAKECMDGOALS)),$(MAKECMDGOALS)) # ...and turn them into do-nothing targets $(eval $(TEST_ARGS):;@:) endif PYTHON=pythontestspec: $(PYTHON) -m unittest -v $(TEST_ARGS) .PHONY: all test clean style testspec",PYTHON = python.PHONY: all test clean style,13,2
openstack%2Fmonasca-analytics~master~Ife4741e909695a79a261884dd7c9fd73893ba08e,openstack/monasca-analytics,master,Ife4741e909695a79a261884dd7c9fd73893ba08e,Rename transitions. Tweak Markov configuration.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/markov_source_config.json', 'main/source_manager/source/markov_chain_source.py', 'test/source_manager/source/test_markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f084843b9a198031a193d8a5f8260e630a7829f3', 'message': 'Rename transitions. Tweak Markov configuration.\n\nChange-Id: Ife4741e909695a79a261884dd7c9fd73893ba08e\n'}]",0,313349,f084843b9a198031a193d8a5f8260e630a7829f3,3,1,1,21739,,,0,"Rename transitions. Tweak Markov configuration.

Change-Id: Ife4741e909695a79a261884dd7c9fd73893ba08e
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/49/313349/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/markov_source_config.json', 'main/source_manager/source/markov_chain_source.py', 'test/source_manager/source/test_markov_chain_source.py']",3,f084843b9a198031a193d8a5f8260e630a7829f3,," ""server_sleep_in_seconds"": 0.1 } transitions = { ""webservice"": { ""run=>slow"": { ""slow=>run"": { ""stop=>run"": 0.5 ""on=>off"": 0.1, ""off=>on"": 0.5 ""on=>off"": 0.5, ""off=>on"": 0.1 } ""transitions"": dict(transitions), self.config_missing_param[""transitions""] = dict(transitions) self.config_missing_param[""transitions""].pop(""host"") ""transitions"": dict(self.valid_config[""transitions""]), ""params"": dict(params), sw = FakeSwitch({""switch"": {""on=>off"": 0.5, ""off=>on"": 0.5}}) sw = FakeSwitch({""switch"": {""on=>off"": 1, ""off=>on"": 1}}) hs = FakeHost({""host"": {""on=>off"": 0, ""off=>on"": 0}})"," ""webservice"": { ""run_to_slow"": { ""slow_to_run"": { ""stop_to_run"": 0.5 ""on_to_off"": 0.1, ""off_to_on"": 0.5 ""on_to_off"": 0.5, ""off_to_on"": 0.1 }, ""server_sleep_in_seconds"": 0.1 self.config_missing_param[""params""] = dict(params) self.config_missing_param[""params""].pop(""host"") ""params"": dict(self.valid_config[""params""]), sw = FakeSwitch({""switch"": {""on_to_off"": 0.5, ""off_to_on"": 0.5}}) sw = FakeSwitch({""switch"": {""on_to_off"": 1, ""off_to_on"": 1}}) hs = FakeHost({""host"": {""on_to_off"": 0, ""off_to_on"": 0}})",46,40
openstack%2Fmonasca-analytics~master~If6491ecafef7c9f73421df86ec23f81861b1fda2,openstack/monasca-analytics,master,If6491ecafef7c9f73421df86ec23f81861b1fda2,Fix test and addressed comments.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:43:25.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/util/math.py', 'test/util/test_math.py', 'main/source_manager/source/markov_chain_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/0e706538767c3e7c6c4c2e7db5df64c8f33f41b8', 'message': 'Fix test and addressed comments.\n\nChange-Id: If6491ecafef7c9f73421df86ec23f81861b1fda2\n'}]",0,313352,0e706538767c3e7c6c4c2e7db5df64c8f33f41b8,3,1,1,21739,,,0,"Fix test and addressed comments.

Change-Id: If6491ecafef7c9f73421df86ec23f81861b1fda2
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/52/313352/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/util/math.py', 'test/util/test_math.py', 'main/source_manager/source/markov_chain_source.py']",3,0e706538767c3e7c6c4c2e7db5df64c8f33f41b8,,"from main.util.math import interpolate_1d if type(n) == FakeHost and\ type(o) == FakeSwitch: elif type(n) == FakeWebService and\ type(o) == FakeHost:# ============================================================================ # Model part # ============================================================================ self._hosts = [host for host in nodes if type(host) == FakeHost] self._swits = [swit for swit in nodes if type(swit) == FakeSwitch] self._webss = [webs for webs in nodes if type(webs) == FakeWebService] p = interpolate_1d(self._prob_get_called, hour_of_day) p = interpolate_1d(self._prob_run_to_slow, hour_of_day) p = interpolate_1d(self._prob_slow_to_run, hour_of_day)","from main.util.math import interp1 if isinstance(n, FakeHost) and\ isinstance(o, FakeSwitch): elif isinstance(n, FakeWebService) and\ isinstance(o, FakeHost):# ================= # Model part # ================= self._hosts = [host for host in nodes if type(host, FakeHost)] self._swits = [swit for swit in nodes if type(swit, FakeSwitch)] self._webss = [ webs for webs in nodes if type( webs, FakeWebService)] p = interp1(self._prob_get_called, hour_of_day) p = interp1(self._prob_run_to_slow, hour_of_day) p = interp1(self._prob_slow_to_run, hour_of_day)",23,25
openstack%2Fmonasca-analytics~master~I915e9701750bb37ed2105d2bfe15aa9e09e0d241,openstack/monasca-analytics,master,I915e9701750bb37ed2105d2bfe15aa9e09e0d241,"refactored the connection code to use the connecitons subdictionary in the config, instead of connections defined directly as part of the components definition",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:50.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/resources/logging.json', 'test/util/test_common_util.py', 'test/test_ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e828c7ee539df457ae74361d5572a53bbaafef43', 'message': 'refactored the connection code to use the connecitons subdictionary in the config, instead of connections defined directly as part of the components definition\n\nChange-Id: I915e9701750bb37ed2105d2bfe15aa9e09e0d241\n'}]",0,313355,e828c7ee539df457ae74361d5572a53bbaafef43,3,1,1,21739,,,0,"refactored the connection code to use the connecitons subdictionary in the config, instead of connections defined directly as part of the components definition

Change-Id: I915e9701750bb37ed2105d2bfe15aa9e09e0d241
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/55/313355/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/resources/logging.json', 'test/util/test_common_util.py', 'test/test_ml_framework.py']",4,e828c7ee539df457ae74361d5572a53bbaafef43,," def test_connect_sources(self): ml_mocks.ml_mocks.reset_connections() self.mlf._connect_sources() self.assert_src_ingestors_connection(True) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) self.assert_src_ingestors_connection(False) def test_connect_ingestors_no_connections_list(self): ml_mocks.ml_mocks.reset_connections() del self.mlf._config[cu.connections][""ing1""] self.mlf._connect_ingestors() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(True) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_ingestors_empty_connections_list(self): ml_mocks.ml_mocks.reset_connections() self.mlf._config[cu.connections][""ing1""] = [] self.mlf._connect_ingestors() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(True) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_aggregator_no_connections_list(self): ml_mocks.ml_mocks.reset_connections() del self.mlf._config[cu.connections][""agg1""] self.mlf._connect_aggregator() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(True) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_aggregator_empty_connections_list(self): ml_mocks.ml_mocks.reset_connections() self.mlf._config[cu.connections][""agg1""] = [] self.mlf._connect_aggregator() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(True) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_learners_no_connections_list(self): ml_mocks.ml_mocks.reset_connections() del self.mlf._config[cu.connections][""lrn1""] self.mlf._connect_learners() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(True) self.assert_learners_buffer_connection(True) self.assert_learners_voter_connection(True) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_learners_empty_connections_list(self): ml_mocks.ml_mocks.reset_connections() self.mlf._config[cu.connections][""lrn1""] = [] self.mlf._connect_learners() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(True) self.assert_learners_buffer_connection(True) self.assert_learners_voter_connection(True) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_voter_no_connections_list(self): ml_mocks.ml_mocks.reset_connections() del self.mlf._config[cu.connections][""vot1""] self.mlf._connect_voter() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_voter_empty_connections_list(self): ml_mocks.ml_mocks.reset_connections() self.mlf._config[cu.connections][""vot1""] = [] self.mlf._connect_voter() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_sinks_no_connections_list(self): ml_mocks.ml_mocks.reset_connections() del self.mlf._config[cu.connections][""sin1""] del self.mlf._config[cu.connections][""sin2""] self.mlf._connect_sinks() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_connect_sinks_empty_connections_list(self): ml_mocks.ml_mocks.reset_connections() self.mlf._config[cu.connections][""sin1""] = [] self.mlf._config[cu.connections][""sin2""] = [] self.mlf._connect_sinks() self.assert_src_ingestors_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_buffer_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_buffer_learners_connection(False) self.assert_learners_buffer_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) ", self.assert_src_ingestors_connection(True),279,62
openstack%2Fmonasca-analytics~master~I79b87e1599dec09977a7b4ab67dd5e97b18619d3,openstack/monasca-analytics,master,I79b87e1599dec09977a7b4ab67dd5e97b18619d3,implemented the schema checking,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:47.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/test_config_model.py', 'main/util/config_model.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/fa4af827a7ab7a0496bada0b96bcda228ed9fab0', 'message': 'implemented the schema checking\n\nChange-Id: I79b87e1599dec09977a7b4ab67dd5e97b18619d3\n'}]",0,313356,fa4af827a7ab7a0496bada0b96bcda228ed9fab0,3,1,1,21739,,,0,"implemented the schema checking

Change-Id: I79b87e1599dec09977a7b4ab67dd5e97b18619d3
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/56/313356/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/test_config_model.py', 'main/util/config_model.py']",2,fa4af827a7ab7a0496bada0b96bcda228ed9fab0,,"from schema import And, Schema, SchemaError comp_types = [""data_models"", ""data_sources"", ""data_ingestors"", ""aggregator"", ""learners"", ""voter"", ""sinks""] def validate_config(config): _validate_schema(config) _validate_only_one_aggregator_and_voter(config) _validate_ids_unicity(config) _validate_connections(config) def _validate_schema(config): """""" Validates the spark configuration and the modules configuration structure up to the orchestration level. Each module will be responsible to validate its own subconfiguration. @type config: Dictionary @param config: Config model for the whole system """""" config_schema = Schema({ ""id"": basestring, ""spark_config"": { ""appName"": basestring, ""streaming"": { ""batch_interval"": And(int, lambda b: b > 0) }, ""server"": { ""port"": int, ""debug"": bool } ""data_models"": { basestring: {basestring: object} }, ""data_sources"": { basestring: {basestring: object} }, ""data_ingestors"": { basestring: {basestring: object} }, ""aggregator"": { basestring: {basestring: object} }, ""learners"": { basestring: {basestring: object} }, ""voter"": { basestring: {basestring: object} }, ""sinks"": { basestring: {basestring: object} }, ""connections"": { basestring: [basestring] return config_schema.validate(config) def _validate_only_one_aggregator_and_voter(config): """""" Checks that the configuraiton define only a single aggregator and a single voter. @type config: Dictionary @param config: Config model for the whole system """""" def _raise(comp): raise SchemaError([ ""More than one "" + comp + "" found in the config, please modify "" + ""it specifying only one aggregator""], []) if len(config[""aggregator""]) > 1: _raise(""aggregator"") if len(config[""voter""]) > 1: _raise(""voter"") def _validate_ids_unicity(config): """""" Validates that the IDs of the components are unique. @type config: Dictionary @param config: Config model for the whole system """""" all_ids = [] for comp_type in comp_types: for com_id in config[comp_type].keys(): if com_id in all_ids: raise SchemaError([""Duplicated component ID : "" + com_id], []) all_ids.append(com_id) def _validate_expected_dest_type(config, from_id, to_ids, expected_types): """""" Auxiliar function that checks that the destination of the connections is one of the types defined in expected_types. @type config: Dictionary @param config: Config model for the whole system @type from_id: String @param from_id: ID of the component which is the initial point of the connection @type to_ids: list @param to_ids: IDs of the components which are the destination point of the connection @type expected_types: list @param expected_types: types of components that are allowed for the destination points """""" for to_id in to_ids: valid_connection = False for expected_type in expected_types: if to_id in config[expected_type].keys(): valid_connection = True if not valid_connection: raise SchemaError([ from_id + "" connected to a wrong component:"" + to_id + ""It should be connected only to "" + expected_type], []) def _validate_existing_id(config, component_id): """""" Checks that the id passed as parameter is defined in the configuration @type config: Dictionary @param config: Config model for the whole system @type from_id: String @param from_id: component ID to be found in config """""" found_id = False for comp_type in comp_types: if component_id in config[comp_type].keys(): found_id = True if not found_id: raise SchemaError(['Data models should not define connections'], []) def _validate_connections(config): """""" Validates the connections, checking that only connections that make sense are defined. @type config: Dictionary @param config: Config model for the whole system """""" for from_id in config[""connections""].keys(): _validate_existing_id(config, from_id) to_ids = config[""connections""][from_id] if from_id in config[""data_models""].keys(): raise SchemaError(['Data models should not define connections'], []) if from_id in config[""data_sources""].keys(): _validate_expected_dest_type(config, from_id, to_ids, [""data_ingestors""]) continue if from_id in config[""data_ingestors""].keys() or\ from_id in config[""aggregator""].keys() or\ from_id in config[""learners""].keys() or\ from_id in config[""voter""].keys(): _validate_expected_dest_type(config, from_id, to_ids, [""sinks""]) continue if from_id in config[""sinks""].keys(): _validate_expected_dest_type(config, from_id, to_ids, [""voter"", ""learners""]) continue","from schema import And, Schema def validate_config(value): """"""Validates the config."""""" config_schema = Schema({ ""appName"": basestring, ""streaming"": { ""batch_interval"": And(int, lambda b: b > 0) ""server"": { ""port"": int, ""debug"": bool return config_schema.validate(value)",372,10
openstack%2Fmonasca-analytics~master~I0d3a9ca5caf5d569ead0bb229f123ba8894a72f0,openstack/monasca-analytics,master,I0d3a9ca5caf5d569ead0bb229f123ba8894a72f0,initial changes,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:44.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/resources/test_json.json', 'test/resources/logging.json', 'main/util/common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/d021e8ce028130bf219d8e5030c9b9d968d3cfa7', 'message': 'initial changes\n\nChange-Id: I0d3a9ca5caf5d569ead0bb229f123ba8894a72f0\n'}]",0,313354,d021e8ce028130bf219d8e5030c9b9d968d3cfa7,3,1,1,21739,,,0,"initial changes

Change-Id: I0d3a9ca5caf5d569ead0bb229f123ba8894a72f0
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/54/313354/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/resources/test_json.json', 'test/resources/logging.json', 'main/util/common_util.py']",4,d021e8ce028130bf219d8e5030c9b9d968d3cfa7,,"connections = ""connections""",,61,27
openstack%2Fmonasca-analytics~master~I5c8f974f9eef32572cf4f93a238351cf8ad73227,openstack/monasca-analytics,master,I5c8f974f9eef32572cf4f93a238351cf8ad73227,Add jenkins script to fetch dependencies if not present.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['jenkins.sh'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e2f623e5a9ba21d2df7be01ac5cdf21282077a95', 'message': 'Add jenkins script to fetch dependencies if not present.\n\nChange-Id: I5c8f974f9eef32572cf4f93a238351cf8ad73227\n'}]",0,313357,e2f623e5a9ba21d2df7be01ac5cdf21282077a95,3,1,1,21739,,,0,"Add jenkins script to fetch dependencies if not present.

Change-Id: I5c8f974f9eef32572cf4f93a238351cf8ad73227
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/57/313357/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins.sh'],1,e2f623e5a9ba21d2df7be01ac5cdf21282077a95,,"# Everything will be done in a tmp directoy. mkdir ~/tmp-build-for-arc-alc cd ~/tmp-build-for-arc-alc if hash scala 2>/dev/null; then # Scala is installed do nothing echo ""Scala is already installed"" else # Install it curl https://downloads.typesafe.com/scala/2.11.7/scala-2.11.7.deb > scala.deb sudo dpkg -i scala.deb # Install sbt echo ""deb https://dl.bintray.com/sbt/debian /"" | sudo tee -a /etc/apt/sources.list.d/sbt.list sudo -E apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823 sudo -E apt-get update sudo -E apt-get -y install sbt fi if [ ""$SPARK_HOME"" ]; then # Spark is installed and home is setup properly echo ""Spark is already installed"" else curl http://apache.arvixe.com/spark/spark-1.4.1/spark-1.4.1.tgz > spark.tgz tar -xzf spark.tgz mv spark-1.4.1/ ~/spark cd ~/spark mvn -DskipTests clean package cp ~/spark/conf/log4j.properties.template ~/spark/conf/log4j.properties sed -i 's/log4j.rootCategory=INFO/log4j.rootCategory=ERROR/g' ~/spark/conf/log4j.properties set -v echo 'export SPARK_HOME=~/spark' >> $HOME/.profile echo 'export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.8.2.1-src.zip:$PYTHONPATH' >> $HOME/.profile set +v cd ~/tmp-build-for-arc-alc fi if hash pep8 2>/dev/null; then echo ""Pep8 is already installed!"" else sudo -E apt-get -y install python-pip python-setuptools sudo -E pip install pep8 fi # Python dependencies sudo -E apt-get -y install python-numpy python-scipy ipython sudo -E -H python setup.py develop # Remove tmp directory cd .. rm tmp-build-for-arc-alc ",,55,0
openstack%2Fmonasca-analytics~master~I8471b2df710cd5435062416d5fac41dbf4b6522f,openstack/monasca-analytics,master,I8471b2df710cd5435062416d5fac41dbf4b6522f,Clean up base.py and added abstract MarkovChain base class.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:38.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source_manager/source/markov_chain/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/1251b4a7823c781e441eb7b767a946a0707d306e', 'message': 'Clean up base.py and added abstract MarkovChain base class.\n\nChange-Id: I8471b2df710cd5435062416d5fac41dbf4b6522f\n'}]",0,313365,1251b4a7823c781e441eb7b767a946a0707d306e,3,1,1,21739,,,0,"Clean up base.py and added abstract MarkovChain base class.

Change-Id: I8471b2df710cd5435062416d5fac41dbf4b6522f
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/65/313365/1 && git format-patch -1 --stdout FETCH_HEAD,['main/source_manager/source/markov_chain/base.py'],1,1251b4a7823c781e441eb7b767a946a0707d306e,," @abstractmethod def _create_system(self): pass """""" Any subclass must check for the presence of ""server_sleep_in_seconds"" in the params field of the configuration @param _config: configuration to be validated. """""" system = LeafNodes(self._create_system()) port = self._start_thread(system) def _start_thread(self, system): self._server.system = systemclass LeafNodes(object): def __init__(self, state_nodes): self._state_nodes = state_nodes def next_state(self, hour_of_day): ignored_states = set([]) for s in self._state_nodes: s.next_state(hour_of_day, ignored_states) def collect_events(self, hour_of_day): pass def next_state(self, hour_of_day, ignored_states): @param ignored_states: set of states that should not change. if self._id not in ignored_states: ignored_states.add(self._id) for dep in self.dependencies: dep.next_state(ignored_states) self._markov_chain.apply_on(self, hour_of_day) def collect_event(self, hour_of_day, ignored_events): class FMSTCPHandler(BaseRequestHandler): """"""A TCP server handler for the alert generation."""""" def handle(self): """"""Handles incoming connection and pushing data into them."""""" fake_date = datetime.today() hour_of_day = fake_date.hour while True and not self.server.terminate: self.server.system.next_state(hour_of_day) events = self.server.system.collect_events(hour_of_day) self.request.send(""{0}\n"".format(json.dumps({ 'ctime': fake_date.ctime(), 'events': events }))) time.sleep(self.server.sleep_in_seconds) hour_of_day += 1 fake_date += timedelta(hours=1) if hour_of_day > 24: hour_of_day = 0"," fake_system = self._prepare_config() port = self._start_thread(fake_system) def _prepare_config(self): transitions = self._config[""transitions""] graph = self._config[""graph""] nodes = dict() for k in graph.keys(): node_name, node_type = k.split("":"") if node_type == ""host"": nodes[node_name] = FakeHost(transitions) elif node_type == ""switch"": nodes[node_name] = FakeSwitch(transitions) elif node_type == ""web_service"": nodes[node_name] = FakeWebService(transitions) for k, v in graph.iteritems(): node_name, _ = k.split("":"") for depend_on in v: if depend_on not in nodes: logger.warn( ""Configuration error: '{}' is not a proper dependency "" ""of '{}'"".format(depend_on, node_name)) else: n = nodes[node_name] o = nodes[depend_on] if type(n) == FakeHost and\ type(o) == FakeSwitch: n.set_switch(o) elif type(n) == FakeWebService and\ type(o) == FakeHost: n.set_host(o) else: logger.warn( ""Configuration error: '{}' doesn't"" "" have a suitable "" ""type for '{}'"".format( depend_on, node_name)) return FakeMonitoringSystem(nodes.values(), transitions) def _start_thread(self, fake_system): self._server.fake_system = fake_system def next_state(self, hour_of_day): self._markov_chain.apply_on(self, hour_of_day) def collect_event(self, hour_of_day):",60,47
openstack%2Fmonasca-analytics~master~I368a024abbfdd147470699348b5dc34cef528bf7,openstack/monasca-analytics,master,I368a024abbfdd147470699348b5dc34cef528bf7,Refactor and cloud example.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:35.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source_manager/source/markov_chain/test_events.py', 'main/source_manager/source/markov_chain_source.py', 'main/source_manager/source/markov_chain/state_check.py', 'test/source_manager/source/markov_chain/test_base.py', 'main/source_manager/source/markov_chain/prob_checks.py', 'main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/test_markov_chain_source.py', 'main/source_manager/source/cloud_markov_chain_source.py', 'test/source_manager/source/markov_chain/test_transition.py', 'main/source_manager/source/markov_chain/base.py', 'main/source_manager/source/markov_chain/events.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/e2876ba7b3efcb98c23c4d53ec2b232fc3965f9a', 'message': 'Refactor and cloud example.\n\nChange-Id: I368a024abbfdd147470699348b5dc34cef528bf7\n'}]",0,313366,e2876ba7b3efcb98c23c4d53ec2b232fc3965f9a,3,1,1,21739,,,0,"Refactor and cloud example.

Change-Id: I368a024abbfdd147470699348b5dc34cef528bf7
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/66/313366/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source_manager/source/markov_chain/test_events.py', 'main/source_manager/source/markov_chain_source.py', 'main/source_manager/source/markov_chain/state_check.py', 'main/source_manager/source/markov_chain/prob_checks.py', 'test/source_manager/source/markov_chain/test_base.py', 'main/source_manager/source/markov_chain/transistion.py', 'test/source_manager/source/test_markov_chain_source.py', 'main/source_manager/source/cloud_markov_chain_source.py', 'test/source_manager/source/markov_chain/test_transition.py', 'main/source_manager/source/markov_chain/base.py', 'main/source_manager/source/markov_chain/events.py']",11,e2876ba7b3efcb98c23c4d53ec2b232fc3965f9a,,"#!/usr/bin/env python class Trigger(object): """""" A trigger generate events when a particular graph state is reached. """""" def __init__(self, node_check, prob_check, event_builder): self._prob_check = prob_check self._node_check = node_check self._event_builder = event_builder def apply_on(self, node, hour_of_day): if self._prob_check(hour_of_day) and self._node_check(node): return self._event_builder(node) return None class Event(object): def __init__(self, msg, ident): self.id = ident self.msg = msg class EventBuilder(object): def __init__(self, msg): self._msg = msg def __call__(self, node): return Event(self._msg, node.id()) ",,591,571
openstack%2Fmonasca-analytics~master~I301b1f3a74e224799b03c8b8de4bbe8bdd5caf84,openstack/monasca-analytics,master,I301b1f3a74e224799b03c8b8de4bbe8bdd5caf84,Add base and kafka sink for dstream sinks. Fix tests. Allow src->tra connection. Remove ing->tra connection.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:32.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/base_source.py', 'test/sink/__init__.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'main/sink/dstream/__init__.py', 'test/sink/dstream_sink/test_kafka_sink.py', 'main/sink/ml/base_sink.py', 'test/mocks/ml_mocks.py', 'main/sink/dstream/sink_config_validator.py', 'main/sink/dstream/kafka_sink.py', 'main/sink/dstream/base_sink.py', 'main/sink/ml/__init__.py', 'main/util/common_util.py', 'main/util/config_model.py', 'test/sink/dstream_sink/test_sink_config_validator.py', 'test/test_ml_framework.py', 'test/sink/dstream_sink/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/6e510eb7d6665cc5309b75cf5ee636a1a3e91f1b', 'message': 'Add base and kafka sink for dstream sinks. Fix tests. Allow src->tra connection. Remove ing->tra connection.\n\nChange-Id: I301b1f3a74e224799b03c8b8de4bbe8bdd5caf84\n'}]",0,313376,6e510eb7d6665cc5309b75cf5ee636a1a3e91f1b,3,2,1,21739,,,0,"Add base and kafka sink for dstream sinks. Fix tests. Allow src->tra connection. Remove ing->tra connection.

Change-Id: I301b1f3a74e224799b03c8b8de4bbe8bdd5caf84
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/76/313376/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/base_source.py', 'test/sink/__init__.py', 'test/util/test_config_model.py', 'test/resources/test_json.json', 'main/sink/dstream/__init__.py', 'test/sink/dstream_sink/test_kafka_sink.py', 'main/sink/ml/base_sink.py', 'test/mocks/ml_mocks.py', 'main/sink/dstream/sink_config_validator.py', 'main/sink/dstream/kafka_sink.py', 'main/sink/dstream/base_sink.py', 'main/sink/ml/__init__.py', 'main/util/common_util.py', 'main/util/config_model.py', 'test/sink/dstream_sink/test_sink_config_validator.py', 'test/test_ml_framework.py', 'test/sink/dstream_sink/__init__.py']",17,6e510eb7d6665cc5309b75cf5ee636a1a3e91f1b,,,,266,49
openstack%2Fmonasca-analytics~master~I99458daac061f07742dd59914a8bf0510c3a1f68,openstack/monasca-analytics,master,I99458daac061f07742dd59914a8bf0510c3a1f68,"initial changes to fix some bugs in markov chain source, and made components optional in the config file validation",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:29.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/base_source.py', 'config/markov_source_config.json', 'main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py', 'test/source/test_markov_chain_source.py', 'main/util/config_model.py', 'main/web_service/web_service.py', 'main/data_ingestion/fake_host_switch_web_service_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b3fd54935aa75772de10f4de7b99294254659de7', 'message': 'initial changes to fix some bugs in markov chain source, and made components optional in the config file validation\n\nChange-Id: I99458daac061f07742dd59914a8bf0510c3a1f68\n'}]",0,313381,b3fd54935aa75772de10f4de7b99294254659de7,3,1,1,21739,,,0,"initial changes to fix some bugs in markov chain source, and made components optional in the config file validation

Change-Id: I99458daac061f07742dd59914a8bf0510c3a1f68
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/81/313381/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/base_source.py', 'config/markov_source_config.json', 'main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/base.py', 'test/source/test_markov_chain_source.py', 'main/util/config_model.py', 'main/web_service/web_service.py', 'main/data_ingestion/fake_host_switch_web_service_ingestor.py']",8,b3fd54935aa75772de10f4de7b99294254659de7,, lambda i: not any(c.isspace() for c in i)) print json_value," lambda i: not any(c.isspace() for c in i)), ""providers_ids"": [basestring]",44,36
openstack%2Fmonasca-analytics~master~Ic3d60543c5a9408ef5d849145944efcaa1ffba3d,openstack/monasca-analytics,master,Ic3d60543c5a9408ef5d849145944efcaa1ffba3d,Remove mdp from dependency list.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:26.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/9a2ea0c247d4cbd29b1844ffbd991a261deaedcd', 'message': 'Remove mdp from dependency list.\n\nChange-Id: Ic3d60543c5a9408ef5d849145944efcaa1ffba3d\n'}]",0,313378,9a2ea0c247d4cbd29b1844ffbd991a261deaedcd,3,2,1,21739,,,0,"Remove mdp from dependency list.

Change-Id: Ic3d60543c5a9408ef5d849145944efcaa1ffba3d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/78/313378/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,9a2ea0c247d4cbd29b1844ffbd991a261deaedcd,,," ""mdp"",",0,1
openstack%2Fmonasca-analytics~master~Ifc34e49116804d4efd1ba768604ed88c57066e13,openstack/monasca-analytics,master,Ifc34e49116804d4efd1ba768604ed88c57066e13,Add doc and rename file.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:24.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/base_source.py', 'main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/transition.py', 'test/source/markov_chain/test_transition.py', 'main/source/markov_chain/base.py', 'test/source/markov_chain/test_base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/0c7510734fc744313454fb7e24f2f42c1322624b', 'message': 'Add doc and rename file.\n\nChange-Id: Ifc34e49116804d4efd1ba768604ed88c57066e13\n'}]",0,313383,0c7510734fc744313454fb7e24f2f42c1322624b,3,1,1,21739,,,0,"Add doc and rename file.

Change-Id: Ifc34e49116804d4efd1ba768604ed88c57066e13
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/83/313383/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/base_source.py', 'main/source/cloud_markov_chain_source.py', 'main/source/markov_chain/transition.py', 'test/source/markov_chain/test_transition.py', 'main/source/markov_chain/base.py', 'test/source/markov_chain/test_base.py']",6,0c7510734fc744313454fb7e24f2f42c1322624b,,import main.source.markov_chain.transition as tr,import main.source.markov_chain.transistion as tr,29,3
openstack%2Fmonasca-analytics~master~I17a0cf10b46ee942657d2a4f10515f30f1185d55,openstack/monasca-analytics,master,I17a0cf10b46ee942657d2a4f10515f30f1185d55,Updated doc's diagram and logo file.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:21.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/images/alert_fatigue_pipeline_with_markov.png', 'doc/images/alert_fatigue_pipeline.png', 'doc/images/monanas-logo.png', 'doc/images/monanas-logo-small.png', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/88dac7edbb86fabf31ae06916ec798005355f2ea', 'message': ""Updated doc's diagram and logo file.\n\nChange-Id: I17a0cf10b46ee942657d2a4f10515f30f1185d55\n""}]",0,313387,88dac7edbb86fabf31ae06916ec798005355f2ea,3,2,1,21739,,,0,"Updated doc's diagram and logo file.

Change-Id: I17a0cf10b46ee942657d2a4f10515f30f1185d55
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/87/313387/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/images/alert_fatigue_pipeline.png', 'doc/images/alert_fatigue_pipeline_with_markov.png', 'doc/images/monanas-logo.png', 'doc/images/monanas-logo-small.png', 'README.md']",5,88dac7edbb86fabf31ae06916ec798005355f2ea,,![MoNanas Logo](doc/images/monanas-logo.png),![MoNanas Logo](doc/images/monanas-logo-small.png),1,1
openstack%2Fmonasca-analytics~master~I1501502afea852c16e5d0a7d6f9c920fd676ce88,openstack/monasca-analytics,master,I1501502afea852c16e5d0a7d6f9c920fd676ce88,Change the interface for set_voter_output (remove path from the argument list) in base transformer.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:18.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/transformer/base_transformer.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/transformer/cloud_transformer/causality_transformer.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/8393fd86a3fda5583a7cbc905c6b7194c686ece2', 'message': 'Change the interface for set_voter_output (remove path from the argument list) in base transformer.\n\nChange-Id: I1501502afea852c16e5d0a7d6f9c920fd676ce88\n'}]",0,313392,8393fd86a3fda5583a7cbc905c6b7194c686ece2,3,2,1,21739,,,0,"Change the interface for set_voter_output (remove path from the argument list) in base transformer.

Change-Id: I1501502afea852c16e5d0a7d6f9c920fd676ce88
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/92/313392/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/transformer/base_transformer.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/transformer/cloud_transformer/causality_transformer.py']",3,8393fd86a3fda5583a7cbc905c6b7194c686ece2,," def __init__(self, _id, _config, sc): base_transformer.BaseTransformer.__init__(_id, _config, sc) def _process_stream(self, dstream): dstream.flatMap(self._aggregate) def _aggregate(self, rdd_entry): events = rdd_entry[""events""] occurred_features = set() for event in events: occurred_features.add(event[""id""])"," def __init__(self, _id, _config): base_transformer.BaseTransformer(_id, _config) def process_stream(self, dstream): if (self._config[""params""][""mode""] == ""aggregate""): self._sink(dstream.transform(lambda timestamp, rdd: self._aggregate(timestamp, rdd))) elif (self._config[""params""][""mode""] == ""filter""): self._sink(dstream.transform(lambda timestamp, rdd: self._filter(timestamp, rdd))) else: self._sink(dstream) def _aggregate(self, timestamp, rdd): if (not self._path or not self._features or not self._matrix): return self._sc.parallelize(rdd.collect()) else: pass def _filter(self, timestamp, rdd): rdd_entries = rdd.collect() if (not self._path or not self._features or not self._matrix): return self._sc.parallelize(rdd_entries) else: if (type(self.path[-1]) == list): pass # else: # for rdd_entry in rdd_entries: # pass def _sink(self, dstream): for sink in self._sinks: sink.sink(dstream)",35,35
openstack%2Fmonasca-analytics~master~Iba3acd897a209efd6e290eef68fadfb572453543,openstack/monasca-analytics,master,Iba3acd897a209efd6e290eef68fadfb572453543,Add causality transformer for cloud transformer.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:14.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/transformer/base_transformer.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/transformer/cloud_transformer/causality_transformer.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/8e146d21337e212594d102e37319b5c1b482b928', 'message': 'Add causality transformer for cloud transformer.\n\nChange-Id: Iba3acd897a209efd6e290eef68fadfb572453543\n'}]",0,313393,8e146d21337e212594d102e37319b5c1b482b928,3,2,1,21739,,,0,"Add causality transformer for cloud transformer.

Change-Id: Iba3acd897a209efd6e290eef68fadfb572453543
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/93/313393/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/transformer/base_transformer.py', 'main/transformer/cloud_transformer/base_transformer.py', 'main/transformer/cloud_transformer/causality_transformer.py']",3,8e146d21337e212594d102e37319b5c1b482b928,," def __init__(self, _id, _config): base_transformer.BaseTransformer.__init__(_id, _config) self._sink(dstream.flatMap(self._aggregate)) new_entries = [] causes = [] try: cause = self._features.index(event[""id""]) for other_event in events: if (other_event[""id""] != event[""id""]): try: caused = self._features.index(other_event[""id""]) if (self._matrix[caused][cause]): causes.append(other_event[""id""]) except ValueError: pass except ValueError: pass event[""timestamp""] = rdd_entry[""timestamp""] event[""__monanas__""] = dict(causes=causes) new_entries.append(event) return new_entries"," def __init__(self, _id, _config, sc): base_transformer.BaseTransformer.__init__(_id, _config, sc) dstream.flatMap(self._aggregate) occurred_features = set() occurred_features.add(event[""id""])",28,9
openstack%2Fmonasca-analytics~master~Iba473729506c368b4a5d233d267e775025ebdfc1,openstack/monasca-analytics,master,Iba473729506c368b4a5d233d267e775025ebdfc1,Fix tests.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:11.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/test_common_util.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f889bf7206ef8de2fe0e1133787f7227a864084f', 'message': 'Fix tests.\n\nChange-Id: Iba473729506c368b4a5d233d267e775025ebdfc1\n'}]",0,313395,f889bf7206ef8de2fe0e1133787f7227a864084f,3,1,1,21739,,,0,"Fix tests.

Change-Id: Iba473729506c368b4a5d233d267e775025ebdfc1
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/95/313395/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/util/test_common_util.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py']",3,f889bf7206ef8de2fe0e1133787f7227a864084f,," event_builder=EventBuilder(""test"")"," event_builder=EventBuilder(""test"", ""t"")",3,3
openstack%2Fmonasca-analytics~master~I8fd908ed5f1dc9aa9e86eb41e34ce95852edfa81,openstack/monasca-analytics,master,I8fd908ed5f1dc9aa9e86eb41e34ce95852edfa81,Fix tests for end2end.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:09.000000000,,"[{'_account_id': 3}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/kafka_source.py', 'main/transformer/cloud_causality.py', 'test/machine_learning/test_lingam.py', 'main/source/file_source.py', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/source/random_source.py', 'test/mocks/sources.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2b6ba159f5900389b444edc342c82811d3571255', 'message': 'Fix tests for end2end.\n\nChange-Id: I8fd908ed5f1dc9aa9e86eb41e34ce95852edfa81\n'}]",0,313398,2b6ba159f5900389b444edc342c82811d3571255,3,2,1,21739,,,0,"Fix tests for end2end.

Change-Id: I8fd908ed5f1dc9aa9e86eb41e34ce95852edfa81
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/98/313398/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/kafka_source.py', 'main/transformer/cloud_causality.py', 'test/machine_learning/test_lingam.py', 'main/source/file_source.py', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/source/random_source.py', 'test/mocks/sources.py']",8,2b6ba159f5900389b444edc342c82811d3571255,, def propagate_feature_list(self): pass,,22,24
openstack%2Fmonasca-analytics~master~I5864ebe8cff894f5c111c1003407b1caa830ce7a,openstack/monasca-analytics,master,I5864ebe8cff894f5c111c1003407b1caa830ce7a,Simplified source interface. Removed unused code.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/base_source.py', 'main/source/kafka_source.py', 'main/source/cloud_markov_chain_source.py', 'main/source/source_model.py', 'main/source/file_source.py', 'main/source/markov_chain/base.py', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/source/random_source.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/cec888bdfe4ab00e6b969cc0755d4e924a65d466', 'message': 'Simplified source interface. Removed unused code.\n\nChange-Id: I5864ebe8cff894f5c111c1003407b1caa830ce7a\n'}]",0,313407,cec888bdfe4ab00e6b969cc0755d4e924a65d466,3,1,1,21739,,,0,"Simplified source interface. Removed unused code.

Change-Id: I5864ebe8cff894f5c111c1003407b1caa830ce7a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/07/313407/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/base_source.py', 'main/source/kafka_source.py', 'main/source/cloud_markov_chain_source.py', 'main/source/source_model.py', 'main/source/file_source.py', 'main/source/markov_chain/base.py', 'test/util/test_common_util.py', 'main/util/common_util.py', 'main/source/random_source.py']",9,cec888bdfe4ab00e6b969cc0755d4e924a65d466,," def create_dstream(self, ssc): def get_feature_list(self):"," def before_bind_source(self, ssc): def after_bind_source(self, ssc): pass def before_unbind_source(self, ssc): pass def after_unbind_source(self, ssc): pass def propagate_feature_list(self):",38,160
openstack%2Fmonasca-analytics~master~I8f885f4d1c5b10a90de35c95d225b45feaf9323e,openstack/monasca-analytics,master,I8f885f4d1c5b10a90de35c95d225b45feaf9323e,Fixing tests and style.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:42:03.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml_framework.py', 'test/mocks/ingestors.py', 'test/config/test_create_components.py', 'main/sink/kafka_sink.py', 'test/mocks/aggregator.py', 'test/data_agregator/test_concatenation_aggregator.py', 'main/spark/driver.py', 'test/config/test_connections.py', 'test/voter/test_base_voter.py', 'test/source/test_base_source.py', 'test/source/test_file_source.py', 'test/data_ingestion/test_base_data_ingestor.py', 'test/mocks/ml_mocks.py', 'test/source/test_kafka_source.py', 'test/config/__init__.py', 'test/source/test_markov_chain_source.py', 'test/spark/__init__.py', 'test/mocks/sources.py', 'test/spark/test_driver.py', 'test/test_ml_framework.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/2f95f4f27f59d8641e43891fcffb828cc6a54a22', 'message': 'Fixing tests and style.\n\nChange-Id: I8f885f4d1c5b10a90de35c95d225b45feaf9323e\n'}]",0,313409,2f95f4f27f59d8641e43891fcffb828cc6a54a22,3,1,1,21739,,,0,"Fixing tests and style.

Change-Id: I8f885f4d1c5b10a90de35c95d225b45feaf9323e
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/09/313409/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ml_framework.py', 'test/mocks/ingestors.py', 'test/config/test_create_components.py', 'main/sink/kafka_sink.py', 'test/mocks/aggregator.py', 'test/data_agregator/test_concatenation_aggregator.py', 'main/spark/driver.py', 'test/config/test_connections.py', 'test/voter/test_base_voter.py', 'test/source/test_base_source.py', 'test/source/test_file_source.py', 'test/data_ingestion/test_base_data_ingestor.py', 'test/mocks/ml_mocks.py', 'test/source/test_kafka_source.py', 'test/config/__init__.py', 'test/source/test_markov_chain_source.py', 'test/spark/__init__.py', 'test/mocks/sources.py', 'test/spark/test_driver.py', 'test/test_ml_framework.py']",20,2f95f4f27f59d8641e43891fcffb828cc6a54a22,,import main.spark.driver as driver self.original_SparkContext = driver.SparkContext self.original_StreamingContext = driver.StreamingContext driver.SparkContext = self.original_SparkContext driver.StreamingContext = self.original_StreamingContext driver.SparkContext = MockSparkContext driver.StreamingContext = MockStreamingContext,"import main.config.validation as mod self.original_validate_config_file = ml.MLFramework.\ _validate_config_file self.original_get_class_by_name = cu.get_class_by_name self.original_SparkContext = ml.SparkContext self.original_StreamingContext = ml.StreamingContext ml.MLFramework._validate_config_file =\ self.original_validate_config_file cu.get_class_by_name = self.original_get_class_by_name ml.SparkContext = self.original_SparkContext ml.StreamingContext = self.original_StreamingContext ml.MLFramework._validate_config_file = ml_mocks.ml_mocks.\ mock_validate_config_file cu.get_class_by_name = ml_mocks.mock_get_class_by_name ml.SparkContext = MockSparkContext ml.StreamingContext = MockStreamingContext def assert_got_classes_by_name_once(self): self.assertEqual(9, len(ml_mocks.ml_mocks.classes_got_by_name)) self.assertIn([""src_module1"", mod.SOURCES], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""src_module2"", mod.SOURCES], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""ingestor_module"", mod.INGESTORS], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""aggr_module"", mod.AGGREGATORS], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""learner_module"", mod.LEARNERS], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""voter_module"", mod.VOTERS], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""sink_module1"", mod.SINKS], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""sink_module2"", mod.SINKS], ml_mocks.ml_mocks.classes_got_by_name) self.assertIn([""transformer_module1"", mod.TRANSFORMERS], ml_mocks.ml_mocks.classes_got_by_name) def assert_instantiated_classes_once(self): for n in ml_mocks.ml_mocks.instantiated.keys(): self.assertEqual(1, len(ml_mocks.ml_mocks.instantiated[n])) def assert_instantiated_no_classes(self): for n in ml_mocks.ml_mocks.instantiated.keys(): self.assertEqual(0, len(ml_mocks.ml_mocks.instantiated[n])) def assert_only_instantiated(self, name): self.assertEqual(1, len(ml_mocks.ml_mocks.instantiated[name])) for n in ml_mocks.ml_mocks.instantiated.keys(): if n != name: self.assertEqual(0, len(ml_mocks.ml_mocks.instantiated[n])) def test_ml_framework_orchestration_at_creation(self): """""" Tests that the ML_Framework constructor checks the config json file, gets all the modules classes by name and instantiates them. """""" self.assert_got_classes_by_name_once() self.assert_instantiated_classes_once() self.assertTrue(ml_mocks.ml_mocks.config_validated) def test_create_component_by_module(self): ml_mocks.ml_mocks.reset() component_id = ""ing1"" component_config = {""module"": ""ingestor_module"", ""sink_id"": 1} self.mlf._create_component_by_module(component_id, component_config, ""data_ingestors"") self.assert_only_instantiated(""ingestor_module"") def test_create_component_by_module_inexistent_module(self): ml_mocks.ml_mocks.reset() component_id = ""inex1"" component_config = {""module"": ""inexistent_module""} self.assertRaises( err.MlfNoSuchClassError, self.mlf._create_component_by_module, component_id, component_config, ""data_ingestors"") self.assert_instantiated_no_classes() def test_create_components_by_module(self): ml_mocks.ml_mocks.reset() self.mlf._create_components_by_module(mod.AGGREGATORS) self.assert_only_instantiated(""aggr_module"") def test_create_components_by_module_inexistent1(self): ml_mocks.ml_mocks.reset() self.mlf._config[""voter""] = {""inex1"": {""module"": ""inexistent_voter""}} self.mlf._create_components_by_module(""voter"") self.assert_instantiated_no_classes() def test_create_components_by_module_inexistent2(self): ml_mocks.ml_mocks.reset() self.mlf._config[""data_ingestors""] = { ""inex2"": {""module"": ""inexistent_ingestor"", ""param"": {}} } self.mlf._create_components_by_module(""data_ingestors"") self.assert_instantiated_no_classes() def test_create_components_by_module_mixed_existance(self): ml_mocks.ml_mocks.reset() self.mlf._config[mod.INGESTORS][""inex2""] =\ {""module"": ""inexistent_ingestor"", ""params"": {}} self.mlf._create_components_by_module(mod.INGESTORS) self.assert_only_instantiated(""ingestor_module"") def assert_src_ingestors_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""ingestor_module""], ml_mocks.ml_mocks.instantiated[""src_module1""][0]._ingestors) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""src_module1""][0]._ingestors) def assert_src_transformers_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""transformer_module1""], ml_mocks.ml_mocks.instantiated[ ""src_module1""][0]._transformers) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[ ""src_module1""][0]._transformers) def assert_ingestors_aggregator_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""aggr_module""][0], ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]._aggregator) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""ingestor_module""][0]._aggregator) def assert_ingestors_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""ingestor_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""ingestor_module""][0]._sinks) def assert_aggregator_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._sinks) def assert_aggregator_learners_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""learner_module""], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._learners) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""aggr_module""][0]._learners) def assert_learners_aggregator_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._aggregator, ml_mocks.MockClass_aggr_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._aggregator) def assert_learners_voter_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._voter, ml_mocks.MockClass_voter_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[ ""learner_module""][0]._voter) def assert_learners_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""learner_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""learner_module""][0]._sinks) def assert_voter_transformers_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""transformer_module1""], ml_mocks.ml_mocks.instantiated[ ""voter_module""][0]._transformers) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[ ""voter_module""][0]._transformers) def assert_voter_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module1""], ml_mocks.ml_mocks.instantiated[""voter_module""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""voter_module""][0]._sinks) def assert_transformers_sinks_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""sink_module2""], ml_mocks.ml_mocks.instantiated[ ""transformer_module1""][0]._sinks) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[ ""transformer_module1""][0]._sinks) def assert_sinks_learners_connection(self, connected=True): if connected: self.assertEqual( ml_mocks.ml_mocks.instantiated[""learner_module""], ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._learners) else: self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._learners) self.assertEqual( [], ml_mocks.ml_mocks.instantiated[""sink_module2""][0]._learners) def assert_sinks_voter_connection(self, connected=True): if connected: self.assertTrue(isinstance(ml_mocks.ml_mocks.instantiated[ ""sink_module2""][0]._voter, ml_mocks.MockClass_voter_module)) else: self.assertEqual( None, ml_mocks.ml_mocks.instantiated[""sink_module2""][0]._voter) self.assertEqual( None, ml_mocks.ml_mocks.instantiated[""sink_module1""][0]._voter) def test_all_connections(self): self.assert_src_ingestors_connection(True) self.assert_src_transformers_connection(True) self.assert_ingestors_aggregator_connection(True) self.assert_ingestors_sinks_connection(True) self.assert_aggregator_sinks_connection(True) self.assert_aggregator_learners_connection(True) self.assert_learners_aggregator_connection(True) self.assert_learners_voter_connection(True) self.assert_learners_sinks_connection(True) self.assert_voter_sinks_connection(True) self.assert_voter_transformers_connection(True) self.assert_transformers_sinks_connection(True) self.assert_sinks_learners_connection(True) self.assert_sinks_voter_connection(True) def test_data_connections(self): ml_mocks.ml_mocks.reset_connections() self.mlf.perform_data_connections() self.assert_src_ingestors_connection(True) self.assert_src_transformers_connection(True) self.assert_ingestors_aggregator_connection(True) self.assert_ingestors_sinks_connection(True) self.assert_aggregator_sinks_connection(True) self.assert_aggregator_learners_connection(True) self.assert_learners_aggregator_connection(True) self.assert_learners_voter_connection(True) self.assert_learners_sinks_connection(True) self.assert_voter_sinks_connection(True) self.assert_voter_transformers_connection(True) self.assert_transformers_sinks_connection(True) self.assert_sinks_learners_connection(False) self.assert_sinks_voter_connection(False) def test_feedback_connections(self): ml_mocks.ml_mocks.reset_connections() self.mlf.perform_feedback_connections() self.assert_src_ingestors_connection(False) self.assert_src_transformers_connection(False) self.assert_ingestors_aggregator_connection(False) self.assert_ingestors_sinks_connection(False) self.assert_aggregator_sinks_connection(False) self.assert_aggregator_learners_connection(False) self.assert_learners_aggregator_connection(False) self.assert_learners_voter_connection(False) self.assert_learners_sinks_connection(False) self.assert_voter_sinks_connection(False) self.assert_voter_transformers_connection(False) self.assert_transformers_sinks_connection(False) self.assert_sinks_learners_connection(True) self.assert_sinks_voter_connection(True) def assert_bound_src1(self, bound=True): if bound: self.assertIn(""src1"", self.mlf._bound_source_ids) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module1""][0].unbind_cnt) else: self.assertEqual( 0, ml_mocks.ml_mocks.instantiated[""src_module1""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module1""][0].unbind_cnt) def assert_bound_src2(self, bound=True): if bound: self.assertIn(""src2"", self.mlf._bound_source_ids) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module2""][0].unbind_cnt) else: self.assertEqual( 0, ml_mocks.ml_mocks.instantiated[""src_module2""][0].bind_cnt - ml_mocks.ml_mocks.instantiated[""src_module2""][0].unbind_cnt) def test_bind_sources(self): self.mlf._bind_sources() self.assertEqual(2, len(ml_mocks.ml_mocks.bound_sources)) self.assertIn(ml_mocks.ml_mocks.instantiated[""src_module1""][0], ml_mocks.ml_mocks.bound_sources) self.assertIn(ml_mocks.ml_mocks.instantiated[""src_module2""][0], ml_mocks.ml_mocks.bound_sources) self.assertEqual(2, len(self.mlf._bound_source_ids)) self.assert_bound_src1(True) self.assert_bound_src2(True) def test_unbind_sources(self): self.mlf._bind_sources() self.mlf._unbind_sources() self.assertEqual([], ml_mocks.ml_mocks.bound_sources) self.assertEqual(0, len(self.mlf._bound_source_ids)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].unbind_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].unbind_cnt) def test_terminate_sources(self): self.mlf._terminate_sources() self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) def test_add_sources(self): # TODO test when implemented pass def test_remove_sources(self): # todo test when implemented pass self.assert_bound_src1(True) self.assert_bound_src2(True) self.assertEqual(1, self.mlf._ssc.started_cnt) self.assert_bound_src1(False) self.assert_bound_src2(False) self.assertEqual(None, self.mlf._sc) self.assertEqual(None, self.mlf._ssc) ssc = self.mlf._ssc self.assert_stopped_streaming_state(ssc) ssc = self.mlf._ssc self.assert_stopped_streaming_state(ssc) self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) ssc = self.mlf._ssc self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) self.assert_stopped_streaming_state(ssc) ssc = self.mlf._ssc self.assertEqual(2, len(ml_mocks.ml_mocks.terminated_sources)) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module1""][0].terminate_cnt) self.assertEqual( 1, ml_mocks.ml_mocks.instantiated[""src_module2""][0].terminate_cnt) self.assert_stopped_streaming_state(ssc)",469,513
openstack%2Fmonasca-analytics~master~I7a6c13af0d01c7dd3f421c35c46a672d9ad5c4bb,openstack/monasca-analytics,master,I7a6c13af0d01c7dd3f421c35c46a672d9ad5c4bb,Fix a recursive dependency preventing the project to start. Also add a regression test.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:59.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/kafkas.py', 'main/component/base.py', 'test/sink/test_kafka.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ff141144e4910aabb70f7319c13fbd0d50bcfbf0', 'message': 'Fix a recursive dependency preventing the project to start. Also add a regression test.\n\nChange-Id: I7a6c13af0d01c7dd3f421c35c46a672d9ad5c4bb\n'}]",0,313417,ff141144e4910aabb70f7319c13fbd0d50bcfbf0,3,1,1,21739,,,0,"Fix a recursive dependency preventing the project to start. Also add a regression test.

Change-Id: I7a6c13af0d01c7dd3f421c35c46a672d9ad5c4bb
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/17/313417/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/sink/kafkas.py', 'main/component/base.py', 'test/sink/test_kafka.py']",3,ff141144e4910aabb70f7319c13fbd0d50bcfbf0,,"# This file is name kafkas otherwise it will conflict # with the global import 'kafka' import main.sink.kafkas as kf class MockedKafka(object): def __init__(self): self.has_been_called = False def KafkaProducer(self, *_, **kwargs): self.has_been_called = True self.mock_kafka = MockedKafka() self.original_kafka = kf.kafka kf.kafka = self.mock_kafka def testKafkaSinkInit(self): kf.KafkaSink(""id"", { ""module"": ""KafkaSink"", ""params"": { ""host"": ""localhost"", ""port"": 00, ""topic"": ""boom"", } }) self.assertTrue(self.mock_kafka) kf.kafka = self.original_kafka", def testKafkaSinkInit(self): pass,25,2
openstack%2Fmonasca-analytics~master~Ib61980ed661b3ccf9aa227caeaca8f4db787d9d2,openstack/monasca-analytics,master,Ib61980ed661b3ccf9aa227caeaca8f4db787d9d2,Fix a bug causing the algorithm to fail prematurely.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:56.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ml/lingam.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/4df1f8e2d3d8b1c4428c38c887d3aff77e2a632a', 'message': 'Fix a bug causing the algorithm to fail prematurely.\n\nChange-Id: Ib61980ed661b3ccf9aa227caeaca8f4db787d9d2\n'}]",0,313419,4df1f8e2d3d8b1c4428c38c887d3aff77e2a632a,3,1,1,21739,,,0,"Fix a bug causing the algorithm to fail prematurely.

Change-Id: Ib61980ed661b3ccf9aa227caeaca8f4db787d9d2
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/19/313419/1 && git format-patch -1 --stdout FETCH_HEAD,['main/ml/lingam.py'],1,4df1f8e2d3d8b1c4428c38c887d3aff77e2a632a,," def __init__(self, _id, _config): super(LiNGAM, self).__init__(_id, _config) self._threshold = 0.1 def validate_config(self, _config): Schema({ self._threshold = _config[""params""][""threshold""] threshold = self._threshold"," def validate_config(self, _config): return Schema({ threshold = self._config[""params""][""threshold""]",7,2
openstack%2Fmonasca-analytics~master~I7dcfc93ec57afec8bf01584afd43f5a23b7cac53,openstack/monasca-analytics,master,I7dcfc93ec57afec8bf01584afd43f5a23b7cac53,added unit tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:53.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/util/test_common_util.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/a01f3758e94bfd1e111f6d03bd345ba9cc41b059', 'message': 'added unit tests\n\nChange-Id: I7dcfc93ec57afec8bf01584afd43f5a23b7cac53\n'}]",0,313427,a01f3758e94bfd1e111f6d03bd345ba9cc41b059,3,1,1,21739,,,0,"added unit tests

Change-Id: I7dcfc93ec57afec8bf01584afd43f5a23b7cac53
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/27/313427/1 && git format-patch -1 --stdout FETCH_HEAD,['test/util/test_common_util.py'],1,a01f3758e94bfd1e111f6d03bd345ba9cc41b059,,"from main.config import const from main.exception.mlf import MonanasNoSuchClassError def test_get_class_by_name(self): common_util.get_class_by_name(""RandomSource"", const.SOURCES) def test_get_class_by_name_no_such_class(self): self.assertRaises(MonanasNoSuchClassError, common_util.get_class_by_name, ""InventedSource"", const.SOURCES) ",,11,0
openstack%2Fmonasca-analytics~master~I96a8151881479d88bc217b9ca972fc20f30c0cb4,openstack/monasca-analytics,master,I96a8151881479d88bc217b9ca972fc20f30c0cb4,Add awaitTermination to MockStreamingContext.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:50.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/spark_mocks.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/fb5a9ce6f2d5c0164535ee46fa0f215eac4dbf88', 'message': 'Add awaitTermination to MockStreamingContext.\n\nChange-Id: I96a8151881479d88bc217b9ca972fc20f30c0cb4\n'}]",0,313434,fb5a9ce6f2d5c0164535ee46fa0f215eac4dbf88,2,0,1,21739,,,0,"Add awaitTermination to MockStreamingContext.

Change-Id: I96a8151881479d88bc217b9ca972fc20f30c0cb4
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/34/313434/1 && git format-patch -1 --stdout FETCH_HEAD,['test/mocks/spark_mocks.py'],1,fb5a9ce6f2d5c0164535ee46fa0f215eac4dbf88,, def awaitTermination(self): self.stopped_cnt += 1 ,,3,0
openstack%2Fmonasca-analytics~master~I058820b7c1895d0360a2f6cc0d4fc36f094934b2,openstack/monasca-analytics,master,I058820b7c1895d0360a2f6cc0d4fc36f094934b2,"Added iptables_anomalies config file, source and ingestor code. The source creates a markov chain to generate traffic in different states, and the ingestor does a pprint of the stream",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:46.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'main/source/kafka.py', 'config/iptables_anomalies.json', 'main/source/file.py', 'main/ingestor/iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/9cdc43194590bd0008e5c8208057e787dde65c14', 'message': 'Added iptables_anomalies config file, source and ingestor code. The source creates a markov chain to generate traffic in different states, and the ingestor does a pprint of the stream\n\nChange-Id: I058820b7c1895d0360a2f6cc0d4fc36f094934b2\n'}]",0,313435,9cdc43194590bd0008e5c8208057e787dde65c14,2,0,1,21739,,,0,"Added iptables_anomalies config file, source and ingestor code. The source creates a markov chain to generate traffic in different states, and the ingestor does a pprint of the stream

Change-Id: I058820b7c1895d0360a2f6cc0d4fc36f094934b2
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/35/313435/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'main/source/kafka.py', 'config/iptables_anomalies.json', 'main/source/file.py', 'main/ingestor/iptables_ingestor.py']",5,9cdc43194590bd0008e5c8208057e787dde65c14,,"#!/usr/bin/env python import logging from schema import And, Schema from main.ingestor.base import BaseIngestor logger = logging.getLogger(__name__) class IptablesIngestor(BaseIngestor): def validate_config(self, _config): return Schema({ ""module"": And(basestring, lambda i: not any(c.isspace() for c in i)) }).validate(_config) def map_dstream(self, dstream): dstream.pprint() ",,220,2
openstack%2Fmonasca-analytics~master~Ie9caa663a4ca67c6fec7c19690835796f9cf8d42,openstack/monasca-analytics,master,Ie9caa663a4ca67c6fec7c19690835796f9cf8d42,Real fix for shutting down the TCP handler.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:43.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/markov_chain/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/08036f2563f21a7bf8cae486d34fcd3505149d18', 'message': 'Real fix for shutting down the TCP handler.\n\nChange-Id: Ie9caa663a4ca67c6fec7c19690835796f9cf8d42\n'}]",0,313432,08036f2563f21a7bf8cae486d34fcd3505149d18,2,0,1,21739,,,0,"Real fix for shutting down the TCP handler.

Change-Id: Ie9caa663a4ca67c6fec7c19690835796f9cf8d42
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/32/313432/1 && git format-patch -1 --stdout FETCH_HEAD,['main/source/markov_chain/base.py'],1,08036f2563f21a7bf8cae486d34fcd3505149d18,, self._server.terminate = True self._server.shutdown() self._server_thread.join(0.1) while not self.server.terminate:, self._server.terminate = True self._server_thread.join(0.2) while True and not self.server.terminate:,4,3
openstack%2Fmonasca-analytics~master~I3cc7b9bf75fb78d0e131bf5dc00743199ba0fa0c,openstack/monasca-analytics,master,I3cc7b9bf75fb78d0e131bf5dc00743199ba0fa0c,error handling logic moved to config.py instead of driver.py,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/config/config.py', 'main/spark/driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/64d13fe706a257930aa3f19f4388eaddc6579edb', 'message': 'error handling logic moved to config.py instead of driver.py\n\nChange-Id: I3cc7b9bf75fb78d0e131bf5dc00743199ba0fa0c\n'}]",0,313429,64d13fe706a257930aa3f19f4388eaddc6579edb,3,1,1,21739,,,0,"error handling logic moved to config.py instead of driver.py

Change-Id: I3cc7b9bf75fb78d0e131bf5dc00743199ba0fa0c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/29/313429/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/config/config.py', 'main/spark/driver.py']",2,64d13fe706a257930aa3f19f4388eaddc6579edb,, self._links = config.instantiate_components(_config),"import sys try: self._links = config.instantiate_components(_config) except Exception as e: logger.error(""Failed to instantiate components"") logger.error(""Reason : "" + str(e)) sys.exit(-1)",13,18
openstack%2Fmonasca-analytics~master~I4e7e38830c43a218cd5c1782a48dc74a5f70d6a5,openstack/monasca-analytics,master,I4e7e38830c43a218cd5c1782a48dc74a5f70d6a5,fixed pep8,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:37.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source/test_iptables_markov_chain.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b21a7d1283fa9081006c6c1ea4690901d26df32b', 'message': 'fixed pep8\n\nChange-Id: I4e7e38830c43a218cd5c1782a48dc74a5f70d6a5\n'}]",0,313437,b21a7d1283fa9081006c6c1ea4690901d26df32b,2,0,1,21739,,,0,"fixed pep8

Change-Id: I4e7e38830c43a218cd5c1782a48dc74a5f70d6a5
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/37/313437/1 && git format-patch -1 --stdout FETCH_HEAD,['test/source/test_iptables_markov_chain.py'],1,b21a7d1283fa9081006c6c1ea4690901d26df32b,,,,0,1
openstack%2Fmonasca-analytics~master~Ic24a3312f3868ef94dd2149e82af889f10206378,openstack/monasca-analytics,master,Ic24a3312f3868ef94dd2149e82af889f10206378,Change example to a more interesting scenario.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:34.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['fetch-deps.sh', 'config/markov_source_config.json', 'main/spark/driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/0f7c90f9a7953cfd003c965ec2e59e221acef5f3', 'message': 'Change example to a more interesting scenario.\n\nThis commit also change the `fetch-deps.sh` script where there was\na problem when trying to set up the vm.\n\nChange-Id: Ic24a3312f3868ef94dd2149e82af889f10206378\n'}]",0,313442,0f7c90f9a7953cfd003c965ec2e59e221acef5f3,2,0,1,21739,,,0,"Change example to a more interesting scenario.

This commit also change the `fetch-deps.sh` script where there was
a problem when trying to set up the vm.

Change-Id: Ic24a3312f3868ef94dd2149e82af889f10206378
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/42/313442/1 && git format-patch -1 --stdout FETCH_HEAD,"['fetch-deps.sh', 'config/markov_source_config.json', 'main/spark/driver.py']",3,0f7c90f9a7953cfd003c965ec2e59e221acef5f3,," logger.debug(""Phase 2: Stop SparkStreamingContext."") self._ssc.stop(False, False)"," logger.debug(""Phase 2: Stop SparkStreamingContext."") self._ssc.stop(False, False) logger.debug(""Phase 2: Await termination."") self._ssc.awaitTermination()",13,14
openstack%2Fmonasca-analytics~master~I9f8401f0bfba07a152033ad248501259127b54be,openstack/monasca-analytics,master,I9f8401f0bfba07a152033ad248501259127b54be,"removed time zone dependency, assuming the times are in UTC",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:31.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/cd65034a74af92761da19c49cd72a415d74cd17c', 'message': 'removed time zone dependency, assuming the times are in UTC\n\nChange-Id: I9f8401f0bfba07a152033ad248501259127b54be\n'}]",0,313447,cd65034a74af92761da19c49cd72a415d74cd17c,2,0,1,21739,,,0,"removed time zone dependency, assuming the times are in UTC

Change-Id: I9f8401f0bfba07a152033ad248501259127b54be
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/47/313447/1 && git format-patch -1 --stdout FETCH_HEAD,['test/ingestor/test_iptables_ingestor.py'],1,cd65034a74af92761da19c49cd72a415d74cd17c,,,<<<<<<< HEAD======= 1460401152])) >>>>>>> 11afbe4... added timestamp in the test,0,4
openstack%2Fmonasca-analytics~master~I36d130873255f30bc608ae35b38a30fc94f3a3bf,openstack/monasca-analytics,master,I36d130873255f30bc608ae35b38a30fc94f3a3bf,stopping sources before stopping streaming context in move_to_phase2,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:23.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/spark/driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/fa3ede41b49e2af8b2f25ff6e5b3e544b3bac18d', 'message': 'stopping sources before stopping streaming context in move_to_phase2\n\nChange-Id: I36d130873255f30bc608ae35b38a30fc94f3a3bf\n'}]",0,313449,fa3ede41b49e2af8b2f25ff6e5b3e544b3bac18d,2,0,1,21739,,,0,"stopping sources before stopping streaming context in move_to_phase2

Change-Id: I36d130873255f30bc608ae35b38a30fc94f3a3bf
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/49/313449/1 && git format-patch -1 --stdout FETCH_HEAD,['main/spark/driver.py'],1,fa3ede41b49e2af8b2f25ff6e5b3e544b3bac18d,," logger.debug(""Phase 2: Stop sources"") self._terminate_sources()"," logger.debug(""Phase 2: Stop sources"") self._terminate_sources()",2,2
openstack%2Fmonasca-analytics~master~I3c70f44d5811fc56c6b0c592f96f919219c1afce,openstack/monasca-analytics,master,I3c70f44d5811fc56c6b0c592f96f919219c1afce,"made validate_config abtract and static in the base component class, and static in all the implementations",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:19.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'main/sink/kafkas.py', 'main/voter/pick_index.py', 'test/mocks/ingestors.py', 'main/component/base.py', 'test/resources/test_json.json', 'main/source/cloud_markov_chain.py', 'main/source/file.py', 'test/util/test_common_util.py', 'main/ingestor/iptables_ingestor.py', 'test/voter/test_base_voter.py', 'test/source/test_base.py', 'main/source/kafka.py', 'test/mocks/sml_mocks.py', 'main/config/dsl.py', 'main/ldp/cloud_causality.py', 'test/config/test_dsl.py', 'main/source/markov_chain/base.py', 'main/ingestor/cloud.py', 'main/sml/lingam.py', 'main/source/random.py', 'test/mocks/sources.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/a9b8ed1b667292b80313e26cf11b3e93c8a4156a', 'message': 'made validate_config abtract and static in the base component class, and static in all the implementations\n\nChange-Id: I3c70f44d5811fc56c6b0c592f96f919219c1afce\n'}]",0,313451,a9b8ed1b667292b80313e26cf11b3e93c8a4156a,2,0,1,21739,,,0,"made validate_config abtract and static in the base component class, and static in all the implementations

Change-Id: I3c70f44d5811fc56c6b0c592f96f919219c1afce
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/51/313451/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'main/sink/kafkas.py', 'main/voter/pick_index.py', 'test/mocks/ingestors.py', 'main/component/base.py', 'test/resources/test_json.json', 'main/source/cloud_markov_chain.py', 'main/source/file.py', 'test/util/test_common_util.py', 'main/ingestor/iptables_ingestor.py', 'test/voter/test_base_voter.py', 'test/source/test_base.py', 'main/source/kafka.py', 'test/mocks/sml_mocks.py', 'main/config/dsl.py', 'main/ldp/cloud_causality.py', 'test/config/test_dsl.py', 'main/source/markov_chain/base.py', 'main/ingestor/cloud.py', 'main/sml/lingam.py', 'main/source/random.py', 'test/mocks/sources.py']",22,a9b8ed1b667292b80313e26cf11b3e93c8a4156a,," validation_cnt = 0 def __init__(self, _id, _config): MockBaseSource.validation_cnt = 0 @staticmethod def validate_config(_config): MockBaseSource.validation_cnt += 1"," def __init__(self, _id, _config): self.validation_cnt = 0 def validate_config(self, _config): self.validation_cnt += 1",107,59
openstack%2Fmonasca-analytics~master~Ida49bf6c23ed21025b91848c33b6197212477e00,openstack/monasca-analytics,master,Ida49bf6c23ed21025b91848c33b6197212477e00,added timestamp in the test,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:15.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/bfeeea207e81400cee36a72572e78406629ee5ba', 'message': 'added timestamp in the test\n\nChange-Id: Ida49bf6c23ed21025b91848c33b6197212477e00\n'}]",0,313446,bfeeea207e81400cee36a72572e78406629ee5ba,2,0,1,21739,,,0,"added timestamp in the test

Change-Id: Ida49bf6c23ed21025b91848c33b6197212477e00
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/46/313446/1 && git format-patch -1 --stdout FETCH_HEAD,['test/ingestor/test_iptables_ingestor.py'],1,bfeeea207e81400cee36a72572e78406629ee5ba,,<<<<<<< HEAD======= 1460401152])) >>>>>>> 11afbe4... added timestamp in the test,,4,0
openstack%2Fmonasca-analytics~master~I116bcd9e0baee7ce88e998ae9606524d36a8ffd3,openstack/monasca-analytics,master,I116bcd9e0baee7ce88e998ae9606524d36a8ffd3,throwing exception on unimplemented methods,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:41:11.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'main/source/kafka.py', 'main/source/file.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/8ee1c5e7fdbb692f614921cda527cf59149af4b5', 'message': 'throwing exception on unimplemented methods\n\nChange-Id: I116bcd9e0baee7ce88e998ae9606524d36a8ffd3\n'}]",0,313438,8ee1c5e7fdbb692f614921cda527cf59149af4b5,2,0,1,21739,,,0,"throwing exception on unimplemented methods

Change-Id: I116bcd9e0baee7ce88e998ae9606524d36a8ffd3
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/38/313438/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'main/source/kafka.py', 'main/source/file.py']",3,8ee1c5e7fdbb692f614921cda527cf59149af4b5,," raise NotImplementedError(""This method needs to be implemented"")"," logger.debug("" FileSource using directory : "" + self._config[""params""][""directory""]) pass",3,5
openstack%2Fdjango_openstack_auth~master~I6a947abb891e1d34e1cf3aea53b345e0a804bacf,openstack/django_openstack_auth,master,I6a947abb891e1d34e1cf3aea53b345e0a804bacf,"When calculating session_time, use the actual token life",MERGED,2016-03-27 04:45:37.000000000,2016-05-11 16:37:21.000000000,2016-05-11 16:37:21.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 10063}, {'_account_id': 12826}, {'_account_id': 12932}, {'_account_id': 14124}]","[{'number': 1, 'created': '2016-03-27 04:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/7adb8d29f4cf72b73b4681da705ea9578b02a418', 'message': ""When calculating session_time, use the actual token life.\n\nThis calculation uses the 'token_life' var which is a datetime.timedelta\nobject.  timedelta.seconds gets us just the 'seconds' component of the\nobject, truncating away any days, hours, or weeks that might be included\nin the object.\n\nWhat we want here is the total time in seconds, which is total_seconds().\n\nCloses-Bug: #1562452\nChange-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf\n""}, {'number': 2, 'created': '2016-03-27 04:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/12312f79b081289446794ab2a761d23297c1e3cb', 'message': ""When calculating session_time, use the actual token life.\n\nThis calculation uses the 'token_life' var which is a\ndatetime.timedelta object.  timedelta.seconds gets us just the\n'seconds' component of the object, truncating away any days, hours,\nor weeks that might be included in the object.\n\nWhat we want here is the total time in seconds, which is\ntotal_seconds().\n\nCloses-Bug: #1562452\nChange-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf\n""}, {'number': 3, 'created': '2016-03-27 14:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/ffc636e416825d86c693fe1be806b5d051bb9b86', 'message': ""When calculating session_time, use the actual token life.\n\nThis calculation uses the 'token_life' var which is a\ndatetime.timedelta object.  timedelta.seconds gets us just the\n'seconds' component of the object, truncating away any days, hours,\nor weeks that might be included in the object.\n\nWhat we want here is the total time in seconds, which is\ntotal_seconds().\n\nCloses-Bug: #1562452\nChange-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf\n""}, {'number': 4, 'created': '2016-03-29 03:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/91e1d50233c18642e99957cbfbf966a14a4e58bb', 'message': ""When calculating session_time, use the actual token life\n\nThis calculation uses the 'token_life' var which is a\ndatetime.timedelta object.  timedelta.seconds gets us just the\n'seconds' component of the object, truncating away any days, hours,\nor weeks that might be included in the object.\n\nWhat we want here is the total time in seconds, which is\ntotal_seconds().\n\nCloses-Bug: #1562452\nChange-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf\n""}, {'number': 5, 'created': '2016-03-29 14:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/febfe80eebca0fa1412ad52217153b7a985d6730', 'message': ""When calculating session_time, use the actual token life\n\nThis calculation uses the 'token_life' var which is a\ndatetime.timedelta object.  timedelta.seconds gets us just the\n'seconds' component of the object, truncating away any days, hours,\nor weeks that might be included in the object.\n\nWhat we want here is the total time in seconds, which is\ntotal_seconds().\n\nCloses-Bug: #1562452\nChange-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf\n""}, {'number': 6, 'created': '2016-03-29 16:16:52.000000000', 'files': ['openstack_auth/backend.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/d7a2dce59d95979fb3d4ae5cdac9fd063c09d88d', 'message': ""When calculating session_time, use the actual token life\n\nThis calculation uses the 'token_life' var which is a\ndatetime.timedelta object.  timedelta.seconds gets us just the\n'seconds' component of the object, truncating away any days, hours,\nor weeks that might be included in the object.\n\nWhat we want here is the total time in seconds, which is\ntotal_seconds().\n\nCloses-Bug: #1562452\nChange-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf\n""}]",5,298002,d7a2dce59d95979fb3d4ae5cdac9fd063c09d88d,31,7,6,12932,,,0,"When calculating session_time, use the actual token life

This calculation uses the 'token_life' var which is a
datetime.timedelta object.  timedelta.seconds gets us just the
'seconds' component of the object, truncating away any days, hours,
or weeks that might be included in the object.

What we want here is the total time in seconds, which is
total_seconds().

Closes-Bug: #1562452
Change-Id: I6a947abb891e1d34e1cf3aea53b345e0a804bacf
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/02/298002/5 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/backend.py'],1,7adb8d29f4cf72b73b4681da705ea9578b02a418,bug/1562452," session_time = min(timeout, token_life.total_seconds())"," session_time = min(timeout, token_life.seconds)",1,1
openstack%2Fmurano-apps~master~Iaf75ec38b133d45778bb1c0f3328e939a9a54bda,openstack/murano-apps,master,Iaf75ec38b133d45778bb1c0f3328e939a9a54bda,Fix yaql related issues in Docker apps,MERGED,2016-04-04 13:42:40.000000000,2016-05-11 16:36:15.000000000,2016-05-11 16:36:15.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-04-04 13:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/b024faa79a19551a65fa4a752ec1efafc3910371', 'message': 'Fix yaql related issues in Docker apps\n\nPartially-Implements: bp refactor-apps-scripts\n\nChange-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda\n'}, {'number': 2, 'created': '2016-04-04 13:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/e7b36b7797c6b55167fefcf957b164e5945548ea', 'message': 'Fix yaql related issues in Docker apps\n\nPartially-Implements: bp refactor-apps-scripts\n\nChange-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda\n'}, {'number': 3, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/e20325ed9f12342d98e476ece63703e9dbe14673', 'message': 'Fix yaql related issues in Docker apps\n\nPartially-Implements: bp refactor-apps-scripts\n\nChange-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda\n'}, {'number': 4, 'created': '2016-05-11 14:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/82ede4421110491db2b903f62587912277adcbee', 'message': 'Fix yaql related issues in Docker apps\n\nPartially-Implements: bp refactor-apps-scripts\n\nChange-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda\n'}, {'number': 5, 'created': '2016-05-11 16:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/511e94120adc8f9e348d58499e7ffcd3950cf352', 'message': 'Fix yaql related issues in Docker apps\n\nPartially-Implements: bp refactor-apps-scripts\n\nChange-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda\n'}, {'number': 6, 'created': '2016-05-11 16:27:06.000000000', 'files': ['Docker/Applications/Tomcat/package/Classes/DockerTomcat.yaml', 'Docker/Applications/Redis/package/Classes/DockerRedis.yaml', 'Docker/Applications/Grafana/package/Classes/DockerGrafana.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesGatewayNode.yaml', 'Docker/DockerStandaloneHost/package/Classes/DockerStandaloneHost.yaml', 'Docker/Kubernetes/KubernetesPod/package/Classes/KubernetesPod.yaml', 'Docker/Applications/Jenkins/package/Classes/DockerJenkins.yaml', 'Docker/Applications/NginxSite/package/Classes/DockerNginxSite.yaml', 'Docker/Applications/MongoDB/package/Classes/DockerMongoDB.yaml', 'Docker/Applications/Nginx/package/Classes/DockerNginx.yaml', 'Docker/Applications/MySQL/package/Classes/DockerMySQL.yaml', 'Docker/Applications/GlassFish/package/Classes/DockerGlassFish.yaml', 'Docker/Applications/GuestBook/package/Classes/RedisSlave.yaml', 'Docker/DockerInterfacesLibrary/package/Classes/DockerHelpers.yaml', 'Docker/Applications/JBoss/package/Classes/DockerJBoss.yaml', 'Docker/Applications/MariaDB/package/Classes/DockerMariaDB.yaml', 'Docker/Applications/HTTPdServer/package/Classes/DockerHTTPd.yaml', 'Docker/Applications/DockerApp/package/Classes/DockerApp.yaml', 'Docker/Applications/Crate/package/Classes/DockerCrate.yaml', 'Docker/Applications/Elasticsearch/package/Classes/DockerElasticsearch.yaml', 'Docker/Applications/HTTPdSite/package/Classes/DockerHTTPdSite.yaml', 'Docker/Applications/InfluxDB/package/Classes/DockerInfluxDB.yaml', 'Docker/Applications/PostgreSQL/package/Classes/DockerPostgreSQL.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesMinionNode.yaml', 'Docker/Applications/Orion/package/Classes/DockerOrion.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesCluster.yaml', 'Docker/Applications/GuestBook/package/Classes/GuestBook.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesMasterNode.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/059fa6afa085b8ad019adc9585ca43c3c0dd5a3c', 'message': 'Fix yaql related issues in Docker apps\n\nPartially-Implements: bp refactor-apps-scripts\n\nChange-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda\n'}]",0,301136,059fa6afa085b8ad019adc9585ca43c3c0dd5a3c,20,10,6,13149,,,0,"Fix yaql related issues in Docker apps

Partially-Implements: bp refactor-apps-scripts

Change-Id: Iaf75ec38b133d45778bb1c0f3328e939a9a54bda
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/36/301136/1 && git format-patch -1 --stdout FETCH_HEAD,"['Docker/Applications/Tomcat/package/Classes/DockerTomcat.yaml', 'Docker/Applications/Redis/package/Classes/DockerRedis.yaml', 'Docker/Applications/Grafana/package/Classes/DockerGrafana.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesGatewayNode.yaml', 'Docker/DockerStandaloneHost/package/Classes/DockerStandaloneHost.yaml', 'Docker/Kubernetes/KubernetesPod/package/Classes/KubernetesPod.yaml', 'Docker/Applications/Jenkins/package/Classes/DockerJenkins.yaml', 'Docker/Applications/NginxSite/package/Classes/DockerNginxSite.yaml', 'Docker/Applications/MongoDB/package/Classes/DockerMongoDB.yaml', 'Docker/Applications/Nginx/package/Classes/DockerNginx.yaml', 'Docker/Applications/MySQL/package/Classes/DockerMySQL.yaml', 'Docker/Applications/GlassFish/package/Classes/DockerGlassFish.yaml', 'Docker/Applications/GuestBook/package/Classes/RedisSlave.yaml', 'Docker/DockerInterfacesLibrary/package/Classes/DockerHelpers.yaml', 'Docker/Applications/JBoss/package/Classes/DockerJBoss.yaml', 'Docker/Applications/MariaDB/package/Classes/DockerMariaDB.yaml', 'Docker/Applications/HTTPdServer/package/Classes/DockerHTTPd.yaml', 'Docker/Applications/DockerApp/package/Classes/DockerApp.yaml', 'Docker/Applications/Crate/package/Classes/DockerCrate.yaml', 'MySQL/package/Classes/MySql.yaml', 'Docker/Applications/Elasticsearch/package/Classes/DockerElasticsearch.yaml', 'Docker/Applications/HTTPdSite/package/Classes/DockerHTTPdSite.yaml', 'Docker/Applications/InfluxDB/package/Classes/DockerInfluxDB.yaml', 'Docker/Applications/PostgreSQL/package/Classes/DockerPostgreSQL.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesMinionNode.yaml', 'Docker/Applications/Orion/package/Classes/DockerOrion.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesCluster.yaml', 'Docker/Applications/GuestBook/package/Classes/GuestBook.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesMasterNode.yaml']",29,b024faa79a19551a65fa4a752ec1efafc3910371,bp/refactor-apps-scripts," - super($, $.deployInstance())", - $.super($.deployInstance()),52,52
openstack%2Fmurano-apps~master~I85c345cc8c8c5368d9217b6dac59780767a5838d,openstack/murano-apps,master,I85c345cc8c8c5368d9217b6dac59780767a5838d,[Tomcat] Use simple software configuration,MERGED,2016-04-01 13:04:14.000000000,2016-05-11 16:35:10.000000000,2016-05-11 16:35:10.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/6398ba8111c65206f25c6784cc059b8bbfdaf1ef', 'message': '[Tomcat] Use simple software configuration\n\nChange-Id: I85c345cc8c8c5368d9217b6dac59780767a5838d\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 2, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/3ff996548be491bb0fdbd9608b5ef44a5bdf8d0a', 'message': '[Tomcat] Use simple software configuration\n\nChange-Id: I85c345cc8c8c5368d9217b6dac59780767a5838d\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 3, 'created': '2016-05-11 16:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/84659128f15f110b23e049b837ccd6007abe80f2', 'message': '[Tomcat] Use simple software configuration\n\nChange-Id: I85c345cc8c8c5368d9217b6dac59780767a5838d\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 4, 'created': '2016-05-11 16:29:32.000000000', 'files': ['Tomcat/package/Resources/DeployTomcat.template', 'Tomcat/package/Classes/Tomcat.yaml', 'Tomcat/package/Resources/deployTomcat.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/5d8802d02fbfac297d95467620e3d152c9f3ffbc', 'message': '[Tomcat] Use simple software configuration\n\nChange-Id: I85c345cc8c8c5368d9217b6dac59780767a5838d\nPartially-Implements: bp refactor-apps-scripts\n'}]",0,300470,5d8802d02fbfac297d95467620e3d152c9f3ffbc,17,4,4,13149,,,0,"[Tomcat] Use simple software configuration

Change-Id: I85c345cc8c8c5368d9217b6dac59780767a5838d
Partially-Implements: bp refactor-apps-scripts
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/70/300470/4 && git format-patch -1 --stdout FETCH_HEAD,"['Tomcat/package/Resources/DeployTomcat.template', 'Tomcat/package/Classes/Tomcat.yaml', 'Tomcat/package/Resources/deployTomcat.sh']",3,6398ba8111c65206f25c6784cc059b8bbfdaf1ef,bp/refactor-apps-scripts,,,4,34
openstack%2Fmurano-apps~master~I0c2e651965288b3551fdfbf910d119ec04677324,openstack/murano-apps,master,I0c2e651965288b3551fdfbf910d119ec04677324,[Rally] Use simple software configuration,MERGED,2016-04-01 13:04:14.000000000,2016-05-11 16:35:05.000000000,2016-05-11 16:35:05.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/679bb94ad64e3a51180c7af028d70dc472f66e6a', 'message': '[Rally] Use simple software configuration\n\nChange-Id: I0c2e651965288b3551fdfbf910d119ec04677324\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 2, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/3ef5053047cd7cac5e5738f2eb3923817daa3981', 'message': '[Rally] Use simple software configuration\n\nChange-Id: I0c2e651965288b3551fdfbf910d119ec04677324\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 3, 'created': '2016-05-11 16:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/797f23d3278ca7150c7a6b049dcd4c56597daa6d', 'message': '[Rally] Use simple software configuration\n\nChange-Id: I0c2e651965288b3551fdfbf910d119ec04677324\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 4, 'created': '2016-05-11 16:31:26.000000000', 'files': ['Rally/package/Resources/InstallRally.template', 'Rally/package/Resources/installRally.sh', 'Rally/package/Classes/Rally.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/56e0719886077359101ef7a0d728fd69a40cb58c', 'message': '[Rally] Use simple software configuration\n\nChange-Id: I0c2e651965288b3551fdfbf910d119ec04677324\nPartially-Implements: bp refactor-apps-scripts\n'}]",0,300469,56e0719886077359101ef7a0d728fd69a40cb58c,17,10,4,13149,,,0,"[Rally] Use simple software configuration

Change-Id: I0c2e651965288b3551fdfbf910d119ec04677324
Partially-Implements: bp refactor-apps-scripts
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/69/300469/1 && git format-patch -1 --stdout FETCH_HEAD,"['Rally/package/Resources/InstallRally.template', 'Rally/package/Resources/installRally.sh', 'Rally/package/Classes/Rally.yaml']",3,679bb94ad64e3a51180c7af028d70dc472f66e6a,bp/refactor-apps-scripts," conf: io.murano.configuration - $replacements: ""%REPO%"": $.repository ""%VER%"": $.version - $file: $resources.string('installRally.sh').replace($replacements) - conf:Linux.runCommand($.instance.agent, $file)"," - $template: $resources.yaml('InstallRally.template').bind(dict( repository => $.repository, version => $.version )) - $.instance.agent.call($template, $resources)",8,40
openstack%2Fmurano-apps~master~I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc,openstack/murano-apps,master,I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc,[Guacamole] Use simple software configuration,MERGED,2016-04-01 13:04:14.000000000,2016-05-11 16:34:55.000000000,2016-05-11 16:34:55.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/348c95ff6d3ce8ab16f9b62845600df60fa5d603', 'message': '[Guacamole] Use simple software configuration\n\nChange-Id: I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 2, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/0ee6ec58eac0473363755f58e827501a7410f7cb', 'message': '[Guacamole] Use simple software configuration\n\nChange-Id: I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 3, 'created': '2016-05-06 11:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/0c2801aca2bf77ae4aaa3f582e0f2afc6989bf8b', 'message': '[Guacamole] Use simple software configuration\n\nChange-Id: I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 4, 'created': '2016-05-11 16:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/bf4b69f3a266f1ff54a4700105fe0c5ba584c99e', 'message': '[Guacamole] Use simple software configuration\n\nChange-Id: I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 5, 'created': '2016-05-11 16:31:51.000000000', 'files': ['Guacamole/package/Resources/DeployGuacamole.template', 'Guacamole/package/Resources/deployGuacamole.sh', 'Guacamole/package/Classes/Guacamole.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/9cd613cdf83fa1050d425d194af3b60e2e1bb4a5', 'message': '[Guacamole] Use simple software configuration\n\nChange-Id: I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc\nPartially-Implements: bp refactor-apps-scripts\n'}]",0,300468,9cd613cdf83fa1050d425d194af3b60e2e1bb4a5,20,4,5,13149,,,0,"[Guacamole] Use simple software configuration

Change-Id: I7e3e4f59ba6d2ce425098c9b204c369dc4ede2fc
Partially-Implements: bp refactor-apps-scripts
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/68/300468/3 && git format-patch -1 --stdout FETCH_HEAD,"['Guacamole/package/Resources/DeployGuacamole.template', 'Guacamole/package/Resources/deployGuacamole.sh', 'Guacamole/package/Classes/Guacamole.yaml']",3,348c95ff6d3ce8ab16f9b62845600df60fa5d603,bp/refactor-apps-scripts," conf: io.murano.configuration - $replacements: ""%USERNAME%"": $.username ""%PASSWORD%"": $.password - $file: $resources.string('deployGuacamole.sh').replace($replacements) - conf:Linux.runCommand($.server.instance.agent, $file) "," - $template: $resources.yaml('DeployGuacamole.template').bind(dict( username => $.username, password => $.password )) - $.server.instance.agent.call($template, $resources)",9,41
openstack%2Fmonasca-analytics~master~I564170c3da78d306b4b641f8a86d5b2b2e759a2b,openstack/monasca-analytics,master,I564170c3da78d306b4b641f8a86d5b2b2e759a2b,implemented and tested the DSL parser,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:34:49.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/dsl/dsl.py', 'test/dsl/__init__.py', 'test/dsl/test_dsl.py', 'main/dsl/__init__.py', 'main/dsl/const.py', 'test/resources/dsl_code.txt'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/c248e420268b4bdb81e42c4a50854c99a4bd7145', 'message': 'implemented and tested the DSL parser\n\nChange-Id: I564170c3da78d306b4b641f8a86d5b2b2e759a2b\n'}]",0,313456,c248e420268b4bdb81e42c4a50854c99a4bd7145,2,0,1,21739,,,0,"implemented and tested the DSL parser

Change-Id: I564170c3da78d306b4b641f8a86d5b2b2e759a2b
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/56/313456/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/dsl/dsl.py', 'test/dsl/__init__.py', 'test/dsl/test_dsl.py', 'main/dsl/__init__.py', 'main/dsl/const.py', 'test/resources/dsl_code.txt']",6,c248e420268b4bdb81e42c4a50854c99a4bd7145,,#target generated_config.json A = CloudMarkovChainSource A.params.server_sleep_in_seconds = 0.1 B = CloudIngestor C = LiNGAM C.params.threshold = 0.1 D = PickIndexVoter E = KafkaSink F = CloudCausalityLDP A -> B A -> F C -> D D -> F F -> E,,25,2
openstack%2Fmurano-apps~master~Ia838a0ba8d72f9446439bc1992baf807d5917570,openstack/murano-apps,master,Ia838a0ba8d72f9446439bc1992baf807d5917570,[Cassandra] Use simple software configuration,MERGED,2016-04-01 13:04:14.000000000,2016-05-11 16:34:48.000000000,2016-05-11 16:34:48.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 10424}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/f461e05f42e8eedd346e9b86153a99aed65329b9', 'message': '[Cassandra] Use simple software configuration\n\nChange-Id: Ia838a0ba8d72f9446439bc1992baf807d5917570\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 2, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/e99a4b53850556b8870b82580f554e9d84c729ee', 'message': '[Cassandra] Use simple software configuration\n\nChange-Id: Ia838a0ba8d72f9446439bc1992baf807d5917570\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 3, 'created': '2016-04-12 15:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/5c35d2755ef683d9c98376ae3c76d58095b93591', 'message': '[Cassandra] Use simple software configuration\n\nChange-Id: Ia838a0ba8d72f9446439bc1992baf807d5917570\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 4, 'created': '2016-05-11 16:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/214352c2a9edca6dc3528fa189e6a28452ac5d0e', 'message': '[Cassandra] Use simple software configuration\n\nChange-Id: Ia838a0ba8d72f9446439bc1992baf807d5917570\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 5, 'created': '2016-05-11 16:31:56.000000000', 'files': ['Cassandra/package/Resources/DeployCassandra.template', 'Cassandra/package/Resources/updateCassandraYaml.sh', 'Cassandra/package/Resources/UpdateCassandraYaml.template', 'Cassandra/package/Classes/CassandraCluster.yaml', 'Cassandra/package/Classes/CassandraNode.yaml', 'Cassandra/package/Resources/deployCassandra.sh', 'Cassandra/package/Resources/RestartCassandra.template', 'Cassandra/package/Resources/restartCassandra.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/e022463cf54b75d09e08d5bb8b95b593fb3d850c', 'message': '[Cassandra] Use simple software configuration\n\nChange-Id: Ia838a0ba8d72f9446439bc1992baf807d5917570\nPartially-Implements: bp refactor-apps-scripts\n'}]",1,300467,e022463cf54b75d09e08d5bb8b95b593fb3d850c,20,5,5,13149,,,0,"[Cassandra] Use simple software configuration

Change-Id: Ia838a0ba8d72f9446439bc1992baf807d5917570
Partially-Implements: bp refactor-apps-scripts
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/67/300467/1 && git format-patch -1 --stdout FETCH_HEAD,"['Cassandra/package/Resources/DeployCassandra.template', 'Cassandra/package/Resources/updateCassandraYaml.sh', 'Cassandra/package/Resources/UpdateCassandraYaml.template', 'Cassandra/package/Classes/CassandraCluster.yaml', 'Cassandra/package/Classes/CassandraNode.yaml', 'Cassandra/package/Resources/deployCassandra.sh', 'Cassandra/package/Resources/RestartCassandra.template', 'Cassandra/package/Resources/restartCassandra.sh']",8,f461e05f42e8eedd346e9b86153a99aed65329b9,bp/refactor-apps-scripts,,,17,118
openstack%2Fmonasca-analytics~master~I7ca05f493c6a4cc0edaac55abf3c53ec523f207a,openstack/monasca-analytics,master,I7ca05f493c6a4cc0edaac55abf3c53ec523f207a,"implemented and tested static default configuration for each module, this will be used by DSL",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:34:46.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'test/source/test_iptables_markov_chain.py', 'main/voter/pick_index.py', 'test/mocks/ingestors.py', 'main/component/base.py', 'main/source/cloud_markov_chain.py', 'test/source/test_markov_chain.py', 'test/sink/test_kafka.py', 'main/ingestor/iptables_ingestor.py', 'test/voter/test_base_voter.py', 'main/source/kafka.py', 'test/mocks/sml_mocks.py', 'test/source/test_random.py', 'main/source/random.py', 'test/mocks/sources.py', 'test/ingestor/test_iptables_ingestor.py', 'test/ldp/__init__.py', 'main/sink/kafkas.py', 'test/source/test_kafka.py', 'test/voter/test_pick_index.py', 'main/source/file.py', 'test/util/test_common_util.py', 'test/ingestor/test_cloud.py', 'test/ldp/cloud_causality.py', 'test/sml/test_lingam.py', 'main/ldp/cloud_causality.py', 'main/config/const.py', 'main/ingestor/cloud.py', 'main/sml/lingam.py', 'test/source/test_file.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/990b995a587ceaaecbaec7f34d9365162ceb1652', 'message': 'implemented and tested static default configuration for each module, this will be used by DSL\n\nChange-Id: I7ca05f493c6a4cc0edaac55abf3c53ec523f207a\n'}]",0,313455,990b995a587ceaaecbaec7f34d9365162ceb1652,2,0,1,21739,,,0,"implemented and tested static default configuration for each module, this will be used by DSL

Change-Id: I7ca05f493c6a4cc0edaac55abf3c53ec523f207a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/55/313455/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'test/source/test_iptables_markov_chain.py', 'main/voter/pick_index.py', 'test/mocks/ingestors.py', 'main/component/base.py', 'main/source/cloud_markov_chain.py', 'test/source/test_markov_chain.py', 'test/sink/test_kafka.py', 'main/ingestor/iptables_ingestor.py', 'test/voter/test_base_voter.py', 'main/source/kafka.py', 'test/mocks/sml_mocks.py', 'test/source/test_random.py', 'main/source/random.py', 'test/mocks/sources.py', 'test/ingestor/test_iptables_ingestor.py', 'test/ldp/__init__.py', 'main/sink/kafkas.py', 'test/source/test_kafka.py', 'test/voter/test_pick_index.py', 'main/source/file.py', 'test/util/test_common_util.py', 'test/ingestor/test_cloud.py', 'test/ldp/cloud_causality.py', 'test/sml/test_lingam.py', 'main/ldp/cloud_causality.py', 'main/config/const.py', 'main/ingestor/cloud.py', 'main/sml/lingam.py', 'test/source/test_file.py']",30,990b995a587ceaaecbaec7f34d9365162ceb1652,,,"import json import os import unittest from logging.config import dictConfig from schema import SchemaError from main.source.file import FileSource from test.mocks.spark_mocks import MockStreamingContext class FileSourceTest(unittest.TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def setUp(self): self.setup_logging() self.valid_config = { ""module"": ""file"", ""params"": { ""directory"": ""resources/fake_data_files/"" } } self.config_extra_param = { ""module"": ""file_source"", ""params"": { ""directory"": ""resources/fake_data_files/"", ""infiltrated"": ""wrong_param"" } } self.config_missing_dir = { ""module"": ""file"", ""params"": {} } self.config_wrong_type = { ""module"": 123, ""params"": { ""directory"": ""resources/fake_data_files/"" } } self.config_missing_params = {""module"": ""file""} self.fs = FileSource(""fake_id"", self.valid_config) def tearDown(self): pass def test_validate_valid_config(self): self.assertEqual(self.valid_config, self.fs._config) def test_validate_config_extra_param(self): self.assertRaises( SchemaError, self.fs.validate_config, self.config_extra_param) def test_validate_config_missing_dir(self): self.assertRaises( SchemaError, self.fs.validate_config, self.config_missing_dir) def test_validate_config_wrong_type(self): self.assertRaises( SchemaError, self.fs.validate_config, self.config_wrong_type) def test_before_bind_source_dstream_created(self): ssc = MockStreamingContext(None, None) self.assertIsNotNone(self.fs.create_dstream(ssc)) self.assertEqual(""resources/fake_data_files/"", ssc._textFileStreamDirectory) ",362,122
openstack%2Fmurano-apps~master~Ie3d6766754e8ee1300580de7a9441f47a09fc81f,openstack/murano-apps,master,Ie3d6766754e8ee1300580de7a9441f47a09fc81f,[MongoDB] Use simple software configuration,MERGED,2016-04-01 13:04:14.000000000,2016-05-11 16:34:37.000000000,2016-05-11 16:34:37.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/bfe5381179ef804867d6293015957a3bb1fd1e0d', 'message': '[MongoDB] Use simple software configuration\n\nChange-Id: Ie3d6766754e8ee1300580de7a9441f47a09fc81f\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 2, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/af6f9616a4ac545e79ec2e6cc8ef1a37206e8777', 'message': '[MongoDB] Use simple software configuration\n\nChange-Id: Ie3d6766754e8ee1300580de7a9441f47a09fc81f\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 3, 'created': '2016-05-11 16:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/59a3d07791dbb2e125c2f5b3d398f9e4fcff346b', 'message': '[MongoDB] Use simple software configuration\n\nChange-Id: Ie3d6766754e8ee1300580de7a9441f47a09fc81f\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 4, 'created': '2016-05-11 16:32:02.000000000', 'files': ['MongoDB/package/Resources/configureMongoDB.sh', 'MongoDB/package/Resources/scripts/deployMongoDB.sh', 'MongoDB/package/Resources/AddFirewallRules.template', 'MongoDB/package/Resources/DeployMongoDB.template', 'MongoDB/package/Resources/ConfigureMongoDB.template', 'MongoDB/package/Resources/CreateMongoDBDatabase.template', 'MongoDB/package/Resources/createMongoDBDatabase.sh', 'MongoDB/package/Resources/CreateUserForMongoDBDatabase.template', 'MongoDB/package/Resources/createUserForMongoDBDatabase.sh', 'MongoDB/package/Classes/MongoDB.yaml', 'MongoDB/package/Resources/addFirewallRules.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/69da599031a143db3cb6b944ec9b3af486aa0854', 'message': '[MongoDB] Use simple software configuration\n\nChange-Id: Ie3d6766754e8ee1300580de7a9441f47a09fc81f\nPartially-Implements: bp refactor-apps-scripts\n'}]",0,300466,69da599031a143db3cb6b944ec9b3af486aa0854,17,10,4,13149,,,0,"[MongoDB] Use simple software configuration

Change-Id: Ie3d6766754e8ee1300580de7a9441f47a09fc81f
Partially-Implements: bp refactor-apps-scripts
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/66/300466/4 && git format-patch -1 --stdout FETCH_HEAD,"['MongoDB/package/Resources/configureMongoDB.sh', 'MongoDB/package/Resources/scripts/deployMongoDB.sh', 'MongoDB/package/Resources/AddFirewallRules.template', 'MongoDB/package/Resources/DeployMongoDB.template', 'MongoDB/package/Resources/ConfigureMongoDB.template', 'MongoDB/package/Resources/CreateMongoDBDatabase.template', 'MongoDB/package/Resources/CreateUserForMongoDBDatabase.template', 'MongoDB/package/Resources/createMongoDBDatabase.sh', 'MongoDB/package/Resources/createUserForMongoDBDatabase.sh', 'MongoDB/package/Classes/MongoDB.yaml', 'MongoDB/package/Resources/addFirewallRules.sh']",11,bfe5381179ef804867d6293015957a3bb1fd1e0d,bp/refactor-apps-scripts,,,21,191
openstack%2Fmurano-apps~master~If7e254ed03d040ce6348dc7094b57ccd35c55ca9,openstack/murano-apps,master,If7e254ed03d040ce6348dc7094b57ccd35c55ca9,[WordPress] Use simple software configuration,MERGED,2016-04-01 13:04:14.000000000,2016-05-11 16:34:15.000000000,2016-05-11 16:34:15.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/5d40ec139169c985cb221556ed0f6a5840cc76ae', 'message': '[WordPress] Use simple software configuration\n\nChange-Id: If7e254ed03d040ce6348dc7094b57ccd35c55ca9\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 2, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/73ef91127e127b19df9b7edf76268c6c0ef0adf7', 'message': '[WordPress] Use simple software configuration\n\nChange-Id: If7e254ed03d040ce6348dc7094b57ccd35c55ca9\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 3, 'created': '2016-04-22 13:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/d3e94fac368d8bc33b88e932d94bc43740b15d6e', 'message': '[WordPress] Use simple software configuration\n\nChange-Id: If7e254ed03d040ce6348dc7094b57ccd35c55ca9\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 4, 'created': '2016-05-11 16:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/f7d338e8b6fed943cb5a14db522df447726143d4', 'message': '[WordPress] Use simple software configuration\n\nChange-Id: If7e254ed03d040ce6348dc7094b57ccd35c55ca9\nPartially-Implements: bp refactor-apps-scripts\n'}, {'number': 5, 'created': '2016-05-11 16:32:08.000000000', 'files': ['WordPress/package/Resources/ConfigureAccessToMySql.template', 'WordPress/package/Resources/DeployWordPress.template', 'WordPress/package/Resources/deployWordPress.sh', 'WordPress/package/Resources/configureAccessToMySql.sh', 'WordPress/package/Classes/WordPress.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/2fbbb04b200482931353e952ec1ee43b9f90a758', 'message': '[WordPress] Use simple software configuration\n\nChange-Id: If7e254ed03d040ce6348dc7094b57ccd35c55ca9\nPartially-Implements: bp refactor-apps-scripts\n'}]",0,300465,2fbbb04b200482931353e952ec1ee43b9f90a758,19,5,5,13149,,,0,"[WordPress] Use simple software configuration

Change-Id: If7e254ed03d040ce6348dc7094b57ccd35c55ca9
Partially-Implements: bp refactor-apps-scripts
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/65/300465/2 && git format-patch -1 --stdout FETCH_HEAD,"['WordPress/package/Resources/ConfigureAccessToMySql.template', 'WordPress/package/Resources/DeployWordPress.template', 'WordPress/package/Resources/deployWordPress.sh', 'WordPress/package/Resources/configureAccessToMySql.sh', 'WordPress/package/Classes/WordPress.yaml']",5,5d40ec139169c985cb221556ed0f6a5840cc76ae,bp/refactor-apps-scripts," conf: io.murano.configuration - $file: $resources.string('deployWordPress.sh') - conf:Linux.runCommand($.instance.agent, $file) - $replacements: ""%DATABASE%"": $.dbName ""%USERNAME%"": $.dbUser ""%HOST%"": $.database.instance.ipAddresses[0] ""%PASSWORD%"": $.dbPassword - $file: $resources.string('configureAccessToMySql.sh').replace($replacements) - conf:Linux.runCommand($.instance.agent, $file)"," - $template: $resources.yaml('DeployWordPress.template') - $.server.instance.agent.call($template, $resources) - $template: $resources.yaml('ConfigureAccessToMySql.template').bind(dict( database => $.dbName, username => $.dbUser, password => $.dbPassword, host => $.database.instance.ipAddresses[0] )) - $.server.instance.agent.call($template, $resources)",15,78
openstack%2Fmonasca-analytics~master~Ib3468e1d79999b03fce70429ec35e6c82f407171,openstack/monasca-analytics,master,Ib3468e1d79999b03fce70429ec35e6c82f407171,improved documentation,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:33:11.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/config/dsl.py', 'test/config/test_dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/ceb66603f22e58621c0442fa90aea82a9527370f', 'message': 'improved documentation\n\nChange-Id: Ib3468e1d79999b03fce70429ec35e6c82f407171\n'}]",0,313453,ceb66603f22e58621c0442fa90aea82a9527370f,2,0,1,21739,,,0,"improved documentation

Change-Id: Ib3468e1d79999b03fce70429ec35e6c82f407171
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/53/313453/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/config/dsl.py', 'test/config/test_dsl.py']",2,ceb66603f22e58621c0442fa90aea82a9527370f,," def test_generate_id_wrong_type(self): self.assertRaises(KeyError, self.dsl._generate_id, ""wrong_type"") ",,66,1
openstack%2Fmonasca-analytics~master~I1d86e03441a035a6ba76f0edd1f6d7d87d1e258c,openstack/monasca-analytics,master,I1d86e03441a035a6ba76f0edd1f6d7d87d1e258c,"added the modify functionality to DSL, also added unit tests for it",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:33:03.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/dsl/dsl.py', 'test/resources/test_json.json', 'test/dsl/test_dsl.py', 'main/exception/dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/baf7faf24f9ad40719c31d75398a2c9e4037ee25', 'message': 'added the modify functionality to DSL, also added unit tests for it\n\nChange-Id: I1d86e03441a035a6ba76f0edd1f6d7d87d1e258c\n'}]",0,313457,baf7faf24f9ad40719c31d75398a2c9e4037ee25,2,0,1,21739,,,0,"added the modify functionality to DSL, also added unit tests for it

Change-Id: I1d86e03441a035a6ba76f0edd1f6d7d87d1e258c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/57/313457/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/dsl/dsl.py', 'test/resources/test_json.json', 'test/dsl/test_dsl.py', 'main/exception/dsl.py']",4,baf7faf24f9ad40719c31d75398a2c9e4037ee25,," class DSLInterpreterException(DSLException): def __init__(self, value): self._value = value def __str__(self): DSLException.__str__(self) return repr(self._value)",,137,8
openstack%2Fmonasca-analytics~master~I9f361b37fa8490a92892bdd859cce8859cab584d,openstack/monasca-analytics,master,I9f361b37fa8490a92892bdd859cce8859cab584d,fixed tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:59.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/dsl/test_interpreter.py', 'test/dsl/test_dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/02922c885902b823b179036c54160badad05410f', 'message': 'fixed tests\n\nChange-Id: I9f361b37fa8490a92892bdd859cce8859cab584d\n'}]",0,313460,02922c885902b823b179036c54160badad05410f,2,0,1,21739,,,0,"fixed tests

Change-Id: I9f361b37fa8490a92892bdd859cce8859cab584d
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/60/313460/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/dsl/test_interpreter.py', 'test/dsl/test_dsl.py']",2,02922c885902b823b179036c54160badad05410f,," self.assertFalse(self.dsl.modify_component( ""src3"", [""fake"", ""fake_param""], 123))"," self.assertRaises(SchemaError, self.dsl.modify_component, ""src3"", [""fake"", ""fake_param""], 123)",2,13
openstack%2Fmonasca-analytics~master~Ic7c646d930e5edbe55a7761a00d0ba22e2f16d32,openstack/monasca-analytics,master,Ic7c646d930e5edbe55a7761a00d0ba22e2f16d32,added print and list commands. Also made the default config read only by accessing it with a getter that deepcopies it,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:55.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/dsl/dsl.py', 'test/dsl/test_interpreter.py', 'main/config/const.py', 'main/dsl/const.py', 'main/dsl/interpreter.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/70363c9aef09476d0b09470b92dce09dfee74369', 'message': 'added print and list commands. Also made the default config read only by accessing it with a getter that deepcopies it\n\nChange-Id: Ic7c646d930e5edbe55a7761a00d0ba22e2f16d32\n'}]",0,313462,70363c9aef09476d0b09470b92dce09dfee74369,2,0,1,21739,,,0,"added print and list commands. Also made the default config read only by accessing it with a getter that deepcopies it

Change-Id: Ic7c646d930e5edbe55a7761a00d0ba22e2f16d32
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/62/313462/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/dsl/dsl.py', 'test/dsl/test_interpreter.py', 'main/config/const.py', 'main/dsl/const.py', 'main/dsl/interpreter.py']",5,70363c9aef09476d0b09470b92dce09dfee74369,,"from main.config import const as config_constimport json elif key == const.PRINT: if len(cmd[key]) > 0: return self.prnt(cmd[key][0]) else: return self.prnt_all() elif key == const.LIST: if len(cmd[key]) > 0: return self.list(cmd[key][0]) else: return self.list_all() elif key == const.HELP: return self.help() origin_id = self._get_id(origin_varname) dest_id = self._get_id(dest_varname) return self.dsl.connect_components(origin_id, dest_id) def _get_id(self, name_or_id): if name_or_id in self.mappings.keys(): return self.mappings[name_or_id] for comp_type in config_const.components_types: if name_or_id in self.dsl._config[comp_type]: return name_or_id raise DSLInterpreterException(""undefined variable: "" + name_or_id) origin_id = self._get_id(origin_varname) dest_id = self._get_id(dest_varname) return self.dsl.disconnect_components(origin_id, dest_id) remove_id = self._get_id(varname) return self.dsl.remove_component(remove_id) modify_id = self._get_id(varname) return self.dsl.modify_component(modify_id, params, value) def prnt(self, varname): if varname in self.dsl._config.keys(): return self._json_print(self.dsl._config[varname]) itemId = self._get_id(varname) for k in config_const.components_types: if itemId in self.dsl._config[k]: return self._json_print(self.dsl._config[k][itemId]) def prnt_all(self): return self._json_print(self.dsl._config) def _json_print(self, jstr): return json.dumps(jstr, indent=4, separators=(',', ': ')) def list(self, key): ret = """" if key in config_const.components_types: for name in cu.get_available_class_names(key): ret += ""- "" + name + ""\n"" return ret def list_all(self): ret = """" for key in config_const.components_types: ret += ""- "" + key + ""\n"" for name in cu.get_available_class_names(key): ret += "" - "" + name + ""\n"" return ret def help(self): return """""" Available commands - print: prints current configuration - list: shows available modules - load: loads a config from a file - save: saves a config to a file - <var> = <module>: instantiates module <module>, referenced by <var> - <var1>-><var2>: connects the module <var1> to the module <var2> - <var1>!-><var2>: disconnects the module <var1> from the module <var2> - rm <var>: removes the module corresponding to <var> - exit: finishes the execution of monanas command line """""""," self._assert_vars_created([origin_varname, dest_varname]) return self.dsl.connect_components(self.mappings[origin_varname], self.mappings[dest_varname]) self._assert_vars_created([origin_varname, dest_varname]) return self.dsl.disconnect_components(self.mappings[origin_varname], self.mappings[dest_varname]) self._assert_vars_created([varname]) return self.dsl.remove_component(self.mappings[varname]) self._assert_vars_created([varname]) return self.dsl.modify_component(self.mappings[varname], params, value) def _assert_vars_created(self, varnames): for varname in varnames: if varname not in self.mappings.keys(): raise DSLInterpreterException(""undefined variable: "" + varname)",98,19
openstack%2Fmonasca-analytics~master~Ie208ce0b63e9cf7f9e9be5bd5f9aabfca5ecb7d1,openstack/monasca-analytics,master,Ie208ce0b63e9cf7f9e9be5bd5f9aabfca5ecb7d1,added flie to execute DLS,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:51.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config_dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f90cc892389087a765b19b29fb307aa4921f7f0f', 'message': 'added flie to execute DLS\n\nChange-Id: Ie208ce0b63e9cf7f9e9be5bd5f9aabfca5ecb7d1\n'}]",0,313463,f90cc892389087a765b19b29fb307aa4921f7f0f,2,0,1,21739,,,0,"added flie to execute DLS

Change-Id: Ie208ce0b63e9cf7f9e9be5bd5f9aabfca5ecb7d1
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/63/313463/1 && git format-patch -1 --stdout FETCH_HEAD,['config_dsl.py'],1,f90cc892389087a765b19b29fb307aa4921f7f0f,,"#!/usr/bin/env python from main.dsl.interpreter import DSLInterpreter import os import json from logging.config import dictConfig DEFAULT_LOGGING_CONFIG_FILE = ""config/logging.json"" def setup_logging(): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, DEFAULT_LOGGING_CONFIG_FILE) with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def main(): setup_logging() print ""Welcome to Monanas config command line"" print ""Type help for help about commands"" inter = DSLInterpreter() cmd = """" while(""exit"" != cmd.lower()): cmd = raw_input("">> "") if cmd != """": try: print inter.execute_string(cmd) except Exception as e: print ""Failed : "" + str(e) if __name__ == ""__main__"": main() ",,36,0
openstack%2Fmonasca-analytics~master~I07e72a1f05c7e35acebbea887f0a4f0bb5d7ab32,openstack/monasca-analytics,master,I07e72a1f05c7e35acebbea887f0a4f0bb5d7ab32,"implemented DSL interpreter and tested it. Also fixed a few bugs, including the dynamic typing of variables at modify",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:48.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/dsl/dsl.py', 'test/dsl/test_interpreter.py', 'main/util/common_util.py', 'main/dsl/interpreter.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/0aea43ffe1b760fd4181e7cd1b84bcc2f322e17a', 'message': 'implemented DSL interpreter and tested it. Also fixed a few bugs, including the dynamic typing of variables at modify\n\nChange-Id: I07e72a1f05c7e35acebbea887f0a4f0bb5d7ab32\n'}]",0,313459,0aea43ffe1b760fd4181e7cd1b84bcc2f322e17a,2,0,1,21739,,,0,"implemented DSL interpreter and tested it. Also fixed a few bugs, including the dynamic typing of variables at modify

Change-Id: I07e72a1f05c7e35acebbea887f0a4f0bb5d7ab32
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/59/313459/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/dsl/dsl.py', 'test/dsl/test_interpreter.py', 'main/util/common_util.py', 'main/dsl/interpreter.py']",4,0aea43ffe1b760fd4181e7cd1b84bcc2f322e17a,,"from main.dsl import parser from main.dsl import const from main.dsl.dsl import MonanasDSL from main.exception.dsl import DSLInterpreterException import main.util.common_util as cu import logging import copy logger = logging.getLogger(__name__) class DSLInterpreter(): def __init__(self): self.dsl = MonanasDSL() self.mappings = {} def execute_string(self, str_program): info = parser.get_parser().parseString(str_program) return self.execute(info) def execute_file(self, file_program): info = parser.get_parser().parseFile(file_program) return self.execute(info) def execute(self, info): for cmd in info: for key in cmd.keys(): if key == const.CREATE: return self.create(cmd[key][0], cmd[key][1]) elif key == const.CONNECT: return self.connect(cmd[key][0], cmd[key][1]) elif key == const.DISCONNECT: return self.disconnect(cmd[key][0], cmd[key][1]) elif key == const.LOAD: return self.load(cmd[key][0]) elif key == const.SAVE_AS: return self.save(cmd[key][0]) elif key == const.SAVE: return self.save() elif key == const.REMOVE: return self.remove(cmd[key][0]) elif key == const.MODIFY: return self.modify( cmd[key][0], cmd[key][1:-1], cmd[key][-1]) else: return logger.warn(""Wrong command"" + str(cmd)) def create(self, varname, modulename): clz = cu.get_class_by_name(modulename) conf = copy.deepcopy(clz.get_default_config()) comp_id = self.dsl.add_component(conf) self.mappings[varname] = comp_id return comp_id def connect(self, origin_varname, dest_varname): self._assert_vars_created([origin_varname, dest_varname]) return self.dsl.connect_components(self.mappings[origin_varname], self.mappings[dest_varname]) def disconnect(self, origin_varname, dest_varname): self._assert_vars_created([origin_varname, dest_varname]) return self.dsl.disconnect_components(self.mappings[origin_varname], self.mappings[dest_varname]) def load(self, filepath): return self.dsl.load_configuration(filepath) def save(self, filepath=None): return self.dsl.save_configuration(filepath, overwrite_file=True) def remove(self, varname): self._assert_vars_created([varname]) return self.dsl.remove_component(self.mappings[varname]) def modify(self, varname, params, value): self._assert_vars_created([varname]) return self.dsl.modify_component(self.mappings[varname], params, value) def _assert_vars_created(self, varnames): for varname in varnames: if varname not in self.mappings.keys(): raise DSLInterpreterException(""undefined variable: "" + varname) ",,282,7
openstack%2Fmonasca-analytics~master~I69c787826ec6e284e9c2977e1dea358326cc2476,openstack/monasca-analytics,master,I69c787826ec6e284e9c2977e1dea358326cc2476,tmp commit to check what tests fails in remote,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:45.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/dsl/test_interpreter.py', 'test/dsl/__init__.py', 'test/dsl/test_dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/db1842dc4b4dc31fc9e2a5ff655001e6cd6b7080', 'message': 'tmp commit to check what tests fails in remote\n\nChange-Id: I69c787826ec6e284e9c2977e1dea358326cc2476\n'}]",0,313464,db1842dc4b4dc31fc9e2a5ff655001e6cd6b7080,2,0,1,21739,,,0,"tmp commit to check what tests fails in remote

Change-Id: I69c787826ec6e284e9c2977e1dea358326cc2476
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/64/313464/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/dsl/test_interpreter.py', 'test/dsl/__init__.py', 'test/dsl/test_dsl.py']",3,db1842dc4b4dc31fc9e2a5ff655001e6cd6b7080,,,"#!/usr/bin/env python import os import json import copy from logging.config import dictConfig from unittest import TestCase from main.config import const from main.exception.dsl import DSLExistingConnection, DSLInvalidConnection from main.exception.monanas import MonanasNoSuchClassError from schema import SchemaError from main.dsl.dsl import MonanasDSL class TestMonanasDSL(TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def get_test_config_file_path(self): current_dir = os.path.dirname(__file__) return os.path.join(current_dir, ""../resources/test_json.json"") def setUp(self): self.setup_logging() config_file_path = self.get_test_config_file_path() self.dsl = MonanasDSL(config_file_path) self.original_config = copy.deepcopy(self.dsl._config) self.testing_new_source_config = { ""module"": ""KafkaSource"", ""params"": { ""zk_host"": ""myHost"", ""zk_port"": 1234, ""group_id"": ""myGroupId"", ""topics"": { ""myTopic1"": 1, ""myTopic2"": 2 } } } self.tmp_file = ""tmp_config_file.json"" def tearDown(self): if os.path.exists(self.tmp_file): os.remove(self.tmp_file) def test_generate_id(self): self.assertEqual(""src4"", self.dsl._generate_id(const.SOURCES)) self.assertEqual(""ing2"", self.dsl._generate_id(const.INGESTORS)) self.assertEqual(""sml2"", self.dsl._generate_id(const.SMLS)) self.assertEqual(""vot2"", self.dsl._generate_id(const.VOTERS)) self.assertEqual(""snk3"", self.dsl._generate_id(const.SINKS)) self.assertEqual(""ldp2"", self.dsl._generate_id(const.LDPS)) self.assertEqual(""src5"", self.dsl._generate_id(const.SOURCES)) self.assertEqual(""ing3"", self.dsl._generate_id(const.INGESTORS)) self.assertEqual(""sml3"", self.dsl._generate_id(const.SMLS)) self.assertEqual(""vot3"", self.dsl._generate_id(const.VOTERS)) self.assertEqual(""snk4"", self.dsl._generate_id(const.SINKS)) self.assertEqual(""ldp3"", self.dsl._generate_id(const.LDPS)) self.assertEqual(self.original_config, self.dsl._config) def test_generate_id_wrong_type(self): self.assertRaises(KeyError, self.dsl._generate_id, ""wrong_type"") def test_is_connected(self): self.assertTrue(self.dsl._is_connected(""src1"")) self.assertFalse(self.dsl._is_connected(""src2"")) self.assertTrue(self.dsl._is_connected(""ing1"")) self.assertTrue(self.dsl._is_connected(""sml1"")) self.assertTrue(self.dsl._is_connected(""vot1"")) self.assertTrue(self.dsl._is_connected(""snk1"")) self.assertTrue(self.dsl._is_connected(""snk2"")) self.assertTrue(self.dsl._is_connected(""ldp1"")) self.assertEqual(self.original_config, self.dsl._config) def test_component_defined(self): self.assertTrue(self.dsl._component_defined(""src1"")) self.assertFalse(self.dsl._component_defined(""fake_id"")) self.assertEqual(self.original_config, self.dsl._config) def test_validate_connection_by_ids(self): self.assertTrue(self.dsl._validate_connection_by_ids(""src1"", ""ing1"")) self.assertTrue(self.dsl._validate_connection_by_ids(""src1"", ""ldp1"")) self.assertFalse(self.dsl._validate_connection_by_ids(""src2"", ""sml1"")) self.assertFalse(self.dsl._validate_connection_by_ids(""ing1"", ""vot1"")) self.assertTrue(self.dsl._validate_connection_by_ids(""ldp1"", ""snk1"")) self.assertEqual(self.original_config, self.dsl._config) def test_add_component(self): new_id = self.dsl.add_component(self.testing_new_source_config) self.assertEqual(""src4"", new_id) expected_config = self.original_config expected_config[const.SOURCES][""src4""] = self.testing_new_source_config expected_config[const.CONNECTIONS][""src4""] = [] self.assertEqual(expected_config, self.dsl._config) def test_add_component_string(self): conf_str = json.dumps(self.testing_new_source_config) new_id = self.dsl.add_component(conf_str) self.assertEqual(""src4"", new_id) expected_config = self.original_config expected_config[const.SOURCES][""src4""] = self.testing_new_source_config expected_config[const.CONNECTIONS][""src4""] = [] self.assertEqual(expected_config, self.dsl._config) def test_add_component_wrong_config(self): del (self.testing_new_source_config[""params""][""zk_port""]) self.assertRaises(SchemaError, self.dsl.add_component, self.testing_new_source_config) self.assertEqual(self.original_config, self.dsl._config) def test_add_component_wrong_module(self): self.testing_new_source_config[""module""] = ""fake_module"" self.assertRaises(MonanasNoSuchClassError, self.dsl.add_component, self.testing_new_source_config) self.assertEqual(self.original_config, self.dsl._config) def test_modify_component(self): self.assertTrue(self.dsl.modify_component( ""src3"", [""params"", ""server_sleep_in_seconds""], 0.02)) expected_config = self.original_config expected_config[const.SOURCES][""src3""][""params""][ ""server_sleep_in_seconds""] = 0.02 self.assertEqual(expected_config, self.dsl._config) def test_modify_component_inexistent(self): self.assertFalse(self.dsl.modify_component( ""src8"", [""params"", ""server_sleep_in_seconds""], 0.02)) self.assertEqual(self.original_config, self.dsl._config) def test_modify_component_to_invalid_config(self): self.assertFalse(self.dsl.modify_component( ""src3"", [""fake"", ""fake_param""], 123)) self.assertEqual(self.original_config, self.dsl._config) def test_modify_dictionary_new_path(self): original = self.original_config[""voters""][""vot1""] modified = self.dsl._modify_dictionary( original, [""params"", ""param1"", ""subparam1A""], ""new_value"") expected = { ""module"": ""voter_module"", ""params"": { ""param1"": { ""subparam1A"": ""new_value"" } } } self.assertEqual(expected, modified) def test_modify_dictioinary_overwrite_value(self): original = self.original_config[""sources""][""src1""] modified = self.dsl._modify_dictionary( original, [""params"", ""param1""], ""new_value"") expected = { ""module"": ""src_module1"", ""params"": { ""param1"": ""new_value"", ""param2"": ""val2"", ""model_id"": 3 } } self.assertEqual(expected, modified) def test_modify_dictionary_overwrite_path(self): original = self.original_config[""sources""][""src1""] modified = self.dsl._modify_dictionary( original, [""params""], ""new_value"") expected = { ""module"": ""src_module1"", ""params"": ""new_value"" } self.assertEqual(expected, modified) def test_remove_unconnected_component(self): self.assertTrue(self.dsl.remove_component(""src2"")) expected_config = self.original_config del(expected_config[const.SOURCES][""src2""]) del(expected_config[const.CONNECTIONS][""src2""]) self.assertEqual(expected_config, self.dsl._config) def test_remove_connected_component(self): self.assertRaises(DSLExistingConnection, self.dsl.remove_component, ""src1"") self.assertEqual(self.original_config, self.dsl._config) def test_remove_component_wrong_id(self): self.assertFalse(self.dsl.remove_component(""fake_id"")) self.assertEqual(self.original_config, self.dsl._config) def test_connect_component_new_allowed(self): self.assertTrue(self.dsl.connect_components(""src2"", ""ing1"")) expected_config = self.original_config expected_config[const.CONNECTIONS][""src2""].append(""ing1"") self.assertEqual(self.original_config, self.dsl._config) def test_connect_existing(self): self.assertFalse(self.dsl.connect_components(""src1"", ""ing1"")) self.assertEqual(self.original_config, self.dsl._config) def test_connect_component_new_forbidden(self): self.assertRaises(DSLInvalidConnection, self.dsl.connect_components, ""src1"", ""vot1"") self.assertEqual(self.original_config, self.dsl._config) def test_disconnect(self): self.assertTrue(self.dsl.disconnect_components(""src1"", ""ing1"")) expected_config = self.original_config expected_config[const.CONNECTIONS][""src1""] = [""ldp1""] self.assertEqual(self.original_config, self.dsl._config) def test_disconnect_inexistent_components(self): self.assertFalse(self.dsl.disconnect_components(""fake_1"", ""fake_2"")) self.assertFalse(self.dsl.disconnect_components(""fake_id"", ""snk1"")) self.assertFalse(self.dsl.disconnect_components(""src1"", ""fake_id"")) self.assertEqual(self.original_config, self.dsl._config) def test_disconnect_inexistent_connection(self): self.assertFalse(self.dsl.disconnect_components(""src2"", ""ing1"")) self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_overwrite_no_file(self): self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=True)) self.dsl._config = None self.dsl.load_configuration(self.tmp_file) self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_not_overwrite_no_file(self): self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=False)) self.dsl._config = None self.dsl.load_configuration(self.tmp_file) self.assertEqual(self.original_config, self.dsl._config) def _create_dirty_fyle(self, fname): with open(fname, ""w"") as f: f.write(""This content may be overwritten"") def test_save_configuration_overwrite_file(self): self._create_dirty_fyle(self.tmp_file) self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=True)) self.dsl._config = None self.dsl.load_configuration(""tmp_config_file.json"") self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_not_overwrite_file(self): self._create_dirty_fyle(self.tmp_file) old_size = os.stat(self.tmp_file).st_size self.assertFalse( self.dsl.save_configuration(self.tmp_file, overwrite_file=False)) self.assertEqual(old_size, os.stat(self.tmp_file).st_size) ",0,428
openstack%2Fmonasca-analytics~master~Ia1c26a7922a8cbf95c7dda8fa9fb2722985757be,openstack/monasca-analytics,master,Ia1c26a7922a8cbf95c7dda8fa9fb2722985757be,"documented DSL, and simplified the getting started page, by putting the config and DSL in separate MD files",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:42.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/getting_started.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/d26602c050278b25248bd61230454b17755139f7', 'message': 'documented DSL, and simplified the getting started page, by putting the config and DSL in separate MD files\n\nChange-Id: Ia1c26a7922a8cbf95c7dda8fa9fb2722985757be\n'}]",0,313469,d26602c050278b25248bd61230454b17755139f7,2,0,1,21739,,,0,"documented DSL, and simplified the getting started page, by putting the config and DSL in separate MD files

Change-Id: Ia1c26a7922a8cbf95c7dda8fa9fb2722985757be
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/69/313469/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/getting_started.md'],1,d26602c050278b25248bd61230454b17755139f7,,"and the other for logging. A Domain Specific Language (DSL) has been implemented in order to manipulate configurations. Please, see [MoNanas/Configuration](configuration.md) for more details on MoNanas configuration; and [MoNanas/Dsl](dsl.md) for more details on MoNanas DSL.","and the other for logging. ### Orchestrating Configuration > Note: Please refer to [Monasca/Design](design.md) to understand the concept of each component before creating or modifying a configuration. With the current implementation, a JSON file is used to configure how MoNanas orchestrates the data execution pipeline. This comes in different parts as follows. #### ID (`id`) A unique identifier for the configuration. #### Spark (`spark_config`) * `appName`: A string describing the Spark's application name. * `streaming`: Attributes for data streaming. * `batch_interval`: DStream's batch interval. #### Server (`server`) * `port`: Port number to listen. * `debug`: Debug mode. #### Sources (`sources`) `sources` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of sources. Each source has the following attributes: * `module`: The name of the python module used for connecting to the source. * `params`: A JSON object representing the source's parameters (e.g. data model used). #### Ingestors (`ingestors`) `ingestors` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of ingestors. Each ingestor has the following attributes: * `module`: The name of the python module implementing the ingestor. * `params`: A JSON object representing the ingestor's parameters (e.g. parameters for data conversion). #### Aggregators (`aggregators`) `aggregators` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of aggregators. Each aggregator has the following attributes: * `module`: The name of the python module implementing the aggregator. * `params`: A JSON object representing the aggregator's parameters (e.g. how data streams are aggregated). > Note: Currently, only one aggregator is supported - the python module is `default_aggregator`. #### SML Functions (`sml`) `sml` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of SML functions. Each SML function has the following attributes: * `module`: The name of the python module implementing the SML function. * `params`: A JSON object representing the SML function's parameters (e.g. number of samples, confidence interval). #### Voters (`voters`) `voters` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of voters. Each voter has the following attributes: * `module`: The name of the python module implementing the voter. * `params`: A JSON object representing the voter's parameters (e.g. weights, topology). #### Live Data Processors (`ldp`) `ldp` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of live data processors. Each live data processor has the following attributes: * `module`: The name of the python module implementing the live data processor. * `params`: A JSON object representing the live data processor's parameters (e.g. mode). #### Sinks (`sinks`) `sinks` is a JSON object (equivalent to python dictionary in this case) where the keys represent unique identifiers of sinks. Each sink has the following attributes: * `module`: The name of the python module used for connecting to the sink. * `params`: A JSON object representing the sink's parameters (e.g. server's details, data format). #### Connections `connections` is a JSON object (equivalent to python dictionary in this case) where each key represents a unique identifier of the component acting as the originating end of the data flow where its associated value is an list of unique identifiers of components acting as terminating ends of the data flow. The information described by `connections` can be used to represent the flow of data execution end-to-end. ### Logging Configuration #### MoNanas MoNanas comes with a default logging configuration. To change the logging properties including format, level, etc., simply override `$MONANAS_HOME/config/logging.json`. #### Spark By default, Spark's logging is at an INFO level. To avoid unnecessary console output, change `log4j.rootCategory=INFO, console` to `log4j.rootCategory=ERROR, console` in `$SPARK_HOME/conf/log4j.properties` or as preferred. > Note: Not required for a Vagrant generated VM. #### Other Software/Tools For logging configuration of other software/tools, please refer to their user guide.",3,120
openstack%2Fmonasca-analytics~master~I2c375e5bd6cada6dba4c2e7acdad3db6a2e7a3a4,openstack/monasca-analytics,master,I2c375e5bd6cada6dba4c2e7acdad3db6a2e7a3a4,finished the Dev Guide,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:38.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/dev_guide.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/71639077de921bb8574ac9a9be534816503ae2d1', 'message': 'finished the Dev Guide\n\nChange-Id: I2c375e5bd6cada6dba4c2e7acdad3db6a2e7a3a4\n'}]",0,313471,71639077de921bb8574ac9a9be534816503ae2d1,2,0,1,21739,,,0,"finished the Dev Guide

Change-Id: I2c375e5bd6cada6dba4c2e7acdad3db6a2e7a3a4
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/71/313471/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/dev_guide.md'],1,71639077de921bb8574ac9a9be534816503ae2d1,," When creating a new data source, everything you need is located in `main/source` package, and new sources should be contained in that package in order to keep the convention. All you need to do is extend the class `BaseSource` in `main/source/base.py` module. #### Default configuration and Validation The first step in the Data Source life-cycle is its creation and configuration validation. Also, a default configuration is needed by DSL in order to add a component to the configuration, and it can be very convenient for users to have a default configuration. Please, implement the following methods: * `validate_config` It should validate the schema of the configuration passed as parameter, checking that expected parameters are there, and values have the expected type and/or values. Please, check other classes validate_config implementations in order to have examples on how to use the Schema library. Please, make this method static by annotating it with the @staticmethod decorator. * `get_default_config` It should return a dictionary containing the default schema of this component. This method will be called by DSL when creating a component of this type. Please, make this method static by annotating it with the @staticmethod decorator. #### Main logic functions The aim of a source class is to provide data which will then be consumed by ingestors. When MoNanas is ordered to start streaming data, the source classes will be asked to create a stream of data, and other components in the pipeline may be interested in the features of the data provided by the source class. * `create_dstream` It should create a spark dstream using the Spark Streaming Context passed as parameter. Please, refer to spark documentation if you want more details about dstream object, and feel free to view implementations of this function by other source classes. * `get_feature_list` It should return a list of strings in order representing the features provided by the dstream. #### Termination functions When MoNanas is ordered to stop streaming data, it will call terminate_source in all the sources that are streaming. * `terminate_source` It should do any necessary cleanup of the source when it is terminated. For example, if the source was running a TCP server generating traffic, at this point it may want to stop it. `main/sml` package, and new algorithms should be contained in that package in order to keep the convention. All you need to do is extend the class `BaseSML` in `main/sml/base.py` module. #### Default configuration and Validation Please, refer to the 'Add New Data Sources' section. #### Main logic functions The aim of a SML class is to train a machine learning algorithm, or do statistics to learn something, using a batch of data provided by the aggregator. When data is available, it will be manipulated by the logic implemented in the learn_structure function; the data flow will be stopped by MoNanas when all the SMLs have consumed at least the number of samples provided by the number_of_samples_required function. * `learn_structure` This is the function that implements the logic of the algorithm. the data is provided as a parameter, and it should return the structure learned from the data (e.g. causality matrix, or trained classifier object). * `number_of_samples_required` this function should return the number of samples that the algorithm requires in order to provide reliable results.",> TODO`machine_learning_manager` package. All you need to do is extend the class `BaseMachineLearning` in `base_machine_learning` module. > TODO #### Validation of parameters,41,5
openstack%2Fmonasca-analytics~master~Iea50349a348d1a724c6aec99070b93a858593d3a,openstack/monasca-analytics,master,Iea50349a348d1a724c6aec99070b93a858593d3a,added the tests back,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:19.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/dsl/test_interpreter.py', 'test/dsl/test_dsl.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/03a960bc41d13d29822cf34804f170d8364fd04d', 'message': 'added the tests back\n\nChange-Id: Iea50349a348d1a724c6aec99070b93a858593d3a\n'}]",0,313468,03a960bc41d13d29822cf34804f170d8364fd04d,2,0,1,21739,,,0,"added the tests back

Change-Id: Iea50349a348d1a724c6aec99070b93a858593d3a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/68/313468/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/dsl/test_interpreter.py', 'test/dsl/test_dsl.py']",2,03a960bc41d13d29822cf34804f170d8364fd04d,,"#!/usr/bin/env python import os import json import copy from logging.config import dictConfig from unittest import TestCase from main.config import const from main.exception.dsl import DSLExistingConnection, DSLInvalidConnection from main.exception.monanas import MonanasNoSuchClassError from schema import SchemaError from main.dsl.dsl import MonanasDSL class TestMonanasDSL(TestCase): def setup_logging(self): current_dir = os.path.dirname(__file__) logging_config_file = os.path.join(current_dir, ""../resources/logging.json"") with open(logging_config_file, ""rt"") as f: config = json.load(f) dictConfig(config) def get_test_config_file_path(self): current_dir = os.path.dirname(__file__) return os.path.join(current_dir, ""../resources/test_json.json"") def setUp(self): self.setup_logging() config_file_path = self.get_test_config_file_path() self.dsl = MonanasDSL(config_file_path) self.original_config = copy.deepcopy(self.dsl._config) self.testing_new_source_config = { ""module"": ""KafkaSource"", ""params"": { ""zk_host"": ""myHost"", ""zk_port"": 1234, ""group_id"": ""myGroupId"", ""topics"": { ""myTopic1"": 1, ""myTopic2"": 2 } } } self.tmp_file = ""tmp_config_file.json"" def tearDown(self): if os.path.exists(self.tmp_file): os.remove(self.tmp_file) def test_generate_id(self): self.assertEqual(""src4"", self.dsl._generate_id(const.SOURCES)) self.assertEqual(""ing2"", self.dsl._generate_id(const.INGESTORS)) self.assertEqual(""sml2"", self.dsl._generate_id(const.SMLS)) self.assertEqual(""vot2"", self.dsl._generate_id(const.VOTERS)) self.assertEqual(""snk3"", self.dsl._generate_id(const.SINKS)) self.assertEqual(""ldp2"", self.dsl._generate_id(const.LDPS)) self.assertEqual(""src5"", self.dsl._generate_id(const.SOURCES)) self.assertEqual(""ing3"", self.dsl._generate_id(const.INGESTORS)) self.assertEqual(""sml3"", self.dsl._generate_id(const.SMLS)) self.assertEqual(""vot3"", self.dsl._generate_id(const.VOTERS)) self.assertEqual(""snk4"", self.dsl._generate_id(const.SINKS)) self.assertEqual(""ldp3"", self.dsl._generate_id(const.LDPS)) self.assertEqual(self.original_config, self.dsl._config) def test_generate_id_wrong_type(self): self.assertRaises(KeyError, self.dsl._generate_id, ""wrong_type"") def test_is_connected(self): self.assertTrue(self.dsl._is_connected(""src1"")) self.assertFalse(self.dsl._is_connected(""src2"")) self.assertTrue(self.dsl._is_connected(""ing1"")) self.assertTrue(self.dsl._is_connected(""sml1"")) self.assertTrue(self.dsl._is_connected(""vot1"")) self.assertTrue(self.dsl._is_connected(""snk1"")) self.assertTrue(self.dsl._is_connected(""snk2"")) self.assertTrue(self.dsl._is_connected(""ldp1"")) self.assertEqual(self.original_config, self.dsl._config) def test_component_defined(self): self.assertTrue(self.dsl._component_defined(""src1"")) self.assertFalse(self.dsl._component_defined(""fake_id"")) self.assertEqual(self.original_config, self.dsl._config) def test_validate_connection_by_ids(self): self.assertTrue(self.dsl._validate_connection_by_ids(""src1"", ""ing1"")) self.assertTrue(self.dsl._validate_connection_by_ids(""src1"", ""ldp1"")) self.assertFalse(self.dsl._validate_connection_by_ids(""src2"", ""sml1"")) self.assertFalse(self.dsl._validate_connection_by_ids(""ing1"", ""vot1"")) self.assertTrue(self.dsl._validate_connection_by_ids(""ldp1"", ""snk1"")) self.assertEqual(self.original_config, self.dsl._config) def test_add_component(self): new_id = self.dsl.add_component(self.testing_new_source_config) self.assertEqual(""src4"", new_id) expected_config = self.original_config expected_config[const.SOURCES][""src4""] = self.testing_new_source_config expected_config[const.CONNECTIONS][""src4""] = [] self.assertEqual(expected_config, self.dsl._config) def test_add_component_string(self): conf_str = json.dumps(self.testing_new_source_config) new_id = self.dsl.add_component(conf_str) self.assertEqual(""src4"", new_id) expected_config = self.original_config expected_config[const.SOURCES][""src4""] = self.testing_new_source_config expected_config[const.CONNECTIONS][""src4""] = [] self.assertEqual(expected_config, self.dsl._config) def test_add_component_wrong_config(self): del (self.testing_new_source_config[""params""][""zk_port""]) self.assertRaises(SchemaError, self.dsl.add_component, self.testing_new_source_config) self.assertEqual(self.original_config, self.dsl._config) def test_add_component_wrong_module(self): self.testing_new_source_config[""module""] = ""fake_module"" self.assertRaises(MonanasNoSuchClassError, self.dsl.add_component, self.testing_new_source_config) self.assertEqual(self.original_config, self.dsl._config) def test_modify_component(self): self.assertTrue(self.dsl.modify_component( ""src3"", [""params"", ""server_sleep_in_seconds""], 0.02)) expected_config = self.original_config expected_config[const.SOURCES][""src3""][""params""][ ""server_sleep_in_seconds""] = 0.02 self.assertEqual(expected_config, self.dsl._config) def test_modify_component_inexistent(self): self.assertFalse(self.dsl.modify_component( ""src8"", [""params"", ""server_sleep_in_seconds""], 0.02)) self.assertEqual(self.original_config, self.dsl._config) def test_modify_component_to_invalid_config(self): self.assertFalse(self.dsl.modify_component( ""src3"", [""fake"", ""fake_param""], 123)) self.assertEqual(self.original_config, self.dsl._config) def test_modify_dictionary_new_path(self): original = self.original_config[""voters""][""vot1""] modified = self.dsl._modify_dictionary( original, [""params"", ""param1"", ""subparam1A""], ""new_value"") expected = { ""module"": ""voter_module"", ""params"": { ""param1"": { ""subparam1A"": ""new_value"" } } } self.assertEqual(expected, modified) def test_modify_dictioinary_overwrite_value(self): original = self.original_config[""sources""][""src1""] modified = self.dsl._modify_dictionary( original, [""params"", ""param1""], ""new_value"") expected = { ""module"": ""src_module1"", ""params"": { ""param1"": ""new_value"", ""param2"": ""val2"", ""model_id"": 3 } } self.assertEqual(expected, modified) def test_modify_dictionary_overwrite_path(self): original = self.original_config[""sources""][""src1""] modified = self.dsl._modify_dictionary( original, [""params""], ""new_value"") expected = { ""module"": ""src_module1"", ""params"": ""new_value"" } self.assertEqual(expected, modified) def test_remove_unconnected_component(self): self.assertTrue(self.dsl.remove_component(""src2"")) expected_config = self.original_config del(expected_config[const.SOURCES][""src2""]) del(expected_config[const.CONNECTIONS][""src2""]) self.assertEqual(expected_config, self.dsl._config) def test_remove_connected_component(self): self.assertRaises(DSLExistingConnection, self.dsl.remove_component, ""src1"") self.assertEqual(self.original_config, self.dsl._config) def test_remove_component_wrong_id(self): self.assertFalse(self.dsl.remove_component(""fake_id"")) self.assertEqual(self.original_config, self.dsl._config) def test_connect_component_new_allowed(self): self.assertTrue(self.dsl.connect_components(""src2"", ""ing1"")) expected_config = self.original_config expected_config[const.CONNECTIONS][""src2""].append(""ing1"") self.assertEqual(self.original_config, self.dsl._config) def test_connect_existing(self): self.assertFalse(self.dsl.connect_components(""src1"", ""ing1"")) self.assertEqual(self.original_config, self.dsl._config) def test_connect_component_new_forbidden(self): self.assertRaises(DSLInvalidConnection, self.dsl.connect_components, ""src1"", ""vot1"") self.assertEqual(self.original_config, self.dsl._config) def test_disconnect(self): self.assertTrue(self.dsl.disconnect_components(""src1"", ""ing1"")) expected_config = self.original_config expected_config[const.CONNECTIONS][""src1""] = [""ldp1""] self.assertEqual(self.original_config, self.dsl._config) def test_disconnect_inexistent_components(self): self.assertFalse(self.dsl.disconnect_components(""fake_1"", ""fake_2"")) self.assertFalse(self.dsl.disconnect_components(""fake_id"", ""snk1"")) self.assertFalse(self.dsl.disconnect_components(""src1"", ""fake_id"")) self.assertEqual(self.original_config, self.dsl._config) def test_disconnect_inexistent_connection(self): self.assertFalse(self.dsl.disconnect_components(""src2"", ""ing1"")) self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_overwrite_no_file(self): self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=True)) self.dsl._config = None self.dsl.load_configuration(self.tmp_file) self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_not_overwrite_no_file(self): self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=False)) self.dsl._config = None self.dsl.load_configuration(self.tmp_file) self.assertEqual(self.original_config, self.dsl._config) def _create_dirty_fyle(self, fname): with open(fname, ""w"") as f: f.write(""This content may be overwritten"") def test_save_configuration_overwrite_file(self): self._create_dirty_fyle(self.tmp_file) self.assertTrue( self.dsl.save_configuration(self.tmp_file, overwrite_file=True)) self.dsl._config = None self.dsl.load_configuration(""tmp_config_file.json"") self.assertEqual(self.original_config, self.dsl._config) def test_save_configuration_not_overwrite_file(self): self._create_dirty_fyle(self.tmp_file) old_size = os.stat(self.tmp_file).st_size self.assertFalse( self.dsl.save_configuration(self.tmp_file, overwrite_file=False)) self.assertEqual(old_size, os.stat(self.tmp_file).st_size) ",,428,0
openstack%2Fmonasca-analytics~master~I62a8e7b48bb3aeb0e1ab61a06752804d7cc35cf6,openstack/monasca-analytics,master,I62a8e7b48bb3aeb0e1ab61a06752804d7cc35cf6,added the comma,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:13.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/examples.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3877f06b0c3016de2958388e949da3b617a435f8', 'message': 'added the comma\n\nChange-Id: I62a8e7b48bb3aeb0e1ab61a06752804d7cc35cf6\n'}]",0,313472,3877f06b0c3016de2958388e949da3b617a435f8,2,0,1,21739,,,0,"added the comma

Change-Id: I62a8e7b48bb3aeb0e1ab61a06752804d7cc35cf6
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/72/313472/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/examples.md'],1,3877f06b0c3016de2958388e949da3b617a435f8,," ""ldp1"": [""snk1""],"," ""ldp1"": [""snk1""]",1,1
openstack%2Fmonasca-analytics~master~I686193c839cf08d64f9e8e364b6c5bc72c17a66c,openstack/monasca-analytics,master,I686193c839cf08d64f9e8e364b6c5bc72c17a66c,added svm one class SML and iptables LDP,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:10.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/iptables_anomalies.json', 'main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py', 'test/ingestor/test_iptables_ingestor.py', 'test/sml/test_svm_one_class.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/246327f8e272a557cff33dcee6c945034ef7da27', 'message': 'added svm one class SML and iptables LDP\n\nChange-Id: I686193c839cf08d64f9e8e364b6c5bc72c17a66c\n'}]",0,313475,246327f8e272a557cff33dcee6c945034ef7da27,2,0,1,21739,,,0,"added svm one class SML and iptables LDP

Change-Id: I686193c839cf08d64f9e8e364b6c5bc72c17a66c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/75/313475/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/iptables_anomalies.json', 'main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py', 'test/ingestor/test_iptables_ingestor.py', 'test/sml/test_svm_one_class.py']",5,246327f8e272a557cff33dcee6c945034ef7da27,,"#!/usr/bin/env python from main.sml.svm_one_class import SvmOneClass import numpy as np import logging import unittest logger = logging.getLogger(__name__) class TestSvmOneClass(unittest.TestCase): def setUp(self): unittest.TestCase.setUp(self) self.svm = SvmOneClass(""fakeid"", {""module"": ""fake""}) def tearDown(self): unittest.TestCase.tearDown(self) def get_testing_data(self): a = np.random.uniform(size=1000) b = np.random.uniform(size=1000) c = np.random.uniform(size=1000) d = np.random.uniform(size=1000) return np.array([a, b, c, d]).T def test_generate_train_test_sets(self): data = self.get_testing_data() train, test = self.svm._generate_train_test_sets(data, 0.6) self.assertEqual(600, len(train)) self.assertEqual(400, len(test)) def test_learn_structure(self): data = self.get_testing_data() clf = self.svm.learn_structure(data) print str(clf) if __name__ == ""__main__"": unittest.main() ",,80,7
openstack%2Fmonasca-analytics~master~Ic9e1c4e2332e09462d25d3bf6d74f6179c7e33af,openstack/monasca-analytics,master,Ic9e1c4e2332e09462d25d3bf6d74f6179c7e33af,fixed and added tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:32:02.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/mocks/classifier_mock.py', 'test/ldp/test_iptables_ldp.py', 'test/util/test_common_util.py', 'main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py', 'test/sml/test_svm_one_class.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/247e0fda56cf2ce1b179b8075bf8adda39e81484', 'message': 'fixed and added tests\n\nChange-Id: Ic9e1c4e2332e09462d25d3bf6d74f6179c7e33af\n'}]",0,313477,247e0fda56cf2ce1b179b8075bf8adda39e81484,2,0,1,21739,,,0,"fixed and added tests

Change-Id: Ic9e1c4e2332e09462d25d3bf6d74f6179c7e33af
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/77/313477/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/mocks/classifier_mock.py', 'test/ldp/test_iptables_ldp.py', 'test/util/test_common_util.py', 'main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py', 'test/sml/test_svm_one_class.py']",6,247e0fda56cf2ce1b179b8075bf8adda39e81484,,"from sklearn import svm self.assertTrue(isinstance(clf, svm.OneClassSVM))", print str(clf),97,6
openstack%2Fmonasca-analytics~master~I49cd1e7bf04464424f4d8ac5c4dcc21c44dc37e1,openstack/monasca-analytics,master,I49cd1e7bf04464424f4d8ac5c4dcc21c44dc37e1,changed SVM configuration to reduce the number of false alarms during anomaly detection.,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:56.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sml/svm_one_class.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/89274b9fec3d19edd5432dedd8d84e2a72ab42b1', 'message': 'changed SVM configuration to reduce the number of false alarms during anomaly detection.\n\nChange-Id: I49cd1e7bf04464424f4d8ac5c4dcc21c44dc37e1\n'}]",0,313478,89274b9fec3d19edd5432dedd8d84e2a72ab42b1,2,0,1,21739,,,0,"changed SVM configuration to reduce the number of false alarms during anomaly detection.

Change-Id: I49cd1e7bf04464424f4d8ac5c4dcc21c44dc37e1
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/78/313478/1 && git format-patch -1 --stdout FETCH_HEAD,['main/sml/svm_one_class.py'],1,89274b9fec3d19edd5432dedd8d84e2a72ab42b1,,"ANOMALY = -1 NON_ANOMALY = 1OUTLIERS_FRACTION = 0.10 svm_detector = svm.OneClassSVM(nu=0.95 * OUTLIERS_FRACTION + 0.05, kernel=""rbf"", gamma=0.1)","ANOMALY = 1 NON_ANOMALY = -1 svm_detector = svm.OneClassSVM(kernel=""rbf"")",5,3
openstack%2Fmonasca-analytics~master~I70b9c7a1c7f93f9fe5bccdbc18fb7bcde6712041,openstack/monasca-analytics,master,I70b9c7a1c7f93f9fe5bccdbc18fb7bcde6712041,fixed the config validation and get default config methods in SVM One Class and IPTables LDP. Also removed a test that was testing something that was removed,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:51.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py', 'test/ingestor/test_iptables_ingestor.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f2c9b27feb4737a95bfc3cd628c1298ff45c5b1e', 'message': 'fixed the config validation and get default config methods in SVM One Class and IPTables LDP. Also removed a test that was testing something that was removed\n\nChange-Id: I70b9c7a1c7f93f9fe5bccdbc18fb7bcde6712041\n'}]",0,313479,f2c9b27feb4737a95bfc3cd628c1298ff45c5b1e,2,0,1,21739,,,0,"fixed the config validation and get default config methods in SVM One Class and IPTables LDP. Also removed a test that was testing something that was removed

Change-Id: I70b9c7a1c7f93f9fe5bccdbc18fb7bcde6712041
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/79/313479/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/ldp/iptables_ldp.py', 'main/sml/svm_one_class.py', 'test/ingestor/test_iptables_ingestor.py']",3,f2c9b27feb4737a95bfc3cd628c1298ff45c5b1e,,," def test_parse_timestamp(self): t = self.ip_ing._parse_timestamp(self.rdd_entry[""ctime""]) self.assertEqual(type(t), int) self.assertEqual(1460404752, t) ",12,7
openstack%2Fmonasca-analytics~master~I68e2ae4e8cfeb15717db068f5501e314e925b0df,openstack/monasca-analytics,master,I68e2ae4e8cfeb15717db068f5501e314e925b0df,fixed base_sqlite and implemented tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:48.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/base_sqlite.py', 'test/mocks/spark_mocks.py', 'test/sink/test_iptables_sqlite.py', 'test/sink/test_base_sqlite.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/87c56f5edb325da482a0942399a07fc5447d57aa', 'message': 'fixed base_sqlite and implemented tests\n\nChange-Id: I68e2ae4e8cfeb15717db068f5501e314e925b0df\n'}]",0,313481,87c56f5edb325da482a0942399a07fc5447d57aa,2,0,1,21739,,,0,"fixed base_sqlite and implemented tests

Change-Id: I68e2ae4e8cfeb15717db068f5501e314e925b0df
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/81/313481/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/sink/base_sqlite.py', 'test/mocks/spark_mocks.py', 'test/sink/test_iptables_sqlite.py', 'test/sink/test_base_sqlite.py']",4,87c56f5edb325da482a0942399a07fc5447d57aa,,"from main.sink import base_sqlite as bsql from test.mocks.spark_mocks import MockRDD from schema import SchemaErrorimport sqlite3 import os import numpy as np import cPickle class BaseSQLiteSinkDummyExtension(bsql.BaseSQLiteSink): def _rdds_table_create_query(self): return """"""CREATE TABLE IF NOT EXISTS rdds (fake_col1 TEXT, fake_col2 TEXT)"""""" def _rdd_insert_query(self, rdd_json): return ('INSERT INTO rdds VALUES(""' + rdd_json[""one""] + '"", ""' + rdd_json[""two""] + '"")') class TestSQLiteSink(unittest.TestCase): self._valid_config = {""module"": ""BaseSQLiteSinkDummyExtension""} self.snk = BaseSQLiteSinkDummyExtension(""fake_id"", self._valid_config) def get_rdd_mock(self): rdd = MockRDD(None, None, None) rdd_entries = [{""one"": ""row1col1"", ""two"": ""row1col2""}, {""one"": ""row2col1"", ""two"": ""row2col2""}, {""one"": ""row3col1"", ""two"": ""row3col2""}] rdd.set_rdd_entries(rdd_entries) return rdd def assert_rdd_written_to_db(self, rdd): with sqlite3.connect(""sqlite_sink.db"") as conn: c = conn.cursor() for row in c.execute('SELECT * FROM rdds'): if self._find_row_in_rdd(row, rdd): return self.fail(""Did not find rdd in database"") def _find_row_in_rdd(self, row, rdd): for rdd_entry in rdd._rdd_entries: if rdd_entry[""one""] == row[0] and rdd_entry[""two""] == row[1]: return True return False def assert_sml_written_to_db(self, sml, voter_id): with sqlite3.connect(""sqlite_sink.db"") as conn: c = conn.cursor() c.execute('SELECT sml FROM smls WHERE voter_id = ""' + voter_id + '""') fetched_sml = c.fetchone() fetched_sml = cPickle.loads(str(fetched_sml[0])) self.assertEqual(len(sml), len(fetched_sml)) self.assertTrue((sml == fetched_sml).all()) def test_validate_valid_config_no_dbname(self): conf = {""module"": ""BaseSQLiteSinkDummyExtension""} self.snk.validate_config(conf) def test_validate_valid_config_with_dbname(self): conf = {""module"": ""BaseSQLiteSinkDummyExtension"", ""db_name"": ""mySQLite.db""} self.snk.validate_config(conf) def test_validate_config_no_module(self): conf = {""db_name"": ""mySQLite.db""} self.assertRaises(SchemaError, self.snk.validate_config, conf) def test_validate_config_extra_param(self): conf = {""module"": ""BaseSQLiteSinkDummyExtension"", ""infiltrated"": ""I shouldn't be here""} self.assertRaises(SchemaError, self.snk.validate_config, conf) def test_get_db_name(self): conf = {""db_name"": ""mySQLite.db""} db_name = self.snk._get_db_name(conf) self.assertEqual(""mySQLite.db"", db_name) def test_get_db_name_default(self): conf = {""module"": ""BaseSQLiteSinkDummyExtension""} db_name = self.snk._get_db_name(conf) self.assertEqual(bsql.DB_NAME_DEFAULT, db_name) def test_persist(self): rdd = self.get_rdd_mock() self.snk._persist(None, rdd) self.assert_rdd_written_to_db(rdd) def test_sink_ml_array(self): sml = np.array([[1, 2, 3], [""a"", ""b"", ""c""], [.1, .5, .9]]) self.snk.sink_ml(""vot1"", sml) self.assert_sml_written_to_db(sml, ""vot1"") os.remove(""sqlite_sink.db"")","from main.sink.iptables_sqlite import IptablesSQLiteSink class TestIptablesSQLiteSink(unittest.TestCase): self._valid_config = {""module"": ""IptablesSQLiteSink""} self.snk = IptablesSQLiteSink(""fake_id"", self._valid_config) def test_rdd_insert_query_valid_rdd(self): rdd_entry = { ""msg"": ""test message"", ""id"": 1, ""anomalous"": True, ""ctime"": ""t1"" } query = self.snk._rdd_insert_query(rdd_entry) self.assertEqual( 'INSERT INTO rdds VALUES(""test message"", ""True"", ""1"", ""t1"")', query) def test_rdd_insert_query_invalid_rdd(self): rdd_entry = { ""msg"": ""test message"", ""anomalous"": True, ""ctime"": ""t1"" } self.assertRaises(KeyError, self.snk._rdd_insert_query, rdd_entry)",108,29
openstack%2Fmonasca-analytics~master~I3ad74c133e0083020885f3418d4f1651df2889b4,openstack/monasca-analytics,master,I3ad74c133e0083020885f3418d4f1651df2889b4,"implemented the default config and config validation functions in iptalbes_sqlite, as it depends on each extension of base_sqlite. Also made the methods static, as expected",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:43.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/base_sqlite.py', 'test/sink/test_base_sqlite.py', 'main/sink/iptables_sqlite.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/572017b597055cb6403e1a7678f59e837b5c45b6', 'message': 'implemented the default config and config validation functions in iptalbes_sqlite, as it depends on each extension of base_sqlite. Also made the methods static, as expected\n\nChange-Id: I3ad74c133e0083020885f3418d4f1651df2889b4\n'}]",0,313482,572017b597055cb6403e1a7678f59e837b5c45b6,2,0,1,21739,,,0,"implemented the default config and config validation functions in iptalbes_sqlite, as it depends on each extension of base_sqlite. Also made the methods static, as expected

Change-Id: I3ad74c133e0083020885f3418d4f1651df2889b4
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/82/313482/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/sink/base_sqlite.py', 'test/sink/test_base_sqlite.py', 'main/sink/iptables_sqlite.py']",3,572017b597055cb6403e1a7678f59e837b5c45b6,,"from schema import Schema, And, Optional @staticmethod def get_default_config(): return { ""module"": IptablesSQLiteSink.__name__, ""params"": { ""db_name"": ""sqlite_sink.db"" } } @staticmethod def validate_config(_config): return Schema({ ""module"": And(basestring, lambda i: not any(c.isspace() for c in i)), Optional(""db_name""): And( basestring, lambda i: not any(c.isspace() for c in i)), }).validate(_config)",,38,9
openstack%2Fmonasca-analytics~master~I69d1955723c36062de40da43b48455a99050f347,openstack/monasca-analytics,master,I69d1955723c36062de40da43b48455a99050f347,"created base and iptables sqlite sink, and started implementing unit tests",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:38.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/base_sqlite.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f76a60f477f109207597c3cdab35d0117ce32dde', 'message': 'created base and iptables sqlite sink, and started implementing unit tests\n\nChange-Id: I69d1955723c36062de40da43b48455a99050f347\n'}]",0,313483,f76a60f477f109207597c3cdab35d0117ce32dde,2,0,1,21739,,,0,"created base and iptables sqlite sink, and started implementing unit tests

Change-Id: I69d1955723c36062de40da43b48455a99050f347
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/83/313483/1 && git format-patch -1 --stdout FETCH_HEAD,['main/sink/base_sqlite.py'],1,f76a60f477f109207597c3cdab35d0117ce32dde,,"from schema import Schema, And, Optional def validate_config(self, _config): return Schema({ ""module"": And(basestring, lambda i: not any(c.isspace() for c in i)), Optional(""db_name""): And( basestring, lambda i: not any(c.isspace() for c in i)), }).validate(_config) return self._config[""db_name""] logger.info(""Query = "" + query) c.execute(""INSERT INTO rdds VALUES(?,?,?)"", timestamp, voter_id, matrix)"," return _config[""db_name""] blob_matrix = cPickle.dumps(matrix, cPickle.HIGHEST_PROTOCOL) c.execute( 'INSERT INTO smls (timestamp, voter_id, sml) VALUES(?, ?, ?);', [timestamp, voter_id, sqlite3.Binary(blob_matrix)])",13,5
openstack%2Fmonasca-analytics~master~Ib6d620e79bf40774510189d51059da28bfa54069,openstack/monasca-analytics,master,Ib6d620e79bf40774510189d51059da28bfa54069,fixed base_sqlite and implemented tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:35.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/base_sqlite.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b810e2ee2c669f9b216b3db3eaeb991e85c34179', 'message': 'fixed base_sqlite and implemented tests\n\nChange-Id: Ib6d620e79bf40774510189d51059da28bfa54069\n'}]",0,313484,b810e2ee2c669f9b216b3db3eaeb991e85c34179,2,0,1,21739,,,0,"fixed base_sqlite and implemented tests

Change-Id: Ib6d620e79bf40774510189d51059da28bfa54069
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/84/313484/1 && git format-patch -1 --stdout FETCH_HEAD,['main/sink/base_sqlite.py'],1,b810e2ee2c669f9b216b3db3eaeb991e85c34179,," return _config[""db_name""] blob_matrix = cPickle.dumps(matrix, cPickle.HIGHEST_PROTOCOL) c.execute( 'INSERT INTO smls (timestamp, voter_id, sml) VALUES(?, ?, ?);', [timestamp, voter_id, sqlite3.Binary(blob_matrix)])"," return self._config[""db_name""] logger.info(""Query = "" + query) c.execute(""INSERT INTO rdds VALUES(?,?,?)"", timestamp, voter_id, matrix)",5,4
openstack%2Fmonasca-analytics~master~I26638fa98df8837af6b80bf070b685e7551bfb15,openstack/monasca-analytics,master,I26638fa98df8837af6b80bf070b685e7551bfb15,"added sinks to the config file, and implemented stdoutSink to print data to screen, instead of doing it directly from ldp",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:31.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/sink/stdout_sink.py', 'config/iptables_anomalies.json', 'main/ldp/iptables_ldp.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/49cea2f364a0027b7c26baab000e5a76d842c6ae', 'message': 'added sinks to the config file, and implemented stdoutSink to print data to screen, instead of doing it directly from ldp\n\nChange-Id: I26638fa98df8837af6b80bf070b685e7551bfb15\n'}]",0,313485,49cea2f364a0027b7c26baab000e5a76d842c6ae,2,0,1,21739,,,0,"added sinks to the config file, and implemented stdoutSink to print data to screen, instead of doing it directly from ldp

Change-Id: I26638fa98df8837af6b80bf070b685e7551bfb15
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/85/313485/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/sink/stdout_sink.py', 'config/iptables_anomalies.json', 'main/ldp/iptables_ldp.py']",3,49cea2f364a0027b7c26baab000e5a76d842c6ae,," return dstream.flatMap(lambda r: self._detect_anomalies(r, data))"," new_dstream = dstream.flatMap(lambda r: self._detect_anomalies(r, data)) new_dstream.pprint() return new_dstream",36,6
openstack%2Fmonasca-analytics~master~I50ae48e36c71f642ace0d3f1a34383c47477e580,openstack/monasca-analytics,master,I50ae48e36c71f642ace0d3f1a34383c47477e580,modified example config for iptables,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:27.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/examples.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3f00d36928b07be0550f3d6c75b9655ee3f8e45c', 'message': 'modified example config for iptables\n\nChange-Id: I50ae48e36c71f642ace0d3f1a34383c47477e580\n'}]",0,313486,3f00d36928b07be0550f3d6c75b9655ee3f8e45c,2,0,1,21739,,,0,"modified example config for iptables

Change-Id: I50ae48e36c71f642ace0d3f1a34383c47477e580
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/86/313486/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/examples.md'],1,3f00d36928b07be0550f3d6c75b9655ee3f8e45c,," }, ""snk2"": { ""module"": ""StdoutSink"" ""ldp1"": [""snk1"", ""snk2""], ""snk1"": [], ""snk2"": []"," ""ldp1"": [""snk1""], ""snk1"": []",6,2
openstack%2Fmonasca-analytics~master~Iaf5b683700e3244b01058fad0388d7f24e51ee84,openstack/monasca-analytics,master,Iaf5b683700e3244b01058fad0388d7f24e51ee84,added missing line,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:22.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['config/iptables_anomalies.json'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f148ad009e768682815d4e1913d11a23950067a3', 'message': 'added missing line\n\nChange-Id: Iaf5b683700e3244b01058fad0388d7f24e51ee84\n'}]",0,313487,f148ad009e768682815d4e1913d11a23950067a3,2,0,1,21739,,,0,"added missing line

Change-Id: Iaf5b683700e3244b01058fad0388d7f24e51ee84
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/87/313487/1 && git format-patch -1 --stdout FETCH_HEAD,['config/iptables_anomalies.json'],1,f148ad009e768682815d4e1913d11a23950067a3,,} ,},1,1
openstack%2Fmonasca-analytics~master~I4bf1d78b1ca7dbb5fb2dca722fb6c245a173b732,openstack/monasca-analytics,master,I4bf1d78b1ca7dbb5fb2dca722fb6c245a173b732,replaced all the comments to follow the convention defined in http://docs.openstack.org/developer/hacking/#docstrings,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:31:05.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'main/source/markov_chain/prob_checks.py', 'main/util/math.py', 'main/component/base.py', 'main/source/markov_chain/transition.py', 'main/util/singleton.py', 'main/spark/driver.py', 'main/source/markov_chain/events.py', 'main/sink/iptables_sqlite.py', 'main/sml/svm_one_class.py', 'main/dsl/interpreter.py', 'main/spark/aggregator.py', 'main/source/kafka.py', 'main/sink/base_sqlite.py', 'main/sink/stdout_sink.py', 'main/ingestor/base.py', 'main/config/config.py', 'main/config/creation.py', 'main/source/markov_chain/base.py', 'main/ingestor/iptables.py', 'main/sink/base.py', 'main/ldp/monasca/base.py', 'main/source/random.py', 'main/dsl/dsl.py', 'main/sink/kafkas.py', 'main/ldp/base.py', 'main/sink/sink_config_validator.py', 'main/ldp/iptables_ldp.py', 'main/ldp/cloud_causality.py', 'main/web_service/request_handler.py', 'main/monanas.py', 'main/sml/base.py', 'main/voter/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/ingestor/cloud.py', 'main/sml/lingam.py', 'main/source/markov_chain/state_check.py', 'main/util/common_util.py', 'main/web_service/web_service.py', 'main/source/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/50f0fda94f2eddb8e7c6f3a0b6c41897ed8753d1', 'message': 'replaced all the comments to follow the convention defined in http://docs.openstack.org/developer/hacking/#docstrings\n\nChange-Id: I4bf1d78b1ca7dbb5fb2dca722fb6c245a173b732\n'}]",0,313489,50f0fda94f2eddb8e7c6f3a0b6c41897ed8753d1,2,0,1,21739,,,0,"replaced all the comments to follow the convention defined in http://docs.openstack.org/developer/hacking/#docstrings

Change-Id: I4bf1d78b1ca7dbb5fb2dca722fb6c245a173b732
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/89/313489/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'main/source/markov_chain/prob_checks.py', 'main/util/math.py', 'main/component/base.py', 'main/source/markov_chain/transition.py', 'main/util/singleton.py', 'main/spark/driver.py', 'main/source/markov_chain/events.py', 'main/sink/iptables_sqlite.py', 'main/sml/svm_one_class.py', 'main/dsl/interpreter.py', 'main/spark/aggregator.py', 'main/source/kafka.py', 'main/sink/base_sqlite.py', 'main/sink/stdout_sink.py', 'main/ingestor/base.py', 'main/config/config.py', 'main/config/creation.py', 'main/source/markov_chain/base.py', 'main/ingestor/iptables.py', 'main/sink/base.py', 'main/ldp/monasca/base.py', 'main/source/random.py', 'main/dsl/dsl.py', 'main/sink/kafkas.py', 'main/ldp/base.py', 'main/sink/sink_config_validator.py', 'main/ldp/iptables_ldp.py', 'main/ldp/cloud_causality.py', 'main/web_service/request_handler.py', 'main/monanas.py', 'main/sml/base.py', 'main/voter/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/ingestor/cloud.py', 'main/sml/lingam.py', 'main/source/markov_chain/state_check.py', 'main/util/common_util.py', 'main/web_service/web_service.py', 'main/source/base.py']",41,50f0fda94f2eddb8e7c6f3a0b6c41897ed8753d1,," """"""Base class for source provider """"""Returns the list of features names. :returns: list[str] """"""Create a dstream to be consumed by Monanas. :param ssc: pyspark.streaming.StreamingContext -- Spark streaming context. It shouldn't be stored by the source. :returns: pyspark.streaming.DStream -- a Spark dstream to be consumed by Monanas. """"""Terminate the source."," """""" Base class for source provider. """""" Returns the list of features names. @rtype: list[str] """""" Create a dstream to be consumed by Monanas. @type ssc: pyspark.streaming.StreamingContext @param ssc: Spark streaming context. It shouldn't be stored by the source. @rtype: pyspark.streaming.DStream @return: Returns a Spark dstream to be consumed by Monanas. """""" Terminate the source.",740,721
openstack%2Fmonasca-analytics~master~I9e147dc8c3a36c5e4b3a18f7346e3b6914aa507a,openstack/monasca-analytics,master,I9e147dc8c3a36c5e4b3a18f7346e3b6914aa507a,replaced the config file in the alerts example with the markov_chain config file that works,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:30:46.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['doc/examples.md'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/923a051eeaf1fe964d5e2f02016d2a59d37b16c5', 'message': 'replaced the config file in the alerts example with the markov_chain config file that works\n\nChange-Id: I9e147dc8c3a36c5e4b3a18f7346e3b6914aa507a\n'}]",0,313488,923a051eeaf1fe964d5e2f02016d2a59d37b16c5,2,0,1,21739,,,0,"replaced the config file in the alerts example with the markov_chain config file that works

Change-Id: I9e147dc8c3a36c5e4b3a18f7346e3b6914aa507a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/88/313488/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/examples.md'],1,923a051eeaf1fe964d5e2f02016d2a59d37b16c5,,"we want MoNanas to orchestrate the data execution (creating a pipeline). You can find the following configuration in `$HOME/config/markov_source_config.json`: ""spark_config"": { ""appName"": ""testApp"", ""streaming"": { ""batch_interval"": 1 } ""server"": { ""port"": 3000, ""debug"": false ""sources"": { ""src1"": { ""module"": ""CloudMarkovChainSource"", ""params"": { ""server_sleep_in_seconds"": 0.01 }, ""transitions"": { ""web_service"": { ""run=>slow"": { ""0"": 0.001, ""8"": 0.02, ""12"": 0.07, ""14"": 0.07, ""22"": 0.03, ""24"": 0.001 }, ""slow=>run"": { ""0"": 0.99, ""8"": 0.7, ""12"": 0.1, ""14"": 0.1, ""22"": 0.8, ""24"": 0.99 }, ""stop=>run"": 0.7 }, ""host"": { ""on=>off"": 0.005, ""off=>on"": 0.5 }, ""switch"": { ""on=>off"": 0.01, ""off=>on"": 0.7 } }, ""triggers"": { ""support"": { ""get_called"": { ""0"": 0.1, ""8"": 0.2, ""12"": 0.8, ""14"": 0.8, ""22"": 0.5, ""24"": 0.0 } } }, ""graph"": { ""h1:host"": [""s1""], ""h2:host"": [""s1""], ""s1:switch"": [], ""w1:web_service"": [""h1""], ""w2:web_service"": [""h2""] } } }, ""ingestors"": { ""ing1"": { ""module"": ""CloudIngestor"" } }, ""smls"": { ""sml1"": { ""module"": ""LiNGAM"", ""params"": { ""threshold"": 0.5 } } }, ""voters"": { ""vot1"": { ""module"": ""PickIndexVoter"", ""params"": { ""index"": 0 } } }, ""sinks"": { ""snk1"": { ""module"": ""KafkaSink"", ""params"": { ""host"": ""localhost"", ""port"": 9092, ""topic"": ""transformed_alerts"" } } }, ""ldps"": { ""ldp1"": { ""module"": ""CloudCausalityLDP"" } }, ""connections"": { ""src1"": [""ing1"", ""ldp1""], ""sml1"": [""vot1""], ""ing1"": [], ""vot1"": [""ldp1""], ""ldp1"": [""snk1""], ""snk1"": [] }, ""feedback"": {}are ingested from `src1` where Monasca-like alerts are being generated using Markov Chain process. The data are then ingested by `ing1` wherethere is only one ingestor, hence the implicit aggregator (not defined in the configuration) simply forwards the data to `sml1`, which simply deduplicates the data then uses LiNGAM algorithm to find a causality structure of the aggregated data then passes the result (structure) to `vot1`. The voter is configured to pick the output of the first SML function and forwards that to `ldp1`. Here, the live data processor transforms data streamed from `src1` using the causality structure and pushes it to standard output as well as the specified Kafka server.","we want MoNanas to orchestrate the data execution (creating a pipeline). Copy and paste the following configuration into a file, e.g. `$HOME/tmp/alert_example.json`. ""id"": ""6b338dd3-056b-4065-a6d8-8738219b3a50"", ""spark_config"": { ""appName"": ""alert_fatigue_management_example"", ""streaming"": { ""batch_interval"": 1 } }, ""server"": { ""port"": 3000, ""debug"": true }, ""sources"": { ""source_1"": { ""module"": ""monasca_markov_chain_source"", ""params"": {} } }, ""ingestors"": { ""ingestor_1"": { ""module"": ""monasca_ingestor"", ""params"": {} } }, ""aggregators"": { ""aggregator_1"": { ""module"": ""default_aggregator"", ""params"": {} } }, ""sml"": { ""sml_1"": { ""module"": ""filter"", ""params"": { ""mode"": ""deduplicate"" } ""sml_2"": { ""module"": ""lingam_algorithm"", ""params"": { ""threshold"": 0.5 } } }, ""voters"": { ""voter_1"": { ""module"": ""pick_voter"", ""params"": { ""index"": 0 } } }, ""ldp"": { ""ldp_1"": { ""module"": ""causality_ldp"", ""params"": { ""mode"": ""aggregate"" } } }, ""sinks"": { ""sink_1"": { ""module"": ""stdout_sink"", ""params"": {} ""sink_2"": { ""module"": ""kafka_sink"", ""params"": { ""host"": ""localhost"", ""port"": 9092, ""topic"": ""transformed_alerts"" } } }, ""connections"": { ""source_1"": [""ingestor_1"", ""ldp_1""], ""ingestor_1"": [""aggregator_1""], ""aggregator_1"": [""sml_1""], ""sml_1"": [""sml_2""], ""sml_2"": [""voter_1""], ""voter_1"": [""ldp_1""], ""ldp_1"": [""sink_1"", ""sink_2""] }are ingested from `source_1` where Monasca-like alerts are being generated using Markov Chain process. The data are then ingested by `ingestor_1` wherethere is only one ingestor, hence `aggregator_1` simply forwards the data to `sml_1`, which simply deduplicates the data then forwards it to `sml_2`. This SML function uses LiNGAM to find a causality structure of the aggregated data then passes the result (structure) to `voter_1`. The voter is configured to pick the output of the first SML function and forwards that to `ldp_1`. Here, the live data processor transforms data streamed from `source_1` using the causality structure and pushes it to standard output as well as the specified Kafka server.",122,93
openstack%2Fmonasca-analytics~master~If99cf639059bd4a01513958fe8489d377d958d4a,openstack/monasca-analytics,master,If99cf639059bd4a01513958fe8489d377d958d4a,"proper types (str, dict, etc)",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:30:41.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/dsl/dsl.py', 'main/source/iptables_markov_chain.py', 'main/component/base.py', 'main/source/markov_chain/transition.py', 'main/ldp/base.py', 'main/spark/driver.py', 'main/source/markov_chain/events.py', 'main/ldp/iptables_ldp.py', 'main/dsl/interpreter.py', 'main/ingestor/base.py', 'main/config/config.py', 'main/config/creation.py', 'main/monanas.py', 'main/ingestor/iptables.py', 'main/config/connection.py', 'main/config/validation.py', 'main/util/common_util.py', 'main/source/random.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b4558c13d89a926f62db7de19a5e93e215bbf153', 'message': 'proper types (str, dict, etc)\n\nChange-Id: If99cf639059bd4a01513958fe8489d377d958d4a\n'}]",0,313490,b4558c13d89a926f62db7de19a5e93e215bbf153,2,0,1,21739,,,0,"proper types (str, dict, etc)

Change-Id: If99cf639059bd4a01513958fe8489d377d958d4a
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/90/313490/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/dsl/dsl.py', 'main/source/iptables_markov_chain.py', 'main/component/base.py', 'main/source/markov_chain/transition.py', 'main/ldp/base.py', 'main/spark/driver.py', 'main/source/markov_chain/events.py', 'main/ldp/iptables_ldp.py', 'main/dsl/interpreter.py', 'main/ingestor/base.py', 'main/config/config.py', 'main/config/creation.py', 'main/monanas.py', 'main/ingestor/iptables.py', 'main/config/connection.py', 'main/config/validation.py', 'main/util/common_util.py', 'main/source/random.py']",18,b4558c13d89a926f62db7de19a5e93e215bbf153,, :param _config: dict -- Configuration of this source, :param _config: Dictionary -- Configuration of this source,122,122
openstack%2Fmonasca-analytics~master~I7e193fd3e1b1ccc0969f56097d85c67eb3be8a54,openstack/monasca-analytics,master,I7e193fd3e1b1ccc0969f56097d85c67eb3be8a54,fixed imports according to openstack convention in the main code,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:30:27.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['main/source/iptables_markov_chain.py', 'main/source/markov_chain/prob_checks.py', 'main/util/math.py', 'main/voter/pick_index.py', 'main/component/base.py', 'main/source/markov_chain/transition.py', 'main/source/cloud_markov_chain.py', 'main/spark/driver.py', 'main/sink/iptables_sqlite.py', 'main/sml/svm_one_class.py', 'main/dsl/interpreter.py', 'main/spark/aggregator.py', 'main/source/kafka.py', 'main/sink/base_sqlite.py', 'main/sink/stdout_sink.py', 'main/ingestor/base.py', 'main/exception/dsl.py', 'main/config/config.py', 'main/source/markov_chain/base.py', 'main/ingestor/iptables.py', 'main/sink/base.py', 'main/source/random.py', 'main/exception/ingestor.py', 'main/dsl/dsl.py', 'main/sink/kafkas.py', 'main/ldp/base.py', 'main/sink/sink_config_validator.py', 'main/ldp/iptables_ldp.py', 'main/ldp/cloud_causality.py', 'main/web_service/request_handler.py', 'main/monanas.py', 'main/sml/base.py', 'main/voter/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/ingestor/cloud.py', 'main/web_service/web_service_model.py', 'main/exception/monanas.py', 'main/sml/lingam.py', 'main/util/common_util.py', 'main/web_service/web_service.py', 'main/source/base.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/f7b647d550bc21d505a852899b581b90427a7aec', 'message': 'fixed imports according to openstack convention in the main code\n\nChange-Id: I7e193fd3e1b1ccc0969f56097d85c67eb3be8a54\n'}]",0,313491,f7b647d550bc21d505a852899b581b90427a7aec,2,0,1,21739,,,0,"fixed imports according to openstack convention in the main code

Change-Id: I7e193fd3e1b1ccc0969f56097d85c67eb3be8a54
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/91/313491/1 && git format-patch -1 --stdout FETCH_HEAD,"['main/source/iptables_markov_chain.py', 'main/source/markov_chain/prob_checks.py', 'main/util/math.py', 'main/voter/pick_index.py', 'main/component/base.py', 'main/source/markov_chain/transition.py', 'main/source/cloud_markov_chain.py', 'main/spark/driver.py', 'main/sink/iptables_sqlite.py', 'main/sml/svm_one_class.py', 'main/dsl/interpreter.py', 'main/spark/aggregator.py', 'main/source/kafka.py', 'main/sink/base_sqlite.py', 'main/sink/stdout_sink.py', 'main/ingestor/base.py', 'main/exception/dsl.py', 'main/config/config.py', 'main/source/markov_chain/base.py', 'main/ingestor/iptables.py', 'main/sink/base.py', 'main/source/random.py', 'main/exception/ingestor.py', 'main/dsl/dsl.py', 'main/sink/kafkas.py', 'main/ldp/base.py', 'main/sink/sink_config_validator.py', 'main/ldp/iptables_ldp.py', 'main/ldp/cloud_causality.py', 'main/web_service/request_handler.py', 'main/monanas.py', 'main/sml/base.py', 'main/voter/base.py', 'main/config/connection.py', 'main/config/validation.py', 'main/ingestor/cloud.py', 'main/web_service/web_service_model.py', 'main/exception/monanas.py', 'main/sml/lingam.py', 'main/util/common_util.py', 'main/web_service/web_service.py', 'main/source/base.py']",42,f7b647d550bc21d505a852899b581b90427a7aec,,import abcfrom main.component import base class BaseSource(base.BaseComponent): @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod,from abc import abstractmethod from main.component.base import BaseComponentclass BaseSource(BaseComponent): @abstractmethod @abstractmethod @abstractmethod,412,373
openstack%2Fmonasca-analytics~master~I77ff21f26a8daf192a527a4053f98b8db4b40182,openstack/monasca-analytics,master,I77ff21f26a8daf192a527a4053f98b8db4b40182,fixed tests,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:30:22.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/test_monanas.py', 'test/source/test_kafka.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/b3c9116f70c15fa12e9156a0cdf81d78067d6abf', 'message': 'fixed tests\n\nChange-Id: I77ff21f26a8daf192a527a4053f98b8db4b40182\n'}]",0,313492,b3c9116f70c15fa12e9156a0cdf81d78067d6abf,2,0,1,21739,,,0,"fixed tests

Change-Id: I77ff21f26a8daf192a527a4053f98b8db4b40182
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/92/313492/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/test_monanas.py', 'test/source/test_kafka.py', 'test/spark/test_driver.py']",3,b3c9116f70c15fa12e9156a0cdf81d78067d6abf,,"from main.config import const self.original_SparkContext = driver.pyspark.SparkContext self.original_StreamingContext = driver.streaming.StreamingContext driver.pyspark.SparkContext = self.original_SparkContext driver.streaming.StreamingContext = self.original_StreamingContext driver.pyspark.SparkContext = MockSparkContext driver.streaming.StreamingContext = MockStreamingContext self.assertIn([""src_module1"", const.SOURCES], self.assertIn([""src_module2"", const.SOURCES], self.assertIn([""IPTablesSource"", const.SOURCES], self.assertIn([""ingestor_module"", const.INGESTORS], self.assertIn([""sml_module"", const.SMLS], self.assertIn([""voter_module"", const.VOTERS], self.assertIn([""sink_module1"", const.SINKS], self.assertIn([""sink_module2"", const.SINKS], self.assertIn([""ldp_module1"", const.LDPS],","import main.config.validation as mod self.original_SparkContext = driver.SparkContext self.original_StreamingContext = driver.StreamingContext driver.SparkContext = self.original_SparkContext driver.StreamingContext = self.original_StreamingContext driver.SparkContext = MockSparkContext driver.StreamingContext = MockStreamingContext self.assertIn([""src_module1"", mod.SOURCES], self.assertIn([""src_module2"", mod.SOURCES], self.assertIn([""IPTablesSource"", mod.SOURCES], self.assertIn([""ingestor_module"", mod.INGESTORS], self.assertIn([""sml_module"", mod.SMLS], self.assertIn([""voter_module"", mod.VOTERS], self.assertIn([""sink_module1"", mod.SINKS], self.assertIn([""sink_module2"", mod.SINKS], self.assertIn([""ldp_module1"", mod.LDPS],",23,23
openstack%2Fmonasca-analytics~master~Icef581012551cb8ae71f88b3227635b344340844,openstack/monasca-analytics,master,Icef581012551cb8ae71f88b3227635b344340844,"removed dependency on BNFinder, as it is GPL and we don't use it",ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:30:16.000000000,,[],"[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/07c8ec941545a09c34c765dc864d112b9e317dd6', 'message': ""removed dependency on BNFinder, as it is GPL and we don't use it\n\nChange-Id: Icef581012551cb8ae71f88b3227635b344340844\n""}]",0,313493,07c8ec941545a09c34c765dc864d112b9e317dd6,2,0,1,21739,,,0,"removed dependency on BNFinder, as it is GPL and we don't use it

Change-Id: Icef581012551cb8ae71f88b3227635b344340844
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/93/313493/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,07c8ec941545a09c34c765dc864d112b9e317dd6,,," ""BNfinder"",",0,1
openstack%2Fmonasca-analytics~master~I68ca39850d02970acb40e21efddf4c675053b801,openstack/monasca-analytics,master,I68ca39850d02970acb40e21efddf4c675053b801,refactored the test imports to comply with openstack convention,ABANDONED,2016-05-06 10:37:16.000000000,2016-05-11 16:29:53.000000000,,"[{'_account_id': 2419}, {'_account_id': 21466}]","[{'number': 1, 'created': '2016-05-06 10:37:16.000000000', 'files': ['test/source/test_iptables_markov_chain.py', 'test/dsl/test_interpreter.py', 'test/mocks/ingestors.py', 'test/config/test_create_components.py', 'test/util/test_config_model.py', 'test/source/test_markov_chain.py', 'config_dsl.py', 'test/sink/test_iptables_sqlite.py', 'setup.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py', 'test/voter/test_base_voter.py', 'test/source/test_base.py', 'test/test_monanas.py', 'test/ingestor/test_base.py', 'test/util/test_math.py', 'test/mocks/sml_mocks.py', 'test/dsl/test_dsl.py', 'test/source/test_random.py', 'main/dsl/parser.py', 'test/mocks/sources.py', 'test/ingestor/test_iptables_ingestor.py', 'test/sml/test_svm_one_class.py', 'test/mocks/classifier_mock.py', 'test/source/test_kafka.py', 'run.py', 'test/voter/test_pick_index.py', 'test/ldp/test_iptables_ldp.py', 'test/spark/test_aggregator.py', 'test/util/test_common_util.py', 'test/ingestor/test_cloud.py', 'test/sink/test_base_sqlite.py', 'test/dsl/test_parser.py', 'test/ldp/cloud_causality.py', 'test/sml/test_lingam.py', 'test/source/markov_chain/test_transition.py', 'test/sink/test_sink_config_validator.py', 'test/spark/test_driver.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/8ec36101cace825b40d04edce0d3ae90db5fe53e', 'message': 'refactored the test imports to comply with openstack convention\n\nChange-Id: I68ca39850d02970acb40e21efddf4c675053b801\n'}]",0,313494,8ec36101cace825b40d04edce0d3ae90db5fe53e,2,2,1,21739,,,0,"refactored the test imports to comply with openstack convention

Change-Id: I68ca39850d02970acb40e21efddf4c675053b801
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/94/313494/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/source/test_iptables_markov_chain.py', 'test/dsl/test_interpreter.py', 'test/mocks/ingestors.py', 'test/config/test_create_components.py', 'test/util/test_config_model.py', 'test/source/test_markov_chain.py', 'config_dsl.py', 'test/sink/test_iptables_sqlite.py', 'setup.py', 'test/source/markov_chain/test_events.py', 'test/source/markov_chain/test_base.py', 'test/voter/test_base_voter.py', 'test/source/test_base.py', 'test/test_monanas.py', 'test/ingestor/test_base.py', 'test/util/test_math.py', 'test/mocks/sml_mocks.py', 'test/dsl/test_dsl.py', 'test/source/test_random.py', 'main/dsl/parser.py', 'test/mocks/sources.py', 'test/ingestor/test_iptables_ingestor.py', 'test/sml/test_svm_one_class.py', 'test/mocks/classifier_mock.py', 'test/source/test_kafka.py', 'run.py', 'test/voter/test_pick_index.py', 'test/ldp/test_iptables_ldp.py', 'test/spark/test_aggregator.py', 'test/util/test_common_util.py', 'test/ingestor/test_cloud.py', 'test/sink/test_base_sqlite.py', 'test/dsl/test_parser.py', 'test/ldp/cloud_causality.py', 'test/sml/test_lingam.py', 'test/source/markov_chain/test_transition.py', 'test/sink/test_sink_config_validator.py', 'test/spark/test_driver.py']",38,8ec36101cace825b40d04edce0d3ae90db5fe53e,,"import loggingfrom test.mocks import spark_mocks logging.config.dictConfig(config) driver.pyspark.SparkContext = spark_mocks.MockSparkContext driver.streaming.StreamingContext = spark_mocks.MockStreamingContext spark_mocks.MockDStream(None, None, None)) spark_mocks.MockDStream(None, None, None))","from logging.config import dictConfigfrom test.mocks.spark_mocks import MockSparkContext from test.mocks.spark_mocks import MockStreamingContext from test.mocks.spark_mocks import MockDStream dictConfig(config) driver.pyspark.SparkContext = MockSparkContext driver.streaming.StreamingContext = MockStreamingContext MockDStream(None, None, None)) MockDStream(None, None, None))",535,310
openstack%2Fironic-python-agent~master~If7cb8d604c0b000e5410c1fa29911cdaf25e7005,openstack/ironic-python-agent,master,If7cb8d604c0b000e5410c1fa29911cdaf25e7005,Updated from global requirements,MERGED,2016-05-10 00:44:41.000000000,2016-05-11 16:27:51.000000000,2016-05-11 16:27:50.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 13719}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-05-10 00:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/791cf9f8b625b2a561f283d15ba07660cd1a2150', 'message': 'Updated from global requirements\n\nChange-Id: If7cb8d604c0b000e5410c1fa29911cdaf25e7005\n'}, {'number': 2, 'created': '2016-05-10 18:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/11afc856b0ea947ef54f1d7688be91e28939f630', 'message': 'Updated from global requirements\n\nChange-Id: If7cb8d604c0b000e5410c1fa29911cdaf25e7005\n'}, {'number': 3, 'created': '2016-05-11 13:58:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/16e8d074344d4e0e34b3158f3ee6e7b4fd9bc466', 'message': 'Updated from global requirements\n\nChange-Id: If7cb8d604c0b000e5410c1fa29911cdaf25e7005\n'}]",0,314354,16e8d074344d4e0e34b3158f3ee6e7b4fd9bc466,20,5,3,11131,,,0,"Updated from global requirements

Change-Id: If7cb8d604c0b000e5410c1fa29911cdaf25e7005
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/54/314354/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,791cf9f8b625b2a561f283d15ba07660cd1a2150,openstack/requirements,stevedore>=1.10.0 # Apache-2.0,stevedore>=1.9.0 # Apache-2.0,1,1
openstack%2Fproject-team-guide~master~I697af934aaca002da0be3555d1e1829099ead4b3,openstack/project-team-guide,master,I697af934aaca002da0be3555d1e1829099ead4b3,Improve docs on setting up development environment,MERGED,2016-01-06 22:59:34.000000000,2016-05-11 16:24:43.000000000,2016-05-11 16:24:43.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 4264}, {'_account_id': 5263}, {'_account_id': 6159}, {'_account_id': 6316}, {'_account_id': 6486}, {'_account_id': 6772}, {'_account_id': 6987}, {'_account_id': 7725}, {'_account_id': 8099}, {'_account_id': 10343}, {'_account_id': 11904}, {'_account_id': 12767}, {'_account_id': 12898}, {'_account_id': 14084}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-06 22:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/7281c782ebe92896cc1da33b8718b336c92bf599', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead use get-pip.py and remove the things we're going to use in\ngetting the virtualenvs up and running.\n\nAn alternative approach that doesn't require altering system installed\npackages is documented on my blog [1] but I'm not sure if it's\nsufficiently low friction to go in the dev docs.\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 2, 'created': '2016-01-06 23:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/d83fd3dc704e31988fd4a7261669934d29851e32', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead use get-pip.py and remove the things we're going to use in\ngetting the virtualenvs up and running.\n\nAn alternative approach that doesn't require altering system installed\npackages is documented on my blog [1] but I'm not sure if it's\nsufficiently low friction to go in the dev docs.\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 3, 'created': '2016-01-06 23:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/3f6ae11a05f2f61c78f1494c14d8448db5db3528', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead use get-pip.py and remove the things we're going to use in\ngetting the virtualenvs up and running.\n\nAn alternative approach that doesn't require altering system installed\npackages is documented on my blog [1] but I'm not sure if it's\nsufficiently low friction to go in the dev docs.\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 4, 'created': '2016-01-08 12:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/edc321ce57bd3611eb2590969abd57b96bf0f3ce', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead use get-pip.py and remove the things we're going to use in\ngetting the virtualenvs up and running.\n\nAn alternative approach that doesn't require altering system installed\npackages is documented on my blog [1] but I'm not sure if it's\nsufficiently low friction to go in the dev docs.\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 5, 'created': '2016-01-29 17:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/18efd6bb0351566d13dda08e65a1734a88b8728b', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead use get-pip.py and remove the things we're going to use in\ngetting the virtualenvs up and running.\n\nAn alternative approach that doesn't require altering system installed\npackages is documented on my blog [1] but I'm not sure if it's\nsufficiently low friction to go in the dev docs.\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 6, 'created': '2016-02-11 11:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/9611fed18625800be00e8c96bac243102060d44c', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead use get-pip.py and remove the things we're going to use in\ngetting the virtualenvs up and running.\n\nAn alternative approach that doesn't require altering system installed\npackages is documented on my blog [1] but I'm not sure if it's\nsufficiently low friction to go in the dev docs.\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 7, 'created': '2016-04-04 18:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/3b32319993a81ed2ddcb69edf6756859d42b2251', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead create a new virtualenv and bindep to install system\ndependencies. This approach doesn't require altering system installed\npackages and is documented on my blog [1].\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 8, 'created': '2016-04-06 19:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/76113c68b2dcd6904fdf018cd45b3757ef915c60', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead create a new virtualenv and bindep to install system\ndependencies. This approach doesn't require altering system installed\npackages and is documented on my blog [1].\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 9, 'created': '2016-04-15 16:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/d57a4ae295bb5225bc537da22da54475915bd6ec', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead create a new virtualenv and bindep to install system\ndependencies. This approach doesn't require altering system installed\npackages and is documented on my blog [1].\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}, {'number': 10, 'created': '2016-04-19 00:20:32.000000000', 'files': ['doc/source/project-setup/python.rst'], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/d8a8aa4abf4d559292b0b3ead63effb3c650bb9f', 'message': ""Improve docs on setting up development environment\n\nWe need newer than distro pip's in tox virtualenvs, which means we\nneed a new virtualenv.\n\nFurther, because some platforms mangle pip by default we can't use\nthe system pip, as the installed tools won't be system installed -\nand often incorrect python paths end up making pip installed things\nthat shadow system packages behave incorrectly.\n\nSo instead create a new virtualenv and bindep to install system\ndependencies. This approach doesn't require altering system installed\npackages and is documented on my blog [1].\n\n[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/\n\nCo-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>\n\nChange-Id: I697af934aaca002da0be3555d1e1829099ead4b3\n""}]",42,264398,d8a8aa4abf4d559292b0b3ead63effb3c650bb9f,71,21,10,17860,,,0,"Improve docs on setting up development environment

We need newer than distro pip's in tox virtualenvs, which means we
need a new virtualenv.

Further, because some platforms mangle pip by default we can't use
the system pip, as the installed tools won't be system installed -
and often incorrect python paths end up making pip installed things
that shadow system packages behave incorrectly.

So instead create a new virtualenv and bindep to install system
dependencies. This approach doesn't require altering system installed
packages and is documented on my blog [1].

[1] https://rbtcollins.wordpress.com/2015/07/12/bootstrapping-developer-environments-for-openstack/

Co-Authored-By: Samuel de Medeiros Queiroz <samueldmq@gmail.com>

Change-Id: I697af934aaca002da0be3555d1e1829099ead4b3
",git fetch https://review.opendev.org/openstack/project-team-guide refs/changes/98/264398/10 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/project-setup/python.rst'],1,7281c782ebe92896cc1da33b8718b336c92bf599,dev-environment-docs,"Remove the system-installed versions of Python 2 packages we need latest versions of:: [apt-get | yum] remove python-pip || true [apt-get | yum] remove python-tox || true [apt-get | yum] remove python-distribute || true [apt-get | yum] remove python-setuptools || true [apt-get | yum] remove python-virtualenv || true [apt-get | yum] remove python-wheel || true Also, their corresponding Python 3 packages:: [apt-get | yum] remove python3-pip || true [apt-get | yum] remove python3-tox || true [apt-get | yum] remove python3-setuptools || true [apt-get | yum] remove python3-virtualenv || true [apt-get | yum] remove python3-wheel || true sudo python <(curl https://bootstrap.pypa.io/get-pip.py) Use pip to install tox, setuptools, virtualenv and wheel:: pip install --upgrade tox setuptools virtualenv wheelso for example, run the test suite in py34 and py27:: tox -e py34,py27"," [apt-get | yum] install python-pip Use pip to install tox:: pip install --upgrade toxso for example, run the test suite in py27:: tox -e py27",23,5
openstack%2Fpython-solumclient~master~I881a1de13afd1d2da3267b358c91b2f5da097796,openstack/python-solumclient,master,I881a1de13afd1d2da3267b358c91b2f5da097796,Updated from global requirements,MERGED,2016-05-11 14:03:36.000000000,2016-05-11 16:11:24.000000000,2016-05-11 16:11:24.000000000,"[{'_account_id': 3}, {'_account_id': 2506}]","[{'number': 1, 'created': '2016-05-11 14:03:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/f1d00c33edd8af40113a0bda606c1389335664a7', 'message': 'Updated from global requirements\n\nChange-Id: I881a1de13afd1d2da3267b358c91b2f5da097796\n'}]",0,315063,f1d00c33edd8af40113a0bda606c1389335664a7,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I881a1de13afd1d2da3267b358c91b2f5da097796
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/63/315063/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f1d00c33edd8af40113a0bda606c1389335664a7,openstack/requirements,"PrettyTable<0.8,>=0.7 # BSD","PrettyTable>=0.7,<0.8 # BSD",1,1
openstack%2Fsahara-dashboard~master~Ie7c9a4f2fe28683b6ae0f2766cc66a94fdbef74a,openstack/sahara-dashboard,master,Ie7c9a4f2fe28683b6ae0f2766cc66a94fdbef74a,Updated from global requirements,MERGED,2016-05-06 22:23:17.000000000,2016-05-11 16:10:10.000000000,2016-05-11 16:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-05-06 22:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/10cf39f41c05d9beedb14e2ea7c4aa0f1f7d25bb', 'message': 'Updated from global requirements\n\nChange-Id: Ie7c9a4f2fe28683b6ae0f2766cc66a94fdbef74a\n'}, {'number': 2, 'created': '2016-05-11 14:04:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/b6ef14b563eada6bce93abf1814f7718df61633e', 'message': 'Updated from global requirements\n\nChange-Id: Ie7c9a4f2fe28683b6ae0f2766cc66a94fdbef74a\n'}]",0,313772,b6ef14b563eada6bce93abf1814f7718df61633e,9,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ie7c9a4f2fe28683b6ae0f2766cc66a94fdbef74a
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/72/313772/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,10cf39f41c05d9beedb14e2ea7c4aa0f1f7d25bb,openstack/requirements,Babel>=2.3.4 # BSD,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",1,1
openstack%2Fmurano-apps~master~I83d9c96f3cf8723b330112dccf3f32c98fdabaaf,openstack/murano-apps,master,I83d9c96f3cf8723b330112dccf3f32c98fdabaaf,[ApacheHttpServer] Use simple software configuration,MERGED,2016-03-15 13:48:41.000000000,2016-05-11 16:09:08.000000000,2016-05-11 16:09:08.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 15168}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-03-15 13:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/8592114e685bff4f8f20355f96c066055f549a1c', 'message': 'Use simple software configuration instead of EP\n\nPartially-Implements: bp refactor-apps-scripts\nChange-Id: I83d9c96f3cf8723b330112dccf3f32c98fdabaaf\n'}, {'number': 2, 'created': '2016-04-01 13:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/22e45bc5370d845dc163bebf0aa55c2a3fb55236', 'message': '[ApacheHttpServer] Use simple software configuration\n\nPartially-Implements: bp refactor-apps-scripts\nChange-Id: I83d9c96f3cf8723b330112dccf3f32c98fdabaaf\n'}, {'number': 3, 'created': '2016-04-07 11:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/2cc38369fe142fbfb8f81a862bb24d6e02040043', 'message': '[ApacheHttpServer] Use simple software configuration\n\nPartially-Implements: bp refactor-apps-scripts\nChange-Id: I83d9c96f3cf8723b330112dccf3f32c98fdabaaf\n'}, {'number': 4, 'created': '2016-05-05 12:30:43.000000000', 'files': ['ApacheHTTPServer/package/Resources/deployApache.sh', 'ApacheHTTPServer/package/Classes/ApacheHttpServer.yaml', 'ApacheHTTPServer/package/Resources/DeployApache.template'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/0ef3586658a0333308633c6b9233e0f48b44881d', 'message': '[ApacheHttpServer] Use simple software configuration\n\nPartially-Implements: bp refactor-apps-scripts\nChange-Id: I83d9c96f3cf8723b330112dccf3f32c98fdabaaf\n'}]",2,292889,0ef3586658a0333308633c6b9233e0f48b44881d,18,5,4,13149,,,0,"[ApacheHttpServer] Use simple software configuration

Partially-Implements: bp refactor-apps-scripts
Change-Id: I83d9c96f3cf8723b330112dccf3f32c98fdabaaf
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/89/292889/3 && git format-patch -1 --stdout FETCH_HEAD,"['WordPress/package/Resources/ConfigureAccessToMySql.template', 'ApacheHTTPServer/package/Resources/configure_iptables.sh', 'Tomcat/package/Classes/Tomcat.yaml', 'Cassandra/package/Resources/deployCassandra.sh', 'Rally/package/Resources/InstallRally.template', 'Cassandra/package/Resources/RestartCassandra.template', 'Cassandra/package/Resources/restartCassandra.sh', 'MySQL/package/Resources/DeployMySql.template', 'Cassandra/package/Classes/CassandraNode.yaml', 'Guacamole/package/Resources/DeployGuacamole.template', 'MongoDB/package/Resources/scripts/deployMongoDB.sh', 'Tomcat/package/Resources/deployTomcat.sh', 'MySQL/package/Classes/MySql.yaml', 'Rally/package/Resources/installRally.sh', 'MySQL/package/Resources/createMySqlUser.sh', 'ApacheHTTPServer/package/Classes/ApacheHttpServer.yaml', 'MongoDB/package/Resources/DeployMongoDB.template', 'MySQL/package/Resources/CreateMySqlUser.template', 'MySQL/package/Resources/createMySqlDatabase.sh', 'MySQL/package/Resources/AssignUserMySql.template', 'ZabbixServer/package/Classes/ZabbixServer.yaml', 'Guacamole/package/Classes/Guacamole.yaml', 'MongoDB/package/Resources/addFirewallRules.sh', 'ApacheHTTPServer/package/Resources/scripts/runApacheDeploy.sh', 'WordPress/package/Resources/DeployWordPress.template', 'WordPress/package/Resources/deployWordPress.sh', 'Cassandra/package/Classes/CassandraCluster.yaml', 'MySQL/package/Resources/deployMySql.sh', 'MongoDB/package/Resources/createUserForMongoDBDatabase.sh', 'Rally/package/Classes/Rally.yaml', 'WordPress/package/Classes/WordPress.yaml', 'Cassandra/package/Resources/DeployCassandra.template', 'Cassandra/package/Resources/UpdateCassandraYaml.template', 'Guacamole/package/Resources/deployGuacamole.sh', 'MongoDB/package/Resources/ConfigureMongoDB.template', 'ZabbixServer/package/Resources/DeployZabbixServer.template', 'ApacheHTTPServer/package/Resources/DeployApache.template', 'MongoDB/package/Resources/configureMongoDB.sh', 'WordPress/package/Resources/configureAccessToMySql.sh', 'MongoDB/package/Resources/createMongoDBDatabase.sh', 'MongoDB/package/Classes/MongoDB.yaml', 'ZabbixServer/package/Resources/deployZabbixServer.sh', 'Tomcat/package/Resources/DeployTomcat.template', 'Cassandra/package/Resources/updateCassandraYaml.sh', 'MongoDB/package/Resources/AddFirewallRules.template', 'MongoDB/package/Resources/CreateMongoDBDatabase.template', 'MySQL/package/Resources/assignMySqlUser.sh', 'MongoDB/package/Resources/CreateUserForMongoDBDatabase.template', 'MySQL/package/Resources/CreateMySqlDatabase.template']",49,8592114e685bff4f8f20355f96c066055f549a1c,bp/refactor-apps-scripts,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. FormatVersion: 2.0.0 Version: 1.0.0 Name: Create MySql database Parameters: database: $database Body: | return createDatabase(args.database).stdout Scripts: createDatabase: Type: Application Version: 1.0.0 EntryPoint: createMySqlDatabase.sh Files: [] Options: captureStdout: true captureStderr: true ",173,762
openstack%2Fcinder~master~I8e33bd4e61cc151952d8074b8540cc39a88baa64,openstack/cinder,master,I8e33bd4e61cc151952d8074b8540cc39a88baa64,Updated from global requirements,MERGED,2016-04-13 12:41:57.000000000,2016-05-11 16:08:06.000000000,2016-04-15 14:15:44.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 8871}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12032}, {'_account_id': 12369}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14384}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-04-13 12:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/34438642f0929eb0c099fbf419609997ba018988', 'message': 'Updated from global requirements\n\nChange-Id: I8e33bd4e61cc151952d8074b8540cc39a88baa64\n'}, {'number': 2, 'created': '2016-04-14 02:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d0991e4eff58a072e7a9f3c5b8b8c937406c0ffa', 'message': 'Updated from global requirements\n\nChange-Id: I8e33bd4e61cc151952d8074b8540cc39a88baa64\n'}, {'number': 3, 'created': '2016-04-14 11:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb6eaa4b0a9ed0d2f726ebfcb1ec5487bca79b46', 'message': 'Updated from global requirements\n\nChange-Id: I8e33bd4e61cc151952d8074b8540cc39a88baa64\n'}, {'number': 4, 'created': '2016-04-15 01:52:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce7dedff981ea6a824da2e64f83dc0d482473031', 'message': 'Updated from global requirements\n\nChange-Id: I8e33bd4e61cc151952d8074b8540cc39a88baa64\n'}]",0,305171,ce7dedff981ea6a824da2e64f83dc0d482473031,102,36,4,11131,,,0,"Updated from global requirements

Change-Id: I8e33bd4e61cc151952d8074b8540cc39a88baa64
",git fetch https://review.opendev.org/openstack/cinder refs/changes/71/305171/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,34438642f0929eb0c099fbf419609997ba018988,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3 # BSD,1,1
openstack%2Fnetworking-midonet~master~I6ff037ab8f195560f6ce393646bba9443305db2e,openstack/networking-midonet,master,I6ff037ab8f195560f6ce393646bba9443305db2e,Updated from global requirements,MERGED,2016-04-08 00:28:38.000000000,2016-05-11 15:58:28.000000000,2016-05-11 15:58:28.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 16272}, {'_account_id': 20993}, {'_account_id': 20996}]","[{'number': 1, 'created': '2016-04-08 00:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/403bb58b707f50fae384d3d1c2a2c46f71f35802', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 2, 'created': '2016-04-11 18:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/aa1017174eb3d3b3d1b8973ac635154192f93471', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 3, 'created': '2016-04-12 23:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/c58a8f2312dda902db242a12533e4725e58c6e46', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 4, 'created': '2016-04-13 12:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/657e71f5ab424c040ebf1da1fd56b9009a891cc4', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 5, 'created': '2016-04-28 16:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/95c452391ffd4ed81553fa7f28fbd29b3bcdb0b7', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 6, 'created': '2016-05-03 15:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/f721547afe584240de9a1daa3a7acfa331907930', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 7, 'created': '2016-05-06 22:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/174b80e0917d2f449a070896b204b440e92791a5', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}, {'number': 8, 'created': '2016-05-10 18:38:33.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/9c1fb88c23e20804ff5842e37334a21a85c2b75a', 'message': 'Updated from global requirements\n\nChange-Id: I6ff037ab8f195560f6ce393646bba9443305db2e\n'}]",0,303135,9c1fb88c23e20804ff5842e37334a21a85c2b75a,45,6,8,11131,,,0,"Updated from global requirements

Change-Id: I6ff037ab8f195560f6ce393646bba9443305db2e
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/35/303135/3 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,403bb58b707f50fae384d3d1c2a2c46f71f35802,openstack/requirements,"fixtures<2.0,>=1.3.1 # Apache-2.0/BSD",fixtures>=1.3.1 # Apache-2.0/BSD,1,1
openstack%2Ftripleo-specs~master~Ie01c29e98492e053d911d73813535c8f22feed6f,openstack/tripleo-specs,master,Ie01c29e98492e053d911d73813535c8f22feed6f,Refactor top level puppet manifests,MERGED,2016-03-01 08:37:28.000000000,2016-05-11 15:53:20.000000000,2016-05-11 15:53:20.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-03-01 08:37:28.000000000', 'files': ['specs/mitaka/refactor-puppet-manifests.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/ec67b42229f41d2a5b670e720a7182b6a45233df', 'message': 'Refactor top level puppet manifests\n\nChange-Id: Ie01c29e98492e053d911d73813535c8f22feed6f\n'}]",0,286439,ec67b42229f41d2a5b670e720a7182b6a45233df,11,6,1,6994,,,0,"Refactor top level puppet manifests

Change-Id: Ie01c29e98492e053d911d73813535c8f22feed6f
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/39/286439/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/refactor-puppet-manifests.rst'],1,ec67b42229f41d2a5b670e720a7182b6a45233df,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Refactor top level puppet manifests ========================================== Launchpad blueprint: https://blueprints.launchpad.net/tripleo/+spec/refactor-puppet-manifests The current overcloud controller puppet manifests duplicate a large amount of code between the pacemaker (HA) and non-ha version. We can reduce the effort required to add new features by refactoring this code, and since there is already a puppet-tripleo module this is the logical destination. Problem Description =================== Large amounts of puppet/manifests/overcloud\_controller.pp are shared with puppet/manifests/overcloud\_controller\_pacemaker.pp. When adding a feature or fixing a mistake in the former, it is frequently also an issue in the latter. It is a violation of the common programming principle of DRY, which while not an inviolable rule, is usually considered good practice. In addition, moving this code into separate classes in another module will make it simpler to enable/disable components, as it will be a matter of merely controlling which classes (profiles) are included. Finally, it allows easier experimentation with modifying the 'ha strategy'. Currently this is done using 'step', but could in theory be done using a service registry. By refactoring into ha+non-ha classes this would be quite simple to swap in/out. Proposed Change =============== Overview -------- While there are significant differences in ha and non-ha deployments, in almost all cases the ha code will be a superset of the non-ha. A simple example of this is at the top of both files, where the load balancer is handled. The non ha version simply includes the loadbalancing class, while the HA version instantiates the exact same class but with some parameters changed. Across the board the same classes are included for the openstack services, but with manage service set to false in the HA case. I propose first breaking up the non-ha version into profiles which can reside in puppet-tripleo/manifests/profile/nonha, then adding ha versions which use those classes under puppet-tripleo-manifests/profile/pacemaker. Pacemaker could be described as an 'ha strategy' which in theory should be replaceable. For this reason we use a pacemaker subfolder since one day perhaps we'll have an alternative. Alternatives ------------ We could leave things as they are, which works and isn't the end of the world, but it's probably not optimal. We could use kolla or something that removes the need for puppet entirely, but this discussion is outside the scope of this spec. Security Impact --------------- None Other End User Impact --------------------- It will make downstreams happy since they can sub in/out classes more easily. Performance Impact ------------------ Adding wrapper classes isn't going to impact puppet compile times very much. Other Deployer Impact --------------------- None Developer Impact ---------------- Changes in t-h-t and puppet-tripleo will often be coupled, as t-h-t defines the data on which puppet-tripleo depends on. Implementation ============== Assignee(s) ----------- Primary assignee: michaeltchapman Work Items ---------- Move overcloud controller to profile classes Move overcloud controller pacemaker to profile classes Move any other classes from the smaller manifests in t-h-t Dependencies ============ None Testing ======= No new features so current tests apply in their entirety. Additional testing can be added for each profile class Documentation Impact ==================== None References ========== None ",,129,0
openstack%2Fpython-heatclient~master~I6ac3e120b083be83328aa834515f7bc51759c5ae,openstack/python-heatclient,master,I6ac3e120b083be83328aa834515f7bc51759c5ae,Unify stack output show display format with --all option,ABANDONED,2016-04-20 10:03:20.000000000,2016-05-11 15:52:12.000000000,,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 10487}, {'_account_id': 13009}, {'_account_id': 18389}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-04-20 10:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0b040f41c26b0080547011dffdefc28443446b91', 'message': 'Unify stack output show display format\n\nopenstack stack output show command output format is not consistent\nacross multiple options.\nThis change is aimed to unify it into the format with --all option\n\nChange-Id: I6ac3e120b083be83328aa834515f7bc51759c5ae\nCloses-Bug: #1571976\n'}, {'number': 2, 'created': '2016-04-21 06:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/1a5c0beb661fdf62f84f1c487d972587121f1603', 'message': 'Unify stack output show display format with --all option\n\nCommand openstack stack output show command output format is not consistent\nacross multiple options. This change is aimed to unify it into the format with\n--all option.\n\nChange-Id: I6ac3e120b083be83328aa834515f7bc51759c5ae\nCloses-Bug: #1571976\n'}, {'number': 3, 'created': '2016-04-21 08:54:53.000000000', 'files': ['heatclient/osc/v1/stack.py', 'heatclient/tests/unit/osc/v1/test_stack.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/4309f805e13f3e6036097ef04c8760a0e809fa58', 'message': ""Unify stack output show display format with --all option\n\nCommand 'openstack stack output show' output format is not consistent\nacross multiple options. This change is aimed to unify it into the format\nwith --all option.\n\nChange-Id: I6ac3e120b083be83328aa834515f7bc51759c5ae\nCloses-Bug: #1571976\n""}]",10,308238,4309f805e13f3e6036097ef04c8760a0e809fa58,18,8,3,18389,,,0,"Unify stack output show display format with --all option

Command 'openstack stack output show' output format is not consistent
across multiple options. This change is aimed to unify it into the format
with --all option.

Change-Id: I6ac3e120b083be83328aa834515f7bc51759c5ae
Closes-Bug: #1571976
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/38/308238/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/stack.py', 'heatclient/tests/unit/osc/v1/test_stack.py']",2,0b040f41c26b0080547011dffdefc28443446b91,bug/1571976," self.assertEqual(['output1'], columns) self.assertEqual(['output1'], columns)"," self.assertEqual(('output_key', 'output_value'), columns) self.assertEqual(('output1', 'value1'), outputs) self.assertEqual(('output_key', 'output_value'), columns) self.assertEqual(('output1', 'value1'), outputs)",5,6
openstack%2Fproject-config~master~Ia1890185d2cded484de5ceb6a4b4001510aa33da,openstack/project-config,master,Ia1890185d2cded484de5ceb6a4b4001510aa33da,"Use ""bindep test""",MERGED,2016-05-10 13:44:48.000000000,2016-05-11 15:48:01.000000000,2016-05-11 15:48:01.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}]","[{'number': 1, 'created': '2016-05-10 13:44:48.000000000', 'files': ['jenkins/scripts/install-distro-packages.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0182437c5a47ac201c07787bcbdcf38abe9d60ad', 'message': 'Use ""bindep test""\n\nFor testing purposes use the ""test"" profile to install packages. This\ninstalls also any packages that have no selector.\n\nChange-Id: Ia1890185d2cded484de5ceb6a4b4001510aa33da\n'}]",0,314571,0182437c5a47ac201c07787bcbdcf38abe9d60ad,7,3,1,6547,,,0,"Use ""bindep test""

For testing purposes use the ""test"" profile to install packages. This
installs also any packages that have no selector.

Change-Id: Ia1890185d2cded484de5ceb6a4b4001510aa33da
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/314571/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/install-distro-packages.sh'],1,0182437c5a47ac201c07787bcbdcf38abe9d60ad,bindep-test,"# Install test profile using bindep until $BINDEP -b -f $PACKAGES test; do ""\n`$BINDEP -b -f $PACKAGES test`\n"" 1>&2 --assume-yes install `$BINDEP -b -f $PACKAGES test` `$BINDEP -b -f $PACKAGES test`","until $BINDEP -b -f $PACKAGES ; do ""\n`$BINDEP -b -f $PACKAGES`\n"" 1>&2 --assume-yes install `$BINDEP -b -f $PACKAGES` `$BINDEP -b -f $PACKAGES`",5,4
openstack%2Fpuppet-neutron~master~Ic399fdac366d34e6d4486e2750a6435691141bc7,openstack/puppet-neutron,master,Ic399fdac366d34e6d4486e2750a6435691141bc7,Allow L3 agent setting changes without setting l3_ha to true.,MERGED,2016-05-09 17:26:30.000000000,2016-05-11 15:46:30.000000000,2016-05-11 15:46:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9500}]","[{'number': 1, 'created': '2016-05-09 17:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/36504d06d0fdb0277349e08044891a4446983102', 'message': 'Allow L3 agent setting changes without setting l3_ha to true.\n\nChange-Id: Ic399fdac366d34e6d4486e2750a6435691141bc7\n'}, {'number': 2, 'created': '2016-05-09 19:58:16.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fc243b5c0d0c63a9f211bd5158d007236fbf2137', 'message': 'Allow L3 agent setting changes without setting l3_ha to true.\n\nWe should allow L3 agent settings to be changed without setting l3_ha to\ntrue. l3_ha is the default router ha setting, but customers could\nmigrate a legacy router to HA router even when l3_ha is set to false.\n\nChange-Id: Ic399fdac366d34e6d4486e2750a6435691141bc7\n'}]",0,314213,fc243b5c0d0c63a9f211bd5158d007236fbf2137,25,7,2,11264,,,0,"Allow L3 agent setting changes without setting l3_ha to true.

We should allow L3 agent settings to be changed without setting l3_ha to
true. l3_ha is the default router ha setting, but customers could
migrate a legacy router to HA router even when l3_ha is set to false.

Change-Id: Ic399fdac366d34e6d4486e2750a6435691141bc7
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/13/314213/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/server.pp'],1,36504d06d0fdb0277349e08044891a4446983102,l3_settings, if $min_l3_agents_per_router <= $max_l3_agents_per_router or $max_l3_agents_per_router == 0 { neutron_config { 'DEFAULT/l3_ha': value => $l3_ha; 'DEFAULT/max_l3_agents_per_router': value => $max_l3_agents_per_router; 'DEFAULT/min_l3_agents_per_router': value => $min_l3_agents_per_router; 'DEFAULT/l3_ha_net_cidr': value => $l3_ha_net_cidr; fail('min_l3_agents_per_router should be less than or equal to max_l3_agents_per_router.'), if $l3_ha { if $min_l3_agents_per_router <= $max_l3_agents_per_router or $max_l3_agents_per_router == 0 { neutron_config { 'DEFAULT/l3_ha': value => true; 'DEFAULT/max_l3_agents_per_router': value => $max_l3_agents_per_router; 'DEFAULT/min_l3_agents_per_router': value => $min_l3_agents_per_router; 'DEFAULT/l3_ha_net_cidr': value => $l3_ha_net_cidr; } } else { fail('min_l3_agents_per_router should be less than or equal to max_l3_agents_per_router.') neutron_config { 'DEFAULT/l3_ha': value => false; },7,13
openstack%2Fshade~master~I6352fa2d64d3e92f823004a5b9f4cbfe61f11403,openstack/shade,master,I6352fa2d64d3e92f823004a5b9f4cbfe61f11403,Don't fail getting flavors if extra_specs is off,MERGED,2016-05-10 15:41:16.000000000,2016-05-11 15:44:16.000000000,2016-05-11 15:44:16.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 532}, {'_account_id': 1106}, {'_account_id': 3099}]","[{'number': 1, 'created': '2016-05-10 15:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/88e487f170008aa7087684d3de0470a6953c430a', 'message': ""Don't fail getting flavors if extra_specs is off\n\nClouds can turn off extra specs. They're extra - we should not fail\non getting flavors if they're not there.\n\nChange-Id: I6352fa2d64d3e92f823004a5b9f4cbfe61f11403\n""}, {'number': 2, 'created': '2016-05-11 13:50:36.000000000', 'files': ['shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/fb357bd7edec2ef72e6d655acb5f8b7e8e786a14', 'message': ""Don't fail getting flavors if extra_specs is off\n\nClouds can turn off extra specs. They're extra - we should not fail\non getting flavors if they're not there.\n\nChange-Id: I6352fa2d64d3e92f823004a5b9f4cbfe61f11403\n""}]",1,314640,fb357bd7edec2ef72e6d655acb5f8b7e8e786a14,13,5,2,2,,,0,"Don't fail getting flavors if extra_specs is off

Clouds can turn off extra specs. They're extra - we should not fail
on getting flavors if they're not there.

Change-Id: I6352fa2d64d3e92f823004a5b9f4cbfe61f11403
",git fetch https://review.opendev.org/openstack/shade refs/changes/40/314640/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/openstackcloud.py'],1,88e487f170008aa7087684d3de0470a6953c430a,314640, try: flavor.extra_specs = self.manager.submitTask( _tasks.FlavorGetExtraSpecs(id=flavor.id)) except keystoneauth1.exceptions.http.HttpError as e: flavor.extra_specs = [] self.log.debug( 'Fetching extra specs for flavor failed:' ' {msg}'.format(str(e))), flavor.extra_specs = self.manager.submitTask( _tasks.FlavorGetExtraSpecs(id=flavor.id)),8,2
openstack%2Fceilometer~master~I0e20d90d117b42edc09120f4bcf25f8cad3360e3,openstack/ceilometer,master,I0e20d90d117b42edc09120f4bcf25f8cad3360e3,Fixes ceilo after oslo.messaging refactoring,ABANDONED,2016-04-05 22:23:36.000000000,2016-05-11 15:43:13.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-04-05 22:23:36.000000000', 'files': ['ceilometer/notification.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/25f9079fe0804374fc27f779eca3891c5b12725c', 'message': 'Fixes ceilo after oslo.messaging refactoring\n\nNext commit removed ""targets"" attribute from dispatcher:\nhttps://github.com/openstack/oslo.messaging/commit/990d894eaf0d18941b56d89bff2bca51de375640\n\nThis patch takes it from correct place\n\nChange-Id: I0e20d90d117b42edc09120f4bcf25f8cad3360e3\n'}]",0,301953,25f9079fe0804374fc27f779eca3891c5b12725c,6,4,1,8601,,,0,"Fixes ceilo after oslo.messaging refactoring

Next commit removed ""targets"" attribute from dispatcher:
https://github.com/openstack/oslo.messaging/commit/990d894eaf0d18941b56d89bff2bca51de375640

This patch takes it from correct place

Change-Id: I0e20d90d117b42edc09120f4bcf25f8cad3360e3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/53/301953/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/notification.py'],1,25f9079fe0804374fc27f779eca3891c5b12725c,fix_targets_location, if listener.targets[0].topic in topics: queue_set.pop(listener.targets[0].topic), if listener.dispatcher.targets[0].topic in topics: queue_set.pop(listener.dispatcher.targets[0].topic),2,2
openstack%2Fwatcher~master~I2192508afda037510f8f91092c5cfde0115dae1d,openstack/watcher,master,I2192508afda037510f8f91092c5cfde0115dae1d,Added .pot file,MERGED,2016-04-18 12:30:48.000000000,2016-05-11 15:39:13.000000000,2016-05-11 15:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/c5d8b6d750c056930d88eb43e7cbfeca94f3d0f5', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}, {'number': 2, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/c5ad15832277e762cb2ad6bbe63ea4133be28c3b', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}, {'number': 3, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6a8cbc5f5eb07e8366fb1e24fa75e4c96a156ac8', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}, {'number': 4, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/f80337752a6e70baee88344885d987f5c96f761d', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}, {'number': 5, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6a6d2805c1ff08a018b17b75017b3a71309c91fe', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}, {'number': 6, 'created': '2016-05-11 13:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/c4d25fc72ee5d6c3df09bf35a99648020bdbe4de', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}, {'number': 7, 'created': '2016-05-11 13:48:25.000000000', 'files': ['watcher/locale/watcher.pot', 'watcher/common/exception.py', 'watcher/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/1a218677354aa5605f80922f8bd46898e1285c1d', 'message': 'Added .pot file\n\nIn this changeset, I just generate the .pot file for all the new\ntranslations that were added during the implementation of this BP\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2192508afda037510f8f91092c5cfde0115dae1d\n'}]",2,307144,1a218677354aa5605f80922f8bd46898e1285c1d,32,3,7,18971,,,0,"Added .pot file

In this changeset, I just generate the .pot file for all the new
translations that were added during the implementation of this BP

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I2192508afda037510f8f91092c5cfde0115dae1d
",git fetch https://review.opendev.org/openstack/watcher refs/changes/44/307144/3 && git format-patch -1 --stdout FETCH_HEAD,['watcher/locale/watcher.pot'],1,c5d8b6d750c056930d88eb43e7cbfeca94f3d0f5,bp/get-goal-from-strategy,"""Project-Id-Version: python-watcher 0.26.1.dev23\n""""POT-Creation-Date: 2016-04-18 14:20+0200\n""""Generated-By: Babel 2.3.2\n"" #: watcher/api/controllers/v1/action.py:368#: watcher/api/controllers/v1/action.py:392#: watcher/api/controllers/v1/action.py:428#: watcher/api/controllers/v1/action_plan.py:87#: watcher/api/controllers/v1/action_plan.py:407#: watcher/api/controllers/v1/audit.py:339#: watcher/api/controllers/v1/audit_template.py:145 msgid ""Cannot remove 'goal_uuid' attribute from an audit template"" msgstr """" msgid ""Goal %(goal)s is invalid""msgid ""Strategy %(strategy)s is invalid""msgid ""Expected a uuid but received %(uuid)s""msgid ""Expected a logical name but received %(name)s""msgid ""Expected a logical name or uuid but received %(name)s""msgid ""Goal %(goal)s could not be found"" msgstr """" #: watcher/common/exception.py:178 #, python-format msgid ""A goal with UUID %(uuid)s already exists"" msgstr """" #: watcher/common/exception.py:182 #, python-format msgid ""Strategy %(strategy)s could not be found"" msgstr """" #: watcher/common/exception.py:186 #, python-format msgid ""A strategy with ID %(id)s already exists"" msgstr """" #: watcher/common/exception.py:190 #, python-format msgid ""AuditTemplate %(audit_template)s could not be found"" msgstr """" #: watcher/common/exception.py:194 #, python-format#: watcher/common/exception.py:199#: watcher/common/exception.py:204#: watcher/common/exception.py:208#: watcher/common/exception.py:212#: watcher/common/exception.py:217#: watcher/common/exception.py:221#: watcher/common/exception.py:225#: watcher/common/exception.py:230#: watcher/common/exception.py:234#: watcher/common/exception.py:238#: watcher/common/exception.py:243#: watcher/common/exception.py:252#: watcher/common/exception.py:258#: watcher/common/exception.py:262#: watcher/common/exception.py:266#: watcher/common/exception.py:270#: watcher/common/exception.py:274#: watcher/common/exception.py:278#: watcher/common/exception.py:282#: watcher/common/exception.py:286#: watcher/common/exception.py:290 msgid ""The cluster state is not defined""#: watcher/common/exception.py:294 #, python-format msgid ""No strategy could be found to achieve the '%(goal)s' goal."" msgstr """" #: watcher/common/exception.py:300#: watcher/common/exception.py:304#: watcher/common/exception.py:308#: watcher/common/exception.py:312#: watcher/common/exception.py:316#: watcher/common/exception.py:320msgid ""Goals""msgid ""Strategies""msgid ""Audit Templates""msgid ""Audits"" msgstr """" #: watcher/db/purge.py:54 msgid ""Action Plans"" msgstr """" #: watcher/db/purge.py:55#: watcher/db/purge.py:102#: watcher/db/purge.py:160#: watcher/db/purge.py:227#: watcher/db/purge.py:305#: watcher/db/purge.py:312#: watcher/db/purge.py:317#: watcher/db/purge.py:407#: watcher/db/purge.py:413#: watcher/db/purge.py:423#: watcher/db/purge.py:424#: watcher/db/purge.py:427 watcher/db/purge.py:428#: watcher/db/purge.py:431#: watcher/db/purge.py:436#: watcher/db/sqlalchemy/api.py:436 msgid ""Cannot overwrite UUID for an existing Goal."" msgstr """" #: watcher/db/sqlalchemy/api.py:545 msgid ""Cannot overwrite UUID for an existing Strategy."" msgstr """" #: watcher/db/sqlalchemy/api.py:645#: watcher/db/sqlalchemy/api.py:668#: watcher/db/sqlalchemy/api.py:782#: watcher/db/sqlalchemy/api.py:877#: watcher/db/sqlalchemy/api.py:990#: watcher/decision_engine/sync.py:94 #, python-format msgid ""Goal %s already exists"" msgstr """" #: watcher/decision_engine/sync.py:101 #, python-format msgid ""Strategy %s already exists"" msgstr """" #: watcher/decision_engine/sync.py:123 #, python-format msgid ""Goal %s created"" msgstr """" #: watcher/decision_engine/sync.py:152 #, python-format msgid ""Strategy %s created"" msgstr """" #: watcher/decision_engine/sync.py:178 #, python-format msgid ""Audit Template '%s' synced"" msgstr """" #: watcher/decision_engine/sync.py:222 #, python-format msgid ""Audit Template '%(audit_template)s' references a goal that does not exist"" msgstr """" #: watcher/decision_engine/sync.py:237 #, python-format msgid """" ""Audit Template '%(audit_template)s' references a strategy that does not "" ""exist"" msgstr """" #: watcher/decision_engine/sync.py:275 #, python-format msgid ""Goal %s unchanged"" msgstr """" #: watcher/decision_engine/sync.py:277 #, python-format msgid ""Goal %s modified"" msgstr """" #: watcher/decision_engine/sync.py:290 #, python-format msgid ""Strategy %s unchanged"" msgstr """" #: watcher/decision_engine/sync.py:292 #, python-format msgid ""Strategy %s modified"" msgstr """" #: watcher/decision_engine/model/model_root.py:33 #: watcher/decision_engine/model/model_root.py:38#: watcher/decision_engine/strategy/selection/default.py:74msgid ""Could not load any strategy for goal %(goal)s""#: watcher/decision_engine/strategy/strategies/base.py:165 msgid ""Dummy goal"" msgstr """" #: watcher/decision_engine/strategy/strategies/base.py:181 msgid ""Server consolidation"" msgstr """" #: watcher/decision_engine/strategy/strategies/base.py:197 msgid ""Thermal optimization"" msgstr """" #: watcher/decision_engine/strategy/strategies/basic_consolidation.py:119 msgid ""Basic offline consolidation"" msgstr """" #: watcher/decision_engine/strategy/strategies/basic_consolidation.py:296 #: watcher/decision_engine/strategy/strategies/basic_consolidation.py:343#: watcher/decision_engine/strategy/strategies/basic_consolidation.py:456#: watcher/decision_engine/strategy/strategies/basic_consolidation.py:500#: watcher/decision_engine/strategy/strategies/dummy_strategy.py:74 msgid ""Dummy strategy"" msgstr """" #: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:102 msgid ""Outlet temperature based strategy"" msgstr """" #: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:156#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:181#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:239#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:262#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:100 msgid ""VM Workload Consolidation Strategy"" msgstr """" #: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:128#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:180#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:264#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:515","""Project-Id-Version: python-watcher 0.25.1.dev3\n""""POT-Creation-Date: 2016-03-30 10:10+0200\n""""Generated-By: Babel 2.2.0\n"" #: watcher/api/controllers/v1/action.py:364#: watcher/api/controllers/v1/action.py:388#: watcher/api/controllers/v1/action.py:424#: watcher/api/controllers/v1/action_plan.py:102#: watcher/api/controllers/v1/action_plan.py:422#: watcher/api/controllers/v1/audit.py:359msgid ""Goal %(goal)s is not defined in Watcher configuration file""msgid ""Expected a uuid but received %(uuid)s""msgid ""Expected a logical name but received %(name)s""msgid ""Expected a logical name or uuid but received %(name)s""msgid ""AuditTemplate %(audit_template)s could not be found""#: watcher/common/exception.py:179#: watcher/common/exception.py:184#: watcher/common/exception.py:188#: watcher/common/exception.py:192#: watcher/common/exception.py:197#: watcher/common/exception.py:201#: watcher/common/exception.py:205#: watcher/common/exception.py:210#: watcher/common/exception.py:214#: watcher/common/exception.py:218#: watcher/common/exception.py:223#: watcher/common/exception.py:232#: watcher/common/exception.py:238#: watcher/common/exception.py:242#: watcher/common/exception.py:246#: watcher/common/exception.py:250#: watcher/common/exception.py:254#: watcher/common/exception.py:258#: watcher/common/exception.py:262#: watcher/common/exception.py:266#: watcher/common/exception.py:270 msgid ""the cluster state is not defined""#: watcher/common/exception.py:276#: watcher/common/exception.py:280#: watcher/common/exception.py:284#: watcher/common/exception.py:288#: watcher/common/exception.py:292#: watcher/common/exception.py:296msgid ""Audit Templates""msgid ""Audits""msgid ""Action Plans""#: watcher/db/purge.py:100#: watcher/db/purge.py:158#: watcher/db/purge.py:206#: watcher/db/purge.py:265#: watcher/db/purge.py:272#: watcher/db/purge.py:277#: watcher/db/purge.py:340#: watcher/db/purge.py:346#: watcher/db/purge.py:356#: watcher/db/purge.py:357#: watcher/db/purge.py:360 watcher/db/purge.py:361#: watcher/db/purge.py:364#: watcher/db/purge.py:369#: watcher/db/sqlalchemy/api.py:362#: watcher/db/sqlalchemy/api.py:384#: watcher/db/sqlalchemy/api.py:495#: watcher/db/sqlalchemy/api.py:588#: watcher/db/sqlalchemy/api.py:699#: watcher/decision_engine/model/model_root.py:37 #: watcher/decision_engine/model/model_root.py:42#: watcher/decision_engine/strategy/selection/default.py:60msgid ""Incorrect mapping: could not find associated strategy for '%s'""#: watcher/decision_engine/strategy/strategies/basic_consolidation.py:288 #: watcher/decision_engine/strategy/strategies/basic_consolidation.py:335#: watcher/decision_engine/strategy/strategies/basic_consolidation.py:448#: watcher/decision_engine/strategy/strategies/basic_consolidation.py:492#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:147#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:172#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:230#: watcher/decision_engine/strategy/strategies/outlet_temp_control.py:253#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:104#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:156#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:240#: watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py:489",214,79
openstack%2Fnetworking-odl~master~I504bfb877b81565373217bcb7cc07d07fcd886dd,openstack/networking-odl,master,I504bfb877b81565373217bcb7cc07d07fcd886dd,Updated from global requirements,MERGED,2016-04-28 16:13:11.000000000,2016-05-11 15:32:42.000000000,2016-05-11 15:32:42.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 10386}, {'_account_id': 14605}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-04-28 16:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/73a24801e0d5fe7d490fb39ba9f89e9025e4cfb7', 'message': 'Updated from global requirements\n\nChange-Id: I504bfb877b81565373217bcb7cc07d07fcd886dd\n'}, {'number': 2, 'created': '2016-04-30 18:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/141d22ef34f33e08bd61508a865f32fe5ebf5761', 'message': 'Updated from global requirements\n\nChange-Id: I504bfb877b81565373217bcb7cc07d07fcd886dd\n'}, {'number': 3, 'created': '2016-05-06 22:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/0be74a348a8850fa932ae9862d4fb73e2265bbcd', 'message': 'Updated from global requirements\n\nChange-Id: I504bfb877b81565373217bcb7cc07d07fcd886dd\n'}, {'number': 4, 'created': '2016-05-10 00:45:46.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/4c52e585fbbede4412113323c243496d363a0395', 'message': 'Updated from global requirements\n\nChange-Id: I504bfb877b81565373217bcb7cc07d07fcd886dd\n'}]",0,310837,4c52e585fbbede4412113323c243496d363a0395,24,5,4,11131,,,0,"Updated from global requirements

Change-Id: I504bfb877b81565373217bcb7cc07d07fcd886dd
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/37/310837/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,73a24801e0d5fe7d490fb39ba9f89e9025e4cfb7,openstack/requirements,stevedore>=1.9.0 # Apache-2.0,stevedore>=1.5.0 # Apache-2.0,1,1
openstack%2Fwatcher~master~I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca,openstack/watcher,master,I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca,Remove [watcher_goals] config section,MERGED,2016-04-15 14:56:28.000000000,2016-05-11 15:32:36.000000000,2016-05-11 15:32:36.000000000,"[{'_account_id': 3}, {'_account_id': 8358}, {'_account_id': 12394}, {'_account_id': 18971}, {'_account_id': 20676}]","[{'number': 1, 'created': '2016-04-15 14:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/474a0d1f4b9c0d196953118d62ec3ba31f061f38', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 2, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/f81c63bef9d170c93aa0eb60945478868ae2df6d', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 3, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4975557cc1e4c7d391d8ecbf05c44669291e4ba8', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 4, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/21510cf07b88fefdf5e353e01019bba2a6ae0454', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 5, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/a91bcda9c045bf1c9609dd214e3da2b8f3205b01', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 6, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/bd62ac4fc54300c78ec97659b90aca425592b71b', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 7, 'created': '2016-05-11 13:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/546913240eb102a581ae17373859e8b61d4aac6e', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}, {'number': 8, 'created': '2016-05-11 13:48:25.000000000', 'files': ['watcher/opts.py', 'watcher/decision_engine/strategy/selection/default.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/5f6a97148fa5aa745dec83fcdeeec8b2ff38216d', 'message': 'Remove [watcher_goals] config section\n\nIn this changeset, I remove the now unused [watcher_goals] section.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca\n'}]",0,306485,5f6a97148fa5aa745dec83fcdeeec8b2ff38216d,36,5,8,18971,,,0,"Remove [watcher_goals] config section

In this changeset, I remove the now unused [watcher_goals] section.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I91e4e1ac3a58bb6f3e30b11449cf1a6eb18cd0ca
",git fetch https://review.opendev.org/openstack/watcher refs/changes/85/306485/4 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/opts.py', 'watcher/decision_engine/strategy/selection/default.py']",2,474a0d1f4b9c0d196953118d62ec3ba31f061f38,bp/get-goal-from-strategy,,"default_goals = {'DUMMY': 'dummy'} WATCHER_GOALS_OPTS = [ cfg.DictOpt( 'goals', default=default_goals, required=True, help='Goals used for the optimization. ' 'Maps each goal to an associated strategy (for example: ' 'BASIC_CONSOLIDATION:basic, MY_GOAL:my_strategy_1)'), ] goals_opt_group = cfg.OptGroup(name='watcher_goals', title='Goals available for the optimization') CONF.register_group(goals_opt_group) CONF.register_opts(WATCHER_GOALS_OPTS, goals_opt_group) ",0,19
openstack%2Fwatcher~master~Iaa986f426dc47f6cbd04e74f16b67670e3563967,openstack/watcher,master,Iaa986f426dc47f6cbd04e74f16b67670e3563967,Remove watcher_goals section from devstack plugin,MERGED,2016-03-31 12:43:39.000000000,2016-05-11 15:32:35.000000000,2016-05-11 15:32:35.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 8358}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-03-31 12:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/545fcebd299d2adb59d80cdd519c35a2414f9922', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 2, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4705d8502a65ca4aecdf31c23d7aad2917960b11', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 3, 'created': '2016-04-13 07:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1a5982dbc6a708851bad5e6a6b605288f4310cea', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 4, 'created': '2016-04-13 08:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/21f07117894e20c67c4eef8a4542b9cceab92a97', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 5, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/845607e32a4a9edd9fc651fd0790447d60ad1c80', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 6, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/a2332ff1b24889d800328550be010bf3a13e14b8', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 7, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/46b02ff3ef0d4122d3e9469e8792dabb2eecd119', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 8, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8be3353918702f3610fbedd39b5d4772a60ad8d2', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 9, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/afa03d44bc4f7f6258894887905a495d5a2ea368', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 10, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/86c7671ee25afc65b7f2babfe1f7a54a27792c5d', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 11, 'created': '2016-05-11 13:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/bc07f49ca9b39bed30fee3f4ebe1fb59fb3ad425', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}, {'number': 12, 'created': '2016-05-11 13:48:25.000000000', 'files': ['devstack/local.conf.controller', 'devstack/lib/watcher'], 'web_link': 'https://opendev.org/openstack/watcher/commit/e6b23a0856e3e26dfd676da39a6149c9a5c0b535', 'message': 'Remove watcher_goals section from devstack plugin\n\nIn this changeset, I removed the now useless [watcher_goals] section\nfrom the devstack plugin.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967\n'}]",0,299902,e6b23a0856e3e26dfd676da39a6149c9a5c0b535,56,9,12,18971,,,0,"Remove watcher_goals section from devstack plugin

In this changeset, I removed the now useless [watcher_goals] section
from the devstack plugin.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: Iaa986f426dc47f6cbd04e74f16b67670e3563967
",git fetch https://review.opendev.org/openstack/watcher refs/changes/02/299902/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/local.conf.controller'],1,545fcebd299d2adb59d80cdd519c35a2414f9922,bp/get-goal-from-strategy,," [[post-config|$WATCHER_CONF]] [watcher_goals] goals=BASIC_CONSOLIDATION:basic,DUMMY:dummy",0,4
openstack%2Fwatcher~master~I40be39624097365220bf7d94cbe177bbf5bbe0ed,openstack/watcher,master,I40be39624097365220bf7d94cbe177bbf5bbe0ed,Documentation update for get-goal-from-strategy,MERGED,2016-03-31 12:36:21.000000000,2016-05-11 15:32:28.000000000,2016-05-11 15:32:28.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 11235}, {'_account_id': 11750}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-03-31 12:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5c29766849c53d4d71bb574bbd6f64e969fa8483', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 2, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5019efabb54769db0686f6926b87a1c5469e619c', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 3, 'created': '2016-04-13 07:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/2dd52776f6dd22a32dfa03e609ed1df9e3d1a2f6', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 4, 'created': '2016-04-13 08:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/324ecd0b1dc18b551f8350e076d6877933d3af41', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 5, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6be954da2f719c95da659e9795d3bc41ad8a0fad', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 6, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/9d54c288474da8b0134ff4bc88df84a6be29b86c', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 7, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4b292d76b8ad25efbf3630933db2cc586ee1a86a', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 8, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/c5d8fe97d9a41f6d627b58ba3fa697c2ac7e928f', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 9, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4ce98274ca9d20515981958cae8c5ad4846d2b4b', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 10, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/dde4bb5449136bd8641d2a393a0573902d6ac570', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 11, 'created': '2016-05-11 13:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/2d1b02f96b50c09251b97f755054328e9e052918', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}, {'number': 12, 'created': '2016-05-11 13:48:25.000000000', 'files': ['watcher/decision_engine/strategy/strategies/base.py', 'doc/source/architecture.rst', 'watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py', 'doc/source/image_src/plantuml/sequence_launch_action_plan.txt', 'doc/source/dev/plugin/strategy-plugin.rst', 'doc/source/deploy/user-guide.rst', 'doc/source/image_src/plantuml/sequence_create_audit_template.txt', 'doc/source/images/sequence_launch_action_plan.png', 'doc/source/images/sequence_create_audit_template.png', 'doc/source/deploy/configuration.rst', 'watcher/api/controllers/v1/strategy.py', 'doc/source/glossary.rst'], 'web_link': 'https://opendev.org/openstack/watcher/commit/f9a1b9d3cec667292dc13ea7bc0fc5e9092869f3', 'message': 'Documentation update for get-goal-from-strategy\n\nIn this changeset, I updated the Watcher documentation to reflect\nthe changes that are introduced by this blueprint.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed\n'}]",38,299900,f9a1b9d3cec667292dc13ea7bc0fc5e9092869f3,54,8,12,18971,,,0,"Documentation update for get-goal-from-strategy

In this changeset, I updated the Watcher documentation to reflect
the changes that are introduced by this blueprint.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I40be39624097365220bf7d94cbe177bbf5bbe0ed
",git fetch https://review.opendev.org/openstack/watcher refs/changes/00/299900/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/image_src/plantuml/sequence_create_audit_template.txt', 'doc/source/images/sequence_launch_action_plan.png', 'doc/source/images/sequence_create_audit_template.png', 'watcher/decision_engine/strategy/strategies/base.py', 'doc/source/architecture.rst', 'doc/source/deploy/configuration.rst', 'doc/source/image_src/plantuml/sequence_launch_action_plan.txt', 'watcher/api/controllers/v1/strategy.py', 'doc/source/dev/plugin/strategy-plugin.rst', 'doc/source/glossary.rst']",10,5c29766849c53d4d71bb574bbd6f64e969fa8483,bp/get-goal-from-strategy,The way efficacy is evaluated will depend on the :ref:`Goal <goal_definition>` to achieve... watcher-term:: watcher.api.controllers.v1.strategy,The way efficacy is evaluated will depend on the :ref:`Goal <goal_definition>` to achieve... watcher-term:: watcher.decision_engine.strategy.strategies.base,118,71
openstack%2Fwatcher~master~I2f1d58bb812fa45bc4bc6467760a071d8612e6a4,openstack/watcher,master,I2f1d58bb812fa45bc4bc6467760a071d8612e6a4,Updated purge to now include goals and strategies,MERGED,2016-03-30 17:03:32.000000000,2016-05-11 15:32:22.000000000,2016-05-11 15:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/bfbf1bb6676e2e43f3b4477ac7d5bbc445eff1f8', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nI also update the /audit_templates endpoint to validate the strategies\nprovided as input for in POST and PATCH\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 2, 'created': '2016-03-30 17:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b32ec5de4adb52e00afbe1973ae409da327bce46', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nI also update the /audit_templates endpoint to validate the strategies\nprovided as input for in POST and PATCH\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 3, 'created': '2016-03-31 12:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3176bb5a2c8cc8949d9441401910821f559b54db', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nI also update the /audit_templates endpoint to validate the strategies\nprovided as input for in POST and PATCH\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 4, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1feb6ff33410a18243e1a1fe57410595255fd731', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 5, 'created': '2016-04-13 08:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/9145bc49d59ea1f5f31ec3ed69cf4c7878bf63b3', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 6, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5b43665500d750a2054dd7ffe4d1d08fafc3ceb9', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 7, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/cfca236918ceade76f750b464a3d23d5a1b16d97', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 8, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4749552a976971d216389c0db9d3b17f34987582', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 9, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/223002e59a5ba6d906c87b8de2d70eb030748d26', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 10, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/ec4dbc51b373ecaeed2327387c58083d8db1c8a2', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 11, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/de2e88b1f058d049bf4f2d4f0345378772cde5fa', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}, {'number': 12, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/db/purge.py', 'watcher/tests/db/test_purge.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/ff611544fbf35ba49d5db8ca9a165d6d02a61a83', 'message': 'Updated purge to now include goals and strategies\n\nIn this changeset, I updated the purge script to now take into\naccount the registered goals and strategies.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4\n'}]",25,299539,ff611544fbf35ba49d5db8ca9a165d6d02a61a83,53,7,12,18971,,,0,"Updated purge to now include goals and strategies

In this changeset, I updated the purge script to now take into
account the registered goals and strategies.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I2f1d58bb812fa45bc4bc6467760a071d8612e6a4
",git fetch https://review.opendev.org/openstack/watcher refs/changes/39/299539/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/api/v1/test_audit_templates.py', 'watcher/db/purge.py', 'watcher/tests/objects/utils.py', 'watcher/tests/db/test_purge.py', 'watcher/common/exception.py', 'watcher/api/controllers/v1/audit_template.py']",6,bfbf1bb6676e2e43f3b4477ac7d5bbc445eff1f8,bp/get-goal-from-strategy," available_strategies = objects.Strategy.list( context_utils.make_context()) available_strategy_ids = [g.id for g in available_strategies] if audit_template.strategy_id not in available_strategy_ids: raise exception.InvalidStrategy(audit_template.strategy_id) if patch.path == ""/strategy_id"" and patch.op != ""remove"": AuditTemplatePatchType._validate_strategy(patch) @staticmethod def _validate_strategy(patch): serialized_patch = {'path': patch.path, 'op': patch.op} if patch.value is not wsme.Unset: serialized_patch['value'] = patch.value new_strategy = patch.value available_strategies = objects.Strategy.list( context_utils.make_context()) available_strategies = [s.id for s in available_strategies] if new_strategy and new_strategy not in available_strategies: raise exception.InvalidStrategy(strategy_id=new_strategy) ",,310,48
openstack%2Fwatcher~master~Ie394c12fe51f73eff95465fd5140d82ebd212599,openstack/watcher,master,Ie394c12fe51f73eff95465fd5140d82ebd212599,Syncer now syncs stale audit templates,MERGED,2016-04-14 16:13:20.000000000,2016-05-11 15:32:17.000000000,2016-05-11 15:32:16.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6ad1ffa573795011cbbbef75c65cb4e786a03a99', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}, {'number': 2, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/07c212ef428abcbb2c9b405ee837d526c493ac2d', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}, {'number': 3, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/717549a3b9280d73662a704c04d89523b46c0fd8', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}, {'number': 4, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/95f798969f607b969a2279d0e00e1724299abc26', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}, {'number': 5, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8faed22d6889a12203c603b8ba69e1d2eb33ef39', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}, {'number': 6, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6d7559f76cb4f5359139c8b7e973ca88b14df95c', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}, {'number': 7, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/decision_engine/sync.py', 'watcher/tests/decision_engine/test_sync.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/18e5c7d844e895e514022f5d64121e1c4484bc65', 'message': 'Syncer now syncs stale audit templates\n\nIn this changeset, I introduce the syncing of audit templates.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599\n'}]",12,305965,18e5c7d844e895e514022f5d64121e1c4484bc65,44,7,7,18971,,,0,"Syncer now syncs stale audit templates

In this changeset, I introduce the syncing of audit templates.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: Ie394c12fe51f73eff95465fd5140d82ebd212599
",git fetch https://review.opendev.org/openstack/watcher refs/changes/65/305965/2 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/sync.py', 'watcher/tests/decision_engine/test_sync.py']",2,6ad1ffa573795011cbbbef75c65cb4e786a03a99,bp/get-goal-from-strategy," # Unmodified goal1 = objects.Goal(self.ctx, id=1, uuid=utils.generate_uuid(), name=""DUMMY_1"", display_name=""Dummy 1"") # Modified goal2 = objects.Goal(self.ctx, id=2, uuid=utils.generate_uuid(), name=""DUMMY_2"", display_name=""Original"") goal1.create() goal2.create() # Unmodified strategy1 = objects.Strategy( self.ctx, id=1, name=""STRATEGY_1"", uuid=utils.generate_uuid(), display_name=""Strategy 1"", goal_id=goal1.id) # Unmodified strategy2 = objects.Strategy( self.ctx, id=2, name=""STRATEGY_2"", uuid=utils.generate_uuid(), display_name=""Strategy 2"", goal_id=goal2.id) # Modified strategy3 = objects.Strategy( self.ctx, id=3, name=""STRATEGY_3"", uuid=utils.generate_uuid(), display_name=""Original"", goal_id=goal2.id) # Modified strategy4 = objects.Strategy( self.ctx, id=4, name=""STRATEGY_4"", uuid=utils.generate_uuid(), display_name=""Original"", goal_id=goal2.id) strategy1.create() strategy2.create() strategy3.create() strategy4.create() # Unmodified audit_template1 = objects.AuditTemplate( self.ctx, id=1, uuid=utils.generate_uuid(), name=""Synced AT1"", goal_id=goal1.id, strategy_id=strategy1.id) # Modified because of the goal audit_template2 = objects.AuditTemplate( self.ctx, id=2, name=""Synced AT2"", uuid=utils.generate_uuid(), goal_id=goal2.id, strategy_id=strategy2.id) # Modified because of the strategy audit_template3 = objects.AuditTemplate( self.ctx, id=3, name=""Synced AT3"", uuid=utils.generate_uuid(), goal_id=goal2.id, strategy_id=strategy3.id) # Modified because of both audit_template4 = objects.AuditTemplate( self.ctx, id=4, name=""Synced AT4"", uuid=utils.generate_uuid(), goal_id=goal2.id, strategy_id=strategy4.id) audit_template1.create() audit_template2.create() audit_template3.create() audit_template4.create() before_audit_templates = objects.AuditTemplate.list(self.ctx) after_audit_templates = objects.AuditTemplate.list(self.ctx) self.assertEqual(2, len(before_goals)) self.assertEqual(4, len(before_strategies)) self.assertEqual(4, len(before_audit_templates)) self.assertEqual(4, len(after_audit_templates)) self.assertEqual(1, len(created_goals)) self.assertEqual(2, len(created_strategies)) modified_audit_templates = { a_at.id for a_at in after_audit_templates if a_at.goal_id not in ( # initial goal IDs b_at.goal_id for b_at in before_audit_templates) or a_at.strategy_id not in ( # initial strategy IDs b_at.strategy_id for b_at in before_audit_templates if b_at.strategy_id is not None) } unmodified_audit_templates = { a_at.id for a_at in after_audit_templates if a_at.goal_id in ( # initial goal IDs b_at.goal_id for b_at in before_audit_templates) and a_at.strategy_id in ( # initial strategy IDs b_at.strategy_id for b_at in before_audit_templates if b_at.strategy_id is not None) } self.assertEqual(set([audit_template2.id, audit_template3.id, audit_template4.id]), modified_audit_templates) self.assertEqual(set([audit_template1.id]), unmodified_audit_templates) def test_end2end_sync_goals_with_removed_goal_and_strategy(self): # We Simulate the fact that we removed 3 strategies # as well as the DUMMY_2 goal strategy.strategies.AVAILABLE_STRATEGIES = [ fake_strategies.FakeDummy1Strategy1] # Unmodified goal1 = objects.Goal(self.ctx, id=1, uuid=utils.generate_uuid(), name=""DUMMY_1"", display_name=""Dummy 1"") # To be removed goal2 = objects.Goal(self.ctx, id=2, uuid=utils.generate_uuid(), name=""DUMMY_2"", display_name=""Dummy 2"") goal1.create() goal2.create() # Unmodified strategy1 = objects.Strategy( self.ctx, id=1, name=""STRATEGY_1"", uuid=utils.generate_uuid(), display_name=""Strategy 1"", goal_id=goal1.id) # To be removed strategy2 = objects.Strategy( self.ctx, id=2, name=""STRATEGY_2"", uuid=utils.generate_uuid(), display_name=""Strategy 2"", goal_id=goal1.id) # To be removed strategy3 = objects.Strategy( self.ctx, id=3, name=""STRATEGY_3"", uuid=utils.generate_uuid(), display_name=""Original"", goal_id=goal2.id) strategy1.create() strategy2.create() strategy3.create() # The strategy of this audit template will be dereferenced # as it does not exist anymore audit_template1 = objects.AuditTemplate( self.ctx, id=1, uuid=utils.generate_uuid(), name=""Synced AT1"", goal_id=goal1.id, strategy_id=strategy1.id) # Stale even after syncing because the goal has been soft deleted audit_template2 = objects.AuditTemplate( self.ctx, id=2, name=""Synced AT2"", uuid=utils.generate_uuid(), goal_id=goal2.id, strategy_id=strategy2.id) audit_template1.create() audit_template2.create() before_audit_templates = objects.AuditTemplate.list(self.ctx) before_goals = objects.Goal.list(self.ctx) before_strategies = objects.Strategy.list(self.ctx) try: self.syncer.sync() except Exception as exc: self.fail(exc) after_audit_templates = objects.AuditTemplate.list(self.ctx) after_goals = objects.Goal.list(self.ctx) after_strategies = objects.Strategy.list(self.ctx) self.assertEqual(2, len(before_goals)) self.assertEqual(3, len(before_strategies)) self.assertEqual(2, len(before_audit_templates)) self.assertEqual(1, len(after_goals)) self.assertEqual(1, len(after_strategies)) self.assertEqual(2, len(after_audit_templates)) self.assertEqual( {""DUMMY_1""}, set([g.name for g in after_goals])) self.assertEqual( {""STRATEGY_1""}, set([s.name for s in after_strategies])) created_goals = [ag for ag in after_goals if ag.uuid not in [bg.uuid for bg in before_goals]] created_strategies = [ a_s for a_s in after_strategies if a_s.uuid not in [b_s.uuid for b_s in before_strategies]] self.assertEqual(0, len(created_goals)) self.assertEqual(0, len(created_strategies)) modified_audit_templates = { a_at.id for a_at in after_audit_templates if a_at.goal_id not in ( # initial goal IDs b_at.goal_id for b_at in before_audit_templates) or a_at.strategy_id not in ( # initial strategy IDs b_at.strategy_id for b_at in before_audit_templates if b_at.strategy_id is not None) } unmodified_audit_templates = { a_at.id for a_at in after_audit_templates if a_at.goal_id in ( # initial goal IDs b_at.goal_id for b_at in before_audit_templates) and a_at.strategy_id in ( # initial strategy IDs b_at.strategy_id for b_at in before_audit_templates if b_at.strategy_id is not None) } self.assertEqual(set([audit_template2.id]), modified_audit_templates) self.assertEqual(set([audit_template1.id]), unmodified_audit_templates)"," goal = objects.Goal(self.ctx, id=1, uuid=utils.generate_uuid(), name=""DUMMY_1"", display_name=""Original"") goal.create() strategy = objects.Strategy( self.ctx, id=1, name=""STRATEGY_1"", display_name=""Original"", goal_id=goal.id) strategy.create() # audit_template = objects.AuditTemplate( # self.ctx, id=1, name=""Synced AT"", goal_id=goal.id, # strategy_id=strategy.id) # audit_template.create() # before_audit_templates = objects.AuditTemplate.list(self.ctx) # after_audit_templates = objects.AuditTemplate.list(self.ctx) self.assertEqual(1, len(before_goals)) self.assertEqual(1, len(before_strategies)) # self.assertEqual(1, len(before_audit_templates)) # self.assertEqual(1, len(after_audit_templates)) self.assertEqual(2, len(created_goals)) self.assertEqual(4, len(created_strategies)) # synced_audit_template = after_audit_templates[0] # self.assertTrue( # audit_template.goal_id != synced_audit_template.goal_id) # self.assertIn(synced_audit_template.goal_id, # (g.id for g in after_goals))",325,59
openstack%2Fwatcher~master~Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9,openstack/watcher,master,Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9,Add strategy_id & goal_id fields in audit template,MERGED,2016-03-23 17:45:09.000000000,2016-05-11 15:32:10.000000000,2016-05-11 15:32:10.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-03-23 17:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/81e31267badca598e2fda91c2276695f45997ae3', 'message': ""Add strategy & goal fields in audit template\n\nIn this changeset, I updated the 'goal' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nI also changed the BaseStrategy abstract class to add new abstract\nclass methods. I also added an abstract strategy class per Goal type\n(i.e. dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 2, 'created': '2016-03-24 13:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/faf517f9da8a12bef05bf9a83d12fed45fe90552', 'message': ""Add strategy & goal fields in audit template\n\nIn this changeset, I updated the 'goal' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nI also changed the BaseStrategy abstract class to add new abstract\nclass methods. I also added an abstract strategy class per Goal type\n(i.e. dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 3, 'created': '2016-03-24 17:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/829df0026595b7eb44950421a387a1bf36779d39', 'message': ""Add strategy & goal fields in audit template\n\nIn this changeset, I updated the 'goal' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nI also changed the BaseStrategy abstract class to add new abstract\nclass methods. I also added an abstract strategy class per Goal type\n(i.e. dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 4, 'created': '2016-03-29 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/17dbca3451cc2a59658a55733e6a6a0ac77fbfb7', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nI also changed the BaseStrategy abstract class to add new abstract\nclass methods. I also added an abstract strategy class per Goal type\n(i.e. dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 5, 'created': '2016-03-29 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0fbae6f6b47eaf2340a3c1951efb7e9b8123c640', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nI also changed the BaseStrategy abstract class to add new abstract\nclass methods. I also added an abstract strategy class per Goal type\n(i.e. dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 6, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0074d1a33d8403c476f089321f9317ef904cd8d0', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nI also changed the BaseStrategy abstract class to add new abstract\nclass methods. I also added an abstract strategy class per Goal type\n(i.e. dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 7, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/2573f5f2e1b47946df2145e1af46a6b5a7c9a892', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 8, 'created': '2016-04-13 08:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/ea75cbd9e22ee2fd1bf4d81ddc54b8c5e30f6627', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 9, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/49ca8b55c5ba254a92f68531e88ddd026a50e37e', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 10, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/05244e1687d112613ebe0f81747698dbaa7b7b79', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 11, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/946910e794f231e09137e490bf0e23349534bd1d', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 12, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1a7c2a2d89a7549bb7bddb76e5af2cdbc157c0d2', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nAPIImpact\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 13, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/e3dc43e4919bf631d187e05638d7b1887fe2dedc', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 14, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/82b63683e60abda3e09219f1ba0440f8c8706425', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}, {'number': 15, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/tests/api/v1/test_audit_templates.py', 'watcher/tests/objects/test_audit_template.py', 'watcher_tempest_plugin/services/infra_optim/v1/json/client.py', 'watcher_tempest_plugin/tests/scenario/base.py', 'watcher_tempest_plugin/tests/scenario/test_execute_basic_optim.py', 'watcher/decision_engine/strategy/context/default.py', 'watcher_tempest_plugin/tests/api/admin/test_action.py', 'watcher/common/exception.py', 'watcher/db/sqlalchemy/api.py', 'watcher/api/controllers/v1/audit_template.py', 'watcher/tests/db/sqlalchemy/test_types.py', 'watcher_tempest_plugin/tests/api/admin/test_audit.py', 'watcher/api/app.py', 'watcher_tempest_plugin/tests/api/admin/base.py', 'watcher_tempest_plugin/tests/api/admin/test_action_plan.py', 'watcher/tests/db/utils.py', 'watcher/objects/audit_template.py', 'watcher_tempest_plugin/tests/api/admin/test_audit_template.py', 'watcher/db/sqlalchemy/models.py', 'watcher_tempest_plugin/tests/scenario/test_execute_dummy_optim.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/2966b93777642fdb7a84419cfdb1c1ccf0e9d723', 'message': ""Add strategy_id & goal_id fields in audit template\n\nIn this changeset, I updated the 'goal_id' field into the AuditTemplate\nto now become a mandatory foreign key towards the Goal model. I also\nadded the 'strategy_id' field into the AuditTemplate model to be an\noptional foreign key onto the Strategy model.\n\nThis changeset also includes an update of the /audit_template\nWatcher API endpoint to reflect the previous changes.\n\nAs this changeset changes the API, this should be merged alongside the\nrelated changeset from python-watcherclient.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9\n""}]",50,296636,2966b93777642fdb7a84419cfdb1c1ccf0e9d723,62,7,15,18971,,,0,"Add strategy_id & goal_id fields in audit template

In this changeset, I updated the 'goal_id' field into the AuditTemplate
to now become a mandatory foreign key towards the Goal model. I also
added the 'strategy_id' field into the AuditTemplate model to be an
optional foreign key onto the Strategy model.

This changeset also includes an update of the /audit_template
Watcher API endpoint to reflect the previous changes.

As this changeset changes the API, this should be merged alongside the
related changeset from python-watcherclient.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: Ic0573d036d1bbd7820f8eb963e47912d6b3ed1a9
",git fetch https://review.opendev.org/openstack/watcher refs/changes/36/296636/11 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/api/v1/test_audit_templates.py', 'watcher/tests/objects/test_audit_template.py', 'watcher_tempest_plugin/tests/scenario/test_execute_basic_optim.py', 'watcher/tests/decision_engine/strategy/selector/test_strategy_selector.py', 'watcher/decision_engine/strategy/context/default.py', 'watcher/api/controllers/v1/audit_template.py', 'watcher/tests/db/sqlalchemy/test_types.py', 'watcher/api/app.py', 'watcher/opts.py', 'watcher/tests/db/utils.py', 'watcher/objects/audit_template.py', 'watcher/tests/decision_engine/strategy/context/test_strategy_context.py', 'watcher_tempest_plugin/tests/api/admin/test_audit_template.py', 'watcher/db/sqlalchemy/models.py', 'watcher/decision_engine/strategy/selection/base.py', 'watcher/decision_engine/strategy/selection/default.py']",16,81e31267badca598e2fda91c2276695f45997ae3,bp/get-goal-from-strategy," def __init__(self, goal_id, strategy_id=None, osc=None): """"""Default strategy selector :param goal_id: ID of the goal :param strategy_id: ID of the strategy :param osc: an OpenStackClients instance """""" self.goal_id = goal_id self.strategy_id = strategy_id self.osc = osc def select(self): """"""Selects a strategy :raises: :py:class:`~.LoadingError` if it failed to load a strategy :returns: A :py:class:`~.BaseStrategy` instance """""" if self.strategy_id: strategy_to_load = self.strategy_id else: available_strategies = self.strategy_loader.list_available() # TODO(v-francoise): We should do some more work here to select # a strategy out of a given goal instead of just choosing the # 1st one strategy_to_load = list(available_strategies.keys())[0] return self.strategy_loader.load(strategy_to_load, osc=self.osc) except exception.LoadingError: raise except Exception as exc: raise exception.LoadingError( _(""Could not load any strategy for goal %(goal)s""), goal=self.goal_id)","default_goals = {'DUMMY': 'dummy'} WATCHER_GOALS_OPTS = [ cfg.DictOpt( 'goals', default=default_goals, required=True, help='Goals used for the optimization. ' 'Maps each goal to an associated strategy (for example: ' 'BASIC_CONSOLIDATION:basic, MY_GOAL:my_strategy_1)'), ] goals_opt_group = cfg.OptGroup(name='watcher_goals', title='Goals available for the optimization') CONF.register_group(goals_opt_group) CONF.register_opts(WATCHER_GOALS_OPTS, goals_opt_group) def __init__(self): def define_from_goal(self, goal_name, osc=None): """""":param osc: an OpenStackClients instance"""""" strategy_to_load = CONF.watcher_goals.goals[goal_name] return self.strategy_loader.load(strategy_to_load, osc=osc) except KeyError as exc: raise exception.WatcherException( _(""Incorrect mapping: could not find "" ""associated strategy for '%s'"") % goal_name )",163,125
openstack%2Fwatcher~master~I2bcb63542f6237f26796a3e5a781c8b62820cf6f,openstack/watcher,master,I2bcb63542f6237f26796a3e5a781c8b62820cf6f,Refactored Strategy selector to select from DB,MERGED,2016-04-12 16:24:38.000000000,2016-05-11 15:32:07.000000000,2016-05-11 15:32:06.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/15626c9eaa4fdd6b54d00ccf7131538311a287fe', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 2, 'created': '2016-04-13 08:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/a1e8f46aceb68df01e906d92681ce6474384c5e0', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 3, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/35ace6ed583f2f2fb8414dd1a1698f1af1494651', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 4, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1cfb99fba8178bba91605eba6c69e181fde9860d', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 5, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/e19410e274e77724f5728a15afec9023314f5813', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 6, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/656481f9297ef5f432dadba9af1354be8464f52a', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 7, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/482a510a890fe29f29710098c6f3e9281ac3cf2a', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 8, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6ff085e951ad635e0580b7f40d39c2422228c899', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}, {'number': 9, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher_tempest_plugin/tests/scenario/test_execute_basic_optim.py', 'watcher/tests/decision_engine/audit/test_default_audit_handler.py', 'watcher/tests/decision_engine/strategy/selector/test_strategy_selector.py', 'devstack/lib/watcher', 'watcher/tests/decision_engine/strategy/context/test_strategy_context.py', 'watcher_tempest_plugin/tests/api/admin/test_audit_template.py', 'watcher/decision_engine/strategy/context/default.py', 'watcher/common/exception.py', 'watcher/decision_engine/strategy/selection/base.py', 'watcher/decision_engine/strategy/selection/default.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/e67b53211019539ee10173ab1310a8758163922a', 'message': 'Refactored Strategy selector to select from DB\n\nIn this changeset, I refactored the strategy selector to now\nlook into the Watcher DB instead of looking into the configuration\nfile.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f\n'}]",8,304751,e67b53211019539ee10173ab1310a8758163922a,42,7,9,18971,,,0,"Refactored Strategy selector to select from DB

In this changeset, I refactored the strategy selector to now
look into the Watcher DB instead of looking into the configuration
file.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I2bcb63542f6237f26796a3e5a781c8b62820cf6f
",git fetch https://review.opendev.org/openstack/watcher refs/changes/51/304751/8 && git format-patch -1 --stdout FETCH_HEAD,"['watcher_tempest_plugin/tests/scenario/test_execute_basic_optim.py', 'devstack/lib/watcher', 'watcher/tests/decision_engine/audit/test_default_audit_handler.py', 'watcher/tests/decision_engine/strategy/selector/test_strategy_selector.py', 'watcher/tests/decision_engine/strategy/context/test_strategy_context.py', 'watcher/decision_engine/strategy/context/default.py', 'watcher/decision_engine/strategy/selection/base.py', 'watcher/decision_engine/strategy/selection/default.py']",8,15626c9eaa4fdd6b54d00ccf7131538311a287fe,bp/get-goal-from-strategy," def __init__(self, goal_name, strategy_name=None, osc=None): """"""Default strategy selector :param goal_name: Name of the goal :param strategy_name: Name of the strategy :param osc: an OpenStackClients instance """""" self.goal_name = goal_name self.strategy_name = strategy_name self.osc = osc def select(self): """"""Selects a strategy :raises: :py:class:`~.LoadingError` if it failed to load a strategy :returns: A :py:class:`~.BaseStrategy` instance """""" if self.strategy_name: strategy_to_load = self.strategy_name else: available_strategies = self.strategy_loader.list_available() # TODO(v-francoise): We should do some more work here to select # a strategy out of a given goal instead of just choosing the # 1st one strategy_to_load = list( key for key, strat in available_strategies.items() if strat.get_goal_name() == self.goal_name)[0] return self.strategy_loader.load(strategy_to_load, osc=self.osc) except exception.LoadingError: raise except Exception as exc: raise exception.LoadingError( _(""Could not load any strategy for goal %(goal)s""), goal=self.goal_name)"," def __init__(self): def define_from_goal(self, goal_name, osc=None): """""":param osc: an OpenStackClients instance"""""" strategy_to_load = CONF.watcher_goals.goals[goal_name] return self.strategy_loader.load(strategy_to_load, osc=osc) except KeyError as exc: raise exception.WatcherException( _(""Incorrect mapping: could not find "" ""associated strategy for '%s'"") % goal_name )",75,53
openstack%2Fwatcher~master~I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9,openstack/watcher,master,I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9,Added /strategies endpoint in Watcher API,MERGED,2016-03-31 12:36:21.000000000,2016-05-11 15:32:01.000000000,2016-05-11 15:32:01.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-03-31 12:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/7a00b36b971bca100fb8b220b964cd0be6043fec', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 2, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0dc4d6f00261cba99abb316f61a7424aeda982cb', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 3, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8332b9806e2388d05bdbec4dfa82d26280356b44', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 4, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/e060ff12a1e6758c37b213595b195c997b953cb1', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 5, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/9e68d01710a48bd17e5a48a21b2203b36754e577', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 6, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/158ba8f69caef577b8276fb425da47367bdd3b5c', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 7, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/f930df2e4d336f74abd18827f673aead86a4c368', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 8, 'created': '2016-05-02 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3cd4f6a12bc617f286b01441d74b92d08626a7c5', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}, {'number': 9, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/api/controllers/v1/__init__.py', 'watcher_tempest_plugin/services/infra_optim/v1/json/client.py', 'watcher/tests/objects/utils.py', 'watcher/api/controllers/v1/strategy.py', 'watcher/decision_engine/strategy/context/default.py', 'watcher/tests/api/v1/test_strategies.py', 'watcher/db/sqlalchemy/api.py', 'watcher_tempest_plugin/tests/api/admin/test_strategy.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/81765b9aa5357043296cb78f76f035ab41b00a64', 'message': 'Added /strategies endpoint in Watcher API\n\nIn this changeset, I added the /strategies endpoint to the Watcher\nAPI service.\nThis also includes the related Tempest tests.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9\n'}]",6,299899,81765b9aa5357043296cb78f76f035ab41b00a64,54,8,9,18971,,,0,"Added /strategies endpoint in Watcher API

In this changeset, I added the /strategies endpoint to the Watcher
API service.
This also includes the related Tempest tests.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I1b70836e0df2082ab0016ecc207e89fdcb0fc8b9
",git fetch https://review.opendev.org/openstack/watcher refs/changes/99/299899/8 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/api/controllers/v1/__init__.py', 'watcher_tempest_plugin/services/infra_optim/v1/json/client.py', 'watcher/api/controllers/v1/strategy.py', 'watcher/tests/api/v1/test_strategies.py', 'watcher_tempest_plugin/tests/api/admin/test_strategy.py']",5,7a00b36b971bca100fb8b220b964cd0be6043fec,bp/get-goal-from-strategy,"# -*- encoding: utf-8 -*- # Copyright (c) 2016 b<>com # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from __future__ import unicode_literals from tempest import test from watcher_tempest_plugin.tests.api.admin import base class TestShowListStrategy(base.BaseInfraOptimTest): """"""Tests for strategies"""""" DUMMY_STRATEGY = ""dummy"" @classmethod def resource_setup(cls): super(TestShowListStrategy, cls).resource_setup() def assert_expected(self, expected, actual, keys=('created_at', 'updated_at', 'deleted_at')): super(TestShowListStrategy, self).assert_expected( expected, actual, keys) @test.attr(type='smoke') def test_show_strategy(self): _, strategy = self.client.show_strategy(self.DUMMY_STRATEGY) self.assertEqual(self.DUMMY_STRATEGY, strategy['id']) self.assertIn(""display_name"", strategy.keys()) @test.attr(type='smoke') def test_show_strategy_with_links(self): _, strategy = self.client.show_strategy(self.DUMMY_STRATEGY) self.assertIn('links', strategy.keys()) self.assertEqual(2, len(strategy['links'])) self.assertIn(strategy['id'], strategy['links'][0]['href']) @test.attr(type=""smoke"") def test_list_strategies(self): _, body = self.client.list_strategies() self.assertIn(self.DUMMY_STRATEGY, [i['id'] for i in body['strategies']]) # Verify self links. for strategy in body['strategies']: self.validate_self_link('strategies', strategy['id'], strategy['links'][0]['href']) ",,367,0
openstack%2Fwatcher~master~Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f,openstack/watcher,master,Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f,Add Goal in BaseStrategy + Goal API reads from DB,MERGED,2016-03-23 17:45:09.000000000,2016-05-11 15:31:58.000000000,2016-05-11 15:31:58.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-03-23 17:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/448581e6c9939d336817b135f2269da655199bc7', 'message': 'Added Goal in Strategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /goal Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 2, 'created': '2016-03-24 13:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3b320e740a2e4707d836226a9b0fe9e2b731ce55', 'message': 'Added Goal in Strategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /goal Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 3, 'created': '2016-03-24 17:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/14ca352c3458c5e477af7a0a83385317b3345757', 'message': 'Added Goal in Strategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the the /goal Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 4, 'created': '2016-03-29 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4e8881877ddc5a36bf02fc944e74404d4d934267', 'message': 'Added Goal in Strategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 5, 'created': '2016-03-29 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/fe17e880de238d67fed4a359034e6704ca46d890', 'message': 'Added Goal in Strategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 6, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/087494ddea3b224f9fef442b71492130557f4de0', 'message': 'Added Goal in Strategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 7, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6b8f1e49de9f3dab9b708639a03fcc8c98215544', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 8, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/2b6df2c175f05c0b71c073b102a4640511e01b13', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 9, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1a1c747e1fb2d43df9c93bb29493f1f45a7ad218', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 10, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/c6c8d6868f928a71d29a7cc341a34ddeed4c5d4b', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 11, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4e3dc64ead858402ae5c837a4dde3ab4f7f04035', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 12, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/88b23ca9a3f508d7d9f2911774167a9b306410be', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}, {'number': 13, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher_tempest_plugin/services/infra_optim/v1/json/client.py', 'watcher/api/controllers/v1/collection.py', 'watcher/decision_engine/strategy/strategies/base.py', 'watcher/tests/objects/utils.py', 'watcher/decision_engine/strategy/strategies/vm_workload_consolidation.py', 'watcher/decision_engine/strategy/strategies/outlet_temp_control.py', 'watcher/tests/decision_engine/planner/test_default_planner.py', 'watcher/cmd/decisionengine.py', 'watcher/tests/db/test_goal.py', 'watcher/tests/decision_engine/strategy/strategies/test_dummy_strategy.py', 'watcher/tests/decision_engine/fake_strategies.py', 'watcher/decision_engine/strategy/strategies/dummy_strategy.py', 'watcher/decision_engine/strategy/strategies/basic_consolidation.py', 'watcher/api/controllers/v1/goal.py', 'watcher/decision_engine/sync.py', 'watcher/tests/api/v1/test_goals.py', 'watcher/tests/decision_engine/test_sync.py', 'watcher_tempest_plugin/tests/api/admin/test_goal.py', 'watcher/tests/decision_engine/strategy/loading/test_default_strategy_loader.py', 'watcher/tests/cmd/test_decision_engine.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/673642e4365186eb0fe29cb547bed8152b93f98e', 'message': 'Add Goal in BaseStrategy + Goal API reads from DB\n\nIn this changeset, I changed the Strategy base class to add new\nabstract class methods. I also added an abstract strategy class\nper Goal type (dummy, server consolidation, thermal optimization).\n\nThis changeset also includes an update of the /goals Watcher API\nendpoint to now use the new Goal model (DB entries) instead of\nreading from the configuration file.\n\nPartially Implements: blueprint get-goal-from-strategy\nChange-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f\n'}]",37,296635,673642e4365186eb0fe29cb547bed8152b93f98e,56,6,13,18971,,,0,"Add Goal in BaseStrategy + Goal API reads from DB

In this changeset, I changed the Strategy base class to add new
abstract class methods. I also added an abstract strategy class
per Goal type (dummy, server consolidation, thermal optimization).

This changeset also includes an update of the /goals Watcher API
endpoint to now use the new Goal model (DB entries) instead of
reading from the configuration file.

Partially Implements: blueprint get-goal-from-strategy
Change-Id: Iecfed58c72f3f9df4e9d27e50a3a274a1fc0a75f
",git fetch https://review.opendev.org/openstack/watcher refs/changes/35/296635/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/api/controllers/v1/collection.py', 'watcher/decision_engine/strategy/strategies/base.py', 'watcher/decision_engine/strategy/strategies/outlet_temp_control.py', 'watcher/tests/decision_engine/planner/test_default_planner.py', 'watcher/cmd/decisionengine.py', 'watcher/tests/decision_engine/strategy/strategies/test_dummy_strategy.py', 'watcher/decision_engine/strategy/strategies/dummy_strategy.py', 'watcher/decision_engine/strategy/strategies/basic_consolidation.py', 'watcher/api/controllers/v1/goal.py', 'watcher/tests/api/v1/test_goals.py', 'watcher_tempest_plugin/tests/api/admin/test_goal.py', 'watcher/tests/decision_engine/strategy/loading/test_default_strategy_loader.py', 'watcher/tests/cmd/test_decision_engine.py', 'watcher/tests/api/base.py']",14,448581e6c9939d336817b135f2269da655199bc7,bp/get-goal-from-strategy,from watcher.decision_engine.goal import registry registry.register_goals(),,199,124
openstack%2Fwatcher~master~Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5,openstack/watcher,master,Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5,DB sync for Strategies,MERGED,2016-03-29 15:07:42.000000000,2016-05-11 15:31:39.000000000,2016-05-11 15:31:39.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-03-29 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/aa10334d78f87aab3fddb7905613df26417d38f9', 'message': 'DB registration for Strategies\n\nIn this changeset, I added the ability to register the strategies into\nthe Wather DB so that it can later be served through the Watcher API\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 2, 'created': '2016-03-29 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/ea7a685eb8ff7b62ea3ac278bb204279e91362d0', 'message': 'DB registration for Strategies\n\nIn this changeset, I added the ability to register the strategies into\nthe Wather DB so that it can later be served through the Watcher API\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 3, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/47109c13c96e7583df9c3257dc420a7ddef6409b', 'message': 'DB registration for Strategies\n\nIn this changeset, I added the ability to register the strategies into\nthe Wather DB so that it can later be served through the Watcher API\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 4, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6a962c32fa75a2835bbf5e4c2d9b5e439d6a9d85', 'message': 'DB registration for Strategies\n\nIn this changeset, I added the ability to register the strategies\ninto the Wather DB so that it can later be served through the Watcher API\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 5, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4b3ef531a7b9d125389cf053a63f8058ffa8ed73', 'message': 'DB sync for Strategies\n\nIn this changeset, I added the ability to synchronize the strategies\ninto the Wather DB so that it can later be served through the Watcher\nAPI.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 6, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b9f90d1bda44bd04aac1591c6d7ae7f90a1110cb', 'message': 'DB sync for Strategies\n\nIn this changeset, I added the ability to synchronize the strategies\ninto the Wather DB so that it can later be served through the Watcher\nAPI.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 7, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/f53624756a39dfb4e4491e7d0d27492414c9951d', 'message': 'DB sync for Strategies\n\nIn this changeset, I added the ability to synchronize the strategies\ninto the Wather DB so that it can later be served through the Watcher\nAPI.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 8, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b6bde86df8746a297fd6a15a14704e5c2eae2699', 'message': 'DB sync for Strategies\n\nIn this changeset, I added the ability to synchronize the strategies\ninto the Wather DB so that it can later be served through the Watcher\nAPI.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 9, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/bd2c5ae41e2bbef67187fea08d9fbe073ba09714', 'message': 'DB sync for Strategies\n\nIn this changeset, I added the ability to synchronize the strategies\ninto the Wather DB so that it can later be served through the Watcher\nAPI.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}, {'number': 10, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/decision_engine/sync.py', 'watcher/tests/decision_engine/test_sync.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/a3ac26870a60ea69f90017592823677de5965ff7', 'message': 'DB sync for Strategies\n\nIn this changeset, I added the ability to synchronize the strategies\ninto the Wather DB so that it can later be served through the Watcher\nAPI.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5\n'}]",6,298808,a3ac26870a60ea69f90017592823677de5965ff7,48,7,10,18971,,,0,"DB sync for Strategies

In this changeset, I added the ability to synchronize the strategies
into the Wather DB so that it can later be served through the Watcher
API.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: Ifeaa1f6e1f4ff7d7efc1b221cf57797a49dc5bc5
",git fetch https://review.opendev.org/openstack/watcher refs/changes/08/298808/9 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/decision_engine/fake_strategies.py', 'watcher/objects/__init__.py', 'watcher/tests/decision_engine/strategy/test_registry.py', 'watcher/tests/db/utils.py', 'watcher/decision_engine/strategy/registry.py', 'watcher/tests/decision_engine/goal/test_registry.py', 'watcher/objects/strategy.py', 'watcher/tests/api/base.py']",8,aa10334d78f87aab3fddb7905613df26417d38f9,bp/get-goal-from-strategy,from watcher.decision_engine.goal import registry as goal_registry from watcher.decision_engine.strategy import registry as strategy_registry goal_registry.register_goals() strategy_registry.register_strategies(),from watcher.decision_engine.goal import registry registry.register_goals(),429,77
openstack%2Fwatcher~master~I438a8788844fbc514edfe1e9e3136f46ba5a82f2,openstack/watcher,master,I438a8788844fbc514edfe1e9e3136f46ba5a82f2,Added Strategy model,MERGED,2016-03-29 15:07:42.000000000,2016-05-11 15:30:46.000000000,2016-05-11 15:30:46.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-03-29 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/112418419848161e684eaebb0895fa3d2e3c1778', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 2, 'created': '2016-03-29 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/746f86dcf68197bb1c0032a0fcab4c0a60b4e2ab', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 3, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/27a54f4ba60f09234125aa049a1e563fe4e2b23c', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 4, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8efc9dccaf84e4c1b4c9920c09fcc64d768c9c0b', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 5, 'created': '2016-04-14 16:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5d1aded2bb01cb6fb12062eb908a2fa758c1503b', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 6, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6a0ae9b57b5937f66d2b8327dedfd4a35546062e', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 7, 'created': '2016-04-20 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/904aa8e693f6e572823277f355c4d2ce76db9172', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 8, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/ba0e6ee02d6b3b6e257b5045d4d12d22de2a0809', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 9, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8af1bb4179284cffd8694cc90c3cad4248cd6084', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}, {'number': 10, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/objects/__init__.py', 'watcher/tests/db/test_strategy.py', 'watcher/objects/base.py', 'watcher/tests/db/utils.py', 'watcher/tests/decision_engine/audit/test_default_audit_handler.py', 'watcher/db/sqlalchemy/models.py', 'watcher/objects/strategy.py', 'watcher/common/exception.py', 'watcher/db/sqlalchemy/api.py', 'watcher/db/api.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/192d8e262c710e5eb7d9613dc503744b9623e7de', 'message': 'Added Strategy model\n\nIn this changeset, I add the Strategy model as well as the DB\nfunctionalities we need to manipulate strategies.\n\nThis changeset implies a DB schema update.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2\n'}]",56,298807,192d8e262c710e5eb7d9613dc503744b9623e7de,57,9,10,18971,,,0,"Added Strategy model

In this changeset, I add the Strategy model as well as the DB
functionalities we need to manipulate strategies.

This changeset implies a DB schema update.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I438a8788844fbc514edfe1e9e3136f46ba5a82f2
",git fetch https://review.opendev.org/openstack/watcher refs/changes/07/298807/3 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/db/test_strategy.py', 'watcher/tests/db/utils.py', 'watcher/db/sqlalchemy/models.py', 'watcher/common/exception.py', 'watcher/db/sqlalchemy/api.py', 'watcher/db/api.py']",6,112418419848161e684eaebb0895fa3d2e3c1778,bp/get-goal-from-strategy," def get_strategy_list(self, context, filters=None, limit=None, marker=None, sort_key=None, sort_dir=None): """"""Get specific columns for matching strategies. Return a list of the specified columns for all goals that match the specified filters. :param context: The security context :param columns: List of column names to return. Defaults to 'id' column when columns == None. :param filters: Filters to apply. Defaults to None. :param limit: Maximum number of goals to return. :param marker: the last item of the previous page; we return the next result set. :param sort_key: Attribute by which results should be sorted. :param sort_dir: direction in which results should be sorted. (asc, desc) :returns: A list of tuples of the specified columns. """""" @abc.abstractmethod def create_strategy(self, values): """"""Create a new strategy. :param values: A dict containing several items used to identify and track the strategy. For example: :: { 'id': 'STRATEGY_ID', 'display_name': 'My strategy', 'goal': 'DUMMY', } :returns: A strategy :raises: :py:class:`~.StrategyAlreadyExists` """""" @abc.abstractmethod def get_strategy_by_id(self, context, strategy_id): """"""Return a strategy given its ID. :param context: The security context :param strategy_id: The ID of a strategy :returns: A strategy :raises: :py:class:`~.StrategyNotFound` """""" @abc.abstractmethod def destroy_strategy(self, strategy_id): """"""Destroy a strategy. :param strategy_id: The ID of a strategy :raises: :py:class:`~.StrategyNotFound` """""" @abc.abstractmethod def update_strategy(self, strategy_id, values): """"""Update properties of a strategy. :param strategy_id: The ID of a strategy :returns: A goal :raises: :py:class:`~.StrategyNotFound` :raises: :py:class:`~.Invalid` """""" @abc.abstractmethod",,512,1
openstack%2Fwatcher~master~Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3,openstack/watcher,master,Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3,Added Goal object + goal syncing,MERGED,2016-03-23 17:45:09.000000000,2016-05-11 15:29:21.000000000,2016-05-11 15:29:21.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-03-23 17:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b61aa9da5699ad73cdd7a465edd197f50bd22cef', 'message': 'Added Goal object\n\nIn this changeset, I added the Goal object into Watcher along with\na registry module that is responsible for populating the Watcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 2, 'created': '2016-03-24 13:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/658c21cd22f3e1221e740fbb54d4cd25b7c11300', 'message': 'Added Goal object\n\nIn this changeset, I added the Goal object into Watcher along with\na registry module that is responsible for populating the Watcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 3, 'created': '2016-03-24 17:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8890d9f76d2b6d2020a2766173fd41f9c89733c2', 'message': 'Added Goal object\n\nIn this changeset, I added the Goal object into Watcher along with\na registry module that is responsible for populating the Watcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 4, 'created': '2016-03-29 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0f54d5a048a91d14b3ba7fc653b45ab1fbb52abd', 'message': 'Added Goal object + goal registration\n\nIn this changeset, I added the Goal object into Watcher along with\na registry module that is responsible for populating the Watcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 5, 'created': '2016-03-29 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1b9a6a7aa5fc7a58999375e2637ffb84e405ce60', 'message': 'Added Goal object + goal registration\n\nIn this changeset, I added the Goal object into Watcher along with\na registry module that is responsible for populating the Watcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 6, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4e08fbc091b87963b2877b599ac2ad4b956c5293', 'message': 'Added Goal object + goal registration\n\nIn this changeset, I added the Goal object into Watcher along with\na registry module that is responsible for populating the Watcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 7, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/a21c29b8ba0defef6a46d596c5206fbf08421331', 'message': 'Added Goal object + goal syncing\n\nIn this changeset, I added the Goal object into Watcher along with\na sync module that is responsible for syncing the goals with the\nWatcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 8, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/e16a668beae60d8c7d2051b46e202f50095d114c', 'message': 'Added Goal object + goal syncing\n\nIn this changeset, I added the Goal object into Watcher along with\na sync module that is responsible for syncing the goals with the\nWatcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 9, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/83de524adbe7606e21c5a3f4ad1661d7a5a2ebab', 'message': 'Added Goal object + goal syncing\n\nIn this changeset, I added the Goal object into Watcher along with\na sync module that is responsible for syncing the goals with the\nWatcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 10, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/34701be34055779ee1323461d5e065b5ebf1d822', 'message': 'Added Goal object + goal syncing\n\nIn this changeset, I added the Goal object into Watcher along with\na sync module that is responsible for syncing the goals with the\nWatcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}, {'number': 11, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/objects/__init__.py', 'watcher/objects/goal.py', 'watcher/tests/objects/test_goal.py', 'watcher/decision_engine/sync.py', 'watcher/tests/decision_engine/test_sync.py', 'watcher/decision_engine/strategy/strategies/__init__.py', 'watcher/tests/db/test_goal.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/3b5ef15db6acdba705843e6ec2fcde74659cf238', 'message': 'Added Goal object + goal syncing\n\nIn this changeset, I added the Goal object into Watcher along with\na sync module that is responsible for syncing the goals with the\nWatcher DB.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3\n'}]",49,296634,3b5ef15db6acdba705843e6ec2fcde74659cf238,55,6,11,18971,,,0,"Added Goal object + goal syncing

In this changeset, I added the Goal object into Watcher along with
a sync module that is responsible for syncing the goals with the
Watcher DB.

Partially Implements: blueprint get-goal-from-strategy

Change-Id: Ia3a2032dd9023d668c6f32ebbce44f8c1d77b0a3
",git fetch https://review.opendev.org/openstack/watcher refs/changes/34/296634/11 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/objects/__init__.py', 'watcher/objects/goal.py', 'watcher/decision_engine/goal/registry.py', 'watcher/decision_engine/goal/__init__.py', 'watcher/decision_engine/strategy/strategies/__init__.py']",5,b61aa9da5699ad73cdd7a465edd197f50bd22cef,bp/get-goal-from-strategy,"AVAILABLE_STRATEGIES = [BasicConsolidation, OutletTempControl, DummyStrategy] __all__ = ( ['AVAILABLE_STRATEGIES'] + [strategy_cls.__name__ for strategy_cls in AVAILABLE_STRATEGIES])"," __all__ = (BasicConsolidation, OutletTempControl, DummyStrategy)",247,2
openstack%2Fwatcher~master~I5b5b0ffc7cff8affb59f17743e1af0e1277c2878,openstack/watcher,master,I5b5b0ffc7cff8affb59f17743e1af0e1277c2878,Added Goal model into Watcher DB,MERGED,2016-03-23 17:45:09.000000000,2016-05-11 15:28:28.000000000,2016-05-11 15:28:28.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 19214}, {'_account_id': 20676}]","[{'number': 1, 'created': '2016-03-23 17:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/677dcc08184dfcddd563df91e7423b5d75b02367', 'message': 'Added Goal and Strategy into Watcher DB\n\nIn this changeset, I added both the Goal and the Watcher DB model\ninto Watcher.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 2, 'created': '2016-03-24 13:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/73c9eccac64909a4d551e96de02f7e85df103b70', 'message': 'Added Goal and Strategy into Watcher DB\n\nIn this changeset, I added both the Goal and the Watcher DB model\ninto Watcher.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 3, 'created': '2016-03-24 17:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/712326ff4dfc41ad6e3973d21352610a04aacd43', 'message': 'Added Goal and Strategy into Watcher DB\n\nIn this changeset, I added both the Goal and the Watcher DB model\ninto Watcher.\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 4, 'created': '2016-03-29 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8ff15194fbc4645c699c0ed87410972a00448490', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 5, 'created': '2016-03-29 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/741ec0fd5e46ccdfcc60477bf6ef42c6391d55ea', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 6, 'created': '2016-03-30 17:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/1f02cd5ef467ff50fe1149d3f068d0759a53bb2f', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 7, 'created': '2016-04-12 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/21cdd65d52d9c8b501040ee07aad254a09855a60', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 8, 'created': '2016-04-18 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5b8bd5daa65c396b7e58006cf8610b7bbb3d7448', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 9, 'created': '2016-04-21 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/41590769b903959ea42d095a8cfa090210630bcd', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 10, 'created': '2016-05-02 08:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/cc1d47338e6b2f77b008378e3a944ded31896067', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}, {'number': 11, 'created': '2016-05-11 13:36:20.000000000', 'files': ['watcher/tests/db/utils.py', 'watcher/db/sqlalchemy/models.py', 'watcher/common/exception.py', 'watcher/db/sqlalchemy/api.py', 'watcher/tests/db/test_goal.py', 'watcher/db/api.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/be9058f3e32b89076a8c41d964e8df483a0ce52e', 'message': 'Added Goal model into Watcher DB\n\nIn this changeset, I added the Goal model into Watcher.\nThis implies a change into the Watcher DB schema\n\nPartially Implements: blueprint get-goal-from-strategy\n\nChange-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878\n'}]",64,296633,be9058f3e32b89076a8c41d964e8df483a0ce52e,61,8,11,18971,,,0,"Added Goal model into Watcher DB

In this changeset, I added the Goal model into Watcher.
This implies a change into the Watcher DB schema

Partially Implements: blueprint get-goal-from-strategy

Change-Id: I5b5b0ffc7cff8affb59f17743e1af0e1277c2878
",git fetch https://review.opendev.org/openstack/watcher refs/changes/33/296633/10 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/db/sqlalchemy/models.py', 'watcher/common/exception.py', 'watcher/db/sqlalchemy/api.py', 'watcher/db/api.py']",4,677dcc08184dfcddd563df91e7423b5d75b02367,bp/get-goal-from-strategy," def get_goal_list(self, context, filters=None, limit=None, marker=None, sort_key=None, sort_dir=None): """"""Get specific columns for matching goals. Return a list of the specified columns for all goals that match the specified filters. :param context: The security context :param columns: List of column names to return. Defaults to 'id' column when columns == None. :param filters: Filters to apply. Defaults to None. :param limit: Maximum number of goals to return. :param marker: the last item of the previous page; we return the next result set. :param sort_key: Attribute by which results should be sorted. :param sort_dir: direction in which results should be sorted. (asc, desc) :returns: A list of tuples of the specified columns. """""" @abc.abstractmethod def create_goal(self, values): """"""Create a new goal. :param values: A dict containing several items used to identify and track the goal. For example: :: { 'uuid': utils.generate_uuid(), 'name': 'example', 'description': 'free text description' 'host_aggregate': 'nova aggregate name or id' 'goal': 'DUMMY' 'extra': {'automatic': True} } :returns: A goal. :raises: :py:class:`~.GoalAlreadyExists` """""" @abc.abstractmethod def get_goal_by_id(self, context, goal_id): """"""Return an goal. :param context: The security context :param goal_id: The id of an goal. :returns: A goal. :raises: :py:class:`~.GoalNotFound` """""" @abc.abstractmethod def destroy_goal(self, goal_id): """"""Destroy an goal. :param goal_id: The id or uuid of an goal. :raises: :py:class:`~.GoalNotFound` """""" @abc.abstractmethod def update_goal(self, goal_id, values): """"""Update properties of a goal. :param audit_template_id: The id or uuid of a goal. :returns: A goal. :raises: :py:class:`~.GoalNotFound` :raises: :py:class:`~.Invalid` """""" @abc.abstractmethod :raises: :py:class:`~.AuditTemplateAlreadyExists` :raises: :py:class:`~.AuditTemplateNotFound` :raises: :py:class:`~.AuditTemplateNotFound` :raises: :py:class:`~.AuditTemplateNotFound` :raises: :py:class:`~.AuditTemplateNotFound` :raises: :py:class:`~.AuditTemplateNotFound` :raises: :py:class:`~.Invalid` :raises: :py:class:`~.AuditTemplateNotFound` :raises: :py:class:`~.AuditAlreadyExists` :raises: :py:class:`~.AuditNotFound` :raises: :py:class:`~.AuditNotFound` :raises: :py:class:`~.AuditNotFound` :raises: :py:class:`~.AuditNotFound` :raises: :py:class:`~.Invalid` :raises: :py:class:`~.AuditNotFound` :raises: :py:class:`~.ActionAlreadyExists` :raises: :py:class:`~.ActionNotFound` :raises: :py:class:`~.ActionNotFound` :raises: :py:class:`~.ActionNotFound` :raises: :py:class:`~.ActionReferenced` :raises: :py:class:`~.ActionNotFound` :raises: :py:class:`~.ActionReferenced` :raises: :py:class:`~.Invalid` :raises: :py:class:`~.ActionPlanAlreadyExists` :raises: :py:class:`~.ActionPlanNotFound` :raises: :py:class:`~.ActionPlanNotFound` :raises: :py:class:`~.ActionPlanNotFound` :raises: :py:class:`~.ActionPlanReferenced` :raises: :py:class:`~.ActionPlanNotFound` :raises: :py:class:`~.ActionPlanReferenced` :raises: :py:class:`~.Invalid`", :raises: AuditTemplateAlreadyExists :raises: AuditTemplateNotFound :raises: AuditTemplateNotFound :raises: AuditTemplateNotFound :raises: AuditTemplateNotFound :raises: AuditTemplateNotFound :raises: Invalid :raises: AuditTemplateNotFound :raises: AuditAlreadyExists :raises: AuditNotFound :raises: AuditNotFound :raises: AuditNotFound :raises: AuditNotFound :raises: Invalid :raises: AuditNotFound :raises: ActionAlreadyExists :raises: ActionNotFound :raises: ActionNotFound :raises: ActionNotFound :raises: ActionReferenced :raises: ActionNotFound :raises: ActionReferenced :raises: Invalid :raises: ActionPlanAlreadyExists :raises: ActionPlanNotFound :raises: ActionPlanNotFound :raises: ActionPlanNotFound :raises: ActionPlanReferenced :raises: ActionPlanNotFound :raises: ActionPlanReferenced :raises: Invalid,234,34
openstack%2Fopenstack-ansible~kilo~I6af714907fa7ffbe3938006140a0e860d2e35b2b,openstack/openstack-ansible,kilo,I6af714907fa7ffbe3938006140a0e860d2e35b2b,Fix rsyslog configuration tag for juno-container-cleanup.sh,MERGED,2016-05-09 18:51:16.000000000,2016-05-11 15:26:56.000000000,2016-05-11 15:26:56.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-09 18:51:16.000000000', 'files': ['doc/source/upgrade-guide/process.rst', 'scripts/run-upgrade.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dfb1944d3963e6e6c205f931470edc859c781169', 'message': 'Fix rsyslog configuration tag for juno-container-cleanup.sh\n\nThis fix will use the correct tag for lxc-hosts-setup.yml\nplaybook inside the juno-container-cleanup.sh script.\nAdditionally the documentation is corrected to.\n\nRelated-To: https://review.openstack.org/#/c/313117/\n\nChange-Id: I6af714907fa7ffbe3938006140a0e860d2e35b2b\nCloses-Bug: #1578777\n'}]",0,314232,dfb1944d3963e6e6c205f931470edc859c781169,9,3,1,14552,,,0,"Fix rsyslog configuration tag for juno-container-cleanup.sh

This fix will use the correct tag for lxc-hosts-setup.yml
playbook inside the juno-container-cleanup.sh script.
Additionally the documentation is corrected to.

Related-To: https://review.openstack.org/#/c/313117/

Change-Id: I6af714907fa7ffbe3938006140a0e860d2e35b2b
Closes-Bug: #1578777
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/32/314232/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/upgrade-guide/process.rst', 'scripts/run-upgrade.sh']",2,dfb1944d3963e6e6c205f931470edc859c781169,bug/1578777," RUN_TASKS+=(""lxc-hosts-setup.yml --tags rsyslog-client"")"," RUN_TASKS+=(""lxc-hosts-setup.yml --tags rsyslog-config"")",2,2
openstack%2Fkuryr~master~I5076fb8a2b56262bfce52c232ef7543ea0ea5436,openstack/kuryr,master,I5076fb8a2b56262bfce52c232ef7543ea0ea5436,Improve documentation,MERGED,2016-05-10 16:56:35.000000000,2016-05-11 15:20:38.000000000,2016-05-11 15:20:38.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 7505}, {'_account_id': 8279}, {'_account_id': 8580}, {'_account_id': 9820}, {'_account_id': 10068}, {'_account_id': 11208}, {'_account_id': 14352}]","[{'number': 1, 'created': '2016-05-10 16:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/11efce3595747eec83c8fbf4982170ae03b2c7ac', 'message': 'Add keystone config\n\nAdded keystone config in kuryr.conf and a quick cli test\n\nChange-Id: I5076fb8a2b56262bfce52c232ef7543ea0ea5436\nSigned-off-by: Fernando Moreno <fernando@midokura.com>\n'}, {'number': 2, 'created': '2016-05-10 17:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/db646e2c6855757e1315a4ff4c79e49eea366aba', 'message': 'Add keystone config\n\nAdded keystone config in kuryr.conf and a quick cli test\n\nChange-Id: I5076fb8a2b56262bfce52c232ef7543ea0ea5436\nSigned-off-by: Fernando Moreno <fernando@midokura.com>\n'}, {'number': 3, 'created': '2016-05-11 08:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/7d48fd97f92f0c06e19455a26f65ed2dadcc93ce', 'message': 'Improve documenation\n\n- Added keystone config in kuryr.conf\n- Uncommented bindir parameter in kuryr.conf\n- Added a quick cli test in the testing section\n\nChange-Id: I5076fb8a2b56262bfce52c232ef7543ea0ea5436\nSigned-off-by: Fernando Moreno <fernando@midokura.com>\n'}, {'number': 4, 'created': '2016-05-11 08:33:48.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/370488315f08fe3b9e8be4fe0b866a6c587eca6b', 'message': 'Improve documentation\n\n- Added keystone config in kuryr.conf\n- Uncommented bindir parameter in kuryr.conf\n- Added a quick cli test in the testing section\n\nChange-Id: I5076fb8a2b56262bfce52c232ef7543ea0ea5436\nSigned-off-by: Fernando Moreno <fernando@midokura.com>\n'}]",2,314676,370488315f08fe3b9e8be4fe0b866a6c587eca6b,20,9,4,21793,,,0,"Improve documentation

- Added keystone config in kuryr.conf
- Uncommented bindir parameter in kuryr.conf
- Added a quick cli test in the testing section

Change-Id: I5076fb8a2b56262bfce52c232ef7543ea0ea5436
Signed-off-by: Fernando Moreno <fernando@midokura.com>
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/76/314676/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,11efce3595747eec83c8fbf4982170ae03b2c7ac,," Configuring Kuryr ----------------- Edit keystone section in `/etc/kuryr/kuryr.conf`, replace ADMIN_PASSWORD: :: auth_uri = http://127.0.0.1:35357/v2.0 admin_user = admin admin_tenant_name = service admin_password = ADMIN_PASSWORD In the same file uncomment the `bindir` parameter with the path for the Kuryr vif binding executables: :: bindir = /usr/local/libexec/kuryr Currently, Kuryr utilizes a bash script to start the service. Make sure thatFor a quick check that Kuryr is working create a network: :: $ docker network create --driver kuryr test_net 785f8c1b5ae480c4ebcb54c1c48ab875754e4680d915b270279e4f6a1aa52283 $ docker network ls NETWORK ID NAME DRIVER 785f8c1b5ae4 test_net kuryr To test it with tox: ","Currently, Kuryr utilizes a bash script to start the service. Make sure that ",32,1
openstack%2Ftripleo-ui~master~I360911fc2bf1acc168be32a61182872c2b5ff573,openstack/tripleo-ui,master,I360911fc2bf1acc168be32a61182872c2b5ff573,Add hints to run validations,MERGED,2016-05-04 12:23:01.000000000,2016-05-11 15:13:39.000000000,2016-05-11 15:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 7509}, {'_account_id': 10112}, {'_account_id': 17888}]","[{'number': 1, 'created': '2016-05-04 12:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/ddc7d0650d93b70ebe0d67bc9334316550dc60bb', 'message': 'Add hints to run validations\n\nChange-Id: I360911fc2bf1acc168be32a61182872c2b5ff573\n'}, {'number': 2, 'created': '2016-05-04 14:20:39.000000000', 'files': ['src/js/components/validations/ValidationsList.js', 'src/js/components/AuthenticatedContent.js', 'src/__tests__/reducers/validationsReducer.tests.js', 'src/js/selectors/validations.js', 'src/__tests__/components/deployment_plan/deploymentPlan.tests.js', 'src/js/actions/ValidationsActions.js', 'src/__tests__/selectors/validations.tests.js', 'src/js/constants/ValidationsConstants.js', 'src/js/immutableRecords/validations.js', 'src/js/components/validations/ValidationStage.js', 'src/js/components/deployment_plan/DeploymentPlan.js', 'src/js/reducers/validationsReducer.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/3a2086628bdc8139df6e60ad6cfe27163a11c7c8', 'message': 'Add hints to run validations\n\nChange-Id: I360911fc2bf1acc168be32a61182872c2b5ff573\n'}]",1,312476,3a2086628bdc8139df6e60ad6cfe27163a11c7c8,11,4,2,20970,,,0,"Add hints to run validations

Change-Id: I360911fc2bf1acc168be32a61182872c2b5ff573
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/76/312476/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/js/components/validations/ValidationsList.js', 'src/js/components/AuthenticatedContent.js', 'src/__tests__/reducers/validationsReducer.tests.js', 'src/js/selectors/validations.js', 'src/__tests__/components/deployment_plan/deploymentPlan.tests.js', 'src/js/actions/ValidationsActions.js', 'src/__tests__/selectors/validations.tests.js', 'src/js/constants/ValidationsConstants.js', 'src/js/immutableRecords/validations.js', 'src/js/components/validations/ValidationStage.js', 'src/js/components/deployment_plan/DeploymentPlan.js', 'src/js/reducers/validationsReducer.js']",12,ddc7d0650d93b70ebe0d67bc9334316550dc60bb,add-validation-hints,"import { fromJS, Map, List } from 'immutable'; const validations = fromJS(action.payload.entities.validations) || Map(); const validationStages = fromJS(action.payload.entities.validationStages) || Map(); const validationResults = fromJS(action.payload.entities.validationResults) || Map(); return state.set('validationStages', validationStages .map(stage => new ValidationStage(stage.set('visible', state.getIn(['validationStages', stage.uuid, 'visible'], false))))) .set('validations', validations .map(validation => new Validation(validation))) .set('validationResults', validationResults .map(result => new ValidationResult(result))) let validationIds = state.getIn( ['validationStages', action.payload.uuid, 'validations'], List([])); let validations = state.get('validations'); let updatedValidations = validationIds.reduce((r, validationId) => { return r.setIn([validationId, 'status'], action.payload.status); }, validations); return state.setIn( ['validationStages', action.payload.uuid, 'status'], action.payload.status).set('validations', updatedValidations); case ValidationsConstants.TOGGLE_VALIDATION_STAGE_VISIBILITY: { return state.updateIn(['validationStages', action.payload.uuid, 'visible'], (oldValue) => !oldValue); } case ValidationsConstants.SHOW_VALIDATION_STAGE: { return state.setIn(['validationStages', action.payload.uuid, 'visible'], true); } ","import { fromJS, Map } from 'immutable'; const { validationStages, validations, validationResults } = action.payload.entities; return state.set('validationStages', validationStages ? fromJS(validationStages) .map(stage => new ValidationStage(stage)) : Map()) .set('validations', validations ? fromJS(validations) .map(validation => new Validation(validation)) : Map()) .set('validationResults', validationResults ? fromJS(validationResults) .map(result => new ValidationResult(result)) : Map()) return state.setIn(['validationStages', action.payload.uuid, 'status'], action.payload.status);",142,27
openstack%2Ffuel-nailgun-agent~stable%2Fmitaka~I0c6f3720943ad21e22899368832e451bc906b098,openstack/fuel-nailgun-agent,stable/mitaka,I0c6f3720943ad21e22899368832e451bc906b098,Do restart mcollective after provisioning,MERGED,2016-05-10 18:22:29.000000000,2016-05-11 15:13:14.000000000,2016-05-11 15:11:40.000000000,"[{'_account_id': 3}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 9448}, {'_account_id': 12559}, {'_account_id': 12661}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-10 18:22:29.000000000', 'files': ['agent'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-agent/commit/8b0ef4e707e6afaae1863978d8b5dc94eb6315be', 'message': ""Do restart mcollective after provisioning\n\nnailgun agent must not change mcollective config after provisioning\ncloudinit is responsible for that.\n\nIt may happen that nailgun agent may be started by cron earlier than\nit is reconfigured and started by cloudinit. This leads to the\nsituation when cloudinit reconfigures mcollective and issues start\nwhich doesn't do anything since it is already started by nailgun agent.\nFinally, mcollective is left started with incorrect default\nconfiguration.\n\nChange-Id: I0c6f3720943ad21e22899368832e451bc906b098\nCloses-Bug: #1455489\n(cherry picked from commit 50bcd8448ecab85194b4559569ebc8568191e481)\n""}]",0,314711,8b0ef4e707e6afaae1863978d8b5dc94eb6315be,18,7,1,21013,,,0,"Do restart mcollective after provisioning

nailgun agent must not change mcollective config after provisioning
cloudinit is responsible for that.

It may happen that nailgun agent may be started by cron earlier than
it is reconfigured and started by cloudinit. This leads to the
situation when cloudinit reconfigures mcollective and issues start
which doesn't do anything since it is already started by nailgun agent.
Finally, mcollective is left started with incorrect default
configuration.

Change-Id: I0c6f3720943ad21e22899368832e451bc906b098
Closes-Bug: #1455489
(cherry picked from commit 50bcd8448ecab85194b4559569ebc8568191e481)
",git fetch https://review.opendev.org/openstack/fuel-nailgun-agent refs/changes/11/314711/1 && git format-patch -1 --stdout FETCH_HEAD,['agent'],1,8b0ef4e707e6afaae1863978d8b5dc94eb6315be,bug/1455489,require 'socket'def provisioned? Socket.gethostname != 'bootstrap' end unless provisioned? mc_config.replace_identity(new_id) end, mc_config.replace_identity(new_id),8,1
openstack%2Fcongress~stable%2Fliberty~Icf27e9eb3e929773dd7f766f174f233e6eb1ab4f,openstack/congress,stable/liberty,Icf27e9eb3e929773dd7f766f174f233e6eb1ab4f,Fix gate failure,MERGED,2016-05-11 06:02:54.000000000,2016-05-11 15:07:07.000000000,2016-05-11 15:07:07.000000000,"[{'_account_id': 3}, {'_account_id': 8878}]","[{'number': 1, 'created': '2016-05-11 06:02:54.000000000', 'files': ['contrib/tempest/tempest/scenario/manager_congress.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/f809fefe53386bf8da7887d44a1e24bdf937443f', 'message': 'Fix gate failure\n\nChange-Id: Icf27e9eb3e929773dd7f766f174f233e6eb1ab4f\n'}]",0,314873,f809fefe53386bf8da7887d44a1e24bdf937443f,6,2,1,11278,,,0,"Fix gate failure

Change-Id: Icf27e9eb3e929773dd7f766f174f233e6eb1ab4f
",git fetch https://review.opendev.org/openstack/congress refs/changes/73/314873/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/manager_congress.py'],1,f809fefe53386bf8da7887d44a1e24bdf937443f,liberty,"from tempest.scenario import network_resources new_port = network_resources.DeletablePort(client=self.network_client, **self.new_port_list[0])","from tempest.services.network import resources as net_resources new_port = net_resources.DeletablePort(client=self.network_client, **self.new_port_list[0])",3,3
openstack%2Fproject-config~master~Ia98bb5bad52c592ecc595b2eb4d8ad4fe9caf942,openstack/project-config,master,Ia98bb5bad52c592ecc595b2eb4d8ad4fe9caf942,Add api-ref jobs for Heat,MERGED,2016-05-04 20:30:00.000000000,2016-05-11 15:06:55.000000000,2016-05-11 15:06:55.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7385}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-04 20:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9c51cc7a5cd5bf54dd2ebb6f399e638aa6ded758', 'message': 'Add api-ref jobs for Heat\n\nChange-Id: Ia98bb5bad52c592ecc595b2eb4d8ad4fe9caf942\nDepends-On: I6f578107e17d3a97e667f645a05493da12ae2048\n'}, {'number': 2, 'created': '2016-05-05 14:17:16.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d88d23c931b4167246c86208e633145b15e8390d', 'message': 'Add api-ref jobs for Heat\n\nChange-Id: Ia98bb5bad52c592ecc595b2eb4d8ad4fe9caf942\nDepends-On: I6f578107e17d3a97e667f645a05493da12ae2048\n'}]",0,312726,d88d23c931b4167246c86208e633145b15e8390d,15,6,2,8399,,,0,"Add api-ref jobs for Heat

Change-Id: Ia98bb5bad52c592ecc595b2eb4d8ad4fe9caf942
Depends-On: I6f578107e17d3a97e667f645a05493da12ae2048
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/312726/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,9c51cc7a5cd5bf54dd2ebb6f399e638aa6ded758,heat-api-ref, - gate-heat-api-ref - gate-heat-api-ref - heat-api-ref,,5,0
openstack%2Fneutron~master~If40a44348e305da444acd6196d2e0c04202b8f7a,openstack/neutron,master,If40a44348e305da444acd6196d2e0c04202b8f7a,Add API to retrieve default quotas,MERGED,2016-04-15 01:04:01.000000000,2016-05-11 15:04:44.000000000,2016-05-11 15:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7018}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11975}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15752}, {'_account_id': 17130}, {'_account_id': 19896}, {'_account_id': 20079}]","[{'number': 1, 'created': '2016-04-15 01:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/327f4442d1ca2b22d0286d4c71aeb2cb18f4f51d', 'message': ""Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/default\nHere the reserved string 'default' is passed as a tenant-id, which\nwill retrieve default quotas.\nSince the defaults are shared by all tenants, there is no need to\nhandle tenant specific defaults.\nThis is a non-admin, read-only API.\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n""}, {'number': 2, 'created': '2016-04-15 20:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/536ef1c988a7cdb8b8697b77bb3d5f913766d6a1', 'message': ""Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/default\nHere the reserved string 'default' is passed as a tenant-id, which\nwill retrieve default quotas.\nSince the defaults are shared by all tenants, there is no need to\nhandle tenant specific defaults.\nThis is a non-admin, read-only API.\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n""}, {'number': 3, 'created': '2016-04-21 02:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a1e8476a9f093e27d0c371aeb3950a281cc775d', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}, {'number': 4, 'created': '2016-04-21 17:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e09165e9fe0e7a016e48f46d49eadf59a3f7875c', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}, {'number': 5, 'created': '2016-04-26 19:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f057e68694200966f28f6bc79a725a42a54b830f', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}, {'number': 6, 'created': '2016-04-27 03:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c2a7922a1a260f20592015f72d9e6c0a2a35221', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}, {'number': 7, 'created': '2016-05-03 18:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ee5967509872cd79ff4a2c3bda6e22283edf0bc', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}, {'number': 8, 'created': '2016-05-04 22:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb49710ba459f618d0498442715f6bcede1e6cfb', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}, {'number': 9, 'created': '2016-05-04 22:47:00.000000000', 'files': ['neutron/extensions/quotasv2.py', 'neutron/tests/unit/extensions/test_quotasv2.py', 'neutron/db/quota/driver.py', 'neutron/tests/unit/db/quota/test_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5a2ee300d109ac9d403ee1f39d6e056ac925133', 'message': 'Add API to retrieve default quotas\n\nCurrently there is no support to retrieve default quotas set\nfor all projects. This patch adds a new API function to get\ndefault quotas.\nGET /v2.0/quotas/<tenant-id>/default\n\nDocImpact: Document new API to used to retrieve default quotas\nAPIImpact: New Read-only API to retrieve default quotas\n\nChange-Id: If40a44348e305da444acd6196d2e0c04202b8f7a\nCloses-Bug: #1204956\n'}]",6,306200,f5a2ee300d109ac9d403ee1f39d6e056ac925133,112,25,9,7018,,,0,"Add API to retrieve default quotas

Currently there is no support to retrieve default quotas set
for all projects. This patch adds a new API function to get
default quotas.
GET /v2.0/quotas/<tenant-id>/default

DocImpact: Document new API to used to retrieve default quotas
APIImpact: New Read-only API to retrieve default quotas

Change-Id: If40a44348e305da444acd6196d2e0c04202b8f7a
Closes-Bug: #1204956
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/306200/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/quotasv2.py', 'neutron/db/quota/driver.py']",2,327f4442d1ca2b22d0286d4c71aeb2cb18f4f51d,bug/1204956," def get_default_quotas(context, resources): """"""Given a list of resources, retrieve the default quotas set for all tenants. :param context: The request context, for access checks. :param resources: A dictionary of the registered resource keys. :return dict: from resource name to dict of name and limit """""" return dict((key, resource.default) for key, resource in resources.items()) @staticmethod",,20,1
openstack%2Fwatcher~master~I668edd85e3ea40c2a309caacbf68cf35bfd680f7,openstack/watcher,master,I668edd85e3ea40c2a309caacbf68cf35bfd680f7,Fix documentation watcher sql database,MERGED,2016-05-11 13:58:55.000000000,2016-05-11 14:57:27.000000000,2016-05-11 14:57:27.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-05-11 13:58:55.000000000', 'files': ['doc/source/dev/environment.rst'], 'web_link': 'https://opendev.org/openstack/watcher/commit/43f5ab18ba0d2c005e7be44a1d764bc93961c925', 'message': 'Fix documentation watcher sql database\n\nThis changeset fixes the issue with the parameter watcher-db-manage\n\nChange-Id: I668edd85e3ea40c2a309caacbf68cf35bfd680f7\nCloses-Bug: #1580617\n'}]",0,315060,43f5ab18ba0d2c005e7be44a1d764bc93961c925,7,3,1,16495,,,0,"Fix documentation watcher sql database

This changeset fixes the issue with the parameter watcher-db-manage

Change-Id: I668edd85e3ea40c2a309caacbf68cf35bfd680f7
Closes-Bug: #1580617
",git fetch https://review.opendev.org/openstack/watcher refs/changes/60/315060/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/environment.rst'],1,43f5ab18ba0d2c005e7be44a1d764bc93961c925,bug/1580617, (watcher) $ watcher-db-manage create_schema, (watcher) $ watcher-db-manage --create_schema,1,1
openstack%2Fopenstack-ansible-galera_client~master~Iab5485529cf14933fd7f37430d234a5c41185c18,openstack/openstack-ansible-galera_client,master,Iab5485529cf14933fd7f37430d234a5c41185c18,Implement Xenial Support,MERGED,2016-05-10 20:40:36.000000000,2016-05-11 14:56:05.000000000,2016-05-11 14:56:05.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-10 20:40:36.000000000', 'files': ['vars/ubuntu-14.04.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/808ef635fe6c5d757781d77c9e33977a2f3e49b5', 'message': 'Implement Xenial Support\n\nGalera client currently only supports Ubuntu 14.04,\ntrusty.  This patch set is intended to support\nUbuntu 16.04, Xenial.\n\nChange-Id: Iab5485529cf14933fd7f37430d234a5c41185c18\nNeeded-By: I4baeb2eddf137619ffedba2f9efd61b7bd142f92\n'}]",0,314765,808ef635fe6c5d757781d77c9e33977a2f3e49b5,10,3,1,20038,,,0,"Implement Xenial Support

Galera client currently only supports Ubuntu 14.04,
trusty.  This patch set is intended to support
Ubuntu 16.04, Xenial.

Change-Id: Iab5485529cf14933fd7f37430d234a5c41185c18
Needed-By: I4baeb2eddf137619ffedba2f9efd61b7bd142f92
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/65/314765/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/ubuntu-14.04.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml', 'meta/main.yml']",4,808ef635fe6c5d757781d77c9e33977a2f3e49b5,implement_xenial_support, - xenial,,40,7
openstack%2Fstevedore~master~I6fe1326d2e6567539a6ad8b13c7d8a50d0459400,openstack/stevedore,master,I6fe1326d2e6567539a6ad8b13c7d8a50d0459400,Trivial: ignore openstack/common in flake8 exclude list,MERGED,2016-05-11 05:47:39.000000000,2016-05-11 14:51:56.000000000,2016-05-11 14:51:56.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-05-11 05:47:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/stevedore/commit/b106ba3fc6cfcc79740af144984863d7f6192417', 'message': ""Trivial: ignore openstack/common in flake8 exclude list\n\nThe directory openstack/common doesn't exist any more.\nso remove it from flake8 exclude list.\n\nChange-Id: I6fe1326d2e6567539a6ad8b13c7d8a50d0459400\n""}]",0,314870,b106ba3fc6cfcc79740af144984863d7f6192417,7,3,1,9796,,,0,"Trivial: ignore openstack/common in flake8 exclude list

The directory openstack/common doesn't exist any more.
so remove it from flake8 exclude list.

Change-Id: I6fe1326d2e6567539a6ad8b13c7d8a50d0459400
",git fetch https://review.opendev.org/openstack/stevedore refs/changes/70/314870/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b106ba3fc6cfcc79740af144984863d7f6192417,,"exclude=.venv,.git,.tox,dist,*lib/python*,*egg,build","exclude=.venv,.git,.tox,dist,*openstack/common*,*lib/python*,*egg,build",1,1
openstack%2Ftaskflow~master~Id6ada69df9961a6b7511316e2f75ef9ee5f0b72b,openstack/taskflow,master,Id6ada69df9961a6b7511316e2f75ef9ee5f0b72b,Always used the library packaged mock,MERGED,2016-05-10 17:48:54.000000000,2016-05-11 14:50:49.000000000,2016-05-11 14:50:49.000000000,"[{'_account_id': 3}, {'_account_id': 9648}]","[{'number': 1, 'created': '2016-05-10 17:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/501b2c7fceafdd099ce91d3abac856dae5619f12', 'message': 'Always used the library packaged mock\n\nChange-Id: Id6ada69df9961a6b7511316e2f75ef9ee5f0b72b\n'}, {'number': 2, 'created': '2016-05-10 17:50:36.000000000', 'files': ['taskflow/test.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3321b22ca81bd0e1d8923abc62db014d07fed9ce', 'message': 'Always used the library packaged mock\n\nThe library packaged mock seems to work\nbetter across python versions, so instead of\ntrying to mix the system one and the library\none always prefer the library one (which should\nwork in all supported python versions).\n\nChange-Id: Id6ada69df9961a6b7511316e2f75ef9ee5f0b72b\n'}]",0,314698,3321b22ca81bd0e1d8923abc62db014d07fed9ce,13,2,2,1297,,,0,"Always used the library packaged mock

The library packaged mock seems to work
better across python versions, so instead of
trying to mix the system one and the library
one always prefer the library one (which should
work in all supported python versions).

Change-Id: Id6ada69df9961a6b7511316e2f75ef9ee5f0b72b
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/98/314698/2 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/test.py'],1,501b2c7fceafdd099ce91d3abac856dae5619f12,,import mock,"# This is weird like this since we want to import a mock that works the best # and we need to try this import order, since oslotest registers a six.moves # module (but depending on the import order of importing oslotest we may or # may not see that change when trying to use it from six). try: from six.moves import mock except ImportError: try: # In python 3.3+ mock got included in the standard library... from unittest import mock except ImportError: import mock",1,12
openstack%2Freleases~master~Icd07ec11daecc1750b3fdb7a14cfe2dd5c09fc35,openstack/releases,master,Icd07ec11daecc1750b3fdb7a14cfe2dd5c09fc35,Propose release for oslo.service 1.10.0,MERGED,2016-05-09 21:59:58.000000000,2016-05-11 14:49:43.000000000,2016-05-11 14:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 8688}]","[{'number': 1, 'created': '2016-05-09 21:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/f9e26a7b5710e9bfa278d191931ceb8ccfd4cffb', 'message': 'Propose release for oslo.service 1.10.0\n\nChange-Id: Icd07ec11daecc1750b3fdb7a14cfe2dd5c09fc35\n'}, {'number': 2, 'created': '2016-05-09 23:11:58.000000000', 'files': ['deliverables/newton/oslo.service.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d8b51bde1af8bfd311e5edb9864447091c8c0d59', 'message': 'Propose release for oslo.service 1.10.0\n\nChange-Id: Icd07ec11daecc1750b3fdb7a14cfe2dd5c09fc35\n'}]",1,314306,d8b51bde1af8bfd311e5edb9864447091c8c0d59,11,3,2,1297,,,0,"Propose release for oslo.service 1.10.0

Change-Id: Icd07ec11daecc1750b3fdb7a14cfe2dd5c09fc35
",git fetch https://review.opendev.org/openstack/releases refs/changes/06/314306/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/oslo.service.yaml'],1,f9e26a7b5710e9bfa278d191931ceb8ccfd4cffb,314306,- version: 1.10.0 projects: - repo: openstack/oslo.service hash: b83ec523b41ed35ee954cff82d01131d701f1255 highlights: '* Offer mutate_config_files',,5,0
openstack%2Fwatcher-specs~master~I57f7e434c41fcbd6606552c186e9a0285ff26e97,openstack/watcher-specs,master,I57f7e434c41fcbd6606552c186e9a0285ff26e97,Achieved goal should be returned by each strategy,MERGED,2016-04-05 15:42:27.000000000,2016-05-11 14:48:06.000000000,2016-05-11 14:48:06.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 7664}, {'_account_id': 11235}, {'_account_id': 11750}, {'_account_id': 12394}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 19214}]","[{'number': 1, 'created': '2016-04-05 15:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/c47cc9d0834b6b0cb2a065bbf26538b72db30a7e', 'message': 'Achieved goal should be returned by each strategy\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 2, 'created': '2016-04-05 15:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/6a9b4e0859fa419a6571351cd1258bfc8f88e7f1', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 3, 'created': '2016-04-05 16:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/19b75c6ed66ff1cbc490917fd472eee7d30690fd', 'message': 'Achieved goal should be returned by each strategy\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 4, 'created': '2016-04-05 16:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/50c5e8f158141fc4529744ddb0d220b2cfd4c26b', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 5, 'created': '2016-04-05 16:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/2eab8efa46f7b5980c84dfe566590e521c944829', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 6, 'created': '2016-04-05 16:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/7228a239dae7f48a0557724cc25eab9cd27fc5a7', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 7, 'created': '2016-04-06 14:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/372473709070861191d07e043cdac5ca7ea817e9', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 8, 'created': '2016-04-06 14:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/934b43f627ac4cfdfd868b9520f172624f32029a', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 9, 'created': '2016-04-06 15:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/3f050556484168506eb5f16985942e2aab541703', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 10, 'created': '2016-04-08 09:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/0186fdceb4c62b469235634b4317bc4b1442b4ca', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 11, 'created': '2016-04-08 09:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/c69ddf8e735e25b544d702573c731082c286efd8', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 12, 'created': '2016-04-08 16:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/601762876ccbaf84806f7f697b0a809a13984a2e', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 13, 'created': '2016-04-14 13:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/6a90062ce4d5b239a9c3c53908db298e51d1c434', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 14, 'created': '2016-04-14 13:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/892ca2b2ecf408c8a015a9822de7a7837c78f963', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 15, 'created': '2016-04-14 13:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/136aa6c4a0effa607df5e54e1875af8d12aec8fd', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 16, 'created': '2016-04-14 13:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/63ce52c28448453bac887b7e031f7020492b6f7b', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 17, 'created': '2016-05-11 10:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/fc95c666102ed40327cbc31aaca1b4d65795005f', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 18, 'created': '2016-05-11 12:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/4e125e1fb66a4b0e9fbd03266b6c9dc016d5f025', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 19, 'created': '2016-05-11 12:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/994e1e0953c43d4270b72771baa9d6a11786a711', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}, {'number': 20, 'created': '2016-05-11 13:55:22.000000000', 'files': ['doc/source/images/get_goal_from_strategy_sync_sequence_diagram.png', 'specs/newton/approved/get-goal-from-strategy.rst', 'doc/source/image_src/plantuml/get_goal_from_strategy_class_diagram.txt', 'doc/source/conf.py', 'doc/source/image_src/plantuml/get_goal_from_strategy_sync_sequence_diagram.txt', 'doc/source/images/get_goal_from_strategy_class_diagram.png', 'doc/source/image_src/plantuml/README.rst'], 'web_link': 'https://opendev.org/openstack/watcher-specs/commit/443556fca189bed973c9ea260662cc842f295c94', 'message': 'Achieved goal should be returned by each strategy\n\nToday, there is no way to know what goal is achieved by a given\nstrategy. The mapping between goal and strategies is done in the\nWatcher configuration.\n\nBeyond that, there is no way to know that several strategies achieve\nthe same optimization goal.\nThere should be a way to return the list of available goals depending\non which strategies have been deployed on the node where the Watcher\nDecision Engine is running.\n\nChange-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97\nImplements: blueprint get-goal-from-strategy\n'}]",14,301774,443556fca189bed973c9ea260662cc842f295c94,51,9,20,16495,,,0,"Achieved goal should be returned by each strategy

Today, there is no way to know what goal is achieved by a given
strategy. The mapping between goal and strategies is done in the
Watcher configuration.

Beyond that, there is no way to know that several strategies achieve
the same optimization goal.
There should be a way to return the list of available goals depending
on which strategies have been deployed on the node where the Watcher
Decision Engine is running.

Change-Id: I57f7e434c41fcbd6606552c186e9a0285ff26e97
Implements: blueprint get-goal-from-strategy
",git fetch https://review.opendev.org/openstack/watcher-specs refs/changes/74/301774/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/approved/get-goal-from-strategy.rst'],1,c47cc9d0834b6b0cb2a065bbf26538b72db30a7e,bp/get-goal-from-strategy,"GOALS uuid (primary key) name display_name STRATEGIES uuid (primary key) name (strategy entry point) display_name goal_uuid (foreign key) AUDIT_TEMPLATE uuid (primary key) name strategy (optional) => if we want to force the usage of a strategy goal_uuid (foreign key) we will expose the uuid has unique id. ( In the context of the Watcher API, the id will be the uuid) strategy optional (do we need to speak about that ? yes, we can say that we will have a more complex strategy selector able to select the strategy depending on many parameters such as ( the number of nodes, the usage of infrastructure, ect) Sync workflow 1) discovering the resources ( goals + strategies) 2) fetch current db states (goals and strategies) 3) compare the discovered resources and the ones fetched from watcher database 4) update DB - soft delete deprecated goals and strategies - update audit template goal_uuid foreign key if necessary ",,33,0
openstack%2Fdeb-openstack-pkg-tools~debian%2Fmitaka~I9d678cb73c845fe2dd00942440f99d18d81725a3,openstack/deb-openstack-pkg-tools,debian/mitaka,I9d678cb73c845fe2dd00942440f99d18d81725a3,Fix build num and upload folder,MERGED,2016-04-29 21:20:12.000000000,2016-05-11 14:47:31.000000000,2016-05-11 14:47:31.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 7613}, {'_account_id': 9582}]","[{'number': 1, 'created': '2016-04-29 21:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/be35bef347b93002531a8564a1b0323ea348caba', 'message': 'Include the number of commits as per ""git describe"" in the version number that we\'re building.\n\nChange-Id: I9d678cb73c845fe2dd00942440f99d18d81725a3\n'}, {'number': 2, 'created': '2016-05-11 12:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/fa0930d81e357b28c45cfa357e37c1d16b8e6794', 'message': 'Fix build num and upload folder\n\n* Include the number of commits as per ""git describe""\nin the version number that we\'re building.\n* Using ${WORKSPACE}/uploads and not ../uploads for\npreparing the files for the upload, as Jenkins can\'t\nupload from outside ${WORKSPACE} until we upgrade to\nzuul v3.\n\nChange-Id: I9d678cb73c845fe2dd00942440f99d18d81725a3\n'}, {'number': 3, 'created': '2016-05-11 13:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/4c2f8f01d83a309268831cf75505a8ba06541432', 'message': 'Fix build num and upload folder\n\n* Include the number of commits as per ""git describe""\nin the version number that we\'re building.\n* Using ${WORKSPACE}/uploads and not ../uploads for\npreparing the files for the upload, as Jenkins can\'t\nupload from outside ${WORKSPACE} until we upgrade to\nzuul v3.\n\nChange-Id: I9d678cb73c845fe2dd00942440f99d18d81725a3\n'}, {'number': 4, 'created': '2016-05-11 14:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/f78438fd0e89d3f2997ce40a3a4460155179995f', 'message': 'Fix build num and upload folder\n\n* Include the number of commits as per ""git describe""\nin the version number that we\'re building.\n* Using ${WORKSPACE}/uploads and not ../uploads for\npreparing the files for the upload, as Jenkins can\'t\nupload from outside ${WORKSPACE} until we upgrade to\nzuul v3.\n\nChange-Id: I9d678cb73c845fe2dd00942440f99d18d81725a3\n'}, {'number': 5, 'created': '2016-05-11 14:14:22.000000000', 'files': ['build-tools/pkgos-infra-build-pkg'], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/95052e1fc251f0ce896546e49e2671e5afa826c8', 'message': 'Fix build num and upload folder\n\n* Include the number of commits as per ""git describe""\nin the version number that we\'re building.\n* Using ${WORKSPACE}/uploads and not ../uploads for\npreparing the files for the upload, as Jenkins can\'t\nupload from outside ${WORKSPACE} until we upgrade to\nzuul v3.\n\nChange-Id: I9d678cb73c845fe2dd00942440f99d18d81725a3\n'}]",2,311274,95052e1fc251f0ce896546e49e2671e5afa826c8,23,4,5,6476,,,0,"Fix build num and upload folder

* Include the number of commits as per ""git describe""
in the version number that we're building.
* Using ${WORKSPACE}/uploads and not ../uploads for
preparing the files for the upload, as Jenkins can't
upload from outside ${WORKSPACE} until we upgrade to
zuul v3.

Change-Id: I9d678cb73c845fe2dd00942440f99d18d81725a3
",git fetch https://review.opendev.org/openstack/deb-openstack-pkg-tools refs/changes/74/311274/1 && git format-patch -1 --stdout FETCH_HEAD,['build-tools/pkgos-infra-build-pkg'],1,be35bef347b93002531a8564a1b0323ea348caba,," NUM_COMMITS_FROM_LAST_TAG=$(git describe | tr '-' '\n' | tail -n 2 | head -n 1) dch --newversion ${DEB_VERS}+${NUM_COMMITS_FROM_LAST_TAG}${BPO_DISTRO_NUM} -b --allow-lower-version -m ""Backport rebuilt by Jenkins in OpenStack infra."""," dch --newversion ${DEB_VERS}${BPO_DISTRO_NUM} -b --allow-lower-version -m ""Backport rebuilt by Jenkins in OpenStack infra.""",2,1
openstack%2Fopenstack-manuals~stable%2Fmitaka~I83c182866ed7a8223a81655e3d3a895502856001,openstack/openstack-manuals,stable/mitaka,I83c182866ed7a8223a81655e3d3a895502856001,[install] Update the invaild link,MERGED,2016-05-11 13:49:08.000000000,2016-05-11 14:45:36.000000000,2016-05-11 14:45:36.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-11 13:49:08.000000000', 'files': ['doc/install-guide/source/manila.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f8d31ed6caf190788bee52edeaa663432ed954e0', 'message': '[install] Update the invaild link\n\nbackport:mitaka\n\nChange-Id: I83c182866ed7a8223a81655e3d3a895502856001\nCloses-Bug: #1580484\n(cherry picked from commit 10430cef088275804fb2fcad23f7bb341a07bf9d)\n'}]",0,315048,f8d31ed6caf190788bee52edeaa663432ed954e0,7,3,1,19779,,,0,"[install] Update the invaild link

backport:mitaka

Change-Id: I83c182866ed7a8223a81655e3d3a895502856001
Closes-Bug: #1580484
(cherry picked from commit 10430cef088275804fb2fcad23f7bb341a07bf9d)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/48/315048/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/manila.rst'],1,f8d31ed6caf190788bee52edeaa663432ed954e0,bug/1580484,"For more information, see the `Configuration Reference <http://docs.openstack.org/mitaka/config-reference/shared-file-systems/drivers.html>`__.","For more information, see the `Configuration Reference <http://docs.openstack.org/mitaka/config-reference/content/section_share-drivers.html>`__.",1,1
openstack%2Fopenstack-ansible-lxc_hosts~stable%2Fmitaka~Ifb5b23e2b472bf0c738a01acefba578754f20b4f,openstack/openstack-ansible-lxc_hosts,stable/mitaka,Ifb5b23e2b472bf0c738a01acefba578754f20b4f,Correct LXC host public key check,MERGED,2016-05-11 13:25:46.000000000,2016-05-11 14:41:08.000000000,2016-05-11 14:41:08.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-05-11 13:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f63aae38667cf1e99218c396935fac85c3352e64', 'message': 'Correct LXC host public key check\n\nIn I167446eee35e40cde645873fbab7491f840dcd15 a pre-flight check\nwas introduced to validate whether an ssh public key is available\nbefore doing anything on the LXC hosts.\n\nThe check is supposed to validate that the requirements for the\nlookup are available. The lookup is executed on the deployment\nhost, not the target host. The check was therefore incorrect.\n\nThis patch corrects it to ensure that it does the check in the\nright places.\n\nChange-Id: Ifb5b23e2b472bf0c738a01acefba578754f20b4f\n'}, {'number': 2, 'created': '2016-05-11 13:42:03.000000000', 'files': ['tasks/main.yml', 'releasenotes/notes/ssh-pub-key-check-c42309653dbe3493.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/47ad392dfc266b2fbdcf0c049b900848929b28b7', 'message': 'Correct LXC host public key check\n\nIn I167446eee35e40cde645873fbab7491f840dcd15 a pre-flight check\nwas introduced to validate whether an ssh public key is available\nbefore doing anything on the LXC hosts.\n\nThe check is supposed to validate that the requirements for the\nlookup are available. The lookup is executed on the deployment\nhost, not the target host. The check was therefore incorrect.\n\nThis patch corrects it to ensure that it does the check in the\nright places.\n\nChange-Id: Ifb5b23e2b472bf0c738a01acefba578754f20b4f\n(cherry picked from commit b93b84c59c7be1da7f0e1e0e397828a83db0d051)'}]",0,315030,47ad392dfc266b2fbdcf0c049b900848929b28b7,11,4,2,7353,,,0,"Correct LXC host public key check

In I167446eee35e40cde645873fbab7491f840dcd15 a pre-flight check
was introduced to validate whether an ssh public key is available
before doing anything on the LXC hosts.

The check is supposed to validate that the requirements for the
lookup are available. The lookup is executed on the deployment
host, not the target host. The check was therefore incorrect.

This patch corrects it to ensure that it does the check in the
right places.

Change-Id: Ifb5b23e2b472bf0c738a01acefba578754f20b4f
(cherry picked from commit b93b84c59c7be1da7f0e1e0e397828a83db0d051)",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/30/315030/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'releasenotes/notes/ssh-pub-key-check-c42309653dbe3493.yaml']",2,f63aae38667cf1e99218c396935fac85c3352e64,,"--- fixes: - The check to validate whether an appropriate ssh public key is available to copy into the container cache has been corrected to check the deployment host, not the LXC host. ",,10,4
openstack%2Freleases~master~I66aee2a7d6a4ff9a1a048a49e1cef2a8f77dac2f,openstack/releases,master,I66aee2a7d6a4ff9a1a048a49e1cef2a8f77dac2f,Oslo releases for week of may 9th,MERGED,2016-05-10 00:07:29.000000000,2016-05-11 14:37:50.000000000,2016-05-11 14:37:50.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-05-10 00:07:29.000000000', 'files': ['deliverables/newton/taskflow.yaml', 'deliverables/newton/oslo.messaging.yaml', 'deliverables/newton/oslo.log.yaml', 'deliverables/newton/oslo.middleware.yaml', 'deliverables/newton/oslo.serialization.yaml', 'deliverables/newton/oslo.utils.yaml', 'deliverables/newton/oslo.privsep.yaml', 'deliverables/newton/tooz.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/cbb2733f906a47c06e202efb6481fdd7b8037ce0', 'message': 'Oslo releases for week of may 9th\n\nChange-Id: I66aee2a7d6a4ff9a1a048a49e1cef2a8f77dac2f\n'}]",0,314337,cbb2733f906a47c06e202efb6481fdd7b8037ce0,6,2,1,1297,,,0,"Oslo releases for week of may 9th

Change-Id: I66aee2a7d6a4ff9a1a048a49e1cef2a8f77dac2f
",git fetch https://review.opendev.org/openstack/releases refs/changes/37/314337/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/newton/taskflow.yaml', 'deliverables/newton/oslo.messaging.yaml', 'deliverables/newton/oslo.log.yaml', 'deliverables/newton/oslo.middleware.yaml', 'deliverables/newton/oslo.privsep.yaml', 'deliverables/newton/oslo.serialization.yaml', 'deliverables/newton/oslo.utils.yaml', 'deliverables/newton/tooz.yaml']",8,cbb2733f906a47c06e202efb6481fdd7b8037ce0,,- version: 1.36.0 projects: - repo: openstack/tooz hash: de9f0beeaf19889e9812c253ac3fa1ef92ed69e6,,39,0
openstack%2Fneutron~stable%2Fkilo~I39dc0e23fc118ede19ef2d986b29fc5a8e48ff78,openstack/neutron,stable/kilo,I39dc0e23fc118ede19ef2d986b29fc5a8e48ff78,Linux Bridge: Add mac spoofing filtering to ebtables,MERGED,2016-03-29 23:07:08.000000000,2016-05-11 14:36:03.000000000,2016-05-10 07:25:24.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 979}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10692}, {'_account_id': 11255}, {'_account_id': 14208}, {'_account_id': 14571}]","[{'number': 1, 'created': '2016-03-29 23:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9d1aa3055fcdb3fbacf68477cb56396e77ae734', 'message': ""Linux Bridge: Add mac spoofing filtering to ebtables\n\nThe current mac-spoofing code in iptables has two issues.\nFirst, it occurs after the address discovery allow rules\n(e.g. DHCP), so MAC addresses can be spoofed on discovery\nprotocols. Second, since it is based on iptables, it\ndoesn't apply to protocols like STP.\n\nThis means a VM could generate one of these types of packets\nwith a spoofed MAC address to trick switches into learning\nthat the spoofed MAC now belongs to the VM's port. The impact\nof this depends on the configuration of the environment\n(e.g. use of L2pop: see the bug report for details).\n\nThis patch adds MAC spoofing filtering to the ARP protection\ncode for Linux bridge based on ebtables. Only traffic sourced\nfrom the MAC address on the port or in the allowed address\npair MACs will be allowed.\n\nThis filtering will not be enabled if the port has port\nsecurity disabled or if the device_owner starts with 'network:'.\n\nConflicts:\n\tneutron/plugins/linuxbridge/agent/arp_protect.py\n\tneutron/tests/functional/agent/linux/test_linuxbridge_arp_protect.py\n    (simple conflicts on both due to utils.is_trusted_port logic being gone)\n\nChange-Id: I39dc0e23fc118ede19ef2d986b29fc5a8e48ff78\nPartial-Bug: #1558658\n(cherry picked from commit be298f8bc35e6d006c7a9361e42755c9d6790e1e)\n""}, {'number': 2, 'created': '2016-05-10 01:03:42.000000000', 'files': ['neutron/plugins/linuxbridge/agent/arp_protect.py', 'etc/neutron.conf', 'neutron/tests/functional/agent/linux/test_linuxbridge_arp_protect.py', 'neutron/agent/common/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d626eb24a304a0ba53311aa1bb877f60c974da72', 'message': ""Linux Bridge: Add mac spoofing filtering to ebtables\n\nThe current mac-spoofing code in iptables has two issues.\nFirst, it occurs after the address discovery allow rules\n(e.g. DHCP), so MAC addresses can be spoofed on discovery\nprotocols. Second, since it is based on iptables, it\ndoesn't apply to protocols like STP.\n\nThis means a VM could generate one of these types of packets\nwith a spoofed MAC address to trick switches into learning\nthat the spoofed MAC now belongs to the VM's port. The impact\nof this depends on the configuration of the environment\n(e.g. use of L2pop: see the bug report for details).\n\nThis patch adds MAC spoofing filtering to the ARP protection\ncode for Linux bridge based on ebtables. Only traffic sourced\nfrom the MAC address on the port or in the allowed address\npair MACs will be allowed.\n\nThis filtering will not be enabled if the port has port\nsecurity disabled or if the device_owner starts with 'network:'.\n\nConflicts:\n\tneutron/plugins/linuxbridge/agent/arp_protect.py\n\tneutron/tests/functional/agent/linux/test_linuxbridge_arp_protect.py\n    (simple conflicts on both due to utils.is_trusted_port logic being gone)\n\nChange-Id: I39dc0e23fc118ede19ef2d986b29fc5a8e48ff78\nPartial-Bug: #1558658\n(cherry picked from commit be298f8bc35e6d006c7a9361e42755c9d6790e1e)\n""}]",0,299027,d626eb24a304a0ba53311aa1bb877f60c974da72,38,13,2,7787,,,0,"Linux Bridge: Add mac spoofing filtering to ebtables

The current mac-spoofing code in iptables has two issues.
First, it occurs after the address discovery allow rules
(e.g. DHCP), so MAC addresses can be spoofed on discovery
protocols. Second, since it is based on iptables, it
doesn't apply to protocols like STP.

This means a VM could generate one of these types of packets
with a spoofed MAC address to trick switches into learning
that the spoofed MAC now belongs to the VM's port. The impact
of this depends on the configuration of the environment
(e.g. use of L2pop: see the bug report for details).

This patch adds MAC spoofing filtering to the ARP protection
code for Linux bridge based on ebtables. Only traffic sourced
from the MAC address on the port or in the allowed address
pair MACs will be allowed.

This filtering will not be enabled if the port has port
security disabled or if the device_owner starts with 'network:'.

Conflicts:
	neutron/plugins/linuxbridge/agent/arp_protect.py
	neutron/tests/functional/agent/linux/test_linuxbridge_arp_protect.py
    (simple conflicts on both due to utils.is_trusted_port logic being gone)

Change-Id: I39dc0e23fc118ede19ef2d986b29fc5a8e48ff78
Partial-Bug: #1558658
(cherry picked from commit be298f8bc35e6d006c7a9361e42755c9d6790e1e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/299027/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/linuxbridge/agent/arp_protect.py', 'neutron/tests/functional/agent/linux/test_linuxbridge_arp_protect.py']",2,c9d1aa3055fcdb3fbacf68477cb56396e77ae734,bug/1558658,"from neutron.common import utils self.addCleanup(self._ensure_rules_cleaned) def _ensure_rules_cleaned(self): rules = [r for r in arp_protect.ebtables(['-L']).splitlines() if r and 'Bridge' not in r] self.assertEqual([], rules, 'Test leaked ebtables rules') port_dict = {'fixed_ips': [{'ip_address': a} for a in addresses], 'mac_address': machine.port.link.address} def test_arp_correct_protection_allowed_address_pairs(self): smac = self.source.port.link.address port = {'mac_address': '00:11:22:33:44:55', 'allowed_address_pairs': [{'mac_address': smac, 'ip_address': self.source.ip}]} # make sure a large number of allowed address pairs works for i in range(100000): port['allowed_address_pairs'].append( {'mac_address': utils.get_random_mac( 'fa:16:3e:00:00:00'.split(':')), 'ip_address': '10.10.10.10'}) self._add_arp_protection(self.source, ['1.2.2.2'], port) self._add_arp_protection(self.destination, [self.destination.ip]) arping(self.source.namespace, self.destination.ip) arping(self.destination.namespace, self.source.ip) def test_arp_fails_incorrect_mac_protection(self): # a bad mac filter on the source will prevent any traffic from it self._add_arp_protection(self.source, [self.source.ip], {'mac_address': '00:11:22:33:44:55'}) no_arping(self.source.namespace, self.destination.ip) no_arping(self.destination.namespace, self.source.ip) # correcting it should make it work self._add_arp_protection(self.source, [self.source.ip]) arping(self.source.namespace, self.destination.ip) ", port_dict = {'fixed_ips': [{'ip_address': a} for a in addresses]},94,1
openstack%2Fpuppet-murano~master~I8d1a34f062fce9868a67a233e0016f7d5639d54f,openstack/puppet-murano,master,I8d1a34f062fce9868a67a233e0016f7d5639d54f,Fix incorrect default auth_tenant value,MERGED,2016-05-11 13:01:03.000000000,2016-05-11 14:33:31.000000000,2016-05-11 14:29:16.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 7745}, {'_account_id': 8482}, {'_account_id': 8971}, {'_account_id': 9414}, {'_account_id': 9500}, {'_account_id': 14985}, {'_account_id': 18795}]","[{'number': 1, 'created': '2016-05-11 13:01:03.000000000', 'files': ['spec/classes/murano_init_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/a2f07094c343c5cf4e49c6987184add8329b7a53', 'message': ""Fix incorrect default auth_tenant value\n\nBy default class ::murano::keystone::auth creates Keystone user\nin 'services' tenant, but class ::murano sets auth_tenant config\nvalue to 'service', it should be fixed.\n\nChange-Id: I8d1a34f062fce9868a67a233e0016f7d5639d54f\n""}]",0,315020,a2f07094c343c5cf4e49c6987184add8329b7a53,10,12,1,13752,,,0,"Fix incorrect default auth_tenant value

By default class ::murano::keystone::auth creates Keystone user
in 'services' tenant, but class ::murano sets auth_tenant config
value to 'service', it should be fixed.

Change-Id: I8d1a34f062fce9868a67a233e0016f7d5639d54f
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/20/315020/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/murano_init_spec.rb', 'manifests/init.pp']",2,a2f07094c343c5cf4e49c6987184add8329b7a53,,"# Defaults to 'services' $admin_tenant_name = 'services',","# Defaults to 'service' $admin_tenant_name = 'service',",3,3
openstack%2Fos-collect-config~master~I8ead8eefb940c3e2e6ec470f06e5288949a9a2bc,openstack/os-collect-config,master,I8ead8eefb940c3e2e6ec470f06e5288949a9a2bc,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:18:01.000000000,2016-05-11 14:29:25.000000000,2016-05-11 14:29:25.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6928}, {'_account_id': 11105}, {'_account_id': 12321}, {'_account_id': 14867}, {'_account_id': 16237}, {'_account_id': 16896}]","[{'number': 1, 'created': '2015-12-11 22:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/df59b0c2305230e3f8f7afc4924119d2a63ada1e', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I8ead8eefb940c3e2e6ec470f06e5288949a9a2bc\n'}, {'number': 2, 'created': '2016-04-23 15:19:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/d45a8c5c7fbb65cf7ce58fd8ca1c0ecead702e37', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I8ead8eefb940c3e2e6ec470f06e5288949a9a2bc\n'}]",0,256804,d45a8c5c7fbb65cf7ce58fd8ca1c0ecead702e37,21,8,2,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I8ead8eefb940c3e2e6ec470f06e5288949a9a2bc
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/04/256804/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,df59b0c2305230e3f8f7afc4924119d2a63ada1e,,,downloadcache = ~/cache/pip,0,1
openstack%2Fpuppet-murano~master~I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6,openstack/puppet-murano,master,I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6,Fix issue with importing packages with enabled Glare,MERGED,2016-04-21 18:12:42.000000000,2016-05-11 14:28:19.000000000,2016-05-11 14:16:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 13752}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-04-21 18:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/edd116306fa96190e05ba33ebc3caea51b710d30', 'message': ""Fix issue with importing packages with enabled Glare\n\nCurrent provider is only work with standard storing packages in\nmurano database (package_service=murano by default) and doesn't\nhandling parameter package_service in get_murano_credentials function.\nIn situation when this parameter changed (for example to 'glance')\nwe can import murano package properly.\n\nAlso fix wrong regexp on checking existing packages.\n\nChange-Id: I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6\nCloses-bug: #1572787\nRelated-bug: #1572785\n""}, {'number': 2, 'created': '2016-04-21 18:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/6921dd68257f96174070c2e2e689f2537c15b521', 'message': ""Fix issue with importing packages with enabled Glare\n\nCurrent provider is only work with standard storing packages in\nmurano database (package_service=murano by default) and doesn't\nhandling parameter package_service in get_murano_credentials function.\nIn situation when this parameter changed (for example to 'glance')\nwe can import murano package properly.\n\nAlso fix wrong regexp on checking existing packages.\n\nChange-Id: I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6\nCloses-bug: #1572787\nRelated-bug: #1572785\n""}, {'number': 3, 'created': '2016-04-22 15:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/264b9cf03f1332986e217787fe131862f0882b21', 'message': ""Fix issue with importing packages with enabled Glare\n\nCurrent provider is only work with standard storing packages in\nmurano database (package_service=murano by default) and doesn't\nhandling parameter package_service in get_murano_credentials function.\nIn situation when this parameter changed (for example to 'glance')\nwe can import murano package properly.\n\nAlso fix wrong regexp on checking existing packages.\n\nChange-Id: I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6\nCloses-bug: #1572787\nRelated-bug: #1572785\n""}, {'number': 4, 'created': '2016-04-22 16:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/bece02c3e9400b3c42a12207fd6bd39942f4751c', 'message': ""Fix issue with importing packages with enabled Glare\n\nCurrent provider is only work with standard storing packages in\nmurano database (package_service=murano by default) and doesn't\nhandling parameter package_service in get_murano_credentials function.\nIn situation when this parameter changed (for example to 'glance')\nwe can import murano package properly.\n\nAlso fix wrong regexp on checking existing packages.\n\nChange-Id: I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6\nCloses-bug: #1572787\nRelated-bug: #1572785\n""}, {'number': 5, 'created': '2016-04-22 16:52:29.000000000', 'files': ['lib/puppet/provider/murano_application/murano.rb', 'spec/unit/provider/murano_spec.rb', 'lib/puppet/provider/murano.rb'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/b36421130e4afcc55ff84c5bcf5d23ba07e2b361', 'message': ""Fix issue with importing packages with enabled Glare\n\nCurrent provider is only work with standard storing packages in\nmurano database (package_service=murano by default) and doesn't\nhandling parameter package_service in get_murano_credentials function.\nIn situation when this parameter changed (for example to 'glance')\nwe can import murano package properly.\n\nAlso fix wrong regexp on checking existing packages.\n\nChange-Id: I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6\nCloses-bug: #1572787\nRelated-bug: #1572785\n""}]",2,309139,b36421130e4afcc55ff84c5bcf5d23ba07e2b361,30,6,5,7745,,,0,"Fix issue with importing packages with enabled Glare

Current provider is only work with standard storing packages in
murano database (package_service=murano by default) and doesn't
handling parameter package_service in get_murano_credentials function.
In situation when this parameter changed (for example to 'glance')
we can import murano package properly.

Also fix wrong regexp on checking existing packages.

Change-Id: I7c8d207d278bf6ce6cddbb9e1448303bf1f88eb6
Closes-bug: #1572787
Related-bug: #1572785
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/39/309139/5 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/murano_application/murano.rb', 'spec/unit/provider/murano_spec.rb', 'lib/puppet/provider/murano.rb']",3,edd116306fa96190e05ba33ebc3caea51b710d30,," creds = Hash[ auth_keys.map { |k| [k, conf['keystone_authtoken'][k].strip] } ] if conf['packages_opts'] and !conf['packages_opts']['packages_service'].nil? creds['packages_service'] = conf['packages_opts']['packages_service'].strip end if m.key?('packages_service') authenv[:MURANO_PACKAGES_SERVICE] = m['packages_service'] end"," return Hash[ auth_keys.map { |k| [k, conf['keystone_authtoken'][k].strip] } ]",34,3
openstack%2Foslo.messaging~master~I604efabd42200e0628f108a7043d1212725a29d6,openstack/oslo.messaging,master,I604efabd42200e0628f108a7043d1212725a29d6,Updated from global requirements,MERGED,2016-05-10 00:48:42.000000000,2016-05-11 14:25:37.000000000,2016-05-11 14:25:37.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-05-10 00:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/74591131c46f0fca4f9fa55dc4f4d06bce1f789d', 'message': 'Updated from global requirements\n\nChange-Id: I604efabd42200e0628f108a7043d1212725a29d6\n'}, {'number': 2, 'created': '2016-05-10 05:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8db5ad9caa4c14de3c17b349d1667b3f4d66297f', 'message': 'Updated from global requirements\n\nChange-Id: I604efabd42200e0628f108a7043d1212725a29d6\n'}, {'number': 3, 'created': '2016-05-10 18:41:44.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6037b2b544b777bcafc5c2b55a0be94ecb2abfc1', 'message': 'Updated from global requirements\n\nChange-Id: I604efabd42200e0628f108a7043d1212725a29d6\n'}]",0,314368,6037b2b544b777bcafc5c2b55a0be94ecb2abfc1,13,3,3,11131,,,0,"Updated from global requirements

Change-Id: I604efabd42200e0628f108a7043d1212725a29d6
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/68/314368/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,74591131c46f0fca4f9fa55dc4f4d06bce1f789d,openstack/requirements,stevedore>=1.10.0 # Apache-2.0,stevedore>=1.9.0 # Apache-2.0,1,1
openstack%2Fopenstack-ansible-os_cinder~master~I744c0e8845ffe4f1100ec880fcce1458e11cbe49,openstack/openstack-ansible-os_cinder,master,I744c0e8845ffe4f1100ec880fcce1458e11cbe49,"[WIP] Revert ""Use PyPi packages for ceph python bindings""",ABANDONED,2016-05-06 08:44:38.000000000,2016-05-11 14:24:17.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}]","[{'number': 1, 'created': '2016-05-06 08:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/1447f5010f67c56cedbc48c7b9832acd22a1898c', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 3dc803d977c6df20ae4e15e6b948f2f6338607ff.\n\nConflicts:\n\tdefaults/main.yml\n\nChange-Id: I744c0e8845ffe4f1100ec880fcce1458e11cbe49\n'}, {'number': 2, 'created': '2016-05-06 10:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/c8b666ecf8d7a5f8e0012207b253c9e3ab741e16', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 3dc803d977c6df20ae4e15e6b948f2f6338607ff.\n\nChange-Id: I744c0e8845ffe4f1100ec880fcce1458e11cbe49\n'}, {'number': 3, 'created': '2016-05-06 10:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/09961a819d63012b49e2543c9258e255f7f09522', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 3dc803d977c6df20ae4e15e6b948f2f6338607ff.\n\nConflicts:\n    defaults/main.yml\n\nChange-Id: I744c0e8845ffe4f1100ec880fcce1458e11cbe49\n'}, {'number': 4, 'created': '2016-05-06 14:41:42.000000000', 'files': ['defaults/main.yml', 'tests/test-vars.yml', 'tasks/cinder_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/709ea29e9045c1f3a3e7881547be2e3ae37246e1', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 3dc803d977c6df20ae4e15e6b948f2f6338607ff.\n\nConflicts:\n    defaults/main.yml\n    tests/test-vars.yml\n\nChange-Id: I744c0e8845ffe4f1100ec880fcce1458e11cbe49\n'}]",0,313278,709ea29e9045c1f3a3e7881547be2e3ae37246e1,11,3,4,7307,,,0,"[WIP] Revert ""Use PyPi packages for ceph python bindings""

This reverts commit 3dc803d977c6df20ae4e15e6b948f2f6338607ff.

Conflicts:
    defaults/main.yml
    tests/test-vars.yml

Change-Id: I744c0e8845ffe4f1100ec880fcce1458e11cbe49
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/78/313278/3 && git format-patch -1 --stdout FETCH_HEAD,"['defaults/main.yml', 'tasks/cinder_install.yml']",2,1447f5010f67c56cedbc48c7b9832acd22a1898c,revert_cephlibs,"# TODO(mattt): remove once ceph_client role can install ceph packages from pypi # This is being done as a temporary workaround since we currently cannot obtain # ceph-related libraries from pypi. There is work in progress [1] to address # this. # [1] http://tracker.ceph.com/issues/5900 - name: Link ceph libraries into the venv file: src: ""{{ item.name }}"" dest: ""{{ cinder_venv_bin | dirname }}/lib/python2.7/site-packages/{{ item.name | basename }}"" state: ""{{ item.state }}"" force: ""yes"" with_items: - { state: link, name: ""/usr/lib/python2.7/dist-packages/rados.py"" } - { state: link, name: ""/usr/lib/python2.7/dist-packages/rbd.py"" } when: - cinder_venv_enabled | bool - inventory_hostname in groups['cinder_volume'] - cinder_backend_rbd_inuse|bool tags: - cinder-install - cinder-pip-packages ",,23,1
openstack%2Fopenstack-ansible-os_glance~master~I8d4c34307a323db8d2e0462577a4da2c5e6871bc,openstack/openstack-ansible-os_glance,master,I8d4c34307a323db8d2e0462577a4da2c5e6871bc,"[WIP] Revert ""Use PyPi packages for ceph python bindings""",ABANDONED,2016-05-06 08:38:58.000000000,2016-05-11 14:23:59.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-06 08:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/2c731366b84537d965d58c76b5b7039a6db104bb', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 9d1b8cdf035420ef8d7b76a3760c6210404ceb77.\n\nChange-Id: I8d4c34307a323db8d2e0462577a4da2c5e6871bc\n'}, {'number': 2, 'created': '2016-05-06 09:45:51.000000000', 'files': ['tasks/glance_install.yml', 'tests/inventory', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/907b48ddf390012c1553110bd091a153867ef1e2', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 9d1b8cdf035420ef8d7b76a3760c6210404ceb77.\n\nNOTE: We update tests/inventory to add a glance_api group, failing to\n      do this will cause the tests to fail since\n      tasks/glance_install.yml makes an explicit call on glance_api\n      group.\n\nConflicts:\n    tests/inventory\n\nChange-Id: I8d4c34307a323db8d2e0462577a4da2c5e6871bc\n'}]",0,313275,907b48ddf390012c1553110bd091a153867ef1e2,6,2,2,7307,,,0,"[WIP] Revert ""Use PyPi packages for ceph python bindings""

This reverts commit 9d1b8cdf035420ef8d7b76a3760c6210404ceb77.

NOTE: We update tests/inventory to add a glance_api group, failing to
      do this will cause the tests to fail since
      tasks/glance_install.yml makes an explicit call on glance_api
      group.

Conflicts:
    tests/inventory

Change-Id: I8d4c34307a323db8d2e0462577a4da2c5e6871bc
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/75/313275/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/glance_install.yml', 'defaults/main.yml']",2,2c731366b84537d965d58c76b5b7039a6db104bb,revert_cephlibs,, - python-cephlibs,22,1
openstack%2Fopenstack-ansible-os_nova~master~I35a25173e5c6554c768ca8e63f51a2f09d345a7e,openstack/openstack-ansible-os_nova,master,I35a25173e5c6554c768ca8e63f51a2f09d345a7e,"[WIP] Revert ""Use PyPi packages for ceph python bindings""",ABANDONED,2016-05-06 08:37:47.000000000,2016-05-11 14:23:51.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-06 08:37:47.000000000', 'files': ['tasks/nova_compute_kvm_install.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/c0514f8fc3a69e401583d42465360a3b3114a1f4', 'message': '[WIP] Revert ""Use PyPi packages for ceph python bindings""\n\nThis reverts commit 1f63049542c5c3b50fbdf31228151af40a86cd0c.\n\nChange-Id: I35a25173e5c6554c768ca8e63f51a2f09d345a7e\n'}]",0,313274,c0514f8fc3a69e401583d42465360a3b3114a1f4,4,2,1,7307,,,0,"[WIP] Revert ""Use PyPi packages for ceph python bindings""

This reverts commit 1f63049542c5c3b50fbdf31228151af40a86cd0c.

Change-Id: I35a25173e5c6554c768ca8e63f51a2f09d345a7e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/74/313274/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/nova_compute_kvm_install.yml', 'defaults/main.yml']",2,c0514f8fc3a69e401583d42465360a3b3114a1f4,revert_cephlibs,, - python-cephlibs,22,1
openstack%2Fpython-tripleoclient~master~I59296b401405515dff38004eb311479966cbd887,openstack/python-tripleoclient,master,I59296b401405515dff38004eb311479966cbd887,Use a released version of tripleo-common,ABANDONED,2016-05-09 12:39:50.000000000,2016-05-11 14:23:31.000000000,,"[{'_account_id': 3}, {'_account_id': 9712}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-05-09 12:39:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/858e4a8d41c2ad8adfb98f22c800a0cdd89a5aae', 'message': 'Use a released version of tripleo-common\n\nChange-Id: I59296b401405515dff38004eb311479966cbd887\nDepends-On: I3aa2b8ad2ca206496e9b0870950c330f6f3d2806\n'}]",0,314081,858e4a8d41c2ad8adfb98f22c800a0cdd89a5aae,6,3,1,9712,,,0,"Use a released version of tripleo-common

Change-Id: I59296b401405515dff38004eb311479966cbd887
Depends-On: I3aa2b8ad2ca206496e9b0870950c330f6f3d2806
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/81/314081/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,858e4a8d41c2ad8adfb98f22c800a0cdd89a5aae,,tripleo-common>=2.0.0 # Apache-2.0, # tripleo-common lib is not yet on PyPi -e git://github.com/openstack/tripleo-common.git#egg=tripleo_common,1,3
openstack%2Freleases~master~I71dc8ea35d3217d704959fdbc505878d06d1d120,openstack/releases,master,I71dc8ea35d3217d704959fdbc505878d06d1d120,Release ironic-inspector 3.3.0 for Newton,MERGED,2016-05-11 12:34:25.000000000,2016-05-11 14:17:14.000000000,2016-05-11 14:17:14.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-05-11 12:34:25.000000000', 'files': ['deliverables/newton/ironic-inspector.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1590314279531877f3ef2957482c2f6adf117d40', 'message': 'Release ironic-inspector 3.3.0 for Newton\n\nChange-Id: I71dc8ea35d3217d704959fdbc505878d06d1d120\n'}]",0,315005,1590314279531877f3ef2957482c2f6adf117d40,6,2,1,10239,,,0,"Release ironic-inspector 3.3.0 for Newton

Change-Id: I71dc8ea35d3217d704959fdbc505878d06d1d120
",git fetch https://review.opendev.org/openstack/releases refs/changes/05/315005/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/ironic-inspector.yaml'],1,1590314279531877f3ef2957482c2f6adf117d40,ironic-inspector,--- launchpad: ironic-inspector release-notes: http://docs.openstack.org/releasenotes/ironic-inspector/current-series.html send-announcements-to: openstack-announce@lists.openstack.org releases: - version: 3.3.0 projects: - repo: openstack/ironic-inspector hash: 1061b124cb8170bb9b7bf05d531fe9fe598849a0 ,,9,0
openstack%2Fpuppet-barbican~master~Ic88a303eecbea2cf252906645e33c6cfc6427edc,openstack/puppet-barbican,master,Ic88a303eecbea2cf252906645e33c6cfc6427edc,Add support for the oslo db_max_retries parameter,ABANDONED,2016-05-10 12:54:33.000000000,2016-05-11 14:08:42.000000000,,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-10 12:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/8c5a43b2018da2ea77a78f88acddbba87fc4c021', 'message': 'Add support for the oslo db_max_retries parameter\n\nThe db_max_retries parameter regulates the number of reconnection\nattempts performed after an error raised rather than at startup.\n\nChange-Id: Ic88a303eecbea2cf252906645e33c6cfc6427edc\nCloses-Bug: 1579718\n'}, {'number': 2, 'created': '2016-05-10 13:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/a940fa4e5b0cbaf457009b3d9b672ab09828f1ca', 'message': 'Add support for the oslo db_max_retries parameter\n\nThe db_max_retries parameter regulates the number of reconnection\nattempts performed after an error raised rather than at startup.\n\nChange-Id: Ic88a303eecbea2cf252906645e33c6cfc6427edc\nCloses-Bug: 1579718\n'}, {'number': 3, 'created': '2016-05-10 14:22:24.000000000', 'files': ['spec/classes/barbican_db_spec.rb', 'manifests/db.pp'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/ac7bd8c5af2827f9618e24dfc58ad7320c260404', 'message': 'Add support for the oslo db_max_retries parameter\n\nThe db_max_retries parameter regulates the number of reconnection\nattempts performed after an error raised rather than at startup.\n\nChange-Id: Ic88a303eecbea2cf252906645e33c6cfc6427edc\nCloses-Bug: 1579718\n'}]",0,314541,ac7bd8c5af2827f9618e24dfc58ad7320c260404,9,3,3,9414,,,0,"Add support for the oslo db_max_retries parameter

The db_max_retries parameter regulates the number of reconnection
attempts performed after an error raised rather than at startup.

Change-Id: Ic88a303eecbea2cf252906645e33c6cfc6427edc
Closes-Bug: 1579718
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/41/314541/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/barbican_db_spec.rb', 'manifests/db.pp']",2,8c5a43b2018da2ea77a78f88acddbba87fc4c021,bug/1579718,"# [*database_db_max_retries*] # (Optional) Maximum retries in case of connection error or deadlock error # before error is raised. Set to -1 to specify an infinite retry count. # Defaults to $::os_service_default # $database_db_max_retries = $::os_service_default, $database_db_max_retries_real = pick($::barbican::database_db_max_retries, $database_db_max_retries) db_max_retries => $database_db_max_retries_real,",,11,0
openstack%2Fbarbican~master~Ibc39fdff8812b6985bebca3ef7ecc7bc47340a56,openstack/barbican,master,Ibc39fdff8812b6985bebca3ef7ecc7bc47340a56,Switch messaging server to RPCServer,ABANDONED,2016-05-11 13:57:05.000000000,2016-05-11 14:04:36.000000000,,[],"[{'number': 1, 'created': '2016-05-11 13:57:05.000000000', 'files': ['barbican/tests/queue/test_keystone_listener.py', 'barbican/queue/__init__.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/cd0354608a36cb04792092a6cdc5636f7c33b2f3', 'message': 'Switch messaging server to RPCServer\n\nGate is recently broken by an interface change in\noslo.messaging v5. This patch changes the\nqueue.get_notification_server return object from a\nMessageHandlingServer to a more specific RPCServer\nthat can use targets.\n\nChange-Id: Ibc39fdff8812b6985bebca3ef7ecc7bc47340a56\nCloses-Bug: 1580139\n'}]",0,315054,cd0354608a36cb04792092a6cdc5636f7c33b2f3,2,0,1,15742,,,0,"Switch messaging server to RPCServer

Gate is recently broken by an interface change in
oslo.messaging v5. This patch changes the
queue.get_notification_server return object from a
MessageHandlingServer to a more specific RPCServer
that can use targets.

Change-Id: Ibc39fdff8812b6985bebca3ef7ecc7bc47340a56
Closes-Bug: 1580139
",git fetch https://review.opendev.org/openstack/barbican refs/changes/54/315054/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/queue/test_keystone_listener.py', 'barbican/queue/__init__.py']",2,cd0354608a36cb04792092a6cdc5636f7c33b2f3,bug/1580139,"from oslo_messaging.rpc import server as msg_server dispatcher = notify_dispatcher.NotificationDispatcher(endpoints, serializer) return msg_server.RPCServer(TRANSPORT, targets, dispatcher, executor='eventlet')","from oslo_messaging import server as msg_server dispatcher = notify_dispatcher.NotificationDispatcher(targets, endpoints, serializer, allow_requeue) return msg_server.MessageHandlingServer(TRANSPORT, dispatcher, executor='eventlet')",6,7
openstack%2Ffuel-ui~stable%2Fmitaka~I8870f03e52af52c1e63dc54167432277586b1ac3,openstack/fuel-ui,stable/mitaka,I8870f03e52af52c1e63dc54167432277586b1ac3,Configuration for virt role fixed on UI,MERGED,2016-05-11 12:29:28.000000000,2016-05-11 14:01:07.000000000,2016-05-11 13:58:09.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-11 12:29:28.000000000', 'files': ['static/views/dialogs.js'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/5a47e9b4397926d39737469498f5436e0b05e61e', 'message': 'Configuration for virt role fixed on UI\n\nCloses-Bug: #1578526\n\nChange-Id: I8870f03e52af52c1e63dc54167432277586b1ac3\n'}]",0,315001,5a47e9b4397926d39737469498f5436e0b05e61e,18,4,1,8735,,,0,"Configuration for virt role fixed on UI

Closes-Bug: #1578526

Change-Id: I8870f03e52af52c1e63dc54167432277586b1ac3
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/01/315001/1 && git format-patch -1 --stdout FETCH_HEAD,['static/views/dialogs.js'],1,5a47e9b4397926d39737469498f5436e0b05e61e,bug/1578526," 'cpu', 'disks', 'interfaces', 'memory', 'system', 'numa_topology', 'config', 'attributes' if (this.state.VMsConf) groups.push('config');"," 'cpu', 'disks', 'interfaces', 'memory', 'system', 'numa_topology', 'attributes'",2,2
openstack%2Fproject-config~master~Ia09f1500a52c60ebdbc81bbb56b97d36fcd46bc2,openstack/project-config,master,Ia09f1500a52c60ebdbc81bbb56b97d36fcd46bc2,Fix on OpenstackID job,MERGED,2016-05-11 13:27:24.000000000,2016-05-11 13:58:55.000000000,2016-05-11 13:58:55.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6133}]","[{'number': 1, 'created': '2016-05-11 13:27:24.000000000', 'files': ['jenkins/jobs/openstackid.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/08192e9639962472c8a9f22d8ab1b4b58b0e1274', 'message': 'Fix on OpenstackID job\n\nupdated config on tarball publishing to enabled php5 ext\nmcrypt\n\nChange-Id: Ia09f1500a52c60ebdbc81bbb56b97d36fcd46bc2\n'}]",0,315031,08192e9639962472c8a9f22d8ab1b4b58b0e1274,7,4,1,9139,,,0,"Fix on OpenstackID job

updated config on tarball publishing to enabled php5 ext
mcrypt

Change-Id: Ia09f1500a52c60ebdbc81bbb56b97d36fcd46bc2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/31/315031/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/openstackid.yaml'],1,08192e9639962472c8a9f22d8ab1b4b58b0e1274,fix_openstackid_job_2, - shell: | #!/bin/bash -xe sudo php5enmod mcrypt,,3,0
openstack%2Fnova~master~I735a14464abbad8f714e84754a38c85b5b0d3b5c,openstack/nova,master,I735a14464abbad8f714e84754a38c85b5b0d3b5c,Complete method verification of os-cloudpipe.inc,MERGED,2016-05-10 21:41:30.000000000,2016-05-11 13:56:48.000000000,2016-05-11 13:56:46.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15286}]","[{'number': 1, 'created': '2016-05-10 21:41:30.000000000', 'files': ['api-ref/source/os-cloudpipe.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7b1d22959eda6d8aaeb4056787be3094e3aa569', 'message': 'Complete method verification of os-cloudpipe.inc\n\nCorrects the error status responses for os-cloudpipe\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I735a14464abbad8f714e84754a38c85b5b0d3b5c\n'}]",2,314783,a7b1d22959eda6d8aaeb4056787be3094e3aa569,14,6,1,18337,,,0,"Complete method verification of os-cloudpipe.inc

Corrects the error status responses for os-cloudpipe

Part of bp:api-ref-in-rst

Change-Id: I735a14464abbad8f714e84754a38c85b5b0d3b5c
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/314783/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-cloudpipe.inc'],1,a7b1d22959eda6d8aaeb4056787be3094e3aa569,bp/api-ref-in-rst,"Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound (404)Error response codes: badRequest(400),unauthorized(401), forbidden(403)Error response codes: badRequest(400), unauthorized(401), forbidden(403)",".. needs:method_verificationError response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",3,7
openstack%2Freleases~master~I5af8ed3154cf6b393fe7aa0ef3452d671dd40004,openstack/releases,master,I5af8ed3154cf6b393fe7aa0ef3452d671dd40004,newton: release oslo.versionedobjects 1.9.1,MERGED,2016-05-11 05:14:02.000000000,2016-05-11 13:54:14.000000000,2016-05-11 13:54:13.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-05-11 05:14:02.000000000', 'files': ['deliverables/newton/oslo.versionedobjects.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/729084ec3ae4d0523caaee8294754f1dbcb13658', 'message': 'newton: release oslo.versionedobjects 1.9.1\n\nThis is a quick fix to get 59ac1d0 in, which corrects a breakage\nin hash calculation for Enum types.\n\nChange-Id: I5af8ed3154cf6b393fe7aa0ef3452d671dd40004\n'}]",0,314864,729084ec3ae4d0523caaee8294754f1dbcb13658,9,2,1,4393,,,0,"newton: release oslo.versionedobjects 1.9.1

This is a quick fix to get 59ac1d0 in, which corrects a breakage
in hash calculation for Enum types.

Change-Id: I5af8ed3154cf6b393fe7aa0ef3452d671dd40004
",git fetch https://review.opendev.org/openstack/releases refs/changes/64/314864/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/oslo.versionedobjects.yaml'],1,729084ec3ae4d0523caaee8294754f1dbcb13658,ovo191, - version: 1.9.1 projects: - repo: openstack/oslo.versionedobjects hash: 72dad2600488d4c49c34233db27604ed2bdcd675,,4,0
openstack%2Ffuel-ui~master~Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e,openstack/fuel-ui,master,Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e,Updates for labels icon and fixes indent positions,MERGED,2016-04-22 13:44:33.000000000,2016-05-11 13:51:21.000000000,2016-05-11 13:48:02.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8970}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 15315}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-22 13:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/32318ddb31466d059ab47a3372b9a506c8002327', 'message': 'Updates for labels icon and fixes indent positions\n\nChange-Id: Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e\n'}, {'number': 2, 'created': '2016-04-22 13:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/e946f202a6ce63a2f5b6bc9e06afce2b6c294791', 'message': 'Updates for labels icon and fixes indent positions\n\nChange-Id: Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e\n'}, {'number': 3, 'created': '2016-04-22 14:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/0987c8e92b8d0388814425467f7089b8fdd66cff', 'message': 'Updates for labels icon and fixes indent positions\n\nChange-Id: Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e\n'}, {'number': 4, 'created': '2016-04-27 10:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/afc435f6a4968bc58a8ccc69f8f0c9892877e7dc', 'message': 'Updates for labels icon and fixes indent positions\n\nChange-Id: Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e\n'}, {'number': 5, 'created': '2016-05-10 14:47:43.000000000', 'files': ['static/styles/main.less', 'static/views/cluster_page_tabs/nodes_tab_screens/node.js', 'static/img/icons/icons-sprite.svg'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/2f14d61772517b668d0790fbe5e9589963183e55', 'message': 'Updates for labels icon and fixes indent positions\n\nRelated-Bug: #1541376\n\n- New icon for \'labels\'\n- Fixed positioning for \'labels"" icon\n- Fixed positioning for count labels near the icon\n\nChange-Id: Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e\n'}]",3,309414,2f14d61772517b668d0790fbe5e9589963183e55,52,8,5,8970,,,0,"Updates for labels icon and fixes indent positions

Related-Bug: #1541376

- New icon for 'labels'
- Fixed positioning for 'labels"" icon
- Fixed positioning for count labels near the icon

Change-Id: Iede9fea095b86e8f4abda8dd9f6de61d5523bb7e
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/14/309414/3 && git format-patch -1 --stdout FETCH_HEAD,"['static/styles/main.less', 'static/views/cluster_page_tabs/nodes_tab_screens/node.js', 'static/img/icons/icons-sprite.svg']",3,32318ddb31466d059ab47a3372b9a506c8002327,(detached," width=""80px"" height=""1160px"" viewBox=""0 0 80 1160"" enable-background=""new 0 0 80 1160"" xml:space=""preserve""> <g> <g> <path fill=""#5988A5"" d=""M24.878,1133.15l1.972,1.973l-0.631,3.58l-7.467,7.469l-4.924-4.924l7.467-7.467L24.878,1133.15 M25.557,1131l-5.229,0.921L11,1141.248l7.752,7.752l9.327-9.328l0.921-5.227L25.557,1131L25.557,1131z""/> </g> <circle fill=""#5988A5"" cx=""24"" cy=""1136"" r=""1""/> </g> "," width=""80px"" height=""1120px"" viewBox=""0 0 80 1120"" enable-background=""new 0 0 80 1120"" xml:space=""preserve""> ",31,4
openstack%2Fnova~master~I08d4cbf17fdc0efa42efe9beaa0012ca92320b09,openstack/nova,master,I08d4cbf17fdc0efa42efe9beaa0012ca92320b09,method verification for servers-action-fixed-ip,MERGED,2016-05-10 20:07:21.000000000,2016-05-11 13:50:58.000000000,2016-05-11 13:50:56.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 9578}, {'_account_id': 15286}, {'_account_id': 19590}]","[{'number': 1, 'created': '2016-05-10 20:07:21.000000000', 'files': ['api-ref/source/servers-action-fixed-ip.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/f6ac9f325737f3caceca0bcb8f923f73fba804a1', 'message': 'method verification for servers-action-fixed-ip\n\nVerify and Update the response codes for the methods based\non what is in the code.\n\npart of blueprint: api-ref-in-rst\n\nChange-Id: I08d4cbf17fdc0efa42efe9beaa0012ca92320b09\n'}]",0,314748,f6ac9f325737f3caceca0bcb8f923f73fba804a1,14,6,1,18335,,,0,"method verification for servers-action-fixed-ip

Verify and Update the response codes for the methods based
on what is in the code.

part of blueprint: api-ref-in-rst

Change-Id: I08d4cbf17fdc0efa42efe9beaa0012ca92320b09
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/314748/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/servers-action-fixed-ip.inc'],1,f6ac9f325737f3caceca0bcb8f923f73fba804a1,bp/api-ref-in-rst,"Adds a fixed IP address to a server instance, which associates that address with the server. The fixed IP address is retrieved from the network that you specify in the request.Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)",".. needs:method_verificationAdds a fixed IP address to a server instance, which associates that address with the server. The fixed IP address is retrieved from the network that you specify in the request.Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",11,8
openstack%2Fmurano~stable%2Fmitaka~I0d7a66b66d47c5996df8047225dcd9323d328412,openstack/murano,stable/mitaka,I0d7a66b66d47c5996df8047225dcd9323d328412,Pass [rabbitmq]/ca_certs file to murano-spawned instance,MERGED,2016-05-10 09:19:09.000000000,2016-05-11 13:49:25.000000000,2016-05-11 13:49:25.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 20563}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-05-10 09:19:09.000000000', 'files': ['meta/io.murano/Classes/resources/LinuxMuranoInstance.yaml', 'murano/common/config.py', 'meta/io.murano/Resources/linux-init.sh', 'murano/engine/system/yaql_functions.py', 'meta/io.murano/Resources/Agent-v2.template'], 'web_link': 'https://opendev.org/openstack/murano/commit/f1614d728c5704464d4931bee532cec7bb6edd49', 'message': 'Pass [rabbitmq]/ca_certs file to murano-spawned instance\n\nChange-Id: I0d7a66b66d47c5996df8047225dcd9323d328412\nCloses-Bug: #1568172\n(cherry picked from commit 21e877c22d2b5303a7c0d07602f84d36754425b1)\n'}]",0,314474,f1614d728c5704464d4931bee532cec7bb6edd49,18,6,1,20364,,,0,"Pass [rabbitmq]/ca_certs file to murano-spawned instance

Change-Id: I0d7a66b66d47c5996df8047225dcd9323d328412
Closes-Bug: #1568172
(cherry picked from commit 21e877c22d2b5303a7c0d07602f84d36754425b1)
",git fetch https://review.opendev.org/openstack/murano refs/changes/74/314474/1 && git format-patch -1 --stdout FETCH_HEAD,"['meta/io.murano/Classes/resources/LinuxMuranoInstance.yaml', 'murano/common/config.py', 'meta/io.murano/Resources/linux-init.sh', 'murano/engine/system/yaql_functions.py', 'meta/io.murano/Resources/Agent-v2.template']",5,f1614d728c5704464d4931bee532cec7bb6edd49,bug/1568172,ca_certs = '/etc/murano/certs/ca_certs',ca_certs =,23,5
openstack%2Fopenstack-manuals~master~I83c182866ed7a8223a81655e3d3a895502856001,openstack/openstack-manuals,master,I83c182866ed7a8223a81655e3d3a895502856001,[install] Update the invaild link,MERGED,2016-05-11 09:08:27.000000000,2016-05-11 13:49:09.000000000,2016-05-11 13:36:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9515}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-11 09:08:27.000000000', 'files': ['doc/install-guide/source/manila.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/10430cef088275804fb2fcad23f7bb341a07bf9d', 'message': '[install] Update the invaild link\n\nbackport:mitaka\n\nChange-Id: I83c182866ed7a8223a81655e3d3a895502856001\nCloses-Bug: #1580484\n'}]",0,314919,10430cef088275804fb2fcad23f7bb341a07bf9d,9,4,1,19779,,,0,"[install] Update the invaild link

backport:mitaka

Change-Id: I83c182866ed7a8223a81655e3d3a895502856001
Closes-Bug: #1580484
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/314919/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/manila.rst'],1,10430cef088275804fb2fcad23f7bb341a07bf9d,bug/1580484,"For more information, see the `Configuration Reference <http://docs.openstack.org/mitaka/config-reference/shared-file-systems/drivers.html>`__.","For more information, see the `Configuration Reference <http://docs.openstack.org/mitaka/config-reference/content/section_share-drivers.html>`__.",1,1
openstack%2Frequirements~master~I2369638282b4fefccd8484a5039fcfa9795069a7,openstack/requirements,master,I2369638282b4fefccd8484a5039fcfa9795069a7,Bump paramiko to version 2.0,MERGED,2016-05-10 14:17:28.000000000,2016-05-11 13:48:57.000000000,2016-05-11 13:48:56.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 10343}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-05-10 14:17:28.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e379813e9ccd41138af969f4c8e57abd062af527', 'message': 'Bump paramiko to version 2.0\n\nparamiko 2.0 released with some much better compatibility for key\ngeneration, which fixes a latent bug in Nova. The interface is\nsufficiently different for 2.0 and 1.16 that we should just make 2.0\nthe new minimum and not have a long lived, poorly tested, compat layer\nin Nova.\n\nDepends-On: I5d6543e690a3b4495476027fd8a4894ff8c42bf6\n(short lived compatibility layer to let us get through this transition)\n\nChange-Id: I2369638282b4fefccd8484a5039fcfa9795069a7\nRelated-Bug: #1483132\n'}]",0,314595,e379813e9ccd41138af969f4c8e57abd062af527,17,6,1,2750,,,0,"Bump paramiko to version 2.0

paramiko 2.0 released with some much better compatibility for key
generation, which fixes a latent bug in Nova. The interface is
sufficiently different for 2.0 and 1.16 that we should just make 2.0
the new minimum and not have a long lived, poorly tested, compat layer
in Nova.

Depends-On: I5d6543e690a3b4495476027fd8a4894ff8c42bf6
(short lived compatibility layer to let us get through this transition)

Change-Id: I2369638282b4fefccd8484a5039fcfa9795069a7
Related-Bug: #1483132
",git fetch https://review.opendev.org/openstack/requirements refs/changes/95/314595/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,e379813e9ccd41138af969f4c8e57abd062af527,paramiko,paramiko===2.0.0,paramiko===1.16.0,2,2
openstack%2Fopenstack-ansible~stable%2Fmitaka~I9f6c1533ac18896fac9cf528b2e32af71c931ebf,openstack/openstack-ansible,stable/mitaka,I9f6c1533ac18896fac9cf528b2e32af71c931ebf,Added upgrade task to generate SSH keys on hosts,ABANDONED,2016-05-03 23:48:24.000000000,2016-05-11 13:46:39.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-05-03 23:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f96d78bf15da483865c8aba96dc98bec1b550aa7', 'message': 'Added upgrade task to generate SSH keys on hosts\n\nThis change adds a simple playbook to generate SSH keys on all\ninventory items within the ""hosts"" group.\n\nChange-Id: I9f6c1533ac18896fac9cf528b2e32af71c931ebf\nCloses-Bug: #1574019\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-05-06 15:35:07.000000000', 'files': ['doc/source/upgrade-guide/manual-upgrade.rst', 'scripts/upgrade-utilities/playbooks/ssh-key-generate.yml', 'doc/source/upgrade-guide/upgrade-playbooks.rst', 'scripts/run-upgrade.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aed75d1d7d3be2393ca39664bde13b64f61d251e', 'message': 'Added upgrade task to generate SSH keys on hosts\n\nThis change adds a simple playbook to generate SSH keys on all\ninventory items within the ""hosts"" group.\n\nImplements: blueprint upgrade-liberty-mitaka\nChange-Id: I9f6c1533ac18896fac9cf528b2e32af71c931ebf\nCloses-Bug: #1574019\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,312286,aed75d1d7d3be2393ca39664bde13b64f61d251e,11,4,2,7353,,,0,"Added upgrade task to generate SSH keys on hosts

This change adds a simple playbook to generate SSH keys on all
inventory items within the ""hosts"" group.

Implements: blueprint upgrade-liberty-mitaka
Change-Id: I9f6c1533ac18896fac9cf528b2e32af71c931ebf
Closes-Bug: #1574019
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/312286/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/upgrade-guide/manual-upgrade.rst', 'scripts/upgrade-utilities/playbooks/ssh-key-generate.yml', 'doc/source/upgrade-guide/upgrade-playbooks.rst', 'scripts/run-upgrade.sh']",4,f96d78bf15da483865c8aba96dc98bec1b550aa7,bug/1574019," RUN_TASKS+=(""${UPGRADE_PLAYBOOKS}/ssh-key-generate.yml"")",,48,0
openstack%2Fpython-cinderclient~master~If2686461bff1ef9afd318e999c9e517e15b1677f,openstack/python-cinderclient,master,If2686461bff1ef9afd318e999c9e517e15b1677f,Change api_version to self.api_version,MERGED,2016-05-10 20:34:01.000000000,2016-05-11 13:44:15.000000000,2016-05-11 13:44:15.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 9535}, {'_account_id': 20541}]","[{'number': 1, 'created': '2016-05-10 20:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/25f611ebd3e11259f42b898c29ecafc904dde5df', 'message': 'Change api_version to self.api_version\n\nCall to _construct_http_client uses:\napi_version=api_version\nbut should be:\napi_version=self.api_version\n\nChange-Id: If2686461bff1ef9afd318e999c9e517e15b1677f\nFixes-Bug: 1580319\n'}, {'number': 2, 'created': '2016-05-10 20:44:41.000000000', 'files': ['cinderclient/v3/client.py', 'cinderclient/v2/client.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/030dedf9e8beb89784ab112977716f9b96073195', 'message': 'Change api_version to self.api_version\n\nCall to _construct_http_client uses:\napi_version=api_version\nbut should be:\napi_version=self.api_version\n\nChange-Id: If2686461bff1ef9afd318e999c9e517e15b1677f\nCloses-Bug: 1580319\n'}]",4,314759,030dedf9e8beb89784ab112977716f9b96073195,12,5,2,7173,,,0,"Change api_version to self.api_version

Call to _construct_http_client uses:
api_version=api_version
but should be:
api_version=self.api_version

Change-Id: If2686461bff1ef9afd318e999c9e517e15b1677f
Closes-Bug: 1580319
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/59/314759/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v3/client.py', 'cinderclient/v2/client.py']",2,25f611ebd3e11259f42b898c29ecafc904dde5df,bug/1580319," api_version=self.api_version,"," api_version=api_version,",2,2
openstack%2Ftripleo-quickstart~master~Ia863ea0afc1123a8e38da2a053780262c317aa86,openstack/tripleo-quickstart,master,Ia863ea0afc1123a8e38da2a053780262c317aa86,Teardown network fix,MERGED,2016-05-06 14:31:52.000000000,2016-05-11 13:44:07.000000000,2016-05-11 13:44:07.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 8745}, {'_account_id': 10061}, {'_account_id': 18846}]","[{'number': 1, 'created': '2016-05-06 14:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/cff3abece409d6e77805535198ab64bc9fa153ff', 'message': ""Teardown network fix\n\nWhen running the teardown playbook the deployment stopped due to not\nignoring errors for the 'Undefine libvirt networks' task. It was also\nrecommended by adarazs to ignore errors for the following task.\n\nChange-Id: Ia863ea0afc1123a8e38da2a053780262c317aa86\n""}, {'number': 2, 'created': '2016-05-11 13:28:16.000000000', 'files': ['playbooks/roles/environment/teardown/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/efaaeb714067aff5be5c2fbd98bbcb1c6f52fe39', 'message': ""Teardown network fix\n\nWhen running the teardown playbook the deployment stopped due to not\nignoring errors for the 'Undefine libvirt networks' task.\n\nChange-Id: Ia863ea0afc1123a8e38da2a053780262c317aa86\n""}]",3,313575,efaaeb714067aff5be5c2fbd98bbcb1c6f52fe39,14,5,2,10061,,,0,"Teardown network fix

When running the teardown playbook the deployment stopped due to not
ignoring errors for the 'Undefine libvirt networks' task.

Change-Id: Ia863ea0afc1123a8e38da2a053780262c317aa86
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/75/313575/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/environment/teardown/tasks/main.yml'],1,cff3abece409d6e77805535198ab64bc9fa153ff,teardown-fix, ignore_errors: true ignore_errors: true,,2,0
openstack%2Fopenstack-ansible-os_tempest~master~I6f3c36a8150b83afabae8d397d5fc7340dbc93fd,openstack/openstack-ansible-os_tempest,master,I6f3c36a8150b83afabae8d397d5fc7340dbc93fd,Standardise tempest role,MERGED,2016-04-28 13:10:34.000000000,2016-05-11 13:43:52.000000000,2016-05-11 13:43:52.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-04-28 13:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/13bb77cd4fee63cf4f499a9694583e767f543824', 'message': ""Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\n""}, {'number': 2, 'created': '2016-04-28 13:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/691226ee3cce7e8a4b079c77e1a9554b983ca113', 'message': ""[WIP] Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\n""}, {'number': 3, 'created': '2016-05-04 13:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/6e8509d69cb39a84a26cb0ef2c026431d14d029f', 'message': ""[WIP] Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\n""}, {'number': 4, 'created': '2016-05-04 14:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/624f97413cfe09490ae53d2371ba3f01e956e89a', 'message': ""[WIP] Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\n""}, {'number': 5, 'created': '2016-05-04 14:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/016bc8ef24e462457360d69e7b313a03623d563b', 'message': ""[WIP] Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\n""}, {'number': 6, 'created': '2016-05-05 10:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/38b2134ece4ebebd06f8d7634f7c4aca1eab55ec', 'message': ""[WIP] Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\n""}, {'number': 7, 'created': '2016-05-09 13:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/75be2748491e6354f5984ad9b01c72c958c41241', 'message': ""Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\nDepends-On: Ie700c061cf0efa3d1fcda9e74618bb8c6e9ae371\n""}, {'number': 8, 'created': '2016-05-09 14:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/cd2cc35c00dd579317c9d2370aa1dd81e585eec8', 'message': ""Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\nDepends-On: Ie700c061cf0efa3d1fcda9e74618bb8c6e9ae371\n""}, {'number': 9, 'created': '2016-05-10 08:08:33.000000000', 'files': ['templates/tempest.conf.j2', 'tasks/tempest_post_install.yml', 'tasks/tempest_install.yml', 'templates/openstack_tempest_gate.sh.j2', 'defaults/main.yml', 'tests/test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/75bd092b9e66e4ef79bfc4449ec60901496128d4', 'message': ""Standardise tempest role\n\nAll of our roles have a standard pattern for installing services,\nhowever tempest does things slightly differently.  I think most of this\nis legacy and this commit brings tempest in line (for the most part)\nwith how other roles are written.\n\nNote that tempest now has a ``tempest`` cli, and in a future commit we\nwill update this role to use that instead.  This will allow us to skip\nthe additional step of cloning the tempest git repo to act as a working\ndirectory when running tests.\n\nFor some background as to why this work is being done, newer versions\nof tempest are failing when run in an IRR because we are not installing\nurllib3 into tempest's venv.  This is not an issue when we do an\nintegrated build because the repo server actually installs tempest into\nthe tempest venv, and all requirements get satisfied.  However, when we\ninstall tempest without a repo server we simply install\ntempest_pip_packages (which previously did not include tempest itself)\ninto the tempest venv.  We could update update tempest_pip_packages to\ninclude urllib3, but doing so creates duplicate work as this\nrequirement is already captured in tempest's requirements.txt.\n\nChange-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd\nDepends-On: Ie700c061cf0efa3d1fcda9e74618bb8c6e9ae371\n""}]",2,310766,75bd092b9e66e4ef79bfc4449ec60901496128d4,32,5,9,7307,,,0,"Standardise tempest role

All of our roles have a standard pattern for installing services,
however tempest does things slightly differently.  I think most of this
is legacy and this commit brings tempest in line (for the most part)
with how other roles are written.

Note that tempest now has a ``tempest`` cli, and in a future commit we
will update this role to use that instead.  This will allow us to skip
the additional step of cloning the tempest git repo to act as a working
directory when running tests.

For some background as to why this work is being done, newer versions
of tempest are failing when run in an IRR because we are not installing
urllib3 into tempest's venv.  This is not an issue when we do an
integrated build because the repo server actually installs tempest into
the tempest venv, and all requirements get satisfied.  However, when we
install tempest without a repo server we simply install
tempest_pip_packages (which previously did not include tempest itself)
into the tempest venv.  We could update update tempest_pip_packages to
include urllib3, but doing so creates duplicate work as this
requirement is already captured in tempest's requirements.txt.

Change-Id: I6f3c36a8150b83afabae8d397d5fc7340dbc93fd
Depends-On: Ie700c061cf0efa3d1fcda9e74618bb8c6e9ae371
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/66/310766/9 && git format-patch -1 --stdout FETCH_HEAD,"['templates/tempest.conf.j2', 'tasks/tempest_post_install.yml', 'tasks/tempest_install.yml', 'templates/openstack_tempest_gate.sh.j2', 'defaults/main.yml', 'tests/test-vars.yml']",6,13bb77cd4fee63cf4f499a9694583e767f543824,standardise_tempest,"tempest_venv_tag: ""{{ tempest_git_install_branch }}""","tempest_git_dest: ""/opt/tempest_{{ tempest_git_install_branch | replace('/', '_') }}""",160,72
openstack%2Frally~master~Ied595d4b8e08ec8f6cf0ef8b16b543d92650dd91,openstack/rally,master,Ied595d4b8e08ec8f6cf0ef8b16b543d92650dd91,[Doc] Fix small typo in cli_reference,MERGED,2016-05-11 10:15:26.000000000,2016-05-11 13:42:58.000000000,2016-05-11 13:42:58.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-11 10:15:26.000000000', 'files': ['doc/ext/cli_reference.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d75e6f22f87df6ec216bc53a6217d680e7729d8f', 'message': '[Doc] Fix small typo in cli_reference\n\nChange-Id: Ied595d4b8e08ec8f6cf0ef8b16b543d92650dd91\n'}]",0,314948,d75e6f22f87df6ec216bc53a6217d680e7729d8f,9,5,1,10475,,,0,"[Doc] Fix small typo in cli_reference

Change-Id: Ied595d4b8e08ec8f6cf0ef8b16b543d92650dd91
",git fetch https://review.opendev.org/openstack/rally refs/changes/48/314948/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ext/cli_reference.py'],1,d75e6f22f87df6ec216bc53a6217d680e7729d8f,small-fix-in-docs," compose_use_cmd_hint_msg(""rally verify use""))"," compose_use_cmd_hint_msg(""rally %verify use""))",1,1
openstack%2Fnetworking-midonet~master~I5e748f5caa261b1a47f9ba39d0a05aebe8446b08,openstack/networking-midonet,master,I5e748f5caa261b1a47f9ba39d0a05aebe8446b08,devstackrc: Make Keystore use eventlet deployment strategy,ABANDONED,2015-12-18 04:49:36.000000000,2016-05-11 13:41:00.000000000,,"[{'_account_id': 3}, {'_account_id': 6854}]","[{'number': 1, 'created': '2015-12-18 04:49:36.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/313c39e1f8eb066a872212e9928578db857a9720', 'message': 'devstackrc: Make Keystore use eventlet deployment strategy\n\nHopefully it uses less memory than apache.\n\nRelated-Bug: #1527451\nChange-Id: I5e748f5caa261b1a47f9ba39d0a05aebe8446b08\n'}]",0,259278,313c39e1f8eb066a872212e9928578db857a9720,4,2,1,6854,,,0,"devstackrc: Make Keystore use eventlet deployment strategy

Hopefully it uses less memory than apache.

Related-Bug: #1527451
Change-Id: I5e748f5caa261b1a47f9ba39d0a05aebe8446b08
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/78/259278/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,313c39e1f8eb066a872212e9928578db857a9720,bug/1527451,"# Try to save some memory to make a space for midolman export DEVSTACK_LOCAL_CONFIG+=$'\n'""KEYSTONE_USE_MOD_WSGI=False"" ",,3,0
openstack%2Ftripleo-common~master~Idadb05d01a7e2353dd812e8461c5641e4dafdae5,openstack/tripleo-common,master,Idadb05d01a7e2353dd812e8461c5641e4dafdae5,Collect the common logic in tripleo-common,ABANDONED,2015-09-29 15:12:26.000000000,2016-05-11 13:39:35.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7065}, {'_account_id': 7386}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 11997}, {'_account_id': 15192}, {'_account_id': 20775}]","[{'number': 1, 'created': '2015-09-29 15:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e764d53d9ccb2110b14778feacc3efecebb2dc57', 'message': 'Start to abstract the code for deployment\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 2, 'created': '2015-09-29 15:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8b11944d012f43bd0b47e9e950ad21d7542ec89d', 'message': 'Start to abstract the code for deployment\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 3, 'created': '2015-09-29 15:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3ae7d78f8a83364ba2123b0434b0ce0d7085ba22', 'message': '[WIP] Start to abstract the code for deployment\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 4, 'created': '2015-09-30 13:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/564a3c3ec8a1e51fcecc14daca02523cf739a94c', 'message': '[WIP] Start to abstract the code for deployment\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 5, 'created': '2015-10-06 09:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9d7e76fad6244ede851297be1638e8d45536b02d', 'message': '[WIP] Start to abstract the code for deployment\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 6, 'created': '2015-10-06 13:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/eece4cf84552eedb2bc62a15abdeeba69885862f', 'message': '[WIP] Start to abstract the code for deployment\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 7, 'created': '2015-10-06 13:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3033e6f50e05d18bbae2f5b6d736ecb86bafda8c', 'message': 'Collect the common logic used when dealing with Heat\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 8, 'created': '2015-10-07 12:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9dadedd81c01d9b02a54745de4b3f3c166ba9c55', 'message': 'Collect the common logic used when dealing with Heat\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 9, 'created': '2015-10-07 12:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7fed936da679607dd885483cd0dbd855e489081c', 'message': 'Collect the common logic used when dealing with Heat\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 10, 'created': '2015-10-08 12:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5d58f40affee57d45c1bfce6269319f82e1d84c7', 'message': 'Collect the common logic used when dealing with Heat\n\nThis change is the begining of work that will enable\ntripleo-common to handle more generic deployments than it does\ncurrently.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 11, 'created': '2015-10-08 16:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7f6c9052ea3b7eb8dbf15129b677c376174775c8', 'message': 'Collect the common logic in tripleo-common\n\nThis change generalises the common logic and better defines the public API by\nmarking stack_update as private.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 12, 'created': '2015-10-14 12:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/60dd3efc51b20cf7bde51ef0f6f7eb6fa04838ff', 'message': 'Collect the common logic in tripleo-common\n\nThis change generalises the common logic and better defines the public API by\nmarking stack_update as private.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 13, 'created': '2015-10-14 12:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/028dcca7fb4cc8ecd1a0ae6dbc4fe52e0d52b2b0', 'message': 'Collect the common logic in tripleo-common\n\nThis change generalises the common logic and better defines the public API by\nmarking stack_update as private.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 14, 'created': '2015-10-16 15:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4fd2d210977a13bcbd46052bdc37a689de07a207', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 15, 'created': '2015-10-16 15:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/be70b17fa0b9a9b76ba2bddf83c2d120b44528cd', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 16, 'created': '2015-10-19 09:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/96431125f758fe72398f59272d99388596e3e8ed', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 17, 'created': '2015-11-09 15:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/eb89f95cd695fd5b43dac9ab163ab28a04bbf4ac', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 18, 'created': '2015-11-09 16:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/43e5adaf2e1794ca1420107c92e614c9e8a0ba6a', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 19, 'created': '2015-11-09 16:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/82deaa8a0f29a0c37c1c89d7ca1cd88c156f0883', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 20, 'created': '2015-11-12 14:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/97cf471f35d0e9b7d7cac7077cedeb26c0abdbac', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 21, 'created': '2015-11-17 14:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b524d98d4e57136475ae6b2ac16085381a388759', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 22, 'created': '2015-11-20 11:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1fecf89df823ca1dfe50f1f75257e636e169cce2', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 23, 'created': '2015-11-24 11:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/767a319c852e43bc4eaeef3deb33b8923d8879c6', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 24, 'created': '2015-12-11 12:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/51ac22e8b62b2f83206f1fe8c0b6e9bb82c6dbdb', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 25, 'created': '2015-12-11 15:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/18f6f60db602f04688b1c640ba21b6a4b4fb1f1a', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 26, 'created': '2015-12-11 20:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9568722147c94b93af53a5715c8d262456a43168', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 27, 'created': '2015-12-17 09:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ef27ee8a49312e5e98f635bf96d60b91bf552b8d', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 28, 'created': '2015-12-17 12:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8ceb79c9d36d832f2924910068a2e89afd4efafe', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 29, 'created': '2015-12-18 08:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d273724aa4651d1d42d015184d1df1171ce6688f', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 30, 'created': '2015-12-18 12:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/362199e80a86d03328ebf2d7f91b43a36ca2f5db', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 31, 'created': '2015-12-18 17:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/47a35ab6f73aabd62cc94a1f1733d8a821857475', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 32, 'created': '2015-12-21 08:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5aff64fc170eb009fffd546c9dd8005e097c2766', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 33, 'created': '2015-12-22 12:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/582ba9db32e7fdd2c28427baa22c60cddaf83acf', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 34, 'created': '2016-01-06 15:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/59c9c05780b1455a7cfc48babc3a05e55db03ebd', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 35, 'created': '2016-01-08 09:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/27542a552feb5962e3b39175cccf16b0d53f9a51', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 36, 'created': '2016-02-17 13:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b65e5a4348765e2f858158d13b2492e18e5b1bae', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 37, 'created': '2016-03-08 12:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/059133dcc4dd4bf93f6db125771eca518bb32be2', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 38, 'created': '2016-03-21 08:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/59b0ba4197d3e19c7399d7323e99e3d7c21c7a20', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 39, 'created': '2016-04-25 08:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/627fa9b98b2a272b90dd634b6ff9c1f0c91ea1be', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 40, 'created': '2016-05-06 07:17:23.000000000', 'files': ['tripleo_common/utils/__init__.py', 'tripleo_common/tests/test_deploy.py', 'tripleo_common/deploy.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/edbc920a80d621c1182fefd457a950079b0bd633', 'message': 'Collect the common logic in tripleo-common\n\nThis change adds a general interface for deploying to heat. A follow up change\nwill migrate the update and scale packages to use it.\n\nChange-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}]",3,228991,edbc920a80d621c1182fefd457a950079b0bd633,154,9,40,9712,,,0,"Collect the common logic in tripleo-common

This change adds a general interface for deploying to heat. A follow up change
will migrate the update and scale packages to use it.

Change-Id: Idadb05d01a7e2353dd812e8461c5641e4dafdae5
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/91/228991/10 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/constants.py', 'tripleo_common/deploy.py', 'tripleo_common/scale.py', 'tripleo_common/update.py']",4,e764d53d9ccb2110b14778feacc3efecebb2dc57,add-initial-swift-patch35," from tripleo_common import constants template_file=os.path.join(self.tht_dir, constants.TEMPLATE_NAME))","TEMPLATE_NAME = 'overcloud-without-mergepy.yaml' template_file=os.path.join(self.tht_dir, TEMPLATE_NAME))",84,31
openstack%2Fpuppet-barbican~master~Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434,openstack/puppet-barbican,master,Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434,Make database parameters match upstream,MERGED,2016-04-01 20:07:03.000000000,2016-05-11 13:39:10.000000000,2016-05-11 13:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 9914}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-04-01 20:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/8243a718a1d924402cec838b0f8985250ae8e3de', 'message': 'Make database parameters match upstream\n\nUpdates the database parameters to actually match what upstream\nbarbican uses in its config file:\n\nhttp://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41\n\nWithout these changes I get db sync failures w/ barbican when\nusing MySQL.\n\nChange-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434\n'}, {'number': 2, 'created': '2016-05-10 14:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/c761d1f3306c1eec309c5191a43f94d1b789710c', 'message': 'Make database parameters match upstream\n\nUpdates the database parameters to actually match what upstream\nbarbican uses in its config file:\n\nhttp://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41\n\nWithout these changes I get db sync failures w/ barbican when\nusing MySQL.\n\nChange-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434\nCo-Authored-By: Alex Schultz <aschultz@mirantis.com>\n'}, {'number': 3, 'created': '2016-05-10 14:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/00f9af13ff0463464fe0c3b3c575be8a11b6e2bf', 'message': 'Make database parameters match upstream\n\nUpdates the database parameters to actually match what upstream\nbarbican uses in its config file:\n\nhttp://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41\n\nWithout these changes I get db sync failures w/ barbican when\nusing MySQL.\n\nChange-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434\nCo-Authored-By: Alex Schultz <aschultz@mirantis.com>\n'}, {'number': 4, 'created': '2016-05-10 15:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/026601f32f9c7dc07b47c1731755aa063906618a', 'message': 'Make database parameters match upstream\n\nUpdates the database parameters to actually match what upstream\nbarbican uses in its config file:\n\nhttp://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41\n\nWithout these changes I get db sync failures w/ barbican when\nusing MySQL.\n\nChange-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434\nCo-Authored-By: Alex Schultz <aschultz@mirantis.com>\n'}, {'number': 5, 'created': '2016-05-10 16:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/dd16f0cec2cc1e56c974f11fd4c5db145363a2bd', 'message': 'Make database parameters match upstream\n\nUpdates the database parameters to actually match what upstream\nbarbican uses in its config file:\n\nhttp://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41\n\nWithout these changes I get db sync failures w/ barbican when\nusing MySQL.\n\nChange-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434\nCo-Authored-By: Alex Schultz <aschultz@mirantis.com>\n'}, {'number': 6, 'created': '2016-05-10 18:49:35.000000000', 'files': ['spec/classes/barbican_db_spec.rb', 'manifests/db/sync.pp', 'manifests/db.pp'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/aa2165e7d7f29ff0226dfb5a1be463cdaa49f9b9', 'message': 'Make database parameters match upstream\n\nUpdates the database parameters to actually match what upstream\nbarbican uses in its config file:\n\nhttp://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41\n\nWithout these changes I get db sync failures w/ barbican when\nusing MySQL.\n\nChange-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434\nCo-Authored-By: Alex Schultz <aschultz@mirantis.com>\n'}]",2,300640,aa2165e7d7f29ff0226dfb5a1be463cdaa49f9b9,26,6,6,360,,,0,"Make database parameters match upstream

Updates the database parameters to actually match what upstream
barbican uses in its config file:

http://git.openstack.org/cgit/openstack/barbican/tree/etc/barbican/barbican.conf#n41

Without these changes I get db sync failures w/ barbican when
using MySQL.

Change-Id: Ia79f3d1bed0c2a66ed17ae2ee91ca70c73f6c434
Co-Authored-By: Alex Schultz <aschultz@mirantis.com>
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/40/300640/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/barbican_db_spec.rb', 'manifests/db/sync.pp', 'manifests/db.pp']",3,8243a718a1d924402cec838b0f8985250ae8e3de,sql_connection,"# [*database_pool_size*] # Number of SQL connections to keep open in a pool. $database_pool_size = $::os_service_default, $database_pool_size_real = pick($::barbican::database_pool_size, $database_pool_size) 'DEFAULT/sql_connection': value => $database_connection_real, secret => true; 'DEFAULT/sql_idle_timeout': value => $database_idle_timeout_real; 'DEFAULT/sql_pool_size': value => $database_pool_size_real; 'DEFAULT/sql_pool_max_overflow': value => $database_max_overflow_real;","# [*database_max_retries*] # Maximum number of database connection retries during startup. # Setting -1 implies an infinite retry count. # (Optional) Defaults to $::os_service_default # # [*database_retry_interval*] # Interval between retries of opening a database connection. # (Optional) Defaults to $::os_service_default # # [*database_min_pool_size*] # Minimum number of SQL connections to keep open in a pool. # (Optional) Defaults to $::os_service_default # # [*database_max_pool_size*] # Maximum number of SQL connections to keep open in a pool. $database_min_pool_size = $::os_service_default, $database_max_pool_size = $::os_service_default, $database_max_retries = $::os_service_default, $database_retry_interval = $::os_service_default, $database_min_pool_size_real = pick($::barbican::database_min_pool_size, $database_min_pool_size) $database_max_pool_size_real = pick($::barbican::database_max_pool_size, $database_max_pool_size) $database_max_retries_real = pick($::barbican::database_max_retries, $database_max_retries) $database_retry_interval_real = pick($::barbican::database_retry_interval, $database_retry_interval) 'database/connection': value => $database_connection_real, secret => true; 'database/idle_timeout': value => $database_idle_timeout_real; 'database/min_pool_size': value => $database_min_pool_size_real; 'database/max_retries': value => $database_max_retries_real; 'database/retry_interval': value => $database_retry_interval_real; 'database/max_pool_size': value => $database_max_pool_size_real; 'database/max_overflow': value => $database_max_overflow_real;",19,44
openstack%2Fpuppet-barbican~master~I1fb742b2459b149a4bb634c5b83bdcfcefac0deb,openstack/puppet-barbican,master,I1fb742b2459b149a4bb634c5b83bdcfcefac0deb,Use localhost for host_href,MERGED,2016-05-10 17:38:28.000000000,2016-05-11 13:39:02.000000000,2016-05-11 13:39:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-05-10 17:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/5b92922ea56344ccabaacab97b05f7c3ce478dd0', 'message': 'Use localhost for host_href\n\nThis change updates the acceptance tests to specify\nhttp://localhost:9311 for the acceptance tests to prevent any external\nnetwork access attempts during testing.\n\nChange-Id: I1fb742b2459b149a4bb634c5b83bdcfcefac0deb\n'}, {'number': 2, 'created': '2016-05-10 18:25:32.000000000', 'files': ['spec/acceptance/basic_barbican_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/406cd9d6cab498edb246d703851d1924c7848736', 'message': 'Use localhost for host_href\n\nThis change updates the acceptance tests to specify\nhttp://localhost:9311 for the acceptance tests to prevent any external\nnetwork access attempts during testing.\n\nChange-Id: I1fb742b2459b149a4bb634c5b83bdcfcefac0deb\n'}]",0,314693,406cd9d6cab498edb246d703851d1924c7848736,11,5,2,14985,,,0,"Use localhost for host_href

This change updates the acceptance tests to specify
http://localhost:9311 for the acceptance tests to prevent any external
network access attempts during testing.

Change-Id: I1fb742b2459b149a4bb634c5b83bdcfcefac0deb
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/93/314693/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_barbican_spec.rb'],1,5b92922ea56344ccabaacab97b05f7c3ce478dd0,beaker_host_ref, host_href => 'http://localhost:9311',,1,0
openstack%2Fproject-team-guide~master~Ib361b1ecd25930b1144cc97e2fa891afb4361bc6,openstack/project-team-guide,master,Ib361b1ecd25930b1144cc97e2fa891afb4361bc6,stable: link to section on proposing fixes for proposing fixes,MERGED,2016-02-15 19:51:48.000000000,2016-05-11 13:38:56.000000000,2016-05-11 13:38:56.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 4264}, {'_account_id': 6159}, {'_account_id': 9656}, {'_account_id': 12898}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-15 19:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/7f4784950c656ff21e6262e7bda13eb4f3cea3f6', 'message': ""stable: link to section on proposing fixes for proposing fixes\n\nThe comment about seeing the infra manual for proposing fixes is\nactually something that doesn't exist anymore, so just link back\nto the internal section on proposing fixes.\n\nChange-Id: Ib361b1ecd25930b1144cc97e2fa891afb4361bc6\n""}, {'number': 2, 'created': '2016-02-15 21:50:56.000000000', 'files': ['doc/source/stable-branches.rst'], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/a3d22772a6ca6d018492355a42178462e5d1e3cb', 'message': ""stable: link to section on proposing fixes for proposing fixes\n\nThe comment about seeing the infra manual for proposing fixes is\nactually something that doesn't exist anymore, so just link back\nto the internal section on proposing fixes.\n\nChange-Id: Ib361b1ecd25930b1144cc97e2fa891afb4361bc6\n""}]",6,280376,a3d22772a6ca6d018492355a42178462e5d1e3cb,15,8,2,6873,,,0,"stable: link to section on proposing fixes for proposing fixes

The comment about seeing the infra manual for proposing fixes is
actually something that doesn't exist anymore, so just link back
to the internal section on proposing fixes.

Change-Id: Ib361b1ecd25930b1144cc97e2fa891afb4361bc6
",git fetch https://review.opendev.org/openstack/project-team-guide refs/changes/76/280376/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/stable-branches.rst'],1,7f4784950c656ff21e6262e7bda13eb4f3cea3f6,define-active-stable,Anyone can propose stable branch backports. See `Proposing Fixes`_ for more,Anyone can propose stable branch backports. See the Infra manual for more,1,1
openstack%2Fproject-team-guide~master~I4f6866e75aaed54608a8739ccd7f3ca3d268b419,openstack/project-team-guide,master,I4f6866e75aaed54608a8739ccd7f3ca3d268b419,Clarify what are cross-project specs,MERGED,2016-03-22 16:29:59.000000000,2016-05-11 13:38:49.000000000,2016-05-11 13:38:49.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 308}, {'_account_id': 330}, {'_account_id': 2417}, {'_account_id': 2419}, {'_account_id': 2472}, {'_account_id': 2537}, {'_account_id': 2750}, {'_account_id': 2834}, {'_account_id': 2889}, {'_account_id': 4393}, {'_account_id': 5545}, {'_account_id': 5623}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6537}, {'_account_id': 7225}, {'_account_id': 7665}, {'_account_id': 7973}, {'_account_id': 8005}, {'_account_id': 8099}, {'_account_id': 8215}, {'_account_id': 8246}, {'_account_id': 8731}, {'_account_id': 8797}, {'_account_id': 9562}, {'_account_id': 10343}, {'_account_id': 10584}, {'_account_id': 10670}, {'_account_id': 11536}, {'_account_id': 11564}, {'_account_id': 11800}, {'_account_id': 12404}, {'_account_id': 12651}, {'_account_id': 13380}, {'_account_id': 14091}, {'_account_id': 14509}, {'_account_id': 15521}, {'_account_id': 16157}, {'_account_id': 16708}, {'_account_id': 17860}, {'_account_id': 19563}, {'_account_id': 21439}]","[{'number': 1, 'created': '2016-03-22 16:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/6720c0f212e17424c0d889623158da15c6134227', 'message': ""Clarify what are cross-project specs\n\nBased on discussions from a previous cross-project meeting, there's not\na clear agreement of what these specification should be. This also\nexplains the process of proposing and setting up meetings.\n\nChange-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419\n""}, {'number': 2, 'created': '2016-04-05 16:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/4db881c6731ef0b7394bcfa48592a04e803a69ef', 'message': ""Clarify what are cross-project specs\n\nBased on discussions from a previous cross-project meeting, there's not\na clear agreement of what these specification should be. This also\nexplains the process of proposing and setting up meetings.\n\nChange-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419\n""}, {'number': 3, 'created': '2016-04-07 13:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/dbb3299cf51d1af89c9796fd94f478ab7abc994a', 'message': ""Clarify what are cross-project specs\n\nBased on discussions from a previous cross-project meeting, there's not\na clear agreement of what these specification should be. This also\nexplains the process of proposing and setting up meetings.\n\nChange-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419\n""}, {'number': 4, 'created': '2016-04-14 19:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/0b7e5f811e7998eabda02b0ea020c480ab24766d', 'message': ""Clarify what are cross-project specs\n\nBased on discussions from a previous cross-project meeting, there's not\na clear agreement of what these specification should be. This also\nexplains the process of proposing and setting up meetings.\n\nChange-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419\n""}, {'number': 5, 'created': '2016-04-18 22:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/6e6569c79ba39f2fd050f51b1c0b59b9db3d507d', 'message': ""Clarify what are cross-project specs\n\nBased on discussions from a previous cross-project meeting, there's not\na clear agreement of what these specification should be. This also\nexplains the process of proposing and setting up meetings.\n\nChange-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419\n""}, {'number': 6, 'created': '2016-04-18 22:12:37.000000000', 'files': ['doc/source/cross-project.rst'], 'web_link': 'https://opendev.org/openstack/project-team-guide/commit/ae399d31cd4cb3608e13423be7a1ae4a23230b37', 'message': ""Clarify what are cross-project specs\n\nBased on discussions from a previous cross-project meeting, there's not\na clear agreement of what these specification should be. This also\nexplains the process of proposing and setting up meetings.\n\nChange-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419\n""}]",46,295940,ae399d31cd4cb3608e13423be7a1ae4a23230b37,58,45,6,170,,,0,"Clarify what are cross-project specs

Based on discussions from a previous cross-project meeting, there's not
a clear agreement of what these specification should be. This also
explains the process of proposing and setting up meetings.

Change-Id: I4f6866e75aaed54608a8739ccd7f3ca3d268b419
",git fetch https://review.opendev.org/openstack/project-team-guide refs/changes/40/295940/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/cross-project.rst'],1,6720c0f212e17424c0d889623158da15c6134227,301822,"What are Specifications? ------------------------ These documents are for problems that exist with **more than one** project. Not everything that meets this criteria is required to go through this process. Since these specifications are cross-project, they should consist mainly of: * General concept of the problem. * General solutions to the problem. (e.g. shared/OSLO libraries) or best practices. A specification will have a list of projects it involves, and their linked blueprint. A project may choose to write a more detailed specification within their own project specification repository if necessary. Proposing A Specification ------------------------- Create ^^^^^^ #. If you haven't already, read our `developer guide`_. #. git clone https://git.openstack.org/openstack/openstack-specs #. Use the provided `template`_. #. Push to gerrit for review. #. Propose `agenda items`_ to the Cross-Project meeting, and make sure someone who understands the subject can attend the meeting to answer questions. Agreement ^^^^^^^^^ Once the `Cross-Project Spec Liaisons`_ from the list of effected projects agree on a cross-project specification, the Technical Committee will review it for approval. Rolling Out the Change ^^^^^^^^^^^^^^^^^^^^^^ As mentioned in the `Cross-Project Spec Liaisons`_ responsibilities, it's up to them to communicate with the PTL of the project of this initiative. Depending on availability of resources and the project's priorities, these changes might not roll out right away. `Cross-Project Spec Liaisons`_ wiki page.Meetings ======== General ------- The cross-project meeting occurs if there are `agenda items`_ proposed by the community that involve the attention of the `Cross-Project Spec Liaisons`_. Sub Cross-Project Meetings -------------------------- For ideas that take more than a couple of meetings to discuss, it's recommended to break out into a group with all effected projects' `Cross-Project Spec Liaisons`_, and iterate together through a specification. Propose A Sub Cross-Project Meeting ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ #. Clone https://git.openstack.org/openstack-infra/irc-meetings #. In the meetings directory add a file in the format of <name>_wg.rst, where <name> should be something to identify your groups initiative. Use this example for the file content of service-catalog-wg.rst:: project: Service Catalog TNG Working Group Virtual Standup meeting_id: service_catalog_tng agenda_url: https://wiki.openstack.org/wiki/Meetings/ServiceCatalogTNG schedule: - time: '1500' day: Thursday irc: openstack-meeting-cp frequency: weekly start_date: 20160107 chair: Sean Dague (sdague), Anne Gentle (annegentle) description: > This is a weekly 30 minute virtual standup to see where our progress is for the overall effort. It is assumed most folks won't attend the meeting but will instead update our virtual standup etherpad before the meeting. This will just be a checkpoint and point at the top issue that needs to be focussed on for the next week. .. _developer guide: http://docs.openstack.org/infra/manual/developers.html .. _template: http://git.openstack.org/cgit/openstack/openstack-specs/plain/template.rst .. _specification: http://git.openstack.org/cgit/openstack/openstack-specs/tree/template.rst .. _Cross-Project Spec Liaisons: https://wiki.openstack.org/wiki/CrossProjectLiaisons#Cross-Project_Spec_Liaisons.. _agenda items: https://wiki.openstack.org/wiki/Meetings/CrossProjectMeeting#Proposed_agenda",CrossProjectLiaisons_ wiki page. .. _CrossProjectLiaisons: https://wiki.openstack.org/wiki/CrossProjectLiaisons,91,2
openstack%2Fopenstack-ansible-lxc_hosts~master~Ifb5b23e2b472bf0c738a01acefba578754f20b4f,openstack/openstack-ansible-lxc_hosts,master,Ifb5b23e2b472bf0c738a01acefba578754f20b4f,Correct LXC host public key check,MERGED,2016-05-11 12:35:55.000000000,2016-05-11 13:34:55.000000000,2016-05-11 13:34:55.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-11 12:35:55.000000000', 'files': ['tasks/main.yml', 'releasenotes/notes/ssh-pub-key-check-c42309653dbe3493.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/b93b84c59c7be1da7f0e1e0e397828a83db0d051', 'message': 'Correct LXC host public key check\n\nIn I167446eee35e40cde645873fbab7491f840dcd15 a pre-flight check\nwas introduced to validate whether an ssh public key is available\nbefore doing anything on the LXC hosts.\n\nThe check is supposed to validate that the requirements for the\nlookup are available. The lookup is executed on the deployment\nhost, not the target host. The check was therefore incorrect.\n\nThis patch corrects it to ensure that it does the check in the\nright places.\n\nChange-Id: Ifb5b23e2b472bf0c738a01acefba578754f20b4f\n'}]",0,315008,b93b84c59c7be1da7f0e1e0e397828a83db0d051,10,3,1,6816,,,0,"Correct LXC host public key check

In I167446eee35e40cde645873fbab7491f840dcd15 a pre-flight check
was introduced to validate whether an ssh public key is available
before doing anything on the LXC hosts.

The check is supposed to validate that the requirements for the
lookup are available. The lookup is executed on the deployment
host, not the target host. The check was therefore incorrect.

This patch corrects it to ensure that it does the check in the
right places.

Change-Id: Ifb5b23e2b472bf0c738a01acefba578754f20b4f
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/08/315008/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'releasenotes/notes/ssh-pub-key-check-c42309653dbe3493.yaml']",2,b93b84c59c7be1da7f0e1e0e397828a83db0d051,,"--- fixes: - The check to validate whether an appropriate ssh public key is available to copy into the container cache has been corrected to check the deployment host, not the LXC host. ",,10,4
openstack%2Foslo.concurrency~master~I0abc5403851f9ab2f78cdf26d29b82c3ec76ec25,openstack/oslo.concurrency,master,I0abc5403851f9ab2f78cdf26d29b82c3ec76ec25,Fix wrong import example in docstring,MERGED,2016-05-11 11:23:13.000000000,2016-05-11 13:29:32.000000000,2016-05-11 13:29:32.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1669}]","[{'number': 1, 'created': '2016-05-11 11:23:13.000000000', 'files': ['oslo_concurrency/lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/7279c316c8705be527d67d1942c8ad496302bb38', 'message': 'Fix wrong import example in docstring\n\nChange-Id: I0abc5403851f9ab2f78cdf26d29b82c3ec76ec25\n'}]",0,314978,7279c316c8705be527d67d1942c8ad496302bb38,7,3,1,9796,,,0,"Fix wrong import example in docstring

Change-Id: I0abc5403851f9ab2f78cdf26d29b82c3ec76ec25
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/78/314978/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_concurrency/lockutils.py'],1,7279c316c8705be527d67d1942c8ad496302bb38,fix_doc, from oslo_concurrency import lockutils from oslo_concurrency import lockutils, from nova.openstack.common import lockutils from nova.openstack.common import lockutils,2,2
openstack%2Foslo.concurrency~master~Ieb4a5aac33b69f4cd7a4c0761836cb6bee087430,openstack/oslo.concurrency,master,Ieb4a5aac33b69f4cd7a4c0761836cb6bee087430,Trivial: ignore openstack/common in flake8 exclude list,MERGED,2016-05-11 11:19:41.000000000,2016-05-11 13:29:27.000000000,2016-05-11 13:29:27.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1669}]","[{'number': 1, 'created': '2016-05-11 11:19:41.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/45cf9f0a9e69907f741651217493258965baf138', 'message': ""Trivial: ignore openstack/common in flake8 exclude list\n\nThe directory openstack/common doesn't exist any more.\nSo remove it from flake8 exclude list.\n\nChange-Id: Ieb4a5aac33b69f4cd7a4c0761836cb6bee087430\n""}]",0,314975,45cf9f0a9e69907f741651217493258965baf138,7,3,1,9796,,,0,"Trivial: ignore openstack/common in flake8 exclude list

The directory openstack/common doesn't exist any more.
So remove it from flake8 exclude list.

Change-Id: Ieb4a5aac33b69f4cd7a4c0761836cb6bee087430
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/75/314975/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,45cf9f0a9e69907f741651217493258965baf138,oslo_incubator_cleanup,"exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,build","exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,build",1,1
openstack%2Fpython-openstackclient~master~I6eb0c4e7d5d3e677764b253e3324720a784a110b,openstack/python-openstackclient,master,I6eb0c4e7d5d3e677764b253e3324720a784a110b,"Add unit tests for ""server show"" command",MERGED,2016-05-10 11:41:52.000000000,2016-05-11 13:26:55.000000000,2016-05-11 13:26:55.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-05-10 11:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/201c9e6686768519b0710a3eab7389b6716d4e19', 'message': 'Add unit tests for ""server show"" command\n\nChange-Id: I6eb0c4e7d5d3e677764b253e3324720a784a110b\n'}, {'number': 2, 'created': '2016-05-11 01:40:17.000000000', 'files': ['openstackclient/tests/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/06780dd880a316ce4f0750f22c794916aa904fcf', 'message': 'Add unit tests for ""server show"" command\n\nChange-Id: I6eb0c4e7d5d3e677764b253e3324720a784a110b\n'}]",0,314519,06780dd880a316ce4f0750f22c794916aa904fcf,9,3,2,14937,,,0,"Add unit tests for ""server show"" command

Change-Id: I6eb0c4e7d5d3e677764b253e3324720a784a110b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/19/314519/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/compute/v2/test_server.py'],1,201c9e6686768519b0710a3eab7389b6716d4e19,test_server_show-20160505,"class TestServerShow(TestServer): def setUp(self): super(TestServerShow, self).setUp() self.image = image_fakes.FakeImage.create_one_image() self.flavor = compute_fakes.FakeFlavor.create_one_flavor() server_info = { 'image': {'id': self.image.id}, 'flavor': {'id': self.flavor.id}, 'tenant_id': 'tenant-id-xxx', 'networks': {'public': ['10.20.30.40', '2001:db8::f']}, } # Fake the server.diagnostics() method. The return value contains http # response and data. The data is a dict. Sincce this method itself is # faked, we don't need to fake everything of the return value exactly. resp = mock.Mock() resp.status_code = 200 server_method = { 'diagnostics': (resp, {'test': 'test'}), } self.server = compute_fakes.FakeServer.create_one_server( attrs=server_info, methods=server_method) # This is the return value for utils.find_resource() self.servers_mock.get.return_value = self.server self.cimages_mock.get.return_value = self.image self.flavors_mock.get.return_value = self.flavor # Get the command object to test self.cmd = server.ShowServer(self.app, None) self.columns = ( 'addresses', 'flavor', 'id', 'image', 'name', 'networks', 'project_id', 'properties', ) self.data = ( 'public=10.20.30.40, 2001:db8::f', self.flavor.name + "" ("" + self.flavor.id + "")"", self.server.id, self.image.name + "" ("" + self.image.id + "")"", self.server.name, {'public': ['10.20.30.40', '2001:db8::f']}, 'tenant-id-xxx', '', ) def test_show_no_options(self): arglist = [] verifylist = [] self.assertRaises(utils.ParserException, self.check_parser, self.cmd, arglist, verifylist) def test_show(self): arglist = [ self.server.name, ] verifylist = [ ('diagnostics', False), ('server', self.server.name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) columns, data = self.cmd.take_action(parsed_args) self.assertEqual(self.columns, columns) self.assertEqual(self.data, data) def test_show_diagnostics(self): arglist = [ '--diagnostics', self.server.name, ] verifylist = [ ('diagnostics', True), ('server', self.server.name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) columns, data = self.cmd.take_action(parsed_args) self.assertEqual(('test',), columns) self.assertEqual(('test',), data) ",,93,0
openstack%2Fpython-openstackclient~master~I8d79afc5f341fb5caf771d905506b7f1c7a41ae8,openstack/python-openstackclient,master,I8d79afc5f341fb5caf771d905506b7f1c7a41ae8,Use find_resource() instead of get() in _prep_server_detail(),MERGED,2016-05-09 07:03:17.000000000,2016-05-11 13:26:30.000000000,2016-05-11 13:26:29.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-05-09 07:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/84f7c2165c411445506ebc1db8182b31eeafea6c', 'message': 'Use find_resource() instead of get() in _prep_server_detail()\n\nThere is such a comment in test_server.py:\n\n    # Call .get() to retrieve all of the server information\n    # as findall(name=blah) and REST /details are not the same\n    # and do not return flavor and image information.\n\nThis is an out of date comment. There is no function named\nfindall() in OSC now. So use find_resource() instead of get(),\nand remove this comment.\n\nChange-Id: I8d79afc5f341fb5caf771d905506b7f1c7a41ae8\n'}, {'number': 2, 'created': '2016-05-09 07:28:30.000000000', 'files': ['openstackclient/tests/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d58280a27989ab781cbf2598a6f7c263cb2275e8', 'message': 'Use find_resource() instead of get() in _prep_server_detail()\n\nThere is such a comment in test_server.py:\n\n    # Call .get() to retrieve all of the server information\n    # as findall(name=blah) and REST /details are not the same\n    # and do not return flavor and image information.\n\nThis is an out of date comment. There is no function named\nfindall() in OSC now. So use find_resource() instead of get(),\nand remove this comment.\n\nChange-Id: I8d79afc5f341fb5caf771d905506b7f1c7a41ae8\n'}]",4,313997,d58280a27989ab781cbf2598a6f7c263cb2275e8,13,3,2,14937,,,0,"Use find_resource() instead of get() in _prep_server_detail()

There is such a comment in test_server.py:

    # Call .get() to retrieve all of the server information
    # as findall(name=blah) and REST /details are not the same
    # and do not return flavor and image information.

This is an out of date comment. There is no function named
findall() in OSC now. So use find_resource() instead of get(),
and remove this comment.

Change-Id: I8d79afc5f341fb5caf771d905506b7f1c7a41ae8
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/97/313997/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py']",2,84f7c2165c411445506ebc1db8182b31eeafea6c,no-findall-20160509," server = utils.find_resource(compute_client.servers, info['id'])", # Call .get() to retrieve all of the server information # as findall(name=blah) and REST /details are not the same # and do not return flavor and image information. server = compute_client.servers.get(info['id']),7,11
openstack%2Fwatcher~master~I98541810139d9d4319ac89f21a5e0bc25454ee62,openstack/watcher,master,I98541810139d9d4319ac89f21a5e0bc25454ee62,"Log ""https"" if using SSL",MERGED,2016-05-10 14:49:33.000000000,2016-05-11 13:24:43.000000000,2016-05-11 13:24:43.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 18971}, {'_account_id': 20676}, {'_account_id': 21522}]","[{'number': 1, 'created': '2016-05-10 14:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b0a6eb71bbf0b5cbf64b059c32567dbee564e8d4', 'message': 'Log ""https"" if using SSL\n\nWhen starting the Watcher API service, the URI it served to is shown in\na log message. In this log message (in watcher/cmd/api.py) take into\naccount the case where SSL has been enabled with CONF.api.enable_ssl_api\nset to True and format this log message accordingly.\n\nChange-Id: I98541810139d9d4319ac89f21a5e0bc25454ee62\nCloses-Bug: #1580044\n'}, {'number': 2, 'created': '2016-05-10 15:47:28.000000000', 'files': ['watcher/cmd/api.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/76e3d2e2f6c09e19f748971d509937b64cf46f45', 'message': 'Log ""https"" if using SSL\n\nWhen starting the Watcher API service, the URI it served to is shown in\na log message. In this log message (in watcher/cmd/api.py) take into\naccount the case where SSL has been enabled with CONF.api.enable_ssl_api\nset to True and format this log message accordingly.\n\nChange-Id: I98541810139d9d4319ac89f21a5e0bc25454ee62\nCloses-Bug: #1580044\n'}]",5,314610,76e3d2e2f6c09e19f748971d509937b64cf46f45,12,5,2,21522,,,0,"Log ""https"" if using SSL

When starting the Watcher API service, the URI it served to is shown in
a log message. In this log message (in watcher/cmd/api.py) take into
account the case where SSL has been enabled with CONF.api.enable_ssl_api
set to True and format this log message accordingly.

Change-Id: I98541810139d9d4319ac89f21a5e0bc25454ee62
Closes-Bug: #1580044
",git fetch https://review.opendev.org/openstack/watcher refs/changes/10/314610/1 && git format-patch -1 --stdout FETCH_HEAD,['watcher/cmd/api.py'],1,b0a6eb71bbf0b5cbf64b059c32567dbee564e8d4,bug/1580044," host, port = CONF.api.host, CONF.api.port prefix = 'http' try: if CONF.api.enable_ssl_api: prefix = 'https' except cfg.NoSuchOptError: pass CONF.log_opt_values(LOG, std_logging.DEBUG) 'view at %(prefix)s://127.0.0.1:%(port)s') % dict(prefix=prefix, port=port)) else: LOG.info(_('serving on %(prefix)s://%(host)s:%(port)s') % dict(prefix=prefix, host=host, port=port))"," host, port = cfg.CONF.api.host, cfg.CONF.api.port cfg.CONF.log_opt_values(LOG, std_logging.DEBUG) 'view at http://127.0.0.1:%(port)s') % dict(port=port)) else: LOG.info(_('serving on http://%(host)s:%(port)s') % dict(host=host, port=port))",12,6
openstack%2Fnetworking-generic-switch~master~I02e6f1c1196f53d13f3f4446bcd7b24e69376de7,openstack/networking-generic-switch,master,I02e6f1c1196f53d13f3f4446bcd7b24e69376de7,Add switch configuration format,MERGED,2016-04-27 08:29:41.000000000,2016-05-11 13:24:37.000000000,2016-05-11 13:24:37.000000000,"[{'_account_id': 3}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-04-27 08:29:41.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/3d5acfba80e83537fa74de273f7f46ddadc5cd38', 'message': 'Add switch configuration format\n\nSpecify supported parameters when configuring a switch.\n\nChange-Id: I02e6f1c1196f53d13f3f4446bcd7b24e69376de7\nCloses-Bug: #1575503\n'}]",0,310368,3d5acfba80e83537fa74de273f7f46ddadc5cd38,7,2,1,6610,,,0,"Add switch configuration format

Specify supported parameters when configuring a switch.

Change-Id: I02e6f1c1196f53d13f3f4446bcd7b24e69376de7
Closes-Bug: #1575503
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/68/310368/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3d5acfba80e83537fa74de273f7f46ddadc5cd38,bug/1575503, Switch configuration format:: [genericswitch:<switch name>] device_type = <netmiko device type> ip = <IP address of switch> port = <ssh port> username = <credential username> password = <credential password> key_file = <ssh key file> secret = <enable secret> port = 8222,,13,0
openstack%2Fnetworking-generic-switch~master~If474bedda43b571474bdfabfc3e8bf9f8f9b49cf,openstack/networking-generic-switch,master,If474bedda43b571474bdfabfc3e8bf9f8f9b49cf,Wrap error log message with i18n._LE(),MERGED,2016-04-27 09:51:39.000000000,2016-05-11 13:24:32.000000000,2016-05-11 13:24:32.000000000,"[{'_account_id': 3}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-04-27 09:51:39.000000000', 'files': ['networking_generic_switch/devices/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/494f0271cee788f03acc83749f798926730b992b', 'message': 'Wrap error log message with i18n._LE()\n\nChange-Id: If474bedda43b571474bdfabfc3e8bf9f8f9b49cf\n'}]",0,310392,494f0271cee788f03acc83749f798926730b992b,7,2,1,6610,,,0,"Wrap error log message with i18n._LE()

Change-Id: If474bedda43b571474bdfabfc3e8bf9f8f9b49cf
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/92/310392/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_generic_switch/devices/__init__.py'],1,494f0271cee788f03acc83749f798926730b992b,,"from networking_generic_switch._i18n import _LE LOG.error(_LE(""Driver manager %(manager)s failed to load device plugin "" ""%(entrypoint)s: %(exp)s""), {'manager': manager, 'entrypoint': entrypoint, 'exp': exception})"," LOG.error(""Driver manager %s failed to load device plugin %s: %s"" % ( manager, entrypoint, exception))",4,2
openstack%2Fnova~master~Id542ba32d95f67820da112bfc994b9878c998aaa,openstack/nova,master,Id542ba32d95f67820da112bfc994b9878c998aaa,Corrected the typo.,MERGED,2016-05-11 10:33:48.000000000,2016-05-11 13:17:42.000000000,2016-05-11 12:19:49.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7634}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16237}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-05-11 10:33:48.000000000', 'files': ['api-ref/source/servers-actions.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/3300cdfcfb20045b7626e973f41bcbb0aa4030c2', 'message': 'Corrected the typo.\n\nChange-Id: Id542ba32d95f67820da112bfc994b9878c998aaa\nCloses-Bug: #1580536\n'}]",1,314957,3300cdfcfb20045b7626e973f41bcbb0aa4030c2,16,11,1,20863,,,0,"Corrected the typo.

Change-Id: Id542ba32d95f67820da112bfc994b9878c998aaa
Closes-Bug: #1580536
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/314957/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/servers-actions.inc'],1,3300cdfcfb20045b7626e973f41bcbb0aa4030c2,bug/1580536,Enables all users to perform an action on a server. Specify the action,Enables all users to performs an action on a server. Specify the action,1,1
openstack%2Ftripleo-puppet-elements~master~I574ebb0ad0164a3eca3f6bb02312adf960342f86,openstack/tripleo-puppet-elements,master,I574ebb0ad0164a3eca3f6bb02312adf960342f86,Add puppet-barbican to puppet-modules.,MERGED,2016-03-17 12:52:17.000000000,2016-05-11 13:16:45.000000000,2016-05-11 13:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-03-17 12:52:17.000000000', 'files': ['elements/puppet-modules/environment.d/01-puppet-modules-install-types.sh', 'elements/puppet-modules/source-repository-puppet-modules'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/eb4bd7838148c4132e89a3cc79a897873e8d64d7', 'message': 'Add puppet-barbican to puppet-modules.\n\nChange-Id: I574ebb0ad0164a3eca3f6bb02312adf960342f86\n'}]",0,294001,eb4bd7838148c4132e89a3cc79a897873e8d64d7,11,4,1,360,,,0,"Add puppet-barbican to puppet-modules.

Change-Id: I574ebb0ad0164a3eca3f6bb02312adf960342f86
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/01/294001/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/puppet-modules/environment.d/01-puppet-modules-install-types.sh', 'elements/puppet-modules/source-repository-puppet-modules']",2,eb4bd7838148c4132e89a3cc79a897873e8d64d7,barbican_puppet,puppet-barbican git /opt/stack/puppet-modules/barbican https://git.openstack.org/openstack/puppet-barbican.git,,2,0
openstack%2Fkeystone~master~Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9,openstack/keystone,master,Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9,WIP: Remove domain table references,ABANDONED,2015-03-19 17:33:41.000000000,2016-05-11 13:16:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6486}, {'_account_id': 8866}, {'_account_id': 8871}, {'_account_id': 10046}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 16246}]","[{'number': 1, 'created': '2015-03-19 17:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fe618e04e538c22fa12e6e3e0a027d4ffa5cb275', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 2, 'created': '2015-03-19 17:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a9d15e79bee7e11725a9f5358aa50de2643129c', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 3, 'created': '2015-03-19 20:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1f539626de8a17c28a1d2750dba8f0eb039146b2', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 4, 'created': '2015-03-24 13:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2b7f37ea63980f2d45eb90a0d0588499a42d2e2b', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 5, 'created': '2015-03-26 14:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/134d5d2b4094d8b7a5b308e3f2c1fa726c2637c3', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 6, 'created': '2015-03-26 17:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/75f407d29ad4410bbfd253fb451f502888afedf9', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 7, 'created': '2015-03-27 14:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c271ae2b3cfbd75d0408df157746eb48a6adaabf', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 8, 'created': '2015-04-02 14:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c46b9f93f3849ad404d1048a1450db4c9b69c33c', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 9, 'created': '2015-04-07 16:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5cf754f999dbf305a1bc9d90cda7411fac538732', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 10, 'created': '2015-04-07 19:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e4f9dd8fb96ebabf429d93103e164aa0daa51290', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 11, 'created': '2015-04-07 20:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/50b90de333ce4d06058f4ed072b1a45665b8e663', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 12, 'created': '2015-04-08 14:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/474e564eb7acead8c95dd0694cd7064655f40961', 'message': 'Stop calling domain drivers\n\nThis patch removes all references to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 13, 'created': '2015-04-08 20:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/705f28627db77567d28a646f7cc58aa132650325', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and updates the\nproject table domain_id FK, that once pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 14, 'created': '2015-04-10 20:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f12ce3aa4b9ee0859a2d511a83794861a9e5cb22', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and updates the\nproject table domain_id FK, that once pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 15, 'created': '2015-04-13 14:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aaa6517d39039c08a7209f7871322df422c5b018', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and updates the\nproject table domain_id FK, that once pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 16, 'created': '2015-04-13 17:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2d7ca21938589b4028619b6310e769f954950f6b', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and updates the\nproject table domain_id FK, that once pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 17, 'created': '2015-04-13 18:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5aa1813cf7b736be92d54646723bf9383516d5c9', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 18, 'created': '2015-04-29 17:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ef8718bacfd146856a25e645b3939a43c4538bca', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 19, 'created': '2015-04-29 17:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/14e3147145ff6360d38df733821b2e5b6fe7217c', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 20, 'created': '2015-05-06 19:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/577fb1ae4dbf7ef2b4fc954b69f18e10b788323f', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 21, 'created': '2015-05-07 16:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/42f006f47cb51acf7748eb64237f3cd77260c873', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 22, 'created': '2015-06-09 16:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/75a9bc7a9a38dc10e3b9b31f6f1556094489d08b', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 23, 'created': '2015-06-11 17:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/14657033f8735d069c53822bd0c334a755594cd6', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 24, 'created': '2015-06-11 20:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/39665e659d26a282ee251f75daf014715ea31ca4', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nThis patch is part of Reseller. Previous patches did:\n\n- Honor domain operations in project table\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nImplements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 25, 'created': '2015-06-29 18:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ebfdb84f3c89a3f87a5222ecff04bccf8a52d8c4', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 26, 'created': '2015-06-30 12:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9202af0f344df033adbc026862d3417caded01d5', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 27, 'created': '2015-06-30 15:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ca6c093badbfe5105eb369d24a7b6c6408cc427f', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 28, 'created': '2015-07-14 01:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a85492f93a5f9ac21aeb5ae90da9c59b814b3925', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 29, 'created': '2015-07-16 17:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8c31e5e2572f899165ce5bbea11ab822afe274f7', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 30, 'created': '2015-07-23 23:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f3156a5526b48b2114ab94b540f66e422dc97725', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 31, 'created': '2015-07-25 01:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f029f9278056755fa403bc5d60ddd511a3409757', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 32, 'created': '2015-07-26 22:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1acb124b83be25e512bf55afd3ddf2e9bdee47ef', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 33, 'created': '2015-07-27 13:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/be27315c6397f2bd700fb40601793672dc399208', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 34, 'created': '2015-07-27 15:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a1b831481cbb1276e0362ab1729c17a6c14ec065', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 35, 'created': '2015-07-28 15:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/43085836d8fbef62f51360a807ea56fb82cee162', 'message': 'Remove domain table references\n\nThis patch removes all references to the domain table, and removes the\nproject table domain_id FK, that pointed to the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 36, 'created': '2015-08-05 19:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/25374814fd9915b9bb8a3ab923cb736852344358', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 37, 'created': '2015-08-08 00:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f5811b65c6efaba64e9dea8380bbf8213af0010', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 38, 'created': '2015-08-10 20:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c0dec9e1cc0ac0b17623916f505e9e3f1808b0db', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 39, 'created': '2015-08-11 15:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2894da6dd26a163ab7d32a2cbd0f5b6c83cce867', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 40, 'created': '2015-09-02 02:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6ca0ca1deb8e2cff6c267a55ed990d4c227d6c32', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 41, 'created': '2015-09-03 15:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ab7847ff8ff4d7786ae373ed9640022ba4d96d42', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 42, 'created': '2015-09-30 13:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f2d3df2ac5c8408394e88825915e63f542d03954', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 43, 'created': '2015-10-01 00:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2963ce4c175f92c6038101b2136813a28a5c16b1', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 44, 'created': '2015-10-08 14:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57c5fd4d9c88656b4bbc709eb3223cd4cf26934a', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 45, 'created': '2015-10-13 16:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f0d05dbc6d87b443cfb5401d6a05bee3f9b8b15b', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\nIt also removes the project table domain_id FK, that point to domain\ntable.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 46, 'created': '2015-10-15 21:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/101eef2507a32cc3c8b41357b6f7c8caab698294', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 47, 'created': '2015-10-19 20:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/30dfc614b35037000f51ba8a05cfd24ef5b67a20', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 48, 'created': '2015-10-27 05:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6ec2739f4edca09931c25c77a06a4de6bc0f356d', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 49, 'created': '2015-10-28 03:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a7493233e8ab8a311e02dacaae96cdd6cbff5a5', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 50, 'created': '2015-10-30 07:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/98e271fe5f9271a4ba32ae5f30621dc39829966f', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 51, 'created': '2015-11-04 16:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b35fa7cb095561a0e6b3579ae4e85f81cc582aa3', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 52, 'created': '2015-11-13 13:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eecea7dae9c825d65d50ac9bd451f23b2d598845', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 53, 'created': '2015-11-18 16:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4cc72fe18a9a3494a3f62d18e17e958f8fcfdad0', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 54, 'created': '2015-11-19 16:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/02380ab6944497069712cf9b6ff808da091a6c2e', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 55, 'created': '2015-11-20 17:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cdaeffe02f9458d1defc64a044279c528ef8ca46', 'message': 'Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}, {'number': 56, 'created': '2016-01-25 07:44:46.000000000', 'files': ['keystone/common/models.py', 'keystone/resource/backends/sql.py', 'keystone/resource/core.py', 'keystone/tests/unit/test_backend_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/17134dca49ec3dabbaa7071a5de25f63cd54f0f5', 'message': 'WIP: Remove domain table references\n\nRemoves all Manager and Driver calls that used the domain table.\n\nTODO: keystone-manage\n\nCo-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>\n\nPartially-Implements: bp reseller\n\nChange-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9\n'}]",24,165936,17134dca49ec3dabbaa7071a5de25f63cd54f0f5,143,11,56,11022,,,0,"WIP: Remove domain table references

Removes all Manager and Driver calls that used the domain table.

TODO: keystone-manage

Co-Authored-By: Henrique Truta <henrique@lsd.ufcg.edu.br>
Co-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>
Co-Authored-By: Erickson Santos <erickson@lsd.ufcg.edu.br>

Partially-Implements: bp reseller

Change-Id: Ie883caaa9f0dd7c1731691d23a7d43ab40b23fe9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/36/165936/6 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/models.py', 'keystone/resource/backends/ldap.py', 'keystone/resource/backends/sql.py', 'keystone/resource/core.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py', 'keystone/tests/unit/test_sql_upgrade.py']",7,fe618e04e538c22fa12e6e3e0a027d4ffa5cb275,bp/reseller, '''def test_drop_domain_table(self): self.upgrade(69) self.assertTableDoesNotExist('domain') self.downgrade(68) self.assertTableExists('domain')''' ,,73,157
openstack%2Fwatcher~master~If29158cc9b5e5e50f6c69d67c232cceeb07084f2,openstack/watcher,master,If29158cc9b5e5e50f6c69d67c232cceeb07084f2,Refactored DE and Applier to use oslo.service,MERGED,2016-03-18 12:24:23.000000000,2016-05-11 13:14:52.000000000,2016-05-11 13:14:52.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-03-18 12:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8f0e0db40dabe48ec656db71a5091777e5bd5f0c', 'message': 'Refactored DE and Applier to use oslo.service\n\nIn this PS, I have refactored the Decision Engine and the Applier\nto use the oslo service utility.\n\nChange-Id: If29158cc9b5e5e50f6c69d67c232cceeb07084f2\nCloses-Bug: #1541850\n'}, {'number': 2, 'created': '2016-03-18 13:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/e401972196e9f9537c1e24cfb4f5047ac8853adb', 'message': 'Refactored DE and Applier to use oslo.service\n\nIn this PS, I have refactored the Decision Engine and the Applier\nto use the oslo service utility.\n\nChange-Id: If29158cc9b5e5e50f6c69d67c232cceeb07084f2\nCloses-Bug: #1541850\n'}, {'number': 3, 'created': '2016-03-30 08:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6777efaffee3abc002d75378529ddb5fbda4cc79', 'message': 'Refactored DE and Applier to use oslo.service\n\nIn this PS, I have refactored the Decision Engine and the Applier\nto use the oslo service utility.\n\nChange-Id: If29158cc9b5e5e50f6c69d67c232cceeb07084f2\nCloses-Bug: #1541850\n'}, {'number': 4, 'created': '2016-04-22 09:01:21.000000000', 'files': ['watcher/decision_engine/messaging/audit_endpoint.py', 'watcher/applier/rpcapi.py', 'watcher/cmd/decisionengine.py', 'watcher/common/service.py', 'watcher/tests/cmd/test_applier.py', 'watcher/applier/manager.py', 'watcher/decision_engine/manager.py', 'watcher/cmd/applier.py', 'watcher/tests/common/messaging/test_messaging_handler.py', 'watcher/decision_engine/rpcapi.py', 'watcher/common/messaging/messaging_handler.py', 'watcher/tests/common/test_service.py', 'watcher/tests/cmd/test_decision_engine.py', 'watcher/tests/decision_engine/messaging/test_audit_endpoint.py', 'watcher/common/messaging/messaging_core.py', 'watcher/tests/applier/test_applier_manager.py', 'watcher/tests/common/messaging/test_messaging_core.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/eb861f86abd3c470ea7abac39e7ff23c26e7c9ab', 'message': 'Refactored DE and Applier to use oslo.service\n\nIn this PS, I have refactored the Decision Engine and the Applier\nto use the oslo service utility.\n\nChange-Id: If29158cc9b5e5e50f6c69d67c232cceeb07084f2\nCloses-Bug: #1541850\n'}]",22,294556,eb861f86abd3c470ea7abac39e7ff23c26e7c9ab,17,4,4,18971,,,0,"Refactored DE and Applier to use oslo.service

In this PS, I have refactored the Decision Engine and the Applier
to use the oslo service utility.

Change-Id: If29158cc9b5e5e50f6c69d67c232cceeb07084f2
Closes-Bug: #1541850
",git fetch https://review.opendev.org/openstack/watcher refs/changes/56/294556/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/messaging/audit_endpoint.py', 'watcher/applier/rpcapi.py', 'watcher/cmd/decisionengine.py', 'watcher/cmd/api.py', 'watcher/common/service.py', 'watcher/tests/cmd/test_applier.py', 'watcher/applier/manager.py', 'watcher/decision_engine/manager.py', 'watcher/cmd/applier.py', 'watcher/locale/watcher.pot', 'watcher/tests/common/messaging/test_messaging_handler.py', 'watcher/decision_engine/rpcapi.py', 'watcher/common/messaging/messaging_handler.py', 'watcher/tests/common/test_service.py', 'watcher/tests/cmd/test_decision_engine.py', 'watcher/tests/decision_engine/messaging/test_audit_endpoint.py', 'watcher/common/messaging/messaging_core.py', 'watcher/tests/applier/test_applier_manager.py']",18,8f0e0db40dabe48ec656db71a5091777e5bd5f0c,bug/1541850," from watcher.applier import manager as applier_manager from watcher.common import service from watcher.common.messaging import messaging_handler self.applier = service.Service(applier_manager.ApplierManager) @patch.object(messaging_handler.MessagingHandler, ""stop"") @patch.object(messaging_handler.MessagingHandler, ""start"") def test_start(self, m_messaging_start, m_messaging_stop): self.applier.start() self.applier.stop() self.assertEqual(2, m_messaging_start.call_count) self.assertEqual(2, m_messaging_stop.call_count)","from threading import Thread from watcher.applier.manager import ApplierManager from watcher.common.messaging.messaging_core import MessagingCore self.applier = ApplierManager() @patch.object(MessagingCore, ""connect"") @patch.object(Thread, ""join"") def test_connect(self, m_messaging, m_thread): self.applier.connect() self.applier.join() self.assertEqual(2, m_messaging.call_count) self.assertEqual(1, m_thread.call_count)",295,280
openstack%2Fpython-glanceclient~stable%2Fmitaka~I0db0fd7ab07a0d61082b86829a671d8dbc0f2963,openstack/python-glanceclient,stable/mitaka,I0db0fd7ab07a0d61082b86829a671d8dbc0f2963,Fix missing of debug info after we use session,MERGED,2016-04-26 10:14:30.000000000,2016-05-11 13:14:40.000000000,2016-05-11 13:14:40.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 11391}, {'_account_id': 20105}]","[{'number': 1, 'created': '2016-04-26 10:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/10fb0e04abd356bf414066ea3d318b657cb6e25b', 'message': ""Fix missing of debug info after we use session\n\nAfter the introduce of this patch set[1], cli user can't get debug\ninfo even --debug is passed. With the patch set[1], the request\naction will be performed in keystoneclient.session.Session.\nHowever the default log level of keystoneclient module is WARNING,\nso user can't get debug info from keystoneclient.session.Session.\n\nThis change set the root log level to DEBUG when --debug is\npassed.\n\n[1]: https://review.openstack.org/#/c/262220/\n\nChange-Id: I0db0fd7ab07a0d61082b86829a671d8dbc0f2963\nCloses-bug: 1551076\n""}, {'number': 2, 'created': '2016-04-26 10:24:16.000000000', 'files': ['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b1245621da4ef8cccff171e9516f3b7289dda407', 'message': ""Fix missing of debug info after we use session\n\nAfter the introduce of this patch set[1], cli user can't get debug\ninfo even --debug is passed. With the patch set[1], the request\naction will be performed in keystoneclient.session.Session.\nHowever the default log level of keystoneclient module is WARNING,\nso user can't get debug info from keystoneclient.session.Session.\n\nThis change set the root log level to DEBUG when --debug is\npassed.\n\n[1]: https://review.openstack.org/#/c/262220/\n\nChange-Id: I0db0fd7ab07a0d61082b86829a671d8dbc0f2963\nCloses-bug: 1551076\n(cherry picked from commit 87c8c933bd9b79a2cf06f9f0bc02160b21e8920d)\n""}]",0,310167,b1245621da4ef8cccff171e9516f3b7289dda407,9,4,2,16658,,,0,"Fix missing of debug info after we use session

After the introduce of this patch set[1], cli user can't get debug
info even --debug is passed. With the patch set[1], the request
action will be performed in keystoneclient.session.Session.
However the default log level of keystoneclient module is WARNING,
so user can't get debug info from keystoneclient.session.Session.

This change set the root log level to DEBUG when --debug is
passed.

[1]: https://review.openstack.org/#/c/262220/

Change-Id: I0db0fd7ab07a0d61082b86829a671d8dbc0f2963
Closes-bug: 1551076
(cherry picked from commit 87c8c933bd9b79a2cf06f9f0bc02160b21e8920d)
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/67/310167/2 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py']",2,10fb0e04abd356bf414066ea3d318b657cb6e25b,bug/1551076, if args.debug: # Set up the root logger to debug so that the submodules can # print debug messages logging.basicConfig(level=logging.DEBUG) # for iso8601 < 0.1.11 logging.getLogger('iso8601').setLevel(logging.WARNING),,21,0
openstack%2Fwatcher~master~I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd,openstack/watcher,master,I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd,Refactored Watcher API service,MERGED,2016-03-18 12:24:23.000000000,2016-05-11 13:14:29.000000000,2016-05-11 13:14:29.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20676}]","[{'number': 1, 'created': '2016-03-18 12:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/48ff47b8ebdacd89c5e40ca60a1d0240bca01051', 'message': 'Refactored Watcher API service\n\nThis patchset introduces the use of oslo.service to run the\nWatcher API service.\n\nChange-Id: I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd\nRelated-Bug: #1541850\n'}, {'number': 2, 'created': '2016-03-18 13:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3b68b56cff6a1461fa5f52c00c85194a8ca566b2', 'message': 'Refactored Watcher API service\n\nThis patchset introduces the use of oslo.service to run the\nWatcher API service.\n\nChange-Id: I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd\nRelated-Bug: #1541850\n'}, {'number': 3, 'created': '2016-03-30 08:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/10833ccdc8ad46b9c3b469401ba6feb7e9cd5530', 'message': 'Refactored Watcher API service\n\nThis patchset introduces the use of oslo.service to run the\nWatcher API service.\n\nChange-Id: I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd\nRelated-Bug: #1541850\n'}, {'number': 4, 'created': '2016-04-22 09:01:21.000000000', 'files': ['requirements.txt', 'watcher/api/app.py', 'watcher/locale/watcher.pot', 'watcher/cmd/api.py', 'watcher/common/service.py', 'watcher/tests/cmd/test_api.py', 'watcher/version.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/a9e7251d0d57015d752ca7e8b9ea1f1667d8ddc5', 'message': 'Refactored Watcher API service\n\nThis patchset introduces the use of oslo.service to run the\nWatcher API service.\n\nChange-Id: I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd\nRelated-Bug: #1541850\n'}]",15,294555,a9e7251d0d57015d752ca7e8b9ea1f1667d8ddc5,25,5,4,18971,,,0,"Refactored Watcher API service

This patchset introduces the use of oslo.service to run the
Watcher API service.

Change-Id: I6c38a3c1a2b4dc47388876e4c0ba61b7447690bd
Related-Bug: #1541850
",git fetch https://review.opendev.org/openstack/watcher refs/changes/55/294555/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'watcher/api/app.py', 'watcher/locale/watcher.pot', 'watcher/cmd/api.py', 'watcher/common/service.py', 'watcher/tests/cmd/test_api.py', 'watcher/version.py']",7,48ff47b8ebdacd89c5e40ca60a1d0240bca01051,bug/1541850,version_string = version_info.version_string,,151,151
openstack%2Ftripleo-ci~master~Ib48fee711af527aaff740b636531eaf787670766,openstack/tripleo-ci,master,Ib48fee711af527aaff740b636531eaf787670766,Ignore bash errors when posting metrics,MERGED,2016-04-18 17:01:38.000000000,2016-05-11 13:13:37.000000000,2016-05-11 13:13:37.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 3153}]","[{'number': 1, 'created': '2016-04-18 17:01:38.000000000', 'files': ['scripts/metrics.bash'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/713dbc76daa358fce5f98f1bf37c46e41ce84428', 'message': ""Ignore bash errors when posting metrics\n\nTreat metrics harvesting as optional so that even if posting\nmetrics fails it doesn't fail the associated CI job. We\naren't seeing issues with this yet... this is just a\nprecaution to avoid any job failures due to this sort of thing.\n\nChange-Id: Ib48fee711af527aaff740b636531eaf787670766\n""}]",0,307374,713dbc76daa358fce5f98f1bf37c46e41ce84428,11,3,1,360,,,0,"Ignore bash errors when posting metrics

Treat metrics harvesting as optional so that even if posting
metrics fails it doesn't fail the associated CI job. We
aren't seeing issues with this yet... this is just a
precaution to avoid any job failures due to this sort of thing.

Change-Id: Ib48fee711af527aaff740b636531eaf787670766
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/74/307374/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/metrics.bash'],1,713dbc76daa358fce5f98f1bf37c46e41ce84428,ignore_metrics_posting_errors, set +e #ignore errors posting metrics results set -e,,2,0
openstack%2Foslo.utils~master~I6f7f6bb9dd8b8e89979efd030a022d7455df67c7,openstack/oslo.utils,master,I6f7f6bb9dd8b8e89979efd030a022d7455df67c7,Trivial: ignore openstack/common in flake8 exclude list,MERGED,2016-05-11 06:46:01.000000000,2016-05-11 13:13:23.000000000,2016-05-11 13:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2016-05-11 06:46:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/12d4936f12ffaef1d8d1f753b2dc359e78205b34', 'message': ""Trivial: ignore openstack/common in flake8 exclude list\n\nThe directory openstack/common doesn't exist any more,\nso remove it from flake8 exclude list.\n\nChange-Id: I6f7f6bb9dd8b8e89979efd030a022d7455df67c7\n""}]",0,314885,12d4936f12ffaef1d8d1f753b2dc359e78205b34,6,2,1,9796,,,0,"Trivial: ignore openstack/common in flake8 exclude list

The directory openstack/common doesn't exist any more,
so remove it from flake8 exclude list.

Change-Id: I6f7f6bb9dd8b8e89979efd030a022d7455df67c7
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/85/314885/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,12d4936f12ffaef1d8d1f753b2dc359e78205b34,oslo_incubator_cleanup,"exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,build,__init__.py","exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,build,__init__.py",1,1
openstack%2Fsahara~master~I928712ef0c3a6b477da1d6cdae1fef6684dd7f44,openstack/sahara,master,I928712ef0c3a6b477da1d6cdae1fef6684dd7f44,DNM: test paramiko version bump,ABANDONED,2016-05-10 20:27:06.000000000,2016-05-11 13:12:59.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-05-10 20:27:06.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/f506eae8afe4708bfb06b32f671b5e6ac324e1f3', 'message': 'DNM: test paramiko version bump\n\nChange-Id: I928712ef0c3a6b477da1d6cdae1fef6684dd7f44\nDepends-On: I2369638282b4fefccd8484a5039fcfa9795069a7\n'}]",0,314757,f506eae8afe4708bfb06b32f671b5e6ac324e1f3,6,4,1,2750,,,0,"DNM: test paramiko version bump

Change-Id: I928712ef0c3a6b477da1d6cdae1fef6684dd7f44
Depends-On: I2369638282b4fefccd8484a5039fcfa9795069a7
",git fetch https://review.opendev.org/openstack/sahara refs/changes/57/314757/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f506eae8afe4708bfb06b32f671b5e6ac324e1f3,,paramiko>=2.0 # LGPL,paramiko>=1.16.0 # LGPL,1,1
openstack%2Fironic~master~I7d55e7d9af599bf3f980aeedb4e7436c3772903c,openstack/ironic,master,I7d55e7d9af599bf3f980aeedb4e7436c3772903c,DNM: testing paramiko bump,ABANDONED,2016-05-10 20:26:12.000000000,2016-05-11 13:12:56.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 10118}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-05-10 20:26:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/292191b8430662b526ff852d4ec2bef7291204c2', 'message': 'DNM: testing paramiko bump\n\nChange-Id: I7d55e7d9af599bf3f980aeedb4e7436c3772903c\nDepends-On: I2369638282b4fefccd8484a5039fcfa9795069a7\n'}]",0,314756,292191b8430662b526ff852d4ec2bef7291204c2,12,4,1,2750,,,0,"DNM: testing paramiko bump

Change-Id: I7d55e7d9af599bf3f980aeedb4e7436c3772903c
Depends-On: I2369638282b4fefccd8484a5039fcfa9795069a7
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/314756/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,292191b8430662b526ff852d4ec2bef7291204c2,,paramiko>=2.0 # LGPL,paramiko>=1.16.0 # LGPL,1,1
openstack%2Fproject-config~master~Iae3d0e28d39a69dd6626a6e9a6493bf868f8fe38,openstack/project-config,master,Iae3d0e28d39a69dd6626a6e9a6493bf868f8fe38,Delete bare-precise,MERGED,2016-05-06 16:10:40.000000000,2016-05-11 13:12:37.000000000,2016-05-11 13:12:37.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-05-06 16:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b3e2940afabd6fcce032bb9341970bf40066395d', 'message': ""Delete bare-precise\n\nI'm happy to say we've fully migrated from bare-precise to\nubuntu-precise.  You will be missed bare-precise.\n\nChange-Id: Iae3d0e28d39a69dd6626a6e9a6493bf868f8fe38\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}, {'number': 2, 'created': '2016-05-06 16:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b9f5bb9ea35812cea8f526e4aad15148c507a197', 'message': ""Delete bare-precise\n\nI'm happy to say we've fully migrated from bare-precise to\nubuntu-precise.  You will be missed bare-precise.\n\nChange-Id: Iae3d0e28d39a69dd6626a6e9a6493bf868f8fe38\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}, {'number': 3, 'created': '2016-05-06 16:30:10.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3ef8fb878672a4614dc4dd048b236a5df8544d4b', 'message': ""Delete bare-precise\n\nI'm happy to say we've fully migrated from bare-precise to\nubuntu-precise.  You will be missed bare-precise.\n\nChange-Id: Iae3d0e28d39a69dd6626a6e9a6493bf868f8fe38\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,313631,3ef8fb878672a4614dc4dd048b236a5df8544d4b,24,5,3,4162,,,0,"Delete bare-precise

I'm happy to say we've fully migrated from bare-precise to
ubuntu-precise.  You will be missed bare-precise.

Change-Id: Iae3d0e28d39a69dd6626a6e9a6493bf868f8fe38
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/31/313631/2 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,b3e2940afabd6fcce032bb9341970bf40066395d,ubuntu-precise,, - name: bare-precise image: bare-precise ready-script: configure_mirror.sh min-ready: -1 providers: - name: rax-dfw - name: rax-ord - name: rax-iad - name: bare-precise base-image: 'Ubuntu 12.04 LTS (Precise Pangolin) (PVHVM)' min-ram: 8192 name-filter: 'Performance' setup: prepare_node_bare.sh username: jenkins private-key: /home/nodepool/.ssh/id_rsa - name: bare-precise base-image: 'Ubuntu 12.04 LTS (Precise Pangolin) (PVHVM)' min-ram: 8192 name-filter: 'Performance' setup: prepare_node_bare.sh username: jenkins private-key: /home/nodepool/.ssh/id_rsa - name: bare-precise base-image: 'Ubuntu 12.04 LTS (Precise Pangolin) (PVHVM)' min-ram: 8192 name-filter: 'Performance' setup: prepare_node_bare.sh username: jenkins private-key: /home/nodepool/.ssh/id_rsa,0,29
openstack%2Fopenstack-ansible-plugins~master~I8784d4213e297fd78477b54b21c47f4c5223bb1e,openstack/openstack-ansible-plugins,master,I8784d4213e297fd78477b54b21c47f4c5223bb1e,"Revert ""Support users without projects in keystone library""",MERGED,2016-05-11 13:02:21.000000000,2016-05-11 13:12:03.000000000,2016-05-11 13:12:03.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}]","[{'number': 1, 'created': '2016-05-11 13:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/4b93374eea34c872abeec7f78cac0929a13d8f21', 'message': 'Revert ""Support users without projects in keystone library""\n\nIn the os_keystone role, the \'Ensure Keystone user to Admin role\' this patch causes \'keystoneclient.exceptions.ValidationError: Specify either a domain or project, not both\'.\n\nThis reverts commit 2e1492a127923a79ef3189433c4134df98c22502.\n\nChange-Id: I8784d4213e297fd78477b54b21c47f4c5223bb1e\n'}, {'number': 2, 'created': '2016-05-11 13:04:42.000000000', 'files': ['library/keystone'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/f975da26ce306b63a6bf72b6a15c27224ed29c29', 'message': 'Revert ""Support users without projects in keystone library""\n\nIn the os_keystone role, the \'Ensure Keystone user to Admin role\'\nthis patch causes \'keystoneclient.exceptions.ValidationError:\nSpecify either a domain or project, not both\'.\n\nThis reverts commit 2e1492a127923a79ef3189433c4134df98c22502.\n\nChange-Id: I8784d4213e297fd78477b54b21c47f4c5223bb1e\n'}]",0,315021,f975da26ce306b63a6bf72b6a15c27224ed29c29,9,3,2,6816,,,0,"Revert ""Support users without projects in keystone library""

In the os_keystone role, the 'Ensure Keystone user to Admin role'
this patch causes 'keystoneclient.exceptions.ValidationError:
Specify either a domain or project, not both'.

This reverts commit 2e1492a127923a79ef3189433c4134df98c22502.

Change-Id: I8784d4213e297fd78477b54b21c47f4c5223bb1e
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/21/315021/2 && git format-patch -1 --stdout FETCH_HEAD,['library/keystone'],1,4b93374eea34c872abeec7f78cac0929a13d8f21,bug/1579612," 'role_name' if project is None: if project is None: def _get_user_roles(self, name, user, project): project=project name=role_name, user=user, project=project user=user, role=role, project=project name=role_name, user=user, project=project"," 'role_name', 'domain_name' if project is None and project_name is not None: if project is None and project_name is not None: def _get_user_roles(self, name, user, project, domain): project=project, domain=domain name=role_name, user=user, project=project, domain=domain user=user, role=role, project=project, domain=domain name=role_name, user=user, project=project, domain=domain",8,10
openstack%2Fsahara-dashboard~master~Ib59322fa77dc807d87f147a15168415ff70ff2ad,openstack/sahara-dashboard,master,Ib59322fa77dc807d87f147a15168415ff70ff2ad,Imported Translations from Zanata,MERGED,2016-05-11 06:50:53.000000000,2016-05-11 13:11:09.000000000,2016-05-11 13:11:09.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-05-11 06:50:53.000000000', 'files': ['sahara_dashboard/locale/djangojs.pot', 'sahara_dashboard/locale/fr/LC_MESSAGES/django.po', 'sahara_dashboard/locale/django.pot'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/2e0227b1a2b9a2a1c15782aa1125ae32ef9a9295', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ib59322fa77dc807d87f147a15168415ff70ff2ad\n'}]",0,314887,2e0227b1a2b9a2a1c15782aa1125ae32ef9a9295,10,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ib59322fa77dc807d87f147a15168415ff70ff2ad
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/87/314887/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/locale/djangojs.pot', 'sahara_dashboard/locale/fr/LC_MESSAGES/django.po', 'sahara_dashboard/locale/django.pot']",3,2e0227b1a2b9a2a1c15782aa1125ae32ef9a9295,zanata/translations,,"# Translations template for sahara-dashboard. # Copyright (C) 2016 ORGANIZATION # This file is distributed under the same license as the sahara-dashboard # project. # FIRST AUTHOR <EMAIL@ADDRESS>, 2016. # #, fuzzy msgid """" msgstr """" ""Project-Id-Version: sahara-dashboard 4.0.0.0rc2.dev36\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2016-05-01 06:53+0000\n"" ""PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"" ""Language-Team: LANGUAGE <LL@li.org>\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=utf-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 2.2.0\n"" #: sahara_dashboard/content/data_processing/clusters/panel.py:21 #: sahara_dashboard/content/data_processing/clusters/views.py:40 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:253 #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:39 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:46 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/index.html:3 msgid ""Clusters"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/forms.py:27 msgid ""Cluster Template Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/forms.py:35 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:13 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:37 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:19 msgid ""Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/forms.py:53 msgid ""Unable to upload cluster template file"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:29 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:145 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:32 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:226 #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:176 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:27 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:113 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:5 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:5 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_health_checks_table.html:8 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:86 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:29 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:55 #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:106 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:28 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:123 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:74 #: sahara_dashboard/content/data_processing/jobs/templates/data_plugins/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:54 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:116 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:135 msgid ""Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:30 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:149 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:231 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:28 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:116 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html:6 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:15 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html:6 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:31 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_tag_form.html:7 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html:6 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:42 msgid ""Plugin"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:31 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:151 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:234 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:29 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:118 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html:8 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:17 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html:8 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:33 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_tag_form.html:8 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html:8 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:44 #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:64 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:64 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:264 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:270 msgid ""Version"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:32 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:157 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:83 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:70 #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:31 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:48 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_health_checks_table.html:10 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:11 #: sahara_dashboard/content/data_processing/jobs/data_plugins/tables.py:32 #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:92 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:78 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:159 #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:111 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:30 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:129 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:100 #: sahara_dashboard/content/data_processing/jobs/templates/data_plugins/_details.html:9 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:15 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:13 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:13 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:139 msgid ""Description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:37 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:86 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_upload_file.html:10 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/upload_file.html:3 msgid ""Upload Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:45 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:44 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:223 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:51 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:203 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_create_cluster.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/configure.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/create.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/create_cluster.html:3 msgid ""Launch Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:61 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:53 msgid ""Copy Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:68 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:60 msgid ""Edit Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:76 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:68 msgid ""Delete Template"" msgid_plural ""Delete Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:84 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:76 msgid ""Deleted Template"" msgid_plural ""Deleted Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:96 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:34 msgid ""Create Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:105 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:103 msgid ""Configure Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:153 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py:88 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:210 #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:125 msgid ""Node Groups"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py:161 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py:36 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:43 msgid ""Cluster Templates"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py:52 msgid ""Unable to fetch cluster template list"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py:57 #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:59 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:57 #: sahara_dashboard/content/data_processing/jobs/data_sources/tabs.py:47 #: sahara_dashboard/content/data_processing/jobs/job_binaries/tabs.py:47 #: sahara_dashboard/content/data_processing/jobs/job_templates/tabs.py:52 #: sahara_dashboard/content/data_processing/jobs/jobs/tabs.py:60 msgid ""General Info"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py:72 #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:102 msgid ""Configuration Details"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py:109 msgid ""Unable to fetch node group details."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:57 #, python-format msgid ""Unable to retrieve details for cluster template \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:95 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:60 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:281 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/configure.html:3 msgid ""Create Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:111 msgid ""Copy Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py:129 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:261 msgid ""Unable to fetch cluster template."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/copy.py:29 #, python-format msgid ""Cluster Template copy %s created"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/copy.py:107 msgid ""Unable to fetch template to copy."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:49 msgid ""Select plugin and hadoop version for cluster template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:61 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:592 msgid ""Next"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:62 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:593 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:574 msgid ""Created"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:63 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:594 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:575 msgid ""Could not create"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:81 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:46 msgid ""Template Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:88 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:153 msgid ""Auto-configure"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:89 msgid """" ""If selected, instances of a cluster will be automatically configured "" ""during creation. Otherwise you should manually specify configuration "" ""values"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:97 #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:98 msgid ""cluster template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:135 #: sahara_dashboard/content/data_processing/jobs/data_plugins/tabs.py:47 msgid ""Details"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:232 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:44 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:357 msgid ""Select Shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:243 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:81 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:368 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:104 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:211 msgid ""Failed to get list of shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:253 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:91 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:373 msgid ""Shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:254 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:92 msgid ""Select the manila shares for this cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:282 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:428 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:138 #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:61 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:224 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:573 msgid ""Create"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:283 #, python-format msgid ""Created Cluster Template %s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py:384 msgid ""Cluster template creation failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py:32 #, python-format msgid ""Cluster Template %s updated"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py:34 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/edit.py:31 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/edit.py:27 #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:81 msgid ""Update"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py:35 msgid ""Edit Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py:53 msgid ""Unable to fetch template to edit."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py:106 msgid ""Cluster template update failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:33 #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:238 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:13 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:34 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_health_checks_table.html:7 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:38 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:236 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:5 msgid ""Status"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:38 msgid ""Cluster Creation Guide"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:52 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:243 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py:37 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/scale.html:3 msgid ""Scale Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:63 msgid ""Delete Cluster"" msgid_plural ""Delete Clusters"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:71 msgid ""Deleted Cluster"" msgid_plural ""Deleted Clusters"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:86 msgid ""Start Verification"" msgid_plural ""Start Verifications"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:94 msgid ""Started Verification"" msgid_plural ""Started Verifications"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:106 msgid ""Update Shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:125 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:130 msgid ""Unable to update row"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:169 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:230 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:186 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:422 msgid ""Configure Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:210 msgid ""Checking"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:242 msgid ""Health"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:246 msgid ""Instances Count"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tables.py:249 msgid ""Uptime"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:54 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:58 msgid ""Unable to fetch cluster list"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:153 msgid ""Unable to get node group details."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:179 msgid ""Internal IP"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:182 msgid ""Management IP"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:186 msgid ""Cluster Instances"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:190 msgid ""Instances"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:215 msgid ""Unable to fetch instance details."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:220 msgid ""Cluster Events"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/tabs.py:233 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_health_checks_table.html:3 msgid ""Cluster health checks"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:73 #, python-format msgid ""Unable to retrieve details for cluster \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:132 msgid ""Unknown"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:135 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:154 msgid ""Completed Successfully"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:137 #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:156 msgid ""Failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:142 msgid ""No info available"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:149 msgid ""In progress"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:198 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:19 msgid ""No description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:276 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:119 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/update.html:3 msgid ""Update Cluster Shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/views.py:292 msgid ""Unable to fetch cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:41 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:562 msgid ""Select plugin and hadoop version for cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:68 msgid ""Cluster Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:73 msgid ""Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:79 msgid ""Cluster Count"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:82 msgid ""Number of clusters to launch."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:84 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:126 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:44 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:17 msgid ""Base Image"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:88 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:51 msgid ""Keypair"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:90 msgid ""Which keypair to use for authentication."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:101 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:48 msgid ""Neutron Management Network"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:107 #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:109 msgid ""cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:129 msgid ""Unable to fetch keypair choices."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:131 msgid ""No keypair"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:147 msgid ""No Templates Available"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:204 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:491 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:583 msgid ""Launch"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:205 #, python-format msgid ""Launched Cluster %s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py:241 msgid ""Unable to create the cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py:38 msgid ""Scale"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py:45 msgid ""Scaled cluster successfully started."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py:102 msgid ""Unable to fetch cluster to scale"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py:157 msgid ""Unable to fetch cluster to scale."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py:167 msgid ""Scale cluster operation failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:120 msgid ""Updated"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:121 msgid ""Could not update cluster shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py:135 msgid ""Cluster share update failed."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:29 msgid ""User Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:46 msgid ""Successfully updated image."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:50 msgid ""Failed to update image."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:59 #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:69 msgid ""Image"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:71 msgid ""Select Image"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:73 msgid ""No images available."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:83 #, python-format msgid ""Unable to retrieve images with filter %s."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/forms.py:110 msgid ""Unable to fetch available images."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:25 msgid ""Edit Tags"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:38 #: sahara_dashboard/content/data_processing/clusters/image_registry/views.py:94 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_register_image.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/register_image.html:3 msgid ""Register Image"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:49 msgid ""Unregister Image"" msgid_plural ""Unregister Images"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:57 msgid ""Unregistered Image"" msgid_plural ""Unregistered Images"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:73 msgid ""Tags"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tables.py:77 #: sahara_dashboard/content/data_processing/clusters/image_registry/tabs.py:30 msgid ""Image Registry"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/tabs.py:39 msgid ""Unable to retrieve image list"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/views.py:35 #: sahara_dashboard/content/data_processing/clusters/image_registry/views.py:50 msgid ""Unable to process plugin tags"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/views.py:61 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_edit_tags.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/edit_tags.html:3 msgid ""Edit Image Tags"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/image_registry/views.py:76 msgid ""Unable to fetch the image details"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:43 msgid ""Configure Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:120 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:345 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:47 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:48 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:78 msgid ""Node Processes"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py:126 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:36 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py:39 msgid ""Node Group Templates"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:52 msgid ""Unable to fetch node group template list"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:77 msgid ""Unable to fetch flavor for template."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:86 msgid ""Unable to fetch floating ip pools."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:95 #, python-format msgid ""Unable to fetch Base Image with id: %s."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py:114 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_service_confs.html:2 msgid ""Service Configurations"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py:52 msgid ""Unable to fetch node group template list."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py:67 #, python-format msgid ""Unable to retrieve details for node group template \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py:98 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py:106 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:427 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:591 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/configure.html:3 msgid ""Create Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py:136 msgid ""Unable to fetch template object."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/copy.py:24 #, python-format msgid ""Node Group Template copy %s created"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/copy.py:109 msgid ""Unable to fetch plugin details."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:52 msgid ""OpenStack Flavor"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:55 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:21 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:31 msgid ""Availability Zone"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:56 msgid ""Launch instances in this availability zone."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:62 msgid ""Storage location"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:63 msgid ""Choose a storage location"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:72 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:78 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:91 msgid ""Volumes per node"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:83 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:89 msgid ""Volumes size (GB)"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:94 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:99 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:95 msgid ""Volumes type"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:104 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:111 msgid ""Volume local to instance"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:106 msgid ""Instance and attached volumes will be created on the same physical host"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:116 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:122 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:100 msgid ""Volumes Availability Zone"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:117 msgid ""Create volumes in this availability zone."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:148 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:15 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:37 msgid ""Floating IP Pool"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:154 msgid """" ""If selected, instances of a node group will be automatically configured "" ""during cluster creation. Otherwise you should manually specify "" ""configuration values."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:164 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:28 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:29 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:53 msgid ""Proxy Gateway"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:166 msgid """" ""Sahara will use instances of this node group to access other cluster "" ""instances."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:171 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:173 msgid ""node group template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:202 msgid ""Unable to get volume type list."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:204 msgid ""No volume type"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:216 #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:223 msgid ""No availability zone specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:242 msgid ""Configure Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:251 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:31 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:32 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:58 msgid ""Auto Security Group"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:253 msgid ""Create security group for this Node Group."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:261 msgid ""Unable to get security group list."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:266 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:34 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:35 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:63 msgid ""Security Groups"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:268 msgid ""Launch instances in these security groups."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:273 msgid ""Security"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:274 msgid ""Control access to instances of the node group."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:292 #, python-format msgid ""%s processes: "" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:331 msgid ""Unable to generate process choices."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:339 msgid ""Select Node Group Processes"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:346 msgid ""Select node processes for the node group"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:374 msgid ""Select the manila shares for this node group"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:429 #, python-format msgid ""Created Node Group Template %s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py:573 msgid ""Select plugin and hadoop version"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/edit.py:30 #, python-format msgid ""Node Group Template %s updated"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/edit.py:32 msgid ""Edit Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:2 msgid ""Cluster Template Configuration Overview"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:37 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:37 #, python-format msgid ""%(conf_name)s: %(conf_value)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:16 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:41 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:16 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:41 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_service_confs.html:17 msgid ""No configurations"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:21 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:21 msgid ""Cluster configurations are not specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:25 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:25 msgid ""Node Groups Configuration Overview"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:29 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:29 #, python-format msgid ""Node Group Name: %(node_group_name)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html:46 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:46 msgid ""Node group configurations are not specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html:4 msgid ""This Cluster Template will be created for:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html:13 msgid """" ""The Cluster Template object should specify Node Group Templates that will"" "" be used to build a Cluster.\n"" "" You can add Node Groups using Node Group Templates on a &quot;Node "" ""Groups&quot; tab."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html:16 msgid ""You may set <b>cluster</b> scoped configurations on corresponding tabs."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html:20 msgid """" ""The Cluster Template object may specify a list of processes in anti-"" ""affinity group.\n"" "" That means these processes may not be launched more than once on a "" ""single host."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_create_general_help.html:3 msgid ""Select a plugin and version for a new Cluster template."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:7 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:7 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:7 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:7 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:7 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:9 msgid ""Project ID"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:9 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:35 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:217 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:9 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:9 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:9 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:7 msgid ""ID"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:12 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:16 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:14 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:14 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:23 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:29 msgid ""None"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:19 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:25 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:53 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:26 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:49 msgid ""Use auto-configuration"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:21 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:55 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:13 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:17 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:15 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:15 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:13 #: sahara_dashboard/content/data_processing/utils/acl.py:124 msgid ""Public"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:23 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:57 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:15 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:19 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:17 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:17 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:15 #: sahara_dashboard/content/data_processing/utils/acl.py:135 msgid ""Protected"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:27 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:61 msgid ""Anti-affinity enabled for"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html:37 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:71 msgid ""no processes"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:6 #, python-format msgid ""Node Group: %(node_group_name)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:7 msgid ""Nodes Count"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:10 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:26 msgid ""Flavor"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:12 msgid ""Flavor is not specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:17 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:41 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:23 msgid ""Template not specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html:57 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:58 msgid ""Node processes are not specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_upload_file.html:21 msgid ""Upload"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_upload_file.html:23 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_ngt_select.html:29 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_plugin_select.html:29 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_create_cluster.html:22 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_edit_tags.html:28 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_register_image.html:26 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create.html:26 #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/_job_type_select.html:29 msgid ""Cancel"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/cluster_node_groups_template.html:95 msgid ""Select a Node Group Template to add:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/cluster_templates.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/clusters.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/image_registry.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/nodegroup_templates.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/data_plugins/plugins.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/data_sources.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/job_binaries.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/jobs.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/job_executions.html:3 #: sahara_dashboard/enabled/_1810_data_processing_panel_group.py:6 msgid ""Data Processing"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_ngt_select.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/ngt_select.html:3 #: sahara_dashboard/content/data_processing/clusters/wizard/views.py:72 msgid ""Choose node group template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_ngt_select.html:27 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_plugin_select.html:27 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/job_interface_arguments_template.html:7 #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/_job_type_select.html:27 msgid ""Select"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_ngt_select_help.html:4 msgid """" ""Select an existing node group template.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_plugin_select.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/plugin_select.html:3 #: sahara_dashboard/content/data_processing/clusters/wizard/views.py:63 msgid ""Choose plugin and version"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_plugin_select_help.html:4 msgid """" ""Select which plugin and version that you\n"" "" want to use to create your cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:19 msgid """" ""The first step is to determine which type of\n"" "" cluster you want to run. You may have several "" ""choices\n"" "" available depending on the configuration of your "" ""system.\n"" "" Click on \""choose plugin\"" to bring up the list of "" ""data\n"" "" processing plugins. There you will be able to choose"" "" the\n"" "" data processing plugin along with the version number."" ""\n"" "" Choosing this up front will allow the rest of the "" ""cluster\n"" "" creation steps to focus only on options that are "" ""pertinent\n"" "" to your desired cluster type."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:22 msgid ""Choose plugin"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:23 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:67 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:102 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:134 msgid ""Current choice:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:26 msgid ""Plugin:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:28 msgid ""Version:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:33 msgid ""No plugin chosen"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:51 msgid """" ""Next, you need to define the different\n"" "" types of machines in your cluster. This is done "" ""by\n"" "" defining a Node Group Template for each type of\n"" "" machine. A very common case is where you\n"" "" need to have one or more machines running a "" ""\""master\""\n"" "" set of processes while another set of machines "" ""need\n"" "" to be running the \""worker\"" processes. Here,\n"" "" you will define the Node Group Template for your\n"" "" \""master\"" node(s).\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:57 msgid ""Create a Master Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:59 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:94 msgid "" or "" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:63 msgid ""Choose an existing Master Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:70 msgid ""Master Node Group Template:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:75 msgid ""No Master Node Group Template Created"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:86 msgid """" ""Repeat the Node Group Template\n"" "" creation process, but this time you are creating\n"" "" your \""worker\"" Node Group Template."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:92 msgid ""Create a Worker Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:98 msgid ""Choose an existing Worker Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:105 #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:137 msgid ""Worker Node Group Template:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:110 msgid ""No Worker Node Group Template Created"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:126 msgid """" ""Now you need to set the layout of your\n"" "" cluster. By\n"" "" creating a Cluster Template, you will be choosing"" "" the\n"" "" number of instances of each Node Group Template "" ""that\n"" "" will appear in your cluster. Additionally,\n"" "" you will have a chance to set any cluster-"" ""specific\n"" "" configuration items in the additional tabs on the"" ""\n"" "" create Cluster Template form."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:132 msgid ""Create a Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:142 msgid ""No Cluster Template Created"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:158 msgid """" ""You are now ready to\n"" "" launch your cluster. When you click on the link\n"" "" below, you will need to give your cluster a name,"" ""\n"" "" choose the Cluster Template to use and choose "" ""which\n"" "" image to use to build your instances. After you\n"" "" click on \""Create\"", your instances will begin to"" ""\n"" "" spawn. Your cluster should be operational in a "" ""few\n"" "" minutes."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:164 msgid ""Launch a Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:172 msgid ""Reset Cluster Guide"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html:174 msgid ""Reset Cluster Creation Guide"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html:2 msgid ""Cluster Configuration Overview"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html:4 msgid ""This Cluster will be started with:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html:12 msgid ""Cluster can be launched using existing Cluster Templates."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html:15 msgid """" ""The Cluster object should specify OpenStack Image to boot instances for "" ""Cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html:18 msgid ""User has to choose a keypair to have access to clusters instances."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_create_cluster.html:20 msgid "" Done"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_create_general_help.html:3 msgid ""Select a plugin and version for a new Cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:15 msgid ""Status description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:24 msgid ""Error Details"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html:79 #, python-format msgid ""%(key)s: %(val)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:3 msgid ""Cluster provision steps"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:7 msgid ""Step Description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:8 msgid ""Started at"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_health_checks_table.html:9 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:239 msgid ""Duration"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:10 msgid ""Progress"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:30 msgid ""Node Group"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:31 msgid ""Instance"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:32 msgid ""Event time"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html:33 msgid ""Info"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:7 #, python-format msgid ""Name: %(node_group_name)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html:8 msgid ""Number of Nodes"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/clusters/index.html:35 msgid ""Add Node Group"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_edit_tags.html:26 #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_register_image.html:24 msgid ""Done"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_help.html:3 msgid ""Image Registry tool:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_help.html:6 msgid """" ""Image Registry is used to provide additional information about images for"" "" Data Processing."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_help.html:9 msgid """" ""Specified User Name will be used by Data Processing to apply configs and "" ""manage processes on instances."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_help.html:13 msgid """" ""Tags are used for filtering images suitable for each plugin and each Data"" "" Processing version.\n"" "" To add required tags, select a plugin and a Data Processing "" ""version and click &quot;Add plugin tags&quot; button."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_help.html:16 msgid ""You may also add any custom tag."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_help.html:19 msgid ""Unnecessary tags may be removed by clicking a cross near tag's name."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_tag_form.html:5 msgid """" ""Register tags required for the Plugin with specified Data Processing "" ""Version"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_tag_form.html:30 msgid ""Add plugin tags"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/image_registry/_tag_form.html:38 msgid ""Add custom tag"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html:4 msgid ""This Node Group Template will be created for:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html:15 msgid """" ""The Node Group Template object specifies the processes\n"" "" that will be launched on each instance. Check one or more "" ""processes.\n"" "" When processes are selected, you may set <b>node</b> scoped\n"" "" configurations on corresponding tabs."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html:18 msgid """" ""You must choose a flavor to determine the size (VCPUs, memory and "" ""storage) of all launched VMs."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html:21 msgid """" ""Data Processing provides different storage location options. You may "" ""choose Ephemeral Drive or a Cinder Volume to be attached to instances."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_create_general_help.html:3 msgid ""Select a plugin and version for the new Node Group template."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:7 msgid ""Project Id"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:21 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:242 msgid ""No image specified"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:88 msgid ""HDFS placement"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:90 msgid ""Cinder volumes"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:93 msgid ""Volumes size"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:97 msgid ""Volumes local to instance"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html:104 msgid ""Ephemeral drive"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_fields_help.html:3 msgid ""Filter"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_fields_help.html:4 msgid ""Show full configuration"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_fields_help.html:5 msgid ""Hide full configuration"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_service_confs.html:12 #, python-format msgid ""%(conf_name)s: %(conf_val)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:43 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:43 msgid ""Cluster type chosen"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:47 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:47 msgid ""Unable to set cluster type"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:56 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:56 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:255 msgid ""Plugin Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:86 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:86 msgid ""Choose plugin type and version"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:91 msgid ""Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:144 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:116 msgid ""Job type chosen"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/forms.py:148 msgid ""Unable to set node group template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/wizard/views.py:31 msgid ""Guided Cluster Creation"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/panel.py:21 #: sahara_dashboard/content/data_processing/jobs/views.py:44 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:248 #: sahara_dashboard/content/data_processing/jobs/jobs/tabs.py:32 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/index.html:3 msgid ""Jobs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/tables.py:22 #: sahara_dashboard/content/data_processing/jobs/templates/data_plugins/_details.html:7 msgid ""Title"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/tables.py:27 #: sahara_dashboard/content/data_processing/jobs/templates/data_plugins/_details.html:11 msgid ""Supported Versions"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/tables.py:36 #: sahara_dashboard/content/data_processing/jobs/data_plugins/tabs.py:32 msgid ""Plugins"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/tabs.py:42 msgid ""Unable to fetch plugin list"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/tabs.py:60 msgid ""Unable to retrieve plugin."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/views.py:30 msgid ""Data Processing Plugins"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/views.py:37 msgid ""Unable to retrieve data processing plugins."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_plugins/views.py:45 msgid ""Data Processing Plugin Details"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:26 #: sahara_dashboard/content/data_processing/jobs/data_sources/views.py:55 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:109 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:137 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/create.html:3 msgid ""Create Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:35 msgid ""Delete Data Source"" msgid_plural ""Delete Data Sources"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:43 msgid ""Deleted Data Source"" msgid_plural ""Deleted Data Sources"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:55 #: sahara_dashboard/content/data_processing/jobs/data_sources/views.py:60 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/edit.py:26 msgid ""Edit Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:90 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:29 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:127 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:11 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:11 msgid ""Type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tables.py:96 #: sahara_dashboard/content/data_processing/jobs/data_sources/tabs.py:32 #: sahara_dashboard/content/data_processing/jobs/data_sources/views.py:37 msgid ""Data Sources"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/tabs.py:42 msgid ""Unable to fetch data source list"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/views.py:45 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:80 msgid ""Unable to fetch data sources."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/views.py:86 #, python-format msgid ""Unable to retrieve details for data source \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:32 msgid ""Data Source Type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:39 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:44 msgid ""Manila share"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:48 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:53 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:54 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:55 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:66 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:72 #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:13 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:11 msgid ""URL"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:52 msgid ""Path on share"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:59 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:64 msgid ""Source username"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:71 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:74 msgid ""Source password"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:82 #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:83 msgid ""data source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:139 msgid ""Data source created"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py:140 msgid ""Could not create data source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/edit.py:28 msgid ""Data source updated"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/data_sources/workflows/edit.py:29 msgid ""Could not update data source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:58 msgid ""Storage type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:76 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:82 msgid ""Share"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:86 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:92 msgid ""Path"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:96 msgid ""Internal binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:103 msgid ""Internal Binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:107 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:113 msgid ""Upload File"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:117 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:123 msgid ""Script name"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:127 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:134 msgid ""Script text"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:138 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:144 msgid ""Username"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:148 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:155 msgid ""Password"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:164 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:166 msgid ""job binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:220 msgid ""Failed to get list of internal binaries."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:259 #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:303 msgid ""Unable to create job binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:274 #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:27 #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:58 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/create.html:3 msgid ""Create Job Binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:291 msgid ""Unable to upload job binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:324 msgid ""Failed to fetch internal binary list"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py:373 msgid ""Unable to update job binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:36 msgid ""Delete Job Binary"" msgid_plural ""Delete Job Binaries"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:44 msgid ""Deleted Job Binary"" msgid_plural ""Deleted Job Binaries"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:71 msgid ""Download Job Binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:78 #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:78 msgid ""Edit Job Binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:109 msgid ""Url"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py:115 #: sahara_dashboard/content/data_processing/jobs/job_binaries/tabs.py:32 #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:40 msgid ""Job Binaries"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/tabs.py:42 msgid ""Unable to fetch job binary list"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:48 msgid ""Unable to fetch job binary list."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:89 #, python-format msgid ""Unable to retrieve job binary \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:112 #, python-format msgid ""Unable to retrieve details for job binary \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_binaries/views.py:142 #, python-format msgid ""Unable to fetch job binary: %(exc)s"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:35 #: sahara_dashboard/content/data_processing/jobs/job_templates/views.py:41 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:142 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:223 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/create.html:3 msgid ""Create Job Template"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:44 msgid ""Delete Job Template"" msgid_plural ""Delete Job Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:52 msgid ""Deleted Job Template"" msgid_plural ""Deleted Jobs Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:64 msgid ""Launch On Existing Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:77 #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:90 msgid ""Launch On New Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tables.py:133 #: sahara_dashboard/content/data_processing/jobs/job_templates/tabs.py:32 msgid ""Job Templates"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/tabs.py:47 msgid ""Unable to fetch job template list"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/views.py:55 #, python-format msgid ""Unable to retrieve details for job template \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/views.py:82 #: sahara_dashboard/content/data_processing/jobs/job_templates/views.py:103 #: sahara_dashboard/content/data_processing/jobs/job_templates/views.py:116 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:490 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:572 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:582 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:71 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:100 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/launch.html:3 msgid ""Launch Job"" msgid_plural ""Launch Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:39 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:46 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:47 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:49 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:50 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:51 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:52 msgid ""Choose libraries"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:48 msgid ""Choose additional files"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:64 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:129 msgid ""-- not selected --"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:69 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:25 msgid ""Libs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:76 #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:91 msgid ""Job Type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:83 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:92 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:93 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:95 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:96 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:97 msgid ""Choose a main binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:85 msgid ""Choose the binary which should be used in this Job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:94 msgid ""Choose a shell script"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:103 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:104 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:51 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:52 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:112 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:113 msgid ""job"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:183 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:476 msgid ""Interface Arguments"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:225 msgid ""Job created"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py:226 msgid ""Could not create job template"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:40 msgid ""Input"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:46 msgid ""Output"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:61 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:102 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:129 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:36 msgid ""Job"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:94 msgid ""Unable to fetch jobs."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:108 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:37 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:229 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:25 msgid ""Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:121 msgid ""Unable to fetch clusters."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:192 msgid ""Main Class"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:195 msgid ""Java Opts"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:198 msgid ""Mapper"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:200 msgid ""Reducer"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:203 msgid ""Use HBase Common library"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:204 msgid ""Run HBase EDP Jobs with common HBase library on HDFS"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:208 msgid ""Adapt For Oozie"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:209 msgid """" ""Automatically modify the Hadoop configuration so that job config values "" ""are set and so that Oozie will handle exit codes correctly."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:215 msgid ""Enable Swift Paths"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:216 msgid """" ""Modify the configuration so that swift URLs can be dereferenced through "" ""HDFS at runtime."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:221 msgid ""Use Data Source Substitution for Names and UUIDs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:222 msgid """" ""Substitute data source objects for URLs of the form datasource://name or "" ""uuid."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:323 msgid ""Configure"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:418 msgid ""Persist cluster after job exit"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:492 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:584 msgid ""Job launched"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:493 #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:585 msgid ""Could not launch job"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:523 msgid ""Plugin name"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:528 msgid ""Job configs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:532 msgid ""Job args"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:536 msgid ""Job params"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:542 msgid ""Job Execution ID"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:621 msgid ""Unable to create new cluster for job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py:638 msgid ""Unable to launch job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:43 msgid ""Job Guide"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:50 msgid ""Delete Job"" msgid_plural ""Delete Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:58 msgid ""Deleted Job"" msgid_plural ""Deleted Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:79 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:108 msgid ""Launched Job"" msgid_plural ""Launched Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:86 msgid ""Relaunch On Existing Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:115 msgid ""Relaunch On New Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:170 #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:185 msgid ""Not available"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:206 msgctxt ""Current status of a Job"" msgid ""Done with Error"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:208 msgctxt ""Current status of a Job"" msgid ""Failed"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:210 msgctxt ""Current status of a Job"" msgid ""Killed"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:212 msgctxt ""Current status of a Job"" msgid ""Succeeded"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tables.py:224 #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:11 msgid ""Job Template"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/tabs.py:55 msgid ""Unable to fetch job list"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/jobs/views.py:39 #, python-format msgid ""Unable to retrieve details for job \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_create_data_source_help.html:4 msgid ""Create a Data Source with a specified name."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_create_data_source_help.html:7 msgid ""Select the type of your Data Source."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_create_data_source_help.html:10 msgid ""You may need to enter the username and password for your Data Source."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_create_data_source_help.html:13 msgid """" ""For Data Sources on a Manila share, choose the share and enter the path "" ""relative to the share (example: /outputdir/myinputfile.txt)"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_create_data_source_help.html:16 msgid ""You may also enter an optional description for your Data Source."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html:21 #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:19 msgid ""Create time"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:5 msgid """" ""<b>Important</b>: The name that you give your job binary will be the "" ""name used in your job execution.\n"" "" If your binary requires a particular name or extension (ie: \"".jar\""), "" ""be sure to include it here."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:8 msgid ""Select the storage type for your job binary."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:10 msgid ""Data Processing internal database"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:11 msgid ""Swift"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:15 msgid """" ""For Data Processing internal job binaries, you may choose from the "" ""following:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:17 msgid ""Choose an existing file"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:18 msgid ""Upload a new file"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:19 msgid ""Create a script to be uploaded dynamically"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:23 msgid ""For Object Store job binaries, you must:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:25 msgid ""Enter the URL for the file"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:26 msgid ""Enter the username and password required to access that file"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html:30 msgid ""You may also enter an optional description for your job binary."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html:22 msgid ""Download job binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:4 msgid ""Create a job template with a specified name."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:7 msgid ""Select the type of your job:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:9 #: sahara_dashboard/content/data_processing/utils/helpers.py:184 msgid ""Pig"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:10 #: sahara_dashboard/content/data_processing/utils/helpers.py:185 msgid ""Hive"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:11 #: sahara_dashboard/content/data_processing/utils/helpers.py:186 msgid ""Spark"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:12 #: sahara_dashboard/content/data_processing/utils/helpers.py:187 msgid ""Storm"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:13 #: sahara_dashboard/content/data_processing/utils/helpers.py:188 msgid ""MapReduce"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:14 msgid ""Java Action"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:15 msgid ""Shell Action"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:19 msgid """" ""Choose or create your main binary. Additional libraries can be added "" ""from the \""Libs\"" tab."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:22 msgid ""For Spark and Shell jobs, only a main is required, \""libs\"" are optional."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:26 msgid """" ""For MapReduce or Java Action jobs, \""mains\"" are not applicable. You are"" "" required to add one\n"" "" or more \""libs\"" for these jobs."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html:29 msgid ""You may also enter an optional description for your job template."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_libs_help.html:4 msgid ""Add libraries to your job template."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_libs_help.html:7 msgid """" ""Choose from the list of binaries and click \""choose\"" to add the library "" ""to your job template. This can be repeated for additional libraries."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_libs_help.html:10 msgid """" ""For Shell Action jobs, any required files beyond the main script may be "" ""added as \""libraries\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:19 msgid ""Mains"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:31 msgid ""Created time"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:33 msgid ""Updated time"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html:34 msgid ""Never"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_configure_help.html:4 msgid ""Enter any custom configuration required for your job's execution."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_help.html:4 msgid ""Launch the given job template on a cluster."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_help.html:7 msgid ""Choose the cluster to use for the job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_help.html:10 msgid ""Choose the Input Data Source (n/a for Java and Shell jobs)."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_help.html:13 msgid ""Choose the Output Data Source (n/a for Java and Shell jobs)."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:5 msgid ""Select property name"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:16 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:34 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:47 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/library_template.html:3 msgid ""Remove"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:55 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:65 msgid ""Value"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:59 #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:69 msgid ""Add"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:236 msgid ""Configuration"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:239 msgid ""Parameters"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html:242 msgid ""Arguments"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/job_interface_arguments_template.html:3 msgid ""Select a Value Type for your next argument:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/job_interface_arguments_template.html:8 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:157 msgid ""String"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/job_interface_arguments_template.html:9 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:158 msgid ""Number"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/job_interface_arguments_template.html:10 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:159 msgid ""Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/library_template.html:86 msgid ""Choose"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_templates/library_template.html:98 msgid ""Chosen Libraries"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/_job_type_select.html:12 #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/job_type_select.html:3 #: sahara_dashboard/content/data_processing/jobs/wizard/views.py:58 msgid ""Choose job type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/_job_type_select_help.html:6 msgid """" ""Select which type of job that you want to run.\n"" "" This choice will dictate which steps are required to successfully\n"" "" execute your job.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:15 msgid """" ""First, select which type of job that\n"" "" you want to run. This choice will determine "" ""which\n"" "" other steps are required\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:20 msgid ""Select type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:23 msgid ""Current type:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:30 msgid ""No type chosen"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:46 msgid """" ""Data Sources are what your\n"" "" job uses for input and output. Depending on "" ""the type\n"" "" of job you will be running, you may need to "" ""define one\n"" "" or more data sources. You can create "" ""multiple data\n"" "" sources by repeating this step.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:51 msgid ""Create a data source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:65 msgid """" ""Define your Job Template.\n"" "" This is where you choose the type of job that you"" ""\n"" "" want to run (Pig, Java Action, Spark, etc) and "" ""choose\n"" "" or upload the files necessary to run it. The "" ""inputs\n"" "" and outputs will be defined later.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:70 msgid ""Create a job template"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:72 msgid ""Job template:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:79 msgid ""No job template created"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:94 msgid """" ""Launch your job. When\n"" "" launching, you may need to choose your input and\n"" "" output data sources. This is where you would "" ""also\n"" "" add any special configuration values, parameters,"" ""\n"" "" or arguments that you need to pass along\n"" "" to your job.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:98 msgid ""Launch job"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:107 #: sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html:109 msgid ""Reset Job Execution Guide"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:18 msgid ""Input Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:22 msgid ""Output Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:27 msgid ""Last Updated"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:29 msgctxt ""Start time"" msgid ""Started"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:31 msgctxt ""End time"" msgid ""Ended"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:33 msgid ""Return Code"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:35 msgid ""Oozie Job ID"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:37 msgctxt ""Created time"" msgid ""Created"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:39 msgid ""Job Configuration"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html:41 #, python-format msgid ""%(group)s:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/wizard/forms.py:120 msgid ""Unable to set job type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/wizard/views.py:29 msgid ""Guided Job Execution"" msgstr """" #: sahara_dashboard/content/data_processing/utils/acl.py:125 #, python-format msgid ""If selected, %s will be shared across the tenants"" msgstr """" #: sahara_dashboard/content/data_processing/utils/acl.py:136 #, python-format msgid """" ""If selected, %s will be protected from modifications until this will be "" ""unselected"" msgstr """" #: sahara_dashboard/content/data_processing/utils/anti_affinity.py:26 msgid ""Use anti-affinity groups for: "" msgstr """" #: sahara_dashboard/content/data_processing/utils/anti_affinity.py:28 msgid ""Use anti-affinity groups for processes"" msgstr """" #: sahara_dashboard/content/data_processing/utils/anti_affinity.py:61 msgid ""Unable to populate anti-affinity processes."" msgstr """" #: sahara_dashboard/content/data_processing/utils/helpers.py:189 msgid ""Streaming MapReduce"" msgstr """" #: sahara_dashboard/content/data_processing/utils/helpers.py:191 msgid ""Java"" msgstr """" #: sahara_dashboard/content/data_processing/utils/helpers.py:192 msgid ""Shell"" msgstr """" #: sahara_dashboard/content/data_processing/utils/neutron_support.py:31 msgid ""Unable to retrieve networks."" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:120 msgid ""Node group cluster"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:124 msgid ""Count"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:143 msgid ""Mapping Type"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:146 msgid ""Positional Argument"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:147 msgid ""Configuration Value"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:148 msgid ""Named Parameter"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:150 msgid ""Location"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:154 msgid ""Value Type"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:162 msgid ""Required"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:166 msgid ""Default Value"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:195 #, python-format msgid ""Unable to retrieve security group %(group)s."" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:239 msgid ""Unable to fetch image choices."" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:244 msgid ""No Images Available"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:373 msgid ""Read/Write"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:373 msgid ""Read only"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:418 msgid ""The value of shares must be a list of values"" msgstr """" ",8,2856
openstack%2Ftripleo-ci~master~I07b1db0992bd25742f329957dc5a090b74626ba8,openstack/tripleo-ci,master,I07b1db0992bd25742f329957dc5a090b74626ba8,Make the reviewday config file pluggable,MERGED,2016-04-18 17:03:53.000000000,2016-05-11 13:09:49.000000000,2016-05-11 13:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 3153}]","[{'number': 1, 'created': '2016-04-18 17:03:53.000000000', 'files': ['scripts/website/generate_site.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fa597d10bd8b150abeba9d6d01af0f740a9513cb', 'message': 'Make the reviewday config file pluggable\n\nAdds the option to specify an external environment variable for\nREVIEWDAY_INPUT_FILE to control the reviewday file used\nto build the website.\n\nChange-Id: I07b1db0992bd25742f329957dc5a090b74626ba8\n'}]",0,307377,fa597d10bd8b150abeba9d6d01af0f740a9513cb,8,3,1,360,,,0,"Make the reviewday config file pluggable

Adds the option to specify an external environment variable for
REVIEWDAY_INPUT_FILE to control the reviewday file used
to build the website.

Change-Id: I07b1db0992bd25742f329957dc5a090b74626ba8
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/77/307377/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/website/generate_site.sh'],1,fa597d10bd8b150abeba9d6d01af0f740a9513cb,website_reviewday_pluggable,"REVIEWDAY_INPUT_FILE=${REVIEWDAY_INPUT_FILE:-""${SCRIPT_DIR}/tripleo-reviewday.yaml""}","REVIEWDAY_INPUT_FILE=""${SCRIPT_DIR}/tripleo-reviewday.yaml""",1,1
openstack%2Ffuel-ui~master~I5c5371c0c912c0e15814898f51f672c55b869d4b,openstack/fuel-ui,master,I5c5371c0c912c0e15814898f51f672c55b869d4b,Upgrade Intern to 3.2.0,MERGED,2016-05-10 16:02:51.000000000,2016-05-11 13:09:47.000000000,2016-05-11 13:06:47.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-10 16:02:51.000000000', 'files': ['npm-shrinkwrap.json', 'package.json'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/996088b2c0fa5056b7045a1ba588760c7ea75749', 'message': 'Upgrade Intern to 3.2.0\n\nChange-Id: I5c5371c0c912c0e15814898f51f672c55b869d4b\n'}]",0,314652,996088b2c0fa5056b7045a1ba588760c7ea75749,34,6,1,8735,,,0,"Upgrade Intern to 3.2.0

Change-Id: I5c5371c0c912c0e15814898f51f672c55b869d4b
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/52/314652/1 && git format-patch -1 --stdout FETCH_HEAD,"['npm-shrinkwrap.json', 'package.json']",2,996088b2c0fa5056b7045a1ba588760c7ea75749,intern32," ""intern"": ""3.2.0"","," ""intern"": ""3.0.6"",",1581,275
openstack%2Fpython-cinderclient~master~Id29f0cee786205cc751d2d5bc031b3c105ae6aaa,openstack/python-cinderclient,master,Id29f0cee786205cc751d2d5bc031b3c105ae6aaa,Remove Python 2.5 compat shim,MERGED,2016-04-21 18:36:10.000000000,2016-05-11 13:03:50.000000000,2016-05-11 13:03:50.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 9535}, {'_account_id': 11600}]","[{'number': 1, 'created': '2016-04-21 18:36:10.000000000', 'files': ['cinderclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/dfefde11e1de46630415f37181cdf8300456f07f', 'message': ""Remove Python 2.5 compat shim\n\nWe don't support or test with Python 2.5.\n\nChange-Id: Id29f0cee786205cc751d2d5bc031b3c105ae6aaa\n""}]",0,309149,dfefde11e1de46630415f37181cdf8300456f07f,8,4,1,4523,,,0,"Remove Python 2.5 compat shim

We don't support or test with Python 2.5.

Change-Id: Id29f0cee786205cc751d2d5bc031b3c105ae6aaa
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/49/309149/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/client.py'],1,dfefde11e1de46630415f37181cdf8300456f07f,,,"# Python 2.5 compat fix if not hasattr(urlparse, 'parse_qsl'): import cgi urlparse.parse_qsl = cgi.parse_qsl ",0,5
openstack%2Fopenstack-ansible-plugins~master~I0e4c51e772f61d4879716b7b5dbe5c8211cea901,openstack/openstack-ansible-plugins,master,I0e4c51e772f61d4879716b7b5dbe5c8211cea901,Support users without projects in keystone library,MERGED,2016-05-10 20:34:17.000000000,2016-05-11 13:02:21.000000000,2016-05-11 10:42:13.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-10 20:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/d2e9408048398dce356131aade839655107b9ab3', 'message': 'Support users without projects in keystone library\n\nUpdate the ensure_user and ensure_user_role commands and dependent\nfunctions to allow creation of and role assignment to a user without\nspecifying a project.\n\nThis will allow use of the keystone library for creating users, such as\nthe heat stack admin, within only a domain.\n\nChange-Id: I0e4c51e772f61d4879716b7b5dbe5c8211cea901\n'}, {'number': 2, 'created': '2016-05-10 20:35:38.000000000', 'files': ['library/keystone'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/2e1492a127923a79ef3189433c4134df98c22502', 'message': 'Support users without projects in keystone library\n\nUpdate the ensure_user and ensure_user_role commands and dependent\nfunctions to allow creation of and role assignment to a user without\nspecifying a project.\n\nThis will allow use of the keystone library for creating users, such as\nthe heat stack admin, within only a domain.\n\nPartial-Bug: 1579612\nChange-Id: I0e4c51e772f61d4879716b7b5dbe5c8211cea901\n'}]",0,314761,2e1492a127923a79ef3189433c4134df98c22502,9,3,2,14805,,,0,"Support users without projects in keystone library

Update the ensure_user and ensure_user_role commands and dependent
functions to allow creation of and role assignment to a user without
specifying a project.

This will allow use of the keystone library for creating users, such as
the heat stack admin, within only a domain.

Partial-Bug: 1579612
Change-Id: I0e4c51e772f61d4879716b7b5dbe5c8211cea901
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/61/314761/1 && git format-patch -1 --stdout FETCH_HEAD,['library/keystone'],1,d2e9408048398dce356131aade839655107b9ab3,bug/1579612," 'role_name', 'domain_name' if project is None and project_name is not None: if project is None and project_name is not None: def _get_user_roles(self, name, user, project, domain): project=project, domain=domain name=role_name, user=user, project=project, domain=domain user=user, role=role, project=project, domain=domain name=role_name, user=user, project=project, domain=domain"," 'role_name' if project is None: if project is None: def _get_user_roles(self, name, user, project): project=project name=role_name, user=user, project=project user=user, role=role, project=project name=role_name, user=user, project=project",10,8
openstack%2Fnova~master~Ia4aa0e6378e1b327fb75b2f630279b35835ba095,openstack/nova,master,Ia4aa0e6378e1b327fb75b2f630279b35835ba095,Complete method verification of os-migrations,MERGED,2016-05-09 22:11:22.000000000,2016-05-11 12:58:45.000000000,2016-05-10 23:06:56.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 2750}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 18339}, {'_account_id': 19590}]","[{'number': 1, 'created': '2016-05-09 22:11:22.000000000', 'files': ['api-ref/source/os-migrations.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/f8870c6d26a3c63d47ecbf3e7fcf4282804674b9', 'message': 'Complete method verification of os-migrations\n\nCorrects the error status responses for os-migrations\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ia4aa0e6378e1b327fb75b2f630279b35835ba095\n'}]",0,314310,f8870c6d26a3c63d47ecbf3e7fcf4282804674b9,15,9,1,18337,,,0,"Complete method verification of os-migrations

Corrects the error status responses for os-migrations

Part of bp:api-ref-in-rst

Change-Id: Ia4aa0e6378e1b327fb75b2f630279b35835ba095
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/314310/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-migrations.inc'],1,f8870c6d26a3c63d47ecbf3e7fcf4282804674b9,bp/api-ref-in-rst,"Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: unauthorized(401), forbidden(403), itemNotFound(404)",".. needs:method_verificationPolicy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file.Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",3,4
openstack%2Fironic-python-agent~stable%2Fmitaka~I8b04bf726980fdcf6bd536c6bb28e30ac50658fb,openstack/ironic-python-agent,stable/mitaka,I8b04bf726980fdcf6bd536c6bb28e30ac50658fb,[inspection] wait for the PXE DHCP by default and remove the carrier check,MERGED,2016-05-10 18:35:35.000000000,2016-05-11 12:58:42.000000000,2016-05-11 12:58:42.000000000,"[{'_account_id': 3}, {'_account_id': 7080}, {'_account_id': 10343}]","[{'number': 1, 'created': '2016-05-10 18:35:35.000000000', 'files': ['ironic_python_agent/tests/unit/test_inspector.py', 'ironic_python_agent/inspector.py', 'releasenotes/notes/inspection-wait-for-ips-v2-146016f758d7010c.yaml', 'ironic_python_agent/cmd/agent.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ed978f312e1079c6eb7166947253007d141eb82d', 'message': ""[inspection] wait for the PXE DHCP by default and remove the carrier check\n\nWe hoped that checking /sys/class/net/XXX/carrier will allow us\nto not wait for interfaces that are not connected at all.\nIn reality this field turned out to be unreliable. For example, it is\nalso set to 0 when interface is down or is being configured.\nThe bug https://bugzilla.redhat.com/show_bug.cgi?id=1327255 shows\nthe case when carrier is 0 for all interfaces, including one that is\nused to post back data, which is obvious non-sense.\n\nThis change removes check on carrier for the loop. To avoid 60 seconds\nwait for people with several NIC's, it's changed to only wait for the\nPXE booting NIC, which obviously must get an IP address.\n\nThis makes IP addresses in the inspection data for other NIC's somewhat\nunreliable. A new option inspection_dhcp_all_interfaces is introduced\nto allow waiting for all NIC's to get IP addresses.\n\nThis change should finally fix bug 1564954.\n\nChange-Id: I8b04bf726980fdcf6bd536c6bb28e30ac50658fb\nRelated-Bug: #1564954\n(cherry picked from commit 6da6ace3840d56c7145ddf528bbdcbb813fc6ce2)\n""}]",0,314713,ed978f312e1079c6eb7166947253007d141eb82d,9,3,1,10239,,,0,"[inspection] wait for the PXE DHCP by default and remove the carrier check

We hoped that checking /sys/class/net/XXX/carrier will allow us
to not wait for interfaces that are not connected at all.
In reality this field turned out to be unreliable. For example, it is
also set to 0 when interface is down or is being configured.
The bug https://bugzilla.redhat.com/show_bug.cgi?id=1327255 shows
the case when carrier is 0 for all interfaces, including one that is
used to post back data, which is obvious non-sense.

This change removes check on carrier for the loop. To avoid 60 seconds
wait for people with several NIC's, it's changed to only wait for the
PXE booting NIC, which obviously must get an IP address.

This makes IP addresses in the inspection data for other NIC's somewhat
unreliable. A new option inspection_dhcp_all_interfaces is introduced
to allow waiting for all NIC's to get IP addresses.

This change should finally fix bug 1564954.

Change-Id: I8b04bf726980fdcf6bd536c6bb28e30ac50658fb
Related-Bug: #1564954
(cherry picked from commit 6da6ace3840d56c7145ddf528bbdcbb813fc6ce2)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/13/314713/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/test_inspector.py', 'ironic_python_agent/inspector.py', 'releasenotes/notes/inspection-wait-for-ips-v2-146016f758d7010c.yaml', 'ironic_python_agent/cmd/agent.py']",4,ed978f312e1079c6eb7166947253007d141eb82d,bug/1564954," help='Maximum time (in seconds) to wait for the PXE NIC ' '(or all NICs if inspection_dhcp_all_interfaces is True) ' 'to get its IP address via DHCP before inspection. ' cfg.BoolOpt('inspection_dhcp_all_interfaces', default=APARAMS.get('ipa-inspection-dhcp-all-interfaces', False), help='Whether to wait for all interfaces to get their IP ' 'addresses before inspection. If set to false ' '(the default), only waits for the PXE interface.'),", help='Maximum time (in seconds) to wait for all NIC\'s ' 'to get their IP addresses via DHCP before inspection. ',98,16
openstack%2Fheat~master~I0df5b872afeb123a743c964bde93114d38a55161,openstack/heat,master,I0df5b872afeb123a743c964bde93114d38a55161,Cleanup magnum client test case,MERGED,2016-05-09 06:07:28.000000000,2016-05-11 12:53:05.000000000,2016-05-11 12:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 8289}, {'_account_id': 10487}, {'_account_id': 12363}]","[{'number': 1, 'created': '2016-05-09 06:07:28.000000000', 'files': ['heat/tests/clients/test_magnum_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a9f38e1a7b8c891a8381b180d877d927a2b48407', 'message': 'Cleanup magnum client test case\n\nNow magnum client is part of requirments.txt so the conditional\ntesting part is removed from the magnum test case\n\nChange-Id: I0df5b872afeb123a743c964bde93114d38a55161\n'}]",0,313988,a9f38e1a7b8c891a8381b180d877d927a2b48407,11,4,1,10487,,,0,"Cleanup magnum client test case

Now magnum client is part of requirments.txt so the conditional
testing part is removed from the magnum test case

Change-Id: I0df5b872afeb123a743c964bde93114d38a55161
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/313988/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/clients/test_magnum_client.py'],1,a9f38e1a7b8c891a8381b180d877d927a2b48407,heat-cleanup-magnum-client-test-case,,"from oslo_utils import importutils import testtools magnum_client = importutils.try_import('magnumclient.v1.client') @testtools.skipIf(magnum_client is None, 'Tests the magnum client')",0,6
openstack%2Fironic~stable%2Fmitaka~I85a77dd2193bac0ea4bd4fc1985c82d9f598b06b,openstack/ironic,stable/mitaka,I85a77dd2193bac0ea4bd4fc1985c82d9f598b06b,Update tempest compute flavor_ref/flavor_ref_alt,MERGED,2016-05-10 16:18:01.000000000,2016-05-11 12:51:30.000000000,2016-05-11 12:51:30.000000000,"[{'_account_id': 3}, {'_account_id': 9542}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-05-10 16:18:01.000000000', 'files': ['devstack/lib/ironic', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/427c0b5f46a3d2387194904923e9452566aa850d', 'message': ""Update tempest compute flavor_ref/flavor_ref_alt\n\nAfter Ironic is moved to devstack plugin the tempest is always\nexecuted before ironic devstack plugin. Unfortunatly there is no quick\nway to change order.\nThis change introduce new function ironic_configure_tempest that is\ncalled from Ironic's devstack plugin. It updated flavor_ref and\nflavor_ref_alt compute tempest options.\n\nChange-Id: I85a77dd2193bac0ea4bd4fc1985c82d9f598b06b\n(cherry picked from commit ba15202d99b2c26ba3eaf319f1e3d20edb697483)\n""}]",0,314662,427c0b5f46a3d2387194904923e9452566aa850d,12,3,1,10343,,,0,"Update tempest compute flavor_ref/flavor_ref_alt

After Ironic is moved to devstack plugin the tempest is always
executed before ironic devstack plugin. Unfortunatly there is no quick
way to change order.
This change introduce new function ironic_configure_tempest that is
called from Ironic's devstack plugin. It updated flavor_ref and
flavor_ref_alt compute tempest options.

Change-Id: I85a77dd2193bac0ea4bd4fc1985c82d9f598b06b
(cherry picked from commit ba15202d99b2c26ba3eaf319f1e3d20edb697483)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/314662/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/ironic', 'devstack/plugin.sh']",2,427c0b5f46a3d2387194904923e9452566aa850d,(HEAD, if is_service_enabled tempest; then ironic_configure_tempest fi,,11,0
openstack%2Ftripleo-heat-templates~master~Ia61295943e67efe354a51a26fe4540f288ff6ede,openstack/tripleo-heat-templates,master,Ia61295943e67efe354a51a26fe4540f288ff6ede,composable neutron dhcp service,MERGED,2016-04-08 12:43:23.000000000,2016-05-11 12:48:35.000000000,2016-05-11 12:48:35.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6681}, {'_account_id': 6994}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 10419}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-04-08 12:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0339558409d0dc746c82e2e375cb42cbb0ee9036', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 2, 'created': '2016-04-08 18:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d64851f73eb1c242259e1cb895e5cdf242aeebdc', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 3, 'created': '2016-04-09 17:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/39521d133964bca437017a434a294445158446df', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 4, 'created': '2016-04-11 02:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/db462c4f109f08dc1eb7d9f6cdb14b1bf424007c', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 5, 'created': '2016-04-11 14:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/db8bd7eb815f5f3d19f2e496ec3a6867102eaab2', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 6, 'created': '2016-04-11 14:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e5cb4f18fd3640f01d1e904aea9a9465c038994c', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 7, 'created': '2016-04-11 18:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/300c7589b7d43eba60a239400a6f01baabd71a64', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 8, 'created': '2016-04-11 18:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d9118cf0c1efa67edc7c579ca31d819731efb0b7', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 9, 'created': '2016-04-12 13:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/89e6d3c6842576e8753af71b59929ddf56937ecd', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 10, 'created': '2016-04-13 21:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fffc6459debaba560a735e51bc7a0c731fb442a5', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 11, 'created': '2016-04-14 02:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7b04d90087defe99ddec42f7ea3819cd8c36edca', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 12, 'created': '2016-04-14 11:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eecbd3736b49b3be18d99c90500680b90dfb6d14', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 13, 'created': '2016-04-14 11:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8e3c31954699421d3ced0938864d1fbaf37e5c1b', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 14, 'created': '2016-04-14 11:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d6a98ec0052a11fed5e56257d8f1105c1fb199d2', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 15, 'created': '2016-04-14 15:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6e88c098975215610fe34215e079b71ffe3beb74', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 16, 'created': '2016-04-15 11:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6daf322dd6db48a3af82d5de7b4399f553277c57', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 17, 'created': '2016-04-18 16:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/62570a5896d87ffd00bad4865277c4a078da28b3', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 18, 'created': '2016-04-19 17:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4fc4f297570e4ad34d04756e255f9b9863fd8073', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 19, 'created': '2016-04-20 18:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a1e7eb3bc980fe74b63e243947778a6b3a887a20', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 20, 'created': '2016-04-21 01:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/69490266be71640ddc54d84e46b51c63763be45c', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 21, 'created': '2016-04-26 16:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee069c52a8cfea7a715ea07a1d51cb3b7adeb107', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nPartially-implements: blueprint composable-services-within-roles\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 22, 'created': '2016-05-10 19:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b790c75ace1efeb43bbe766b916befa7d7ffec17', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ida781badbcd63bbcb481a2170638aefe262b717b\n\nPartially-implements: blueprint composable-services-within-roles\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}, {'number': 23, 'created': '2016-05-11 01:53:32.000000000', 'files': ['environments/neutron-opencontrail.yaml', 'environments/neutron-plumgrid.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/services/neutron-dhcp.yaml', 'puppet/services/pacemaker/neutron-dhcp.yaml', 'puppet/manifests/overcloud_controller.pp', 'puppet/controller.yaml', 'overcloud.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'environments/puppet-pacemaker.yaml', 'puppet/hieradata/controller.yaml', 'puppet/services/neutron-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/27f7d220bd5a9d0a1deebe16dd1d6a3dee11af82', 'message': 'composable neutron dhcp service\n\nAdds new puppet and puppet pacemaker specific services for\nthe Neutron DHCP agent.\n\nDepends-On: Ibbfd79421f871e41f870745a593cca65e8c0e58a\n\nPartially-implements: blueprint composable-services-within-roles\n\nChange-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede\n'}]",12,303386,27f7d220bd5a9d0a1deebe16dd1d6a3dee11af82,122,10,23,360,,,0,"composable neutron dhcp service

Adds new puppet and puppet pacemaker specific services for
the Neutron DHCP agent.

Depends-On: Ibbfd79421f871e41f870745a593cca65e8c0e58a

Partially-implements: blueprint composable-services-within-roles

Change-Id: Ia61295943e67efe354a51a26fe4540f288ff6ede
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/303386/10 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/controller.yaml', 'overcloud-resource-registry-puppet.yaml', 'overcloud.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/services/neutron-dhcp.yaml', 'environments/puppet-pacemaker.yaml', 'puppet/services/pacemaker/neutron-dhcp.yaml', 'puppet/hieradata/controller.yaml', 'puppet/services/neutron-base.yaml']",10,0339558409d0dc746c82e2e375cb42cbb0ee9036,bp/composable-services-within-roles,"heat_template_version: 2016-04-08 description: > OpenStack Neutron base service. Shared for all Neutron agents. parameters: RabbitPassword: description: The password for RabbitMQ type: string hidden: true RabbitUserName: default: guest description: The username for RabbitMQ type: string RabbitClientUseSSL: default: false description: > Rabbit client subscriber parameter to specify an SSL connection to the RabbitMQ host. type: string RabbitClientPort: default: 5672 description: Set rabbit subscriber port, change this if using SSL type: number NeutronDhcpAgentsPerNetwork: type: number default: 3 description: The number of neutron dhcp agents to schedule per network outputs: role_data: description: Role data for the Neutron base service. value: config_settings: neutron::rabbit_password: {get_param: RabbitPassword} neutron::rabbit_user: {get_param: RabbitUserName} neutron::rabbit_use_ssl: {get_param: RabbitClientUseSSL} neutron::rabbit_port: {get_param: RabbitClientPort} neutron::dhcp_agents_per_network: {get_param: NeutronDhcpAgentsPerNetwork} ",,132,188
openstack%2Fcinder~master~I67c509c828cadbd0585b6badca733039d697eeea,openstack/cinder,master,I67c509c828cadbd0585b6badca733039d697eeea,Fix Lun ID 0 in HPE 3PAR driver,MERGED,2016-04-21 23:05:36.000000000,2016-05-11 12:47:12.000000000,2016-05-07 04:11:22.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 6043}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16917}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 21193}, {'_account_id': 21309}]","[{'number': 1, 'created': '2016-04-21 23:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8adc965199357081f13d1d5bba820087f3cc523', 'message': 'Fix Lun ID 0 in HPE 3PAR driver\n\nIf Lun ID is set to 0, auto is not disabled\nInstead, we checked if Lun_id is not None to disable auto.\n\nChange-Id: I67c509c828cadbd0585b6badca733039d697eeea\n'}, {'number': 2, 'created': '2016-04-21 23:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65652a248fbb0538f4a5475caf4fd46fde4f8ffc', 'message': 'Fix Lun ID 0 in HPE 3PAR driver\n\nIf Lun ID is set to 0, auto is not disabled.\nInstead, we checked if Lun_id is not None to disable auto.\n\nChange-Id: I67c509c828cadbd0585b6badca733039d697eeea\n'}, {'number': 3, 'created': '2016-04-21 23:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c1bf8d91f3d816df05de33d9f2b898808afd7d82', 'message': 'Fix Lun ID 0 in HPE 3PAR driver\n\nIf Lun ID is set to 0, auto is not disabled.\nInstead, we checked if Lun_id is not None to disable auto.\n\nCloses-Bug: #1573298\nChange-Id: I67c509c828cadbd0585b6badca733039d697eeea\n'}, {'number': 4, 'created': '2016-04-22 22:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4c94c6e0d88756fa9bd26acbbc53426d14ad95b5', 'message': 'Fix Lun ID 0 in HPE 3PAR driver\n\nIf Lun ID is set to 0, auto is not disabled.\nInstead, we checked if Lun_id is not None to disable auto.\nAdded unittest to verify auto\n\nCloses-Bug: #1573298\nChange-Id: I67c509c828cadbd0585b6badca733039d697eeea\n'}, {'number': 5, 'created': '2016-05-05 20:59:52.000000000', 'files': ['cinder/tests/unit/test_hpe3par.py', 'cinder/volume/drivers/hpe/hpe_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4649d3d830c3210734a75c8c5c0a733ddb5e694c', 'message': 'Fix Lun ID 0 in HPE 3PAR driver\n\nIf Lun ID is set to 0, auto is not disabled.\nInstead, we checked if Lun_id is not None to disable auto.\nAdded unittest to verify auto\n\nCloses-Bug: #1573298\nChange-Id: I67c509c828cadbd0585b6badca733039d697eeea\n'}]",4,309213,4649d3d830c3210734a75c8c5c0a733ddb5e694c,129,41,5,21309,,,0,"Fix Lun ID 0 in HPE 3PAR driver

If Lun ID is set to 0, auto is not disabled.
Instead, we checked if Lun_id is not None to disable auto.
Added unittest to verify auto

Closes-Bug: #1573298
Change-Id: I67c509c828cadbd0585b6badca733039d697eeea
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/309213/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/hpe/hpe_3par_common.py'],1,a8adc965199357081f13d1d5bba820087f3cc523,bug/1573298, if lun_id is not None:, if lun_id:,1,1
openstack%2Ffuel-ui~master~I8870f03e52af52c1e63dc54167432277586b1ac3,openstack/fuel-ui,master,I8870f03e52af52c1e63dc54167432277586b1ac3,Configuration for virt role fixed on UI,MERGED,2016-05-10 15:08:54.000000000,2016-05-11 12:45:27.000000000,2016-05-11 12:42:20.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-10 15:08:54.000000000', 'files': ['static/views/dialogs.js'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/69fb8b6a1a3207666d11b561e9d1e340b99da5dc', 'message': 'Configuration for virt role fixed on UI\n\nCloses-Bug: #1578526\n\nChange-Id: I8870f03e52af52c1e63dc54167432277586b1ac3\n'}]",2,314621,69fb8b6a1a3207666d11b561e9d1e340b99da5dc,19,5,1,9730,,,0,"Configuration for virt role fixed on UI

Closes-Bug: #1578526

Change-Id: I8870f03e52af52c1e63dc54167432277586b1ac3
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/21/314621/1 && git format-patch -1 --stdout FETCH_HEAD,['static/views/dialogs.js'],1,69fb8b6a1a3207666d11b561e9d1e340b99da5dc,bug/1578526," 'cpu', 'disks', 'interfaces', 'memory', 'system', 'numa_topology', 'config', 'attributes' if (this.state.VMsConf) groups.push('config');"," 'cpu', 'disks', 'interfaces', 'memory', 'system', 'numa_topology', 'attributes'",2,2
openstack%2Fsenlin~master~I6cf6bbaf381541b54519111d96693f75f000f05d,openstack/senlin,master,I6cf6bbaf381541b54519111d96693f75f000f05d,Add API document for cluster_policies,MERGED,2016-05-11 04:47:33.000000000,2016-05-11 12:42:00.000000000,2016-05-11 12:42:00.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 16803}]","[{'number': 1, 'created': '2016-05-11 04:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/7e30e8f9fc6d8a3ce4e2c7c7f841eb897911e8b0', 'message': 'Add API document for cluster_policies\n\nThis patch adds API document for cluster_policies\n\nChange-Id: I6cf6bbaf381541b54519111d96693f75f000f05d\n'}, {'number': 2, 'created': '2016-05-11 06:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/aafa605eccb4d9d76b00fb74fec19b93e389bee2', 'message': 'Add API document for cluster_policies\n\nThis patch adds API document for cluster_policies\n\nChange-Id: I6cf6bbaf381541b54519111d96693f75f000f05d\n'}, {'number': 3, 'created': '2016-05-11 06:44:21.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/samples/cluster-policies-list-response.json', 'api-ref/source/index.rst', 'api-ref/source/cluster_policies.inc', 'api-ref/source/samples/cluster-policy-show-response.json'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a29fb286ecf4e8c39a33d7824bd79d17db7897e2', 'message': 'Add API document for cluster_policies\n\nThis patch adds API document for cluster_policies\n\nChange-Id: I6cf6bbaf381541b54519111d96693f75f000f05d\n'}]",18,314859,a29fb286ecf4e8c39a33d7824bd79d17db7897e2,18,4,3,11034,,,0,"Add API document for cluster_policies

This patch adds API document for cluster_policies

Change-Id: I6cf6bbaf381541b54519111d96693f75f000f05d
",git fetch https://review.opendev.org/openstack/senlin refs/changes/59/314859/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/samples/cluster-policies-list-response.json', 'api-ref/source/index.rst', 'api-ref/source/cluster_policies.inc', 'api-ref/source/samples/cluster-policy-show-response.json']",5,7e30e8f9fc6d8a3ce4e2c7c7f841eb897911e8b0,api-doc,"{ ""cluster_policy"": { ""cluster_id"": ""7d85f602-a948-4a30-afd4-e84f47471c15"", ""cluster_name"": ""cluster4"", ""enabled"": true, ""id"": ""06be3a1f-b238-4a96-a737-ceec5714087e"", ""policy_id"": ""714fe676-a08f-4196-b7af-61d52eeded15"", ""policy_name"": ""dp01"", ""policy_type"": ""senlin.policy.deletion-1.0"" } } ",,175,1
openstack%2Fnetworking-generic-switch~master~I5685faab3598b98523d7eb78847015e16ae3657e,openstack/networking-generic-switch,master,I5685faab3598b98523d7eb78847015e16ae3657e,Load all devices in driver initialization,MERGED,2016-04-22 07:06:55.000000000,2016-05-11 12:40:53.000000000,2016-05-11 12:40:53.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 9542}, {'_account_id': 12232}, {'_account_id': 12356}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-04-22 07:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/87af5ef7da7422fe16498b5380eb1d2973098681', 'message': ""Load all devices in driver initialization\n\ninitialize method will be called by neutron after all drivers\nhave been loaded, it's the right place to do initialization work\nlike loading devices.\n\nChange-Id: I5685faab3598b98523d7eb78847015e16ae3657e\n""}, {'number': 2, 'created': '2016-04-25 02:58:14.000000000', 'files': ['networking_generic_switch/tests/unit/test_generic_switch_mech.py', 'networking_generic_switch/generic_switch_mech.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/38452e6db684ec3591c393f70e5db01d3bd3443e', 'message': ""Load all devices in driver initialization\n\ninitialize method will be called by neutron after all drivers\nhave been loaded, it's the right place to do initialization work\nlike loading devices.\n\nChange-Id: I5685faab3598b98523d7eb78847015e16ae3657e\n""}]",0,309285,38452e6db684ec3591c393f70e5db01d3bd3443e,20,6,2,6610,,,0,"Load all devices in driver initialization

initialize method will be called by neutron after all drivers
have been loaded, it's the right place to do initialization work
like loading devices.

Change-Id: I5685faab3598b98523d7eb78847015e16ae3657e
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/85/309285/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_generic_switch/tests/unit/test_generic_switch_mech.py', 'networking_generic_switch/generic_switch_mech.py']",2,87af5ef7da7422fe16498b5380eb1d2973098681,, self.gsw_devices = gsw_conf.get_devices() self.switches = [] for device_cfg in self.gsw_devices.values(): switch = devices.device_manager(device_cfg) self.switches.append(switch) for switch in self.switches: for switch in self.switches: if switch_info not in self.gsw_devices: switch = devices.device_manager(self.gsw_devices[switch_info]), pass gsw_devices = gsw_conf.get_devices() for device_cfg in gsw_devices.values(): switch = devices.device_manager(device_cfg) gsw_devices = gsw_conf.get_devices() for device_cfg in gsw_devices.values(): switch = devices.device_manager(device_cfg) gsw_devices = gsw_conf.get_devices() if switch_info not in gsw_devices: switch = devices.device_manager(gsw_devices[switch_info]),14,10
openstack%2Fsahara-dashboard~master~Id443d6a716309df0add9235634c27c2e12876b8e,openstack/sahara-dashboard,master,Id443d6a716309df0add9235634c27c2e12876b8e,Add testcases 'Update EDP resources',MERGED,2016-02-09 10:21:01.000000000,2016-05-11 12:34:12.000000000,2016-05-11 12:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 8090}, {'_account_id': 9740}, {'_account_id': 12038}, {'_account_id': 19265}]","[{'number': 1, 'created': '2016-02-09 10:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/bc281dd0c76d2fcc4fea286c37797329a16d2a69', 'message': ""Add testcases 'Update EDP resources'\n\nTestcases check updating data sources, job binaries, passing extra\nparameters to job templates on launching it.\n\nChange-Id: Id443d6a716309df0add9235634c27c2e12876b8e\n""}, {'number': 2, 'created': '2016-02-09 13:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/97b6d9ded94b717768ac9d4ee07b4661e5ff6c7e', 'message': ""Add testcases 'Update EDP resources'\n\nTestcases check updating data sources, job binaries, passing extra\nparameters to job templates on launching it.\n\nChange-Id: Id443d6a716309df0add9235634c27c2e12876b8e\n""}, {'number': 3, 'created': '2016-02-15 17:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/68f4b8258636dd377867f0a1d43addad2895b482', 'message': ""Add testcases 'Update EDP resources'\n\nTestcases check updating data sources, job binaries, passing extra\nparameters to job templates on launching it.\n\nChange-Id: Id443d6a716309df0add9235634c27c2e12876b8e\n""}, {'number': 4, 'created': '2016-04-06 10:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/d60021caffac58280a0cd70ceb255d724feaa2cf', 'message': ""Add testcases 'Update EDP resources'\n\nTestcases check updating data sources, job binaries, passing extra\nparameters to job templates on launching it.\n\nChange-Id: Id443d6a716309df0add9235634c27c2e12876b8e\n""}, {'number': 5, 'created': '2016-04-27 11:45:52.000000000', 'files': ['sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/jobbinariespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/datasourcespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/jobspage.py', 'sahara_dashboard/test/integration_tests/tests/test_crud.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/jobtemplatespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/clusters/nodegrouptemplatespage.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/10476765e7be0f4aff0813d09f065d2d4cb1932b', 'message': ""Add testcases 'Update EDP resources'\n\nTestcases check updating data sources, job binaries, passing extra\nparameters to job templates on launching it.\n\nChange-Id: Id443d6a716309df0add9235634c27c2e12876b8e\n""}]",0,277769,10476765e7be0f4aff0813d09f065d2d4cb1932b,25,5,5,19265,,,0,"Add testcases 'Update EDP resources'

Testcases check updating data sources, job binaries, passing extra
parameters to job templates on launching it.

Change-Id: Id443d6a716309df0add9235634c27c2e12876b8e
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/69/277769/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/test/integration_tests/pages/project/data_processing/jobbinariespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobspage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/datasourcespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobtemplatespage.py', 'sahara_dashboard/test/integration_tests/tests/test_crud.py']",5,bc281dd0c76d2fcc4fea286c37797329a16d2a69,update_edp_resources,"class TestCRUDBase(SaharaTestCase): super(TestCRUDBase, self).setUp() self.ds_input_name = gen_name('input') self.ds_output_name = gen_name('output') self.job_binary_name = gen_name('function') self.jobtemplate_name = gen_name('test-job') def create_flavor(self): def delete_flavor(self): flavors_page = self.home_pg.go_to_system_flavorspage() flavors_page.delete_flavor(FLAVOR_NAME) self.assertFalse(flavors_page.is_flavor_present(FLAVOR_NAME)) def create_image(self): def delete_image(self): image_pg = self.home_pg.go_to_compute_imagespage() image_pg.delete_image(IMAGE_NAME) def register_image(self): def unregister_image(self): image_reg_pg = self.home_pg.go_to_dataprocessing_imageregistrypage() image_reg_pg.unregister_image(IMAGE_NAME) def create_datasources(self): datasource_pg.create(name=self.ds_input_name, source_type=""HDFS"", datasource_pg.create(name=self.ds_output_name, source_type=""Swift"", def delete_datasources(self): datasource_pg = self.home_pg.go_to_dataprocessing_datasourcespage() datasource_pg.delete(self.ds_input_name) datasource_pg.delete(self.ds_output_name) def create_job_binary(self): job_binary_pg.create_job_binary_from_file( self.job_binary_name, __file__) self.assertTrue( job_binary_pg.is_job_binary_present(self.job_binary_name), ""Job binary is not in the binaries job table after its creation."") def delete_job_binary(self): job_binary_pg = self.home_pg.go_to_dataprocessing_jobbinariespage() job_binary_pg.delete_job_binary(self.job_binary_name) self.assertFalse( job_binary_pg.is_job_binary_present(self.job_binary_name), ""Job binary was not removed from binaries job table."") def create_job_template(self): jobtemplates_pg.create(name=self.jobtemplate_name, job_type='Pig', binary_name=self.job_binary_name) def delete_job_template(self): jobtemplates_pg = self.home_pg.go_to_dataprocessing_jobtemplatespage() jobtemplates_pg.delete(self.jobtemplate_name) def run_edp_job(self): jobtemplates_pg = self.home_pg.go_to_dataprocessing_jobtemplatespage() jobtemplates_pg.launch_on_exists(job_name=self.jobtemplate_name, input_name=self.ds_input_name, output_name=self.ds_output_name, jobs_pg.wait_until_job_succeeded(self.jobtemplate_name) def delete_job(self): jobs_pg = self.home_pg.go_to_dataprocessing_jobspage() jobs_pg.delete(self.jobtemplate_name) class TestCRUD(TestCRUDBase): def setUp(self): super(TestCRUD, self).setUp() self.create_flavor() self.create_image() self.register_image() def test_cluster_create_scale_delete(self): self.create_cluster() self.cluster_scale() self.delete_cluster() def test_run_edp_job(self): self.create_cluster() self.create_datasources() self.create_job_binary() self.create_job_template() self.run_edp_job() self.delete_job() self.delete_job_template() self.delete_job_binary() self.delete_datasources() self.delete_cluster() def tearDown(self): self.unregister_image() self.delete_image() self.delete_flavor() class TestUpdateDataSource(SaharaTestCase): def setUp(self): super(TestUpdateDataSource, self).setUp() datasource_pg = self.home_pg.go_to_dataprocessing_datasourcespage() self.name = gen_name('input') self.new_name = '{}-new'.format(self.name) datasource_pg.create(name=self.name, source_type=""HDFS"", url=""hdfs://user/input"") def test_update(self): datasource_pg = self.home_pg.go_to_dataprocessing_datasourcespage() kwargs = { 'data_source_name': self.new_name, 'data_source_type': 'Swift', 'data_source_url': 'swift://test', 'data_source_credential_user': 'test-user', 'data_source_credential_pass': 'test-password', 'data_source_description': '{} description'.format(self.new_name), } datasource_pg.update(self.name, **kwargs) self.assertTrue(datasource_pg.has_success_message()) self.assertFalse(datasource_pg.has_error_message()) self.assertTrue(datasource_pg.is_present(self.new_name), ""Node group template was not updated."") details = datasource_pg.get_details(self.new_name) expected = { 'Description': kwargs['data_source_description'], 'Name': self.new_name, 'Type': 'swift', 'URL': 'swift://test' } details = {k: v for k, v in details.items() if k in expected} self.assertEqual(expected, details) def tearDown(self): datasource_pg = self.home_pg.go_to_dataprocessing_datasourcespage() datasource_pg.delete_many([self.name, self.new_name]) super(TestUpdateDataSource, self).tearDown() class TestUpdateJobBinaries(SaharaTestCase): def setUp(self): super(TestUpdateJobBinaries, self).setUp() # create job binary job_binary_pg = self.home_pg.go_to_dataprocessing_jobbinariespage() self.name = gen_name('function') self.new_name = '{}-new'.format(self.name) job_binary_pg.create_job_binary_from_file(self.name, __file__) def test_update(self): job_binary_pg = self.home_pg.go_to_dataprocessing_jobbinariespage() kwargs = { ""job_binary_name"": self.new_name, ""job_binary_type"": ""Internal database"", ""job_binary_internal"": ""*Create a script"", ""job_binary_script_name"": ""script-name"", ""job_binary_script"": ""script-text"", ""job_binary_description"": ""{} description"".format(self.new_name), } job_binary_pg.update_job_binary(self.name, **kwargs) self.assertTrue(job_binary_pg.has_success_message()) self.assertFalse(job_binary_pg.has_error_message()) self.assertTrue(job_binary_pg.is_job_binary_present(self.new_name), ""Job binary was not updated."") details = job_binary_pg.get_details(self.new_name) expected = { 'Description': kwargs['job_binary_description'], 'Name': self.new_name, } details = {k: v for k, v in details.items() if k in expected} self.assertEqual(expected, details) def tearDown(self): job_binary_pg = self.home_pg.go_to_dataprocessing_jobbinariespage() for name in (self.name, self.new_name): try: job_binary_pg.delete_job_binary(name) except Exception: pass super(TestUpdateJobBinaries, self).tearDown() class TestLaunchJobWithParameters(TestCRUDBase): def setUp(self): super(TestLaunchJobWithParameters, self).setUp() self.create_flavor() self.create_image() self.register_image() self.create_cluster() self.create_datasources() self.create_job_binary() self.create_job_template() def test_launch_with_parameters(self): jobtemplates_pg = self.home_pg.go_to_dataprocessing_jobtemplatespage() jobtemplates_pg.launch_on_exists(job_name=self.jobtemplate_name, input_name=self.ds_input_name, output_name=self.ds_output_name, cluster_name=CLUSTER_NAME, adapt_swift=False, datasource_substitution=False, configuration={'foo': 'bar'}, parameters={'key': 'value'}, arguments=('one', 'two')) jobs_pg = self.home_pg.go_to_dataprocessing_jobspage() details = jobs_pg.get_details(self.jobtemplate_name) expected = { 'Job Configuration': { 'configs': set([ 'edp.substitute_data_source_for_name = False', 'foo = bar', 'edp.substitute_data_source_for_uuid = False' ]), 'params': set(['key = value']), 'args': set(['one', 'two']), 'job_execution_info': set([]), }, 'Job Template': self.jobtemplate_name, } details = {k: v for k, v in details.items() if k in expected} self.assertEqual(expected, details) self.delete_job() def tearDown(self): self.delete_job_template() self.delete_job_binary() self.delete_datasources() self.delete_cluster() self.unregister_image() self.delete_image() self.delete_flavor() super(TestLaunchJobWithParameters, self).tearDown()","class TestCRUD(SaharaTestCase): super(TestCRUD, self).setUp() def run_edp_job(self): input_name = gen_name('input') datasource_pg.create(name=input_name, source_type=""HDFS"", output_name = gen_name('output') datasource_pg.create(name=output_name, source_type=""Swift"", # create job binary job_binary_name = gen_name('function') job_binary_pg.create_job_binary_from_file(job_binary_name, __file__) self.assertTrue(job_binary_pg.is_job_binary_present(job_binary_name), ""Job binary is not in the binaries job table after"" "" its creation."") # create job template jobtemplate_name = gen_name('test-job') jobtemplates_pg.create(name=jobtemplate_name, job_type='Pig', binary_name=job_binary_name) # launch job jobtemplates_pg.launch_on_exists(job_name=jobtemplate_name, input_name=input_name, output_name=output_name, jobs_pg.wait_until_job_succeeded(jobtemplate_name) # delete job jobs_pg.delete(jobtemplate_name) # delete job_template jobtemplates_pg = self.home_pg.go_to_dataprocessing_jobtemplatespage() jobtemplates_pg.delete(jobtemplate_name) # delete job binary job_binary_pg = self.home_pg.go_to_dataprocessing_jobbinariespage() job_binary_pg.delete_job_binary(job_binary_name) self.assertFalse(job_binary_pg.is_job_binary_present(job_binary_name), ""Job binary was not removed from binaries job table."") datasource_pg = self.home_pg.go_to_dataprocessing_datasourcespage() datasource_pg.delete(input_name) datasource_pg.delete(output_name) def test_cluster_create_scale_delete(self): self.create_cluster() self.cluster_scale() self.delete_cluster() def test_run_edp_job(self): self.create_cluster() self.run_edp_job() self.delete_cluster() def tearDown(self): image_reg_pg = self.home_pg.go_to_dataprocessing_imageregistrypage() image_reg_pg.unregister_image(IMAGE_NAME) image_pg = self.home_pg.go_to_compute_imagespage() image_pg.delete_image(IMAGE_NAME) flavors_page = self.home_pg.go_to_system_flavorspage() flavors_page.delete_flavor(FLAVOR_NAME) self.assertFalse(flavors_page.is_flavor_present(FLAVOR_NAME))",401,96
openstack%2Fproject-config~master~Ibfcafdc3608299563704708af4cac1ee737c5311,openstack/project-config,master,Ibfcafdc3608299563704708af4cac1ee737c5311,Add new project Higgins to openstack repo,MERGED,2016-05-08 14:31:56.000000000,2016-05-11 12:02:53.000000000,2016-05-11 12:02:53.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 1726}, {'_account_id': 5638}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 8246}, {'_account_id': 10206}, {'_account_id': 11034}, {'_account_id': 11208}, {'_account_id': 11536}, {'_account_id': 11809}, {'_account_id': 12385}, {'_account_id': 16308}, {'_account_id': 19457}]","[{'number': 1, 'created': '2016-05-08 14:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3cc65477c44605da4ec7b81c52b258a7df0665bb', 'message': 'Add new project Higgins to openstack repo\n\nHiggens is an OpenStack Container Management Service making container\navailable as first class resources in OpenStack. It aims to provide\nan unified API or launching and managing containers backed by\ndifferent container technologies.\n\nMagnum is the original OpenStack Container Service, but this is\ngoing to change [1]. In the future, Magnum will focus on deploying\nand managing Container Orchestraction Engines (COEs), and the job of\nmanaging container life-cycle will go into Higgins.\n\n[1] https://review.openstack.org/#/c/311476/\n\nChange-Id: Ibfcafdc3608299563704708af4cac1ee737c5311\n'}, {'number': 2, 'created': '2016-05-08 15:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/efacd59989c501d6286381d031108de914645cc6', 'message': 'Add new project Higgins to openstack repo\n\nHiggens is an OpenStack Container Management Service making container\navailable as first class resources in OpenStack. It aims to provide\nan unified API or launching and managing containers backed by\ndifferent container technologies.\n\nMagnum is the original OpenStack Container Service, but this is\ngoing to change [1]. In the future, Magnum will focus on deploying\nand managing Container Orchestraction Engines (COEs), and the job of\nmanaging container life-cycle will go into Higgins.\n\n[1] https://review.openstack.org/#/c/311476/\n\nChange-Id: Ibfcafdc3608299563704708af4cac1ee737c5311\n'}, {'number': 3, 'created': '2016-05-08 15:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/62e781647f97e2dc38e32dd195c90aba0cffd546', 'message': 'Add new project Higgins to openstack repo\n\nHiggens is an OpenStack Container Management Service making container\navailable as first class resources in OpenStack. It aims to provide\nan unified API or launching and managing containers backed by\ndifferent container technologies.\n\nMagnum is the original OpenStack Container Service, but this is\ngoing to change [1]. In the future, Magnum will focus on deploying\nand managing Container Orchestraction Engines (COEs), and the job of\nmanaging container life-cycle will go into Higgins.\n\n[1] https://review.openstack.org/#/c/311476/\n\nChange-Id: Ibfcafdc3608299563704708af4cac1ee737c5311\n'}, {'number': 4, 'created': '2016-05-09 14:06:04.000000000', 'files': ['gerritbot/channels.yaml', 'accessbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/acls/openstack/higgins.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cb93466b1b20d7668d9f6f38d0a0af1ebcbd09c5', 'message': 'Add new project Higgins to openstack repo\n\nHiggins is a Container Management Service for OpenStack to make\ncontainer available as first class resources in OpenStack. It aims\nto provide an unified API or launching and managing containers\nbacked by different container technologies.\n\nMagnum is the original OpenStack Container Service, but this is\ngoing to change [1]. In the future, Magnum will focus on deploying\nand managing Container Orchestraction Engines (COEs), and the job of\nmanaging container life-cycle will go into Higgins, which is\nindependent of Magnum.\n\nHiggins is not an official OpenStack project yet, but we will work\nhard to make it become an official project.\n\n[1] https://review.openstack.org/#/c/311476/\n\nChange-Id: Ibfcafdc3608299563704708af4cac1ee737c5311\n'}]",16,313935,cb93466b1b20d7668d9f6f38d0a0af1ebcbd09c5,40,16,4,11536,,,0,"Add new project Higgins to openstack repo

Higgins is a Container Management Service for OpenStack to make
container available as first class resources in OpenStack. It aims
to provide an unified API or launching and managing containers
backed by different container technologies.

Magnum is the original OpenStack Container Service, but this is
going to change [1]. In the future, Magnum will focus on deploying
and managing Container Orchestraction Engines (COEs), and the job of
managing container life-cycle will go into Higgins, which is
independent of Magnum.

Higgins is not an official OpenStack project yet, but we will work
hard to make it become an official project.

[1] https://review.openstack.org/#/c/311476/

Change-Id: Ibfcafdc3608299563704708af4cac1ee737c5311
",git fetch https://review.opendev.org/openstack/project-config refs/changes/35/313935/4 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/acls/openstack/higgins.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,3cc65477c44605da4ec7b81c52b258a7df0665bb,new-project, - name: openstack/higgins template: - name: merge-check - name: python-jobs - name: check-requirements ,,43,0
openstack%2Fsenlin-dashboard~master~I6cd74ec5722e178a5a62962c08eb24d34584496d,openstack/senlin-dashboard,master,I6cd74ec5722e178a5a62962c08eb24d34584496d,Add sort key and dir for cluster_list,MERGED,2016-05-10 12:39:17.000000000,2016-05-11 12:02:12.000000000,2016-05-11 12:02:12.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-05-10 12:39:17.000000000', 'files': ['senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/receivers/forms.py', 'senlin_dashboard/cluster/nodes/forms.py', 'senlin_dashboard/test/api_tests/senlin_tests.py', 'senlin_dashboard/cluster/clusters/views.py', 'senlin_dashboard/cluster/nodes/tests.py', 'senlin_dashboard/cluster/receivers/tests.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/85ecd9079dbae22e83061f3cef6db66e498425cc', 'message': 'Add sort key and dir for cluster_list\n\nChange-Id: I6cd74ec5722e178a5a62962c08eb24d34584496d\nPartial-Bug: #1580160\n'}]",0,314537,85ecd9079dbae22e83061f3cef6db66e498425cc,7,3,1,6763,,,0,"Add sort key and dir for cluster_list

Change-Id: I6cd74ec5722e178a5a62962c08eb24d34584496d
Partial-Bug: #1580160
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/37/314537/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/receivers/forms.py', 'senlin_dashboard/cluster/nodes/forms.py', 'senlin_dashboard/test/api_tests/senlin_tests.py', 'senlin_dashboard/cluster/clusters/views.py', 'senlin_dashboard/cluster/nodes/tests.py', 'senlin_dashboard/cluster/receivers/tests.py']",8,85ecd9079dbae22e83061f3cef6db66e498425cc,bug/1580160, IsA(http.HttpRequest)).AndReturn(clusters)," IsA(http.HttpRequest), params={}).AndReturn(clusters)",13,12
openstack%2Fsenlin-dashboard~master~I8982795de637637350cc32623c15c328608fbd22,openstack/senlin-dashboard,master,I8982795de637637350cc32623c15c328608fbd22,Add sort key and dir for profile_list,MERGED,2016-05-10 12:34:18.000000000,2016-05-11 12:02:06.000000000,2016-05-11 12:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-05-10 12:34:18.000000000', 'files': ['senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/profiles/tests.py', 'senlin_dashboard/cluster/clusters/forms.py', 'senlin_dashboard/cluster/nodes/forms.py', 'senlin_dashboard/test/api_tests/senlin_tests.py', 'senlin_dashboard/cluster/profiles/views.py', 'senlin_dashboard/cluster/nodes/tests.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/e202c4454dd612556c1de02a21430a682e9a36fd', 'message': 'Add sort key and dir for profile_list\n\nChange-Id: I8982795de637637350cc32623c15c328608fbd22\nPartial-Bug: #1580160\n'}]",0,314535,e202c4454dd612556c1de02a21430a682e9a36fd,7,3,1,6763,,,0,"Add sort key and dir for profile_list

Change-Id: I8982795de637637350cc32623c15c328608fbd22
Partial-Bug: #1580160
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/35/314535/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/profiles/tests.py', 'senlin_dashboard/cluster/clusters/forms.py', 'senlin_dashboard/cluster/nodes/forms.py', 'senlin_dashboard/test/api_tests/senlin_tests.py', 'senlin_dashboard/cluster/nodes/tests.py', 'senlin_dashboard/cluster/profiles/views.py']",8,e202c4454dd612556c1de02a21430a682e9a36fd,bug/1580160, profiles = senlin.profile_list(self.request)," params = {} profiles = senlin.profile_list(self.request, params)",14,13
openstack%2Fheat~master~I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf,openstack/heat,master,I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf,Enable client plugin to support dynamic api version,MERGED,2015-12-09 19:10:59.000000000,2016-05-11 11:42:36.000000000,2016-05-11 11:42:36.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8399}, {'_account_id': 10487}, {'_account_id': 13009}, {'_account_id': 13720}, {'_account_id': 16929}]","[{'number': 1, 'created': '2015-12-09 19:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4d0b99becfbb7e43152b8e7fccbf61e132aa10e6', 'message': 'WIP Add multi-version supportability in client plugin\n\nSome resource plugin would need to use multiple versions\nof service api for a given client. This patch enables this support.\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 2, 'created': '2015-12-10 09:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4da958778c5bef893c02a10c450d07f1a3e1dbd8', 'message': 'WIP Add multi-version supportability in client plugin\n\nSome resource plugin would need to use multiple versions\nof service api for a given client. This patch enables this support.\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 3, 'created': '2015-12-14 10:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f75375c7113a86d03ac4c98789adfcedd5c79492', 'message': 'Add multi-version supportability in client plugin\n\nSome resource plugin would need to use multiple versions\nof service api for a given client. This patch enables this support.\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 4, 'created': '2015-12-15 03:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/65a1058ad6de6128197ade236c248fd98ee09ec9', 'message': 'Add multi-version supportability in client plugin\n\nSome resource plugins require to use multiple versions given\nservice api such as glance resource plugin needs v1 and v2.\nThis patch enables this support.\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 5, 'created': '2016-02-26 00:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ce5ddd7fefd943928f7c870ff25a7ce7dbbcbc93', 'message': 'Enable client plugin to support dynamic api version\n\nIt helps client plugin to create client based on the required api\nversion given at run time instead of hard-coded version.\n\nimplements blueprint enable-client-plugin-to-use-a-given-service-api-version\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 6, 'created': '2016-02-26 04:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7fc9375b598309463e024029f1066d8fdf8f792a', 'message': 'Enable client plugin to support dynamic api version\n\nIt helps client plugin to create client based on the required api\nversion given at run time instead of hard-coded version.\n\nimplements blueprint enable-client-plugin-to-use-a-given-service-api-version\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 7, 'created': '2016-03-17 17:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/512660165dcaf1b793dc91ddec34e2a00b0a9f84', 'message': 'Enable client plugin to support dynamic api version\n\nIt helps client plugin to create client based on the required api\nversion given at run time instead of hard-coded version.\n\nimplements blueprint enable-client-plugin-to-use-a-given-service-api-version\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 8, 'created': '2016-04-11 11:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa4154fda365b346ec9357bb978e761bbf55d4a4', 'message': 'Enable client plugin to support dynamic api version\n\nIt helps client plugin to create client based on the required api\nversion given at run time instead of hard-coded version.\n\nimplements blueprint enable-client-plugin-to-use-a-given-service-api-version\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 9, 'created': '2016-05-09 06:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/717cbd8079495d94adb0ee639b4e24d4a64ecf66', 'message': 'Enable client plugin to support dynamic api version\n\nIt helps client plugin to create client based on the required api\nversion given at run time instead of hard-coded version.\n\nimplements blueprint enable-client-plugin-to-use-a-given-service-api-version\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}, {'number': 10, 'created': '2016-05-09 09:11:41.000000000', 'files': ['heat/tests/clients/test_neutron_client.py', 'heat/engine/clients/client_plugin.py', 'heat/tests/clients/test_manila_client.py', 'heat/tests/clients/test_barbican_client.py', 'heat/tests/clients/test_clients.py', 'heat/tests/clients/test_sahara_client.py', 'heat/common/exception.py', 'heat/tests/clients/test_swift_client.py', 'heat/engine/resource.py', 'heat/tests/clients/test_cinder_client.py', 'heat/engine/clients/__init__.py', 'heat/tests/clients/test_glance_client.py', 'heat/tests/clients/test_nova_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/00d3677615b0587fc05e3043ee0a3a10d237c780', 'message': 'Enable client plugin to support dynamic api version\n\nIt helps client plugin to create client based on the required api\nversion given at run time instead of hard-coded version.\n\nimplements blueprint enable-client-plugin-to-use-a-given-service-api-version\n\nChange-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf\n'}]",20,255443,00d3677615b0587fc05e3043ee0a3a10d237c780,52,10,10,10487,,,0,"Enable client plugin to support dynamic api version

It helps client plugin to create client based on the required api
version given at run time instead of hard-coded version.

implements blueprint enable-client-plugin-to-use-a-given-service-api-version

Change-Id: I1cf3cdf498b7a97b6aa262eb3012edda8ad2aaaf
",git fetch https://review.opendev.org/openstack/heat refs/changes/43/255443/10 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/exception.py', 'heat/engine/clients/client_plugin.py', 'heat/engine/resource.py']",3,4d0b99becfbb7e43152b8e7fccbf61e132aa10e6,bp/enable-client-plugin-to-use-a-given-service-api-version," def client(self, name=None, version=None):"," def client(self, name=None):",39,14
openstack%2Fironic-inspector~master~If442fe5db8484900a5bd688e02d77d5bed69b326,openstack/ironic-inspector,master,If442fe5db8484900a5bd688e02d77d5bed69b326,Ensure rules documentation examples are valid JSON,MERGED,2016-05-11 10:29:45.000000000,2016-05-11 11:41:59.000000000,2016-05-11 11:41:59.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 13636}, {'_account_id': 18653}, {'_account_id': 18893}]","[{'number': 1, 'created': '2016-05-11 10:29:45.000000000', 'files': ['doc/source/usage.rst'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ef8033679639854b1e86f0dbcda3088f96333f80', 'message': ""Ensure rules documentation examples are valid JSON\n\nCurrent documentation uses python syntax to explain the structure of the\nintrospection rules, this is misleading as we're actually expecting JSON\ninput on the rules API. This patch converts all rule examples to use\nJSON syntax to prevent confusion.\n\nChange-Id: If442fe5db8484900a5bd688e02d77d5bed69b326\nCloses-Bug: #1564238\n""}]",0,314953,ef8033679639854b1e86f0dbcda3088f96333f80,9,5,1,6637,,,0,"Ensure rules documentation examples are valid JSON

Current documentation uses python syntax to explain the structure of the
introspection rules, this is misleading as we're actually expecting JSON
input on the rules API. This patch converts all rule examples to use
JSON syntax to prevent confusion.

Change-Id: If442fe5db8484900a5bd688e02d77d5bed69b326
Closes-Bug: #1564238
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/53/314953/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/usage.rst'],1,ef8033679639854b1e86f0dbcda3088f96333f80,bug/1564238," {""field"": ""node://property.path"", ""op"": ""eq"", ""value"": ""val""} {""field"": ""data://introspection.path"", ""op"": ""eq"", ""value"": ""val""} {""action"": ""set-attribute"", ""path"": ""/driver_info/ipmi_address"", ""value"": ""{data[inventory][bmc_address]}""} [{ ""description"": ""Set IPMI driver_info if no credentials"", ""actions"": [ {""action"": ""set-attribute"", ""path"": ""driver"", ""value"": ""agent_ipmitool""}, {""action"": ""set-attribute"", ""path"": ""driver_info/ipmi_username"", ""value"": ""username""}, {""action"": ""set-attribute"", ""path"": ""driver_info/ipmi_password"", ""value"": ""password""} ], ""conditions"": [ {""op"": ""is-empty"", ""field"": ""node://driver_info.ipmi_password""}, {""op"": ""is-empty"", ""field"": ""node://driver_info.ipmi_username""} ] },{ ""description"": ""Set deploy info if not already set on node"", ""actions"": [ {""action"": ""set-attribute"", ""path"": ""driver_info/deploy_kernel"", ""value"": ""<glance uuid>""}, {""action"": ""set-attribute"", ""path"": ""driver_info/deploy_ramdisk"", ""value"": ""<glance uuid>""} ], ""conditions"": [ {""op"": ""is-empty"", ""field"": ""node://driver_info.deploy_ramdisk""}, {""op"": ""is-empty"", ""field"": ""node://driver_info.deploy_kernel""} ] }] { ""description"": ""Enroll auto-discovered nodes with fake driver"", ""actions"": [ {""action"": ""set-attribute"", ""path"": ""driver"", ""value"": ""fake""} ], ""conditions"": [ {""op"": ""eq"", ""field"": ""data://auto_discovered"", ""value"": true} ] }"," {'field': 'node://property.path', 'op': 'eq', 'value': 'val'} {'field': 'data://introspection.path', 'op': 'eq', 'value': 'val'} {'action': 'set-attribute', 'path': '/driver_info/ipmi_address', 'value': '{data[inventory][bmc_address]}'} ""description"": ""Set IPMI driver_info if no credentials"", ""actions"": [ {'action': 'set-attribute', 'path': 'driver', 'value': 'agent_ipmitool'}, {'action': 'set-attribute', 'path': 'driver_info/ipmi_username', 'value': 'username'}, {'action': 'set-attribute', 'path': 'driver_info/ipmi_password', 'value': 'password'} ] ""conditions"": [ {'op': 'is-empty', 'field': 'node://driver_info.ipmi_password'}, {'op': 'is-empty', 'field': 'node://driver_info.ipmi_username'} ] ""description"": ""Set deploy info if not already set on node"", ""actions"": [ {'action': 'set-attribute', 'path': 'driver_info/deploy_kernel', 'value': '<glance uuid>'}, {'action': 'set-attribute', 'path': 'driver_info/deploy_ramdisk', 'value': '<glance uuid>'}, ] ""conditions"": [ {'op': 'is-empty', 'field': 'node://driver_info.deploy_ramdisk'}, {'op': 'is-empty', 'field': 'node://driver_info.deploy_kernel'} ] ""description"": ""Enroll auto-discovered nodes with fake driver"", ""actions"": [ {'action': 'set-attribute', 'path': 'driver', 'value': 'fake'} ] ""conditions"": [ {'op': 'eq', 'field': 'data://auto_discovered', 'value': True} ]",39,35
openstack%2Fpython-openstackclient~master~I37c73391a41ac239dd72d55dbc0adbebd7701f4a,openstack/python-openstackclient,master,I37c73391a41ac239dd72d55dbc0adbebd7701f4a,"Implement ""address scope create"" command",MERGED,2016-04-20 10:36:28.000000000,2016-05-11 11:39:42.000000000,2016-05-11 06:42:25.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8276}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17776}, {'_account_id': 21514}]","[{'number': 1, 'created': '2016-04-20 10:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/208548c7eae8701e2af79b0dedd42f221776f429', 'message': 'Implement ""address scope create"" command\n\nThis patch supports creating a new address scope,\nwith --ip-version,--project,--project-domain\nand --share or --no-share options.\n\nChange-Id: I37c73391a41ac239dd72d55dbc0adbebd7701f4a\nPartial-Bug: #1566269\n'}, {'number': 2, 'created': '2016-05-07 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/01f61ec60654dd509e96d3b62f459aea54438499', 'message': 'Implement ""address scope create"" command\n\nThis patch supports creating a new address scope,\nwith --ip-version,--project,--project-domain\nand --share or --no-share options.\n\nChange-Id: I37c73391a41ac239dd72d55dbc0adbebd7701f4a\nPartial-Bug: #1566269\n'}, {'number': 3, 'created': '2016-05-09 08:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6cd12845f54d6e590d20d2ba35402715070bb6b9', 'message': 'Implement ""address scope create"" command\n\nThis patch supports creating a new address scope,\nwith --ip-version,--project,--project-domain\nand --share or --no-share options.\n\nChange-Id: I37c73391a41ac239dd72d55dbc0adbebd7701f4a\nPartial-Bug: #1566269\n'}, {'number': 4, 'created': '2016-05-11 02:09:44.000000000', 'files': ['doc/source/commands.rst', 'openstackclient/tests/network/v2/test_address_scope.py', 'doc/source/command-objects/address-scope.rst', 'openstackclient/network/v2/address_scope.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/98bee08e0ff9bd0eae185265d20ee3b40a12efd4', 'message': 'Implement ""address scope create"" command\n\nThis patch supports creating a new address scope,\nwith --ip-version,--project,--project-domain\nand --share or --no-share options.\n\nChange-Id: I37c73391a41ac239dd72d55dbc0adbebd7701f4a\nPartial-Bug: #1566269\n'}]",48,308256,98bee08e0ff9bd0eae185265d20ee3b40a12efd4,36,8,4,21514,,,0,"Implement ""address scope create"" command

This patch supports creating a new address scope,
with --ip-version,--project,--project-domain
and --share or --no-share options.

Change-Id: I37c73391a41ac239dd72d55dbc0adbebd7701f4a
Partial-Bug: #1566269
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/56/308256/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_address_scope.py', 'openstackclient/network/v2/address_scope.py', 'setup.cfg']",3,208548c7eae8701e2af79b0dedd42f221776f429,bug/1566269, address_scope_create = openstackclient.network.v2.address_scope:CreateAddressScope ,,270,0
openstack%2Fswift~feature%2Fcrypto~I2b573c32d10b4ab0b59aee8d36ad858e48a7e26b,openstack/swift,feature/crypto,I2b573c32d10b4ab0b59aee8d36ad858e48a7e26b,crypto - add functional test to verify container listing detail,MERGED,2016-04-18 11:41:31.000000000,2016-05-11 11:34:11.000000000,2016-05-11 11:34:11.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 12279}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-04-18 11:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/20e7718195a8da1d534a7a5a7fc39c1f4d4cee94', 'message': 'crypto - add functional test to verify container listing detail\n\nChange-Id: I2b573c32d10b4ab0b59aee8d36ad858e48a7e26b\n'}, {'number': 2, 'created': '2016-05-06 08:05:19.000000000', 'files': ['test/functional/tests.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/aa054d9e51730b25c48c65336e5adc4651122c0a', 'message': 'crypto - add functional test to verify container listing detail\n\nChange-Id: I2b573c32d10b4ab0b59aee8d36ad858e48a7e26b\n'}]",0,307121,aa054d9e51730b25c48c65336e5adc4651122c0a,13,5,2,7847,,,0,"crypto - add functional test to verify container listing detail

Change-Id: I2b573c32d10b4ab0b59aee8d36ad858e48a7e26b
",git fetch https://review.opendev.org/openstack/swift refs/changes/21/307121/2 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/tests.py'],1,20e7718195a8da1d534a7a5a7fc39c1f4d4cee94,p-cr-listing-test," def _testContainerFormattedFileList(self, format_type): expected = {} for name in self.env.files: expected[name] = self.env.container.file(name).info() file_list = self.env.container.files(parms={'format': format_type}) self.assert_status(200) for actual in file_list: name = actual['name'] self.assertIn(name, expected) self.assertEqual(expected[name]['etag'], actual['hash']) self.assertEqual( expected[name]['content_type'], actual['content_type']) self.assertEqual( expected[name]['content_length'], int(actual['bytes'])) expected.pop(name) self.assertFalse(expected) # sanity check def testContainerJsonFileList(self): self._testContainerFormattedFileList('json') def testContainerXmlFileList(self): self._testContainerFormattedFileList('xml') ",,24,0
openstack%2Fnetworking-generic-switch~master~Ia1d54c5e1911b3ec49dfdf7d02b7f9063b2a074b,openstack/networking-generic-switch,master,Ia1d54c5e1911b3ec49dfdf7d02b7f9063b2a074b,Wrap netmiko.ConnectHandler in try-except block,MERGED,2016-04-27 09:30:54.000000000,2016-05-11 11:34:02.000000000,2016-05-11 11:34:02.000000000,"[{'_account_id': 3}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-04-27 09:30:54.000000000', 'files': ['networking_generic_switch/devices/netmiko_devices/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/1b442466126be99d608775720f7c792c847bd059', 'message': 'Wrap netmiko.ConnectHandler in try-except block\n\nCatching netmiko connection error to switch, and raising\nexception with the corresponding config\n\nChange-Id: Ia1d54c5e1911b3ec49dfdf7d02b7f9063b2a074b\n'}]",0,310384,1b442466126be99d608775720f7c792c847bd059,14,2,1,6610,,,0,"Wrap netmiko.ConnectHandler in try-except block

Catching netmiko connection error to switch, and raising
exception with the corresponding config

Change-Id: Ia1d54c5e1911b3ec49dfdf7d02b7f9063b2a074b
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/84/310384/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_generic_switch/devices/netmiko_devices/__init__.py'],1,1b442466126be99d608775720f7c792c847bd059,,"class GenericSwitchNetmikoConnectError(exc.GenericSwitchException): message = _(""Netmiko connected error: %(config)s"") try: net_connect = netmiko.ConnectHandler(**self.config) except Exception: raise GenericSwitchNetmikoConnectError(config=self.config)", net_connect = netmiko.ConnectHandler(**self.config),8,1
openstack%2Frally~master~I3d2476428bc6da3a0b11a38e4fdd12c2d64272f4,openstack/rally,master,I3d2476428bc6da3a0b11a38e4fdd12c2d64272f4,install_rally.sh: Get latest pypi links more robustly,MERGED,2016-05-05 14:20:04.000000000,2016-05-11 11:32:50.000000000,2016-05-11 11:32:50.000000000,"[{'_account_id': 3}, {'_account_id': 9234}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}]","[{'number': 1, 'created': '2016-05-05 14:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d19673f284212f3cc1fbf9db2df025874ae6fd2f', 'message': 'install_rally.sh: Get latest pypi links more robustly\n\nThis parses the JSON from PyPI with a real JSON parser rather than\ntrying to parse the HTML with shell tools, which should be more\nfailsafe going forward.\n\nChange-Id: I3d2476428bc6da3a0b11a38e4fdd12c2d64272f4\n'}, {'number': 2, 'created': '2016-05-06 13:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0dc87281e8b56865e5cec0f15b160e0a195db4d8', 'message': 'install_rally.sh: Get latest pypi links more robustly\n\nThis parses the JSON from PyPI with a real JSON parser rather than\ntrying to parse the HTML with shell tools, which should be more\nfailsafe going forward.\n\nChange-Id: I3d2476428bc6da3a0b11a38e4fdd12c2d64272f4\n'}, {'number': 3, 'created': '2016-05-06 19:16:55.000000000', 'files': ['install_rally.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/3e60ab567d0b123cc47b4ee02af787d98d50c126', 'message': 'install_rally.sh: Get latest pypi links more robustly\n\nThis parses the JSON from PyPI with a real JSON parser rather than\ntrying to parse the HTML with shell tools, which should be more\nfailsafe going forward.\n\nChange-Id: I3d2476428bc6da3a0b11a38e4fdd12c2d64272f4\n'}]",7,312991,3e60ab567d0b123cc47b4ee02af787d98d50c126,21,5,3,11748,,,0,"install_rally.sh: Get latest pypi links more robustly

This parses the JSON from PyPI with a real JSON parser rather than
trying to parse the HTML with shell tools, which should be more
failsafe going forward.

Change-Id: I3d2476428bc6da3a0b11a38e4fdd12c2d64272f4
",git fetch https://review.opendev.org/openstack/rally refs/changes/91/312991/1 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,d19673f284212f3cc1fbf9db2df025874ae6fd2f,," local url # NOTE(stpierre): This (admittedly ugly) one-liner parses the JSON # returned from pypi and fetches the URL for the latest version of # the source (i.e., .tar.gz) package. url=$(download - ""http://pypi.python.org/pypi/${pkg}/json/"" | \ python -c 'import sys,json;i=json.load(sys.stdin);print([p[""url""] for p in i[""releases""][i[""info""][""version""]] if p[""python_version""] == ""source""][0])') download ""$(basename ""$url"")"" ""$url"""," # NOTE(amaretskiy): get packages list in HTML local packages=$(download - ""${BASE_PIP_URL}/${pkg}/"") # NOTE(amaretskiy): filter packages URLs packages=$(echo ${packages} | sed -En ""s/.*href=\""(.*${pkg}-.*\\.gz)\#.*/\1/p"") # NOTE(amaretskiy): sort packages URLs by their version part packages=$(echo ${packages} | sort -t / -k 7 -V) # NOTE(amaretskiy): finally, the URL is in the last line local url=$(echo ${packages} | tail -1) download ""$(basename ""$url"")"" ""$BASE_PIP_URL""/""$pkg""/""$url""",7,13
openstack%2Fpython-heatclient~master~I888960d2c83c96af80414c61dfd5faf38478f3fa,openstack/python-heatclient,master,I888960d2c83c96af80414c61dfd5faf38478f3fa,Moved required parameter for visibility,MERGED,2016-04-26 02:44:57.000000000,2016-05-11 11:29:53.000000000,2016-05-11 11:29:52.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 10487}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-04-26 02:44:57.000000000', 'files': ['heatclient/osc/v1/template.py', 'heatclient/osc/v1/software_deployment.py', 'heatclient/osc/v1/stack.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d60ad183ab0b00d90d7ba03304dbf0f31cdcd6a0', 'message': 'Moved required parameter for visibility\n\nThis change moved the required parameters so that it\nis more easily visible to the user what is required.\n\nChange-Id: I888960d2c83c96af80414c61dfd5faf38478f3fa\n'}]",0,310088,d60ad183ab0b00d90d7ba03304dbf0f31cdcd6a0,11,5,1,18389,,,0,"Moved required parameter for visibility

This change moved the required parameters so that it
is more easily visible to the user what is required.

Change-Id: I888960d2c83c96af80414c61dfd5faf38478f3fa
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/88/310088/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/template.py', 'heatclient/osc/v1/software_deployment.py', 'heatclient/osc/v1/stack.py']",3,d60ad183ab0b00d90d7ba03304dbf0f31cdcd6a0,param-order," parser.add_argument( '--adopt-file', metavar='<adopt-file>', required=True, help=_('Path to adopt stack data file') )"," '--adopt-file', metavar='<adopt-file>', required=True, help=_('Path to adopt stack data file') ) parser.add_argument(",18,18
openstack%2Fdragonflow~master~Id5a01ed1184562a88b5caf32f7a01ea95ad2b676,openstack/dragonflow,master,Id5a01ed1184562a88b5caf32f7a01ea95ad2b676,Delete redundance method in some nb_api objects,ABANDONED,2016-05-10 12:41:17.000000000,2016-05-11 11:28:12.000000000,,"[{'_account_id': 3}, {'_account_id': 13070}, {'_account_id': 20229}, {'_account_id': 20287}, {'_account_id': 20297}]","[{'number': 1, 'created': '2016-05-10 12:41:17.000000000', 'files': ['dragonflow/db/api_nb.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e9dbdba102ff65a2434368af2f47e5555df605c8', 'message': 'Delete redundance method in some nb_api objects\n\nChange-Id: Id5a01ed1184562a88b5caf32f7a01ea95ad2b676\nCloses-bug: #1580158\n'}]",2,314539,e9dbdba102ff65a2434368af2f47e5555df605c8,7,5,1,20287,,,0,"Delete redundance method in some nb_api objects

Change-Id: Id5a01ed1184562a88b5caf32f7a01ea95ad2b676
Closes-bug: #1580158
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/39/314539/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/db/api_nb.py'],1,e9dbdba102ff65a2434368af2f47e5555df605c8,bug/1580158,, def get_id(self): return self.lrouter.get('id') def get_id(self): return self.router_port.get('id') def get_id(self): return self.secgroup.get('id') def id(self): return self.get_id() @property,0,13
openstack%2Fnova~master~I7071a1e528b0aa8df16589facee4ed4fd62f7b4b,openstack/nova,master,I7071a1e528b0aa8df16589facee4ed4fd62f7b4b,api-ref: perform all 4 phases of verification for action console output,MERGED,2016-05-09 19:52:56.000000000,2016-05-11 11:24:41.000000000,2016-05-11 06:55:08.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2016-05-09 19:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/87a4766041c1e7fcc848f2ad957d1040dd879bd1', 'message': ""api-ref: perform all 4 phases of verification for action console output\n\nThis provides the verification of the action console output.\n\n* Return codes updated based on what's in the code\n* Parameters fixed (length -1 is not actually a thing, it's suggestion\n  for future enhancement; console output described).\n* Add preamble for request example\n* Clean up language on preamble\n\nChange-Id: I7071a1e528b0aa8df16589facee4ed4fd62f7b4b\n""}, {'number': 2, 'created': '2016-05-09 19:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/143b5dece5d5f7f09a206ca4480988f3440909f3', 'message': ""api-ref: perform all 4 phases of verification for action console output\n\nThis provides the verification of the action console output.\n\n* Return codes updated based on what's in the code\n* Parameters fixed (length -1 is not actually a thing, it's suggestion\n  for future enhancement; console output described; server_id should be in path).\n* Add preamble for request example\n* Clean up language on preamble\n\nChange-Id: I7071a1e528b0aa8df16589facee4ed4fd62f7b4b\n""}, {'number': 3, 'created': '2016-05-09 20:53:12.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/servers-action-console-output.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/549fe62bba121642a2ed1c70a4f49c6dd0d3f898', 'message': ""api-ref: perform all 4 phases of verification for action console output\n\nThis provides the verification of the action console output.\n\n* Return codes updated based on what's in the code\n* Parameters fixed (length -1 is not actually a thing, it's suggestion\n  for future enhancement; console output described; server_id should be in path).\n* Add preamble for request example\n* Clean up language on preamble\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I7071a1e528b0aa8df16589facee4ed4fd62f7b4b\n""}]",3,314257,549fe62bba121642a2ed1c70a4f49c6dd0d3f898,21,8,3,2750,,,0,"api-ref: perform all 4 phases of verification for action console output

This provides the verification of the action console output.

* Return codes updated based on what's in the code
* Parameters fixed (length -1 is not actually a thing, it's suggestion
  for future enhancement; console output described; server_id should be in path).
* Add preamble for request example
* Clean up language on preamble

Part of bp:api-ref-in-rst

Change-Id: I7071a1e528b0aa8df16589facee4ed4fd62f7b4b
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/314257/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/servers-action-console-output.inc']",2,87a4766041c1e7fcc848f2ad957d1040dd879bd1,bp/api-ref-in-rst,"This returns the text of the console since boot in a REST response. The console content may be large, you can limit it with the optional ``length`` parameter.Error response codes: unauthorized(401), forbidden(403), notFound(404), conflict(409), methodNotImplemented(501)**Example Get console output** This requests the last 50 lines of the server in question... rest_parameters:: parameters.yaml - output: console_output ",".. needs:method_verification .. needs:parameter_verification .. needs:example_verification .. needs:body_verificationSpecify the ``os-getConsoleOutput`` action in the request body.Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)**Example Get console output: JSON request**",21,10
openstack%2Ftripleo-heat-templates~stable%2Fmitaka~Ib149ecf28c224947a3e917c3e0d30586c610bd85,openstack/tripleo-heat-templates,stable/mitaka,Ib149ecf28c224947a3e917c3e0d30586c610bd85,Testing purposes do not merge,ABANDONED,2016-05-04 10:39:51.000000000,2016-05-11 11:19:57.000000000,,"[{'_account_id': 3}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-04 10:39:51.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3836cc8ee7f1ce3df55637f2c8c199c02ccc754a', 'message': 'Testing purposes do not merge\n\nTo test tripleo.sh in Mitaka/Liberty\n\nChange-Id: Ib149ecf28c224947a3e917c3e0d30586c610bd85\nDepends-On: I731f2e6294d211c77a3d1bd3311616a5f8e4e2a0\n'}]",0,312442,3836cc8ee7f1ce3df55637f2c8c199c02ccc754a,17,2,1,20775,,,0,"Testing purposes do not merge

To test tripleo.sh in Mitaka/Liberty

Change-Id: Ib149ecf28c224947a3e917c3e0d30586c610bd85
Depends-On: I731f2e6294d211c77a3d1bd3311616a5f8e4e2a0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/312442/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3836cc8ee7f1ce3df55637f2c8c199c02ccc754a,test_not_merge,,,1,0
openstack%2Ftripleo-heat-templates~master~Ib149ecf28c224947a3e917c3e0d30586c610bd85,openstack/tripleo-heat-templates,master,Ib149ecf28c224947a3e917c3e0d30586c610bd85,Testing purposes do not merge,ABANDONED,2016-05-04 10:39:07.000000000,2016-05-11 11:19:45.000000000,,"[{'_account_id': 3}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-04 10:39:07.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61ad02d6c7f09f7a7c4f66286fdf7efb79584c67', 'message': 'Testing purposes do not merge\n\nTo test tripleo.sh in Mitaka/Liberty\n\nChange-Id: Ib149ecf28c224947a3e917c3e0d30586c610bd85\nDepends-On: I731f2e6294d211c77a3d1bd3311616a5f8e4e2a0\n'}]",0,312440,61ad02d6c7f09f7a7c4f66286fdf7efb79584c67,18,2,1,20775,,,0,"Testing purposes do not merge

To test tripleo.sh in Mitaka/Liberty

Change-Id: Ib149ecf28c224947a3e917c3e0d30586c610bd85
Depends-On: I731f2e6294d211c77a3d1bd3311616a5f8e4e2a0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/312440/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,61ad02d6c7f09f7a7c4f66286fdf7efb79584c67,test_not_merge,,,1,0
openstack%2Fopenstack-manuals~stable%2Fmitaka~I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5,openstack/openstack-manuals,stable/mitaka,I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5,[config-ref] Fix the incorrect vmware_disktype properties,MERGED,2016-05-11 09:52:20.000000000,2016-05-11 11:15:29.000000000,2016-05-11 11:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 14643}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-11 09:52:20.000000000', 'files': ['doc/config-reference/source/compute/hypervisor-vmware.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9a36ecc7cfe9dc874b638576c9e0c75fee73c613', 'message': '[config-ref] Fix the incorrect vmware_disktype properties\n\nbackport: mitaka\n\nChange-Id: I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5\nCloses-Bug: #1578385\n(cherry picked from commit 29a32c4d539ba5abd805e95e86416e40f4d5f050)\n'}]",0,314939,9a36ecc7cfe9dc874b638576c9e0c75fee73c613,8,4,1,19779,,,0,"[config-ref] Fix the incorrect vmware_disktype properties

backport: mitaka

Change-Id: I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5
Closes-Bug: #1578385
(cherry picked from commit 29a32c4d539ba5abd805e95e86416e40f4d5f050)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/314939/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/compute/hypervisor-vmware.rst'],1,9a36ecc7cfe9dc874b638576c9e0c75fee73c613,bug/1578385, * - streamOptimized, * - Streamoptimized,1,1
openstack%2Fopenstack-manuals~master~Ie97c05f13aae0eeafec4b4121928283962bf0822,openstack/openstack-manuals,master,Ie97c05f13aae0eeafec4b4121928283962bf0822,[admin-guide] Complete the example description,MERGED,2016-05-11 08:44:38.000000000,2016-05-11 11:15:21.000000000,2016-05-11 11:15:21.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-11 08:44:38.000000000', 'files': ['doc/admin-guide/source/cli_manage_projects_users_and_roles.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c87de4a9c971b192beb8c3023981c0dced97042f', 'message': '[admin-guide] Complete the example description\n\nChange-Id: Ie97c05f13aae0eeafec4b4121928283962bf0822\nCloses-Bug: #1532247\n'}]",0,314912,c87de4a9c971b192beb8c3023981c0dced97042f,8,4,1,16523,,,0,"[admin-guide] Complete the example description

Change-Id: Ie97c05f13aae0eeafec4b4121928283962bf0822
Closes-Bug: #1532247
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/12/314912/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/cli_manage_projects_users_and_roles.rst'],1,c87de4a9c971b192beb8c3023981c0dced97042f,bug/1532247,"#. Assign a role to a user-project pair: For example, assign the ``new-role`` role to the ``demo`` and ``test-project`` pair: .. code-block:: console $ openstack role add --user demo --project test-project new-role ","#. Assign a role to a user-project pair. In this example, assign the ``new-role`` role to the ``demo`` and ``test-project`` pair:",8,2
openstack%2Ffuel-ui~master~I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4,openstack/fuel-ui,master,I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4,Rename some lodash methods,MERGED,2016-05-10 15:12:53.000000000,2016-05-11 11:13:21.000000000,2016-05-11 11:10:22.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 15315}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-10 15:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/f7a069e730dc6f1d3736f753a2baaf2f61e92bc9', 'message': 'Rename some lodash methods\n\nThis commit renames some methods which work both for v3 and v4.\n\nThe list of renames:\n\n* all -> every\n* any -> some\n* contains -> includes\n\nChange-Id: I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4\n'}, {'number': 2, 'created': '2016-05-10 15:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/a8f52dd197623b21f7316ee25ed5056e763f5ee9', 'message': 'Rename some lodash methods\n\nThis commit renames some methods which work both for v3 and v4.\n\nThe list of renames:\n\n* all -> every\n* any -> some\n* contains -> includes\n\nChange-Id: I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4\n'}, {'number': 3, 'created': '2016-05-10 15:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/aa0f0698847a1300cb388542b53078eb8786110d', 'message': 'Rename some lodash methods\n\nThis commit renames some methods which work both for v3 and v4.\n\nThe list of renames:\n\n* all -> every\n* any -> some\n* contains -> includes\n\nThese and some other methods were removed from BaseCollection.\n\nChange-Id: I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4\n'}, {'number': 4, 'created': '2016-05-10 15:38:14.000000000', 'files': ['static/views/cluster_page_tabs/nodes_tab_screens/node.js', 'static/views/wizard.js', 'static/i18n.js', 'static/views/plugins_page.js', 'static/tests/functional/pages/interfaces.js', 'static/views/cluster_page_tabs/dashboard_tab.js', 'static/views/support_page.js', 'static/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js', 'static/views/cluster_page_tabs/settings_tab.js', 'static/views/equipment_page.js', 'static/views/layout.js', 'static/utils.js', 'static/views/cluster_page_tabs/setting_section.js', 'static/app.js', 'static/plugins/vmware/vmware_models.js', 'static/models.js', 'static/views/controls.js', 'static/views/cluster_page_tabs/network_tab.js', 'static/views/clusters_page.js', 'static/views/cluster_page_tabs/healthcheck_tab.js', 'static/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.js', 'static/views/cluster_page_tabs/logs_tab.js', 'static/views/dialogs.js', 'static/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/2ce3d9e9338856eb12b7e527bb730e13b1348c7e', 'message': 'Rename some lodash methods\n\nThis commit renames some methods which work both for v3 and v4.\n\nThe list of renames:\n\n* all -> every\n* any -> some\n* contains -> includes\n* rest -> tail\n\nThese and some other methods were removed from BaseCollection.\n\nChange-Id: I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4\n'}]",0,314626,2ce3d9e9338856eb12b7e527bb730e13b1348c7e,48,7,4,8735,,,0,"Rename some lodash methods

This commit renames some methods which work both for v3 and v4.

The list of renames:

* all -> every
* any -> some
* contains -> includes
* rest -> tail

These and some other methods were removed from BaseCollection.

Change-Id: I0fd0c3ef74be6fb3719d91faf92cd9e2fe07a9a4
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/26/314626/4 && git format-patch -1 --stdout FETCH_HEAD,"['static/views/cluster_page_tabs/nodes_tab_screens/node.js', 'static/views/wizard.js', 'static/i18n.js', 'static/views/plugins_page.js', 'static/tests/functional/pages/interfaces.js', 'static/views/cluster_page_tabs/dashboard_tab.js', 'static/views/support_page.js', 'static/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js', 'static/views/cluster_page_tabs/settings_tab.js', 'static/views/equipment_page.js', 'static/views/layout.js', 'static/utils.js', 'static/views/cluster_page_tabs/setting_section.js', 'static/app.js', 'static/plugins/vmware/vmware_models.js', 'static/models.js', 'static/views/controls.js', 'static/views/cluster_page_tabs/network_tab.js', 'static/views/clusters_page.js', 'static/views/cluster_page_tabs/healthcheck_tab.js', 'static/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.js', 'static/views/cluster_page_tabs/logs_tab.js', 'static/views/dialogs.js', 'static/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js']",24,f7a069e730dc6f1d3736f753a2baaf2f61e92bc9,lodash4," var equal = _.every(ifcProperties, (ifcProperty) => _.isEqual(ifcProperty, shown)); !_.every(this.props.nodes.invoke('areInterfacesConfigurable')); return _.some(this.props.nodes.slice(1), (node) => { return _.some(initialInterfacesData, (ifcData, index) => { return _.some(ifcData, (data, attribute) => { enabled: _.every(interfaces, available: _.every(interfaces, bondProperties.dpdk.enabled = _.every(interfaces, var bondHasUnmovableNetwork = bond.get('assigned_networks').some((interfaceNetwork) => { return ifc.get('pxe') && _.includes(slaveInterfaceNames, ifc.get('name')); (ifc) => _.includes(names, ifc.get('name')) if (!_.includes(slaveInterfaceNames, ifc.get('name'))) { interfaces.some((ifc) => ifc.isBond() && this.validateSpeedsForBonding([ifc])); {_.some(availableBondingTypes, (bondingTypes) => bondingTypes.length) && if (!_.includes(slaveInterfaceNames, ifcName)) { if (_.includes(app.version.get('feature_groups'), 'experimental')) { return _.includes(this.getBondPropertyValues('lacp_rate', 'for_modes'), this.getBondMode()); return _.includes(this.getBondPropertyValues('xmit_hash_policy', 'for_modes'), if (_.includes(['mtu', 'sriov.sriov_numvfs'], name)) { if (_.includes(renderableIfcProperties, propertyName)) {"," var equal = _.all(ifcProperties, (ifcProperty) => _.isEqual(ifcProperty, shown)); !_.all(this.props.nodes.invoke('areInterfacesConfigurable')); return _.any(this.props.nodes.slice(1), (node) => { return _.any(initialInterfacesData, (ifcData, index) => { return _.any(ifcData, (data, attribute) => { enabled: _.all(interfaces, available: _.all(interfaces, bondProperties.dpdk.enabled = _.all(interfaces, var bondHasUnmovableNetwork = bond.get('assigned_networks').any((interfaceNetwork) => { return ifc.get('pxe') && _.contains(slaveInterfaceNames, ifc.get('name')); (ifc) => _.contains(names, ifc.get('name')) if (!_.contains(slaveInterfaceNames, ifc.get('name'))) { interfaces.any((ifc) => ifc.isBond() && this.validateSpeedsForBonding([ifc])); {_.any(availableBondingTypes, (bondingTypes) => bondingTypes.length) && if (!_.contains(slaveInterfaceNames, ifcName)) { if (_.contains(app.version.get('feature_groups'), 'experimental')) { return _.contains(this.getBondPropertyValues('lacp_rate', 'for_modes'), this.getBondMode()); return _.contains(this.getBondPropertyValues('xmit_hash_policy', 'for_modes'), if (_.contains(['mtu', 'sriov.sriov_numvfs'], name)) { if (_.contains(renderableIfcProperties, propertyName)) {",155,155
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ib149ecf28c224947a3e917c3e0d30586c610bd85,openstack/tripleo-heat-templates,stable/liberty,Ib149ecf28c224947a3e917c3e0d30586c610bd85,Testing purposes do not merge,ABANDONED,2016-05-04 10:39:30.000000000,2016-05-11 11:11:57.000000000,,"[{'_account_id': 3}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-04 10:39:30.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1736ec24fcfe64eac13e31b6386d006412ac9cf6', 'message': 'Testing purposes do not merge\n\nTo test tripleo.sh in Mitaka/Liberty\n\nChange-Id: Ib149ecf28c224947a3e917c3e0d30586c610bd85\nDepends-On: I731f2e6294d211c77a3d1bd3311616a5f8e4e2a0\n'}]",0,312441,1736ec24fcfe64eac13e31b6386d006412ac9cf6,36,2,1,20775,,,0,"Testing purposes do not merge

To test tripleo.sh in Mitaka/Liberty

Change-Id: Ib149ecf28c224947a3e917c3e0d30586c610bd85
Depends-On: I731f2e6294d211c77a3d1bd3311616a5f8e4e2a0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/41/312441/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1736ec24fcfe64eac13e31b6386d006412ac9cf6,test_not_merge,,,1,0
openstack%2Ftripleo-ci~master~I9a12ef0f2c6114c09b76bb2bf17906875921ed31,openstack/tripleo-ci,master,I9a12ef0f2c6114c09b76bb2bf17906875921ed31,Add Emilien Macchi blog to TripleO blogs feed,MERGED,2016-05-06 14:15:54.000000000,2016-05-11 11:08:49.000000000,2016-05-11 08:57:24.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 20581}]","[{'number': 1, 'created': '2016-05-06 14:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9b3f2e07ac5c1f8c68b6cf9528a63e3e00938ea9', 'message': 'Add Emilien Macchi blog to TripleO blogs feed\n\nChange-Id: I9a12ef0f2c6114c09b76bb2bf17906875921ed31\n'}, {'number': 2, 'created': '2016-05-11 08:55:24.000000000', 'files': ['scripts/website/planet.config.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fb8b914e1db7f2adefb1a7d6973e9354a7179c58', 'message': 'Add Emilien Macchi blog to TripleO blogs feed\n\nChange-Id: I9a12ef0f2c6114c09b76bb2bf17906875921ed31\n'}]",2,313566,fb8b914e1db7f2adefb1a7d6973e9354a7179c58,19,6,2,3153,,,0,"Add Emilien Macchi blog to TripleO blogs feed

Change-Id: I9a12ef0f2c6114c09b76bb2bf17906875921ed31
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/66/313566/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/website/planet.config.ini'],1,9b3f2e07ac5c1f8c68b6cf9528a63e3e00938ea9,blog/emilien, [http://my1.fr/blog/category/virtualization/openstack/tripleo/feed/atom/] name = Emilien Macchi,,3,0
openstack%2Fpython-keystoneclient~master~I4ec588c5c0a2cf1b3bf06b4754889dc27d391b33,openstack/python-keystoneclient,master,I4ec588c5c0a2cf1b3bf06b4754889dc27d391b33,Trivial: ignore openstack/common in flake8 exclude list,MERGED,2016-05-11 05:53:42.000000000,2016-05-11 11:03:12.000000000,2016-05-11 11:03:12.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-05-11 05:53:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6e758ba78f6dfe84fa0b5cce9b23faf6b61a7a81', 'message': ""Trivial: ignore openstack/common in flake8 exclude list\n\nThe directory openstack/common doesn't exist any more,\nso remove it from flake8 exclude list.\n\nChange-Id: I4ec588c5c0a2cf1b3bf06b4754889dc27d391b33\n""}]",0,314871,6e758ba78f6dfe84fa0b5cce9b23faf6b61a7a81,8,2,1,9796,,,0,"Trivial: ignore openstack/common in flake8 exclude list

The directory openstack/common doesn't exist any more,
so remove it from flake8 exclude list.

Change-Id: I4ec588c5c0a2cf1b3bf06b4754889dc27d391b33
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/71/314871/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6e758ba78f6dfe84fa0b5cce9b23faf6b61a7a81,,"exclude = .venv,.tox,dist,doc,*egg,build","exclude = .venv,.tox,dist,doc,*egg,build,*openstack/common*",1,1
openstack%2Fnova-specs~master~I68775f064cf942ed9590749093d00a8b6b0c8390,openstack/nova-specs,master,I68775f064cf942ed9590749093d00a8b6b0c8390,Get set of instances by set of UUIDs,ABANDONED,2015-10-25 19:36:05.000000000,2016-05-11 11:01:13.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6849}, {'_account_id': 9569}, {'_account_id': 10618}, {'_account_id': 12898}, {'_account_id': 14819}, {'_account_id': 15834}, {'_account_id': 21060}]","[{'number': 1, 'created': '2015-10-25 19:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/18905f30ab90ad6b75eba6928d28f3f994ee9371', 'message': 'Get set of instances by set of UUIDs\n\nBlueprint specification for a new search filter\nfor getting set of instances by set of UUIDs.\n\nAPIImpact\n\nChange-Id: I68775f064cf942ed9590749093d00a8b6b0c8390\nBlueprint: get-multi-servers-filter\n'}, {'number': 2, 'created': '2015-12-03 15:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2d25bbbd4b37a5e9f1e6e293c4107b931e00e0c4', 'message': 'Get set of instances by set of UUIDs\n\nBlueprint specification for a new search filter\nfor getting set of instances by set of UUIDs.\n\nAPIImpact\n\nChange-Id: I68775f064cf942ed9590749093d00a8b6b0c8390\nBlueprint: get-multi-servers-filter\n'}, {'number': 3, 'created': '2015-12-15 08:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/91c006afe8056b4b914353e8c854319ccad2e54f', 'message': 'Get set of instances by set of UUIDs\n\nBlueprint specification for a new search filter\nfor getting set of instances by set of UUIDs.\n\nAPIImpact\n\nChange-Id: I68775f064cf942ed9590749093d00a8b6b0c8390\nBlueprint: get-multi-servers-filter\n'}, {'number': 4, 'created': '2016-01-29 08:44:49.000000000', 'files': ['specs/newton/approved/get-multi-servers-filter.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ebbfe0ee7ba00d8f39fe8fd6b97a8ac7c411a9bb', 'message': 'Get set of instances by set of UUIDs\n\nBlueprint specification for a new search filter\nfor getting set of instances by set of UUIDs.\n\nAPIImpact\n\nChange-Id: I68775f064cf942ed9590749093d00a8b6b0c8390\nBlueprint: get-multi-servers-filter\n'}]",18,239286,ebbfe0ee7ba00d8f39fe8fd6b97a8ac7c411a9bb,37,16,4,9569,,,0,"Get set of instances by set of UUIDs

Blueprint specification for a new search filter
for getting set of instances by set of UUIDs.

APIImpact

Change-Id: I68775f064cf942ed9590749093d00a8b6b0c8390
Blueprint: get-multi-servers-filter
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/86/239286/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/approved/get-multi-servers-filter.rst'],1,18905f30ab90ad6b75eba6928d28f3f994ee9371,bp/specification,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== Add new filter for getting a set of instances by uuids ====================================================== https://blueprints.launchpad.net/nova/+spec/get-multi-servers-filter This blueprint aims to add new filter 'server_ids' to the GET /servers/detail request to allow getting a set of instances by uuids. Problem description =================== Right now there are two ways to get detailed information about instances: 1. ask for information about a specific instance passing its UUID 2. ask for information about all instances of this tenant These two ways don't allow to get detailed information about *several* servers quickly. A way to solve this problem is to extend Nova API, so that it would be possible to pass multiple UUIDs of instances a user is interested in to Servers REST API controller in one API query. Use Cases --------- The scale testing of Horizon faced several problems with a lot of data being received from Nova side when Horizon actually doesn't need so much data [1]. The first case is getting the volumes list from Cinder. All the instances are being requested from Nova side by Horizon just to show the names of Instances that Cinder volumes are attached to. In cases when the total number of Instances is much bigger than the number of Volumes this causes a serious performance issues in Horizon where it shouldn't. The second case is getting Floating IPs list from Neutron. We again request all the instances from Nova just to show their names for some Floating IPs (which number could be much less than the number of Instances). Both cases could be avoided if we were able to request details for a limited set of instances (specified by their UUIDs) from Nova. Proposed change =============== Add an API microversion that allows to get a set of instances by set of UUIDs with the help of search filter `server_ids` in request GET /servers/detail. Alternatives ------------ If one was to get information about multiple instances he/she would have to either: 1. do a separate API request for each instance 2. or ask for all instances and pick the ones he/she is interested in The first would possibly cause a multiple round trips to API (i.e. be slow). And the second would potentially load a large amount of data from the DB and transfer it over a network, when only a subset of that data is actually needed (i.e. be slow and cause unnecessary load on disks and network). Data model impact ----------------- None REST API impact --------------- This proposal would add an API microversion for searching a set of instances by a set of UUIDs. The new `server_ids` search filter for GET /servers/detail request will be created. Example of using this filter :: GET /servers/detail?server_ids={uuid1},{uuid2},{uuid3} Response :: { 'servers': [ { 'id': {uuid1}, 'name': inst1, ... other server resource properties ... }, { 'id': {uuid2}, 'name': some_other_name, ... other server resource properties ... }, { 'id': {uuid3}, 'name': inst3, ... other server resource properties ... } } Also this filter can be used with other search filters :: GET /servers/detail?server_ids={uuid1},{uuid2},{uuid3}&name=inst Response :: { 'servers': [ { 'id': {uuid1}, 'name': inst1, ... other server resource properties ... }, { 'id': {uuid3}, 'name': inst3, ... other server resource properties ... } } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ This change will help to improve performance of some horizon pages. New API microversion will allow to escape unnecessary/irrational DB queries. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: snikitin Work Items ---------- The only thing that should be done is to create a new API microversion with a new search filter. Dependencies ============ None Testing ======= Would need new Tempest, functional and unit tests. Documentation Impact ==================== Docs needed for new API microversion and usage. References ========== Nova bug describes the problem: [1] https://bugs.launchpad.net/nova/+bug/1442310 History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Mitaka - Introduced",,202,0
openstack%2Fopenstack-manuals~master~Ia0108cc91743c252d8899436e20419d2a30598e2,openstack/openstack-manuals,master,Ia0108cc91743c252d8899436e20419d2a30598e2,[www] Update Japanese index for Mitaka,MERGED,2016-05-11 02:47:14.000000000,2016-05-11 10:51:02.000000000,2016-05-11 10:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-05-11 02:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bcc10786d4fa4b6bc899def7ad73d2f65ea259fb', 'message': '[www] Update Japanese index for Mitaka\n\nChange-Id: Ia0108cc91743c252d8899436e20419d2a30598e2\n'}, {'number': 2, 'created': '2016-05-11 03:50:11.000000000', 'files': ['www/ja/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/68d167685dc6891d16e42326b1901841717d786d', 'message': '[www] Update Japanese index for Mitaka\n\nChange-Id: Ia0108cc91743c252d8899436e20419d2a30598e2\n'}]",0,314836,68d167685dc6891d16e42326b1901841717d786d,10,4,2,841,,,0,"[www] Update Japanese index for Mitaka

Change-Id: Ia0108cc91743c252d8899436e20419d2a30598e2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/36/314836/2 && git format-patch -1 --stdout FETCH_HEAD,['www/ja/index.html'],1,bcc10786d4fa4b6bc899def7ad73d2f65ea259fb,," <h4>Mitaka 版インストールガイド</h4> <a href=""/mitaka/ja/install-guide-obs/"">Mitaka インストールガイド openSUSE 13.2、SUSE Linux Enterprise Server 12 版</a> <a href=""/mitaka/ja/install-guide-rdo/"">Mitaka インストールガイド Red Hat Enterprise Linux 7、CentOS 7 版</a> <a href=""/mitaka/ja/install-guide-ubuntu/"">Mitaka インストールガイド Ubuntu 14.04 (LTS) 版</a> <h4>Liberty 版インストールガイド</h4> <a href=""/mitaka/ja/networking-guide/"">ネットワークガイド (Mitaka 版)</a> <a href=""/liberty/ja/networking-guide/"">ネットワークガイド (Liberty 版)</a>"," <a href=""/draft/ja/networking-guide/"">ネットワークガイド Mitaka 版</a>、 <a href=""/liberty/ja/networking-guide/"">Liberty 版</a>",7,2
openstack%2Fopenstack-manuals~master~I27ef4a85cdae10c4c880334e03a48cff1c465286,openstack/openstack-manuals,master,I27ef4a85cdae10c4c880334e03a48cff1c465286,[common] Added MariaDB in doc,MERGED,2016-05-09 12:01:15.000000000,2016-05-11 10:50:54.000000000,2016-05-11 10:50:54.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 16237}, {'_account_id': 19390}]","[{'number': 1, 'created': '2016-05-09 12:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ddddf5a57e55481d4364a40d04a89bb2cfacf2e6', 'message': '[install] Added MariaDB in doc\n\nChange-Id: I27ef4a85cdae10c4c880334e03a48cff1c465286\nCloses-Bug: #1579297\n'}, {'number': 2, 'created': '2016-05-11 07:49:58.000000000', 'files': ['doc/common/get_started_compute.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4072b38b7b7b4fdb7d2da0270f933318d3f0272c', 'message': '[common] Added MariaDB in doc\n\nChange-Id: I27ef4a85cdae10c4c880334e03a48cff1c465286\nCloses-Bug: #1579297\n'}]",4,314068,4072b38b7b7b4fdb7d2da0270f933318d3f0272c,16,6,2,19390,,,0,"[common] Added MariaDB in doc

Change-Id: I27ef4a85cdae10c4c880334e03a48cff1c465286
Closes-Bug: #1579297
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/314068/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/get_started_compute.rst'],1,ddddf5a57e55481d4364a40d04a89bb2cfacf2e6,bug/1579297," development work, MySQL, MariaDB, and PostgreSQL."," development work, MySQL, and PostgreSQL.",1,1
openstack%2Fsahara-dashboard~master~Ie9eba4773df6be9ac9663fdba0d07fa44afe6912,openstack/sahara-dashboard,master,Ie9eba4773df6be9ac9663fdba0d07fa44afe6912,fix unit test failures,MERGED,2016-05-06 12:48:46.000000000,2016-05-11 10:50:36.000000000,2016-05-11 10:50:36.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13953}]","[{'number': 1, 'created': '2016-05-06 12:48:46.000000000', 'files': ['sahara_dashboard/content/data_processing/clusters/image_registry/tests.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/jobs/tests.py', 'sahara_dashboard/content/data_processing/clusters/wizard/tests.py', 'sahara_dashboard/content/data_processing/jobs/data_plugins/tests.py', 'sahara_dashboard/content/data_processing/jobs/data_sources/tests.py', 'sahara_dashboard/content/data_processing/clusters/clusters/tests.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/tests.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/35ab4ab33bc5d3fb9a69c602286431420eb285dd', 'message': 'fix unit test failures\n\nnew tab approach produces new API call, which were unmocked.\nalso added missing stuff in order to repair unit tests.\n\nChange-Id: Ie9eba4773df6be9ac9663fdba0d07fa44afe6912\nCloses-bug: 1578195\n'}]",0,313535,35ab4ab33bc5d3fb9a69c602286431420eb285dd,17,14,1,12038,,,0,"fix unit test failures

new tab approach produces new API call, which were unmocked.
also added missing stuff in order to repair unit tests.

Change-Id: Ie9eba4773df6be9ac9663fdba0d07fa44afe6912
Closes-bug: 1578195
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/35/313535/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/clusters/image_registry/tests.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/jobs/tests.py', 'sahara_dashboard/content/data_processing/clusters/wizard/tests.py', 'sahara_dashboard/content/data_processing/jobs/data_plugins/tests.py', 'sahara_dashboard/content/data_processing/jobs/data_sources/tests.py', 'sahara_dashboard/content/data_processing/clusters/clusters/tests.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/tests.py']",10,35ab4ab33bc5d3fb9a69c602286431420eb285dd,bug/1578195," @test.create_stubs({api.sahara: ('job_execution_list', 'plugin_list', 'job_binary_list', 'data_source_list', 'job_list')}) 'job_binary_update', 'job_binary_internal_list')}) api.sahara: ('job_binary_create', 'job_binary_internal_list'),"," @test.create_stubs({api.sahara: ('job_binary_list',)}) 'job_binary_update')})",70,19
openstack%2Fmonasca-api~master~I14721769194cedc7189652ac6575a6f8c4c80e58,openstack/monasca-api,master,I14721769194cedc7189652ac6575a6f8c4c80e58,Honour ENABLED_SERVICES in devstack plugin,MERGED,2016-05-03 10:34:55.000000000,2016-05-11 10:50:26.000000000,2016-05-11 10:50:26.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 9276}, {'_account_id': 11809}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 18179}, {'_account_id': 20873}]","[{'number': 1, 'created': '2016-05-03 10:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/67439a29b626ab6565a7a4eb0cc1f59dc2177dca', 'message': 'Honour ENABLED_SERVICES in devstack plugin\n\nChange-Id: I14721769194cedc7189652ac6575a6f8c4c80e58\nCloses-Bug: 1573651\n'}, {'number': 2, 'created': '2016-05-03 12:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/bd25bacfa082557a5756822c8a7758b9c9dde62a', 'message': 'Honour ENABLED_SERVICES in devstack plugin\n\nChange-Id: I14721769194cedc7189652ac6575a6f8c4c80e58\nCloses-Bug: 1573651\n'}, {'number': 3, 'created': '2016-05-04 08:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/c35f8fa838444c32f8b6500448e4a68b18c31d8d', 'message': 'Honour ENABLED_SERVICES in devstack plugin\n\nChange-Id: I14721769194cedc7189652ac6575a6f8c4c80e58\nCloses-Bug: 1573651\n'}, {'number': 4, 'created': '2016-05-05 15:41:33.000000000', 'files': ['devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e46a57fa5fb7421c43022728f320910060a0761c', 'message': 'Honour ENABLED_SERVICES in devstack plugin\n\nChange-Id: I14721769194cedc7189652ac6575a6f8c4c80e58\nCloses-Bug: 1573651\n'}]",12,312011,e46a57fa5fb7421c43022728f320910060a0761c,34,8,4,9276,,,0,"Honour ENABLED_SERVICES in devstack plugin

Change-Id: I14721769194cedc7189652ac6575a6f8c4c80e58
Closes-Bug: 1573651
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/11/312011/4 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,67439a29b626ab6565a7a4eb0cc1f59dc2177dca,bug/1573651," if is_service_enabled monasca-persister; then if [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'java' ]]; then install_monasca_persister_java elif [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'python' ]]; then install_monasca_persister_python else echo ""Found invalid value for varible MONASCA_PERSISTER_IMPLEMENTATION_LANG: $MONASCA_PERSISTER_IMPLEMENTATION_LANG"" echo ""Valid values for MONASCA_PERSISTER_IMPLEMENTATION_LANG are \""java\"" and \""python\"""" die ""Please set MONASCA_PERSISTER_IMPLEMENTATION_LANG to either \""java\"" or \""python\"""" fi fi if is_service_enabled monasca-persister; then install_monasca_notification if is_service_enabled monasca-thresh; then install_monasca_thresh fi if is_service_enabled monasca-smoke-test; then install_monasca_smoke_test fi sudo ln -sf /var/log/monasca/persister/persister.log ${SCREEN_LOGDIR}/screen-monasca-persister.log || true sudo ln -sf /var/log/monasca/notification/notification.log ${SCREEN_LOGDIR}/screen-monasca-notification.log || true if is_service_enabled monasca-thresh; then clean_monasca_thresh fi if is_service_enabled monasca-notification; then clean_monasca_notification fi if is_service_enabled monasca-persister; then if [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'java' ]]; then clean_monasca_persister_java elif [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'python' ]]; then clean_monasca_persister_python else echo ""Found invalid value for varible MONASCA_PERSISTER_IMPLEMENTATION_LANG: $MONASCA_PERSISTER_IMPLEMENTATION_LANG"" echo ""Valid values for MONASCA_PERSISTER_IMPLEMENTATION_LANG are \""java\"" and \""python\"""" die ""Please set MONASCA_PERSISTER_IMPLEMENTATION_LANG to either \""java\"" or \""python\"""" fi"," if [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'java' ]]; then install_monasca_persister_java elif [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'python' ]]; then install_monasca_persister_python else echo ""Found invalid value for varible MONASCA_PERSISTER_IMPLEMENTATION_LANG: $MONASCA_PERSISTER_IMPLEMENTATION_LANG"" echo ""Valid values for MONASCA_PERSISTER_IMPLEMENTATION_LANG are \""java\"" and \""python\"""" die ""Please set MONASCA_PERSISTER_IMPLEMENTATION_LANG to either \""java\"" or \""python\"""" install_monasca_notification install_monasca_thresh install_monasca_smoke_test sudo ln -sf /var/log/monasca/persister/persister.log ${SCREEN_LOGDIR}/screen-monasca-persister.log sudo ln -sf /var/log/monasca/notification/notification.log ${SCREEN_LOGDIR}/screen-monasca-notification.log clean_monasca_thresh clean_monasca_notification if [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'java' ]]; then clean_monasca_persister_java elif [[ ""${MONASCA_PERSISTER_IMPLEMENTATION_LANG,,}"" == 'python' ]]; then clean_monasca_persister_python else echo ""Found invalid value for varible MONASCA_PERSISTER_IMPLEMENTATION_LANG: $MONASCA_PERSISTER_IMPLEMENTATION_LANG"" echo ""Valid values for MONASCA_PERSISTER_IMPLEMENTATION_LANG are \""java\"" and \""python\"""" die ""Please set MONASCA_PERSISTER_IMPLEMENTATION_LANG to either \""java\"" or \""python\"""" ",37,27
openstack%2Fpuppet-tripleo~master~Ibbfd79421f871e41f870745a593cca65e8c0e58a,openstack/puppet-tripleo,master,Ibbfd79421f871e41f870745a593cca65e8c0e58a,Add the neutron-dnsmasq.conf to neutron profile,MERGED,2016-05-11 01:50:55.000000000,2016-05-11 10:49:10.000000000,2016-05-11 10:49:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 8449}]","[{'number': 1, 'created': '2016-05-11 01:50:55.000000000', 'files': ['manifests/profile/base/neutron/dhcp.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4966c016bbf0b4c5015268a5f14ae173f4627ada', 'message': 'Add the neutron-dnsmasq.conf to neutron profile\n\nThis was in the initial neutron profile patches but got removed\nmid-way (see patch 16 comments here:\nIda781badbcd63bbcb481a2170638aefe262b717b). The file is in fact\nrequired in order to get the ping test properly passing with TripleO.\n\nChange-Id: Ibbfd79421f871e41f870745a593cca65e8c0e58a\n'}]",1,314827,4966c016bbf0b4c5015268a5f14ae173f4627ada,9,4,1,360,,,0,"Add the neutron-dnsmasq.conf to neutron profile

This was in the initial neutron profile patches but got removed
mid-way (see patch 16 comments here:
Ida781badbcd63bbcb481a2170638aefe262b717b). The file is in fact
required in order to get the ping test properly passing with TripleO.

Change-Id: Ibbfd79421f871e41f870745a593cca65e8c0e58a
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/27/314827/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/neutron/dhcp.pp'],1,4966c016bbf0b4c5015268a5f14ae173f4627ada,neutron_dnsmasq_config_file," file { '/etc/neutron/dnsmasq-neutron.conf': content => $neutron_dnsmasq_options, owner => 'neutron', group => 'neutron', notify => Service['neutron-dhcp-service'], require => Package['neutron'], } ",,8,0
openstack%2Fopenstack-manuals~stable%2Fmitaka~I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8,openstack/openstack-manuals,stable/mitaka,I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8,"[network] Updates to ""Using SR-IOV functionality""",MERGED,2016-05-11 00:26:58.000000000,2016-05-11 10:40:34.000000000,2016-05-11 10:39:37.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14962}, {'_account_id': 16237}, {'_account_id': 17973}]","[{'number': 1, 'created': '2016-05-11 00:26:58.000000000', 'files': ['doc/networking-guide/source/adv-config-sriov.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/096e4e5c8b3b72b84a5a536f9ba461b9fa7d4cb2', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nbackport: liberty\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n(cherry picked from commit d291408ba2e0bcdb013709bcb6f267c05b5f50c1)\n'}]",0,314814,096e4e5c8b3b72b84a5a536f9ba461b9fa7d4cb2,11,6,1,16237,,,0,"[network] Updates to ""Using SR-IOV functionality""

- Indicate how a user can discover how many VFs a given PF can support.
- PF interface need to be 'up' else spawn will fail.

backport: liberty

Change-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8
(cherry picked from commit d291408ba2e0bcdb013709bcb6f267c05b5f50c1)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/14/314814/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/adv-config-sriov.rst'],1,096e4e5c8b3b72b84a5a536f9ba461b9fa7d4cb2,sriov," make sure it is enabled. After enabling VT-d, enable IOMMU on .. note:: On some PCI devices, observe that when changing the amount of VFs you receive the error ``Device or resource busy``. In this case, you first need to set ``sriov_numvfs`` to ``0``, then set it to your new value. .. warning:: Alternatively, you can create VFs by passing the ``max_vfs`` to the kernel module of your network interface. However, the ``max_vfs`` parameter has been deprecated, so the PCI SYS interface is the preferred method. You can determine the maximum number of VFs a PF can support: .. code-block:: console # cat /sys/class/net/eth3/device/sriov_totalvfs 63 If the interface is down, make sure it is set to ``up`` before launching a guest, else the instance will fail to spawn: .. code-block:: console # ip link set eth3 up # ip link show eth3 8: eth3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT qlen 1000 link/ether a0:36:9f:8f:3f:b8 brd ff:ff:ff:ff:ff:ff vf 0 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 1 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 2 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 3 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 4 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 5 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 6 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 7 MAC 00:00:00:00:00:00, spoof checking on, link-state auto"," make sure it is enabled. After enabling VT-d, enable IOMMU on Alternatively VFs can be created by passing the ``max_vfs`` to the kernel module of your network interface. The ``max_vfs`` parameter has been deprecated so the PCI SYS interface is the preferred method.",38,4
openstack%2Fmistral~master~I07f495ab316b0f164caece78b1f101219199e68c,openstack/mistral,master,I07f495ab316b0f164caece78b1f101219199e68c,Refactoring exception hierarchy,MERGED,2016-05-06 11:22:01.000000000,2016-05-11 10:39:54.000000000,2016-05-11 10:39:54.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 9408}]","[{'number': 1, 'created': '2016-05-06 11:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/259a8bc3dccfbdeeed9892118d790ccedf51fe03', 'message': ""Refactoring exception hierarchy\n\n* Clear separation for problems that can be handled so that the program\n  can continue and problems that can't handled automatically due to major\n  issues in configuration, environment or code itself\n* Split YAQL exceptions into two types: grammar exception and evaluation\n  exception\n* General NotFoundException is replaced with more specific DBEntryNotFoundException\n  for better consistency with other DB exceptions and more clear semantics\n* Fixed corresponding tests\n\nChange-Id: I07f495ab316b0f164caece78b1f101219199e68c\nImplements: blueprint mistral-engine-error-handling\n""}, {'number': 2, 'created': '2016-05-06 11:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f751d622d77fcddea8da32160c12aa2da56e0163', 'message': ""Refactoring exception hierarchy\n\n* Clear separation for problems that can be handled so that the program\n  can continue and problems that can't handled automatically due to major\n  issues in configuration, environment or code itself\n* Split YAQL exceptions into two types: grammar exception and evaluation\n  exception\n* General NotFoundException is replaced with more specific DBEntryNotFoundException\n  for better consistency with other DB exceptions and more clear semantics\n* Fixed corresponding tests\n\nChange-Id: I07f495ab316b0f164caece78b1f101219199e68c\nImplements: blueprint mistral-engine-error-handling\n""}, {'number': 3, 'created': '2016-05-06 11:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4cc9b167026a32dba8c3dc77a9d90b63b68e9300', 'message': ""Refactoring exception hierarchy\n\n* Clear separation for problems that can be handled so that the program\n  can continue and problems that can't handled automatically due to major\n  issues in configuration, environment or code itself\n* Split YAQL exceptions into two types: grammar exception and evaluation\n  exception\n* General NotFoundException is replaced with more specific DBEntryNotFoundException\n  for better consistency with other DB exceptions and more clear semantics\n* Fixed corresponding tests\n\nChange-Id: I07f495ab316b0f164caece78b1f101219199e68c\nImplements: blueprint mistral-engine-error-handling\n""}, {'number': 4, 'created': '2016-05-06 11:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c49c96d2e076f669f6fbe5eb920cb4d9093b35e8', 'message': ""Refactoring exception hierarchy\n\n* Clear separation for problems that can be handled so that the program\n  can continue and problems that can't handled automatically due to major\n  issues in configuration, environment or code itself\n* Split YAQL exceptions into two types: grammar exception and evaluation\n  exception\n* General NotFoundException is replaced with more specific DBEntryNotFoundException\n  for better consistency with other DB exceptions and more clear semantics\n* Fixed corresponding tests\n\nChange-Id: I07f495ab316b0f164caece78b1f101219199e68c\nImplements: blueprint mistral-engine-error-handling\n""}, {'number': 5, 'created': '2016-05-11 10:13:33.000000000', 'files': ['mistral/workflow/base.py', 'mistral/tests/unit/api/v2/test_workflows.py', 'mistral/tests/unit/test_exception_base.py', 'mistral/tests/unit/engine/test_default_engine.py', 'mistral/exceptions.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/tests/unit/api/v2/test_action_executions.py', 'mistral/tests/unit/api/v2/test_environment.py', 'mistral/tests/unit/api/v2/test_tasks.py', 'mistral/tests/unit/api/v2/test_workbooks.py', 'mistral/tests/unit/api/v2/test_cron_triggers.py', 'mistral/tests/unit/services/test_scheduler.py', 'mistral/tests/unit/test_expressions.py', 'mistral/tests/unit/api/v2/test_actions.py', 'mistral/services/periodic.py', 'mistral/expressions.py', 'mistral/tests/unit/api/v2/test_executions.py', 'mistral/db/v2/sqlalchemy/api.py', 'mistral/tests/unit/services/test_workflow_service.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/96e6d7e40329edfb9fb855d30b324a76221eba32', 'message': ""Refactoring exception hierarchy\n\n* Clear separation for problems that can be handled so that the program\n  can continue and problems that can't handled automatically due to major\n  issues in configuration, environment or code itself\n* Split YAQL exceptions into two types: grammar exception and evaluation\n  exception\n* General NotFoundException is replaced with more specific DBEntryNotFoundException\n  for better consistency with other DB exceptions and more clear semantics\n* Fixed corresponding tests\n\nChange-Id: I07f495ab316b0f164caece78b1f101219199e68c\nImplements: blueprint mistral-engine-error-handling\n""}]",2,313509,96e6d7e40329edfb9fb855d30b324a76221eba32,20,8,5,8731,,,0,"Refactoring exception hierarchy

* Clear separation for problems that can be handled so that the program
  can continue and problems that can't handled automatically due to major
  issues in configuration, environment or code itself
* Split YAQL exceptions into two types: grammar exception and evaluation
  exception
* General NotFoundException is replaced with more specific DBEntryNotFoundException
  for better consistency with other DB exceptions and more clear semantics
* Fixed corresponding tests

Change-Id: I07f495ab316b0f164caece78b1f101219199e68c
Implements: blueprint mistral-engine-error-handling
",git fetch https://review.opendev.org/openstack/mistral refs/changes/09/313509/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workflow/base.py', 'mistral/tests/unit/api/v2/test_workflows.py', 'mistral/tests/unit/test_exception_base.py', 'mistral/tests/unit/engine/test_default_engine.py', 'mistral/exceptions.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/tests/unit/api/v2/test_action_executions.py', 'mistral/tests/unit/api/v2/test_environment.py', 'mistral/tests/unit/api/v2/test_tasks.py', 'mistral/tests/unit/api/v2/test_workbooks.py', 'mistral/tests/unit/api/v2/test_cron_triggers.py', 'mistral/tests/unit/services/test_scheduler.py', 'mistral/tests/unit/api/v2/test_actions.py', 'mistral/services/periodic.py', 'mistral/expressions.py', 'mistral/tests/unit/api/v2/test_executions.py', 'mistral/db/v2/sqlalchemy/api.py', 'mistral/tests/unit/services/test_workflow_service.py']",18,259a8bc3dccfbdeeed9892118d790ccedf51fe03,bp/mistral-engine-error-handling," exc.DBEntityNotFoundException,"," exc.NotFoundException,",133,103
openstack%2Fopenstack-manuals~stable%2Fmitaka~I8d2289c26a84f985846dabbc5316a5911e220fa6,openstack/openstack-manuals,stable/mitaka,I8d2289c26a84f985846dabbc5316a5911e220fa6,[network] BGP dynamic routing,MERGED,2016-05-11 07:17:47.000000000,2016-05-11 10:39:21.000000000,2016-05-11 10:39:20.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14643}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-11 07:17:47.000000000', 'files': ['doc/networking-guide/source/figures/bgp-with-address-scope-diagram.png', 'doc/networking-guide/source/figures/bgp-with-address-scope-diagram.svg', 'doc/networking-guide/source/deploy.rst', 'doc/networking-guide/source/figures/bgp-with-floating-ips.png', 'doc/networking-guide/source/adv-config-bgp-dynamic-routing.rst', 'doc/networking-guide/source/figures/bgp-basic-routing-example.png', 'doc/networking-guide/source/figures/bgp-basic-routing-example.svg', 'doc/networking-guide/source/figures/bgp-with-floating-ips.svg', 'doc/networking-guide/source/adv-config.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5d871e6047e376fdbdc418f1af165e0dabacbca4', 'message': '[network] BGP dynamic routing\n\nAdd documentation for BGP dynamic routing.\n\nChange-Id: Idc947ce7eb8b1907ade1e156631de32797bced63\nCo-Authored-By: Matt Kassawara <mkassawara@gmail.com>\nCloses-Bug: #1554783\n\n(cherry picked from commit 3c8250eac4011c89fa154763a83f18536e7ab6c9)\n\nChange-Id: I8d2289c26a84f985846dabbc5316a5911e220fa6\n'}]",0,314892,5d871e6047e376fdbdc418f1af165e0dabacbca4,9,5,1,16237,,,0,"[network] BGP dynamic routing

Add documentation for BGP dynamic routing.

Change-Id: Idc947ce7eb8b1907ade1e156631de32797bced63
Co-Authored-By: Matt Kassawara <mkassawara@gmail.com>
Closes-Bug: #1554783

(cherry picked from commit 3c8250eac4011c89fa154763a83f18536e7ab6c9)

Change-Id: I8d2289c26a84f985846dabbc5316a5911e220fa6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/314892/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/figures/bgp-with-address-scope-diagram.png', 'doc/networking-guide/source/figures/bgp-with-address-scope-diagram.svg', 'doc/networking-guide/source/deploy.rst', 'doc/networking-guide/source/figures/bgp-with-floating-ips.png', 'doc/networking-guide/source/adv-config-bgp-dynamic-routing.rst', 'doc/networking-guide/source/figures/bgp-basic-routing-example.png', 'doc/networking-guide/source/figures/bgp-basic-routing-example.svg', 'doc/networking-guide/source/figures/bgp-with-floating-ips.svg', 'doc/networking-guide/source/adv-config.rst']",9,5d871e6047e376fdbdc418f1af165e0dabacbca4,bug/1554783, adv-config-bgp-dynamic-routing.rst,,2160,0
openstack%2Fnova~master~Iae7bc4b2cee9ef76323877d502035e878d0d7182,openstack/nova,master,Iae7bc4b2cee9ef76323877d502035e878d0d7182,api-ref: add url parameter to expand all sections,MERGED,2016-05-09 20:37:38.000000000,2016-05-11 10:38:18.000000000,2016-05-10 10:00:35.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-05-09 20:37:38.000000000', 'files': ['api-ref/source/_static/api-site.js'], 'web_link': 'https://opendev.org/openstack/nova/commit/534320c87555fc184c6e1547a588d6c5b7a60c87', 'message': ""api-ref: add url parameter to expand all sections\n\nWhen attempting to link to a specific element that is inside of a\ncollaspable section, the anchors don't work because they are not\nvisible. A relatively low complexity work around is to add an\n?expand_all parameter, which allows one to specify the url as a page\nthat should be fully expanded. Then any deep linking will take people\nto the right place.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Iae7bc4b2cee9ef76323877d502035e878d0d7182\n""}]",0,314271,534320c87555fc184c6e1547a588d6c5b7a60c87,15,9,1,2750,,,0,"api-ref: add url parameter to expand all sections

When attempting to link to a specific element that is inside of a
collaspable section, the anchors don't work because they are not
visible. A relatively low complexity work around is to add an
?expand_all parameter, which allows one to specify the url as a page
that should be fully expanded. Then any deep linking will take people
to the right place.

Part of bp:api-ref-in-rst

Change-Id: Iae7bc4b2cee9ef76323877d502035e878d0d7182
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/314271/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/_static/api-site.js'],1,534320c87555fc184c6e1547a588d6c5b7a60c87,bp/api-ref-in-rst," // if ?expand_all is in the query string, then expand all // sections. This is useful for linking to nested elements, which // only work if that element is expanded. if (window.location.search.substring(1).indexOf(""expand_all"") > -1); { $('#expand-all').click(); } ",,7,0
openstack%2Fkolla~master~Iac3bb7309fc88c3e62bb2e92a3272545cbf9a778,openstack/kolla,master,Iac3bb7309fc88c3e62bb2e92a3272545cbf9a778,Use updated wsgi file for Keystone 9.0.0 release,MERGED,2016-05-07 00:18:15.000000000,2016-05-11 10:37:48.000000000,2016-05-11 10:37:48.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 3098}, {'_account_id': 5638}, {'_account_id': 13642}, {'_account_id': 16233}, {'_account_id': 16993}]","[{'number': 1, 'created': '2016-05-07 00:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a90a38b5497ccf9b7027b8f81a2aa2f2ed41745a', 'message': 'Derecate httpd/keystone.py for Keystone 9.0.0 release\n\nhttpd/keystone.py already deprecated in Keystone upstream[1] post 9.0.0\nrelease. This change swiches to use keystone-wsgi-admin and\nkeystone-wsgi-public to match the upstream change.\n\n[1] https://github.com/openstack/keystone/commit/70a42e7a82ddae9be75dba8f063170a1d13ce301\n\nChange-Id: Iac3bb7309fc88c3e62bb2e92a3272545cbf9a778\nCloses-Bug: #1579275\n'}, {'number': 2, 'created': '2016-05-07 03:28:32.000000000', 'files': ['docker/keystone/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0a53d16b170f2f61cd9bd7ae4761ac35b918d5ca', 'message': 'Use updated wsgi file for Keystone 9.0.0 release\n\nhttpd/keystone.py is already deprecated in Keystone upstream[1] post\n9.0.0 release. This change swiches to use keystone-wsgi-admin and\nkeystone-wsgi-public to match the upstream change.\n\n[1] https://github.com/openstack/keystone/commit/70a42e7a82ddae9be75dba8f063170a1d13ce301\n\nChange-Id: Iac3bb7309fc88c3e62bb2e92a3272545cbf9a778\nCloses-Bug: #1579275\n'}]",0,313814,0a53d16b170f2f61cd9bd7ae4761ac35b918d5ca,13,7,2,2468,,,0,"Use updated wsgi file for Keystone 9.0.0 release

httpd/keystone.py is already deprecated in Keystone upstream[1] post
9.0.0 release. This change swiches to use keystone-wsgi-admin and
keystone-wsgi-public to match the upstream change.

[1] https://github.com/openstack/keystone/commit/70a42e7a82ddae9be75dba8f063170a1d13ce301

Change-Id: Iac3bb7309fc88c3e62bb2e92a3272545cbf9a778
Closes-Bug: #1579275
",git fetch https://review.opendev.org/openstack/kolla refs/changes/14/313814/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/keystone/Dockerfile.j2'],1,a90a38b5497ccf9b7027b8f81a2aa2f2ed41745a,bug/1579275, && cp /var/lib/kolla/venv/bin/keystone-wsgi-admin /var/www/cgi-bin/keystone/admin \ && cp /var/lib/kolla/venv/bin/keystone-wsgi-public /var/www/cgi-bin/keystone/main \, && cp /keystone/httpd/keystone.py /var/www/cgi-bin/keystone/admin \ && cp /keystone/httpd/keystone.py /var/www/cgi-bin/keystone/main \,2,2
openstack%2Fironic-inspector~master~I20cf65e57910568b70a62c3f9269a962e78a07e2,openstack/ironic-inspector,master,I20cf65e57910568b70a62c3f9269a962e78a07e2,Support Ironic node names in our API,MERGED,2016-02-04 16:23:50.000000000,2016-05-11 10:28:02.000000000,2016-05-11 10:28:02.000000000,"[{'_account_id': 3}, {'_account_id': 6637}, {'_account_id': 7080}, {'_account_id': 7419}, {'_account_id': 7882}, {'_account_id': 10239}, {'_account_id': 18653}]","[{'number': 1, 'created': '2016-02-04 16:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/6c12c518285462ba65081120903314a77d9000d3', 'message': '[WIP] Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection call, which might make it slightly longer\n(but only when name is used).\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}, {'number': 2, 'created': '2016-04-08 13:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/93545a3b79c9483df6bf87b528a8636383aee3a4', 'message': '[WIP] Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection call, which might make it slightly longer\n(but only when name is used).\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}, {'number': 3, 'created': '2016-04-11 14:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e79ec01efce2a2936a6bb5a15190527f088cad02', 'message': 'Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection status call, which might make it slightly\nlonger (but only when name is used).\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}, {'number': 4, 'created': '2016-05-04 12:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/914e6f80c54d6f5f1312ec026cbce859ccbaed27', 'message': 'Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection status call, which might make it slightly\nlonger (but only when name is used).\n\nA new helper common.ironic.get_node is created to unify how we fetch nodes\nfrom Ironic. It also provides nicer exceptions.\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}, {'number': 5, 'created': '2016-05-05 12:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/02c7eb4f6728db47030a9f65506518c7b648638a', 'message': 'Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection status and data fetch calls, which might make them\nslightly longer (but only when name is used).\n\nA new helper common.ironic.get_node is created to unify how we fetch nodes\nfrom Ironic. It also provides nicer exceptions.\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}, {'number': 6, 'created': '2016-05-05 12:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/a6c2ec0e408f929606cacd4305146dfa8e867bec', 'message': 'Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection status and data fetch calls, which might make them\nslightly longer (but only when name is used).\n\nA new helper common.ironic.get_node is created to unify how we fetch nodes\nfrom Ironic. It also provides nicer exceptions.\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}, {'number': 7, 'created': '2016-05-09 13:01:46.000000000', 'files': ['ironic_inspector/node_cache.py', 'ironic_inspector/test/unit/test_introspect.py', 'doc/source/http-api.rst', 'ironic_inspector/introspect.py', 'ironic_inspector/test/unit/test_node_cache.py', 'ironic_inspector/process.py', 'ironic_inspector/test/unit/test_process.py', 'ironic_inspector/main.py', 'ironic_inspector/common/ironic.py', 'ironic_inspector/test/unit/test_main.py', 'releasenotes/notes/names-82d9f84153a228ec.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/af6fbf0717de9e9b92007615ba0d9760c7964d89', 'message': 'Support Ironic node names in our API\n\nThis change drops check on UUID validness from our API.\nIt also has a subtle effect of doing Ironic node fetching in\nthe introspection status and data fetch calls, which might make them\nslightly longer (but only when name is used).\n\nA new helper common.ironic.get_node is created to unify how we fetch nodes\nfrom Ironic. It also provides nicer exceptions.\n\nChange-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2\nCloses-Bug: #1523902\n'}]",14,276331,af6fbf0717de9e9b92007615ba0d9760c7964d89,45,7,7,10239,,,0,"Support Ironic node names in our API

This change drops check on UUID validness from our API.
It also has a subtle effect of doing Ironic node fetching in
the introspection status and data fetch calls, which might make them
slightly longer (but only when name is used).

A new helper common.ironic.get_node is created to unify how we fetch nodes
from Ironic. It also provides nicer exceptions.

Change-Id: I20cf65e57910568b70a62c3f9269a962e78a07e2
Closes-Bug: #1523902
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/31/276331/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/node_cache.py', 'ironic_inspector/introspect.py', 'ironic_inspector/main.py', 'ironic_inspector/utils.py', 'ironic_inspector/test/test_node_cache.py', 'ironic_inspector/test/test_main.py', 'ironic_inspector/test/test_process.py']",7,6c12c518285462ba65081120903314a77d9000d3,bug/1523902," 'Cannot find node %s' % self.uuid,"," 'not found', pop_mock.return_value.finished.assert_called_once_with(error=mock.ANY)",41,30
openstack%2Fpuppet-nova~master~Ic5c7d1be866ab25f4bb01a89253a3db92e4ee6f5,openstack/puppet-nova,master,Ic5c7d1be866ab25f4bb01a89253a3db92e4ee6f5,Add support for db_max_retries param,MERGED,2016-05-09 11:35:37.000000000,2016-05-11 10:24:00.000000000,2016-05-11 10:14:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-09 11:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/aab9203baee691f29bfd42d9384f42171be2f566', 'message': 'Add support for db_max_retries param\n\nThe db_max_retries parameter regulates the number of reconnection\nattempts performed after an error raised rather than at startup.\n\nChange-Id: Ic5c7d1be866ab25f4bb01a89253a3db92e4ee6f5\nCloses-Bug: 1579718\n'}, {'number': 2, 'created': '2016-05-09 19:10:25.000000000', 'files': ['manifests/db.pp', 'spec/classes/nova_db_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/28b936594708bc170cc15952220d0f10488db076', 'message': 'Add support for db_max_retries param\n\nThe db_max_retries parameter regulates the number of reconnection\nattempts performed after an error raised rather than at startup.\n\nChange-Id: Ic5c7d1be866ab25f4bb01a89253a3db92e4ee6f5\nCloses-Bug: 1579718\n'}]",0,314056,28b936594708bc170cc15952220d0f10488db076,31,7,2,6796,,,0,"Add support for db_max_retries param

The db_max_retries parameter regulates the number of reconnection
attempts performed after an error raised rather than at startup.

Change-Id: Ic5c7d1be866ab25f4bb01a89253a3db92e4ee6f5
Closes-Bug: 1579718
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/56/314056/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db.pp', 'spec/classes/nova_db_spec.rb']",2,aab9203baee691f29bfd42d9384f42171be2f566,bug/1579718, it { is_expected.to_not contain_nova_config('database/db_max_retries') } it { is_expected.to contain_nova_config('database/db_max_retries').with_value('<SERVICE DEFAULT>') },,9,0
openstack%2Fproject-config~master~I21399dd3549befa01009b5b75f1b2d86814cf174,openstack/project-config,master,I21399dd3549befa01009b5b75f1b2d86814cf174,puppet/proposal: add missing publishers,MERGED,2016-05-10 20:14:56.000000000,2016-05-11 10:13:42.000000000,2016-05-11 10:13:42.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-10 20:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8bbf21bdf0998ebf3c22242b20b8005516cca75e', 'message': 'puppet: add missing proposal job in JJB\n\nAdd propose-puppet-openstack-constraints in puppet-openstack-integration\nJJB configuration so periodic proposal job can run.\n\nChange-Id: I21399dd3549befa01009b5b75f1b2d86814cf174\n'}, {'number': 2, 'created': '2016-05-10 20:44:39.000000000', 'files': ['jenkins/jobs/puppet-module-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/56b4c0d9af003a942caf517505a33850d8ab3daf', 'message': 'puppet/proposal: add missing publishers\n\nAdd missing publishers to propose-puppet-openstack-constraints job so we\ncan have logs and cleanup the slave node.\n\nChange-Id: I21399dd3549befa01009b5b75f1b2d86814cf174\n'}]",0,314751,56b4c0d9af003a942caf517505a33850d8ab3daf,14,4,2,3153,,,0,"puppet/proposal: add missing publishers

Add missing publishers to propose-puppet-openstack-constraints job so we
can have logs and cleanup the slave node.

Change-Id: I21399dd3549befa01009b5b75f1b2d86814cf174
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/314751/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/projects.yaml'],1,8bbf21bdf0998ebf3c22242b20b8005516cca75e,puppet/periodic, - propose-puppet-openstack-constraints,,1,0
openstack%2Fmistral~master~I08b2b552130fd16a20f6647349006939619b6659,openstack/mistral,master,I08b2b552130fd16a20f6647349006939619b6659,Fixing engine facade hierarchy,MERGED,2016-05-06 07:30:05.000000000,2016-05-11 10:08:33.000000000,2016-05-11 10:08:33.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 9408}, {'_account_id': 18238}]","[{'number': 1, 'created': '2016-05-06 07:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4eb1ae19785833c5b40b501200bde7af1df3c577', 'message': 'Fixing engine facade hierarchy\n\n* Method rerun_workflow() was missing in Engine interface\n* Renamed parameters in the hierarchy to be more consistent\n* Added missing docstrings\n\nChange-Id: I08b2b552130fd16a20f6647349006939619b6659\n'}, {'number': 2, 'created': '2016-05-06 09:55:51.000000000', 'files': ['mistral/engine/rpc.py', 'mistral/engine/base.py', 'mistral/engine/default_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/cc32c82c165df4083f1eed2ce2c18fb9cc38b346', 'message': 'Fixing engine facade hierarchy\n\n* Method rerun_workflow() was missing in Engine interface\n* Renamed parameters in the hierarchy to be more consistent\n* Added missing docstrings\n\nChange-Id: I08b2b552130fd16a20f6647349006939619b6659\n'}]",0,313257,cc32c82c165df4083f1eed2ce2c18fb9cc38b346,17,7,2,8731,,,0,"Fixing engine facade hierarchy

* Method rerun_workflow() was missing in Engine interface
* Renamed parameters in the hierarchy to be more consistent
* Added missing docstrings

Change-Id: I08b2b552130fd16a20f6647349006939619b6659
",git fetch https://review.opendev.org/openstack/mistral refs/changes/57/313257/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/rpc.py', 'mistral/engine/base.py', 'mistral/engine/default_engine.py']",3,4eb1ae19785833c5b40b501200bde7af1df3c577,bp/mistral-engine-error-handling," def pause_workflow(self, wf_ex_id): with db_api.transaction(): wf_ex = wf_handler.lock_workflow_execution(wf_ex_id)"," def pause_workflow(self, execution_id): with db_api.transaction(): wf_ex = wf_handler.lock_workflow_execution(execution_id)",59,22
openstack%2Ftempest~master~I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7,openstack/tempest,master,I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7,Snapshot list using 'limit' parameter,MERGED,2016-03-30 13:30:09.000000000,2016-05-11 10:07:20.000000000,2016-05-11 10:07:19.000000000,"[{'_account_id': 3}, {'_account_id': 4727}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9152}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11075}, {'_account_id': 12017}, {'_account_id': 12024}, {'_account_id': 19262}, {'_account_id': 19587}]","[{'number': 1, 'created': '2016-03-30 13:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/da5416784b1725f1f33881158d5731110803228f', 'message': ""Snapshot list with details using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 2, 'created': '2016-03-30 17:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/18785096112c61ba2e8bf7bf2c7f177e3c537461', 'message': ""Snapshot list with details using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 3, 'created': '2016-03-30 17:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5fd0c9f9e95c1f84008ad534150a00cc6b21ecdd', 'message': ""Snapshot list with details using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 4, 'created': '2016-04-03 09:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/32fd700546dcd881c798365b7c66570717e49ca2', 'message': ""Snapshot list with details using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 5, 'created': '2016-04-03 12:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/37a8862784bca7b7151d060558920dce1ae355ca', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 6, 'created': '2016-04-04 09:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/86f434f7baf87e9d9e75c8c7cf0c397cdbfc4730', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 7, 'created': '2016-04-10 06:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/185ab56b56a6097855622cd3ae4d20d3d648174d', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 8, 'created': '2016-04-10 15:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f19496c9fe1a9af73e45cd5902362314fe9684ff', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 9, 'created': '2016-04-11 06:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f11d5991e899ca4d61d4d2780d92562caab04f91', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 10, 'created': '2016-04-11 12:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5829652ba31efcfa0f08c3157223bd7a0d392b11', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 11, 'created': '2016-04-12 08:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e5e8718c9230995cabcd12dd0083ac03c7e222f', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nall snapshots, while we expect to get an empty list. The test runs\non version 2 and skips on version 1.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 12, 'created': '2016-04-12 08:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/678d7724d6fb0979216d2bd08424dfc93a342467', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThere is a bug in api version 1 when limit=0, the api returns,\nall snapshots, while we expect to get an empty list.\nThe test runs on version 2 and skips on version 1.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 13, 'created': '2016-04-12 10:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d938fa155ae68f8e8617ff4bb8c395a74ac7ec06', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThere is a bug in api version 1 when limit=0, the api returns,\nall snapshots, while we expect to get an empty list.\nThe test runs on version 2 and skips on version 1.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 14, 'created': '2016-04-21 13:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a08255aaae075c89d2f0236a677ab92ffcc61c35', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThe patch caught 2 cinder bugs when limit=0. One in api V1\nand second on kilo V2. In both cases api returns,\nall snapshots, while we expect to get an empty list.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 15, 'created': '2016-05-01 05:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5122c0285d60d54fd1fbfeee2f1439875c8e62b8', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThe patch caught 2 cinder bugs when limit=0. One in api V1\nand second on kilo V2. In both cases api returns,\nall snapshots, while we expect to get an empty list.\nTherfore, I removed the limit=0 filter case until it'll be fixed\non kilo V2.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 16, 'created': '2016-05-01 07:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8f91911331c8a4b244c5d0e1668311f3641f682', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThe patch caught 2 cinder bugs when limit=0. One in api V1\nand second on kilo V2. In both cases api returns,\nall snapshots, while we expect to get an empty list.\nTherfore, I removed the limit=0 filter case until it'll be fixed\non kilo V2.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 17, 'created': '2016-05-04 08:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/70e14dc76dc2b7b2729c84c3902ed9718a5bc3e5', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThe patch caught 2 cinder bugs when limit=0. One in api V1\nand second on kilo V2. In both cases api returns,\nall snapshots, while we expect to get an empty list.\nTherfore, I removed the limit=0 filter case until it'll be fixed\non kilo V2.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 18, 'created': '2016-05-09 09:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c151ac1a4be07f3c8fad29effe00b74e53ad7df', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThe patch caught 2 cinder bugs when limit=0. One in api V1\nand second on kilo V2. In both cases api returns,\nall snapshots, while we expect to get an empty list.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}, {'number': 19, 'created': '2016-05-09 15:48:22.000000000', 'files': ['tempest/api/volume/test_volumes_snapshots.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/755c6ee99133ffe586d8290910dc286459339264', 'message': ""Snapshot list using 'limit' parameter\n\nThis patch tests the option to determine the number\nof snapshots that will be displayed from a list of snapshots,\nby using the 'limit' parameter.\n\nThe patch caught 2 cinder bugs when limit=0. One in api V1\nand second on kilo V2. In both cases api returns,\nall snapshots, while we expect to get an empty list.\n\nChange-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7\n""}]",49,299393,755c6ee99133ffe586d8290910dc286459339264,134,16,19,19262,,,0,"Snapshot list using 'limit' parameter

This patch tests the option to determine the number
of snapshots that will be displayed from a list of snapshots,
by using the 'limit' parameter.

The patch caught 2 cinder bugs when limit=0. One in api V1
and second on kilo V2. In both cases api returns,
all snapshots, while we expect to get an empty list.

Change-Id: I1b83d98ec0d8e97adc849a3fdd1471f3ffc5cbb7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/93/299393/7 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/volume/test_volumes_snapshots.py'],1,da5416784b1725f1f33881158d5731110803228f,snap_limit," def _list_snapshots_by_param_limit(self, with_detail=False): # Create two snapshots for snap in xrange(2): self.create_snapshot(self.volume_origin['id']) params = {'limit': 1} # Get snapshots list using limit parameter if with_detail: fetched_snp_list = self.snapshots_client.list_snapshots( detail=True, **params)['snapshots'] else: fetched_snp_list = self.snapshots_client.list_snapshots( **params)['snapshots'] self.assertEqual(params['limit'], len(fetched_snp_list), ""Failed to list snapshot details by limit"") @test.idempotent_id('db4d8e0a-7a2e-41cc-a712-961f6844e896') def test_snapshots_list_with_detail_param_limit(self): self._list_snapshots_by_param_limit(with_detail=True) ",,21,0
openstack%2Fproject-config~master~I940dd2e5e42d989645601dca26d8f1049392230a,openstack/project-config,master,I940dd2e5e42d989645601dca26d8f1049392230a,Make gate-murano-python34-db not running on stable/mitaka,MERGED,2016-05-10 15:54:53.000000000,2016-05-11 10:02:16.000000000,2016-05-11 10:02:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 15168}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-05-10 15:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/61e4385bda4ce4b23b3a888dfd8e899a61716ba0', 'message': 'Make gate-murano-python34-db non-voting\n\nPatch makes this job non-voting at all stable\nbranches so far, because murano does not have support\nfor py34 there\n\nChange-Id: I940dd2e5e42d989645601dca26d8f1049392230a\n'}, {'number': 2, 'created': '2016-05-10 15:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5df4020ec6a2cfe4c8a369b22205dc5ea1186032', 'message': 'Make gate-murano-python34-db non-voting\n\nPatch makes this job non-voting at all stable branches,\nbecause murano does not have support for py34 there\n\nChange-Id: I940dd2e5e42d989645601dca26d8f1049392230a\n'}, {'number': 3, 'created': '2016-05-10 16:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6c5d0c2045d093efb2cfb91cc10a9a99b2e000a4', 'message': 'Make gate-murano-python34-db non-voting\n\nPatch makes this job non-voting at all stable branches,\nbecause murano does not have support for py34 there\n\nChange-Id: I940dd2e5e42d989645601dca26d8f1049392230a\n'}, {'number': 4, 'created': '2016-05-11 09:06:53.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8a1a41a7a6debcb10dbb87428e6025027c2637d8', 'message': 'Make gate-murano-python34-db not running on stable/mitaka\n\nPatch makes this job non-running on stable/mitaka branch,\nbecause murano does not have support for py34 there\n\nChange-Id: I940dd2e5e42d989645601dca26d8f1049392230a\n'}]",0,314645,8a1a41a7a6debcb10dbb87428e6025027c2637d8,16,5,4,13149,,,0,"Make gate-murano-python34-db not running on stable/mitaka

Patch makes this job non-running on stable/mitaka branch,
because murano does not have support for py34 there

Change-Id: I940dd2e5e42d989645601dca26d8f1049392230a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/314645/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,61e4385bda4ce4b23b3a888dfd8e899a61716ba0,, branch: ^(?!stable/(?:juno|kilo|liberty|mitaka)).*$ voting: false, branch: ^(?!stable/(?:juno|kilo|liberty)).*$,2,1
openstack%2Fproject-config~master~Icb99127da057f470a407412deb997ab4b74cf980,openstack/project-config,master,Icb99127da057f470a407412deb997ab4b74cf980,fuel-devops: Add jobs,MERGED,2016-05-10 11:41:36.000000000,2016-05-11 09:58:04.000000000,2016-05-11 09:58:03.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6719}, {'_account_id': 7069}, {'_account_id': 8882}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2016-05-10 11:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c867cd8f3b8139f67d6a72153e394b8618574549', 'message': ""fuel-devops: Add jobs\n\nAdd:\n1. py3 job with vote\n2. Doc job without vote\n  tox env's active: py27, pep8, py34\n  Current branches: stable (old), release/2.9, master\n\nChange-Id: Icb99127da057f470a407412deb997ab4b74cf980\n""}, {'number': 2, 'created': '2016-05-10 11:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/af2ea89c6dec00f906233f4d0cde0a5811334e02', 'message': ""fuel-devops: Add jobs\n\nAdd:\n1. py3 job with vote\n2. Doc job without vote\n  tox env's active: py27, pep8, py34\n  Current branches: stable (old), release/2.9, master\n\nChange-Id: Icb99127da057f470a407412deb997ab4b74cf980\n""}, {'number': 3, 'created': '2016-05-10 12:22:59.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/12ebe994f5c2844c0b6725dd9ad498d5c3c4b420', 'message': ""fuel-devops: Add jobs\n\nAdd:\n1. py3 job with vote\n2. Doc job without vote\n  tox env's active: py27, pep8, py34\n  Current branches: stable (old), release/2.9, master\n\nChange-Id: Icb99127da057f470a407412deb997ab4b74cf980\n""}]",0,314518,12ebe994f5c2844c0b6725dd9ad498d5c3c4b420,22,8,3,19119,,,0,"fuel-devops: Add jobs

Add:
1. py3 job with vote
2. Doc job without vote
  tox env's active: py27, pep8, py34
  Current branches: stable (old), release/2.9, master

Change-Id: Icb99127da057f470a407412deb997ab4b74cf980
",git fetch https://review.opendev.org/openstack/project-config refs/changes/18/314518/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,c867cd8f3b8139f67d6a72153e394b8618574549,, - name: ^gate-fuel-devops-python34 branch: ^(?!release/(?:2\.9)|?!stable).*$ - name: ^gate-fuel-devops-docs branch: ^(?!release/(?:2\.9)).*$ voting: false - name: python3-jobs - gate-fuel-devops-docs, - name: ^gate-fuel-devops-python.*$ branch: ^(?!stable/(?:5\.0|5\.1|6\.0|6\.1|7\.0)).*$,9,2
openstack%2Fproject-config~master~Idda045fb291b1ab80b8fd6e20d4af7e40b1cc48e,openstack/project-config,master,Idda045fb291b1ab80b8fd6e20d4af7e40b1cc48e,Add non-voting docs job for fuel-web,MERGED,2016-05-11 09:08:54.000000000,2016-05-11 09:57:31.000000000,2016-05-11 09:57:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7069}]","[{'number': 1, 'created': '2016-05-11 09:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f7a00f4dd12d39f6649275b7f157ce17b135ad00', 'message': ""Add non-voting docs job for fuel-web\n\nEnable building of Nailgun API docs in fuel-web by upstream infra.\nThis is a part of initiative to move all documentation related processes\nupstream for fuel-* repos and deprecate some Fuel CI jobs in favour of\nupstream ones.\nDocs building should work fine for fuel-web, but let's enable it in\nnon-voting to ensure everything is ok.\n\nChange-Id: Idda045fb291b1ab80b8fd6e20d4af7e40b1cc48e\n""}, {'number': 2, 'created': '2016-05-11 09:20:23.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/899db6f876da76215ced3c9ec26f29649652e723', 'message': ""Add non-voting docs job for fuel-web\n\nEnable building of Nailgun API docs in fuel-web by upstream infra.\nThis is a part of initiative to move all documentation related processes\nupstream for fuel-* repos and deprecate some Fuel CI jobs in favour of\nupstream ones.\nDocs building should work fine for fuel-web, but let's enable it in\nnon-voting to ensure everything is ok.\n\nChange-Id: Idda045fb291b1ab80b8fd6e20d4af7e40b1cc48e\n""}]",0,314920,899db6f876da76215ced3c9ec26f29649652e723,11,3,2,13505,,,0,"Add non-voting docs job for fuel-web

Enable building of Nailgun API docs in fuel-web by upstream infra.
This is a part of initiative to move all documentation related processes
upstream for fuel-* repos and deprecate some Fuel CI jobs in favour of
upstream ones.
Docs building should work fine for fuel-web, but let's enable it in
non-voting to ensure everything is ok.

Change-Id: Idda045fb291b1ab80b8fd6e20d4af7e40b1cc48e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/314920/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,f7a00f4dd12d39f6649275b7f157ce17b135ad00,, - name: gate-fuel-web-docs branch: ^(?!stable/(?:5\.0|5\.1|6\.0|6\.1|7\.0|8\.0)).*$ voting: false - gate-fuel-web-docs,,6,0
openstack%2Fopenstack-manuals~master~I0e9d65895dcf0132a6c7be39731cae8f44e8418e,openstack/openstack-manuals,master,I0e9d65895dcf0132a6c7be39731cae8f44e8418e,Provide exact and direct link for 'instance does not launch',MERGED,2016-05-01 05:00:53.000000000,2016-05-11 09:54:24.000000000,2016-05-11 09:28:47.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14151}, {'_account_id': 14962}, {'_account_id': 16237}, {'_account_id': 17106}]","[{'number': 1, 'created': '2016-05-01 05:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/20de78ffd97c82e486520b51a19e317e820e97e7', 'message': ""Provide exact and direct link for 'instance does not launch'\n\nChange-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e\n""}, {'number': 2, 'created': '2016-05-01 05:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/157d5b59692b251fed46385a462ba27e7b892063', 'message': ""Provide exact and direct link for 'instance does not launch'\n\nChange-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e\n""}, {'number': 3, 'created': '2016-05-01 07:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/203473e10b8faff95ac714dedfdf314f85f90012', 'message': ""Provide exact and direct link for 'instance does not launch'\n\nChange-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e\n""}, {'number': 4, 'created': '2016-05-09 13:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/baca5b7aef71345c0b5f81789bd8b49eb4cf3275', 'message': ""Provide exact and direct link for 'instance does not launch'\n\nChange-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e\n""}, {'number': 5, 'created': '2016-05-10 08:42:59.000000000', 'files': ['doc/install-guide/source/launch-instance-selfservice.rst', 'doc/install-guide/source/launch-instance-provider.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e5960bc5f971f52e7d5ae484c5f704f4e1ce9c34', 'message': ""Provide exact and direct link for 'instance does not launch'\n\nbackport: mitaka\n\nChange-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e\n""}]",2,311597,e5960bc5f971f52e7d5ae484c5f704f4e1ce9c34,23,6,5,14151,,,0,"Provide exact and direct link for 'instance does not launch'

backport: mitaka

Change-Id: I0e9d65895dcf0132a6c7be39731cae8f44e8418e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/311597/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/launch-instance-selfservice.rst', 'doc/install-guide/source/launch-instance-provider.rst']",2,20de78ffd97c82e486520b51a19e317e820e97e7,vm_fail_link,`Instance Boot Failures http://docs.openstack.org/openstack-ops/content/instances.html#instance_boot_failures`__ in `OpenStack Operations Guide <http://docs.openstack.org/ops>`__ for more,`OpenStack Operations Guide <http://docs.openstack.org/ops>`__ for more,6,2
openstack%2Fopenstack-manuals~master~I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5,openstack/openstack-manuals,master,I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5,[config-ref] Fix the incorrect vmware_disktype properties,MERGED,2016-05-05 02:00:45.000000000,2016-05-11 09:52:20.000000000,2016-05-11 09:28:57.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 17207}]","[{'number': 1, 'created': '2016-05-05 02:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/10df9a4739117fd606ddd65e64d6043fb5b20a80', 'message': '[config-ref] Fix the incorrect vmware_disktype properties\n\nChange-Id: I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5\nCloses-Bug: #1578385\n'}, {'number': 2, 'created': '2016-05-06 05:15:35.000000000', 'files': ['doc/config-reference/source/compute/hypervisor-vmware.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/29a32c4d539ba5abd805e95e86416e40f4d5f050', 'message': '[config-ref] Fix the incorrect vmware_disktype properties\n\nbackport: mitaka\n\nChange-Id: I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5\nCloses-Bug: #1578385\n'}]",0,312807,29a32c4d539ba5abd805e95e86416e40f4d5f050,12,4,2,19779,,,0,"[config-ref] Fix the incorrect vmware_disktype properties

backport: mitaka

Change-Id: I4ce5fe86efc2717a3f2c2ac57f8a60c9d7f39bf5
Closes-Bug: #1578385
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/312807/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/compute/hypervisor-vmware.rst'],1,10df9a4739117fd606ddd65e64d6043fb5b20a80,bug/1578385, * - streamOptimized, * - Streamoptimized,1,1
openstack%2Fnova~master~Ic03c0e6486a300c3cd724b798850dedeae014faf,openstack/nova,master,Ic03c0e6486a300c3cd724b798850dedeae014faf,api-ref: update parameter validation on servers,MERGED,2016-05-06 12:37:31.000000000,2016-05-11 09:50:55.000000000,2016-05-10 15:36:46.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7789}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-05-06 12:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c8ec4a00046f656fc80c5f76151a180617d1aa2', 'message': 'WIP: api-ref: working on parameters validation for servers\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 2, 'created': '2016-05-06 12:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20e48dd9c15df763afc45ecb0c12cf3b01e14da3', 'message': 'WIP: api-ref: working on parameters validation for servers\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 3, 'created': '2016-05-09 10:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa6cc0740d34c80ebadfebe14a6e7e636d64900b', 'message': 'WIP: api-ref: working on parameters validation for servers\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 4, 'created': '2016-05-09 12:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7529b94f4a0be17fb3988362619f83b404ccad86', 'message': 'api-ref: update parameter validation on servers\n\nThis updates all the v2.1 parameters for servers, as well as some of\nthe microversions added parameters. It makes us more accurate than the\nexisting api-site.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 5, 'created': '2016-05-09 16:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/393a3557eb72862f47f205759e2bf8156bbbc2cd', 'message': 'api-ref: update parameter validation on servers\n\nThis updates all the v2.1 parameters for servers, as well as some of\nthe microversions added parameters. It makes us more accurate than the\nexisting api-site.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 6, 'created': '2016-05-09 18:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e40f84075da946c7be5cd3ca9aacf963c0caab5', 'message': 'api-ref: update parameter validation on servers\n\nThis updates all the v2.1 parameters for servers, as well as some of\nthe microversions added parameters. It makes us more accurate than the\nexisting api-site.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 7, 'created': '2016-05-09 19:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/787988b53a323ea27a678c9a45b8c348c46139d4', 'message': 'api-ref: update parameter validation on servers\n\nThis updates all the v2.1 parameters for servers, as well as some of\nthe microversions added parameters. It makes us more accurate than the\nexisting api-site.\n\nThis specificially *does not* include the additional response\nparameters for microversions > 2.1 (tags, ext attrs for ec2, etc).\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 8, 'created': '2016-05-09 19:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bf76bc61bfcc7dd3c53ee69663a884ede10e2d1', 'message': 'api-ref: update parameter validation on servers\n\nThis updates all the v2.1 parameters for servers, as well as some of\nthe microversions added parameters. It makes us more accurate than the\nexisting api-site.\n\nThis specificially *does not* include the additional response\nparameters for microversions > 2.1 (tags, ext attrs for ec2, etc).\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}, {'number': 9, 'created': '2016-05-09 20:25:32.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/servers.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/e131317430b0c2b3737dae3a76f875c308301685', 'message': 'api-ref: update parameter validation on servers\n\nThis updates all the v2.1 parameters for servers, as well as some of\nthe microversions added parameters. It makes us more accurate than the\nexisting api-site.\n\nThis specificially *does not* include the additional response\nparameters for microversions > 2.1 (tags, ext attrs for ec2, etc).\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf\n'}]",31,313532,e131317430b0c2b3737dae3a76f875c308301685,71,14,9,2750,,,0,"api-ref: update parameter validation on servers

This updates all the v2.1 parameters for servers, as well as some of
the microversions added parameters. It makes us more accurate than the
existing api-site.

This specificially *does not* include the additional response
parameters for microversions > 2.1 (tags, ext attrs for ec2, etc).

Part of bp:api-ref-in-rst

Change-Id: Ic03c0e6486a300c3cd724b798850dedeae014faf
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/313532/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/servers.inc']",2,6c8ec4a00046f656fc80c5f76151a180617d1aa2,bp/api-ref-in-rst, - limit: limit - marker: marker - sort_key: sort_key - sort_dir: sort_dir - ip: ip_query - reservation_id: reservation_id_query - all_tenants: all_tenants_query - deleted: deleted_query - ip6: ip6_query - tags: tags_query - tags-any: tags_any_query - not-tags: not_tags_query - not-tags-any: not_tags_any_query, - limit: limit - marker: marker,78,3
openstack%2Ffuel-library~master~If9859950fb4c8704da0df5a6c715eaeb08ad3b51,openstack/fuel-library,master,If9859950fb4c8704da0df5a6c715eaeb08ad3b51,Do not omit syncing the '*-all.log' syslog files,MERGED,2016-05-09 15:40:18.000000000,2016-05-11 09:38:02.000000000,2016-05-11 09:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 17730}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-09 15:40:18.000000000', 'files': ['deployment/puppet/openstack/templates/52-sahara.conf.erb', 'deployment/puppet/openstack/templates/50-neutron.conf.erb', 'deployment/puppet/openstack/templates/54-heat.conf.erb', 'deployment/puppet/openstack/templates/51-ceilometer.conf.erb', 'deployment/puppet/openstack/templates/80-swift.conf.erb', 'deployment/puppet/openstack/templates/55-murano.conf.erb', 'deployment/puppet/openstack/templates/40-glance.conf.erb', 'deployment/puppet/openstack/templates/10-nova.conf.erb', 'deployment/puppet/openstack/templates/20-keystone.conf.erb', 'deployment/puppet/openstack/templates/30-cinder.conf.erb', 'deployment/puppet/openstack/templates/53-aodh.conf.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8f10ba3e0bf83f249b44b79a4f9f1b9ae416e866', 'message': ""Do not omit syncing the '*-all.log' syslog files\n\nWhile parsing syslogtag from many sources we always should sync.\n\nChange-Id: If9859950fb4c8704da0df5a6c715eaeb08ad3b51\nCloses-Bug: #1573047\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n""}]",0,314186,8f10ba3e0bf83f249b44b79a4f9f1b9ae416e866,28,13,1,14200,,,0,"Do not omit syncing the '*-all.log' syslog files

While parsing syslogtag from many sources we always should sync.

Change-Id: If9859950fb4c8704da0df5a6c715eaeb08ad3b51
Closes-Bug: #1573047
Signed-off-by: Maksim Malchuk <mmalchuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/86/314186/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/templates/52-sahara.conf.erb', 'deployment/puppet/openstack/templates/50-neutron.conf.erb', 'deployment/puppet/openstack/templates/54-heat.conf.erb', 'deployment/puppet/openstack/templates/51-ceilometer.conf.erb', 'deployment/puppet/openstack/templates/80-swift.conf.erb', 'deployment/puppet/openstack/templates/55-murano.conf.erb', 'deployment/puppet/openstack/templates/40-glance.conf.erb', 'deployment/puppet/openstack/templates/10-nova.conf.erb', 'deployment/puppet/openstack/templates/20-keystone.conf.erb', 'deployment/puppet/openstack/templates/30-cinder.conf.erb', 'deployment/puppet/openstack/templates/53-aodh.conf.erb']",11,8f10ba3e0bf83f249b44b79a4f9f1b9ae416e866,bug/1573047,":syslogtag, contains, ""aodh"" /var/log/aodh-all.log ### stop further processing for the matched entries",":syslogtag, contains, ""aodh"" -/var/log/aodh-all.log",21,11
openstack%2Fpython-magnumclient~master~I448b78ce8a65cb052306126d1996abd0775fa251,openstack/python-magnumclient,master,I448b78ce8a65cb052306126d1996abd0775fa251,Corrected spacing mistake in baymodels_shell.py,MERGED,2016-05-11 08:45:54.000000000,2016-05-11 09:31:13.000000000,2016-05-11 09:31:13.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 12053}, {'_account_id': 16523}]","[{'number': 1, 'created': '2016-05-11 08:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/4a77c64fe7b3e2ac89998bc39ca5f97544a1a967', 'message': 'Discription: This patch consist of misspaced word baymodels\n\nChange-Id: I448b78ce8a65cb052306126d1996abd0775fa251\ncloses-bug:1580450\n'}, {'number': 2, 'created': '2016-05-11 09:22:09.000000000', 'files': ['magnumclient/v1/baymodels_shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/f56285a6886a4f76097da530757fe496bb4d3db4', 'message': 'Corrected spacing mistake in baymodels_shell.py\n\n\nThis patch fixes a problem in help output where  ""bay models"" was mispaced\n\nChange-Id: I448b78ce8a65cb052306126d1996abd0775fa251\ncloses-bug: #1580450\n'}]",2,314913,f56285a6886a4f76097da530757fe496bb4d3db4,11,4,2,21785,,,0,"Corrected spacing mistake in baymodels_shell.py


This patch fixes a problem in help output where  ""bay models"" was mispaced

Change-Id: I448b78ce8a65cb052306126d1996abd0775fa251
closes-bug: #1580450
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/13/314913/2 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/v1/baymodels_shell.py'],1,4a77c64fe7b3e2ac89998bc39ca5f97544a1a967,bug/1580450," """"""Print a list of baymodels."""""""," """"""Print a list of bay models.""""""",1,1
openstack%2Fopenstack-manuals~master~I3fbf7c88e2ad47b02df6650555c2b4927632aaf2,openstack/openstack-manuals,master,I3fbf7c88e2ad47b02df6650555c2b4927632aaf2,[ops-guide] Cleanup backup and recovery chapter,MERGED,2016-05-08 06:08:40.000000000,2016-05-11 09:28:37.000000000,2016-05-11 09:28:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 16237}, {'_account_id': 17130}, {'_account_id': 19779}, {'_account_id': 19896}]","[{'number': 1, 'created': '2016-05-08 06:08:40.000000000', 'files': ['doc/ops-guide/source/ops_backup_recovery.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8af40da9b6a1f5160a6464b3cac7dcec9346386c', 'message': '[ops-guide] Cleanup backup and recovery chapter\n\nChange-Id: I3fbf7c88e2ad47b02df6650555c2b4927632aaf2\nImplements: blueprint ops-guide-rst\n'}]",0,313907,8af40da9b6a1f5160a6464b3cac7dcec9346386c,11,7,1,10497,,,0,"[ops-guide] Cleanup backup and recovery chapter

Change-Id: I3fbf7c88e2ad47b02df6650555c2b4927632aaf2
Implements: blueprint ops-guide-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/313907/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_backup_recovery.rst'],1,8af40da9b6a1f5160a6464b3cac7dcec9346386c,bp/ops-guide-rst,* How many backups to keep? * Should backups be kept off-site? * How often should backups be tested? # rsync -az --progress /var/lib/glance/images backup-server:/var/lib/glance/images/ # for i in nova-api nova-cert nova-consoleauth nova-novncproxy \ nova-objectstore nova-scheduler,- How many backups to keep? - Should backups be kept off-site? - How often should backups be tested? # rsync -az --progress /var/lib/glance/images \ backup-server:/var/lib/glance/images/ # for i in nova-api nova-cert nova-consoleauth nova-novncproxy nova-objectstore nova-scheduler,6,9
openstack%2Fgovernance~master~I498e4de49922c87ace4aeb22ea81072b2998e14f,openstack/governance,master,I498e4de49922c87ace4aeb22ea81072b2998e14f,Add manila-specs repo,MERGED,2016-05-03 14:18:57.000000000,2016-05-11 09:28:13.000000000,2016-05-11 09:28:12.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 7102}]","[{'number': 1, 'created': '2016-05-03 14:18:57.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/d67bbbe2657e711b102e6d3f4598ee25fdcc0c51', 'message': 'Add manila-specs repo\n\nChange-Id: I498e4de49922c87ace4aeb22ea81072b2998e14f\nDepends-On: I106fe89890f0d587a2ac5c6e3e14a237c1bcc7c2\n'}]",0,312102,d67bbbe2657e711b102e6d3f4598ee25fdcc0c51,12,6,1,2417,,,0,"Add manila-specs repo

Change-Id: I498e4de49922c87ace4aeb22ea81072b2998e14f
Depends-On: I106fe89890f0d587a2ac5c6e3e14a237c1bcc7c2
",git fetch https://review.opendev.org/openstack/governance refs/changes/02/312102/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,d67bbbe2657e711b102e6d3f4598ee25fdcc0c51,manila-specs, manila-specs: repos: - openstack/manila-specs tags: - release:none,,5,0
openstack%2Fgovernance~master~Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9,openstack/governance,master,Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9,Adds networking-hyperv to winstackers governance,MERGED,2016-04-30 19:56:17.000000000,2016-05-11 09:28:07.000000000,2016-05-11 09:28:07.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 2472}, {'_account_id': 3185}, {'_account_id': 6316}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 10635}, {'_account_id': 12604}]","[{'number': 1, 'created': '2016-04-30 19:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/00a8b6a63abcc01398b983f1c5ac683f1a147fdb', 'message': 'Adds networking-hyperv to winstackers governance\n\nCommit 846a52873 introduced a selection criterion for Neutron projects\nwhereby no interface to proprietary system is vouched for by the Neutron\ncore team.\n\nBecause of this, networking-hyperv was removed from the neutron governance\nin the commit 396c0df16.\n\nThis commit adds networking-hyperv to the winstackers governance. This\nprjects fits the winstackers mission, as it is a Neutron ML2 Agent\nneeded for binding neutron ports to Hyper-V compute nodes.\n\nnetworking-hyperv was added back in Kilo as a result of the Neutron\nvendor decomposition.\n\nChange-Id: Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9\n'}, {'number': 2, 'created': '2016-05-03 03:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/fa3e8a3e294d091d9518903ef491107811bd04c0', 'message': 'Adds networking-hyperv to winstackers governance\n\nCommit 846a52873 introduced a selection criterion for Neutron projects\nwhereby no interface to proprietary system is vouched for by the Neutron\ncore team.\n\nBecause of this, networking-hyperv was removed from the neutron governance\nin the commit 396c0df16.\n\nThis commit adds networking-hyperv to the winstackers governance. This\nprjects fits the winstackers mission, as it is a Neutron ML2 Agent\nneeded for binding neutron ports to Hyper-V compute nodes.\n\nnetworking-hyperv was added back in Kilo as a result of the Neutron\nvendor decomposition.\n\nChange-Id: Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9\n'}, {'number': 3, 'created': '2016-05-03 12:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a95b28cff9e8cf006ba8f6158d4a96a1e2e9be01', 'message': 'Adds networking-hyperv to winstackers governance\n\nCommit 846a52873 introduced a selection criterion for Neutron projects\nwhereby no interface to proprietary system is vouched for by the Neutron\ncore team.\n\nBecause of this, networking-hyperv was removed from the neutron governance\nin the commit 396c0df16.\n\nThis commit adds networking-hyperv to the winstackers governance. This\nprjects fits the winstackers mission, as it is a Neutron ML2 Agent\nneeded for binding neutron ports to Hyper-V compute nodes.\n\nnetworking-hyperv was added back in Kilo as a result of the Neutron\nvendor decomposition.\n\nChange-Id: Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9\n'}, {'number': 4, 'created': '2016-05-09 03:41:53.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/c84d0a702f536a43324212f803e0a43a640c9b56', 'message': 'Adds networking-hyperv to winstackers governance\n\nCommit 846a52873 introduced a selection criterion for Neutron projects\nwhereby no interface to proprietary system is vouched for by the Neutron\ncore team.\n\nBecause of this, networking-hyperv was removed from the neutron governance\nin the commit 396c0df16.\n\nThis commit adds networking-hyperv to the winstackers governance. This\nprjects fits the winstackers mission, as it is a Neutron ML2 Agent\nneeded for binding neutron ports to Hyper-V compute nodes.\n\nnetworking-hyperv was added back in Kilo as a result of the Neutron\nvendor decomposition.\n\nChange-Id: Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9\n'}]",7,311566,c84d0a702f536a43324212f803e0a43a640c9b56,23,12,4,8213,,,0,"Adds networking-hyperv to winstackers governance

Commit 846a52873 introduced a selection criterion for Neutron projects
whereby no interface to proprietary system is vouched for by the Neutron
core team.

Because of this, networking-hyperv was removed from the neutron governance
in the commit 396c0df16.

This commit adds networking-hyperv to the winstackers governance. This
prjects fits the winstackers mission, as it is a Neutron ML2 Agent
needed for binding neutron ports to Hyper-V compute nodes.

networking-hyperv was added back in Kilo as a result of the Neutron
vendor decomposition.

Change-Id: Idf4889c9e81e5bbe10ddfdd03fa7e47f4442e6a9
",git fetch https://review.opendev.org/openstack/governance refs/changes/66/311566/4 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,00a8b6a63abcc01398b983f1c5ac683f1a147fdb,, networking-hyperv: repos: - openstack/networking-hyperv tags: - release:cycle-with-intermediary - release:has-stable-branches - release:independent,,7,0
openstack%2Fopenstack-manuals~master~If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817,openstack/openstack-manuals,master,If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817,[install-guide] Add ipset installation in compute node,MERGED,2016-05-06 13:10:14.000000000,2016-05-11 09:27:53.000000000,2016-05-11 09:15:07.000000000,"[{'_account_id': 3}, {'_account_id': 9515}, {'_account_id': 10607}, {'_account_id': 12860}]","[{'number': 1, 'created': '2016-05-06 13:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2870d7e077cb4909085d190cfdd2ef8ea11736db', 'message': '[install-guide] Add ipset installation in compute node\n\nIn some case, host may lack ipset utility(e.g., due to a\ndependency issue). This will cause create vm failed if we\nenable Neutron securitygroup in compute node.\n\nWe had already fixed in Neutron side, we using neutron-sanity-check\ntool for check ipset installation. But this is insufficiency,\nsome guys may not know that tool.\n\nSo we install ipset in compute node.\n\nChange-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817\nRelated-Bug: #1510680\n'}, {'number': 2, 'created': '2016-05-10 08:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/07e4ac8742eb8307e52217b65c2665f6807f92b1', 'message': '[install-guide] Add ipset installation in compute node\n\nIn some case, host may lack ipset utility(e.g., due to a\ndependency issue). This will cause create vm failed if we\nenable Neutron securitygroup in compute node.\n\nWe had already fixed in Neutron side, we using neutron-sanity-check\ntool for check ipset installation. But this is insufficiency,\nsome guys may not know that tool.\n\nSo we install ipset in compute node.\n\nbackport: Mitaka\nTODO in RDO: https://bugzilla.redhat.com/show_bug.cgi?id=1334626\n\nChange-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817\nRelated-Bug: #1510680\n'}, {'number': 3, 'created': '2016-05-10 13:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/db80c263e1cbe87d7410652b3cb88a3af3d4fb75', 'message': '[install-guide] Add ipset installation in compute node\n\nIn some case, host may lack ipset utility(e.g., due to a\ndependency issue). This will cause create vm failed if we\nenable Neutron securitygroup in compute node.\n\nWe had already fixed in Neutron side, we using neutron-sanity-check\ntool for check ipset installation. But this is insufficiency,\nsome guys may not know that tool.\n\nSo we install ipset in compute node.\n\nbackport: Mitaka\nTODO in RDO: https://bugzilla.redhat.com/show_bug.cgi?id=1334626\n\nChange-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817\nRelated-Bug: #1510680\n'}, {'number': 4, 'created': '2016-05-10 14:01:30.000000000', 'files': ['doc/install-guide/source/neutron-compute-install.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8a4ffb4224d438d68d642f93269002b06bf63502', 'message': '[install-guide] Add ipset installation in compute node\n\nIn some case, host may lack ipset utility(e.g., due to a\ndependency issue). This will cause create vm failed if we\nenable Neutron securitygroup in compute node.\n\nWe had already fixed in Neutron side, we using neutron-sanity-check\ntool for check ipset installation. But this is insufficiency,\nsome guys may not know that tool.\n\nSo we install ipset in compute node.\n\nbackport: Mitaka\n\nChange-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817\nRelated-Bug: #1510680\n'}]",0,313542,8a4ffb4224d438d68d642f93269002b06bf63502,18,4,4,12860,,,0,"[install-guide] Add ipset installation in compute node

In some case, host may lack ipset utility(e.g., due to a
dependency issue). This will cause create vm failed if we
enable Neutron securitygroup in compute node.

We had already fixed in Neutron side, we using neutron-sanity-check
tool for check ipset installation. But this is insufficiency,
some guys may not know that tool.

So we install ipset in compute node.

backport: Mitaka

Change-Id: If071a9aa3d8bb5854de1abd4c9eb3eafb3b07817
Related-Bug: #1510680
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/42/313542/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/neutron-compute-install.rst'],1,2870d7e077cb4909085d190cfdd2ef8ea11736db,add_ipset, # apt-get install neutron-linuxbridge-agent ipset # yum install openstack-neutron-linuxbridge ebtables ipset, # apt-get install neutron-linuxbridge-agent # yum install openstack-neutron-linuxbridge ebtables,2,2
openstack%2Fmagnum~master~Ie66634819f91189566e441ceceab3a4ab28f7cea,openstack/magnum,master,Ie66634819f91189566e441ceceab3a4ab28f7cea,Corrected spelling mistake in quickstart.rst,MERGED,2016-05-10 12:20:38.000000000,2016-05-11 09:26:31.000000000,2016-05-11 09:26:31.000000000,"[{'_account_id': 3}, {'_account_id': 12053}, {'_account_id': 12175}]","[{'number': 1, 'created': '2016-05-10 12:20:38.000000000', 'files': ['doc/source/dev/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/958d1e593efd2601e721c61a3fee41dacef45b19', 'message': 'Corrected spelling mistake in quickstart.rst\n\nThis patch fixes a problem in quick start where\n""kubectl get po"" was mispelled.\n\nChange-Id: Ie66634819f91189566e441ceceab3a4ab28f7cea\nCloses-bug: #1580121\n'}]",0,314530,958d1e593efd2601e721c61a3fee41dacef45b19,8,3,1,21785,,,0,"Corrected spelling mistake in quickstart.rst

This patch fixes a problem in quick start where
""kubectl get po"" was mispelled.

Change-Id: Ie66634819f91189566e441ceceab3a4ab28f7cea
Closes-bug: #1580121
",git fetch https://review.opendev.org/openstack/magnum refs/changes/30/314530/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/quickstart.rst'],1,958d1e593efd2601e721c61a3fee41dacef45b19,bug/1580121, kubectl get pods # Get pods, kubectl get po # Get pods,1,1
openstack%2Fpython-designateclient~master~I4b64fee4f526cc5b4a5e36cc8edb61164ceded51,openstack/python-designateclient,master,I4b64fee4f526cc5b4a5e36cc8edb61164ceded51,Update doc examples to use keystoneauth,MERGED,2016-05-07 00:11:14.000000000,2016-05-11 09:24:51.000000000,2016-05-11 09:24:51.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 15699}]","[{'number': 1, 'created': '2016-05-07 00:11:14.000000000', 'files': ['doc/source/bindings.rst', 'doc/examples/zone_list_paging.py', 'doc/examples/recordset_create.py', 'doc/examples/zone_create_primary.py', 'doc/examples/recordset_crud.py', 'doc/examples/zone_create_secondary.py', 'doc/examples/zone_list_nameservers.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/69f4597bf1232bf4c3a37f2516a48fd185a1d0cd', 'message': ""Update doc examples to use keystoneauth\n\nAs keystoneclient's Session and auth plugins have been deprecated in\nfavor of keystoneauth, the documentation examples must reflect that.\n\nThis patch updates all examples in order to show keystoneauth Session\nusage instead of deprecated keystoneclient Session. Also, the python API\nbindings were updated too.\n\nChange-Id: I4b64fee4f526cc5b4a5e36cc8edb61164ceded51\n""}]",0,313809,69f4597bf1232bf4c3a37f2516a48fd185a1d0cd,9,4,1,20259,,,0,"Update doc examples to use keystoneauth

As keystoneclient's Session and auth plugins have been deprecated in
favor of keystoneauth, the documentation examples must reflect that.

This patch updates all examples in order to show keystoneauth Session
usage instead of deprecated keystoneclient Session. Also, the python API
bindings were updated too.

Change-Id: I4b64fee4f526cc5b4a5e36cc8edb61164ceded51
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/09/313809/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/bindings.rst', 'doc/examples/zone_list_paging.py', 'doc/examples/recordset_create.py', 'doc/examples/zone_create_primary.py', 'doc/examples/recordset_crud.py', 'doc/examples/zone_create_secondary.py', 'doc/examples/zone_list_nameservers.py']",7,69f4597bf1232bf4c3a37f2516a48fd185a1d0cd,use-ksa,"from keystoneauth1.identity import generic from keystoneauth1 import session as keystone_session project_name=shell.env('OS_PROJECT_NAME'), project_domain_id='default', user_domain_id='default')",from keystoneclient.auth.identity import generic from keystoneclient import session as keystone_session tenant_name=shell.env('OS_TENANT_NAME')),85,42
openstack%2Fgovernance~master~I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751,openstack/governance,master,I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751,Change OpenStack-Ansible release model to cycle-trailing,MERGED,2016-03-24 18:31:59.000000000,2016-05-11 09:22:32.000000000,2016-05-11 09:22:32.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-03-24 18:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/5a475279e0247414efd4352bc10b46eadeed23c8', 'message': 'Change OpenStack-Ansible release model\n\nOpenStack-Ansible has been releasing in a cycle-with-intermediary\nmodel since its inception. As a deployment project the release\ndates may not be exactly in line with OpenStack service projects\n(as it relies on them) but the major releases are done in the same\ngeneral cycle as the OpenStack service projects.\n\nThe integrated release repository (openstack-ansible) is the primary\nrelease mechanism. In the Mitaka cycle each Ansible role which\ndeploys and configures a particular OpenStack or supporting service\nis considered a deliverable in its own right and they have therefore\nbeen split into their own repositories. Each of these will also\nfollow the cycle-with-intermediary release cycle, each having stable\nstable branches that follow the OpenStack major releases.\n\nChange-Id: I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751\n'}, {'number': 2, 'created': '2016-03-25 10:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/7f362ea07d296f249074fc9225bde0508b8219d6', 'message': 'Change OpenStack-Ansible release model\n\nOpenStack-Ansible has been releasing in a cycle-with-intermediary\nmodel since its inception. As a deployment project the release\ndates may not be exactly in line with OpenStack service projects\n(as it relies on them) but the major releases are done in the same\ngeneral cycle as the OpenStack service projects.\n\nThe integrated release repository (openstack-ansible) is the primary\nrelease mechanism. In the Mitaka cycle each Ansible role which\ndeploys and configures a particular OpenStack or supporting service\nis considered a deliverable in its own right and they have therefore\nbeen split into their own repositories. Each of these will also\nfollow the cycle-with-intermediary release cycle, each having stable\nstable branches that follow the OpenStack major releases.\n\nChange-Id: I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751\n'}, {'number': 3, 'created': '2016-04-05 10:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/2247eb06fb828fc88ed66ee477401ab35af3e91f', 'message': 'Change OpenStack-Ansible release model\n\nOpenStack-Ansible has been releasing in a cycle-with-intermediary\nmodel since its inception. As a deployment project the release\ndates may not be exactly in line with OpenStack service projects\n(as it relies on them) but the major releases are done in the same\ngeneral cycle as the OpenStack service projects.\n\nThe integrated release repository (openstack-ansible) is the primary\nrelease mechanism. In the Mitaka cycle each Ansible role which\ndeploys and configures a particular OpenStack or supporting service\nis considered a deliverable in its own right and they have therefore\nbeen split into their own repositories. Each of these will also\nfollow the cycle-with-intermediary release cycle, each having stable\nstable branches that follow the OpenStack major releases.\n\nChange-Id: I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751\n'}, {'number': 4, 'created': '2016-04-22 11:41:59.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/5b9316832d3764a59e06978d9b6d656c1f3661a4', 'message': ""Change OpenStack-Ansible release model to cycle-trailing\n\nOpenStack-Ansible (OSA) has been releasing on a cycle-based model\nsince its inception, but none of the existing models really\nfit properly.\n\nThe release-trailing model was recently created and provides\nthe opportunity for OSA to formally implement a cycle-based\nrelease model while still accommodating the need to sometimes\nlag a little behind the service projects. This is essential for\ndeployment projects as they consume the service projects.\n\nThis patch changes the OSA release model to cycle-trailing to\nproperly reflect the model that's always been used and to allow\nOSA to properly fit within OpenStack's governance framework.\n\nChange-Id: I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751\n""}]",0,297297,5b9316832d3764a59e06978d9b6d656c1f3661a4,36,9,4,6816,,,0,"Change OpenStack-Ansible release model to cycle-trailing

OpenStack-Ansible (OSA) has been releasing on a cycle-based model
since its inception, but none of the existing models really
fit properly.

The release-trailing model was recently created and provides
the opportunity for OSA to formally implement a cycle-based
release model while still accommodating the need to sometimes
lag a little behind the service projects. This is essential for
deployment projects as they consume the service projects.

This patch changes the OSA release model to cycle-trailing to
properly reflect the model that's always been used and to allow
OSA to properly fit within OpenStack's governance framework.

Change-Id: I5375caefa078a8b34c8b2c24a9fcb6e7ea90b751
",git fetch https://review.opendev.org/openstack/governance refs/changes/97/297297/4 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,5a475279e0247414efd4352bc10b46eadeed23c8,OpenStack-Ansible, - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary - release:cycle-with-intermediary, - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent - release:independent,34,34
openstack%2Fgovernance~master~I16d2499c4721fbbb3d9af3eb48962a9f3aacb4b5,openstack/governance,master,I16d2499c4721fbbb3d9af3eb48962a9f3aacb4b5,update management expectations for release tags,MERGED,2016-04-19 21:20:52.000000000,2016-05-11 09:21:18.000000000,2016-05-11 09:21:18.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 170}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 5638}, {'_account_id': 6159}]","[{'number': 1, 'created': '2016-04-19 21:20:52.000000000', 'files': ['reference/tags/release_cycle-trailing.rst', 'reference/tags/release_cycle-with-intermediary.rst', 'reference/tags/release_cycle-with-milestones.rst', 'reference/tags/release_independent.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/4df15d4c580ada99270b3ed1790bb7683966ea25', 'message': 'update management expectations for release tags\n\nUpdate the requirements for the release model tags to document which\nones require project teams to go through the release review process.\n\nChange-Id: I16d2499c4721fbbb3d9af3eb48962a9f3aacb4b5\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,308045,4df15d4c580ada99270b3ed1790bb7683966ea25,21,11,1,2472,,,0,"update management expectations for release tags

Update the requirements for the release model tags to document which
ones require project teams to go through the release review process.

Change-Id: I16d2499c4721fbbb3d9af3eb48962a9f3aacb4b5
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/45/308045/1 && git format-patch -1 --stdout FETCH_HEAD,"['reference/tags/release_cycle-trailing.rst', 'reference/tags/release_cycle-with-intermediary.rst', 'reference/tags/release_cycle-with-milestones.rst', 'reference/tags/release_independent.rst']",4,4df15d4c580ada99270b3ed1790bb7683966ea25,formal-vote,* Release tags for deliverables using this tag are managed without oversight from the Release Management team.,,8,0
openstack%2Fopenstack-manuals~master~Iedc03a596d3890b3a170141ed244ff123c6a5239,openstack/openstack-manuals,master,Iedc03a596d3890b3a170141ed244ff123c6a5239,[ops-guide] Cleanup upgrades chapter,MERGED,2016-05-07 11:29:09.000000000,2016-05-11 09:17:32.000000000,2016-05-11 09:17:31.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 16237}, {'_account_id': 17130}, {'_account_id': 19896}]","[{'number': 1, 'created': '2016-05-07 11:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f22a1375ce6d6c3f2a730302d530ebbb4f41ec6f', 'message': '[ops-guide] Cleanup upgrades chapter\n\nChange-Id: Iedc03a596d3890b3a170141ed244ff123c6a5239\nImplements: blueprint ops-guide-rst\n'}, {'number': 2, 'created': '2016-05-07 12:40:53.000000000', 'files': ['doc/ops-guide/source/ops_upgrades.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b359671836487f67cb698b2d32365fde5b83e12e', 'message': '[ops-guide] Cleanup upgrades chapter\n\nChange-Id: Iedc03a596d3890b3a170141ed244ff123c6a5239\nImplements: blueprint ops-guide-rst\n'}]",2,313863,b359671836487f67cb698b2d32365fde5b83e12e,14,7,2,10497,,,0,"[ops-guide] Cleanup upgrades chapter

Change-Id: Iedc03a596d3890b3a170141ed244ff123c6a5239
Implements: blueprint ops-guide-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/313863/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_upgrades.rst'],1,f22a1375ce6d6c3f2a730302d530ebbb4f41ec6f,bp/ops-guide-rst," notes <http://http://releases.openstack.org/>`_ to learn Reference <http://docs.openstack.org/mitaka/config-reference/>`_* `Upgrading the Networking service <http://docs.openstack.org/developer/neutron/devref/upgrade.html>`_#. Identity service - Clear any expired tokens before synchronizing the database. #. Image service #. Compute service, including networking components. #. Networking service #. Block Storage service #. Dashboard - In typical environments, updating Dashboard only requires restarting the Apache HTTP service. #. Orchestration service #. Telemetry service - In typical environments, updating the Telemetry service only requires restarting the service. #. Compute service - Edit the configuration file and restart the service. #. Networking service - Edit the configuration file and restart the service.* Block Storage service - Updating the Block Storage service only requires restarting the service. **Compute nodes** * Networking service - Edit the configuration file and restart the service."," notes <http://wiki.openstack.org/wiki/ReleaseNotes/>`_ to learn Reference <http://docs.openstack.org/liberty/config-reference/content/>`_* `Upgrading the Networking Service <http://docs.openstack.org/developer/neutron/devref/upgrade.html>`_#. OpenStack Identity - Clear any expired tokens before synchronizing the database. #. OpenStack Image service #. OpenStack Compute, including networking components. #. OpenStack Networking #. OpenStack Block Storage #. OpenStack dashboard - In typical environments, updating the dashboard only requires restarting the Apache HTTP service. #. OpenStack Orchestration #. OpenStack Telemetry - In typical environments, updating the Telemetry service only requires restarting the service. #. OpenStack Compute - Edit the configuration file and restart the service. #. OpenStack Networking - Edit the configuration file and restart the service. **Compute nodes** - OpenStack Block Storage - Updating the Block Storage service only requires restarting the service.- OpenStack Networking - Edit the configuration file and restart the service.",23,25
openstack%2Ffuel-library~stable%2F7.0~I4c51f8608702f2284d835ba9c3c9070b2c329ed8,openstack/fuel-library,stable/7.0,I4c51f8608702f2284d835ba9c3c9070b2c329ed8,Stop process when rabbit is running but is not connected to master.,MERGED,2016-05-06 10:29:38.000000000,2016-05-11 09:13:05.000000000,2016-05-11 09:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14689}, {'_account_id': 14985}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-06 10:29:38.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3fecfb479b01e25d0c15ab31e4af06db2de8f30d', 'message': ""Stop process when rabbit is running but is not connected to master.\n\nIt's should goes down due to avoid split brain.\n\nChange-Id: I4c51f8608702f2284d835ba9c3c9070b2c329ed8\nCloses-Bug: #1541471\nUpstream PR: https://github.com/rabbitmq/rabbitmq-server/pull/758\n""}]",2,313315,3fecfb479b01e25d0c15ab31e4af06db2de8f30d,29,8,1,17730,,,0,"Stop process when rabbit is running but is not connected to master.

It's should goes down due to avoid split brain.

Change-Id: I4c51f8608702f2284d835ba9c3c9070b2c329ed8
Closes-Bug: #1541471
Upstream PR: https://github.com/rabbitmq/rabbitmq-server/pull/758
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/15/313315/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,3fecfb479b01e25d0c15ab31e4af06db2de8f30d,,"#!/bin/sh # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License.# Note that the script uses an external file to setup RabbitMQ policies # so make sure to create it from an example shipped with the package. #OCF_RESKEY_pid_file_default=""/var/run/rabbitmq/pid"" OCF_RESKEY_log_dir_default=""/var/log/rabbitmq"" OCF_RESKEY_mnesia_base_default=""/var/lib/rabbitmq/mnesia"" OCF_RESKEY_host_ip_default=""127.0.0.1""OCF_RESKEY_use_fqdn_default=false OCF_RESKEY_fqdn_prefix_default="""" OCF_RESKEY_max_rabbitmqctl_timeouts_default=3 OCF_RESKEY_policy_file_default=""/usr/local/sbin/set_rabbitmq_policy"": ${OCF_RESKEY_use_fqdn=${OCF_RESKEY_use_fqdn_default}} : ${OCF_RESKEY_fqdn_prefix=${OCF_RESKEY_fqdn_prefix_default}}: ${OCF_RESKEY_policy_file=${OCF_RESKEY_policy_file_default}}OCF_RESKEY_stop_time_default=${OCF_RESKEY_start_time_default} : ${OCF_RESKEY_stop_time=${OCF_RESKEY_start_time_default}} # The EXTENDED_OCF_PARAMS parameter below does not exist by default # and hence converted to an empty string unless overridden. It # could be used by an extention script to add new parameters. For # example see https://review.openstack.org/#/c/249180/10 <parameter name=""stop_time"" unique=""0"" required=""0""> <longdesc lang=""en""> Timeout for stopping rabbitmq server </longdesc> <shortdesc lang=""en"">Timeout for stopping rabbitmq server</shortdesc> <content type=""string"" default=""${OCF_RESKEY_stop_time_default}"" /> </parameter> <parameter name=""host_ip"" unique=""0"" required=""0""> <longdesc lang=""en""> ${OCF_RESKEY_binary} should listen on this IP address </longdesc> <shortdesc lang=""en"">${OCF_RESKEY_binary} should listen on this IP address</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_host_ip_default}"" /> </parameter> <parameter name=""use_fqdn"" unique=""0"" required=""0""> <longdesc lang=""en""> Either to use FQDN or a shortname for the rabbitmq node </longdesc> <shortdesc lang=""en"">Use FQDN</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_use_fqdn_default}"" /> </parameter> <parameter name=""fqdn_prefix"" unique=""0"" required=""0""> <longdesc lang=""en""> Optional FQDN prefix for RabbitMQ nodes in cluster. FQDN prefix can be specified to host multiple RabbitMQ instances on a node or in case of RabbitMQ running in dedicated network/interface. </longdesc> <shortdesc lang=""en"">FQDN prefix</shortdesc> <content type=""string"" default=""${OCF_RESKEY_fqdn_prefix_default}"" /> </parameter> <parameter name=""policy_file"" unique=""0"" required=""0""> <longdesc lang=""en""> A path to the shell script to setup RabbitMQ policies </longdesc> <shortdesc lang=""en"">A policy file path</shortdesc> <content type=""string"" default=""${OCF_RESKEY_policy_file_default}"" /> </parameter> $EXTENDED_OCF_PARAMS #TODO(bogdando) move proc_kill, proc_stop to shared OCF functions # to be shipped with HA cluster packages ########################################################### # Attempts to kill a process with retries and checks procfs # to make sure the process is stopped. # # Globals: # LL # Arguments: # $1 - pid of the process to try and kill # $2 - service name used for logging and match-based kill, if the pid is ""none"" # $3 - signal to use, defaults to SIGTERM # $4 - number of retries, defaults to 5 # $5 - time to sleep between retries, defaults to 2 # Returns: # 0 - if successful # 1 - if process is still running according to procfs # 2 - if invalid parameters passed in ########################################################### proc_kill() { local pid=""${1}"" local service_name=""${2}"" local signal=""${3:-SIGTERM}"" local count=""${4:-5}"" local process_sleep=""${5:-2}"" local LH=""${LL} proc_kill():"" local pgrp=""$(ps -o pgid= ${pid} 2>/dev/null | tr -d '[[:space:]]')"" if [ ""${pid}"" -a ""${pgrp}"" = ""1"" ] ; then ocf_log err ""${LH} shall not kill by the bad pid 1 (init)!"" return 2 fi if [ ""${pid}"" = ""none"" ]; then local matched matched=""$(pgrep -fla ${service_name})"" if [ -z ""${matched}"" ] ; then ocf_log err ""${LH} cannot find any processes matching the ${service_name}!"" return 2 fi ocf_log debug ""${LH} no pid provided, will try the ${service_name}, matched list: ${matched}"" while [ $count -gt 0 ]; do if [ -z ""${matched}"" ]; then break else matched=""$(pgrep -fla ${service_name})"" ocf_log debug ""${LH} Stopping ${service_name} with ${signal}..."" ocf_run pkill -f -""${signal}"" ""${service_name}"" fi sleep $process_sleep count=$(( count-1 )) done pgrep -f ""${service_name}"" > /dev/null if [ $? -ne 0 ] ; then ocf_log debug ""${LH} Stopped ${service_name} with ${signal}"" return 0 else ocf_log warn ""${LH} Failed to stop ${service_name} with ${signal}"" return 1 fi else # pid is not none while [ $count -gt 0 ]; do if [ ! -d ""/proc/${pid}"" ]; then break else ocf_log debug ""${LH} Stopping ${service_name} with ${signal}..."" ocf_run pkill -""${signal}"" -g ""${pgrp}"" fi sleep $process_sleep count=$(( count-1 )) done # Check if the process ended after the last sleep if [ ! -d ""/proc/${pid}"" ] ; then ocf_log debug ""${LH} Stopped ${service_name} with ${signal}"" return 0 fi ocf_log warn ""${LH} Failed to stop ${service_name} with ${signal}"" return 1 fi } ########################################################### # Attempts to kill a process with the given pid or pid file # using proc_kill and will retry with sigkill if sigterm is # unsuccessful. # # Globals: # OCF_ERR_GENERIC # OCF_SUCCESS # LL # Arguments: # $1 - pidfile or pid or 'none', if stopping by the name matching # $2 - service name used for logging or for the failback stopping method # $3 - stop process timeout (in sec), used to determine how many times we try # SIGTERM and an upper limit on how long this function should try and # stop the process. Defaults to 15. # Returns: # OCF_SUCCESS - if successful # OCF_ERR_GENERIC - if process is still running according to procfs ########################################################### proc_stop() { local pid_param=""${1}"" local service_name=""${2}"" local timeout=""${3:-15}"" local LH=""${LL} proc_stop():"" local i local pid local pidfile if [ ""${pid_param}"" = ""none"" ] ; then pid=""none"" else # check if provide just a number echo ""${pid_param}"" | egrep -q '^[0-9]+$' if [ $? -eq 0 ]; then pid=""${pid_param}"" elif [ -e ""${pid_param}"" ]; then # check if passed in a pid file pidfile=""${pid_param}"" pid=$(cat ""${pidfile}"" 2>/dev/null | tr -s "" "" ""\n"" | sort -u) else ocf_log warn ""${LH} pid param ${pid_param} is not a file or a number, try match by ${service_name}"" pid=""none"" fi fi # number of times to try a SIGTEM is (timeout - 5 seconds) / 2 seconds local stop_count=$(( ($timeout-5)/2 )) # make sure we stop at least once if [ $stop_count -le 0 ]; then stop_count=1 fi if [ -z ""${pid}"" ] ; then ocf_log warn ""${LH} unable to get PID from ${pidfile}, try match by ${service_name}"" pid=""none"" fi if [ -n ""${pid}"" ]; then for i in ${pid} ; do [ ""${i}"" ] || break ocf_log info ""${LH} Stopping ${service_name} by PID ${i}"" proc_kill ""${i}"" ""${service_name}"" SIGTERM $stop_count if [ $? -ne 0 ]; then # SIGTERM failed, send a single SIGKILL proc_kill ""${i}"" ""${service_name}"" SIGKILL 1 2 if [ $? -ne 0 ]; then ocf_log err ""${LH} ERROR: could not stop ${service_name}"" return ""${OCF_ERR_GENERIC}"" fi fi done fi # Remove the pid file here which will remove empty pid files as well if [ -n ""${pidfile}"" ]; then rm -f ""${pidfile}"" fi ocf_log info ""${LH} Stopped ${service_name}"" return ""${OCF_SUCCESS}"" } local timeout if [ ""$1"" = ""-t"" ]; then timeout=""/usr/bin/timeout ${OCF_RESKEY_command_timeout} $2"" shift 2 else timeout=$COMMAND_TIMEOUT fi local cmd=""${1:-status}"" ${timeout} ${cmd}"" local LH=""${LL} master_score():"" if [ -z $score ] ; then ocf_log info ""${LH} Updating master score attribute with ${score}""# Return either FQDN or shortname, depends on the OCF_RESKEY_use_fqdn. get_hostname() { if [ ""${OCF_RESKEY_use_fqdn}"" = 'false' ] ; then echo ""$(hostname -s)"" else echo ""$(hostname -f)"" fi } # Strip the FQDN to the shortname, if OCF_RESKEY_use_fqdn was set; # Prepend prefix to the hostname process_fqdn() { if [ ""${OCF_RESKEY_use_fqdn}"" = 'false' ] ; then echo ""${OCF_RESKEY_fqdn_prefix}$1"" | awk -F. '{print $1}' else echo ""${OCF_RESKEY_fqdn_prefix}$1"" fi } local hostname hostname=$(process_fqdn $(get_hostname)) hn=$(process_fqdn ""${host}"") if [ ""${hostname}"" = ""${hn}"" ] ; then if [ -z ""${stime}"" -o ""${stime}"" = ""(null)"" ] ; then# Return either rabbit node name as FQDN or shortname, depends on the OCF_RESKEY_use_fqdn. rabbit_node_name() { echo ""rabbit@$(process_fqdn $1)"" } H=""$(get_hostname)"" export RABBITMQ_NODENAME=$(rabbit_node_name $H) MNESIA_FILES=""${OCF_RESKEY_mnesia_base}/$(rabbit_node_name $H)"" local files files=$(su -s /bin/sh - $OCF_RESKEY_username -c ""find ${dir} ! -writable"") if [ ""${files}"" ]; then export LL=""${OCF_RESOURCE_INSTANCE}[$$]:"" if [ $rc -eq 0 ] ; then if [ $rc -eq 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then ocf_run rm -rf ""${MNESIA_FILES}"" ocf_log warn ""${LH} Mnesia files appear corrupted and have been removed from ${MNESIA_FILES}."" until $(iptables -nvL | grep -q 'temporary RMQ block') || [ $tries -eq 0 ]; do tries=$((tries-1)) local c_status if [ ""$1"" = 'nodes' ] elif [ ""$1"" = 'running' ] c_status=`${OCF_RESKEY_ctl} eval ""mnesia:system_info(${infotype})."" 2>/dev/null` if [ $rc -ne 0 ] ; then echo $(echo ""${c_status}"" | awk -F, '{ for (i=1;i<=NF;i++) { if ($i ~ /@/) { gsub(/[\[\]}{]/,"""",$i); print $i; } }}' | tr -d ""\'"") if [ -z ""$1"" ]; then} # Get current master. If a parameter is provided, # do not check node with that name get_master_name_but() { local node for node in $(get_alive_pacemaker_nodes_but ""$@"") do ocf_log info ""${LH} looking if $node is master"" if is_master $node; then ocf_log info ""${LH} master is $node"" echo $node break fi done } # Returns 0 if we are clustered with provideded node is_clustered_with() { get_running_nodes | grep -q $(rabbit_node_name $1); check_need_join_to() { local join_to local running_nodes join_to=$(rabbit_node_name $1) running_nodes=$(get_running_nodes) if [ ""${join_to}"" = ""${node}"" ] ; then# Stop rmq beam process by pid and by rabbit node name match. Returns SUCCESS/ERROR kill_rmq_and_remove_pid() { # Stop the rabbitmq-server by its pidfile, use the name matching as a fallback, # and ignore the exit code proc_stop ""${OCF_RESKEY_pid_file}"" ""beam.*${RABBITMQ_NODENAME}"" ""${OCF_RESKEY_stop_time}"" # Ensure the beam.smp stopped by the rabbit node name matching as well proc_stop none ""beam.*${RABBITMQ_NODENAME}"" ""${OCF_RESKEY_stop_time}"" if [ $? -eq 0 ] ; then return $OCF_SUCCESS else return $OCF_ERR_GENERIC local rmq_node local nowtime rmq_node=$(rabbit_node_name $node) ocf_log info ""${LH} Joining to cluster by node '${rmq_node}'."" if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then nowtime=""$(now)"" ocf_log info ""${LH} Rabbit app started successfully. Updating start time attribute with ${nowtime}"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update ""${nowtime}"" if [ $rc -ne 0 ] ; then if [ ""${nodename}"" = ""${RABBITMQ_NODENAME}"" ] ; then if [ ""${nodename}"" = ""${rnode}"" ] ; then if [ $rc -eq $OCF_SUCCESS ] ; then tries=$((tries+1)) if is_clustered_with $nodename; then else break if [ $rc -eq 0 ] ; then# Stop RMQ beam server process. Returns SUCCESS/ERROR if [ $rc -ne 0 ] ; then # Try to stop without known PID ocf_log err ""${LH} RMQ-server process PIDFILE was not found!"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" if [ $? -eq 0 ] ; then ocf_log info ""${LH} RMQ-server process stopped succesfully, although there was no PIDFILE found."" ocf_log info ""${LH} grant a graceful termintation window ${OCF_RESKEY_stop_time} to end its beam"" sleep ""${OCF_RESKEY_stop_time}"" else kill_rmq_and_remove_pid fi elif [ ""${pid}"" ] ; then # Try to stop gracefully by known PID ocf_log info ""${LH} Execute stop with timeout: ${TIMEOUT_ARG}"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop ${OCF_RESKEY_pid_file} 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" [ $? -eq 0 ] && ocf_log info ""${LH} RMQ-server process (PID=${pid}) stopped succesfully."" # Ensure there is no beam process and pidfile left pgrep -f ""beam.*${RABBITMQ_NODENAME}"" > /dev/null rc=$? if [ -f ${OCF_RESKEY_pid_file} -o $rc -eq 0 ] ; then ocf_log warn ""${LH} The pidfile or beam's still exist, forcing the RMQ-server cleanup"" fi # Return the actual status get_status if [ $? -ne 0 ] ; then return $OCF_SUCCESS else if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then local command if [ -f ""${OCF_RESKEY_pid_file}"" ] ; then if [ ""${pid}"" -a -d ""/proc/${pid}"" ] ; then if [ $rc -eq $OCF_SUCCESS ] ; then ocf_run kill -TERM $pid ocf_run rm -f $OCF_RESKEY_pid_file command=""${OCF_RESKEY_binary} >> \""${OCF_RESKEY_log_dir}/startup_log\"" 2>/dev/null"" if [ -f ""${OCF_RESKEY_pid_file}"" ] ; then if [ ""${pid}"" != ""0"" -a -d ""/proc/${pid}"" ] ; then if [ $rc -ne $OCF_SUCCESS ]; then if [ ""${pid}"" = ""0"" ] ; then local rc=$? if [ $rc -eq 0 ] ; then local list list=`${OCF_RESKEY_ctl} eval 'rabbit_plugins:active().'` echo ""${list}"" if [ $rc -ne $OCF_SUCCESS ] ; then if [ $rc -ne $OCF_SUCCESS ]; then if [ -z ""${startup_log}"" ] ; then if [ $rc -eq 0 ] ; then if [ $rc -ne 0 ] ; then if [ $mrc -eq 0 ] ; then local mlist mlist=`list_active_plugins` ocf_log info ""${LH} Starting plugins: ${mlist}"" if [ $rc -eq $OCF_SUCCESS ]; then if [ $rc -ne $OCF_SUCCESS ] ; then if [ $rc -ne $OCF_SUCCESS ]; then if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc -ne 0 ] ; then for a in $(seq 1 10) ; do if [ $rc -eq $OCF_SUCCESS ]; then if [ $rc -eq $OCF_SUCCESS ]; then if [ $rc -eq $OCF_ERR_GENERIC ] ; then local rc=$OCF_NOT_RUNNING local LH=""${LL} get_status():"" local beam_running pgrep -f ""beam.*${RABBITMQ_NODENAME}"" > /dev/null beam_running=$? # report not running only if the which_applications() reported an error AND the beam is not running if [ $rc -ne 0 -a $beam_running -ne 0 ] ; then ocf_log info ""${LH} failed with code ${rc}. Command output: ${body}"" # return a generic error, if there were errors and beam is found running elif [ $rc -ne 0 ] ; then ocf_log info ""${LH} found the beam process running but failed with code ${rc}. Command output: ${body}"" return $OCF_ERR_GENERIC # try to parse the which_applications() output only if it exited w/o errors if [ ""${what}"" -a $rc -eq 0 ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then ocf_log info ""${LH} app ${what} was not found in command output: ${body}"" [ $rc -ne $OCF_SUCCESS ] && rc=$OCF_NOT_RUNNING if [ ""${result}"" != 'true' ] ; then count=`crm_attribute -N $THIS_PCMK_NODE -l reboot --name $crm_attr_name --query 2>/dev/null` count=`echo ""${count}"" | awk '{print $3}' | awk -F ""="" '{print $2}' | sed -e '/(null)/d'`wait_sync() { wait_time=$1 queues=""${COMMAND_TIMEOUT} ${OCF_RESKEY_ctl} list_queues name state"" su_rabbit_cmd -t ""${wait_time}"" ""sh -c \""while ${queues} | grep -q 'syncing,'; \ do sleep 2; done\"""" return $? } local status_master=1 if [ $rc -eq $OCF_NOT_RUNNING ] ; then elif [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} We are the running master"" elif [ $status_master -eq 0 -a $rabbit_running -ne $OCF_SUCCESS ] ; then ocf_log err ""${LH} We are the master and RMQ-runtime (beam) is not running. this is a failure"" exit $OCF_FAILED_MASTER if [ $rabbit_running -eq $OCF_SUCCESS ] ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" else local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -z ""$master_name"" ]; then ocf_log info ""${LH} no master is elected currently. Skipping cluster health check."" elif is_clustered_with $master_name; then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" else # Rabbit is running but is not connected to master # Failing to avoid split brain ocf_log err ""${LH} rabbit node is running out of the cluster"" stop_server_process rc=$OCF_ERR_GENERIC fi fi if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then # Do not refetch the master status as we know it already if [ $rc -eq $OCF_RUNNING_MASTER ]; then local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -n ""$master_name"" ]; then ocf_log info ""${LH} master exists and rabbit app is not running. Exiting to be restarted by pacemaker"" stop_server_process rc=$OCF_ERR_GENERIC fi fi if [ $rc -eq $OCF_ERR_GENERIC ]; then elif [ $rc -ne $OCF_RUNNING_MASTER ] ; then if [ -z ""${node_start_time}"" -o ""${node_start_time}"" = ""(null)"" ] ; then [ $rc_alive -eq 137 -o $rc_alive -eq 124 ] && ocf_log err ""${LH} 'rabbitmqctl list_channels' timed out, per-node explanation: $(enhanced_list_channels)"" master_score 0 master_score 0 if [ ""${name}"" = ""${RABBITMQ_NODENAME}"" ] ; then master_score 0 local q_c q_c=`printf ""%b\n"" ""${queues}"" | wc -l` local mem mem=`printf ""%b\n"" ""${queues}"" | awk -v sum=0 '{sum+=$1} END {print (sum/1048576)}'` local mes mes=`printf ""%b\n"" ""${queues}"" | awk -v sum=0 '{sum+=$2} END {print sum}'` local c_u c_u=`printf ""%b\n"" ""${queues}"" | awk -v sum=0 -v cnt=${q_c} '{sum+=$3} END {print (sum+1)/(cnt+1)}'` local status status=`echo $(su_rabbit_cmd ""${OCF_RESKEY_ctl} -q status"")` if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} Deleting start time attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete ocf_log info ""${LH} RMQ going to start."" start_rmq_server_app rc=$? if [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} RMQ prepared for start succesfully."" fi if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete ocf_log info ""${LH} Deleting start time attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) # Fail early without additional rabbitmqctl invocations if [ $? -ne $OCF_SUCCESS ] ; then ocf_log err ""RMQ-runtime (beam) couldn't be stopped and will likely became unmanaged. Take care of it manually!"" ocf_log info ""${LH} action end."" exit $OCF_ERR_GENERIC # Ensure the actual status to be returned get_status if [ $? -eq $OCF_NOT_RUNNING ] ; then ocf_log info ""${LH} RMQ-runtime (beam) not running."" ocf_log info ""${LH} action end."" return $OCF_SUCCESS else ocf_log err ""RMQ-runtime (beam) couldn't be stopped and will likely became unmanaged. Take care of it manually!"" ocf_log info ""${LH} action end."" exit $OCF_ERR_GENERIC fi } ####################################################################### # Enhanced list_channels: # - nodes are processed in parallel # - report contains information about which nodes timed out # # 'list_channels' is used as a healh-check for current node, but it # actually checks overall health of all node in cluster. And there were # some bugs where only one (non-local) channel became stuck, but OCF # script was wrongfully killing local node. # # Hopefully all such bugs are fixed, but if not - it will allow to # detect such conditions. # # Somewhat strange implementation is due to the following reasons: # - ability to support older versions of RabbitMQ which have reached # end-of-life with single version of the script # - zero dependencies - for older versions this functionality could be # implemented as a plugin, but it'll require this plugin installation enhanced_list_channels() { # One second less than timeout of su_rabbit_cmd local timeout=$((${TIMEOUT_ARG:-5} - 1)) su_rabbit_cmd ""xargs -0 ${OCF_RESKEY_ctl} eval"" <<EOF SecondsToCompletion = $timeout, %% Milliseconds since unix epoch Now = fun() -> {Mega, Secs, Micro} = os:timestamp(), Mili = Micro div 1000, Mili + 1000 * (Secs + 1000000 * Mega) end, %% We shouldn't continue execution past this time ShouldEndAt = Now() + SecondsToCompletion * 1000, %% How many milliseconds we still have Timeout = fun() -> case ShouldEndAt - Now() of Past when Past =< 0 -> 0; Timeout -> Timeout end end, %% Lambda combinator - for defining anonymous recursive functions Y = fun(F) -> (fun (X) -> F(fun(Y) -> (X(X))(Y) end) end)( fun (X) -> F(fun(Y) -> (X(X))(Y) end) end) end, Parent = self(), ListChannels = Y(fun(Rec) -> fun (({Node, [], OkChannelsCount})) -> Parent ! {Node, ok, OkChannelsCount}; ({Node, [Chan|Rest], OkChannelsCount}) -> case catch rpc:call(Node, rabbit_channel, info, [Chan], Timeout()) of Infos when is_list(Infos) -> Rec({Node, Rest, OkChannelsCount + 1}); {badrpc, {'EXIT', {noproc, _}}} -> %% Channel became dead before we could request it's status, don't care Rec({Node, Rest, OkChannelsCount}); Err -> Parent ! {Node, Err, OkChannelsCount} end end end), SingleNodeListing = fun(Node) -> case catch rpc:call(Node, pg_local, get_members, [rabbit_channels], Timeout()) of LocalChannels when is_list(LocalChannels) -> ListChannels({Node, LocalChannels, 0}); Err -> Parent ! {Node, Err, 0} end end, AllNodes = rabbit_mnesia:cluster_nodes(running), [ spawn(fun() -> SingleNodeListing(Node) end) || Node <- AllNodes ], WaitForNodes = Y(fun(Rec) -> fun ({[], Acc}) -> Acc; ({RemainingNodes, Acc}) -> receive {Node, _Status, _ChannelCount} = Smth -> RemainingNodes1 = lists:delete(Node, RemainingNodes), Rec({RemainingNodes1, [Smth|Acc]}) after Timeout() + 100 -> Acc end end end), Result = WaitForNodes({AllNodes, []}), ExpandedResult = [ case lists:keysearch(Node, 1, Result) of {value, NodeResult} -> NodeResult; false -> {Node, no_data_collected, 0} end || Node <- AllNodes ], ExpandedResult. EOF if [ $rc -ne 0 -a ""${join_to}"" ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then local nowtime if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ ""${OCF_RESKEY_CRM_meta_notify_type}"" = 'pre' ] ; then # PRE- anything notify section case ""$OCF_RESKEY_CRM_meta_notify_operation"" in promote) if [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} Deleting master attribute for node ${i}"" ocf_run crm_attribute -N $i -l reboot --name 'rabbit-master' --delete esac if [ ""${OCF_RESKEY_CRM_meta_notify_type}"" = 'post' ] ; then rc=$OCF_SUCCESS ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" elif my_host ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} ignoring post-promote of self"" elif is_clustered_with ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} we are already clustered with master - ${OCF_RESKEY_CRM_meta_notify_promote_uname}. Nothing to do."" else # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ""${OCF_RESKEY_CRM_meta_notify_promote_uname}"" rc=$? if [ $rc -eq $OCF_ERR_GENERIC ] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" fi return $rc if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc_join -eq $OCF_SUCCESS ]; then jjj_join ""${OCF_RESKEY_CRM_meta_notify_master_uname}"" nowtime=""$(now)"" ocf_log info ""${LH} Updating start time attribute with ${nowtime}"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update ""${nowtime}"" if [ -s ""${OCF_RESKEY_definitions_dump_file}"" ] ; then ocf_run curl --silent --show-error --request POST --user $OCF_RESKEY_admin_user:$OCF_RESKEY_admin_password $OCF_RESKEY_host_ip:15672/api/definitions --header ""Content-Type:application/json"" --data @$OCF_RESKEY_definitions_dump_file if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc2 -eq $OCF_ERR_GENERIC ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) # On other nodes processing the post-stop, make sure the stopped node will be forgotten if [ $rc -ne $OCF_SUCCESS ] ; then # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) ocf_log info ""${LH} Deleting start time attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete if [ $rc2 -ne $OCF_SUCCESS ] ; then local nowtime if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then if [ $rc -eq 0 ] ; then if [ $rc -ne 0 ] ; then [ -f ""${OCF_RESKEY_policy_file}"" ] && . ""${OCF_RESKEY_policy_file}"" nowtime=""$(now)"" ocf_log info ""${LH} Updating start timestamp with ${nowtime}"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update ""${nowtime}"" if [ $rc = $OCF_RUNNING_MASTER ] if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete ocf_log info ""${LH} Deleting start timestamp"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) ","#!/bin/bashOCF_RESKEY_pid_file_default=/var/run/rabbitmq/p_pid OCF_RESKEY_log_dir_default=/var/log/rabbitmq OCF_RESKEY_mnesia_base_default=/var/lib/rabbitmq/mnesiaOCF_RESKEY_max_rabbitmqctl_timeouts_default=1 local cmd=${1:-status} ${COMMAND_TIMEOUT} ${cmd}"" if [[ -z $score ]] ; then local hostname=$(hostname -s) hn=$(echo ""$host"" | awk -F. '{print $1}') if [[ ""X${hostname}"" == ""X${hn}"" ]] ; then if [ -z ""${stime}"" -o x""${stime}"" == x""(null)"" ] ; then H=`hostname -s` export RABBITMQ_NODENAME=""rabbit@${H}"" MNESIA_FILES=""${OCF_RESKEY_mnesia_base}/rabbit@${H}"" local files=$(su -s /bin/sh - $OCF_RESKEY_username -c ""find ${dir} ! -writable"") if [ ! -z ""${files}"" ]; then export LL=""${OCF_RESOURCE_INSTANCE}:""rabbit_node_name() { echo ""rabbit@""$(echo ""$1"" | awk -F. '{print $1}') } if [[ $rc == 0 ]] ; then if [[ $rc == 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then ocf_run rm -rf ${MNESIA_FILES}* ocf_log warn ""${LH} Beam have been killed. Mnesia files appear corrupted and have been removed."" until $(iptables -nvL | grep -q 'temporary RMQ block') || [[ $tries -eq 0 ]]; do ((tries--)) if [ ""$1"" == 'nodes' ] elif [ ""$1"" == 'running' ] local c_status c_status=$(${OCF_RESKEY_ctl} eval ""mnesia:system_info(${infotype})."" 2>/dev/null) if [[ $rc != 0 ]] ; then echo $(echo ""${c_status}"" | grep ""${cl}"" | awk -F, '{ for (i=1;i<=NF;i++) { if ($i ~ /@/) { gsub(/[\[\]}{]/,"""",$i); print $i; } }}' | tr -d ""\'"") return $? if [ -z $1 ]; thencheck_need_join_to() { local join_to=$(rabbit_node_name $1) local running_nodes=$(get_running_nodes) if [[ ${join_to} == ${node} ]] ; thenkill_rmq_and_remove_pid() { local pid if [[ -f $OCF_RESKEY_pid_file ]] ; then pid=$(cat $OCF_RESKEY_pid_file) if [[ -z ${pid} ]] ; then ocf_log err ""${LH} pidfile is empty, cannot kill by unknown PID! Try to stop it manually!"" fi # todo: check content for digital if [[ -d /proc/${pid}/ ]] ; then ocf_run kill -9 $pid ocf_log warn ""${LH} RMQ-runtime (beam) PID=${pid} stopped by 'kill -9', sorry..."" fi ocf_run rm -f $OCF_RESKEY_pid_file local rmq_node=$(rabbit_node_name $node) ocf_log info ""${LH} Joining to cluster by node '${rmq_node}'."" if [[ $rc == $OCF_SUCCESS ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then ocf_log info ""${LH} Rabbit app started successfully. Updating start time attribute with $(now)"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update $(now) if [[ $rc != 0 ]] ; then if [[ ""$nodename"" == ""$RABBITMQ_NODENAME"" ]] ; then if [[ ""$nodename"" == ""$rnode"" ]] ; then if [[ $rc == $OCF_SUCCESS ]] ; then ((tries++)) if get_running_nodes | grep -q $(rabbit_node_name $nodename) then if [[ $rc == 0 ]] ; then# Stop RMQ server process. Returns OCS_SUCCESS if [[ $rc != 0 ]] ; then ocf_log err ""${LH} RMQ-server process PIDFILE was not found!"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" rc=$? if [[ $rc == 0 ]] ; then ocf_log info ""${LH} RMQ-server process stopped succesfully, although there was no PIDFILE found."" return $OCF_SUCCESS else ocf_log err ""${LH} Cannot stop RMQ-server process, and cannot kill it by unknown PID! Try to stop it manually!"" return $OCF_ERR_GENERIC fi if [[ -z ${pid} ]] ; then ocf_log info ""${LH} Execute stop with timeout: ${TIMEOUT_ARG}"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop ${OCF_RESKEY_pid_file} 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" rc=$? if [[ $rc == 0 ]] ; then ocf_log info ""${LH} RMQ-server process (PID=${pid}) stopped succesfully."" fi kill_rmq_and_remove_pid return $OCF_SUCCESS if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ -f $OCF_RESKEY_pid_file ]] ; then if [[ -d /proc/${pid} && ! -z ${pid} ]] ; then if [[ $rc == $OCF_SUCCESS ]] ; then ocf_run kill -9 $pid ocf_run rm -rf $OCF_RESKEY_pid_file local command=""${OCF_RESKEY_binary} >> \""${OCF_RESKEY_log_dir}/startup_log\"" 2>/dev/null"" if [[ -f $OCF_RESKEY_pid_file ]] ; then if [[ $pid != 0 && -d /proc/${pid} ]] ; then if [[ $rc != $OCF_SUCCESS ]]; then if [[ ""${pid}"" == ""0"" ]] ; then if [[ $? == 0 ]] ; then local LIST=`${OCF_RESKEY_ctl} eval 'rabbit_plugins:active().'` echo ""${LIST}"" if [[ $rc != $OCF_SUCCESS ]] ; then if [[ $rc != $OCF_SUCCESS ]]; then if [[ -z $startup_log ]] ; then if [[ $rc == 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $mrc == 0 ]] ; then local MLIST=`list_active_plugins` ocf_log info ""${LH} Starting plugins: $MLIST"" if [[ $rc == $OCF_SUCCESS ]]; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ $rc != $OCF_SUCCESS ]]; then if [[ $rc == $OCF_SUCCESS ]] ; then if [[ $rc != 0 ]] ; then for ((a=10; a > 0 ; a--)) ; do if [[ $rc == $OCF_SUCCESS ]]; then if [[ $rc == $OCF_SUCCESS ]]; then if [[ $rc == $OCF_ERR_GENERIC ]] ; then local rc=$OCF_ERR_GENERIC if [[ $rc != 0 ]] ; then ocf_log info ""get_status() failed with code ${rc}. Command output: ${body}"" if [[ ! -z $what ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then ocf_log info ""get_status(): app ${what} was not found in command output: ${body}"" if [[ ""${result}"" != ""true"" ]] ; then count=`crm_attribute -N $THIS_PCMK_NODE -l reboot --name $crm_attr_name --query 2>/dev/null | awk '{print $3}' | awk -F ""="" '{print $2}' | sed -e '/(null)/d'` local scope local status_master local prev_rc if [[ $rc == $OCF_NOT_RUNNING ]] ; then elif [[ $rc == $OCF_SUCCESS ]] ; then if [ $rabbit_running == $OCF_SUCCESS ] ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" prev_rc=$rc nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do ocf_log info ""${LH} rabbit app is running. looking for master on $node"" is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is running. master is $node"" if get_running_nodes | grep -q $(rabbit_node_name $node) then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" rc=$prev_rc break fi fi done [ $rc -eq $OCF_ERR_GENERIC ] && ocf_log err ""${LH} rabbit node is running out of the cluster"" if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then prev_rc=$rc is_master $THIS_PCMK_NODE i_am_master=$? if [ $i_am_master -eq 0 ]; then nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is not running. master is $node. exiting to be restarted by pacemaker"" fi done fi if [[ $rc == $OCF_ERR_GENERIC ]]; then else if [ -z ""${node_start_time}"" -o x""${node_start_time}"" == x""(null)"" ] ; then if [[ ""${name}"" == ""${RABBITMQ_NODENAME}"" ]] ; then local q_c=`echo -e ""${queues}"" | wc -l` local mem=`echo -e ""${queues}"" | awk -v sum=0 '{sum+=$1} END {print (sum/1048576)}'` local mes=`echo -e ""${queues}"" | awk -v sum=0 '{sum+=$2} END {print sum}'` local c_u=`echo -e ""${queues}"" | awk -v sum=0 -v cnt=${q_c} '{sum+=$3} END {print (sum+1)/(cnt+1)}'` local status=`echo $(su_rabbit_cmd ""${OCF_RESKEY_ctl} -q status"")` if [[ ""${OCF_RESKEY_debug}"" == ""true"" ]] ; then local msg local master_node if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then if [[ $rc == $OCF_SUCCESS ]] ; then ocf_log info ""${LH} RMQ going to start."" start_rmq_server_app rc=$? if [[ $rc == $OCF_SUCCESS ]] ; then ocf_log info ""${LH} RMQ prepared for start succesfully."" fi if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then # remove master flag # remove master score crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete # remove file with rmq-server start timestamp #todo: make this timeout corresponded to the stop timeout for resource sleep 10 ocf_log info ""${LH} action end."" get_status rc=$? if [[ $rc == $OCF_NOT_RUNNING ]] ; then ocf_log info ""${LH} RMQ-runtime (beam) not running."" return $OCF_SUCCESS else return $OCF_ERR_GENERIC if [[ $rc != 0 && $join_to != '' ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then if [[ ${OCF_RESKEY_CRM_meta_notify_type} == 'pre' ]] ; then # PRE- anything notify section case ""$OCF_RESKEY_CRM_meta_notify_operation"" in promote) if [[ $rc == $OCF_SUCCESS ]] ; then crm_attribute -N $i -l reboot --name 'rabbit-master' --delete esac if [[ ${OCF_RESKEY_CRM_meta_notify_type} == 'post' ]] ; then ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" ocf_log info ""${LH} post-promote end."" return $OCF_SUCCESS # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ${OCF_RESKEY_CRM_meta_notify_promote_uname} rc=$? if [[ $rc == $OCF_ERR_GENERIC ]] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" return $OCF_ERR_GENERIC fi if [[ $rc == $OCF_SUCCESS ]] ; then if [[ ${rc_join} == $OCF_SUCCESS ]]; then jjj_join ${OCF_RESKEY_CRM_meta_notify_master_uname} if [[ -s ${OCF_RESKEY_definitions_dump_file} ]] ; then ocf_run curl -X POST -u $OCF_RESKEY_admin_user:$OCF_RESKEY_admin_password 127.0.0.1:15672/api/definitions --header ""Content-Type:application/json"" -d @$OCF_RESKEY_definitions_dump_file if [[ $rc == $OCF_SUCCESS ]] ; then if [[ $rc2 == $OCF_ERR_GENERIC ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then # On ohter nodes processing the post-stop, make sure the stopped node will be forgotten if [[ $rc != $OCF_SUCCESS ]] ; then crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete if [[ $rc2 != $OCF_SUCCESS ]] ; then if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ $rc == 0 ]] ; then if [[ $rc != 0 ]] ; then ocf_log info ""${LH} Setting HA policy for all queues"" rabbitmqctl set_policy ha-all ""."" '{""ha-mode"":""all"", ""ha-sync-mode"":""automatic""}' --apply-to all --priority 0 rabbitmqctl set_policy heat_rpc_expire ""^heat-engine-listener\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 rabbitmqctl set_policy results_expire ""^results\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 rabbitmqctl set_policy tasks_expire ""^tasks\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 ocf_log info ""${LH} Updating start timestamp"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update $(now) if [ $rc == $OCF_RUNNING_MASTER ] if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete",751,269
openstack%2Fpython-openstackclient~master~I2963991dfafbb17431b44e2f37bb26fa4daac9aa,openstack/python-openstackclient,master,I2963991dfafbb17431b44e2f37bb26fa4daac9aa,Fix functional test for floatingip add/remove in ComputeV2,MERGED,2016-05-11 03:45:43.000000000,2016-05-11 09:04:20.000000000,2016-05-11 09:04:20.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-05-11 03:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/382e4eabeee5fa953a974d142decb660c18695b8', 'message': 'Fix functional test for floatingip add/remove in ComputeV2\n\nUpdata test_server_attach_detach_floating_ip in test_server.py\n\nChange-Id: I2963991dfafbb17431b44e2f37bb26fa4daac9aa\n'}, {'number': 2, 'created': '2016-05-11 07:09:38.000000000', 'files': ['functional/tests/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0e0f314e2ed05c269be1d204131216dfbfd5df4e', 'message': 'Fix functional test for floatingip add/remove in ComputeV2\n\nUpdata test_server_attach_detach_floating_ip in test_server.py\n\nChange-Id: I2963991dfafbb17431b44e2f37bb26fa4daac9aa\n'}]",0,314852,0e0f314e2ed05c269be1d204131216dfbfd5df4e,10,2,2,21514,,,0,"Fix functional test for floatingip add/remove in ComputeV2

Updata test_server_attach_detach_floating_ip in test_server.py

Change-Id: I2963991dfafbb17431b44e2f37bb26fa4daac9aa
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/52/314852/2 && git format-patch -1 --stdout FETCH_HEAD,['functional/tests/compute/v2/test_server.py'],1,382e4eabeee5fa953a974d142decb660c18695b8,functest-floatingip-add/remove," opts = self.get_show_opts([""id"", ""floating_ip_address""]) raw_output = self.openstack('ip floating create ' + ip, ipid, rol = tuple(raw_output.split('\n'))"," @testtools.skip('this test needs to be re-worked completely') opts = self.get_show_opts([""id"", ""ip""]) raw_output = self.openstack('ip floating create ' '--debug ' + ipid, ip, rol = tuple(raw_output.split('\n'))",3,5
openstack%2Fnova~master~Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5,openstack/nova,master,Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5,api-ref: complete verification for diagnostics.inc,MERGED,2016-05-09 12:52:53.000000000,2016-05-11 09:01:32.000000000,2016-05-10 15:37:46.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 17130}, {'_account_id': 19590}, {'_account_id': 19896}]","[{'number': 1, 'created': '2016-05-09 12:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7fdb89fdc3e10c75f5b72ee58e1ec3267f0eb51', 'message': ""api-ref: complete verification for diagnostics.inc\n\nThis completes the verification for the diagnostics API. As the\nresponse is still dumping out raw hypervisor stats (for compatibility\nhttps://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)\nthe best we can say about the response is it's hypervisor specific and\ndon't use it.\n\nIn future we should use the standardized format that was defined\nduring the v3 effort.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5\n""}, {'number': 2, 'created': '2016-05-09 16:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42f8faca18e74040f74e38fb60dc772aed649f26', 'message': ""api-ref: complete verification for diagnostics.inc\n\nThis completes the verification for the diagnostics API. As the\nresponse is still dumping out raw hypervisor stats (for compatibility\nhttps://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)\nthe best we can say about the response is it's hypervisor specific and\ndon't use it.\n\nIn future we should use the standardized format that was defined\nduring the v3 effort.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5\n""}, {'number': 3, 'created': '2016-05-09 18:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3982b7af6134d0a9b6ef336a8fa614807a7eedf', 'message': ""api-ref: complete verification for diagnostics.inc\n\nThis completes the verification for the diagnostics API. As the\nresponse is still dumping out raw hypervisor stats (for compatibility\nhttps://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)\nthe best we can say about the response is it's hypervisor specific and\ndon't use it.\n\nIn future we should use the standardized format that was defined\nduring the v3 effort.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5\n""}, {'number': 4, 'created': '2016-05-09 19:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f277a9ee09a04a488b551f75936c60dea96e562e', 'message': ""api-ref: complete verification for diagnostics.inc\n\nThis completes the verification for the diagnostics API. As the\nresponse is still dumping out raw hypervisor stats (for compatibility\nhttps://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)\nthe best we can say about the response is it's hypervisor specific and\ndon't use it.\n\nIn future we should use the standardized format that was defined\nduring the v3 effort.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5\n""}, {'number': 5, 'created': '2016-05-09 19:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0a243e6b0861a41e8e300581888db6d7ea8b939', 'message': ""api-ref: complete verification for diagnostics.inc\n\nThis completes the verification for the diagnostics API. As the\nresponse is still dumping out raw hypervisor stats (for compatibility\nhttps://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)\nthe best we can say about the response is it's hypervisor specific and\ndon't use it.\n\nIn future we should use the standardized format that was defined\nduring the v3 effort.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5\n""}, {'number': 6, 'created': '2016-05-09 20:25:32.000000000', 'files': ['api-ref/source/diagnostics.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f4e803634fc3136aae78c178fbbec8682fe19c0', 'message': ""api-ref: complete verification for diagnostics.inc\n\nThis completes the verification for the diagnostics API. As the\nresponse is still dumping out raw hypervisor stats (for compatibility\nhttps://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)\nthe best we can say about the response is it's hypervisor specific and\ndon't use it.\n\nIn future we should use the standardized format that was defined\nduring the v3 effort.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5\n""}]",1,314085,8f4e803634fc3136aae78c178fbbec8682fe19c0,43,14,6,2750,,,0,"api-ref: complete verification for diagnostics.inc

This completes the verification for the diagnostics API. As the
response is still dumping out raw hypervisor stats (for compatibility
https://github.com/openstack/nova/blob/7529b94f4a0be17fb3988362619f83b404ccad86/nova/api/openstack/compute/server_diagnostics.py#L38-L44)
the best we can say about the response is it's hypervisor specific and
don't use it.

In future we should use the standardized format that was defined
during the v3 effort.

Part of bp:api-ref-in-rst

Change-Id: Id2cca6a2f79542bec17a34aa3d31924e8ed7b9e5
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/314085/4 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/diagnostics.inc'],1,a7fdb89fdc3e10c75f5b72ee58e1ec3267f0eb51,bp/api-ref-in-rst,"Policy defaults enable only users with the administrative role. Cloud providers can change these permissions through the ``policy.json`` file.The response format for diagnostics is backend hypervisor specific, and not well defined. This should be considered a debug interface only, and not relied upon by programmatic tools. **Example Server diagnostics** Below is an example of diagnostics for a libvirt based server instance.",.. needs:parameter_verification .. needs:example_verification .. needs:body_verificationPolicy defaults enable only users with the administrative role. Cloud providers can change these permissions through the ``policy.json`` file.**Example Server diagnostics: JSON response**,10,6
openstack%2Fapi-site~master~Id8c33f8f8fc408ff1e09fc8ef25c108fcc380146,openstack/api-site,master,Id8c33f8f8fc408ff1e09fc8ef25c108fcc380146,[api-ref] Added the request parameter maintenance for node.update.,ABANDONED,2016-04-25 05:53:28.000000000,2016-05-11 09:01:21.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 17207}]","[{'number': 1, 'created': '2016-04-25 05:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/86f627c92176c42cd4742a5d6a2de9a28af83a55', 'message': '[api-ref] Added the request parameter maintenance for node.update.\n\nChange-Id: Id8c33f8f8fc408ff1e09fc8ef25c108fcc380146\nCloses-Bug: #1386878\n'}, {'number': 2, 'created': '2016-04-25 10:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/4ba977f282eb3ede21276f9e9b244d6b7da9513a', 'message': '[api-ref] Added the request parameter maintenance for node.update.\n\nChange-Id: Id8c33f8f8fc408ff1e09fc8ef25c108fcc380146\nCloses-Bug: #1386878\n'}, {'number': 3, 'created': '2016-04-25 11:37:24.000000000', 'files': ['api-ref/src/wadls/baremetal-api/src/v1/common.ent', 'api-ref/src/wadls/baremetal-api/src/v1/baremetal-api-v1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/0215dd5c0c578ca2ae2a5da94689ebe4e0ff4f0a', 'message': '[api-ref] Added the request parameter maintenance for node.update.\n\nChange-Id: Id8c33f8f8fc408ff1e09fc8ef25c108fcc380146\nCloses-Bug: #1386878\n'}]",1,309863,0215dd5c0c578ca2ae2a5da94689ebe4e0ff4f0a,11,3,3,20863,,,0,"[api-ref] Added the request parameter maintenance for node.update.

Change-Id: Id8c33f8f8fc408ff1e09fc8ef25c108fcc380146
Closes-Bug: #1386878
",git fetch https://review.opendev.org/openstack/api-site refs/changes/63/309863/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/baremetal-api/src/v1/baremetal-api-v1.wadl'],1,86f627c92176c42cd4742a5d6a2de9a28af83a55,bug/1386878," <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""maintenance"" style=""plain"" type=""xsd:boolean"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para> Clears the maintenance_reason when set to (<code>false</code>). Default is <code>true</code>. </para> </wadl:doc> </param>",,10,0
openstack%2Fopenstack-manuals~master~Iab67db44287abd07819549eb7045c32333b3bc6e,openstack/openstack-manuals,master,Iab67db44287abd07819549eb7045c32333b3bc6e,[cli-ref] Add extensions for files in index,MERGED,2016-05-11 04:21:28.000000000,2016-05-11 08:59:47.000000000,2016-05-11 08:59:47.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14962}]","[{'number': 1, 'created': '2016-05-11 04:21:28.000000000', 'files': ['doc/cli-reference/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7bf212da84d71e90d93e0504391db4c830db4600', 'message': '[cli-ref] Add extensions for files in index\n\nTo sync with all other guides\n\nChange-Id: Iab67db44287abd07819549eb7045c32333b3bc6e\n'}]",0,314857,7bf212da84d71e90d93e0504391db4c830db4600,7,3,1,16237,,,0,"[cli-ref] Add extensions for files in index

To sync with all other guides

Change-Id: Iab67db44287abd07819549eb7045c32333b3bc6e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/57/314857/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/index.rst'],1,7bf212da84d71e90d93e0504391db4c830db4600,newton, common/conventions.rst overview.rst openstack.rst murano.rst ironic.rst cinder.rst senlin.rst nova.rst magnum.rst sahara.rst trove.rst trove-misc.rst designate.rst glance.rst barbican.rst monasca.rst neutron.rst neutron-misc.rst swift.rst heat.rst cloudkitty.rst manila.rst ceilometer.rst gnocchi.rst mistral.rst common/app_support.rst common/glossary.rst, common/conventions overview openstack murano ironic cinder senlin nova magnum sahara trove trove-misc designate glance barbican monasca neutron neutron-misc swift heat cloudkitty manila ceilometer gnocchi mistral common/app_support common/glossary,27,27
openstack%2Ftripleo-ci~master~I719973e350aec432a3a2ad1413ea873b1edf95e5,openstack/tripleo-ci,master,I719973e350aec432a3a2ad1413ea873b1edf95e5,Add planet blog aggregator feeds to website,MERGED,2016-05-03 01:33:05.000000000,2016-05-11 08:54:49.000000000,2016-05-11 08:54:49.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-05-03 01:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bbf490357795df5dd755d4ff4bf2a6568148a34b', 'message': 'Add planet blog aggregator feeds to website\n\nGenerate a new section of the website to aggregate Blog posts\nabout TripleO.\n\nChange-Id: I719973e350aec432a3a2ad1413ea873b1edf95e5\n'}, {'number': 2, 'created': '2016-05-03 13:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0e5607c028cb8c12223a5c122f348962da62c0d6', 'message': 'Add planet blog aggregator feeds to website\n\nGenerate a new section of the website to aggregate Blog posts\nabout TripleO.\n\nChange-Id: I719973e350aec432a3a2ad1413ea873b1edf95e5\n'}, {'number': 3, 'created': '2016-05-03 13:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bb2298a489925acf510ba508f9258da77b8e87cf', 'message': 'Add planet blog aggregator feeds to website\n\nGenerate a new section of the website to aggregate Blog posts\nabout TripleO.\n\nChange-Id: I719973e350aec432a3a2ad1413ea873b1edf95e5\n'}, {'number': 4, 'created': '2016-05-03 14:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0e338fd8aaeb6308e48c997b19b89a127b7d6091', 'message': 'Add planet blog aggregator feeds to website\n\nGenerate a new section of the website to aggregate Blog posts\nabout TripleO.\n\nChange-Id: I719973e350aec432a3a2ad1413ea873b1edf95e5\n'}, {'number': 5, 'created': '2016-05-09 20:00:16.000000000', 'files': ['.gitignore', 'scripts/website/planet.html.tmpl', 'scripts/website/planet.config.ini', 'scripts/website/generate_site.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3f8d9f19a4c544e6cf25a4b5fe05dd1578613ac1', 'message': 'Add planet blog aggregator feeds to website\n\nGenerate a new section of the website to aggregate Blog posts\nabout TripleO.\n\nChange-Id: I719973e350aec432a3a2ad1413ea873b1edf95e5\n'}]",10,311910,3f8d9f19a4c544e6cf25a4b5fe05dd1578613ac1,29,7,5,360,,,0,"Add planet blog aggregator feeds to website

Generate a new section of the website to aggregate Blog posts
about TripleO.

Change-Id: I719973e350aec432a3a2ad1413ea873b1edf95e5
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/10/311910/5 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'scripts/website/planet.html.tmpl', 'scripts/website/planet.config.ini', 'scripts/website/generate_site.sh']",4,bbf490357795df5dd755d4ff4bf2a6568148a34b,planet,"SKIP_BLOG=${SKIP_BLOG:-''}#Planet (Blog Feed Aggregator) if [ ! -d planet ]; then wget http://www.planetplanet.org/download/planet-2.0.tar.bz2 tar xvf planet-2.0.tar.bz2 rm planet-2.0.tar.bz2 fi # Blog Feeds if [ -z ""$SKIP_BLOG"" ]; then python planet-2.0/planet.py planet.config.ini DATA=$(cat planet-2.0/output/planet.html) OUT_FILE=$SCRIPT_DIR/tripleo-docs/doc/build/html/blogs.html TEMPLATE_FILE=$SCRIPT_DIR/tripleosphinx/doc/build/html/blank.html sed -n '1,/.*Custom Content Here/p' $TEMPLATE_FILE > $OUT_FILE #first half echo ""<h1>TripleO Blogs</h1>"" >> $OUT_FILE sed -e ""s|<title>.*|<title>TripleO: Blogs</title><meta name='description' content='OpenStack Deployment Program Blog posts'/>|"" -i $OUT_FILE # custom title echo $DATA >> $OUT_FILE sed -n '/.*Custom Content Here/,$p' $TEMPLATE_FILE >> $OUT_FILE #second half fi ",,156,0
openstack%2Fnova-specs~master~I4ebf732d7911685c868de9aa92318e12dd5ccf4b,openstack/nova-specs,master,I4ebf732d7911685c868de9aa92318e12dd5ccf4b,Add detail to libvirt-storage-pools,ABANDONED,2015-11-23 13:40:38.000000000,2016-05-11 08:52:02.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5754}, {'_account_id': 6608}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9555}, {'_account_id': 10135}, {'_account_id': 11189}, {'_account_id': 12299}, {'_account_id': 14131}]","[{'number': 1, 'created': '2015-11-23 13:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/453b8e9454438ca39cfcc4e04f6910159e63b998', 'message': ""Add detail to libvirt-storage-pools\n\nThe libvirt-storage-pools spec describes a change to the api used to\ntransfer data. It mentions that a change is required to create libvirt\nstorage volumes during the migration process, but doesn't describe how\nthis will be achieved.\n\nRespecting the storage pool configuration of the destination requires\ndata flow which is not current present. To avoid using another\nheuristic, we propose adding a new hook in the driver api which allows\nthe destination to define where it wants the data to go. This has the\nadded benefits of:\n\n1. Removing the current heuristics around detecting shared storage.\n2. Removing the requirement for SSH between compute hosts to detect\n   shared storage, which is the principal goal of this spec.\n\nChange-Id: I4ebf732d7911685c868de9aa92318e12dd5ccf4b\n""}, {'number': 2, 'created': '2015-11-23 14:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e941ed1f26cfb50121239be27e2293501680ef13', 'message': ""Add detail to libvirt-storage-pools\n\nThe libvirt-storage-pools spec describes a change to the api used to\ntransfer data. It mentions that a change is required to create libvirt\nstorage volumes during the migration process, but doesn't describe how\nthis will be achieved.\n\nRespecting the storage pool configuration of the destination requires\ndata flow which is not current present. To avoid using another\nheuristic, we propose adding a new hook in the driver api which allows\nthe destination to define where it wants the data to go. This has the\nadded benefits of:\n\n1. Removing the current heuristics around detecting shared storage.\n2. Removing the requirement for SSH between compute hosts to detect\n   shared storage, which is the principal goal of this spec.\n\nChange-Id: I4ebf732d7911685c868de9aa92318e12dd5ccf4b\n""}, {'number': 3, 'created': '2015-11-24 09:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/15f60cd3bcb2acb654aaaa3abf5599bbbad32b84', 'message': ""Add detail to libvirt-storage-pools\n\nThe libvirt-storage-pools spec describes a change to the api used to\ntransfer data. It mentions that a change is required to create libvirt\nstorage volumes during the migration process, but doesn't describe how\nthis will be achieved.\n\nRespecting the storage pool configuration of the destination requires\ndata flow which is not current present. To avoid using another\nheuristic, we propose adding a new hook in the driver api which allows\nthe destination to define where it wants the data to go. This has the\nadded benefits of:\n\n1. Removing the current heuristics around detecting shared storage.\n2. Removing the requirement for SSH between compute hosts to detect\n   shared storage, which is the principal goal of this spec.\n\nChange-Id: I4ebf732d7911685c868de9aa92318e12dd5ccf4b\n""}, {'number': 4, 'created': '2015-11-25 14:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7955c5241bf83e19cb3198b842f5d10f8848e929', 'message': ""Add detail to libvirt-storage-pools\n\nThe libvirt-storage-pools spec describes a change to the api used to\ntransfer data. It mentions that a change is required to create libvirt\nstorage volumes during the migration process, but doesn't describe how\nthis will be achieved.\n\nRespecting the storage pool configuration of the destination requires\ndata flow which is not current present. To avoid using another\nheuristic, we propose adding a new hook in the driver api which allows\nthe destination to define where it wants the data to go. This has the\nadded benefits of:\n\n1. Removing the current heuristics around detecting shared storage.\n2. Removing the requirement for SSH between compute hosts to detect\n   shared storage, which is the principal goal of this spec.\n\nChange-Id: I4ebf732d7911685c868de9aa92318e12dd5ccf4b\n""}, {'number': 5, 'created': '2015-11-25 15:14:24.000000000', 'files': ['specs/mitaka/approved/migrate-libvirt-volumes.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/01fb4b3bdaa9587ec919d638e41f9118a2223088', 'message': ""Add detail to libvirt-storage-pools\n\nThe libvirt-storage-pools spec describes a change to the api used to\ntransfer data. It mentions that a change is required to create libvirt\nstorage volumes during the migration process, but doesn't describe how\nthis will be achieved.\n\nRespecting the storage pool configuration of the destination requires\ndata flow which is not current present. To avoid using another\nheuristic, we propose adding a new hook in the driver api which allows\nthe destination to define where it wants the data to go. This has the\nadded benefits of:\n\n1. Removing the current heuristics around detecting shared storage.\n2. Removing the requirement for SSH between compute hosts to detect\n   shared storage, which is the principal goal of this spec.\n\nChange-Id: I4ebf732d7911685c868de9aa92318e12dd5ccf4b\n""}]",9,248705,01fb4b3bdaa9587ec919d638e41f9118a2223088,17,12,5,9555,,,0,"Add detail to libvirt-storage-pools

The libvirt-storage-pools spec describes a change to the api used to
transfer data. It mentions that a change is required to create libvirt
storage volumes during the migration process, but doesn't describe how
this will be achieved.

Respecting the storage pool configuration of the destination requires
data flow which is not current present. To avoid using another
heuristic, we propose adding a new hook in the driver api which allows
the destination to define where it wants the data to go. This has the
added benefits of:

1. Removing the current heuristics around detecting shared storage.
2. Removing the requirement for SSH between compute hosts to detect
   shared storage, which is the principal goal of this spec.

Change-Id: I4ebf732d7911685c868de9aa92318e12dd5ccf4b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/05/248705/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/approved/migrate-libvirt-volumes.rst'],1,453b8e9454438ca39cfcc4e04f6910159e63b998,libvirt_volume_detail,"permissions between compute hosts, which is problematic for a number ofSSH access between compute hosts to perform cold migrations and resizes* From a security perspective, providing SSH access between compute hosts is sub-optimal. Giving compute hosts SSH access could allow a compromised host to compromise other hosts and potentially inflict harm on a cloud. secure a secure communication channel between source and target compute hosts. This could be the use of TLS for example. They must also generate a keypair for each compute host, and upload the public key to each of the other compute hosts.compute hosts while still supporting non-shared-storage resizes and coldThe proposed change is in 2 parts. We assume in this spec that the libvirt-storage-pools spec has been implemented, but that the existing code for cold storage migrations and resizes has been left in place. That is, it will continue to use scp or rsync over ssh, and it will continue to write data to a remote compute host in its legacy location. We assume that :code:`finish_migration` on a compute host which is using storage pools will anticipate this and update the instance to use its new layout before starting it. It will have to handle this in any case, as it may receive a migration from a legacy compute host. The necessary first part of this change is to enable the direct transfer of data to a destination libvirt storage pool. The source compute host needs to be aware that the destination uses storage pools. This solution must be able to co-exist with compute hosts which have not yet been upgraded. The control flow of a migration first calls :code:`prep_resize` on the destination, which then calls :code:`resize_instance` on the source, which then calls :code:`finish_resize` on the destination. We will add a new driver api, :code:`prep_resize`, which will be called by :code:`prep_resize` in compute manager. The default implementation will be to do nothing. The libvirt driver will do several things here: * Create all required volumes in storage pools. * Check for the instance image in its own cache. * If it doesn't have it, it will query glance for it, and immediately start downloading it asynchronously if it is still available. * If it isn't still available from glance, add it to the data required from the source host. * Check if the instance's disks are already available locally. If not, this means no shared storage. * Create a map of guest disks required for transfer and their storage pool destinations. The map will be added to a 'libvirt-storage-pool' key in the instance's system metadata. It will consist of the following data, json encoded: { 'host': the destination host 'images': { <image uuid>: <image destination pool> } 'disks': { <bdm id> : <destination pool> } } Note that there may be multiple images. An image will only be listed in 'images' if the source host must send a copy to the destination host from its image cache. If the destination already has it, or can get it from glance, it will not be listed. When the source host runs :code:`resize_instance` it will check system metadata for this data. If it doesn't exist, or if the destination host in the data doesn't match the actual destination host the data will be deleted and ignored. In this case, it will copy data using the legacy strategy. If the data is present and correct, it will copy all images in 'images' from its image cache to the specified storage pools on the destination. It will copy all disks from the instance with the given block device mapping ids to their specified destination storage pools. If, during :code:`resize_instance`, the source is transferring data to a target libvirt storage volume, we have the option to transfer data over the libvirt connection using the libvirt api :code:`virStorageVolUpload`. This addresses the problems with SSH highlighted in the problem description. Due to the issues mentioned below, this would only be used if the the user has enabled the :code:`[libvirt] vol_upload_migration` option. The intention is that this will eventually be the default.* Just setting up SSH keys between compute hosts: see the problem description steps, it still provides a window where the compute hosts are vulnerable.While this change does require two compute hosts' libvirt daemons to connect impact on source host utilization.daemon on each compute host to listen for remote libvirt connections (if live MatthewBooth1. Implement the new driver api. Update the migration flow to use the data provided by the new call. 2. Implement the option to upload data with :code:`virStorageVolUpload`.be used as an alternative to deploying SSH access between compute hosts, instead of having to provision SSH keys for the compute hosts, as well as","permissions between compute nodes, which is problematic for a number ofSSH access between compute nodes to perform cold migrations and resizes* From a security perspective, providing SSH access between compute nodes is sub-optimal. Giving compute nodes SSH access could allow a compromised node to compromise other nodes and potentially inflict harm on a cloud. a secure communication channel between source and target node. This could be the use of TLS for example. They must also generate a keypair for each compute node, and upload the public key to each of the other compute nodes.compute nodes while still supporting non-shared-storage resizes and coldThe functionality in this blueprint would only be used when the deployer is using the new libvirt storage pool image backend, and has enabled the :code:`[libvirt]vol_upload_migration` option. At migration time, a new volume would be created in the destination node's storage pool, and the methods virStorageVolDownload and virStorageVolUpload would be used to stream the contents of the disk between compute nodes (http://libvirt.org/html/libvirt-libvirt-storage.html#virStorageVolUpload). In order to ensure secure migrations, libvirt should be configured to use one of the various forms of authentication and encryption that it supports, such as Kerberos (via SASL -- http://libvirt.org/auth.html) or TLS client certificates (http://libvirt.org/remote.html#Remote_libvirtd_configuration). To enable migration of suspended instances virDomainSave() will be used to save instance memory instead of virDomainManagedSave(). This will enable control of the file location, so it could be created in a directory based storage pool. This will mean you can use the storage pool APIs to upload and download that data during cold migration of suspended instances * Just setting up SSH keys between compute nodes: see the problem description steps, it still provides a window where the compute nodes are vulnerable.While this change does require two compute nodes' libvirt daemons to connect impact on source node utilization.daemon on each compute node to listen for remote libvirt connections (if live None1. Implement the virStorageVolUpload/virStorageVolDownload code in the :code:`migrate_disk_and_power_off` method, as an alternative to the existing calls to :code:`libvirt_utils.copy_image`. 2. Follow Up: remove the instances of SSH that are used to set up and tear down the migration (e.g. for shared storage detection). These could easily be done in a manner similar to how live migration works (having pre_migrate_host and pre_migrate_dest methods, instead of SSHing).be used as an alternative to deploying SSH access between compute nodes, instead of having to provision SSH keys for the compute nodes, as well as",81,41
openstack%2Ffuel-ostf~stable%2Fmitaka~Ic6daf95fb7380a4c9355a5a1e5c6a1e45de46f89,openstack/fuel-ostf,stable/mitaka,Ic6daf95fb7380a4c9355a5a1e5c6a1e45de46f89,Skip 2 health checks if no computes w/o DPDK,MERGED,2016-05-10 09:12:08.000000000,2016-05-11 08:50:26.000000000,2016-05-11 08:28:51.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 12867}, {'_account_id': 19119}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-10 09:12:08.000000000', 'files': ['fuel_health/tests/smoke/test_nova_create_instance_with_connectivity.py', 'fuel_plugin/testing/tests/unit/test_support_utilities.py', 'fuel_plugin/ostf_adapter/mixins.py', 'fuel_health/tests/smoke/test_dpdk.py', 'fuel_plugin/testing/tests/base.py', 'fuel_health/tests/smoke/test_neutron_actions.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/3addfdd697dc2625c19c3070ebcb5adc135ca2d9', 'message': ""Skip 2 health checks if no computes w/o DPDK\n\nIf environment doesn't contain compute nodes\nwithout DPDK then it's impossible to run instance\nand access it over network using default flavor\nwhich doesn't use huge pages for RAM.\n\nChange-Id: Ic6daf95fb7380a4c9355a5a1e5c6a1e45de46f89\nCloses-bug: #1567447\n(cherry picked from commit 2bdaeafbb2c92fb85aa5b77e24128678fb96fff4)\n""}]",0,314469,3addfdd697dc2625c19c3070ebcb5adc135ca2d9,18,8,1,11081,,,0,"Skip 2 health checks if no computes w/o DPDK

If environment doesn't contain compute nodes
without DPDK then it's impossible to run instance
and access it over network using default flavor
which doesn't use huge pages for RAM.

Change-Id: Ic6daf95fb7380a4c9355a5a1e5c6a1e45de46f89
Closes-bug: #1567447
(cherry picked from commit 2bdaeafbb2c92fb85aa5b77e24128678fb96fff4)
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/69/314469/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/smoke/test_nova_create_instance_with_connectivity.py', 'fuel_plugin/testing/tests/unit/test_support_utilities.py', 'fuel_plugin/ostf_adapter/mixins.py', 'fuel_health/tests/smoke/test_dpdk.py', 'fuel_plugin/testing/tests/base.py', 'fuel_health/tests/smoke/test_neutron_actions.py']",6,3addfdd697dc2625c19c3070ebcb5adc135ca2d9,(detached," Deployment tags: neutron, computes_without_dpdk", Deployment tags: neutron,32,11
openstack%2Fkolla~master~Ia50a21a8cb914ed42f6155759544195d779f90ef,openstack/kolla,master,Ia50a21a8cb914ed42f6155759544195d779f90ef,Refactor task names in reconfigure scripts,ABANDONED,2016-03-08 08:14:57.000000000,2016-05-11 08:42:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 13642}, {'_account_id': 16233}]","[{'number': 1, 'created': '2016-03-08 08:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3d64aea2aa3e4da4ef1617cb21b6e4dca001e60a', 'message': 'Refactor task names in reconfigure scripts\n\nAgree with the comments in the patchset\n\nhttps://review.openstack.org/#/c/288239/3\n\nAll the reconfigure scripts should have common and\ninformative task name.\n\nThis patch refactor task names for murano reconfigure script.\n\nChange-Id: Ia50a21a8cb914ed42f6155759544195d779f90ef\n'}, {'number': 2, 'created': '2016-03-10 04:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f2fe4737be917bcff5a14ec034f73f5103ee36a2', 'message': 'Refactor task names in reconfigure scripts\n\nAgree with the comments in the patchset\n\nhttps://review.openstack.org/#/c/288239/3\n\nAll the reconfigure scripts should have common and\ninformative task name.\n\nChange-Id: Ia50a21a8cb914ed42f6155759544195d779f90ef\n'}, {'number': 3, 'created': '2016-03-10 05:04:22.000000000', 'files': ['ansible/roles/neutron/tasks/do_reconfigure.yml', 'ansible/roles/memcached/tasks/do_reconfigure.yml', 'ansible/roles/glance/tasks/do_reconfigure.yml', 'ansible/roles/cinder/tasks/do_reconfigure.yml', 'ansible/roles/ironic/tasks/do_reconfigure.yml', 'ansible/roles/keystone/tasks/do_reconfigure.yml', 'ansible/roles/swift/tasks/do_reconfigure.yml', 'ansible/roles/horizon/tasks/do_reconfigure.yml', 'ansible/roles/heat/tasks/do_reconfigure.yml', 'ansible/roles/murano/tasks/do_reconfigure.yml', 'ansible/roles/mongodb/tasks/do_reconfigure.yml', 'ansible/roles/ceph/tasks/do_reconfigure.yml', 'ansible/roles/manila/tasks/do_reconfigure.yml', 'ansible/roles/magnum/tasks/do_reconfigure.yml', 'ansible/roles/nova/tasks/do_reconfigure.yml', 'ansible/roles/common/tasks/do_reconfigure.yml', 'ansible/roles/mistral/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a7e223e4039310c66ec0ea542eb0595a57287e46', 'message': 'Refactor task names in reconfigure scripts\n\nAgree with the comments in the patchset\n\nhttps://review.openstack.org/#/c/288239/3\n\nAll the reconfigure scripts should have common and\ninformative task name.\n\nChange-Id: Ia50a21a8cb914ed42f6155759544195d779f90ef\n'}]",48,289778,a7e223e4039310c66ec0ea542eb0595a57287e46,15,5,3,18009,,,0,"Refactor task names in reconfigure scripts

Agree with the comments in the patchset

https://review.openstack.org/#/c/288239/3

All the reconfigure scripts should have common and
informative task name.

Change-Id: Ia50a21a8cb914ed42f6155759544195d779f90ef
",git fetch https://review.opendev.org/openstack/kolla refs/changes/78/289778/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/murano/tasks/do_reconfigure.yml'],1,3d64aea2aa3e4da4ef1617cb21b6e4dca001e60a,refactor_taskname,- name: Ensuring the containers running murano_api and murano_engine are up- name: Checking the config in the containers running murano_api and murano_engine- name: Getting config strategy for the containers running murano_api and murano_engine- name: Removing the containers running murano_api and murano_engine- name: Restarting the containers running murano_api and murano_engine,- name: Ensuring the containers up- name: Check the configs- name: Containers config strategy- name: Remove the containers- name: Restart containers,5,5
openstack%2Fkolla~master~I99bedec208029668c4bb906dc8790e420e6dd9b0,openstack/kolla,master,I99bedec208029668c4bb906dc8790e420e6dd9b0,Remove redundant value,ABANDONED,2016-04-14 06:34:56.000000000,2016-05-11 08:41:14.000000000,,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 17591}]","[{'number': 1, 'created': '2016-04-14 06:34:56.000000000', 'files': ['tests/test_build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/de5c5545867ccaddea340ccd996b353fef425305', 'message': 'Remove redundant value\n\nTrivialFix\n\nChange-Id: I99bedec208029668c4bb906dc8790e420e6dd9b0\n'}]",3,305625,de5c5545867ccaddea340ccd996b353fef425305,7,4,1,18009,,,0,"Remove redundant value

TrivialFix

Change-Id: I99bedec208029668c4bb906dc8790e420e6dd9b0
",git fetch https://review.opendev.org/openstack/kolla refs/changes/25/305625/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_build.py'],1,de5c5545867ccaddea340ccd996b353fef425305,," ""mistral-base""] ""mistral-base""]"," ""mistral-base"", ""murano-base""] ""mistral-base"", ""murano-base""]",2,4
openstack%2Fpython-keystoneclient~master~I8f725ca8071e592fdf932bf83f72eaebf588bb6b,openstack/python-keystoneclient,master,I8f725ca8071e592fdf932bf83f72eaebf588bb6b,Improve docs for v3 users,MERGED,2016-04-14 12:26:12.000000000,2016-05-11 08:32:08.000000000,2016-05-11 08:32:08.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6676}, {'_account_id': 7725}, {'_account_id': 8482}, {'_account_id': 8866}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-04-14 12:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3abe616431df92e9dd2a8ffcc96d7c6baad4769f', 'message': 'Improve docs for v3 users\n\nIn preparation to add functional tests for v3 users, this change\nproposes to detail the method docs, because the tests need to be\nbased on them.\n\nChange-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b\n'}, {'number': 2, 'created': '2016-04-18 11:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/eb39be98f45d12dfc8e4fe71e01502e047609327', 'message': 'Improve docs for v3 users\n\nIn preparation to add functional tests for v3 users, this change\nproposes to detail the method docs, because the tests need to be\nbased on them.\n\nChange-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b\n'}, {'number': 3, 'created': '2016-04-18 20:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ba21ad3b594032eda9e445ea5992ebc43fddeaba', 'message': 'Improve docs for v3 users\n\nIn preparation to add functional tests for v3 users, this change\nproposes to detail the method docs, because the tests need to be\nbased on them.\n\nChange-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b\n'}, {'number': 4, 'created': '2016-05-06 23:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/253b076a40a9277ca5a9a58c4f0a7d178ce5d92d', 'message': 'Improve docs for v3 users\n\nIn preparation to add functional tests for v3 users, this change\nproposes to detail the method docs, because the tests need to be\nbased on them.\n\nChange-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b\n'}, {'number': 5, 'created': '2016-05-07 05:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9f663575f8e60690fde845955558d211a678b1a9', 'message': 'Improve docs for v3 users\n\nIn preparation to add functional tests for v3 users, this change\nproposes to detail the method docs, because the tests need to be\nbased on them.\n\nChange-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b\n'}, {'number': 6, 'created': '2016-05-11 06:28:33.000000000', 'files': ['keystoneclient/v3/users.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b170fa4564dc570f244ce89ff91f58e29bfc09ac', 'message': 'Improve docs for v3 users\n\nIn preparation to add functional tests for v3 users, this change\nproposes to detail the method docs, because the tests need to be\nbased on them.\n\nChange-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b\n'}]",16,305796,b170fa4564dc570f244ce89ff91f58e29bfc09ac,34,9,6,17860,,,0,"Improve docs for v3 users

In preparation to add functional tests for v3 users, this change
proposes to detail the method docs, because the tests need to be
based on them.

Change-Id: I8f725ca8071e592fdf932bf83f72eaebf588bb6b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/96/305796/6 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/v3/users.py'],1,3abe616431df92e9dd2a8ffcc96d7c6baad4769f,user-python-docs," :param str name: the name of the user. :param domain: the domain of the user. :type domain: str or keystoneclient.v3.domains.Domain :param project: the default project of the user. (optional, deprecated, see warning below) :type project: str or keystoneclient.v3.projects.Project :param str password: the password of the user. (optional) :param str email: the email of the user. (optional) :param str description: a description of the user. (optional) :param bool enabled: whether the user is enabled. (optional, defaults to True) :param default_project: the default project of the user. (optional) :type default_project: str or keystoneclient.v3.projects.Project :param **kwargs: any other attribute provided will be passed to server. :returns: the created user returned from server. :rtype: keystoneclient.v3.users.User The project argument is deprecated as of the 1.7.0 release in favor of default_project and may be removed in the 2.0.0 release. If both default_project and project is provided, the default_project will be used. :param project: the default project of the users to be filtered in. (optional, deprecated, see warning below) :type project: str or keystoneclient.v3.projects.Project :param domain: the domain of the users to be filtered in. :type domain: str or keystoneclient.v3.domains.Domain :param group: the group of the users to be filtered in. :type group: str or keystoneclient.v3.groups.Group :param default_project: the default project of the users to be filtered in. (optional) :type default_project: str or keystoneclient.v3.projects.Project :param **kwargs: any other attribute provided will filter users in. :returns: a list of users. :rtype: list of keystoneclient.v3.users.User. If both default_project and project is provided, the default_project will be used. """"""Retrieve a user. :param user: the user to be retrieved from the server. :type user: str or keystoneclient.v3.users.User :returns: the specified user returned from server. :rtype: keystoneclient.v3.users.User """""" :param user: the user to be updated on the server. :type user: str or keystoneclient.v3.users.User :param str name: the new name of the user. :param domain: the new domain of the user. :type domain: str or keystoneclient.v3.domains.Domain :param project: the new default project of the user. (optional, deprecated, see warning below) :type project: str or keystoneclient.v3.projects.Project :param str password: the new password of the user. (optional) :param str email: the new email of the user. (optional) :param str description: the newdescription of the user. (optional) :param bool enabled: whether the user is enabled. (optional, defaults to True) :param default_project: the new default project of the user. (optional) :type default_project: str or keystoneclient.v3.projects.Project :param **kwargs: any other attribute provided will be passed to server. :returns: the updated user returned from server. :rtype: keystoneclient.v3.users.User The project argument is deprecated as of the 1.7.0 release in favor of default_project and may be removed in the 2.0.0 release. If both default_project and project is provided, the default_project will be used. """"""Update the password for the user the token belongs to. :param str old_password: the user's old password :param str new_password: the user's new password :returns: the updated user returned from server. :rtype: keystoneclient.v3.users.User """""" """"""Add the specified user as a member of the specified group. :param user: the user to be added to the group. :type user: str or keystoneclient.v3.users.User :param group: the group to put the user in. :type group: str or keystoneclient.v3.groups.Group :returns: HTTP response from the server. """""" """"""Check if the specified user is a member of the specified group. :param user: the user to be verified in the group. :type user: str or keystoneclient.v3.users.User :param group: the group to check the user in. :type group: str or keystoneclient.v3.groups.Group :returns: HTTP response from the server. """""" """"""Remove the specified user from the specified group. :param user: the user to be removed from the group. :type user: str or keystoneclient.v3.users.User :param group: the group to remove the user from. :type group: str or keystoneclient.v3.groups.Group :returns: HTTP response from the server. """""" """"""Delete a user. :param user: the user to be deleted on the server. :type user: str or keystoneclient.v3.users.User :returns: HTTP response from the server. """""""," The project argument is deprecated as of the 1.7.0 release in favor of default_project and may be removed in the 2.0.0 release. If both default_project and project is provided, the default_project will be used. If project, domain or group are provided, then filter users with those attributes. If ``**kwargs`` are provided, then filter users with attributes matching ``**kwargs``. If both default_project and project is provided, the default_project will be used. The project argument is deprecated as of the 1.7.0 release in favor of default_project and may be removed in the 2.0.0 release. If both default_project and project is provided, the default_project will be used. """"""Update the password for the user the token belongs to.""""""",120,15
openstack%2Fdjango_openstack_auth~master~If3d980e8acb07e03b97d2489664141443b363bc3,openstack/django_openstack_auth,master,If3d980e8acb07e03b97d2489664141443b363bc3,Imported Translations from Zanata,MERGED,2016-05-10 06:09:37.000000000,2016-05-11 08:21:51.000000000,2016-05-11 08:21:51.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6914}]","[{'number': 1, 'created': '2016-05-10 06:09:37.000000000', 'files': ['openstack_auth/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_auth/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_auth/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_auth/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_auth/locale/fr/LC_MESSAGES/django.po', 'openstack_auth/locale/ru/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_auth/locale/fi_FI/LC_MESSAGES/django.po', 'openstack_auth/locale/sl_SI/LC_MESSAGES/django.po', 'openstack_auth/locale/it/LC_MESSAGES/django.po', 'openstack_auth/locale/en_GB/LC_MESSAGES/django.po', 'openstack_auth/locale/es/LC_MESSAGES/django.po', 'openstack_auth/locale/cs/LC_MESSAGES/django.po', 'openstack_auth/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_auth/locale/es_MX/LC_MESSAGES/django.po', 'openstack_auth/locale/en_AU/LC_MESSAGES/django.po', 'openstack_auth/locale/ja/LC_MESSAGES/django.po', 'openstack_auth/locale/django.pot', 'openstack_auth/locale/ca/LC_MESSAGES/django.po', 'openstack_auth/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_auth/locale/hi/LC_MESSAGES/django.po', 'openstack_auth/locale/ar/LC_MESSAGES/django.po', 'openstack_auth/locale/sr/LC_MESSAGES/django.po', 'openstack_auth/locale/ne/LC_MESSAGES/django.po', 'openstack_auth/locale/pt/LC_MESSAGES/django.po', 'openstack_auth/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/5f9fbacd63352bc5616fa201f93b30b49ba1bace', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If3d980e8acb07e03b97d2489664141443b363bc3\n'}]",0,314422,5f9fbacd63352bc5616fa201f93b30b49ba1bace,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: If3d980e8acb07e03b97d2489664141443b363bc3
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/22/314422/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_auth/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_auth/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_auth/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_auth/locale/fr/LC_MESSAGES/django.po', 'openstack_auth/locale/ru/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_auth/locale/fi_FI/LC_MESSAGES/django.po', 'openstack_auth/locale/sl_SI/LC_MESSAGES/django.po', 'openstack_auth/locale/it/LC_MESSAGES/django.po', 'openstack_auth/locale/en_GB/LC_MESSAGES/django.po', 'openstack_auth/locale/es/LC_MESSAGES/django.po', 'openstack_auth/locale/cs/LC_MESSAGES/django.po', 'openstack_auth/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_auth/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_auth/locale/es_MX/LC_MESSAGES/django.po', 'openstack_auth/locale/en_AU/LC_MESSAGES/django.po', 'openstack_auth/locale/ja/LC_MESSAGES/django.po', 'openstack_auth/locale/django.pot', 'openstack_auth/locale/ca/LC_MESSAGES/django.po', 'openstack_auth/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_auth/locale/hi/LC_MESSAGES/django.po', 'openstack_auth/locale/ar/LC_MESSAGES/django.po', 'openstack_auth/locale/sr/LC_MESSAGES/django.po', 'openstack_auth/locale/ne/LC_MESSAGES/django.po', 'openstack_auth/locale/pt/LC_MESSAGES/django.po', 'openstack_auth/locale/de/LC_MESSAGES/django.po']",27,5f9fbacd63352bc5616fa201f93b30b49ba1bace,zanata/translations,"# Andreas Jaeger <jaegerandi@gmail.com>, 2016. #zanata""Project-Id-Version: django_openstack_auth 2.2.1.dev12\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2016-05-09 19:52+0000\n""","# Frank Kloeker <eumel@arcor.de>, 2016. #zanata""Project-Id-Version: PROJECT VERSION\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2016-02-29 11:46+0000\n""",108,207
openstack%2Fnova~master~I4a007d23285b10725123cbfe5554c0964ae798a0,openstack/nova,master,I4a007d23285b10725123cbfe5554c0964ae798a0,Complete method verification of os-tenant-networks,MERGED,2016-05-09 14:48:29.000000000,2016-05-11 08:14:00.000000000,2016-05-10 01:48:00.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16051}, {'_account_id': 16376}, {'_account_id': 19590}]","[{'number': 1, 'created': '2016-05-09 14:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0235ca5477369c570385422e1b48959934d901be', 'message': 'Complete method verification of os-tenant-networks\n\nVerified the API document with source for methods available and response\ncodes used.\nRecorded HTTP methods to match wiki.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I4a007d23285b10725123cbfe5554c0964ae798a0\n'}, {'number': 2, 'created': '2016-05-09 17:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bbba4cb05b731d0d200a6582792e4d1c021cb451', 'message': 'Complete method verification of os-tenant-networks\n\nVerified the API document with source for methods available and response\ncodes used.\nRecorded HTTP methods to match wiki.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I4a007d23285b10725123cbfe5554c0964ae798a0\n'}, {'number': 3, 'created': '2016-05-09 20:22:58.000000000', 'files': ['api-ref/source/os-tenant-network.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/68e7462d08bdd7a944dd038bd73c7c43f860957e', 'message': 'Complete method verification of os-tenant-networks\n\nVerified the API document with source for methods available and response\ncodes used.\nRecorded HTTP methods to match wiki.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I4a007d23285b10725123cbfe5554c0964ae798a0\n'}]",8,314139,68e7462d08bdd7a944dd038bd73c7c43f860957e,35,13,3,16051,,,0,"Complete method verification of os-tenant-networks

Verified the API document with source for methods available and response
codes used.
Recorded HTTP methods to match wiki.

Part of bp:api-ref-in-rst

Change-Id: I4a007d23285b10725123cbfe5554c0964ae798a0
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/314139/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-tenant-network.inc'],1,0235ca5477369c570385422e1b48959934d901be,bp/api-ref-in-rst,"List Project Networks ===================== .. rest_method:: GET /v2.1/{tenant_id}/os-tenant-networks Lists all project networks. Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file. Normal response codes: 200 Error response codes: unauthorized(401), forbidden(403) Request ------- .. rest_parameters:: parameters.yaml - tenant_id: tenant_id Response -------- **Example List Project Networks: JSON response** .. literalinclude:: ../../doc/api_samples/os-tenant-networks/networks-list-res.json :language: javascript Error response codes: badRequest(400), unauthorized(401), forbidden(403), conflict(409), serviceUnavailable(503)Error response codes: unauthorized(401), forbidden(403), itemNotFound(404)Error response codes: unauthorized(401), forbidden(403), itemNotFound(404), conflict(409)",".. needs:method_verificationError response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)List Project Networks ===================== .. rest_method:: GET /v2.1/{tenant_id}/os-tenant-networks Lists all project networks. Policy defaults enable only users with the administrative role or the owner of the server to perform this operation. Cloud providers can change these permissions through the ``policy.json`` file. Normal response codes: 200 Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404) Request ------- .. rest_parameters:: parameters.yaml - tenant_id: tenant_id Response -------- **Example List Project Networks: JSON response** .. literalinclude:: ../../doc/api_samples/os-tenant-networks/networks-list-res.json :language: javascript Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",31,36
openstack%2Fneutron~master~Id2b0463f49df52744e5bc3979a4cfd0ff06f9248,openstack/neutron,master,Id2b0463f49df52744e5bc3979a4cfd0ff06f9248,LinuxBridge agent's QoS driver bw limit for egress traffic,MERGED,2016-03-31 20:53:41.000000000,2016-05-11 08:07:00.000000000,2016-04-19 10:58:54.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 7787}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11975}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 20066}]","[{'number': 1, 'created': '2016-03-31 20:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b89a24b8a185b90621b262ddc630b66445b87cc', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 2, 'created': '2016-04-05 14:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/75912697c710d85e559a473ae247fcc09abab536', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 3, 'created': '2016-04-06 20:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f306f876676e805c65bb4db077ff3e53aded2fa1', 'message': ""[WIP] LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 4, 'created': '2016-04-07 17:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd2652a803186df0b2ac2c2914e3b51058aee0bf', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nLinuxbridge agent's QoS extension configures egress bandwidth limit and burst\nvalue in exactly same way how openvswitch is doing it with tc.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 5, 'created': '2016-04-07 17:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48661f25f5577abf3abc619342e827c27b951ca0', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress\ntraffic only (from VM point of view). QoS extension driver for\nLinuxbridge agent now configures limits in proper way on tap interface\nso limited is traffic which is outgoing from VM.\nLinuxbridge agent's QoS extension configures egress bandwidth limit\nand burst value in exactly same way how openvswitch is doing it with tc.\nOld methods in TcCommand class will stay untouched because they can be\nused later to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 6, 'created': '2016-04-08 08:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/661cf90a336d2ebc9a907391835e2f4b73cdd151', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress\ntraffic only (from VM point of view). QoS extension driver for\nLinuxbridge agent now configures limits in proper way on tap interface\nso limited is traffic which is outgoing from VM.\nLinuxbridge agent's QoS extension configures egress bandwidth limit\nand burst value in exactly same way how openvswitch is doing it with tc.\nOld methods in TcCommand class will stay untouched because they can be\nused later to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 7, 'created': '2016-04-17 21:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8c8f8bac0d70420188c91635fdeb1d186335792', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nLinuxbridge agent's QoS extension configures egress bandwidth limit and burst\nvalue in exactly same way how openvswitch is doing it with tc.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}, {'number': 8, 'created': '2016-04-18 14:46:22.000000000', 'files': ['neutron/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/agent/linux/test_tc_lib.py', 'neutron/tests/fullstack/test_qos.py', 'neutron/tests/functional/agent/linux/test_tc_lib.py', 'etc/neutron/rootwrap.d/linuxbridge-plugin.filters', 'neutron/agent/linux/tc_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/test_qos_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6dcdb15dce4952cdf3782d57431d0c5f7ba6e53b', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nLinuxbridge agent's QoS extension configures egress bandwidth limit and burst\nvalue in exactly same way how openvswitch is doing it with tc.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n""}]",14,300210,6dcdb15dce4952cdf3782d57431d0c5f7ba6e53b,120,18,8,11975,,,0,"LinuxBridge agent's QoS driver bw limit for egress traffic

QoS service plugin provides for now bandwidth limit rules for egress traffic
only (from VM point of view). QoS extension driver for Linuxbridge agent now
configures limits in proper way on tap interface so limited is traffic which is
outgoing from VM.
Linuxbridge agent's QoS extension configures egress bandwidth limit and burst
value in exactly same way how openvswitch is doing it with tc.
Old methods in TcCommand class will stay untouched because they can be used
later to implement also ingress bandwidth limits in QoS.

Change-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248
Closes-bug: #1563720
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/300210/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/agent/linux/test_tc_lib.py', 'neutron/tests/fullstack/test_qos.py', 'neutron/tests/functional/agent/linux/test_tc_lib.py', 'etc/neutron/rootwrap.d/linuxbridge-plugin.filters', 'neutron/agent/linux/tc_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/test_qos_driver.py']",7,4b89a24b8a185b90621b262ddc630b66445b87cc,bug/1563720," tc_lib.TcCommand, ""set_filters_bw_limit"" tc_lib.TcCommand, ""update_filters_bw_limit"" tc_lib.TcCommand, ""delete_filters_bw_limit"""," tc_lib.TcCommand, ""set_bw_limit"" TEST_LATENCY_VALUE tc_lib.TcCommand, ""update_bw_limit"" TEST_LATENCY_VALUE tc_lib.TcCommand, ""delete_bw_limit""",235,71
openstack%2Fgnocchi~master~Ie27a2d9a77f632f027773f84fe23af5c11252aa7,openstack/gnocchi,master,Ie27a2d9a77f632f027773f84fe23af5c11252aa7,gate: work with old and new devstack ceph plugin,MERGED,2016-05-10 06:44:05.000000000,2016-05-11 08:05:21.000000000,2016-05-11 08:05:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2016-05-10 06:44:05.000000000', 'files': ['devstack/gate/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c2d722b185dde43f1505812fe888c3a65bb59549', 'message': 'gate: work with old and new devstack ceph plugin\n\nChange-Id: Ie27a2d9a77f632f027773f84fe23af5c11252aa7\n'}]",0,314427,c2d722b185dde43f1505812fe888c3a65bb59549,9,3,1,2813,,,0,"gate: work with old and new devstack ceph plugin

Change-Id: Ie27a2d9a77f632f027773f84fe23af5c11252aa7
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/27/314427/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/gate/gate_hook.sh'],1,c2d722b185dde43f1505812fe888c3a65bb59549,sileht/devstack-ceph," if [ ""${PROJECTS//devstack-plugin-ceph/}"" == ""$PROJECTS"" ]; then # Old fashion ceph plugin ENABLED_SERVICES+=""ceph"" fi"," ENABLED_SERVICES+=""ceph""",4,1
openstack%2Ffuel-qa~stable%2F8.0~Ie505c2fd03a69df594ba5925fb08eb04d138fc5a,openstack/fuel-qa,stable/8.0,Ie505c2fd03a69df594ba5925fb08eb04d138fc5a,Handling of problem with bad calculated pg Wrap waiting of ceph helth is ok in try/except and log information if it not passed Closes-Bug: #1541418 Change-Id: Ie505c2fd03a69df594ba5925fb08eb04d138fc5a,ABANDONED,2016-02-02 21:32:23.000000000,2016-05-11 08:02:03.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 12867}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-02-02 21:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/042d2a23aa9a02ca033cc375c60a17ac4887902e', 'message': 'Handling of problem with bad calculated pg\nWrap waiting of ceph helth is ok in try/except\nand log information if it not passed\nRelated-Bug: #1539555\nChange-Id: Ie505c2fd03a69df594ba5925fb08eb04d138fc5a\n'}, {'number': 2, 'created': '2016-02-03 11:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/8300145850e7c2a22385eb2095e71d5e429afe91', 'message': 'Handling of problem with bad calculated pg\nWrap waiting of ceph helth is ok in try/except\nand log information if it not passed\nRelated-Bug: #1539555\nChange-Id: Ie505c2fd03a69df594ba5925fb08eb04d138fc5a\n'}, {'number': 3, 'created': '2016-02-03 14:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/51b4edfe17ecb0021005fc235531796233ddd445', 'message': 'Handling of problem with bad calculated pg\nWrap waiting of ceph helth is ok in try/except\nand log information if it not passed\nCloses-Bug: #1541418\nChange-Id: Ie505c2fd03a69df594ba5925fb08eb04d138fc5a\n'}, {'number': 4, 'created': '2016-02-05 11:17:10.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e874a84b6d7983a9797e202835266c1ec6836111', 'message': 'Handling of problem with bad calculated pg\nWrap waiting of ceph helth is ok in try/except\nand log information if it not passed\nCloses-Bug: #1541418\nChange-Id: Ie505c2fd03a69df594ba5925fb08eb04d138fc5a\n'}]",0,275417,e874a84b6d7983a9797e202835266c1ec6836111,30,7,4,15943,,,0,"Handling of problem with bad calculated pg
Wrap waiting of ceph helth is ok in try/except
and log information if it not passed
Closes-Bug: #1541418
Change-Id: Ie505c2fd03a69df594ba5925fb08eb04d138fc5a
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/17/275417/4 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,042d2a23aa9a02ca033cc375c60a17ac4887902e,bug/1539555," try: wait(lambda: ceph.is_health_ok(remote_ceph), interval=30, timeout=10 * 60) except TimeoutError: assert_true( 'too many PGs per OSD' in ceph.get_health(remote_ceph)['summary'][0]['summary'] ) logger.error('Error due to known issue ' 'https://bugs.launchpad.net/fuel/+bug/1539555')"," wait(lambda: ceph.is_health_ok(remote_ceph), interval=30, timeout=10 * 60)",10,2
openstack%2Fpython-openstackclient~master~I9c4b5068a8abb986a9dc18b167b48b924d16ff42,openstack/python-openstackclient,master,I9c4b5068a8abb986a9dc18b167b48b924d16ff42,"Implement ""address scope set"" command",MERGED,2016-04-20 10:36:28.000000000,2016-05-11 07:59:04.000000000,2016-05-11 07:59:04.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17776}, {'_account_id': 21514}]","[{'number': 1, 'created': '2016-04-20 10:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/07fbe1917f173165dea5bc4f855491bf15ab9c35', 'message': 'Implement ""address scope set"" command\n\nThis patch add a command that supports\nsetting a new name for a address scope\n\nChange-Id: I9c4b5068a8abb986a9dc18b167b48b924d16ff42\nCloses-Bug: #1566269\n'}, {'number': 2, 'created': '2016-05-07 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/71da52a79dfccb675f944a1543a34da8a4ca4259', 'message': 'Implement ""address scope set"" command\n\nThis patch add a command that supports\nsetting address scope properties.\n\nChange-Id: I9c4b5068a8abb986a9dc18b167b48b924d16ff42\nCloses-Bug: #1566269\n'}, {'number': 3, 'created': '2016-05-09 08:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/168de19336033f84e7b6eef1e1ba49850a9b3ef4', 'message': 'Implement ""address scope set"" command\n\nThis patch add a command that supports\nsetting address scope properties.\n\nChange-Id: I9c4b5068a8abb986a9dc18b167b48b924d16ff42\nCloses-Bug: #1566269\n'}, {'number': 4, 'created': '2016-05-11 02:09:44.000000000', 'files': ['functional/tests/network/v2/test_address_scope.py', 'openstackclient/tests/network/v2/test_address_scope.py', 'doc/source/command-objects/address-scope.rst', 'releasenotes/notes/bug-1566269-2572bca9157ca107.yaml', 'openstackclient/network/v2/address_scope.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cc78d48a2895413f0ae7547db19ea843ae796cca', 'message': 'Implement ""address scope set"" command\n\nThis patch add a command that supports\nsetting address scope properties.\n\nChange-Id: I9c4b5068a8abb986a9dc18b167b48b924d16ff42\nCloses-Bug: #1566269\n'}]",8,308260,cc78d48a2895413f0ae7547db19ea843ae796cca,23,7,4,21514,,,0,"Implement ""address scope set"" command

This patch add a command that supports
setting address scope properties.

Change-Id: I9c4b5068a8abb986a9dc18b167b48b924d16ff42
Closes-Bug: #1566269
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/60/308260/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_address_scope.py', 'openstackclient/network/v2/address_scope.py', 'setup.cfg']",3,07fbe1917f173165dea5bc4f855491bf15ab9c35,bug/1566269, address_scope_set = openstackclient.network.v2.address_scope:SetAddressScope,,80,0
openstack%2Fheat~master~I654bdfcd6d6b23f0e9063a8cf12654ac2c3d91d7,openstack/heat,master,I654bdfcd6d6b23f0e9063a8cf12654ac2c3d91d7,Adding two parameters into Software configuration,ABANDONED,2016-05-11 07:53:55.000000000,2016-05-11 07:57:33.000000000,,[],"[{'number': 1, 'created': '2016-05-11 07:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/587aa090dfc5f9a90a82520adc5f1d65f554093f', 'message': 'Adding two parameters into Software configuration\n\nThis patch added two parameter: software_config and\nsoftware_deployments.\n""software_config"" add into ""Create configuration"" and\n""Show configuration details"".\n""software_deployments"" parameter add into ""Show deployment details"",\n""Update deployment"" and ""Create deployment"".\n\nChange-Id: I654bdfcd6d6b23f0e9063a8cf12654ac2c3d91d7\nCloses-Bug: #1567193\n'}, {'number': 2, 'created': '2016-05-11 07:57:03.000000000', 'files': ['api-ref/source/v1/parameters.yaml', 'heat/tests/openstack/heat/test_structured_config.py', 'api-ref/source/v1/software-config.inc'], 'web_link': 'https://opendev.org/openstack/heat/commit/b50ed095714040c7973ef0e550f6211a1d8f4afd', 'message': 'Adding two parameters into Software configuration\n\nThis patch added two parameter: software_config and\nsoftware_deployments.\n""software_config"" add into ""Create configuration"" and\n""Show configuration details"".\n""software_deployments"" parameter add into ""Show deployment details"",\n""Update deployment"" and ""Create deployment"".\n\nChange-Id: I654bdfcd6d6b23f0e9063a8cf12654ac2c3d91d7\nCloses-Bug: #1567193\n'}]",0,314903,b50ed095714040c7973ef0e550f6211a1d8f4afd,3,0,2,20863,,,0,"Adding two parameters into Software configuration

This patch added two parameter: software_config and
software_deployments.
""software_config"" add into ""Create configuration"" and
""Show configuration details"".
""software_deployments"" parameter add into ""Show deployment details"",
""Update deployment"" and ""Create deployment"".

Change-Id: I654bdfcd6d6b23f0e9063a8cf12654ac2c3d91d7
Closes-Bug: #1567193
",git fetch https://review.opendev.org/openstack/heat refs/changes/03/314903/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v1/parameters.yaml', 'heat/tests/openstack/heat/test_structured_config.py', 'api-ref/source/v1/software-config.inc']",3,587aa090dfc5f9a90a82520adc5f1d65f554093f,bug/1567193, - software_deployment: software_deployment - software_config: software_config - software_deployment: software_deployment - software_deployment: software_deployment - software_config: software_config,,42,8
openstack%2Fpython-swiftclient~master~I94d4536cc1489968d45a2b6ba7edd70c85800275,openstack/python-swiftclient,master,I94d4536cc1489968d45a2b6ba7edd70c85800275,Check responses when retrying bodies,MERGED,2016-01-18 19:45:08.000000000,2016-05-11 07:52:47.000000000,2016-05-11 07:52:47.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 9216}, {'_account_id': 15343}]","[{'number': 1, 'created': '2016-01-18 19:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/99e8d975681766ce775195686381a710afd05fd5', 'message': 'Check responses when retrying bodies\n\nPreviously, if a Range request came back 200 OK (rather than 206 Partial\nContent), we would mangle the response body. This could happen if there\nwas a middleware that would silently drop Range headers, for example.\n\nNow, if the response does not include a Content-Range header, we will\nseek to our previous position in the stream. If the Content-Range header\nhas an unexpected value, we will raise an exception.\n\nChange-Id: I94d4536cc1489968d45a2b6ba7edd70c85800275\n'}, {'number': 2, 'created': '2016-05-04 23:29:32.000000000', 'files': ['tests/unit/test_swiftclient.py', 'swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/fd5579a154694418c66075d97f43e5d9d741058b', 'message': 'Check responses when retrying bodies\n\nPreviously, if a Range request came back 200 OK (rather than 206 Partial\nContent), we would mangle the response body. This could happen if there\nwas a middleware that would silently drop Range headers, for example.\n\nNow, if the response does not include a Content-Range header, we will\nlog a warning and seek to our previous position in the stream. If the\nContent-Range header has an unexpected value, we will raise an exception.\n\nChange-Id: I94d4536cc1489968d45a2b6ba7edd70c85800275\n'}]",0,269252,fd5579a154694418c66075d97f43e5d9d741058b,20,5,2,15343,,,0,"Check responses when retrying bodies

Previously, if a Range request came back 200 OK (rather than 206 Partial
Content), we would mangle the response body. This could happen if there
was a middleware that would silently drop Range headers, for example.

Now, if the response does not include a Content-Range header, we will
log a warning and seek to our previous position in the stream. If the
Content-Range header has an unexpected value, we will raise an exception.

Change-Id: I94d4536cc1489968d45a2b6ba7edd70c85800275
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/52/269252/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_swiftclient.py', 'swiftclient/client.py']",2,99e8d975681766ce775195686381a710afd05fd5,data-retry," expected_range = 'bytes %d-%d/%d' % ( self.bytes_read, self.expected_length - 1, self.expected_length) if 'content-range' not in hdrs: # Server didn't respond with partial content; manually seek to_read = self.bytes_read while to_read > 0: buf = body.resp.read(min(to_read, self.chunk_size)) to_read -= len(buf) elif hdrs['content-range'] != expected_range: msg = 'Expected range ""%s"" while retrying but got ""%s""' % ( expected_range, hdrs['content-range']) raise ClientException(msg)",,82,2
openstack%2Ftripleo-heat-templates~master~Iae33149e4a03cd64c5831e689be8189ad0cf034b,openstack/tripleo-heat-templates,master,Iae33149e4a03cd64c5831e689be8189ad0cf034b,deployment: drop step6,MERGED,2016-05-09 19:44:40.000000000,2016-05-11 07:31:50.000000000,2016-05-11 07:29:28.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 10873}, {'_account_id': 20172}]","[{'number': 1, 'created': '2016-05-09 19:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e54bb522c543f8fe1d1bf1a65f13ce082bae5e56', 'message': ""deployment: drop step6\n\nStep6 was just about confuring fencing after creating all Pacemaker\nresources.\nA bit of Puppet orchestration can help us to not require an extra step.\n\nThis patch:\n* configure & enable fencing at step5\n* make sure we don't configure fencing because creating Pacemaker\n  resources and constraints.\n* remove step6 from deployment workflow.\n\nChange-Id: Iae33149e4a03cd64c5831e689be8189ad0cf034b\nDepends-On: Icea7537cea330da59fe108c9b874c04f2b94d062\n""}, {'number': 2, 'created': '2016-05-09 22:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ccd61980ff35ef31c708ec43b6f2088f764d11d3', 'message': ""deployment: drop step6\n\nStep6 was just about confuring fencing after creating all Pacemaker\nresources.\nA bit of Puppet orchestration can help us to not require an extra step.\n\nThis patch:\n* configure & enable fencing at step5\n* make sure we don't configure fencing because creating Pacemaker\n  resources and constraints.\n* remove step6 from deployment workflow.\n\nChange-Id: Iae33149e4a03cd64c5831e689be8189ad0cf034b\nDepends-On: Icea7537cea330da59fe108c9b874c04f2b94d062\n""}, {'number': 3, 'created': '2016-05-10 12:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c6cf449c635150fb605c6be8bfec15992cb8ec03', 'message': ""deployment: drop step6\n\nStep6 was just about confuring fencing after creating all Pacemaker\nresources.\nA bit of Puppet orchestration can help us to not require an extra step.\n\nThis patch:\n* configure & enable fencing at step5\n* make sure we don't configure fencing because creating Pacemaker\n  resources and constraints.\n* remove step6 from deployment workflow.\n\nChange-Id: Iae33149e4a03cd64c5831e689be8189ad0cf034b\nDepends-On: Icea7537cea330da59fe108c9b874c04f2b94d062\nDepends-On: I079e65f535af069312b602e8ff58be80ab2f2226\n""}, {'number': 4, 'created': '2016-05-10 13:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/46f67ed87590ed5c8fed450bbe08a33c78640d92', 'message': ""deployment: drop step6\n\nStep6 was just about confuring fencing after creating all Pacemaker\nresources.\nIt was created by this patch:\nhttps://review.openstack.org/#q,1787fbc7ca58f9965cd5d64b685c1f9beed4cb9b,n,z\nA bit of Puppet orchestration can help us to not require an extra step.\n\nThis patch:\n* configure & enable fencing at step5\n* make sure we don't configure fencing because creating Pacemaker\n  resources and constraints.\n* remove step6 from deployment workflow.\n* depends on a patch in puppet-tripleo that moves keystone resources\n  (endpoints, roles) to step 5.\n\nChange-Id: Iae33149e4a03cd64c5831e689be8189ad0cf034b\nDepends-On: Icea7537cea330da59fe108c9b874c04f2b94d062\nDepends-On: I079e65f535af069312b602e8ff58be80ab2f2226\n""}, {'number': 5, 'created': '2016-05-10 22:12:51.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/controller-post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c2cd6f01dc18901a33bd04ffe71ef00613fc3744', 'message': ""deployment: drop step6\n\nStep6 was just about confuring fencing after creating all Pacemaker\nresources.\nIt was created by this patch:\nhttps://review.openstack.org/#q,1787fbc7ca58f9965cd5d64b685c1f9beed4cb9b,n,z\nA bit of Puppet orchestration can help us to not require an extra step.\n\nThis patch:\n* configure & enable fencing at step5\n* make sure we don't configure fencing because creating Pacemaker\n  resources and constraints.\n* remove step6 from deployment workflow.\n* depends on a patch in puppet-tripleo that moves keystone resources\n  (endpoints, roles) to step 5.\n\nChange-Id: Iae33149e4a03cd64c5831e689be8189ad0cf034b\nDepends-On: Icea7537cea330da59fe108c9b874c04f2b94d062\nDepends-On: I079e65f535af069312b602e8ff58be80ab2f2226\n""}]",1,314253,c2cd6f01dc18901a33bd04ffe71ef00613fc3744,34,9,5,3153,,,0,"deployment: drop step6

Step6 was just about confuring fencing after creating all Pacemaker
resources.
It was created by this patch:
https://review.openstack.org/#q,1787fbc7ca58f9965cd5d64b685c1f9beed4cb9b,n,z
A bit of Puppet orchestration can help us to not require an extra step.

This patch:
* configure & enable fencing at step5
* make sure we don't configure fencing because creating Pacemaker
  resources and constraints.
* remove step6 from deployment workflow.
* depends on a patch in puppet-tripleo that moves keystone resources
  (endpoints, roles) to step 5.

Change-Id: Iae33149e4a03cd64c5831e689be8189ad0cf034b
Depends-On: Icea7537cea330da59fe108c9b874c04f2b94d062
Depends-On: I079e65f535af069312b602e8ff58be80ab2f2226
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/314253/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/controller-post.yaml']",2,e54bb522c543f8fe1d1bf1a65f13ce082bae5e56,steps/drop6, depends_on: ControllerOvercloudServicesDeployment_Step5, ControllerOvercloudServicesDeployment_Step6: type: OS::Heat::StructuredDeployments depends_on: ControllerOvercloudServicesDeployment_Step5 properties: name: ControllerOvercloudServicesDeployment_Step6 servers: {get_param: servers} config: {get_resource: ControllerPuppetConfig} input_values: step: 6 update_identifier: {get_param: NodeConfigIdentifiers} depends_on: ControllerOvercloudServicesDeployment_Step6,6,13
openstack%2Fmanila-ui~master~I2e77f4cbb85a0e920bfa394cf021d55215d9eba5,openstack/manila-ui,master,I2e77f4cbb85a0e920bfa394cf021d55215d9eba5,Updated from global requirements,MERGED,2016-05-06 22:18:10.000000000,2016-05-11 07:27:08.000000000,2016-05-11 07:27:08.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 14567}]","[{'number': 1, 'created': '2016-05-06 22:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/6fedd02ac86ba2d9eaa62699cc86d7ed224f6a67', 'message': 'Updated from global requirements\n\nChange-Id: I2e77f4cbb85a0e920bfa394cf021d55215d9eba5\n'}, {'number': 2, 'created': '2016-05-10 18:38:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/a32e0d29b00df38077ee91df5d60f4f51a8b8a2d', 'message': 'Updated from global requirements\n\nChange-Id: I2e77f4cbb85a0e920bfa394cf021d55215d9eba5\n'}]",0,313735,a32e0d29b00df38077ee91df5d60f4f51a8b8a2d,9,3,2,11131,,,0,"Updated from global requirements

Change-Id: I2e77f4cbb85a0e920bfa394cf021d55215d9eba5
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/35/313735/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6fedd02ac86ba2d9eaa62699cc86d7ed224f6a67,openstack/requirements,Babel>=2.3.4 # BSD,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",1,1
openstack%2Finstack-undercloud~master~I277c5982a0f7d08dfa4be208cf19970ce9280ed6,openstack/instack-undercloud,master,I277c5982a0f7d08dfa4be208cf19970ce9280ed6,TripleO common for custom Mistral actions,MERGED,2016-04-28 14:03:58.000000000,2016-05-11 07:25:17.000000000,2016-05-11 07:25:17.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-04-28 14:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/52b8bd905da078ba11d7d2fe5d0f6a486eb2ca90', 'message': 'TripleO common for custom Mistral actions\n\nThis patch updates instack so that we install the tripleo-common\npackage before running Mistral action population via puppet.\n\nChange-Id: I277c5982a0f7d08dfa4be208cf19970ce9280ed6\n'}, {'number': 2, 'created': '2016-05-05 14:40:34.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/b0ccd80938270fd32588170430388b6a48c536e5', 'message': 'TripleO common for custom Mistral actions\n\nThis patch updates instack so that we install the tripleo-common\npackage before running Mistral action population via puppet.\n\nChange-Id: I277c5982a0f7d08dfa4be208cf19970ce9280ed6\n'}]",2,310782,b0ccd80938270fd32588170430388b6a48c536e5,33,6,2,360,,,0,"TripleO common for custom Mistral actions

This patch updates instack so that we install the tripleo-common
package before running Mistral action population via puppet.

Change-Id: I277c5982a0f7d08dfa4be208cf19970ce9280ed6
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/82/310782/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,52b8bd905da078ba11d7d2fe5d0f6a486eb2ca90,mistral_workflows, # ensure TripleO common entrypoints for custom Mistral actions # are installed before performing the Mistral action population Package['tripleo-common'] ~> Exec['mistral-db-populate'],,4,0
openstack%2Fmonasca-common~master~Ic4834a27d36993cd9f4d2b6945cf108e7149d95b,openstack/monasca-common,master,Ic4834a27d36993cd9f4d2b6945cf108e7149d95b,FIX handling json data with multibyte characters,MERGED,2016-04-12 01:41:46.000000000,2016-05-11 07:13:58.000000000,2016-05-11 07:13:58.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16168}, {'_account_id': 16222}, {'_account_id': 17331}]","[{'number': 1, 'created': '2016-04-12 01:41:46.000000000', 'files': ['monasca_common/rest/utils.py'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/5c730775209a8f8f2d0291ddf5c1eeb419a3bdbc', 'message': 'FIX handling json data with multibyte characters\n\n""json.dumps"" function returns encoded value when specifying\n""ensure_ascii=False"", so it\'s not necessary to encode the returned\nvalue.\n\nChange-Id: Ic4834a27d36993cd9f4d2b6945cf108e7149d95b\nCloses-Bug: 1569112\n'}]",1,304360,5c730775209a8f8f2d0291ddf5c1eeb419a3bdbc,13,5,1,17331,,,0,"FIX handling json data with multibyte characters

""json.dumps"" function returns encoded value when specifying
""ensure_ascii=False"", so it's not necessary to encode the returned
value.

Change-Id: Ic4834a27d36993cd9f4d2b6945cf108e7149d95b
Closes-Bug: 1569112
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/60/304360/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_common/rest/utils.py'],1,5c730775209a8f8f2d0291ddf5c1eeb419a3bdbc,bug/1569112, return data, return data.encode(ENCODING),1,1
openstack%2Fkeystoneauth~master~I58db52427a2bac6cd56794429559771499dc7f5a,openstack/keystoneauth,master,I58db52427a2bac6cd56794429559771499dc7f5a,Expose is_admin_project in AccessInfo,MERGED,2016-05-10 04:13:24.000000000,2016-05-11 07:13:53.000000000,2016-05-11 07:13:53.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 13063}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-05-10 04:13:24.000000000', 'files': ['keystoneauth1/access/access.py', 'keystoneauth1/tests/unit/test_fixtures.py', 'keystoneauth1/tests/unit/access/test_v3_access.py', 'keystoneauth1/tests/unit/access/test_v2_access.py', 'keystoneauth1/fixture/v3.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ed7586380732842a0b52236a59499d191033ef11', 'message': 'Expose is_admin_project in AccessInfo\n\nThere is currently incomplete is_admin_project information in the token.\nWe can expose this already via keystoneauth because we have to handle\nthe default case where there is nothing in the token.\n\nThe default feels backwards but to handle the historical situation where\na deployment has not got the admin_project set all projects were in the\nadmin project so it must default to true for policy enforcement.\n\nAdds the fixture handling as well for testing with this enabled.\n\nChange-Id: I58db52427a2bac6cd56794429559771499dc7f5a\nCloses-Bug: #1577996\n'}]",0,314409,ed7586380732842a0b52236a59499d191033ef11,7,14,1,7191,,,0,"Expose is_admin_project in AccessInfo

There is currently incomplete is_admin_project information in the token.
We can expose this already via keystoneauth because we have to handle
the default case where there is nothing in the token.

The default feels backwards but to handle the historical situation where
a deployment has not got the admin_project set all projects were in the
admin project so it must default to true for policy enforcement.

Adds the fixture handling as well for testing with this enabled.

Change-Id: I58db52427a2bac6cd56794429559771499dc7f5a
Closes-Bug: #1577996
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/09/314409/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth1/access/access.py', 'keystoneauth1/tests/unit/test_fixtures.py', 'keystoneauth1/tests/unit/access/test_v3_access.py', 'keystoneauth1/tests/unit/access/test_v2_access.py', 'keystoneauth1/fixture/v3.py']",5,ed7586380732842a0b52236a59499d191033ef11,bug/1577996," oauth_consumer_id=None, audit_id=None, audit_chain_id=None, is_admin_project=None): if is_admin_project is not None: self.is_admin_project = is_admin_project @property def is_admin_project(self): return self.root.get('is_admin_project') @is_admin_project.setter def is_admin_project(self, value): self.root['is_admin_project'] = value @is_admin_project.deleter def is_admin_project(self): self.root.pop('is_admin_project', None) "," oauth_consumer_id=None, audit_id=None, audit_chain_id=None):",78,1
openstack%2Fpython-openstackclient~master~Ic0b41c1cab8c618904c7a6046d7493db5b74b430,openstack/python-openstackclient,master,Ic0b41c1cab8c618904c7a6046d7493db5b74b430,"Implement ""address scope show"" command",MERGED,2016-04-20 10:36:28.000000000,2016-05-11 07:11:43.000000000,2016-05-11 07:11:43.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-04-20 10:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fecb6099eae7e84b392f2fe0eb6e5dfff0c9990b', 'message': 'Implement ""address scope show"" command\n\nThis patch add a command that shows\naddress scope details\n\nChange-Id: Ic0b41c1cab8c618904c7a6046d7493db5b74b430\nPartial-Bug: #1566269\n'}, {'number': 2, 'created': '2016-05-07 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/32c4bb5e821c2eb89a4050b792656346002aadc4', 'message': 'Implement ""address scope show"" command\n\nThis patch add a command that supports\nshowing address scope details\n\nChange-Id: Ic0b41c1cab8c618904c7a6046d7493db5b74b430\nPartial-Bug: #1566269\n'}, {'number': 3, 'created': '2016-05-09 08:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cb2f1a7a3dc949f74461a6f6efdeb15612a6d67a', 'message': 'Implement ""address scope show"" command\n\nThis patch add a command that supports\nshowing address scope details\n\nChange-Id: Ic0b41c1cab8c618904c7a6046d7493db5b74b430\nPartial-Bug: #1566269\n'}, {'number': 4, 'created': '2016-05-11 02:09:44.000000000', 'files': ['openstackclient/tests/network/v2/test_address_scope.py', 'doc/source/command-objects/address-scope.rst', 'openstackclient/network/v2/address_scope.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/32da111c1757a884466814ac000fb7e662e6da42', 'message': 'Implement ""address scope show"" command\n\nThis patch add a command that supports\nshowing address scope details\n\nChange-Id: Ic0b41c1cab8c618904c7a6046d7493db5b74b430\nPartial-Bug: #1566269\n'}]",0,308259,32da111c1757a884466814ac000fb7e662e6da42,18,6,4,21514,,,0,"Implement ""address scope show"" command

This patch add a command that supports
showing address scope details

Change-Id: Ic0b41c1cab8c618904c7a6046d7493db5b74b430
Partial-Bug: #1566269
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/59/308259/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_address_scope.py', 'openstackclient/network/v2/address_scope.py', 'setup.cfg']",3,fecb6099eae7e84b392f2fe0eb6e5dfff0c9990b,bug/1566269, address_scope_show = openstackclient.network.v2.address_scope:ShowAddressScope,,83,0
openstack%2Fpython-openstackclient~master~Id14757011560cacf28011ba51841a8e23b824f33,openstack/python-openstackclient,master,Id14757011560cacf28011ba51841a8e23b824f33,"Implement ""address scope list"" command",MERGED,2016-04-20 10:36:28.000000000,2016-05-11 07:11:36.000000000,2016-05-11 07:11:36.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8276}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17776}, {'_account_id': 21514}]","[{'number': 1, 'created': '2016-04-20 10:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/748c1bf5b83fcfd08eb7bf9dfa80a299fce86cc3', 'message': 'Implement ""address scope list"" command\n\nThis patch add a command that\nlist address scopes\n\nChange-Id: Id14757011560cacf28011ba51841a8e23b824f33\nPartial-Bug: #1566269\n'}, {'number': 2, 'created': '2016-05-07 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ba786138747209691b47e6573783b1bdf8956bbf', 'message': 'Implement ""address scope list"" command\n\nThis patch add a command that supports\nlisting address scopes\n\nChange-Id: Id14757011560cacf28011ba51841a8e23b824f33\nPartial-Bug: #1566269\n'}, {'number': 3, 'created': '2016-05-09 08:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/60f5e6dee1446041571992ec07c03e0f05817794', 'message': 'Implement ""address scope list"" command\n\nThis patch add a command that supports\nlisting address scopes\n\nChange-Id: Id14757011560cacf28011ba51841a8e23b824f33\nPartial-Bug: #1566269\n'}, {'number': 4, 'created': '2016-05-11 02:09:44.000000000', 'files': ['openstackclient/tests/network/v2/fakes.py', 'openstackclient/tests/network/v2/test_address_scope.py', 'doc/source/command-objects/address-scope.rst', 'openstackclient/network/v2/address_scope.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aa5ff67e3fa2b9497218e9bdd4ac3fdf432e007c', 'message': 'Implement ""address scope list"" command\n\nThis patch add a command that supports\nlisting address scopes\n\nChange-Id: Id14757011560cacf28011ba51841a8e23b824f33\nPartial-Bug: #1566269\n'}]",14,308258,aa5ff67e3fa2b9497218e9bdd4ac3fdf432e007c,19,8,4,21514,,,0,"Implement ""address scope list"" command

This patch add a command that supports
listing address scopes

Change-Id: Id14757011560cacf28011ba51841a8e23b824f33
Partial-Bug: #1566269
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/58/308258/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/fakes.py', 'openstackclient/tests/network/v2/test_address_scope.py', 'openstackclient/network/v2/address_scope.py', 'setup.cfg']",4,748c1bf5b83fcfd08eb7bf9dfa80a299fce86cc3,bug/1566269, address_scope_list = openstackclient.network.v2.address_scope:ListAddressScope,,92,0
openstack%2Ftrove-dashboard~master~I92d0b0079d5b0b700e85effafcdc9665556e2ecd,openstack/trove-dashboard,master,I92d0b0079d5b0b700e85effafcdc9665556e2ecd,Database instance status message changed.,MERGED,2016-04-25 11:53:51.000000000,2016-05-11 07:09:35.000000000,2016-05-11 07:09:35.000000000,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 12673}]","[{'number': 1, 'created': '2016-04-25 11:53:51.000000000', 'files': ['trove_dashboard/content/databases/tables.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/31d7b669e9325e102d1c121647cd9ccfb2c9e757', 'message': 'Database instance status message changed.\n\nThe database instance messages which were confusing are changed\nfrom:\nBuild --> Building\nReboot --> Rebooting\nResize --> Resizing\n\nChange-Id: I92d0b0079d5b0b700e85effafcdc9665556e2ecd\nCloses-Bug: #1395897\n'}]",0,309944,31d7b669e9325e102d1c121647cd9ccfb2c9e757,13,5,1,20863,,,0,"Database instance status message changed.

The database instance messages which were confusing are changed
from:
Build --> Building
Reboot --> Rebooting
Resize --> Resizing

Change-Id: I92d0b0079d5b0b700e85effafcdc9665556e2ecd
Closes-Bug: #1395897
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/44/309944/1 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/content/databases/tables.py'],1,31d7b669e9325e102d1c121647cd9ccfb2c9e757,bug/1395897," u""Building"")), u""Rebooting"")), u""Resizing"")),"," u""Build"")), u""Reboot"")), u""Resize"")),",3,3
openstack%2Ftrove-dashboard~master~Ie134a69f57b92bc5fab97860d2839bd9c7f496ec,openstack/trove-dashboard,master,Ie134a69f57b92bc5fab97860d2839bd9c7f496ec,Fix the active attribute check,MERGED,2016-04-21 20:45:16.000000000,2016-05-11 07:06:25.000000000,2016-05-11 07:06:25.000000000,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 10215}, {'_account_id': 15321}]","[{'number': 1, 'created': '2016-04-21 20:45:16.000000000', 'files': ['trove_dashboard/content/databases/workflows/create_instance.py', 'trove_dashboard/content/database_clusters/forms.py', 'trove_dashboard/test/test_data/trove_data.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/fedcd092da745becbb3365b4ae0920e960ecd7e6', 'message': 'Fix the active attribute check\n\nThe datastore version object only contains the active attribute\nwhen the user is an admin user.  The datastore version object for\nnon-admin users does not have the active attribute.  The absence\nof the active attribute should be considered active.\n\nFixed the active attribute check to account for the case when the\nattribute is missing.\n\nAlso modified the test data to create a datastore version without\nthe active attribute to test this scenario.\n\nChange-Id: Ie134a69f57b92bc5fab97860d2839bd9c7f496ec\nCloses-Bug: #1573232\n'}]",0,309177,fedcd092da745becbb3365b4ae0920e960ecd7e6,12,4,1,12673,,,0,"Fix the active attribute check

The datastore version object only contains the active attribute
when the user is an admin user.  The datastore version object for
non-admin users does not have the active attribute.  The absence
of the active attribute should be considered active.

Fixed the active attribute check to account for the case when the
attribute is missing.

Also modified the test data to create a datastore version without
the active attribute to test this scenario.

Change-Id: Ie134a69f57b92bc5fab97860d2839bd9c7f496ec
Closes-Bug: #1573232
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/77/309177/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove_dashboard/content/databases/workflows/create_instance.py', 'trove_dashboard/content/database_clusters/forms.py', 'trove_dashboard/test/test_data/trove_data.py']",3,fedcd092da745becbb3365b4ae0920e960ecd7e6,bug/1573232,," ""active"": 1,",3,2
openstack%2Fnova~master~I0bf1806ad90e18915e4288b84cef3abab281863a,openstack/nova,master,I0bf1806ad90e18915e4288b84cef3abab281863a,Pass req to all API plugins,ABANDONED,2016-01-21 08:24:25.000000000,2016-05-11 07:04:16.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5538}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-01-21 08:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/916823cf63e4e23d39a9ca02320cbb676ea386a2', 'message': 'Pass req to all API plugins\n\nAPI plugins extend base server APIs(""create a server"", etc.) and\nthat mechanism is keeping the base implementations simple and clean\nas the doc[1].\nNow some plugins need to check a microversion which is specified on\nclient side. Then this patch makes base part pass req which contains\nthe microversion.\n\n[1]: https://github.com/openstack/nova/blob/master/doc/source/api_plugins.rst#modularity\n\nChange-Id: I0bf1806ad90e18915e4288b84cef3abab281863a\n'}, {'number': 2, 'created': '2016-01-21 11:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cbf7d62e3264bc8a1ca356819d0a81d116885edb', 'message': 'Pass req to all API plugins\n\nAPI plugins extend base server APIs(""create a server"", etc.) and\nthat mechanism keeps the base implementations simple and clean\nas the doc[1].\nNow some plugins need to check a microversion which is specified on\nclient side. Then this patch makes base part pass req which contains\nthe microversion.\n\n[1]: https://github.com/openstack/nova/blob/master/doc/source/api_plugins.rst#modularity\n\nChange-Id: I0bf1806ad90e18915e4288b84cef3abab281863a\n'}, {'number': 3, 'created': '2016-01-22 06:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de3c7c926bae6fae2bc128eabcc129fb9dcdb1a2', 'message': 'Pass req to all API plugins\n\nAPI plugins extend base server APIs(""create a server"", etc.) and\nthat mechanism keeps the base implementations simple and clean\nas the doc[1].\nNow some plugins need to check a microversion which is specified on\nclient side. Then this patch makes base part pass req which contains\nthe microversion.\n\n[1]: https://github.com/openstack/nova/blob/master/doc/source/api_plugins.rst#modularity\n\nChange-Id: I0bf1806ad90e18915e4288b84cef3abab281863a\n'}, {'number': 4, 'created': '2016-02-06 13:41:59.000000000', 'files': ['nova/api/openstack/compute/personality.py', 'nova/api/openstack/compute/block_device_mapping.py', 'nova/api/openstack/compute/disk_config.py', 'nova/api/openstack/compute/keypairs.py', 'nova/api/openstack/compute/multiple_create.py', 'nova/api/openstack/compute/scheduler_hints.py', 'nova/api/openstack/compute/access_ips.py', 'nova/api/openstack/compute/block_device_mapping_v1.py', 'nova/api/openstack/compute/servers.py', 'nova/api/openstack/compute/user_data.py', 'nova/tests/unit/api/openstack/compute/test_access_ips.py', 'nova/api/openstack/compute/availability_zone.py', 'nova/api/openstack/compute/security_groups.py', 'nova/api/openstack/compute/config_drive.py', 'nova/api/openstack/compute/preserve_ephemeral_rebuild.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/396184a8621eb920f03ee6a5d6f5888724a27597', 'message': 'Pass req to all API plugins\n\nAPI plugins extend base server APIs(""create a server"", etc.) and\nthat mechanism keeps the base implementations simple and clean\nas the doc[1].\nNow some plugins need to check a microversion which is specified on\nclient side. Then this patch makes base part pass req which contains\nthe microversion.\n\n[1]: https://github.com/openstack/nova/blob/master/doc/source/api_plugins.rst#modularity\n\nChange-Id: I0bf1806ad90e18915e4288b84cef3abab281863a\n'}]",0,270658,396184a8621eb920f03ee6a5d6f5888724a27597,46,15,4,6167,,,0,"Pass req to all API plugins

API plugins extend base server APIs(""create a server"", etc.) and
that mechanism keeps the base implementations simple and clean
as the doc[1].
Now some plugins need to check a microversion which is specified on
client side. Then this patch makes base part pass req which contains
the microversion.

[1]: https://github.com/openstack/nova/blob/master/doc/source/api_plugins.rst#modularity

Change-Id: I0bf1806ad90e18915e4288b84cef3abab281863a
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/270658/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/personality.py', 'nova/api/openstack/compute/block_device_mapping.py', 'nova/api/openstack/compute/disk_config.py', 'nova/api/openstack/compute/keypairs.py', 'nova/api/openstack/compute/multiple_create.py', 'nova/api/openstack/compute/scheduler_hints.py', 'nova/api/openstack/compute/access_ips.py', 'nova/api/openstack/compute/block_device_mapping_v1.py', 'nova/api/openstack/compute/servers.py', 'nova/api/openstack/compute/user_data.py', 'nova/api/openstack/compute/availability_zone.py', 'nova/api/openstack/compute/security_groups.py', 'nova/api/openstack/compute/config_drive.py']",13,916823cf63e4e23d39a9ca02320cbb676ea386a2,pass-microversion-to-module," def server_create(self, req, server_dict, create_kwargs, body_deprecated_param):"," def server_create(self, server_dict, create_kwargs, body_deprecated_param):",24,15
openstack%2Fqa-specs~master~I774908afb390fa268e52dbaa0f37af33f50f97eb,openstack/qa-specs,master,I774908afb390fa268e52dbaa0f37af33f50f97eb,Add make-api-schema-fit-to-swagger,ABANDONED,2016-03-25 00:16:19.000000000,2016-05-11 07:04:01.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 7812}, {'_account_id': 8556}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-03-25 00:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/49b537d95c5b9e9bbf659b1e61d9415a802198a3', 'message': 'Add make-api-schema-fit-to-swagger\n\nPartially-implements: bp make-api-schema-fit-to-swagger\n\nChange-Id: I774908afb390fa268e52dbaa0f37af33f50f97eb\n'}, {'number': 2, 'created': '2016-04-07 23:33:15.000000000', 'files': ['specs/tempest/make-api-schema-fit-to-swagger.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/b174a775d0a3bc2a6b8adacebf0fc8b4f50ce9d6', 'message': 'Add make-api-schema-fit-to-swagger\n\nPartially-implements: bp make-api-schema-fit-to-swagger\n\nChange-Id: I774908afb390fa268e52dbaa0f37af33f50f97eb\n'}]",3,297473,b174a775d0a3bc2a6b8adacebf0fc8b4f50ce9d6,13,10,2,6167,,,0,"Add make-api-schema-fit-to-swagger

Partially-implements: bp make-api-schema-fit-to-swagger

Change-Id: I774908afb390fa268e52dbaa0f37af33f50f97eb
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/73/297473/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/tempest/make-api-schema-fit-to-swagger.rst'],1,49b537d95c5b9e9bbf659b1e61d9415a802198a3,bp/make-api-schema-fit-to-swagger,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ========================================= Make API schema fit to Swagger definition ========================================= https://blueprints.launchpad.net/tempest/+spec/make-api-schema-fit-to-swagger Make API schemas of response body fit to Swagger way Problem description =================== OpenStack API-WG defined Swagger as a standard API documentation way. We can write API request/response body formats on Swagger definition with the part of JSON-Schema. On the other hand, Tempest contains API schemas for response body under directories tempest/api_schema/response and tempest/lib/api_schema/response. However these schemas are different from Swagger way because we created these schemas with our own way when we didn't know Swagger. So now these schema don't fit to our standard, and it will be great if these schemas fit to Swagger way for re-using it as the API docs, etc. Proposed change =============== The differences between Tempest and Swagger are small, it is enough to change like:: get_keypair = { - 'status_code': [200], - 'response_body': { + '200': { + 'description': '', + 'schema': { 'type': 'object', 'properties': { 'keypair': { ... The 'description' is required on Swagger specification, but the doc team just defines '' as it on samples. So this spec also does the same. And the corresponding validation side also is need to be changed to fit for the above schema changes. Alternatives ------------ The other outside tools can convert from current Tempest own schemas to Swagger format technically, but that would be redundant. Projects ======== * openstack/tempest Implementation ============== Assignee(s) ----------- Ken'ichi Ohmichi <ken-oomichi@wx.jp.nec.com> Milestones ---------- Target Milestone for completion: Newton-2 Work Items ---------- * Add a new validation way for both old schema and new schema formats. * Switch API schemas to new schema format. * Remove the validation way for old schema. Dependencies ============ Nothing References ========== * http://swagger.io/specification/#responseObject * https://bugs.launchpad.net/openstack-doc-tools/+bug/1534688 ",,93,0
openstack%2Fnova~master~I301bf9430d226944fb7f6a0920a4650c3f3a4a1d,openstack/nova,master,I301bf9430d226944fb7f6a0920a4650c3f3a4a1d,WIP: Swagger prototype,ABANDONED,2016-03-23 02:24:55.000000000,2016-05-11 07:03:47.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-23 02:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0f4082be566dbab83e57828bafb2532fc9292a7', 'message': 'WIP: prototype\n\nChange-Id: I301bf9430d226944fb7f6a0920a4650c3f3a4a1d\n'}, {'number': 2, 'created': '2016-03-23 04:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8505a86deff208b1c5cafff8a6e324daa57e8f93', 'message': 'WIP: prototype\n\nChange-Id: I301bf9430d226944fb7f6a0920a4650c3f3a4a1d\n'}, {'number': 3, 'created': '2016-03-25 00:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e2644baa8a1a3bb558788166b41b092d3e381c1', 'message': 'WIP: Swagger prototype\n\nChange-Id: I301bf9430d226944fb7f6a0920a4650c3f3a4a1d\n'}, {'number': 4, 'created': '2016-03-25 21:37:47.000000000', 'files': ['nova/api/openstack/wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f67ff5a70d82a136b61be2e3db07bf090d6aabfb', 'message': 'WIP: Swagger prototype\n\nChange-Id: I301bf9430d226944fb7f6a0920a4650c3f3a4a1d\n'}]",0,296146,f67ff5a70d82a136b61be2e3db07bf090d6aabfb,50,15,4,6167,,,0,"WIP: Swagger prototype

Change-Id: I301bf9430d226944fb7f6a0920a4650c3f3a4a1d
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/296146/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/wsgi.py'],1,a0f4082be566dbab83e57828bafb2532fc9292a7,swagger-poc," # Action swagger data for each resource self.swagger_actions = {} swagger_data = { ""description"": ""Take action on the certain resource"", ""parameters"": {}, ""responses"": {} } method = getattr(controller, method_name) self.wsgi_actions[key] = method swagger_param, swagger_resp = self.make_action_swagger_data(method) swagger_data[""parameters""] = swagger_param if swagger_resp not in swagger_data[""responses""]: swagger_data[""responses""].extend(swagger_resp) def make_action_swagger_data(self, method): parameter = { ""name"": method.wsgi_action, ""in"": ""body"", ""description"": method.__doc__ } response = { #NOTE: Here just stores an action name because the same success # status code is used on multiple action APIs on the same # resource and need to write a list of APIs on description # later. str(method.wsgi_code): method.wsgi_action } return parameter, response"," self.wsgi_actions[key] = getattr(controller, method_name)",30,1
openstack%2Fnova~master~Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8,openstack/nova,master,Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8,WIP: Add request schema debugging,ABANDONED,2016-04-15 07:52:30.000000000,2016-05-11 07:03:39.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-04-15 07:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/240914dc040457e6131e1de2df7ca8e59b154aa6', 'message': 'WIP: Add request schema debugging\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 2, 'created': '2016-04-15 17:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78eb04e9e33a5facb76afdcab5ee1bdf602c59bb', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz | awk -F ""Request JSON-Schema: "" \'{print $2}\' | awk -F "" __init__ "" \'{print $1}\'\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 3, 'created': '2016-04-15 17:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/756e15a2c451b885b3ad0c8b1c890e05cf75c617', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz | awk -F ""Request JSON-Schema: "" \'{print $2}\' | awk -F "" __init__ "" \'{print $1}\' | sort | uniq\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 4, 'created': '2016-04-15 17:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f2841dad7271c66172fb092542faac5b47df693', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz | awk -F ""Request JSON-Schema: "" \'{print $2}\' | awk -F "" __init__ "" \'{print $1}\' | sort | uniq\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 5, 'created': '2016-04-19 18:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/245c23c7f56b04292ce2d89897710a8305ee5d5c', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 6, 'created': '2016-04-19 20:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/606ac1049cc323aaa98e72cc3f52f8e9b1ca03e0', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 7, 'created': '2016-04-19 20:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32d8a893c0933742f06a9c805344e022394b06ce', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 8, 'created': '2016-04-20 17:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a94fb86ca57b123d88ee87f1b61a49bfcb546ef0', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 9, 'created': '2016-04-20 20:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63b7c4612b4d1917496804d6144c8d398449a938', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n(6) If creating files under a directory instead of putting the result on STDOUT:\n $ ./tools/jsonschema2parameters.py -w <dirname> bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 10, 'created': '2016-04-20 21:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0dd3d863d3298f741e500fe57fc16a504a2ca64', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n(6) If creating files under a directory instead of putting the result on STDOUT:\n $ ./tools/jsonschema2parameters.py -w <dirname> bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}, {'number': 11, 'created': '2016-04-20 21:31:46.000000000', 'files': ['nova/api/validation/__init__.py', 'tools/jsonschema2parameters.py', 'nova/api/openstack/extensions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bb383f8a8b728b1126880fe153f2bff284c2abea', 'message': 'WIP: Add request schema debugging\n\nHow to play:\n(1) Boot nova-api by typing \'recheck\' on the gerrit.\n(2) Wait for finishing gate jobs.\n(3) Get nova-api log with the following example:\n $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz\n(4) Pick up request schemas:\n $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt\n $ awk -F ""Request JSON-Schema: "" \'{print $2}\' foo.txt | awk -F "" __init__ "" \'{print $1}\' | sort | uniq > bar.txt\n(5) Check api-ref contents based on these schemas and fix them if finding bugs.\n $ ./tools/jsonschema2parameters.py bar.txt\n(6) If creating files under a directory instead of putting the result on STDOUT:\n $ ./tools/jsonschema2parameters.py -w <dirname> bar.txt\n\nChange-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8\n'}]",2,306281,bb383f8a8b728b1126880fe153f2bff284c2abea,70,14,11,6167,,,0,"WIP: Add request schema debugging

How to play:
(1) Boot nova-api by typing 'recheck' on the gerrit.
(2) Wait for finishing gate jobs.
(3) Get nova-api log with the following example:
 $ wget http://logs.openstack.org/81/306281/1/check/gate-tempest-dsvm-full/08d26b3/logs/screen-n-api.txt.gz
(4) Pick up request schemas:
 $ grep ""Request JSON-Schema:"" screen-n-api.txt.gz > foo.txt
 $ awk -F ""Request JSON-Schema: "" '{print $2}' foo.txt | awk -F "" __init__ "" '{print $1}' | sort | uniq > bar.txt
(5) Check api-ref contents based on these schemas and fix them if finding bugs.
 $ ./tools/jsonschema2parameters.py bar.txt
(6) If creating files under a directory instead of putting the result on STDOUT:
 $ ./tools/jsonschema2parameters.py -w <dirname> bar.txt

Change-Id: Ifd5d7ab89a69e20dc4b989b9ad37ef035278cca8
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/306281/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/extensions.py', 'nova/api/validation/__init__.py']",2,240914dc040457e6131e1de2df7ca8e59b154aa6,provide-schemas," if min_version in (None, '2.1'): func.schema = request_body_schema ",,21,0
openstack%2Ftrove-dashboard~master~I5fd1b7655e5194389963705bd96d6a90ce099e7d,openstack/trove-dashboard,master,I5fd1b7655e5194389963705bd96d6a90ce099e7d,Add missing mocks to tests,MERGED,2016-05-10 21:50:08.000000000,2016-05-11 06:57:03.000000000,2016-05-11 06:57:03.000000000,"[{'_account_id': 3}, {'_account_id': 10215}, {'_account_id': 21668}]","[{'number': 1, 'created': '2016-05-10 21:50:08.000000000', 'files': ['trove_dashboard/content/databases/tests.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/ab3b0ee780257857b51b6b7b0752a4feacec27d5', 'message': 'Add missing mocks to tests\n\nA horizon change to more strictly detect missing mocks caused test\nfailures.\n\nNeed to add the missing mocks to the failing tests.\n\nChange-Id: I5fd1b7655e5194389963705bd96d6a90ce099e7d\nCloses-Bug: #1580353\n'}]",0,314787,ab3b0ee780257857b51b6b7b0752a4feacec27d5,9,3,1,12673,,,0,"Add missing mocks to tests

A horizon change to more strictly detect missing mocks caused test
failures.

Need to add the missing mocks to the failing tests.

Change-Id: I5fd1b7655e5194389963705bd96d6a90ce099e7d
Closes-Bug: #1580353
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/87/314787/1 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/content/databases/tests.py'],1,ab3b0ee780257857b51b6b7b0752a4feacec27d5,bug/1580353," @test.create_stubs({ api.trove: ('instance_get', 'flavor_get', 'root_show') }) api.trove.root_show(IsA(http.HttpRequest), database.id) \ .AndReturn(self.database_user_roots.first()) api.trove: ('flavor_list', 'instance_list', api.trove.flavor_list(IsA(http.HttpRequest))\ .AndReturn(self.flavors.list()) api.trove: ('flavor_list', 'instance_list', api.trove.flavor_list(IsA(http.HttpRequest))\ .AndReturn(self.flavors.list())"," @test.create_stubs( {api.trove: ('instance_get', 'flavor_get',)}) api.trove: ('instance_list', api.trove: ('instance_list',",11,4
openstack%2Fpython-openstackclient~master~Ie028058c759b9511d105a530d7e89b841865e7d6,openstack/python-openstackclient,master,Ie028058c759b9511d105a530d7e89b841865e7d6,"Implement ""address scope delete"" command",MERGED,2016-04-20 10:36:28.000000000,2016-05-11 06:53:56.000000000,2016-05-11 06:53:56.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17776}, {'_account_id': 21514}]","[{'number': 1, 'created': '2016-04-20 10:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9150a1c81cd7df1fd0113464adedd33877c981cd', 'message': 'Implement ""address scope delete"" command\n\nThis patch add a command that supports\ndelete a address scope\n\nChange-Id: Ie028058c759b9511d105a530d7e89b841865e7d6\nPartial-Bug: #1566269\n'}, {'number': 2, 'created': '2016-05-07 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/74024c803a13bee0ab7a6588fb7a5585a97b0fc7', 'message': 'Implement ""address scope delete"" command\n\nThis patch add a command that supports\ndeleting a address scope\n\nChange-Id: Ie028058c759b9511d105a530d7e89b841865e7d6\nPartial-Bug: #1566269\n'}, {'number': 3, 'created': '2016-05-09 08:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/01401d12ae9a03a1a50cc0513def866229ee90a3', 'message': 'Implement ""address scope delete"" command\n\nThis patch add a command that supports\ndeleting a address scope\n\nChange-Id: Ie028058c759b9511d105a530d7e89b841865e7d6\nPartial-Bug: #1566269\n'}, {'number': 4, 'created': '2016-05-11 02:09:44.000000000', 'files': ['openstackclient/tests/network/v2/test_address_scope.py', 'doc/source/command-objects/address-scope.rst', 'openstackclient/network/v2/address_scope.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4cb5e0bc7959694db70d11c6be8589f1c20d787c', 'message': 'Implement ""address scope delete"" command\n\nThis patch add a command that supports\ndeleting a address scope\n\nChange-Id: Ie028058c759b9511d105a530d7e89b841865e7d6\nPartial-Bug: #1566269\n'}]",6,308257,4cb5e0bc7959694db70d11c6be8589f1c20d787c,20,6,4,21514,,,0,"Implement ""address scope delete"" command

This patch add a command that supports
deleting a address scope

Change-Id: Ie028058c759b9511d105a530d7e89b841865e7d6
Partial-Bug: #1566269
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/57/308257/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_address_scope.py', 'openstackclient/network/v2/address_scope.py', 'setup.cfg']",3,9150a1c81cd7df1fd0113464adedd33877c981cd,bug/1566269, address_scope_delete = openstackclient.network.v2.address_scope:DeleteAddressScope,,58,0
openstack%2Fopenstack-manuals~master~I10a5bfc3849be463547f389b65ba2c8c936e0f97,openstack/openstack-manuals,master,I10a5bfc3849be463547f389b65ba2c8c936e0f97,Imported Translations from Zanata,MERGED,2016-05-11 06:29:47.000000000,2016-05-11 06:53:49.000000000,2016-05-11 06:53:49.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-11 06:29:47.000000000', 'files': ['doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e9d18a962688b0194969d85db475d51e5b631e38', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I10a5bfc3849be463547f389b65ba2c8c936e0f97\n'}]",0,314879,e9d18a962688b0194969d85db475d51e5b631e38,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I10a5bfc3849be463547f389b65ba2c8c936e0f97
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/314879/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po']",3,e9d18a962688b0194969d85db475d51e5b631e38,zanata/translations,"""POT-Creation-Date: 2016-05-11 02:04+0000\n""""PO-Revision-Date: 2016-05-10 11:57+0000\n"" ""Last-Translator: Sungjin Kang <gang.sungjin@gmail.com>\n""msgid """" ""For more information about how to download and build images, see `OpenStack "" ""Virtual Machine Image Guide <http://docs.openstack.org/image-guide/>`__. For "" ""information about how to manage images, see the `OpenStack End User Guide "" ""<http://docs.openstack.org/user-guide/common/cli_manage_images.html>`__."" msgstr """" ""이미지를 다운받고 빌드하는 방법에 대한 정보는 `OpenStack Virtual Machine "" ""Image Guide <http://docs.openstack.org/image-guide/>`__ 를 참고 하십시오. 이"" ""미지 관리에 대한 정보는 `OpenStack End User Guide <http://docs.openstack.org/"" ""user-guide/common/cli_manage_images.html>`__ 를 참고 하십시오."" msgid ""For pre-release testing, use the master repository:"" msgstr ""릴리즈 전 테스트를 위해 마스터 저장소를 사용합니다:"" msgid ""Ignore any deprecation messages in this output."" msgstr ""출력물 중 deprecation 메시지는 무시합니다."" msgid """" ""The Newton release is available directly through the official Debian "" ""backports repository. To use this repository, follow the instruction from "" ""the official `Debian website <http://backports.debian.org/Instructions/>`_, "" ""which basically suggest doing the following steps:"" msgstr """" ""Newton 릴리즈는 공식 Debian backports 저장소에서 직접 사용할 수 있습니다. 이 "" ""저장소를 사용하려면, 공식 `Debian website <http://backports.debian.org/"" ""Instructions/>`_ 에 있는 지시를 따라 다음 단계를 진행하십시오:"" ","""POT-Creation-Date: 2016-05-04 01:03+0000\n""""PO-Revision-Date: 2016-04-29 10:37+0000\n"" ""Last-Translator: Ian Y. Choi <ianyrchoi@gmail.com>\n""msgid """" ""The Mitaka release is available directly through the official Debian "" ""backports repository. To use this repository, follow the instruction from "" ""the official `Debian website <http://backports.debian.org/Instructions/>`_, "" ""which basically suggest doing the following steps:"" msgstr """" ""Mitaka 릴리즈는 공식 Debian backports 저장소를 통하여 직접 사용 가능합니다. "" ""해당 저장소를 사용하기 위해, 공식 `Debian website <http://backports.debian."" ""org/Instructions/>`_ 에서 안내를 살펴봅니다. 기본적으로 다음 단계를 수행하도"" ""록 권장합니다:"" msgid ""This guide documents OpenStack Mitaka release."" msgstr ""이 가이드는 OpenStack Mitaka 릴리즈를 문서화합니다."" ",194,52
openstack%2Fpython-heatclient~master~I489271f8fca94b1a1cb3ad30790042fe7468338c,openstack/python-heatclient,master,I489271f8fca94b1a1cb3ad30790042fe7468338c,use thread safe fnmatch,MERGED,2016-04-20 20:22:07.000000000,2016-05-11 06:52:26.000000000,2016-05-11 06:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 8289}, {'_account_id': 12363}]","[{'number': 1, 'created': '2016-04-20 20:22:07.000000000', 'files': ['heatclient/common/hook_utils.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/38c0684a6be97fd1cb74e7bb1e426e1d6a525d65', 'message': ""use thread safe fnmatch\n\nfnmatch is not thread safe in python <2.7.10, let's use the safe\none in oslo.utils\n\nChange-Id: I489271f8fca94b1a1cb3ad30790042fe7468338c\nref: https://hg.python.org/cpython/rev/fe12c34c39eb\n""}]",0,308568,38c0684a6be97fd1cb74e7bb1e426e1d6a525d65,9,3,1,6676,,,0,"use thread safe fnmatch

fnmatch is not thread safe in python <2.7.10, let's use the safe
one in oslo.utils

Change-Id: I489271f8fca94b1a1cb3ad30790042fe7468338c
ref: https://hg.python.org/cpython/rev/fe12c34c39eb
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/68/308568/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/common/hook_utils.py'],1,38c0684a6be97fd1cb74e7bb1e426e1d6a525d65,use-oslo.utils.fnmatch,from oslo_utils import fnmatch ,import fnmatch,2,1
openstack%2Fopenstack-manuals~stable%2Fmitaka~I74d13473177e4ab6d9fac52dd1fc5588cf2cd02b,openstack/openstack-manuals,stable/mitaka,I74d13473177e4ab6d9fac52dd1fc5588cf2cd02b,Imported Translations from Zanata,MERGED,2016-05-11 06:31:43.000000000,2016-05-11 06:49:44.000000000,2016-05-11 06:49:44.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-11 06:31:43.000000000', 'files': ['doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5fb6d63bf2be1d84d13264a9da1bd77d427cbd82', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I74d13473177e4ab6d9fac52dd1fc5588cf2cd02b\n'}]",0,314880,5fb6d63bf2be1d84d13264a9da1bd77d427cbd82,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I74d13473177e4ab6d9fac52dd1fc5588cf2cd02b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/80/314880/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po']",5,5fb6d63bf2be1d84d13264a9da1bd77d427cbd82,zanata/translations,"""POT-Creation-Date: 2016-05-10 22:21+0000\n""""PO-Revision-Date: 2016-05-10 11:59+0000\n"" ""Last-Translator: Sungjin Kang <gang.sungjin@gmail.com>\n""msgid ""Ignore any deprecation messages in this output."" msgstr ""출력 중 deprecation 메시지는 무시합니다."" ","""POT-Creation-Date: 2016-05-04 07:18+0000\n""""PO-Revision-Date: 2016-05-05 06:17+0000\n"" ""Last-Translator: Ian Y. Choi <ianyrchoi@gmail.com>\n""msgid """" ""For pre-release testing on CentOS or RHEL, install the ``yum-plugin-"" ""priorities`` package so that the Delorean repository takes precedence over "" ""the main RDO repositories, and use the Delorean repositories:"" msgstr """" ""CentOS 또는 RHEL에 대한 pre-release 테스팅을 위해서는 ``yum-plugin-"" ""priorities`` 패키지를 설치합니다. Delorean 저장소가 메인 RDO 저장소보다 높은 "" ""우선 순위를 가지며, Delorean 저장소를 사용합니다:"" msgid ""For pre-release testing, use the staging repository:"" msgstr ""pre-release 테스팅을 위해, staging 저장소를 사용합니다:"" msgid """" ""This guide is a work-in-progress and is subject to updates frequently. Pre-"" ""release packages have been used for testing, and some instructions may not "" ""work with final versions. Please help us make this guide better by reporting "" ""any errors you encounter."" msgstr """" ""이 가이드는 작업 중인 상태이며 빈번하게 업데이트될 수 있습니다. 사전 릴리즈 "" ""패키지들이 테스트 목적으로 사용되었고, 몇몇 안내는 최종 버전에서 동작하지 않"" ""을 수 있습니다. 겪는 오류가 있다면 보고함으로써 해당 가이드를 보다 나아지도"" ""록 도와주십시오."" ",749,73
openstack%2Fnova~master~If56965c88d910d4d3ed2232efa91b2033ed34468,openstack/nova,master,If56965c88d910d4d3ed2232efa91b2033ed34468,Move config options from nova/api directory (2),MERGED,2016-04-21 21:48:32.000000000,2016-05-11 06:39:25.000000000,2016-05-10 22:51:29.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 18602}]","[{'number': 1, 'created': '2016-04-21 21:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e3c13d6f0b8788cb50b1bc267e230566edae5b0', 'message': 'Move config options from nova/api directory (2)\n\nThis is the second patch moving config options from the nova/api\ndirectory. In this patch, the openstack common options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If56965c88d910d4d3ed2232efa91b2033ed34468\n'}, {'number': 2, 'created': '2016-04-27 09:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f02e0702734b34b97320670722e32ef12190c24', 'message': 'Move config options from nova/api directory (2)\n\nThis is the second patch moving config options from the nova/api\ndirectory. In this patch, the openstack common options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If56965c88d910d4d3ed2232efa91b2033ed34468\n'}, {'number': 3, 'created': '2016-04-28 16:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd92c21b42ef1e010d3bf93f9b187fb232c3efda', 'message': 'Move config options from nova/api directory (2)\n\nThis is the second patch moving config options from the nova/api\ndirectory. In this patch, the openstack common options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If56965c88d910d4d3ed2232efa91b2033ed34468\n'}, {'number': 4, 'created': '2016-05-06 18:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bfbc4c26216ddaec36029125cd9d84827bb144f', 'message': 'Move config options from nova/api directory (2)\n\nThis is the second patch moving config options from the nova/api\ndirectory. In this patch, the openstack common options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If56965c88d910d4d3ed2232efa91b2033ed34468\n'}, {'number': 5, 'created': '2016-05-09 20:07:33.000000000', 'files': ['nova/conf/osapi_v21.py', 'nova/api/openstack/__init__.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/api/opts.py', 'nova/conf/__init__.py', 'nova/conf/api.py', 'nova/api/openstack/common.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/39e2bc9cfcab1cc4712c1c1f0adffadb48c57c42', 'message': 'Move config options from nova/api directory (2)\n\nThis is the second patch moving config options from the nova/api\ndirectory. In this patch, the openstack common options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: If56965c88d910d4d3ed2232efa91b2033ed34468\n'}]",8,309194,39e2bc9cfcab1cc4712c1c1f0adffadb48c57c42,101,19,5,1063,,,0,"Move config options from nova/api directory (2)

This is the second patch moving config options from the nova/api
directory. In this patch, the openstack common options are moved. A
subsequent patch will enhance the help text for these options.

Blueprint centralize-config-options-newton

Change-Id: If56965c88d910d4d3ed2232efa91b2033ed34468
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/309194/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/osapi_v21.py', 'nova/api/openstack/__init__.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/api/opts.py', 'nova/conf/__init__.py', 'nova/conf/api.py', 'nova/api/openstack/common.py', 'nova/api/openstack/compute/servers.py']",8,6e3c13d6f0b8788cb50b1bc267e230566edae5b0,bp/centralize-config-options-newton,,"CONF.import_opt('extensions_blacklist', 'nova.api.openstack', group='osapi_v21') CONF.import_opt('extensions_whitelist', 'nova.api.openstack', group='osapi_v21')",73,55
openstack%2Fapi-site~master~I3700860ed836e53f04e14a59ad912fe4aae0352a,openstack/api-site,master,I3700860ed836e53f04e14a59ad912fe4aae0352a,[api-ref] Added tenantId response parameter,ABANDONED,2016-04-20 07:54:00.000000000,2016-05-11 06:39:18.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 17207}, {'_account_id': 20863}]","[{'number': 1, 'created': '2016-04-20 07:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/a79cf94ed79549e5f8b0cf3a80edafb15c08c4ba', 'message': '[api-ref] Added tenant_id optional response parameter\n\nChange-Id: I3700860ed836e53f04e14a59ad912fe4aae0352a\nCloses-Bug: #1572164\n'}, {'number': 2, 'created': '2016-04-20 13:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/9175b73228e396736c53a94cb8ce83df055ff9af', 'message': '[api-ref] Added tenantId optional response parameter\n\nChange-Id: I3700860ed836e53f04e14a59ad912fe4aae0352a\nCloses-Bug: #1572164\n'}, {'number': 3, 'created': '2016-04-21 05:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/d3e844f2d998ba14fbefd74d794802623dd2783c', 'message': '[api-ref] Added tenantId response parameter\n\nChange-Id: I3700860ed836e53f04e14a59ad912fe4aae0352a\nCloses-Bug: #1572164\n'}, {'number': 4, 'created': '2016-04-28 14:28:34.000000000', 'files': ['api-ref/src/wadls/identity-api/src/v2.0/wadl/identity-admin.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/626147aab70390d44725d84539087d206d9d0bd9', 'message': '[api-ref] Added tenantId response parameter\n\nChange-Id: I3700860ed836e53f04e14a59ad912fe4aae0352a\nCloses-Bug: #1572164\n'}]",4,308178,626147aab70390d44725d84539087d206d9d0bd9,16,4,4,20863,,,0,"[api-ref] Added tenantId response parameter

Change-Id: I3700860ed836e53f04e14a59ad912fe4aae0352a
Closes-Bug: #1572164
",git fetch https://review.opendev.org/openstack/api-site refs/changes/78/308178/3 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/identity-api/src/v2.0/wadl/identity-admin.wadl'],1,a79cf94ed79549e5f8b0cf3a80edafb15c08c4ba,bug/1572164," <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""tenantId"" style=""plain"" type=""xsd:string"" required=""false""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"">The tenant ID.</wadl:doc> </param>",,4,0
openstack%2Fsearchlight~master~I11e7ab693c06fef540d6c949800383fb318ea71e,openstack/searchlight,master,I11e7ab693c06fef540d6c949800383fb318ea71e,Remove version parameter from index helper save method,ABANDONED,2016-03-02 16:12:50.000000000,2016-05-11 06:36:56.000000000,,"[{'_account_id': 3}, {'_account_id': 10063}, {'_account_id': 16150}]","[{'number': 1, 'created': '2016-03-02 16:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/33fa5a65803f2d9657869617866e6bcb5ddb2dff', 'message': 'WIP Remove version parameter from index helper save method\n\nRemove version parameter from index helper save method, instead\n_version and _version_type should be put into documents before\npassing them to the index helper save method, this will neat up\nthe code. Also change update image member method, use update\ninstead of index operation. Need some test and verification.\n\nChange-Id: I11e7ab693c06fef540d6c949800383fb318ea71e\n'}, {'number': 2, 'created': '2016-03-03 15:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/1ede355fbf34771c5779431d88577ee1e5f3eb74', 'message': 'Remove version parameter from index helper save method\n\nRemove version parameter from index helper save method, instead\n_version and should be put into documents before\npassing them to the index helper save method. Also change update\nimage member method, use update instead of index operation.\n\nChange-Id: I11e7ab693c06fef540d6c949800383fb318ea71e\n'}, {'number': 3, 'created': '2016-03-07 06:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/9fc7e12a76bd809229ae68dda69b562767fe6568', 'message': 'Remove version parameter from index helper save method\n\nRemove version parameter from index helper save method, instead\n_version and should be put into documents before\npassing them to the index helper save method. Also change update\nimage member method, use update instead of index operation.\n\nChange-Id: I11e7ab693c06fef540d6c949800383fb318ea71e\n'}, {'number': 4, 'created': '2016-03-09 06:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/4c7cd90c13abef022baaff7da47549dd0d0c1658', 'message': 'Remove version parameter from index helper save method\n\nRemove version parameter from index helper save method, instead\n_version and should be put into documents before\npassing them to the index helper save method. Also change update\nimage member method, use update instead of index operation.\n\nChange-Id: I11e7ab693c06fef540d6c949800383fb318ea71e\n'}, {'number': 5, 'created': '2016-03-11 05:31:42.000000000', 'files': ['searchlight/elasticsearch/plugins/glance/metadefs_notification_handler.py', 'searchlight/tests/unit/test_indexing_helper.py', 'searchlight/elasticsearch/plugins/utils.py', 'searchlight/tests/unit/test_glance_image_plugin.py', 'searchlight/elasticsearch/plugins/neutron/notification_handlers.py', 'searchlight/tests/functional/test_api.py', 'searchlight/tests/unit/test_glance_metadefs_plugin.py', 'searchlight/elasticsearch/plugins/base.py', 'searchlight/elasticsearch/plugins/designate/notification_handlers.py', 'searchlight/elasticsearch/plugins/nova/servers_notification_handler.py', 'searchlight/elasticsearch/plugins/glance/images_notification_handler.py'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/ca03e330aae1e200d7b48b5d413e8e40d1c1bfd7', 'message': 'Remove version parameter from index helper save method\n\nRemove version parameter from index helper save method, instead\n_version and should be put into documents before\npassing them to the index helper save method. Also change update\nimage member method, use update instead of index operation.\n\nChange-Id: I11e7ab693c06fef540d6c949800383fb318ea71e\n'}]",0,287293,ca03e330aae1e200d7b48b5d413e8e40d1c1bfd7,17,3,5,16150,,,0,"Remove version parameter from index helper save method

Remove version parameter from index helper save method, instead
_version and should be put into documents before
passing them to the index helper save method. Also change update
image member method, use update instead of index operation.

Change-Id: I11e7ab693c06fef540d6c949800383fb318ea71e
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/93/287293/3 && git format-patch -1 --stdout FETCH_HEAD,"['searchlight/elasticsearch/plugins/glance/metadefs_notification_handler.py', 'searchlight/tests/unit/test_indexing_helper.py', 'searchlight/elasticsearch/plugins/utils.py', 'searchlight/tests/unit/test_glance_image_plugin.py', 'searchlight/tests/utils.py', 'searchlight/tests/functional/test_api.py', 'searchlight/tests/unit/test_glance_metadefs_plugin.py', 'searchlight/elasticsearch/plugins/base.py', 'searchlight/elasticsearch/plugins/designate/notification_handlers.py', 'searchlight/elasticsearch/plugins/nova/servers_notification_handler.py', 'searchlight/elasticsearch/plugins/glance/images_notification_handler.py']",11,33fa5a65803f2d9657869617866e6bcb5ddb2dff,refactor_external_version,"from searchlight.elasticsearch.plugins.utils \ import add_version add_version(payload, version=self.get_version(payload, timestamp)) self.index_helper.save_document(payload) self.index_helper.update_document(payload, image_id, update_as_script=False)"," self.index_helper.save_document( payload, version=self.get_version(payload, timestamp)) self.index_helper.save_document(payload)",284,272
openstack%2Fironic~master~I9ff64a93aca910fc63cd878a42b31dffb8263f8d,openstack/ironic,master,I9ff64a93aca910fc63cd878a42b31dffb8263f8d,Updated from global requirements,MERGED,2016-05-06 22:17:34.000000000,2016-05-11 06:35:23.000000000,2016-05-10 21:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 13719}, {'_account_id': 14525}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-05-06 22:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5b73346e128ef2207392f9384275e1cb65486e2d', 'message': 'Updated from global requirements\n\nChange-Id: I9ff64a93aca910fc63cd878a42b31dffb8263f8d\n'}, {'number': 2, 'created': '2016-05-10 00:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/69c31052f2c1a9036fc706c7ab16dcd19e88e1e6', 'message': 'Updated from global requirements\n\nChange-Id: I9ff64a93aca910fc63cd878a42b31dffb8263f8d\n'}, {'number': 3, 'created': '2016-05-10 18:37:38.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/af937a303aba58f0359717861f3f1238820ad519', 'message': 'Updated from global requirements\n\nChange-Id: I9ff64a93aca910fc63cd878a42b31dffb8263f8d\n'}]",0,313729,af937a303aba58f0359717861f3f1238820ad519,21,7,3,11131,,,0,"Updated from global requirements

Change-Id: I9ff64a93aca910fc63cd878a42b31dffb8263f8d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/313729/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,5b73346e128ef2207392f9384275e1cb65486e2d,openstack/requirements,Babel>=2.3.4 # BSD,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",1,1
openstack%2Fpython-ironicclient~master~I2ac9ffe89dc2e99d0efd8f8753620cff9534cd7a,openstack/python-ironicclient,master,I2ac9ffe89dc2e99d0efd8f8753620cff9534cd7a,improve readme contents,ABANDONED,2015-10-15 10:15:44.000000000,2016-05-11 06:21:24.000000000,,"[{'_account_id': 3}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-10-15 10:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8d1913985a9552081803c9f4af59fee3acbc34d5', 'message': 'improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I2ac9ffe89dc2e99d0efd8f8753620cff9534cd7a\n'}, {'number': 2, 'created': '2015-11-19 08:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5de8855683b3f4adb9a3596fbc00552d0e9adc0b', 'message': 'improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I2ac9ffe89dc2e99d0efd8f8753620cff9534cd7a\n'}, {'number': 3, 'created': '2016-01-03 10:08:17.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/06ee62a618524e85c37589e8d66818c22e341086', 'message': 'improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I2ac9ffe89dc2e99d0efd8f8753620cff9534cd7a\n'}]",4,235228,06ee62a618524e85c37589e8d66818c22e341086,15,4,3,12404,,,0,"improve readme contents

Add more information in README.rst

Change-Id: I2ac9ffe89dc2e99d0efd8f8753620cff9534cd7a
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/28/235228/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8d1913985a9552081803c9f4af59fee3acbc34d5,improve-readme,.. image:: https://img.shields.io/pypi/v/python-ironicclient.svg :target: https://pypi.python.org/pypi/python-ironicclient/ :alt: Latest Version .. image:: https://img.shields.io/pypi/dm/python-ironicclient.svg :target: https://pypi.python.org/pypi/python-ironicclient/ :alt: Downloads * `PyPi`_ - package installation * `Online Documentation`_ * `Launchpad project`_ - release management * `Blueprints`_ - feature specifications * `Bugs`_ - issue tracking * `Source`_ * `Specs`_ * `How to Contribute`_ .. _PyPi: https://pypi.python.org/pypi/python-ironicclient .. _Online Documentation: http://docs.openstack.org/developer/python-ironicclient .. _Launchpad project: https://launchpad.net/python-ironicclient .. _Blueprints: https://blueprints.launchpad.net/python-ironicclient .. _Bugs: https://bugs.launchpad.net/python-ironicclient .. _Source: https://git.openstack.org/cgit/openstack/python-ironicclient .. _How to Contribute: http://docs.openstack.org/infra/manual/developers.html .. _Specs: http://specs.openstack.org/openstack/ironic-specs/,* Documentation: http://docs.openstack.org/developer/python-ironicclient * Source: http://git.openstack.org/cgit/openstack/python-ironicclient * Bugs: http://bugs.launchpad.net/python-ironicclient,25,3
openstack%2Fpython-tripleoclient~master~I537c6a1d2945de948993610a1a58f18ffe0ef598,openstack/python-tripleoclient,master,I537c6a1d2945de948993610a1a58f18ffe0ef598,Improve readme contents,ABANDONED,2015-10-15 10:25:02.000000000,2016-05-11 06:20:38.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 9317}, {'_account_id': 10239}, {'_account_id': 11997}]","[{'number': 1, 'created': '2015-10-15 10:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/768d19517ee49d8285255b45d74cfa9326877919', 'message': 'improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I537c6a1d2945de948993610a1a58f18ffe0ef598\n'}, {'number': 2, 'created': '2015-10-16 08:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6e5dd860e6f474921de280813d8b36d13f75eb04', 'message': 'Improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I537c6a1d2945de948993610a1a58f18ffe0ef598\n'}, {'number': 3, 'created': '2015-11-19 08:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fbbfcf241d56650472b31874621bd77cef68396c', 'message': 'Improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I537c6a1d2945de948993610a1a58f18ffe0ef598\n'}, {'number': 4, 'created': '2015-11-19 10:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/75fff97d724212ad92cd3d6b19b106e63b29a456', 'message': 'Improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I537c6a1d2945de948993610a1a58f18ffe0ef598\n'}, {'number': 5, 'created': '2016-01-03 10:09:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2e38966a92d2c8595ac0358e02d0e189bbd44209', 'message': 'Improve readme contents\n\nAdd more information in README.rst\n\nChange-Id: I537c6a1d2945de948993610a1a58f18ffe0ef598\n'}]",4,235234,2e38966a92d2c8595ac0358e02d0e189bbd44209,23,6,5,12404,,,0,"Improve readme contents

Add more information in README.rst

Change-Id: I537c6a1d2945de948993610a1a58f18ffe0ef598
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/34/235234/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,768d19517ee49d8285255b45d74cfa9326877919,improve-readme,.. image:: https://img.shields.io/pypi/v/python-tripleoclient.svg :target: https://pypi.python.org/pypi/python-tripleoclient/ :alt: Latest Version .. image:: https://img.shields.io/pypi/dm/python-tripleoclient.svg :target: https://pypi.python.org/pypi/python-tripleoclient/ :alt: Downloads * `PyPi`_ - package installation * `Source`_ * `How to Contribute`_ .. _PyPi: https://pypi.python.org/pypi/python-tripleoclient .. _Source: https://git.openstack.org/cgit/openstack/python-tripleoclient .. _How to Contribute: http://docs.openstack.org/infra/manual/developers.html ,,17,0
openstack%2Fheat~master~I595255332abc8bbe49dd6f0986e5dfee72be6510,openstack/heat,master,I595255332abc8bbe49dd6f0986e5dfee72be6510,Support update external_id,ABANDONED,2015-12-29 09:43:10.000000000,2016-05-11 06:19:37.000000000,,"[{'_account_id': 3}, {'_account_id': 12404}]","[{'number': 1, 'created': '2015-12-29 09:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/868b3aa0902a4f232c7c7804d30dd7e5d14de49d', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 2, 'created': '2015-12-29 16:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/75edc98ea4197d57a2ca440485fefa3b61913812', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 3, 'created': '2016-01-14 08:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e1d7fb85656e7e25124c316ca3d1393e661c735', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 4, 'created': '2016-01-17 05:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c82d0cae706b7ca2174b9303a9db93e4d683cc7a', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 5, 'created': '2016-04-03 10:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/532f3d7b477cd766626d15110ae0623f05a6aefc', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 6, 'created': '2016-04-03 12:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55733c2809458f19d73eb26fb9eef7408969e10b', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 7, 'created': '2016-04-03 17:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b252f70c2e68ddd39ed6b424249a647031acc2d', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}, {'number': 8, 'created': '2016-04-03 18:32:25.000000000', 'files': ['doc/source/template_guide/hot_spec.rst', 'heat/engine/resource.py', 'heat/tests/test_resource.py', 'heat_integrationtests/functional/test_external_ref.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/737b312f4704fd0b674c35866066fc0221749136', 'message': 'Support update external_id\n\nAdd update external_id ability to allow heat to take over the resource.\n\nblueprint external-resources\n\nChange-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510\n'}]",0,262173,737b312f4704fd0b674c35866066fc0221749136,18,2,8,12404,,,0,"Support update external_id

Add update external_id ability to allow heat to take over the resource.

blueprint external-resources

Change-Id: I595255332abc8bbe49dd6f0986e5dfee72be6510
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/262173/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/template_guide/hot_spec.rst', 'heat/engine/resource.py', 'heat/tests/test_resource.py', 'heat_integrationtests/functional/test_external_ref.py']",4,868b3aa0902a4f232c7c7804d30dd7e5d14de49d,bp/external-resources," def update_stack(self, stack_identifier, template): stack_name = stack_identifier.split('/')[0] self.client.stacks.update( stack_id=stack_identifier, stack_name=stack_name, template=template, files={}, disable_rollback=True, parameters={}, environment={} ) self._wait_for_stack_status(stack_identifier, 'UPDATE_COMPLETE') self.update_stack(stack_identifier, self.TEMPLATE_WITH_EX_REF) stack = self.client.stacks.get(stack_name) for out in stack.outputs: if out['output_key'] == 'str': # should be what ever we have put there. self.assertEqual('freddy', out['output_value'])"," stack_name = stack_identifier.split('/')[0] kwargs = {'stack_id': stack_identifier, 'stack_name': stack_name, 'template': self.TEMPLATE_WITH_EX_REF, 'files': {}, 'disable_rollback': True, 'parameters': {}, 'environment': {} } self.client.stacks.update(**kwargs) self._wait_for_stack_status(stack_identifier, 'UPDATE_FAILED')",33,28
openstack%2Fdevstack~master~I1a7dd9504da766beb452bd749e325931678de64e,openstack/devstack,master,I1a7dd9504da766beb452bd749e325931678de64e,Fix ovs-vsctl executed in worlddump.py failed issue,MERGED,2016-04-29 08:08:52.000000000,2016-05-11 06:13:44.000000000,2016-05-11 06:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 6754}, {'_account_id': 6890}, {'_account_id': 7118}, {'_account_id': 9459}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10453}, {'_account_id': 11655}, {'_account_id': 11929}, {'_account_id': 13252}, {'_account_id': 14760}, {'_account_id': 14807}, {'_account_id': 17120}, {'_account_id': 18893}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-04-29 08:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9efcb7218b1ef1fec3964ca5d7cbeedc9ddffb1e', 'message': 'Fix ovs-vsctl excuted in worlddump.py failed issue\n\nadd sudo before ovs-vsctl command.\n\nChange-Id: I1a7dd9504da766beb452bd749e325931678de64e\nCloses-Bug: #1576560\n'}, {'number': 2, 'created': '2016-05-05 01:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/68ea8ab0b1d6f798b53fd71fece221cd810c193f', 'message': 'Fix ovs-vsctl excuted in worlddump.py failed issue\n\nadd sudo before ovs-vsctl command.\n\nChange-Id: I1a7dd9504da766beb452bd749e325931678de64e\nCloses-Bug: #1576560\n'}, {'number': 3, 'created': '2016-05-08 13:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4a07de9b968213526a82712e9607fdc9de0f6338', 'message': 'Fix ovs-vsctl excuted in worlddump.py failed issue\n\nadd sudo before ovs-vsctl command.\n\nChange-Id: I1a7dd9504da766beb452bd749e325931678de64e\nCloses-Bug: #1576560\n'}, {'number': 4, 'created': '2016-05-09 03:03:17.000000000', 'files': ['tools/worlddump.py'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6ba17f7d014aa50643a8920ee092424051d78c08', 'message': 'Fix ovs-vsctl executed in worlddump.py failed issue\n\nadd sudo before ovs-vsctl command.\n\nChange-Id: I1a7dd9504da766beb452bd749e325931678de64e\nCloses-Bug: #1576560\n'}]",3,311055,6ba17f7d014aa50643a8920ee092424051d78c08,49,17,4,9459,,,0,"Fix ovs-vsctl executed in worlddump.py failed issue

add sudo before ovs-vsctl command.

Change-Id: I1a7dd9504da766beb452bd749e325931678de64e
Closes-Bug: #1576560
",git fetch https://review.opendev.org/openstack/devstack refs/changes/55/311055/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/worlddump.py'],1,9efcb7218b1ef1fec3964ca5d7cbeedc9ddffb1e,bug/1576560," process = subprocess.Popen(['sudo', 'ovs-vsctl', 'list-br'], stdout=subprocess.PIPE)"," process = subprocess.Popen(['ovs-vsctl', 'list-br'], stdout=subprocess.PIPE)",1,1
openstack%2Fpython-congressclient~stable%2Fmitaka~I6eccea9863e18588ed1751187a4060d07b214e40,openstack/python-congressclient,stable/mitaka,I6eccea9863e18588ed1751187a4060d07b214e40,Updated from global requirements,MERGED,2016-04-29 22:40:35.000000000,2016-05-11 06:10:14.000000000,2016-05-11 06:10:14.000000000,"[{'_account_id': 3}, {'_account_id': 11278}]","[{'number': 1, 'created': '2016-04-29 22:40:35.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/9bab931400ac56faed48e994d70f13ae4bd69f12', 'message': 'Updated from global requirements\n\nChange-Id: I6eccea9863e18588ed1751187a4060d07b214e40\n'}]",0,311338,9bab931400ac56faed48e994d70f13ae4bd69f12,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I6eccea9863e18588ed1751187a4060d07b214e40
",git fetch https://review.opendev.org/openstack/python-congressclient refs/changes/38/311338/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9bab931400ac56faed48e994d70f13ae4bd69f12,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3 # BSD,1,1
openstack%2Fcinder~master~I4b8d81bcec389f224084e5270e884e38836d1136,openstack/cinder,master,I4b8d81bcec389f224084e5270e884e38836d1136,Use to_utf8() instead of safe_encode() in convert_str(),MERGED,2016-05-06 11:52:34.000000000,2016-05-11 06:02:34.000000000,2016-05-06 21:59:56.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 14242}, {'_account_id': 14797}, {'_account_id': 14907}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18752}, {'_account_id': 19933}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-05-06 11:52:34.000000000', 'files': ['cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6bc48aeed6276b762f6e6f2faa4eda04eea12520', 'message': 'Use to_utf8() instead of safe_encode() in convert_str()\n\nsafe_encode() convert string using locale [1]. To avoid\npossible confuses we should use to_utf8() method instead.\n\n[1] https://wiki.openstack.org/wiki/Python3#safe_encode\n\nChange-Id: I4b8d81bcec389f224084e5270e884e38836d1136\n'}]",0,313521,6bc48aeed6276b762f6e6f2faa4eda04eea12520,45,26,1,1736,,,0,"Use to_utf8() instead of safe_encode() in convert_str()

safe_encode() convert string using locale [1]. To avoid
possible confuses we should use to_utf8() method instead.

[1] https://wiki.openstack.org/wiki/Python3#safe_encode

Change-Id: I4b8d81bcec389f224084e5270e884e38836d1136
",git fetch https://review.opendev.org/openstack/cinder refs/changes/21/313521/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/utils.py'],1,6bc48aeed6276b762f6e6f2faa4eda04eea12520,safe-encode, return encodeutils.to_utf8(text), return encodeutils.safe_encode(text),1,1
openstack%2Fkeystonemiddleware~master~I01ebad7b70cf61dd80d3c06c6808d8178fbdd634,openstack/keystonemiddleware,master,I01ebad7b70cf61dd80d3c06c6808d8178fbdd634,Add docstring validation,ABANDONED,2015-10-01 17:17:03.000000000,2016-05-11 05:57:51.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 13055}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-10-01 17:17:03.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/3f38f7a4a762fe6f5b6ced3d7dfd8289dd13bf33', 'message': 'Add docstring validation\n\nThis introduces a linter for PEP257 to avoid trivial nitpicking of\ndocstrings in code reviews. Because flake8_docstrings simply provides a\nplugin to add pep257 to flake8, you can run it via `tox -e pep8`.\n\nPEP257 checks which we are currently violating are ignored in tox.ini.\nWe can remove them from the ignored list as they are fixed.\n\nChange-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634\nRelated-Bug: 1501544\nDepends-On: I60adf0dca4aa32f4ef6bca61250b375c8a3703c6\n'}]",0,230026,3f38f7a4a762fe6f5b6ced3d7dfd8289dd13bf33,15,7,1,4,,,0,"Add docstring validation

This introduces a linter for PEP257 to avoid trivial nitpicking of
docstrings in code reviews. Because flake8_docstrings simply provides a
plugin to add pep257 to flake8, you can run it via `tox -e pep8`.

PEP257 checks which we are currently violating are ignored in tox.ini.
We can remove them from the ignored list as they are fixed.

Change-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634
Related-Bug: 1501544
Depends-On: I60adf0dca4aa32f4ef6bca61250b375c8a3703c6
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/26/230026/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,3f38f7a4a762fe6f5b6ced3d7dfd8289dd13bf33,bug/1501544,"# D100: Missing docstring in public module # D101: Missing docstring in public class # D102: Missing docstring in public method # D103: Missing docstring in public function # D200: One-line docstring should fit on one line with quotes # D202: No blank lines allowed after function docstring # D203: 1 blank required before class docstring. # D204: 1 blank required after class docstring # D205: Blank line required between one-line summary and description. # D208: Docstring is over-indented # D301: Use r”“” if any backslashes in a docstring # D400: First line should end with a period. # D401: First line should be in imperative mood. ignore = H405,D100,D101,D102,D103,D200,D202,D203,D204,D205,D208,D301,D400,D401",ignore = H405,15,1
openstack%2Fkeystone~stable%2Fliberty~I4ead61566000aedf62c9c48b0702ea30472c9925,openstack/keystone,stable/liberty,I4ead61566000aedf62c9c48b0702ea30472c9925,Remove test_invalid_policy_raises_error,MERGED,2016-05-10 19:01:45.000000000,2016-05-11 05:43:32.000000000,2016-05-11 05:43:31.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-05-10 19:01:45.000000000', 'files': ['keystone/tests/unit/test_policy.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f3b9b41dccc6c2e74acaf6bc3dda14df34b4eb29', 'message': ""Remove test_invalid_policy_raises_error\n\nThis test is validating internal behavior of the oslo.policy\nlibrary. Since oslo.policy already has tests for this\nfunction, we don't have to test it in keystone.\n\nAs of commit 83d209e in oslo.policy the test fails because\noslo.policy has been enhanced to support YAML and the test is\nusing valid YAML.\n\nAn alternative is to change the test to have a file that's\ninvalid YAML (remove the ']'), but then it might break again.\n\nAn alternative is to change the test to mock out the behavior,\nbut then the test would just be showing that if we mock out\nrules.enforce to raise ValueError it does that.\n\nChange-Id: I4ead61566000aedf62c9c48b0702ea30472c9925\n(cherry picked from commit 8eb7960e0f31c2624230b88d17933b3f48a17eaa)\n""}]",0,314728,f3b9b41dccc6c2e74acaf6bc3dda14df34b4eb29,9,6,1,6482,,,0,"Remove test_invalid_policy_raises_error

This test is validating internal behavior of the oslo.policy
library. Since oslo.policy already has tests for this
function, we don't have to test it in keystone.

As of commit 83d209e in oslo.policy the test fails because
oslo.policy has been enhanced to support YAML and the test is
using valid YAML.

An alternative is to change the test to have a file that's
invalid YAML (remove the ']'), but then it might break again.

An alternative is to change the test to mock out the behavior,
but then the test would just be showing that if we mock out
rules.enforce to raise ValueError it does that.

Change-Id: I4ead61566000aedf62c9c48b0702ea30472c9925
(cherry picked from commit 8eb7960e0f31c2624230b88d17933b3f48a17eaa)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/28/314728/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_policy.py'],1,f3b9b41dccc6c2e74acaf6bc3dda14df34b4eb29,oslo.policy,," def test_invalid_policy_raises_error(self): action = ""example:test"" empty_credentials = {} invalid_json = '{""example:test"": [],}' with open(self.tmpfilename, ""w"") as policyfile: policyfile.write(invalid_json) self.assertRaises(ValueError, rules.enforce, empty_credentials, action, self.target) ",0,9
openstack%2Fnetworking-sfc~master~I6df52fd831684b0c19ed35c18caadd25f155cafb,openstack/networking-sfc,master,I6df52fd831684b0c19ed35c18caadd25f155cafb,Fixes create_connection() takes no arguments error,MERGED,2016-04-29 13:11:42.000000000,2016-05-11 05:39:27.000000000,2016-05-10 14:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 14605}, {'_account_id': 16707}]","[{'number': 1, 'created': '2016-04-29 13:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/c60f043f2ea34349294a120f768901be0881031d', 'message': 'Fixes create_connection() takes no arguments error\n\nArgument new is removed in neutron commit\n60af7337b9e660a630fc0d3bff10986aed3593e9 as unused\n\nChange-Id: I6df52fd831684b0c19ed35c18caadd25f155cafb\nSigned-off-by: Pavel Gluschak <trustytwelve@gmail.com>\n'}, {'number': 2, 'created': '2016-04-29 13:12:32.000000000', 'files': ['networking_sfc/services/sfc/drivers/ovs/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/75e4ee5c9732ad6273e072f551f57b3b5b6a995a', 'message': 'Fixes create_connection() takes no arguments error\n\nArgument new is removed in neutron commit\n60af7337b9e660a630fc0d3bff10986aed3593e9 as unused\n\nCloses-Bug: #1576678\nChange-Id: I6df52fd831684b0c19ed35c18caadd25f155cafb\nSigned-off-by: Pavel Gluschak <trustytwelve@gmail.com>\n'}]",0,311107,75e4ee5c9732ad6273e072f551f57b3b5b6a995a,12,3,2,21284,,,0,"Fixes create_connection() takes no arguments error

Argument new is removed in neutron commit
60af7337b9e660a630fc0d3bff10986aed3593e9 as unused

Closes-Bug: #1576678
Change-Id: I6df52fd831684b0c19ed35c18caadd25f155cafb
Signed-off-by: Pavel Gluschak <trustytwelve@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/07/311107/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_sfc/services/sfc/drivers/ovs/driver.py'],1,c60f043f2ea34349294a120f768901be0881031d,bug/1576678, self.conn = n_rpc.create_connection(), self.conn = n_rpc.create_connection(new=True),1,1
openstack%2Fironic-specs~master~I7841599c9bf42a8442e679eeed05cb5d00eae4b3,openstack/ironic-specs,master,I7841599c9bf42a8442e679eeed05cb5d00eae4b3,Update of the Ironic Neutron Integration spec,MERGED,2015-06-04 17:51:33.000000000,2016-05-11 05:19:54.000000000,2015-07-22 17:30:07.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6558}, {'_account_id': 6620}, {'_account_id': 7787}, {'_account_id': 8106}, {'_account_id': 9200}, {'_account_id': 9361}, {'_account_id': 10202}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10358}, {'_account_id': 10375}, {'_account_id': 10380}, {'_account_id': 10910}, {'_account_id': 11614}, {'_account_id': 11655}, {'_account_id': 12315}, {'_account_id': 13360}, {'_account_id': 13719}, {'_account_id': 13997}, {'_account_id': 16115}, {'_account_id': 18781}]","[{'number': 1, 'created': '2015-06-04 17:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5fede799f39ad05d8918e906b12263d9b33cf3d4', 'message': 'Initial rough draft of the Ironic ML2 Integration\n\nThis is the first draft of the specification. It is not ready but has been\nsubmitted to illicit responses on the initial ideas contained therein. The\nAPI work etc. will be completed after consensus on the way to proceed.\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}, {'number': 2, 'created': '2015-06-12 16:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ce21142cf93c84c2e8b70db2d5fac16fa170f726', 'message': 'Update of the Ironic ML2 Integration spec\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}, {'number': 3, 'created': '2015-06-24 23:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a401796f84acd9bf6baa35bda13d4ae978d17ecc', 'message': 'Update of the Ironic ML2 Integration spec\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}, {'number': 4, 'created': '2015-07-01 19:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9fd0ea93635aaaa6b386ffdb0e0ccafe7526c7eb', 'message': 'Update of the Ironic ML2 Integration spec\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}, {'number': 5, 'created': '2015-07-01 21:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6b51f4440ef993ac8b61d87cbd396629924a6064', 'message': 'Update of the Ironic ML2 Integration spec\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}, {'number': 6, 'created': '2015-07-07 21:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2c5f405b4e071ff7f4320d46776ccdb7e725c287', 'message': 'Update of the Ironic ML2 Integration spec\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}, {'number': 7, 'created': '2015-07-21 11:10:51.000000000', 'files': ['specs/liberty/ironic-ml2-integration.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b4db386b2fc4539815df0b86a715d2aaff544e03', 'message': 'Update of the Ironic Neutron Integration spec\n\nThis spec proposes how Ironic can provide the requisite\nconnectivity information to Neutron to allow drivers to\nprovision the top-of-rack switch for the baremetal server.\n\nImplements: blueprint ironic-ml2-integration\n\nChange-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3\n'}]",238,188528,b4db386b2fc4539815df0b86a715d2aaff544e03,104,27,7,12315,,,0,"Update of the Ironic Neutron Integration spec

This spec proposes how Ironic can provide the requisite
connectivity information to Neutron to allow drivers to
provision the top-of-rack switch for the baremetal server.

Implements: blueprint ironic-ml2-integration

Change-Id: I7841599c9bf42a8442e679eeed05cb5d00eae4b3
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/28/188528/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/ironic-ml2-integration.rst'],1,5fede799f39ad05d8918e906b12263d9b33cf3d4,bp/ironic-ml2-integration,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Ironic Neutron ML2 Integration ================================================== https://blueprints.launchpad.net/ironic/+spec/ironic-ml2-integration The current Ironic implementation only supports flat networks. For isolation of tenant networks Ironic should be able to pass information to Neutron to allow for provisioning of the baremetal server onto the tenant network. Problem description =================== Ironic currently provisions servers only on flat networks hence providing no network isolation between tenants. Ironic should allow end users to utilize a baremetal instance in the same isolated (e.g. VLAN, VXLAN) networks as their virtual machines are. In order to provide the required network isolation, Ironic should be able to provide the requisite connectivity information (using LLDP) to the Neutron ML2 plugin to allow drivers to provision the top-of-rack (ToR) switch for the baremetal server. Ironic also poses new challenges for Neutron, for example, the concept of aggregating links, however, we believe a complementary specification is not required as the current functionality in Neutron allows for updates to be confined to ML2 drivers. Proposed change =============== When nodes are enrolled/introspected in Ironic, local link (e.g. LLDP) information should be recorded against each port that is enrolled. The option of creating a port group to specify an aggregation of said ports should be made available. Ironic should then send the local link information to Neutron in the form of a port binding profile. If there are port groups, they should be created as a Neutron port and have a binding profile stating that it is an aggregate. Each port within a part group should have its local link information registered in the group's binding profile. Ironic ports that are not part of a port group will have a corresponding Neutron port where their local link information will be registered. The network should first be placed on a provisioning network and then onto the tenant network as specified in the `network-provider spec <https://blueprints.launchpad.net/ironic/+spec/network-provider>`_. To help facilitate this there will be a variable stored in the binding profile to record whether a port binding has been requested. This will allow Ironic to defer binding until Ironic is able to populate the extra information that is required by Neutron. Note also, there will be no support for PXE booting after deploy (i.e. local disk installation only). A supportive ML2 driver can then use the information supplied to provision the port. The Ironic port object will be updated with a new local_link_connection field dict supplying the following values: * chassis_id * port_id * system_name These fields are based on their LLDP TLV counterparts. It is not strictly required to populate these with LLDP values but it is recommended to use LLDP to make it easier to avoid mismatches in the values a Neutron ML2 driver will expect. To facilitate link aggregation a new port_group object will be created. In addition to the base object it will have the following fields: * id * uuid * name * node_id * address * extra The Ironic port object will then have the following fields added to support new functionality: * local_link_connection * port_group_id * pxe_enabled The pxe_enabled field is required to allow selection of the PXE address in the scenario where there are multiple ports (e.g. in the case of port groups). It is thought that introspection methods could automatically set this value e.g. discoverd could enable the interface that it booted from. In the case where there are multiple ports enabled for PXE booting the selection process will be as follows: * Select port groups with an address that corresponds to an enabled port's address. If there are multiple ports choose one at random. * Select enabled ports from port groups. If there are multiple ports choose one at random. * Choose an enabled port at random. The proposed binding profile for Neutron is as follows: +------------------------+----------------------------------------------------+ | Field Name | Description | +========================+====================================================+ | type | Type of the profile ('Ironic' in this case) | +------------------------+----------------------------------------------------+ | local_link_information | A list of the local link information from Ironic. | | | In the case of a single port it will have only one | | | element, the Ironic's port corresponding dict. | +------------------------+----------------------------------------------------+ | is_link_aggregate | A boolean to specify that this port describes an | | | aggregate | +------------------------+----------------------------------------------------+ | bind_requested | A boolean to specify whether to bind the port or | | | defer binding. +------------------------+----------------------------------------------------+ Alternatives ------------ The current model of prescribing flat networks could be maintained with the same flat network being used for everything. The in-progress Ironic-Neutron plugin could be updated with support from networking vendors. This would mean supporting a minimum of two layer 2 plugins and multiple plugins being required for a baremetal and virtual machine cloud. Data model impact ----------------- The proposed change will be to add the following fields to the port object with their data type and default value for migrations: +-----------------------+--------------+-----------------+ | Field Name | Field Type | Migration Value | +=======================+==============+=================+ | local_link_connection | dict_or_none | None | +-----------------------+--------------+-----------------+ | port_group_id | int_or_none | None | +-----------------------+--------------+-----------------+ | pxe_enabled | bool | True | +-----------------------+--------------+-----------------+ All existing ports will have their pxe_enabled set to True so that the current behavior is not changed. The port_group relationship is a 1:n relationship with the port. The port_group object is proposed with the following fields and data types: +-----------------------+-------------------------+ | Field Name | Field Type | +=======================+=========================+ | id | int | +-----------------------+-------------------------+ | uuid | str_or_none | +-----------------------+-------------------------+ | name | str_or_none | +-----------------------+-------------------------+ | node_id | str_or_none | +-----------------------+-------------------------+ | address | str_or_none | +-----------------------+-------------------------+ | extra | dict_or_none | +-----------------------+-------------------------+ | created_at | datetime_or_str_or_none | +-----------------------+-------------------------+ | updated_at | datetime_or_str_or_none | +-----------------------+-------------------------+ State Machine Impact -------------------- The state machine will not be directly impacted, however, when changes can be made will be impacted by the state machine. Any add/update/delete to port_group can only be made when the node is in a MANAGEABLE state or in maintenance mode when in the AVAILABLE/ACTIVE/RESCUE states. REST API impact --------------- TODO: RPC API impact -------------- No impact. Driver API impact ----------------- No impact. Nova driver impact ------------------ TODO: Security impact --------------- TODO: Other end user impact --------------------- TODO: Scalability impact ------------------ TODO: Performance Impact ------------------ TODO: Other deployer impact --------------------- TODO: Developer impact ---------------- TODO: Implementation ============== Assignee(s) ----------- Primary assignee: bertiefulton Other contributors: laura-moore sukhdev-8 Work Items ---------- TODO: Dependencies ============ TODO: Testing ======= TODO: Upgrades and Backwards Compatibility ==================================== TODO: Documentation Impact ==================== TODO: References ========== TODO: ",,278,0
openstack%2Fpuppet-tripleo~master~I079e65f535af069312b602e8ff58be80ab2f2226,openstack/puppet-tripleo,master,I079e65f535af069312b602e8ff58be80ab2f2226,keystone: drop usage of step 6,MERGED,2016-05-10 12:57:53.000000000,2016-05-11 05:13:51.000000000,2016-05-11 05:13:51.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-05-10 12:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/775fb3ac33e002fcb1c9bb236beba5cd29d3f78f', 'message': 'keystone: drop usage of step 6\n\n* Manage roles & endpoints at step 5\n* Set correct orchestration for Pacemaker resources within a single\n  step.\n\nChange-Id: I079e65f535af069312b602e8ff58be80ab2f2226\n'}, {'number': 2, 'created': '2016-05-10 21:49:11.000000000', 'files': ['manifests/profile/pacemaker/keystone.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/74c573eabbed37e689f1ffefdbe33c9cb3f19de8', 'message': 'keystone: drop usage of step 6\n\n* Manage roles & endpoints at step 5\n* Set correct orchestration for Pacemaker resources within a single\n  step.\n\nChange-Id: I079e65f535af069312b602e8ff58be80ab2f2226\n'}]",0,314543,74c573eabbed37e689f1ffefdbe33c9cb3f19de8,13,3,2,3153,,,0,"keystone: drop usage of step 6

* Manage roles & endpoints at step 5
* Set correct orchestration for Pacemaker resources within a single
  step.

Change-Id: I079e65f535af069312b602e8ff58be80ab2f2226
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/43/314543/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/keystone.pp'],1,775fb3ac33e002fcb1c9bb236beba5cd29d3f78f,step6," if $step >= 5 and $pacemaker_master { before => Pacemaker::Resource::Service[$::apache::params::service_name], before => Pacemaker::Resource::Service[$::apache::params::service_name],", if $step >= 6 and $pacemaker_master {,3,1
openstack%2Fnova~master~Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a,openstack/nova,master,Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a,Move config options from nova/api directory (1),MERGED,2016-04-21 21:48:32.000000000,2016-05-11 05:05:34.000000000,2016-05-10 15:35:16.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-04-21 21:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad90d0c410f1f35375e5b5bdf1c0e373831c1294', 'message': 'Move config options from nova/api directory (1)\n\nThis is the first patch moving config options from the nova/api\ndirectory. In this patch, the auth and metadata options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a\n'}, {'number': 2, 'created': '2016-04-27 09:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36dc5bf01a516970319dc505c718c05455fae7c3', 'message': 'Move config options from nova/api directory (1)\n\nThis is the first patch moving config options from the nova/api\ndirectory. In this patch, the auth and metadata options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a\n'}, {'number': 3, 'created': '2016-04-28 16:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24b25e0cce3916037db084c48c3a3fbae918a4ea', 'message': 'Move config options from nova/api directory (1)\n\nThis is the first patch moving config options from the nova/api\ndirectory. In this patch, the auth and metadata options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a\n'}, {'number': 4, 'created': '2016-05-06 18:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc312c87784e2489b130665844c66f176752e8fe', 'message': 'Move config options from nova/api directory (1)\n\nThis is the first patch moving config options from the nova/api\ndirectory. In this patch, the auth and metadata options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a\n'}, {'number': 5, 'created': '2016-05-09 20:04:04.000000000', 'files': ['nova/api/auth.py', 'nova/conf/neutron.py', 'nova/api/openstack/auth.py', 'nova/api/opts.py', 'nova/tests/unit/api/test_auth.py', 'nova/image/glance.py', 'nova/conf/__init__.py', 'nova/api/metadata/vendordata_json.py', 'nova/conf/api.py', 'nova/api/metadata/handler.py', 'nova/api/metadata/base.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/515eacc693c23ad5ed710d76898fcfbff8ad5665', 'message': 'Move config options from nova/api directory (1)\n\nThis is the first patch moving config options from the nova/api\ndirectory. In this patch, the auth and metadata options are moved. A\nsubsequent patch will enhance the help text for these options.\n\nBlueprint centralize-config-options-newton\n\nChange-Id: Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a\n'}]",10,309192,515eacc693c23ad5ed710d76898fcfbff8ad5665,79,17,5,1063,,,0,"Move config options from nova/api directory (1)

This is the first patch moving config options from the nova/api
directory. In this patch, the auth and metadata options are moved. A
subsequent patch will enhance the help text for these options.

Blueprint centralize-config-options-newton

Change-Id: Id2d755ccb589cedd8ac8663f81d3222ae7d47b3a
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/309192/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/auth.py', 'nova/api/openstack/auth.py', 'nova/conf/neutron.py', 'nova/api/opts.py', 'nova/tests/unit/api/test_auth.py', 'nova/conf/__init__.py', 'nova/image/glance.py', 'nova/api/metadata/vendordata_json.py', 'nova/conf/api.py', 'nova/api/metadata/base.py', 'nova/api/metadata/handler.py']",11,ad90d0c410f1f35375e5b5bdf1c0e373831c1294,bp/centralize-config-options-newton,import nova.confCONF = nova.conf.CONF,"from oslo_config import cfgCONF = cfg.CONF CONF.import_opt('use_forwarded_for', 'nova.api.auth') metadata_proxy_opts = [ cfg.BoolOpt( 'service_metadata_proxy', default=False, help='Set flag to indicate Neutron will proxy metadata requests and ' 'resolve instance ids.'), cfg.StrOpt( 'metadata_proxy_shared_secret', default='', secret=True, help='Shared secret to validate proxies Neutron metadata requests'), ] metadata_opts = [ cfg.IntOpt('metadata_cache_expiration', default=15, help='Time in seconds to cache metadata; 0 to disable ' 'metadata caching entirely (not recommended). Increasing' 'this should improve response times of the metadata API ' 'when under heavy load. Higher values may increase memory' 'usage and result in longer times for host metadata ' 'changes to take effect.') ] CONF.register_opts(metadata_proxy_opts, 'neutron') CONF.register_opts(metadata_opts) ",108,93
openstack%2Fironic~master~Ic1c4f911c9760811aea61e0150fa69987ea08e29,openstack/ironic,master,Ic1c4f911c9760811aea61e0150fa69987ea08e29,Cleanup unused conf variables,MERGED,2016-02-16 05:19:46.000000000,2016-05-11 04:55:06.000000000,2016-05-10 13:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 6773}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11076}, {'_account_id': 13362}, {'_account_id': 14525}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-02-16 05:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c32a2fbc313792ec04b0336fa6bc6684c9a283b', 'message': 'Cleanup unused conf variables\n\nI noticed in nova that we had a lot of unused conf variables. I\nwondered if this was a thing in other projects as well. Turns out\nit is.\n\nChange-Id: Ic1c4f911c9760811aea61e0150fa69987ea08e29\n'}, {'number': 2, 'created': '2016-05-09 23:23:14.000000000', 'files': ['ironic/tests/unit/drivers/modules/ilo/test_inspect.py', 'ironic/tests/unit/drivers/modules/irmc/test_power.py', 'ironic/tests/unit/drivers/modules/ilo/test_vendor.py', 'ironic/tests/unit/drivers/modules/test_virtualbox.py', 'ironic/tests/unit/common/test_swift.py', 'ironic/drivers/modules/ilo/vendor.py', 'ironic/tests/unit/drivers/modules/ucs/test_management.py', 'ironic/tests/unit/drivers/modules/ilo/test_deploy.py', 'ironic/tests/unit/drivers/modules/ucs/test_helper.py', 'ironic/drivers/modules/irmc/power.py', 'ironic/tests/unit/drivers/modules/amt/test_management.py', 'ironic/tests/unit/drivers/modules/ilo/test_management.py', 'ironic/tests/unit/drivers/modules/ilo/test_console.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e995881f2386ad69b51355ea8a106fc225fb6141', 'message': 'Cleanup unused conf variables\n\nI noticed in nova that we had a lot of unused conf variables. I\nwondered if this was a thing in other projects as well. Turns out\nit is.\n\nChange-Id: Ic1c4f911c9760811aea61e0150fa69987ea08e29\n'}]",0,280493,e995881f2386ad69b51355ea8a106fc225fb6141,26,10,2,2271,,,0,"Cleanup unused conf variables

I noticed in nova that we had a lot of unused conf variables. I
wondered if this was a thing in other projects as well. Turns out
it is.

Change-Id: Ic1c4f911c9760811aea61e0150fa69987ea08e29
",git fetch https://review.opendev.org/openstack/ironic refs/changes/93/280493/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/ilo/test_inspect.py', 'ironic/tests/unit/drivers/modules/irmc/test_power.py', 'ironic/tests/unit/drivers/modules/ilo/test_vendor.py', 'ironic/tests/unit/drivers/modules/test_virtualbox.py', 'ironic/tests/unit/common/test_swift.py', 'ironic/drivers/modules/ilo/vendor.py', 'ironic/tests/unit/drivers/modules/ucs/test_management.py', 'ironic/tests/unit/drivers/modules/ilo/test_deploy.py', 'ironic/tests/unit/drivers/modules/ucs/test_helper.py', 'ironic/drivers/modules/irmc/power.py', 'ironic/tests/unit/drivers/modules/amt/test_management.py', 'ironic/tests/unit/drivers/modules/ilo/test_management.py', 'ironic/tests/unit/drivers/modules/ilo/test_console.py']",13,2c32a2fbc313792ec04b0336fa6bc6684c9a283b,unused_conf,,from oslo_config import cfgCONF = cfg.CONF,0,29
openstack%2Fkeystonemiddleware~master~I97844a869dc6a5f55d320f9edfcb870347b8e067,openstack/keystonemiddleware,master,I97844a869dc6a5f55d320f9edfcb870347b8e067,Have s3_token accept identity_uri config option,ABANDONED,2016-03-18 22:27:21.000000000,2016-05-11 04:45:01.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 13055}, {'_account_id': 15343}]","[{'number': 1, 'created': '2016-03-18 22:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/9b764d900fbc1bbcc0fd8ef7157ac8139d404e3e', 'message': ""Have s3_token accept identity_uri config option\n\n...similar to what was done for auth_token back when this was still part\nof python-keystoneclient.\n\nWhile we're at it, fix auth_host config option to be IPv6-friendly.\n\nChange-Id: I97844a869dc6a5f55d320f9edfcb870347b8e067\nRelated-Change: I226881a35a74ef668d4cd1c6829a64c94ff185d9\nRelated-Change: I1f8f5064ea8028af60f167df9b97e215cdadba44\n""}, {'number': 2, 'created': '2016-03-31 17:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8aec82ca6b70cb4ceccac8b996b1680ab983cd35', 'message': 'Have s3_token accept identity_uri config option\n\n...similar to what was done for auth_token back when this was still part\nof python-keystoneclient.\n\nChange-Id: I97844a869dc6a5f55d320f9edfcb870347b8e067\nRelated-Change: I1f8f5064ea8028af60f167df9b97e215cdadba44\n'}, {'number': 3, 'created': '2016-04-07 21:44:16.000000000', 'files': ['keystonemiddleware/tests/unit/test_s3_token_middleware.py', 'keystonemiddleware/s3_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8a3b33afec76c75350e5e35aa312872e7bd3e073', 'message': 'Have s3_token accept identity_uri config option\n\n...similar to what was done for auth_token back when this was still part\nof python-keystoneclient.\n\nChange-Id: I97844a869dc6a5f55d320f9edfcb870347b8e067\nRelated-Change: I1f8f5064ea8028af60f167df9b97e215cdadba44\n'}]",7,294835,8a3b33afec76c75350e5e35aa312872e7bd3e073,17,9,3,15343,,,0,"Have s3_token accept identity_uri config option

...similar to what was done for auth_token back when this was still part
of python-keystoneclient.

Change-Id: I97844a869dc6a5f55d320f9edfcb870347b8e067
Related-Change: I1f8f5064ea8028af60f167df9b97e215cdadba44
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/35/294835/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/tests/unit/test_s3_token_middleware.py', 'keystonemiddleware/s3_token.py']",2,9b764d900fbc1bbcc0fd8ef7157ac8139d404e3e,s3token-identity-uri," self._request_uri = conf.get('identity_uri') if self._request_uri is None: auth_host = conf.get('auth_host', '') if ':' in auth_host and not auth_host.startswith('['): # Note(timburke) it is an IPv6 address, so it needs to be # wrapped with '[]' to generate a valid IPv6 URL, based on # http://www.ietf.org/rfc/rfc2732.txt auth_host = '[%s]' % auth_host auth_port = int(conf.get('auth_port', 35357)) auth_protocol = conf.get('auth_protocol', 'https') self._request_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port)"," auth_host = conf.get('auth_host') auth_port = int(conf.get('auth_port', 35357)) auth_protocol = conf.get('auth_protocol', 'https') self._request_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port)",45,15
openstack%2Fneutron~master~Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6,openstack/neutron,master,Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6,DVR: Ensure fpr and rfp devices are configured correctly,MERGED,2016-04-06 16:04:13.000000000,2016-05-11 04:23:31.000000000,2016-05-10 18:31:18.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12237}, {'_account_id': 12860}, {'_account_id': 13667}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14852}, {'_account_id': 15752}, {'_account_id': 20993}]","[{'number': 1, 'created': '2016-04-06 16:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/435e43859fd01cb793676eab7576f05bddc821e9', 'message': 'Restarting neutron-l3-agent when creating fip may leave\nrfp and fpr with no ip as a result of incomplete check.\n\nFix this by check ip configured after rfp and fpr are created.\n\ncloses-Bug: #1566383\n\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6d\n'}, {'number': 2, 'created': '2016-04-07 14:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/47cf46cf8086a62b3d94e793b26e4328a7f90c70', 'message': 'FIP: Ensure fpr and rfp are configured correctly\n\nRestarting neutron-l3-agent when creating fip may leave\nrfp and fpr with no ip as a result of incomplete check.\n\nFix this by check ip configured after rfp and fpr are created.\n\ncloses-Bug: #1566383\n\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6d\n'}, {'number': 3, 'created': '2016-04-07 22:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85516a658f72cdebd8cf27684e0058635f0614ca', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exists.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6d\n'}, {'number': 4, 'created': '2016-04-14 16:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5485668c3e5cb97c6a28251835526a2bcf349ee9', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exists.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6d\n'}, {'number': 5, 'created': '2016-04-22 20:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b0490009ab9217f1c3dfb15b1ad93f13c9b6b79', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exist.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6d\n'}, {'number': 6, 'created': '2016-04-24 02:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f62c64c42459a4c031d545ad3c2bb84c84911f87', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exist.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6\n'}, {'number': 7, 'created': '2016-05-05 14:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b14dfc549be42683924207ae8f1c1801435fb502', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exist.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6\n'}, {'number': 8, 'created': '2016-05-06 21:11:56.000000000', 'files': ['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a47d22942a46cf12589cee6353dc2b6deb58f178', 'message': 'DVR: Ensure fpr and rfp devices are configured correctly\n\nRestarting the l3-agent when creating the fip namespace may\nleave rfp and fpr devices with no IP addresses, since we will\nnot try and configure them if the devices already exist.\n\nFix this by always trying to configure the IP addresses,\neven if the devices already exist.\n\nCloses-Bug: #1566383\nChange-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6\n'}]",21,302340,a47d22942a46cf12589cee6353dc2b6deb58f178,124,21,8,14852,,,0,"DVR: Ensure fpr and rfp devices are configured correctly

Restarting the l3-agent when creating the fip namespace may
leave rfp and fpr devices with no IP addresses, since we will
not try and configure them if the devices already exist.

Fix this by always trying to configure the IP addresses,
even if the devices already exist.

Closes-Bug: #1566383
Change-Id: Idad3bb4808ec66b9a764bb621dfb04a10eb7ed6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/302340/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/dvr_fip_ns.py'],1,435e43859fd01cb793676eab7576f05bddc821e9,bug/1566383," def _check_device_ip(self, interface_name, namespace, ip_cidr): device = ip_lib.IPDevice(interface_name, namespace) existing_cidrs = [add['cidr'] for addr in device.addr.list()] if ip_cidr in existing_cidrs: return True return False if self._check_device_ip(rtr_2_fip_name, ri.ns_name, str(rtr_2_fip)): if self._check_device_ip(fip_2_rtr_name, fip_ns_name, str(fip_2_rtr)): rtr_2_fip_device = ip_lib.IPDevice(rtr_2_fip_name, namespace=ri.ns_name) fip_2_rtr_device = ip_lib.IPDevice(fip_2_rtr_name, namespace=fip_ns_name) mtu = (self.agent_conf.network_device_mtu or ri.get_ex_gw_port().get('mtu')) if mtu: rtr_2_fip_device.link.set_mtu(mtu) fip_2_rtr_device.link.set_mtu(mtu) rtr_2_fip_device.link.set_up() fip_2_rtr_device.link.set_up() rtr_2_fip_device.route.add_gateway(str(fip_2_rtr.ip), table=FIP_RT_TBL)"," mtu = (self.agent_conf.network_device_mtu or ri.get_ex_gw_port().get('mtu')) if mtu: int_dev[0].link.set_mtu(mtu) int_dev[1].link.set_mtu(mtu) int_dev[0].link.set_up() int_dev[1].link.set_up() device = ip_lib.IPDevice(rtr_2_fip_name, namespace=ri.ns_name) device.route.add_gateway(str(fip_2_rtr.ip), table=FIP_RT_TBL)",21,9
openstack%2Fnova~master~Ie3e9e39f5547a3172483b42d21536acf46b445d3,openstack/nova,master,Ie3e9e39f5547a3172483b42d21536acf46b445d3,Complete method verification of os-security-groups,MERGED,2016-05-09 19:49:58.000000000,2016-05-11 04:19:06.000000000,2016-05-10 12:01:13.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16051}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-05-09 19:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f07a8e290d2c1e881c1f807382681dddc9a0fcf', 'message': '[WIP] Complete method verification of os-security-groups\n\nTODO:  Verify the code for List Security Groups By Server\n\nVerified the API document with source for methods available and\nresponse codes used.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ie3e9e39f5547a3172483b42d21536acf46b445d3\n'}, {'number': 2, 'created': '2016-05-09 20:02:19.000000000', 'files': ['api-ref/source/os-security-groups.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca690257d457210646f25feef92fb0e50e320dfe', 'message': 'Complete method verification of os-security-groups\n\nVerified the API document with source for methods available and\nresponse codes used.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: Ie3e9e39f5547a3172483b42d21536acf46b445d3\n'}]",6,314255,ca690257d457210646f25feef92fb0e50e320dfe,24,11,2,16051,,,0,"Complete method verification of os-security-groups

Verified the API document with source for methods available and
response codes used.

Part of bp:api-ref-in-rst

Change-Id: Ie3e9e39f5547a3172483b42d21536acf46b445d3
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/314255/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-security-groups.inc'],1,1f07a8e290d2c1e881c1f807382681dddc9a0fcf,bp/api-ref-in-rst,"Lists, shows information for, creates, updates and deletes security groups.Error response codes: unauthorized(401), forbidden(403), itemNotFound(404)Error response codes: badRequest(400), unauthorized(401), forbidden(403)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)There is no body content for the response of a successful DELETE query. .. literalinclude:: ../../doc/api_samples/os-security-groups/server-security-groups-list-get-resp.json","Lists, shows information for, creates, and deletes security groups.Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404).. literalinclude:: ../../doc/api_samples/os-security-groups/security-groups-list-get-resp.json",9,12
openstack%2Fironic~master~Ib486ba819358c280ddc6941401552a0f58246198,openstack/ironic,master,Ib486ba819358c280ddc6941401552a0f58246198,Adds RAID interface for 'iscsi_ilo',MERGED,2016-05-09 08:34:57.000000000,2016-05-11 04:12:45.000000000,2016-05-10 21:06:17.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 14525}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-05-09 08:34:57.000000000', 'files': ['ironic/drivers/ilo.py', 'releasenotes/notes/bug-1579635-cffd990b51bcb5ab.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7f7b5c7dbc6cb6dabaa8ae2505801a9bbeb8fa8b', 'message': ""Adds RAID interface for 'iscsi_ilo'\n\nCurrently iscsi_ilo doesn't support RAID interface.\nThis commit adds RAID interface support for iscsi_ilo.\n\nCloses-Bug: #1579635\nChange-Id: Ib486ba819358c280ddc6941401552a0f58246198\n""}]",0,314016,7f7b5c7dbc6cb6dabaa8ae2505801a9bbeb8fa8b,27,8,1,15074,,,0,"Adds RAID interface for 'iscsi_ilo'

Currently iscsi_ilo doesn't support RAID interface.
This commit adds RAID interface support for iscsi_ilo.

Closes-Bug: #1579635
Change-Id: Ib486ba819358c280ddc6941401552a0f58246198
",git fetch https://review.opendev.org/openstack/ironic refs/changes/16/314016/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/ilo.py', 'releasenotes/notes/bug-1579635-cffd990b51bcb5ab.yaml']",2,7f7b5c7dbc6cb6dabaa8ae2505801a9bbeb8fa8b,bug-1579635,--- fixes: -This fixes the issue of RAID interface not being supported in iscsi_ilo driver. ,,5,0
openstack%2Fcinder~master~I1d276d93ad5e799401b48d2234e61c28a3aaf790,openstack/cinder,master,I1d276d93ad5e799401b48d2234e61c28a3aaf790,Add ability to filter by volume_glance_metadata,MERGED,2015-01-16 03:43:26.000000000,2016-05-11 04:00:15.000000000,2016-05-09 03:27:55.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 2861}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 7160}, {'_account_id': 7173}, {'_account_id': 7198}, {'_account_id': 8846}, {'_account_id': 8912}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10115}, {'_account_id': 10559}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11676}, {'_account_id': 11811}, {'_account_id': 11903}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12285}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12410}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14103}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14274}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14865}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15741}, {'_account_id': 15764}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16308}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17103}, {'_account_id': 17130}, {'_account_id': 17405}, {'_account_id': 17444}, {'_account_id': 17463}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19896}, {'_account_id': 19933}, {'_account_id': 20105}, {'_account_id': 20683}, {'_account_id': 21193}]","[{'number': 1, 'created': '2015-01-16 03:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2e20828012a8695ea85dd0e4f226a752141d0485', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 2, 'created': '2015-02-04 09:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e177ca819ef88ba044731245b64ecfe9bc91090', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 3, 'created': '2015-02-26 03:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0353614f3096d3b970b4b9fd09257cb25fd06895', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 4, 'created': '2015-02-28 03:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15c8e96088038d4a10c078e914ebe8ca809606c0', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 5, 'created': '2015-04-10 04:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c960225b2e7e9fc49c3d59b1b1eb18cc9f16ec14', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 6, 'created': '2015-04-17 02:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f4f0b60a376c69e3020bbb297f1474b2347d63d6', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 7, 'created': '2015-04-17 03:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c511eb2f32a629ca66938095dab6e0142b657b34', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 8, 'created': '2015-04-23 12:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/10a9ebd477572dfefa4186cfec5503723a5b478b', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 9, 'created': '2015-05-26 03:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7631ca96ebd0d1167eef15be3182b5f8e34603e8', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 10, 'created': '2015-06-16 00:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/06ded3e9987249fc51e863345b12381c3a5613c0', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 11, 'created': '2015-06-16 00:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1784aef3b5ab62bb024d25b6f1a4cd1351ca646f', 'message': 'query volume detail support volume_glance_metadata\n\n1.add volume_glance_metadata query in DB _generate_paginate_query\nfunction.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 12, 'created': '2015-06-29 07:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eed6ca3912a531e9277188af8a45eb534370fc69', 'message': 'query volume detail support volume_glance_metadata\n\nThe purpose of this feature is to make user to query volume detail\nmore conveniently. User can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadta to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 13, 'created': '2015-07-01 03:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/580ed8282d810733771919c878ec2f70e046273c', 'message': 'query volume detail support volume_glance_metadata\n\nThe purpose of this feature is to make user to query volume detail\nmore conveniently. User can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadta to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 14, 'created': '2015-07-01 09:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/85590ecd993a49bbd57b587f94d78eb7a95ca938', 'message': 'Query volume detail support volume_glance_metadata\n\nThe purpose of this feature is to make users to query volume detail\nmore conveniently. Users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadta to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 15, 'created': '2015-07-07 03:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fba15afde9bdb729141e630805a92e8178656391', 'message': 'Add ability to filter volumes list by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadata to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?f_glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 16, 'created': '2015-07-07 08:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3207456a642f6ff05a6aea0290a345aa3a2ea728', 'message': 'Add ability to filter volumes list by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadata to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?f_glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 17, 'created': '2015-07-30 09:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/192ba76b490b3bc8384d5141b691588b180c39b5', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadata to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?f_glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 18, 'created': '2015-11-09 08:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a0ab14f22dc836ec37ba85085328d6cffef6bf48', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadata to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?f_glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 19, 'created': '2015-11-09 09:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21feeb1075475aa1da076841ada0005dadbd546b', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\nUser can use glance metadata to filter volume detail in cinder api.\nThe query url is like this:\n ""volumes/detail?f_glance_metadata={""image_name"":""xxx""}""\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 20, 'created': '2016-04-11 12:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b096b16f10ca699f0758a54d3ca8be079843f945', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\n3. glance_metadata filtering is enabled for non admin users by default\n   in new api version \'3.2\'.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 21, 'created': '2016-04-12 12:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/389fb9b69c51fdb759390aea52962c87d2658637', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\n3. glance_metadata filtering is enabled for non admin users by default\n   in new api version \'3.2\'.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 22, 'created': '2016-04-12 18:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/38ec1d72d423e242805ae21bc61878f6a83486a3', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\n3. glance_metadata filtering is enabled for non admin users by default\n   in new api version \'3.2\'.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 23, 'created': '2016-04-19 09:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f1c2631b0b8a3bc736ed0a64c729b9f8a4373eb6', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\n3. glance_metadata filtering is enabled for non admin users by default\n   in new api version \'3.2\'.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 24, 'created': '2016-04-19 11:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4418239a6cbaed76b7c51cc6a19f33c105737237', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\n3. glance_metadata filtering is enabled for non admin users by default\n   in new api version \'3.2\'.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 25, 'created': '2016-04-20 03:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0768c71064222ea9586468ae68343aa6c7913d41', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\n3. glance_metadata filtering is enabled for non admin users by default\n   in new api version \'3.2\'.\n\nDocImpact\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 26, 'created': '2016-04-23 04:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ea0067d803306eb8b3fb2ae6bff465baa21cf259', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 27, 'created': '2016-04-23 09:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/68240db81fd2d40cb29917ded029113f8b79371b', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 28, 'created': '2016-04-23 09:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6a435c8484ad510a49d28778d25e95181a7c4183', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.2"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 29, 'created': '2016-04-24 22:27:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/edc180ca5da53ee391882590d2c46ef4614b6e79', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.3"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 30, 'created': '2016-04-24 22:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c3a938693e04a0dcdbf27aa5b491a21120231f26', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.3"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 31, 'created': '2016-04-26 08:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bdc222f2c13ef4c99e7a0190d477ac6732e2b6fc', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.3"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 32, 'created': '2016-04-27 00:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0cb89010af7c5b2d6a771801cf8759cf8c7b847a', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.3"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 33, 'created': '2016-04-28 01:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27d836ad009dc944ca368d016d218df58b9226ea', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.3"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 34, 'created': '2016-05-03 02:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a2cba436ed7f2209f53dedffc74f1dc4272249a', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.4"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}, {'number': 35, 'created': '2016-05-06 00:24:00.000000000', 'files': ['cinder/tests/unit/api/v3/test_volumes.py', 'cinder/tests/unit/test_db_api.py', 'cinder/api/v3/volumes.py', 'cinder/api/v2/volumes.py', 'cinder/api/openstack/api_version_request.py', 'cinder/api/openstack/rest_api_version_history.rst', 'cinder/db/sqlalchemy/api.py', 'releasenotes/notes/support-volume-glance-metadata-query-866b9e3beda2cd55.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fca31fc95e00580249b19ec52a2e82e7d8dcff38', 'message': 'Add ability to filter by volume_glance_metadata\n\nThis feature allows users to more conveniently query volume details by\nfiltering the volume list by certain image metadata.\nFor example, users can query a specific bootable volume quickly\nfiltering by image_name or other glance metadata.\n\nAPIImpact\n1. User can use glance metadata to filter volume detail in cinder api.\n   The query url is like this:\n   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""\n\n2. Since microversion is implemented in M, this change will add a new\n   version ""3.4"".\n\nDocImpact\n1.Operator would need to add glance_metadata to \'query_volume_filters\'\noption for new functionality to work.\n\nChange-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790\nImplements: blueprint support-volume-glance-metadata-query\n'}]",68,147738,fca31fc95e00580249b19ec52a2e82e7d8dcff38,845,97,35,8846,,,0,"Add ability to filter by volume_glance_metadata

This feature allows users to more conveniently query volume details by
filtering the volume list by certain image metadata.
For example, users can query a specific bootable volume quickly
filtering by image_name or other glance metadata.

APIImpact
1. User can use glance metadata to filter volume detail in cinder api.
   The query url is like this:
   ""volumes/detail?glance_metadata={""image_name"":""xxx""}""

2. Since microversion is implemented in M, this change will add a new
   version ""3.4"".

DocImpact
1.Operator would need to add glance_metadata to 'query_volume_filters'
option for new functionality to work.

Change-Id: I1d276d93ad5e799401b48d2234e61c28a3aaf790
Implements: blueprint support-volume-glance-metadata-query
",git fetch https://review.opendev.org/openstack/cinder refs/changes/38/147738/35 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/api.py'],1,2e20828012a8695ea85dd0e4f226a752141d0485,bp/support-volume-glance-metadata-query," col_gl_attr = getattr(models.Volume, 'volume_glance_metadata') col_ad_attr.any(key=k, value=v), col_gl_attr.any(key=k, value=v)))"," col_ad_attr.any(key=k, value=v)))",3,1
openstack%2Fnova~master~I746516d8f7ed29ff8ae258d973fb20a60e92c17d,openstack/nova,master,I746516d8f7ed29ff8ae258d973fb20a60e92c17d,Modify the exception handling in order to solve the following questions: nova service-list failed when one or some cell-service exception  of multiple child cells close-bug:#1539056,ABANDONED,2016-02-03 09:39:23.000000000,2016-05-11 03:54:16.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-03 09:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3283692ed29e8f8bb2b04c65659863d99476766', 'message': 'Modify the exception handling in order to solve the following questions:\nnova service-list failed when one or some cell-service exception  of multiple child cells\nclose-bug:#1539056\n\nChange-Id: I746516d8f7ed29ff8ae258d973fb20a60e92c17d\n'}, {'number': 2, 'created': '2016-03-04 06:42:49.000000000', 'files': ['nova/cells/messaging.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/00555efb265c8db9b0e7fd63e72abfe33c77f5eb', 'message': 'Modify the exception handling in order to solve the following questions:\nnova service-list failed when one or some cell-service exception  of multiple child cells\nclose-bug:#1539056\n\nChange-Id: I746516d8f7ed29ff8ae258d973fb20a60e92c17d\n'}]",0,275583,00555efb265c8db9b0e7fd63e72abfe33c77f5eb,25,12,2,17898,,,0,"Modify the exception handling in order to solve the following questions:
nova service-list failed when one or some cell-service exception  of multiple child cells
close-bug:#1539056

Change-Id: I746516d8f7ed29ff8ae258d973fb20a60e92c17d
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/275583/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/cells/messaging.py'],1,b3283692ed29e8f8bb2b04c65659863d99476766,bug/1539056," has_err = False for x in range(num_responses): try: except queue.Empty: if self.method_name == 'service_get_all': has_err = True else: raise exception.CellTimeout() if has_err: LOG.warning(_LW(""get service on some child cell timeout"")) self._cleanup_response_queue()", try: for x in range(num_responses): except queue.Empty: raise exception.CellTimeout() finally: self._cleanup_response_queue(),11,6
openstack%2Fopenstack-ansible~master~I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557,openstack/openstack-ansible,master,I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557,Check for two IP addresses assigned to same host,MERGED,2016-04-19 22:01:57.000000000,2016-05-11 03:50:16.000000000,2016-05-11 03:50:16.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12807}, {'_account_id': 12892}, {'_account_id': 17068}, {'_account_id': 18784}, {'_account_id': 19592}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-04-19 22:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/422dbefdf900892574cbccdcbefa2694208eb58b', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 2, 'created': '2016-04-19 22:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3fe7f9386b6eda01c28d641214482877073179e4', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 3, 'created': '2016-04-20 17:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ef7e436debd318c32833254f0e86f813f1862880', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 4, 'created': '2016-04-21 14:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b2a9f9eb8c070336733a352d9032e6c996d7ce71', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 5, 'created': '2016-04-21 20:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3815fa5737ffea36358d86794fa958173cfafffa', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 6, 'created': '2016-04-21 20:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bbfb54f1cc66b99cccee8b7484899ee26ec88873', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 7, 'created': '2016-04-21 20:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ef084e31d35a20042a8730e5ad177c18bea07a3f', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 8, 'created': '2016-04-21 22:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/23d637446c1c430ff93fcb4c7618575145560e6c', 'message': 'Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n'}, {'number': 9, 'created': '2016-04-22 15:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/450be3c496f0096961d308b720370af9cdc412d7', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 10, 'created': '2016-05-02 15:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b0a72f6fb0c96c5a4282e29ef2860fa8209df2b0', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 11, 'created': '2016-05-02 16:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/23f6dd12a1987ce325b3d3f68fa98eb41cb555af', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 12, 'created': '2016-05-04 15:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8bafe3df56fcea149487cd81c63d5df800ed6c05', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 13, 'created': '2016-05-04 16:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/59c8e6a70db18f866cc3efee2803726dd454643b', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 14, 'created': '2016-05-05 14:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4656188cbe0ad5c4944ff1914420e1b0fb7cffe0', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nAlso, this change introduces a flag for the config check tests to\nindicate whether or not the temp files need to be cleaned up. For\ntargetted, isolated tests, there is no need to write temp files in the\nfirst place, but without some sort of flag the current setUp/tearDown\nmethods would have tried to delete nonexistent files.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 15, 'created': '2016-05-05 16:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e47ce2be7b2d49aba035c1e02aea4d367b2d9384', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 16, 'created': '2016-05-09 16:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6a1677700aa511f66e5d637820551bcbe655eb92', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}, {'number': 17, 'created': '2016-05-10 20:15:58.000000000', 'files': ['releasenotes/notes/multiple-ips-for-host-f27cb1f1e878640d.yaml', 'playbooks/inventory/dynamic_inventory.py', 'tests/test_inventory.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8399965ed095ff7518adbec1ddabdd86bf411223', 'message': ""Check for two IP addresses assigned to same host\n\nWhen parsing the openstack_user_config.yml file, the code would not\naccount for user mistakes when multiple IP addresses were specified for\nthe same hostname. When multiple IP addresses were specified, the last\none parsed would be written to the inventory.\n\nThis change instead throws a runtime error when this situation arises,\nso that the invalid config cannot be written.\n\nThe tox.ini configuration is modified to make sure that the insert order\non the configuration dictionary is the same on every run of the tests.\nWere this not set, the insertion order may well change dependon on the\nhash seed, which would cause test failures because the assertions would\nnot match.\n\nAn OrderedDict is also used to ensure platform differences don't affect\ntesting order. The behavior of this class shouldn't differ from normal\ndictionaries in a way that invalidates the test cases.\n\nChange-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557\n""}]",13,308052,8399965ed095ff7518adbec1ddabdd86bf411223,68,10,17,12892,,,0,"Check for two IP addresses assigned to same host

When parsing the openstack_user_config.yml file, the code would not
account for user mistakes when multiple IP addresses were specified for
the same hostname. When multiple IP addresses were specified, the last
one parsed would be written to the inventory.

This change instead throws a runtime error when this situation arises,
so that the invalid config cannot be written.

The tox.ini configuration is modified to make sure that the insert order
on the configuration dictionary is the same on every run of the tests.
Were this not set, the insertion order may well change dependon on the
hash seed, which would cause test failures because the assertions would
not match.

An OrderedDict is also used to ensure platform differences don't affect
testing order. The behavior of this class shouldn't differ from normal
dictionaries in a way that invalidates the test cases.

Change-Id: I7c724b1dd668a8372bf2dafaf3461e0a3cb1a557
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/52/308052/16 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/inventory/dynamic_inventory.py', 'tests/test_inventory.py']",2,422dbefdf900892574cbccdcbefa2694208eb58b,multiple-ip-assignment," def set_new_ip(self, user_defined_config, group, hostname, ip): # Sets an IP address for a specified host. user_defined_config[group][hostname]['ip'] = ip # rename temporarily our user_config_file so we can use the new one os.rename(USER_CONFIG_FILE, USER_CONFIG_FILE + "".tmp"") # Save new user_config_file with open(USER_CONFIG_FILE, 'wb') as f: f.write(yaml.dump(user_defined_config)) def test_one_host_two_ips(self): # haproxy chosen because it was last in the config file as of # writing self.set_new_ip(self.user_defined_config, 'haproxy_hosts', 'aio1', '172.29.236.101') with self.assertRaises(SystemExit) as context: get_inventory() expectedLog = (""Trying to assign address 172.29.236.101 to host aio1, "" ""but it already has address 172.29.236.100"") self.assertEqual(context.exception.message, expectedLog) ",,30,0
openstack%2Fswift~master~I7aa47c24b5019aa598ee005e01612a49514da25f,openstack/swift,master,I7aa47c24b5019aa598ee005e01612a49514da25f,resurrect gholt blog posts on building consistent hashing ring,MERGED,2016-05-09 20:36:25.000000000,2016-05-11 03:39:04.000000000,2016-05-11 03:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-05-09 20:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/18c52efacc60f235e217f31a53e5320e0d6703c9', 'message': 'resurrect gholt blog posts on building consistent hashing ring\n\nThese are blog posts authored by Greg Holt (gholt) and used with\npermission to add here. Content was only reformatted as rst.\n\nChange-Id: I7aa47c24b5019aa598ee005e01612a49514da25f\n'}, {'number': 2, 'created': '2016-05-10 16:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/35e66e4d1b3dba8d615d52e3e25374d990bee42f', 'message': 'resurrect gholt blog posts on building consistent hashing ring\n\nThese are blog posts authored by Greg Holt (gholt) and used with\npermission to add here. Content was only reformatted as rst and\nwrap prose lines at 70 characters.\n\nChange-Id: I7aa47c24b5019aa598ee005e01612a49514da25f\n'}, {'number': 3, 'created': '2016-05-10 19:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5e399b2f16165a121b3e125aa519742abfa49573', 'message': 'resurrect gholt blog posts on building consistent hashing ring\n\nThese are blog posts authored by Greg Holt (gholt) and used with\npermission to add here. Content was only reformatted as rst and\nwrap prose lines at 70 characters.\n\nChange-Id: I7aa47c24b5019aa598ee005e01612a49514da25f\n'}, {'number': 4, 'created': '2016-05-10 22:41:41.000000000', 'files': ['doc/source/ring_background.rst', 'doc/source/index.rst', 'doc/source/overview_ring.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/cb8cda6588735411c542a1e4d78315ee047a357b', 'message': 'resurrect gholt blog posts on building consistent hashing ring\n\nThese are blog posts authored by Greg Holt (gholt) and used with\npermission to add here. Content was only reformatted as rst and\nwrap prose lines at 70 characters.\n\nChange-Id: I7aa47c24b5019aa598ee005e01612a49514da25f\n'}]",0,314270,cb8cda6588735411c542a1e4d78315ee047a357b,18,4,4,18838,,,0,"resurrect gholt blog posts on building consistent hashing ring

These are blog posts authored by Greg Holt (gholt) and used with
permission to add here. Content was only reformatted as rst and
wrap prose lines at 70 characters.

Change-Id: I7aa47c24b5019aa598ee005e01612a49514da25f
",git fetch https://review.opendev.org/openstack/swift refs/changes/70/314270/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/ring_background.rst', 'doc/source/overview_ring.rst']",3,18c52efacc60f235e217f31a53e5320e0d6703c9,314270," For more background on consistent hashing rings, please see :doc:`ring_background`.",,764,0
openstack%2Fkeystoneauth~master~Ida93dd16972b54ac1965c63ff84f8ce6e01ded3a,openstack/keystoneauth,master,Ida93dd16972b54ac1965c63ff84f8ce6e01ded3a,Documentation example removed for OAuth1,ABANDONED,2016-04-11 17:59:32.000000000,2016-05-11 03:31:32.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7191}]","[{'number': 1, 'created': '2016-04-11 17:59:32.000000000', 'files': ['doc/source/authentication-plugins.rst'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/e8b4d35b33f1cfc500b9a8f3a74b14ebb8138710', 'message': 'Documentation example removed for OAuth1\n\nThere is no plugin for OAuth1 in keystoneauth1 so remove the example\nfrom documentaition.\n\nChange-Id: Ida93dd16972b54ac1965c63ff84f8ce6e01ded3a\nCloses-Bug: 1524862\n'}]",0,304247,e8b4d35b33f1cfc500b9a8f3a74b14ebb8138710,6,3,1,13055,,,0,"Documentation example removed for OAuth1

There is no plugin for OAuth1 in keystoneauth1 so remove the example
from documentaition.

Change-Id: Ida93dd16972b54ac1965c63ff84f8ce6e01ded3a
Closes-Bug: 1524862
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/47/304247/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/authentication-plugins.rst'],1,e8b4d35b33f1cfc500b9a8f3a74b14ebb8138710,bug/1524862,,"V3 OAuth 1.0a Plugins --------------------- There also exists a plugin for OAuth 1.0a authentication. We provide a helper authentication plugin at: :py:class:`~keystoneauth1.v3.contrib.oauth1.auth.OAuth`. The plugin requires the OAuth consumer's key and secret, as well as the OAuth access token's key and secret. For example:: >>> from keystoneauth1.v3.contrib.oauth1 import auth >>> from keystoneauth1 import session >>> from keystoneauth1.v3 import client >>> a = auth.OAuth('http://my.keystone.com:5000/v3', ... consumer_key=consumer_id, ... consumer_secret=consumer_secret, ... access_key=access_token_key, ... access_secret=access_token_secret) >>> s = session.Session(auth=a) ",0,20
openstack%2Fheat~master~Ie53f0c27cc5bc784ec4aa3bba107d79a94ea7743,openstack/heat,master,Ie53f0c27cc5bc784ec4aa3bba107d79a94ea7743,Add Template version registry,ABANDONED,2016-04-29 06:56:25.000000000,2016-05-11 03:27:51.000000000,,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-04-29 06:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b8be1d1336bde3ec7d0581434c725840659bbaf2', 'message': '[WIP]Template version registry\n\nImplement a new function to support alias for heat template\nversion names.\n\nChange-Id: Ie53f0c27cc5bc784ec4aa3bba107d79a94ea7743\nBlueprint: support-alias-for-heat-template-version-names\n'}, {'number': 2, 'created': '2016-05-04 11:30:30.000000000', 'files': ['heat/tests/api/openstack_v1/test_stacks.py', 'heat/tests/test_environment_format.py', 'heat/tests/test_environment.py', 'heat/tests/engine/service/test_stack_update.py', 'heat/engine/environment.py', 'heat/engine/template.py', 'heat/common/environment_format.py', 'doc/source/template_guide/environment.rst', 'heat/tests/test_stack_resource.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6c5963385949efe2f3dc5bd3043f5ac767e15e2d', 'message': 'Add Template version registry\n\nImplement a new function to support alias for heat template\nversion names.\n\nDepends-on: I37fbca824d43c0203343d89536d4bd8cbfb3d1bf\nDepends-on: Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f\nChange-Id: Ie53f0c27cc5bc784ec4aa3bba107d79a94ea7743\nBlueprint: support-alias-for-heat-template-version-names\n'}]",0,311039,6c5963385949efe2f3dc5bd3043f5ac767e15e2d,9,3,2,18389,,,0,"Add Template version registry

Implement a new function to support alias for heat template
version names.

Depends-on: I37fbca824d43c0203343d89536d4bd8cbfb3d1bf
Depends-on: Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f
Change-Id: Ie53f0c27cc5bc784ec4aa3bba107d79a94ea7743
Blueprint: support-alias-for-heat-template-version-names
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/311039/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/template.py', 'heat/common/environment_format.py', 'heat/engine/service.py']",3,b8be1d1336bde3ec7d0581434c725840659bbaf2,bp/template_version_registry,,,19,5
openstack%2Fpython-heatclient~master~Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f,openstack/python-heatclient,master,Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f,Add Template version registry,ABANDONED,2016-04-29 06:56:03.000000000,2016-05-11 03:27:39.000000000,,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-04-29 06:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/af78edff52ba95c854b6dad247f3e1563675da42', 'message': '[WIP]Template version registry\n\nImplement a new function to support alias for heat template\nversion names.\n\nBlueprint: support-alias-for-heat-template-version-names\n\nChange-Id: Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f\n'}, {'number': 2, 'created': '2016-05-04 11:30:08.000000000', 'files': ['heatclient/common/environment_format.py', 'heatclient/tests/unit/test_environment_format.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0d6ad6ac81de7a69bda2930e478a32bb7d7a5cc1', 'message': 'Add Template version registry\n\nImplement a new function to support alias for heat template\nversion names.\n\nDepends-on: I37fbca824d43c0203343d89536d4bd8cbfb3d1bf\nBlueprint: support-alias-for-heat-template-version-names\n\nChange-Id: Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f\n'}]",0,311038,0d6ad6ac81de7a69bda2930e478a32bb7d7a5cc1,7,3,2,18389,,,0,"Add Template version registry

Implement a new function to support alias for heat template
version names.

Depends-on: I37fbca824d43c0203343d89536d4bd8cbfb3d1bf
Blueprint: support-alias-for-heat-template-version-names

Change-Id: Ibcf370dac0fa138a34bf5c0323db84dfd2faab3f
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/38/311038/2 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/common/environment_format.py'],1,af78edff52ba95c854b6dad247f3e1563675da42,bp/template_version_registry," PARAMETER_DEFAULTS, PARAMETERS, RESOURCE_REGISTRY, EVENT_SINKS, TEMPLATE_VERSION_REGISTRY 'parameter_defaults', 'parameters', 'resource_registry', 'event_sinks', 'template_version_registry'"," PARAMETER_DEFAULTS, PARAMETERS, RESOURCE_REGISTRY, EVENT_SINKS 'parameter_defaults', 'parameters', 'resource_registry', 'event_sinks'",4,2
openstack%2Fcinder~master~I5a5774cff71f7a259f3ff06a7d253bb6f0724c71,openstack/cinder,master,I5a5774cff71f7a259f3ff06a7d253bb6f0724c71,NetApp: Managing cDOT LUN by UUID fails,MERGED,2016-05-04 18:38:03.000000000,2016-05-11 03:19:41.000000000,2016-05-09 02:55:04.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11865}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15903}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17130}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 18827}]","[{'number': 1, 'created': '2016-05-04 18:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9de4659c8ad0a7e39b076763320e473c4f300d9c', 'message': ""NetApp: Managing cDOT LUN by UUID fails\n\nManage/unmanage is supported with the NetApp Data ONTAP drivers,\nand cDOT supports specifying a LUN to manage by its UUID, but this\nisn't working and the code involved isn't very readable. This\npatch fixes the bug, clarifies the surrounding logic, removes dead\ncode, and brings unit test coverage of the impacted method to 100%.\n\nChange-Id: I5a5774cff71f7a259f3ff06a7d253bb6f0724c71\nCloses-Bug: #1569548\n""}, {'number': 2, 'created': '2016-05-05 19:32:15.000000000', 'files': ['cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c53ef881a752aac97988a4a69f7a1d896f625905', 'message': ""NetApp: Managing cDOT LUN by UUID fails\n\nManage/unmanage is supported with the NetApp Data ONTAP drivers,\nand cDOT supports specifying a LUN to manage by its UUID, but this\nisn't working and the code involved isn't very readable. This\npatch fixes the bug, clarifies the surrounding logic, removes dead\ncode, and brings unit test coverage of the impacted method to 100%.\n\nChange-Id: I5a5774cff71f7a259f3ff06a7d253bb6f0724c71\nCloses-Bug: #1569548\n""}]",0,312684,c53ef881a752aac97988a4a69f7a1d896f625905,97,37,2,11865,,,0,"NetApp: Managing cDOT LUN by UUID fails

Manage/unmanage is supported with the NetApp Data ONTAP drivers,
and cDOT supports specifying a LUN to manage by its UUID, but this
isn't working and the code involved isn't very readable. This
patch fixes the bug, clarifies the surrounding logic, removes dead
code, and brings unit test coverage of the impacted method to 100%.

Change-Id: I5a5774cff71f7a259f3ff06a7d253bb6f0724c71
Closes-Bug: #1569548
",git fetch https://review.opendev.org/openstack/cinder refs/changes/84/312684/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py']",2,9de4659c8ad0a7e39b076763320e473c4f300d9c,bug/1569548," lun_info = {} if path: lun_info['path'] = path elif uuid: if not hasattr(self, 'vserver'): reason = _('Volume manage identifier with source-id is only ' 'supported with clustered Data ONTAP.') raise exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=reason) lun_info['uuid'] = uuid else: reason = _('Volume manage identifier must contain either ' 'source-id or source-name element.') for lun in luns: netapp_lun = self._extract_lun_info(lun) if self._is_lun_valid_on_storage(netapp_lun): return netapp_lun "," if not (uuid or path): reason = _('Reference must contain either source-id' ' or source-name element.') lun_info = {} lun_info.setdefault('path', path if path else None) if hasattr(self, 'vserver') and uuid: lun_info['uuid'] = uuid if luns: for lun in luns: netapp_lun = self._extract_lun_info(lun) storage_valid = self._is_lun_valid_on_storage(netapp_lun) uuid_valid = True if uuid: if netapp_lun.get_metadata_property('UUID') == uuid: uuid_valid = True else: uuid_valid = False if storage_valid and uuid_valid: return netapp_lun",91,30
openstack%2Fdevstack~stable%2Fmitaka~Ie5fc0d2a45c1b564f98c69ec9ea6fbdeeb465d32,openstack/devstack,stable/mitaka,Ie5fc0d2a45c1b564f98c69ec9ea6fbdeeb465d32,Remove vpnaas code from devstack,MERGED,2016-05-06 23:10:49.000000000,2016-05-11 03:16:22.000000000,2016-05-11 03:16:22.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-05-06 23:10:49.000000000', 'files': ['lib/neutron_plugins/services/vpn', 'stackrc', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/95cb2ea68f7e12a3e7baf627a2c37e77caeea294', 'message': 'Remove vpnaas code from devstack\n\nThis service is now configured by devstack plugin in master.\n\nChange-Id: Ie5fc0d2a45c1b564f98c69ec9ea6fbdeeb465d32\n(cherry picked from commit 1a791cbc449a3cfdbc3d3b94c6cda3ddefa17af4)\n'}]",0,313792,95cb2ea68f7e12a3e7baf627a2c37e77caeea294,8,3,1,5196,,,0,"Remove vpnaas code from devstack

This service is now configured by devstack plugin in master.

Change-Id: Ie5fc0d2a45c1b564f98c69ec9ea6fbdeeb465d32
(cherry picked from commit 1a791cbc449a3cfdbc3d3b94c6cda3ddefa17af4)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/92/313792/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron_plugins/services/vpn', 'stackrc', 'lib/neutron-legacy']",3,95cb2ea68f7e12a3e7baf627a2c37e77caeea294,,,"NEUTRON_VPNAAS_DIR=$DEST/neutron-vpnaas# Default provider for VPN service DEFAULT_VPN_PROVIDER=VPN:openswan:neutron_vpnaas.services.vpn.service_drivers.ipsec.IPsecVPNDriver:default Q_VPN_CONF_FILE=$NEUTRON_CONF_DIR/vpn_agent.ini# List of (optional) config files for VPN device drivers to use with # the neutron-q-vpn agent declare -a Q_VPN_EXTRA_CONF_FILES # VPN service plugin functions # ------------------------------------------- # Hardcoding for 1 service plugin for now source $TOP_DIR/lib/neutron_plugins/services/vpn function _determine_config_vpn { local cfg_file local opts=""--config-file $NEUTRON_CONF --config-file=$Q_L3_CONF_FILE --config-file=$Q_VPN_CONF_FILE"" if is_service_enabled q-fwaas; then opts+="" --config-file $Q_FWAAS_CONF_FILE"" fi for cfg_file in ${Q_VPN_EXTRA_CONF_FILES[@]}; do opts+="" --config-file $cfg_file"" done echo ""$opts"" } ""neutron-vpn-agent"") opts=""$(_determine_config_vpn)"" ;; if is_service_enabled q-vpn; then deprecated ""Configuring q-vpn through devstack is deprecated"" _configure_neutron_vpn fi if is_service_enabled q-vpn; then git_clone $NEUTRON_VPNAAS_REPO $NEUTRON_VPNAAS_DIR $NEUTRON_VPNAAS_BRANCH setup_develop $NEUTRON_VPNAAS_DIR fi elif is_service_enabled q-vpn; then run_process q-vpn ""$AGENT_VPN_BINARY $(determine_config_files neutron-vpn-agent)"" if is_service_enabled q-vpn; then neutron_vpn_stop fi if is_service_enabled q-vpn; then neutron_vpn_configure_agent fi function _configure_neutron_vpn { # Uses oslo config generator to generate VPNaaS sample configuration files (cd $NEUTRON_VPNAAS_DIR && exec ./tools/generate_config_file_samples.sh) if [ -f $NEUTRON_VPNAAS_DIR/etc/neutron_vpnaas.conf.sample ]; then cp $NEUTRON_VPNAAS_DIR/etc/neutron_vpnaas.conf.sample $NEUTRON_CONF_DIR/neutron_vpnaas.conf iniset $NEUTRON_CONF_DIR/neutron_vpnaas.conf service_providers service_provider $DEFAULT_VPN_PROVIDER fi neutron_vpn_install_agent_packages neutron_vpn_configure_common } ",0,118
openstack%2Fcinder~master~I1b69e57309df0b6dc675009f42cef34fd501b179,openstack/cinder,master,I1b69e57309df0b6dc675009f42cef34fd501b179,Use messaging notifications transport instead of default,MERGED,2016-04-04 15:19:20.000000000,2016-05-11 03:10:58.000000000,2016-04-22 13:47:26.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 10873}, {'_account_id': 11751}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 20683}, {'_account_id': 20993}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-04-04 15:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f58d9a6d177699005523888164ffa1ee7fcced7d', 'message': ""Use messaging notifications transport instead of default\n\nThe usage of oslo_messaging.get_transport is not meant for\nnotifications; And oslo_messaging.get_notification_transport is\nfavored for those means. So this change introduces the usage of that\nfunction.\n\nIf the settings for the notifications are not set with the\nconfiguration that's under the oslo_messaging_notifications group,\nthis will fall back to the old settings which are under the DEFAULT\ngroup; just like this used to work.\n\nChange-Id: I1b69e57309df0b6dc675009f42cef34fd501b179\n""}, {'number': 2, 'created': '2016-04-14 17:37:44.000000000', 'files': ['cinder/rpc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1bdb400656193ccb13fc2e2799db1ab7150832ab', 'message': ""Use messaging notifications transport instead of default\n\nThe usage of oslo_messaging.get_transport is not meant for\nnotifications; And oslo_messaging.get_notification_transport is\nfavored for those means. So this change introduces the usage of that\nfunction.\n\nIf the settings for the notifications are not set with the\nconfiguration that's under the oslo_messaging_notifications group,\nthis will fall back to the old settings which are under the DEFAULT\ngroup; just like this used to work.\n\nChange-Id: I1b69e57309df0b6dc675009f42cef34fd501b179\n""}]",2,301182,1bdb400656193ccb13fc2e2799db1ab7150832ab,91,50,2,10873,,,0,"Use messaging notifications transport instead of default

The usage of oslo_messaging.get_transport is not meant for
notifications; And oslo_messaging.get_notification_transport is
favored for those means. So this change introduces the usage of that
function.

If the settings for the notifications are not set with the
configuration that's under the oslo_messaging_notifications group,
this will fall back to the old settings which are under the DEFAULT
group; just like this used to work.

Change-Id: I1b69e57309df0b6dc675009f42cef34fd501b179
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/301182/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/rpc.py', 'cinder/service.py']",2,f58d9a6d177699005523888164ffa1ee7fcced7d,oslo_messaging_notifications," rpc.NOTIFICATION_TRANSPORT, ""cinder"", binary, host)"," rpc.TRANSPORT, ""cinder"", binary, host)",13,5
openstack%2Fkeystoneauth~master~Ie53aeb1b926104cac692cd98551a701522f7fec4,openstack/keystoneauth,master,Ie53aeb1b926104cac692cd98551a701522f7fec4,Add oauth plugin to keystoneauth,MERGED,2016-05-10 02:50:24.000000000,2016-05-11 02:58:27.000000000,2016-05-11 02:54:47.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 13055}]","[{'number': 1, 'created': '2016-05-10 02:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ac894688786d5b3d9bee43ddb0986a04899d2238', 'message': 'Add oauth plugin to keystoneauth\n\nOAuth1 has been supported by keystone for a long time, and was supported\nas an authentication plugin in keystoneclient. Port this work to\nkeystoneauth and add the ability to load it from the CLI.\n\nCloses-Bug: #1524862\nChange-Id: Ie53aeb1b926104cac692cd98551a701522f7fec4\n'}, {'number': 2, 'created': '2016-05-10 04:34:47.000000000', 'files': ['keystoneauth1/extras/oauth1/__init__.py', 'doc/source/authentication-plugins.rst', 'keystoneauth1/extras/oauth1/v3.py', 'keystoneauth1/tests/unit/extras/oauth1/test_oauth1.py', 'keystoneauth1/tests/unit/extras/oauth1/__init__.py', 'keystoneauth1/tests/unit/extras/oauth1/test_oauth1_loading.py', 'setup.cfg', 'tox.ini', 'keystoneauth1/extras/oauth1/_loading.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/c10722b7894d27d6314c41326f096fc6f81b4c0f', 'message': 'Add oauth plugin to keystoneauth\n\nOAuth1 has been supported by keystone for a long time, and was supported\nas an authentication plugin in keystoneclient. Port this work to\nkeystoneauth and add the ability to load it from the CLI.\n\nCloses-Bug: #1524862\nChange-Id: Ie53aeb1b926104cac692cd98551a701522f7fec4\n'}]",0,314401,c10722b7894d27d6314c41326f096fc6f81b4c0f,11,4,2,7191,,,0,"Add oauth plugin to keystoneauth

OAuth1 has been supported by keystone for a long time, and was supported
as an authentication plugin in keystoneclient. Port this work to
keystoneauth and add the ability to load it from the CLI.

Closes-Bug: #1524862
Change-Id: Ie53aeb1b926104cac692cd98551a701522f7fec4
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/01/314401/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/authentication-plugins.rst', 'keystoneauth1/extras/oauth1/__init__.py', 'keystoneauth1/extras/oauth1/v3.py', 'keystoneauth1/tests/unit/extras/oauth1/test_oauth1.py', 'keystoneauth1/tests/unit/extras/oauth1/__init__.py', 'keystoneauth1/tests/unit/extras/oauth1/test_oauth1_loading.py', 'setup.cfg', 'tox.ini', 'keystoneauth1/extras/oauth1/_loading.py']",9,ac894688786d5b3d9bee43ddb0986a04899d2238,bug/1524862,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from keystoneauth1.extras.oauth1 import v3 from keystoneauth1 import loading # NOTE(jamielennox): This is not a BaseV3Loader because we don't want to # include the scoping options like project-id in the option list class V3OAuth1(loading.BaseIdentityLoader): @property def plugin_class(self): return v3.OAuth1 def get_options(self): options = super(V3OAuth1, self).get_options() options.extend([ loading.Opt('consumer-key', required=True, help='OAuth Consumer ID/Key'), loading.Opt('consumer-secret', required=True, help='OAuth Consumer Secret'), loading.Opt('access-key', required=True, help='OAuth Access Key'), loading.Opt('access-secret', required=True, help='OAuth Access Secret'), ]) return options ",,326,9
openstack%2Fopenstack-ansible-os_magnum~master~I3c2e64f546e90c2b2754d2453ce454d3d03e021c,openstack/openstack-ansible-os_magnum,master,I3c2e64f546e90c2b2754d2453ce454d3d03e021c,Remove unneeded with_items usage,MERGED,2016-04-22 14:18:35.000000000,2016-05-11 02:33:33.000000000,2016-05-11 02:33:33.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}]","[{'number': 1, 'created': '2016-04-22 14:18:35.000000000', 'files': ['extras/os-magnum-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/e284362b19b0d0dcd3b196ec3fa9e11461a601c9', 'message': 'Remove unneeded with_items usage\n\nNo need to loop when we only have a single element\n\nChange-Id: I3c2e64f546e90c2b2754d2453ce454d3d03e021c\n'}]",0,309430,e284362b19b0d0dcd3b196ec3fa9e11461a601c9,10,4,1,19814,,,0,"Remove unneeded with_items usage

No need to loop when we only have a single element

Change-Id: I3c2e64f546e90c2b2754d2453ce454d3d03e021c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/30/309430/1 && git format-patch -1 --stdout FETCH_HEAD,['extras/os-magnum-install.yml'],1,e284362b19b0d0dcd3b196ec3fa9e11461a601c9,remove_unneeded_with_items," path: ""/openstack/log/{{ inventory_hostname }}-magnum"" src: ""/openstack/log/{{ inventory_hostname }}-magnum"" dest: ""/var/log/magnum"" state: ""link"""," path: ""{{ item.path }}"" with_items: - { path: ""/openstack/log/{{ inventory_hostname }}-magnum"" } src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" state: ""{{ item.state }}"" with_items: - { src: ""/openstack/log/{{ inventory_hostname }}-magnum"", dest: ""/var/log/magnum"", state: ""link"" }",4,8
openstack%2Fneutron-lbaas~master~I526f41bc631e160df95c9df9fc6c04ca36342dbe,openstack/neutron-lbaas,master,I526f41bc631e160df95c9df9fc6c04ca36342dbe,Fixed typo in subunit-trace.py,ABANDONED,2016-04-15 06:42:28.000000000,2016-05-11 02:13:18.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12403}, {'_account_id': 14605}]","[{'number': 1, 'created': '2016-04-15 06:42:28.000000000', 'files': ['tools/subunit-trace.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ab567539565d5366b00f00d16d969998122c1c2f', 'message': 'Fixed typo in subunit-trace.py\n\nChange-Id: I526f41bc631e160df95c9df9fc6c04ca36342dbe\n'}]",0,306261,ab567539565d5366b00f00d16d969998122c1c2f,8,6,1,18085,,,0,"Fixed typo in subunit-trace.py

Change-Id: I526f41bc631e160df95c9df9fc6c04ca36342dbe
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/61/306261/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/subunit-trace.py'],1,ab567539565d5366b00f00d16d969998122c1c2f,, Make it possible to strip out the test scenarios information (not to, Make it possible to strip out the testscenarios information (not to,1,1
openstack%2Fneutron-lbaas~master~Iebc63add2b45f26bccb132ff264523a8376cf576,openstack/neutron-lbaas,master,Iebc63add2b45f26bccb132ff264523a8376cf576,Fixed typo in subunit-trace.py,ABANDONED,2016-02-29 07:34:07.000000000,2016-05-11 02:11:29.000000000,,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 12040}, {'_account_id': 14605}, {'_account_id': 16522}, {'_account_id': 18085}, {'_account_id': 20777}, {'_account_id': 20991}, {'_account_id': 20997}]","[{'number': 1, 'created': '2016-02-29 07:34:07.000000000', 'files': ['tools/subunit-trace.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/75a7c4cc6524fbaba54c0c3e1bf1411f171b750c', 'message': 'Fixed typo in subunit-trace.py\n\nChange-Id: Iebc63add2b45f26bccb132ff264523a8376cf576\n'}]",4,285913,75a7c4cc6524fbaba54c0c3e1bf1411f171b750c,16,11,1,18085,,,0,"Fixed typo in subunit-trace.py

Change-Id: Iebc63add2b45f26bccb132ff264523a8376cf576
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/13/285913/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/subunit-trace.py'],1,75a7c4cc6524fbaba54c0c3e1bf1411f171b750c,, Make it possible to strip out the test scenarios information (not to identify generated negative tests., Make it possible to strip out the testscenarios information (not to indentify generated negative tests.,2,2
openstack%2Ftripleo-heat-templates~master~Ie5e4ae8ac6c81e78ce12ebe57095ef397929b19f,openstack/tripleo-heat-templates,master,Ie5e4ae8ac6c81e78ce12ebe57095ef397929b19f,WIP: Add BondType/BridgeType parameters,ABANDONED,2016-04-19 02:32:33.000000000,2016-05-11 02:04:02.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-04-19 02:32:33.000000000', 'files': ['network/config/bond-with-vlans/cinder-storage.yaml', 'network/config/bond-with-vlans/swift-storage.yaml', 'network/config/bond-with-vlans/ceph-storage.yaml', 'network/config/bond-with-vlans/controller.yaml', 'network/config/bond-with-vlans/controller-no-external.yaml', 'network/config/bond-with-vlans/controller-v6.yaml', 'network/config/bond-with-vlans/compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55478392fdefde745404866344ad59b505e54603', 'message': 'WIP: Add BondType/BridgeType parameters\n\nAdd new BondType and BridgeType parameters to the bond-with-vlans network\nconfigs.  These options can be set to ovs_bond/linux_bond  and\novs_bridge/linux_bridge (respectively) to switch between using OVS or linux\nbridge for bonds.\n\nNOTE: need to also consider how to handle the BondInterfaceOvsOptions\nparameter (should we add another parameter for specific Linux bridge\noptions too?). Even so os-net-config should ignore ovs_options for\nlinux bonds functionally this should be fine.\n\nChange-Id: I888da58c71a54f96c20ef677a0392dcf09c7193e\n\nFoo\n\nChange-Id: Ie5e4ae8ac6c81e78ce12ebe57095ef397929b19f\n'}]",1,307539,55478392fdefde745404866344ad59b505e54603,7,3,1,360,,,0,"WIP: Add BondType/BridgeType parameters

Add new BondType and BridgeType parameters to the bond-with-vlans network
configs.  These options can be set to ovs_bond/linux_bond  and
ovs_bridge/linux_bridge (respectively) to switch between using OVS or linux
bridge for bonds.

NOTE: need to also consider how to handle the BondInterfaceOvsOptions
parameter (should we add another parameter for specific Linux bridge
options too?). Even so os-net-config should ignore ovs_options for
linux bonds functionally this should be fine.

Change-Id: I888da58c71a54f96c20ef677a0392dcf09c7193e

Foo

Change-Id: Ie5e4ae8ac6c81e78ce12ebe57095ef397929b19f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/307539/1 && git format-patch -1 --stdout FETCH_HEAD,"['network/config/bond-with-vlans/cinder-storage.yaml', 'network/config/bond-with-vlans/swift-storage.yaml', 'network/config/bond-with-vlans/ceph-storage.yaml', 'network/config/bond-with-vlans/controller.yaml', 'network/config/bond-with-vlans/controller-no-external.yaml', 'network/config/bond-with-vlans/controller-v6.yaml', 'network/config/bond-with-vlans/compute.yaml']",7,55478392fdefde745404866344ad59b505e54603,bond_type, BondType: default: 'ovs_bond' description: The type of bond to create ovs_bond or linux_bond. type: string BridgeType: default: 'ovs_bridge' description: The type of bridge to create ovs_bridge or linux_bridge. type: string type: {get_param: BridgeType} type: {get_param: BondType}, type: ovs_bridge type: ovs_bond,70,14
openstack%2Fopenstack-manuals~master~I326744e0c3d456d5a9470a800f68f40ed7cc7ee1,openstack/openstack-manuals,master,I326744e0c3d456d5a9470a800f68f40ed7cc7ee1,[contributor] update Install Guide team lead,MERGED,2016-05-10 23:34:26.000000000,2016-05-11 02:03:14.000000000,2016-05-11 02:03:14.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 16237}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-05-10 23:34:26.000000000', 'files': ['doc/contributor-guide/source/team-structure.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5847856b25a9c67b476ffaf1dbda9620a3940021', 'message': '[contributor] update Install Guide team lead\n\nUpdate the Install Guide team lead to Lana Brindley.\n\nChange-Id: I326744e0c3d456d5a9470a800f68f40ed7cc7ee1\n'}]",0,314808,5847856b25a9c67b476ffaf1dbda9620a3940021,8,4,1,12686,,,0,"[contributor] update Install Guide team lead

Update the Install Guide team lead to Lana Brindley.

Change-Id: I326744e0c3d456d5a9470a800f68f40ed7cc7ee1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/08/314808/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/contributor-guide/source/team-structure.rst'],1,5847856b25a9c67b476ffaf1dbda9620a3940021,update-install-lead,* `Installation guides`_: Lana Brindley,* `Installation guides`_: Christian Berendt,1,1
openstack%2Foslo.db~stable%2Fmitaka~I210011f59398baa1403820f902aecbfecc7e62fd,openstack/oslo.db,stable/mitaka,I210011f59398baa1403820f902aecbfecc7e62fd,Updated from global requirements,MERGED,2016-04-29 22:40:00.000000000,2016-05-11 01:58:25.000000000,2016-05-11 01:58:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8688}]","[{'number': 1, 'created': '2016-04-29 22:40:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7f61fc588d6ffbbd2e304390c46f50708113b941', 'message': 'Updated from global requirements\n\nChange-Id: I210011f59398baa1403820f902aecbfecc7e62fd\n'}]",0,311329,7f61fc588d6ffbbd2e304390c46f50708113b941,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I210011f59398baa1403820f902aecbfecc7e62fd
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/29/311329/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7f61fc588d6ffbbd2e304390c46f50708113b941,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3 # BSD,1,1
openstack%2Foslo.db~master~Ia9fc0a54e5c6b9d30be7e051026471f5b0048fd1,openstack/oslo.db,master,Ia9fc0a54e5c6b9d30be7e051026471f5b0048fd1,Updated from global requirements,MERGED,2016-05-10 00:48:37.000000000,2016-05-11 01:57:37.000000000,2016-05-11 01:57:37.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2016-05-10 00:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/948386f8c41ae130f76618bd74381bf7a181fc1b', 'message': 'Updated from global requirements\n\nChange-Id: Ia9fc0a54e5c6b9d30be7e051026471f5b0048fd1\n'}, {'number': 2, 'created': '2016-05-10 18:41:38.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/3ac4f3f2d8ddfd60543b978026ce37ab2f767cab', 'message': 'Updated from global requirements\n\nChange-Id: Ia9fc0a54e5c6b9d30be7e051026471f5b0048fd1\n'}]",0,314367,3ac4f3f2d8ddfd60543b978026ce37ab2f767cab,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ia9fc0a54e5c6b9d30be7e051026471f5b0048fd1
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/67/314367/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,948386f8c41ae130f76618bd74381bf7a181fc1b,openstack/requirements,stevedore>=1.10.0 # Apache-2.0,stevedore>=1.9.0 # Apache-2.0,1,1
openstack%2Fsenlin~master~I529110c16e4b8cbdc4ba941a57c9923a9d001f08,openstack/senlin,master,I529110c16e4b8cbdc4ba941a57c9923a9d001f08,Add releasenote for completed tempest API tests,ABANDONED,2016-05-10 09:14:36.000000000,2016-05-11 01:55:28.000000000,,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-05-10 09:14:36.000000000', 'files': ['releasenotes/notes/tempest-api-policy-create-delete-update-077868a682ddf460.yaml', 'releasenotes/notes/tempest-api-node-create-delete-update-845a3818653f74a0.yaml', 'releasenotes/notes/tempest-api-receiver-create-delete-trigger-51002012e54f9375.yaml', 'releasenotes/notes/tempest-api-cluster-create-delete-update-action-4a88ff8547e16dc7.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/8665389d494616f41646242655770e7bcfe93d7a', 'message': 'Add releasenote for completed tempest API tests\n\nThis patch adds releasenotes for completed tempest API tests.\n\nChange-Id: I529110c16e4b8cbdc4ba941a57c9923a9d001f08\n'}]",0,314470,8665389d494616f41646242655770e7bcfe93d7a,4,2,1,11034,,,0,"Add releasenote for completed tempest API tests

This patch adds releasenotes for completed tempest API tests.

Change-Id: I529110c16e4b8cbdc4ba941a57c9923a9d001f08
",git fetch https://review.opendev.org/openstack/senlin refs/changes/70/314470/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/tempest-api-policy-create-delete-update-077868a682ddf460.yaml', 'releasenotes/notes/tempest-api-node-create-delete-update-845a3818653f74a0.yaml', 'releasenotes/notes/tempest-api-receiver-create-delete-trigger-51002012e54f9375.yaml', 'releasenotes/notes/tempest-api-cluster-create-delete-update-action-4a88ff8547e16dc7.yaml']",4,8665389d494616f41646242655770e7bcfe93d7a,releasenotes,"--- features: - Add tempest test for Cluster create, delete, update and action API interfaces. ",,13,0
openstack%2Fglance-specs~master~I50c13d7e9ba39687422649e83698edd34c1f7cd9,openstack/glance-specs,master,I50c13d7e9ba39687422649e83698edd34c1f7cd9,Support Upload Image Data To The Specified Backend,ABANDONED,2016-04-29 01:24:45.000000000,2016-05-11 01:47:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 9303}, {'_account_id': 15054}]","[{'number': 1, 'created': '2016-04-29 01:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/5d8595318d03261f70445f6b5ba1fc803d8280f4', 'message': ""Support Upload Image Data To The Specified Backend\n\nNow,glance v2 doesn't support upload the image data\nto the specified backend. It means that users could\nonly upload the image data the default glance store\nbackend even there are some backend support for glance.\n\nChange-Id: I50c13d7e9ba39687422649e83698edd34c1f7cd9\n""}, {'number': 2, 'created': '2016-04-29 01:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/cb9dad716d2bffcb08e0699062e813ceb30b5cab', 'message': ""Support Upload Image Data To The Specified Backend\n\nNow,glance v2 doesn't support upload the image data\nto the specified backend. It means that users could\nonly upload the image data the default glance store\nbackend even there are some backend support for glance.\n\nbp: support-upload-image-to-specified-backend\nChange-Id: I50c13d7e9ba39687422649e83698edd34c1f7cd9\n""}, {'number': 3, 'created': '2016-04-29 01:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/291372eb61c13a704f9356a66ad9bde547436487', 'message': ""Support Upload Image Data To The Specified Backend\n\nNow,glance v2 doesn't support upload the image data\nto the specified backend. It means that users could\nonly upload the image data the default glance store\nbackend even there are some backend support for glance.\n\nbp: support-upload-image-to-specified-backend\nChange-Id: I50c13d7e9ba39687422649e83698edd34c1f7cd9\n""}, {'number': 4, 'created': '2016-04-29 01:44:43.000000000', 'files': ['specs/newton/approved/glance/lite-specs.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/a63a41d4c73981010238a4bcde8ecc3ff33a2e7e', 'message': ""Support Upload Image Data To The Specified Backend\n\nNow,glance v2 doesn't support upload the image data\nto the specified backend. It means that users could\nonly upload the image data the default glance store\nbackend even there are some backend support for glance.\n\nbp: support-upload-image-to-specified-backend\nChange-Id: I50c13d7e9ba39687422649e83698edd34c1f7cd9\n""}]",5,310970,a63a41d4c73981010238a4bcde8ecc3ff33a2e7e,13,5,4,15054,,,0,"Support Upload Image Data To The Specified Backend

Now,glance v2 doesn't support upload the image data
to the specified backend. It means that users could
only upload the image data the default glance store
backend even there are some backend support for glance.

bp: support-upload-image-to-specified-backend
Change-Id: I50c13d7e9ba39687422649e83698edd34c1f7cd9
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/70/310970/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/approved/glance/lite-specs.rst'],1,5d8595318d03261f70445f6b5ba1fc803d8280f4,bp/support-upload-image-to-specified-backend,"<Support Upload Image Data To The Specified Backend> ---------------------------------------------------- :problem: Now,glance v2 doesn't support upload the image data to the specified backend. It means that users could only upload the image data the default glance store backend even there are some backend support for glance. :solution: In v2, I suggest that we can introduce a new optional parameter to image date upload API. It could be named ""data_store"" or something else. It will be used for let users decide which backend the image data will be saved. If it doesn't be passed. The image data will be saved to the default backend which is contained in config file. :impacts: APIimpact: An optional parameter will be added to the create image API. Docimpact: Add the parameter to the doc. :alternatives: In v1, users could pass a header named ""x-image-meta-store"" to indicate which backend they want the image data be stored. We could do it the same as v1. :timeline: Newton-1 :reviewers: Need to add. :assignee: wangxiyuan<wangxiyuan@huawei.com>",,29,0
openstack%2Fironic-ui~master~Id7637c72375fdb7c41f09b27d494067ad0cf9131,openstack/ironic-ui,master,Id7637c72375fdb7c41f09b27d494067ad0cf9131,Update requirement for Horizon in stable/mitaka closes-bug: #1565577 Change-Id: Id7637c72375fdb7c41f09b27d494067ad0cf9131,ABANDONED,2016-04-04 22:39:20.000000000,2016-05-11 01:45:01.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 11655}, {'_account_id': 16628}, {'_account_id': 20581}]","[{'number': 1, 'created': '2016-04-04 22:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/588a1c91fe36bb2ec14e7e0650838ecad8c7081e', 'message': 'Update requirement for Horizon in stable/mitaka\n\nChange-Id: Id7637c72375fdb7c41f09b27d494067ad0cf9131\n'}, {'number': 2, 'created': '2016-04-04 23:08:08.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/cd4abe820185b636acf54ff2827a474a0b331ff2', 'message': 'Update requirement for Horizon in stable/mitaka\ncloses-bug: #1565577\nChange-Id: Id7637c72375fdb7c41f09b27d494067ad0cf9131\n'}]",0,301377,cd4abe820185b636acf54ff2827a474a0b331ff2,10,5,2,20581,,,0,"Update requirement for Horizon in stable/mitaka
closes-bug: #1565577
Change-Id: Id7637c72375fdb7c41f09b27d494067ad0cf9131
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/77/301377/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,588a1c91fe36bb2ec14e7e0650838ecad8c7081e,bug/1565577,-e git://github.com/openstack/horizon/tree/stable/mitaka.git#egg=horizon,-e git://github.com/openstack/horizon.git#egg=horizon,1,1
openstack%2Fswift~master~I39489dd660935bdbfbc26b92af86814369369fb5,openstack/swift,master,I39489dd660935bdbfbc26b92af86814369369fb5,Remove ThreadPool class,MERGED,2016-04-29 18:28:33.000000000,2016-05-11 01:37:40.000000000,2016-05-11 01:37:40.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 9625}]","[{'number': 1, 'created': '2016-04-29 18:28:33.000000000', 'files': ['swift/common/utils.py', 'test/unit/obj/test_diskfile.py', 'test/unit/common/test_utils.py', 'swift/common/exceptions.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4c11833a9cbff499725365e535e217f3eae3c442', 'message': 'Remove ThreadPool class\n\nWith the removement of threads_per_disk there is no longer a need to use\nrun_in_thread() at all; it was just calling the function itself when\nrunning with 0 threads.\nSimilar to force_run_in_thread() - with 0 threads it was basically doing\nthe same like in tpool_reraise(), therefore replacing the call and\nfinally removing the complete ThreadPool class.\n\nNote that this might break external consumers that are inheriting\nBaseDiskFileManager; in this case you need to adopt this change in your\ncodebase then.\n\nChange-Id: I39489dd660935bdbfbc26b92af86814369369fb5\n'}]",0,311219,4c11833a9cbff499725365e535e217f3eae3c442,8,4,1,6968,,,0,"Remove ThreadPool class

With the removement of threads_per_disk there is no longer a need to use
run_in_thread() at all; it was just calling the function itself when
running with 0 threads.
Similar to force_run_in_thread() - with 0 threads it was basically doing
the same like in tpool_reraise(), therefore replacing the call and
finally removing the complete ThreadPool class.

Note that this might break external consumers that are inheriting
BaseDiskFileManager; in this case you need to adopt this change in your
codebase then.

Change-Id: I39489dd660935bdbfbc26b92af86814369369fb5
",git fetch https://review.opendev.org/openstack/swift refs/changes/19/311219/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/obj/test_diskfile.py', 'test/unit/common/test_utils.py', 'swift/common/exceptions.py', 'swift/obj/diskfile.py']",5,4c11833a9cbff499725365e535e217f3eae3c442,," fsync_dir, drop_buffer_cache, lock_path, write_pickle, \ get_md5_socket, F_SETPIPE_SZ, decode_timestamps, encode_timestamps, \ tpool_reraise write_pickle( return self.diskfile_cls(self, dev_path, return self.diskfile_cls(self, dev_path, _junk, hashes = tpool_reraise( def __init__(self, name, datadir, fd, tmppath, bytes_per_sync, diskfile): while chunk: written = os.write(self._fd, chunk) self._upload_size += written chunk = chunk[written:] tpool_reraise(fdatasync, self._fd) tpool_reraise(self._finalize_put, metadata, target_path, cleanup) def __init__(self, fp, data_file, obj_size, etag, chunk = self._fp.read(self._disk_chunk_size) (bytes_in_pipe, _1, _2) = splice( rfd, None, client_wpipe, None, pipe_size, 0) self._quarantined_dir = self.manager.quarantine_renamer( self._device_path, self._data_file) def __init__(self, mgr, device_path, partition, self._quarantined_dir = self.manager.quarantine_renamer( self._device_path, data_file) self._metadata['ETag'], self._disk_chunk_size, tpool_reraise(self._finalize_durable, durable_file_path)"," fsync_dir, drop_buffer_cache, ThreadPool, lock_path, write_pickle, \ get_md5_socket, F_SETPIPE_SZ, decode_timestamps, encode_timestamps self.threadpools = defaultdict(lambda: ThreadPool(nthreads=0)) self.threadpools[device].run_in_thread( write_pickle, return self.diskfile_cls(self, dev_path, self.threadpools[device], return self.diskfile_cls(self, dev_path, self.threadpools[device], _junk, hashes = self.threadpools[device].force_run_in_thread( :param threadpool: internal thread pool to use for disk operations def __init__(self, name, datadir, fd, tmppath, bytes_per_sync, threadpool, diskfile): self._threadpool = threadpool def _write_entire_chunk(chunk): while chunk: written = os.write(self._fd, chunk) self._upload_size += written chunk = chunk[written:] self._threadpool.run_in_thread(_write_entire_chunk, chunk) self._threadpool.force_run_in_thread(fdatasync, self._fd) self._threadpool.force_run_in_thread( self._finalize_put, metadata, target_path, cleanup) :param threadpool: thread pool to use for read operations def __init__(self, fp, data_file, obj_size, etag, threadpool, self._threadpool = threadpool chunk = self._threadpool.run_in_thread( self._fp.read, self._disk_chunk_size) (bytes_in_pipe, _1, _2) = self._threadpool.run_in_thread( splice, rfd, None, client_wpipe, None, pipe_size, 0) self._quarantined_dir = self._threadpool.run_in_thread( self.manager.quarantine_renamer, self._device_path, self._data_file) :param threadpool: thread pool to use for blocking operations def __init__(self, mgr, device_path, threadpool, partition, self._threadpool = threadpool or ThreadPool(nthreads=0) self._quarantined_dir = self._threadpool.run_in_thread( self.manager.quarantine_renamer, self._device_path, data_file) self._metadata['ETag'], self._threadpool, self._disk_chunk_size, threadpool=self._threadpool, self._threadpool.force_run_in_thread( self._finalize_durable, durable_file_path)",28,409
openstack%2Fswift~master~Ie76be5c8a74d60a1330627caace19e06d1b9383c,openstack/swift,master,Ie76be5c8a74d60a1330627caace19e06d1b9383c,Remove threads_per_disk setting,MERGED,2016-04-28 17:06:47.000000000,2016-05-11 01:36:43.000000000,2016-05-11 01:36:43.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}]","[{'number': 1, 'created': '2016-04-28 17:06:47.000000000', 'files': ['doc/source/deployment_guide.rst', 'swift/common/manager.py', 'doc/manpages/object-server.conf.5', 'etc/object-server.conf-sample', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9d6a055b31f267e2380d0470021cac44cdf36203', 'message': 'Remove threads_per_disk setting\n\nThis patch removes the threads_per_disk setting. It was already a deprecated\nsetting and by default set to 0, which effectively meant to not use a per-disk\nthread pool at all. Users are encouraged to use servers_per_port instead.\n\nDocImpact\n\nChange-Id: Ie76be5c8a74d60a1330627caace19e06d1b9383c\n'}]",0,310864,9d6a055b31f267e2380d0470021cac44cdf36203,10,3,1,6968,,,0,"Remove threads_per_disk setting

This patch removes the threads_per_disk setting. It was already a deprecated
setting and by default set to 0, which effectively meant to not use a per-disk
thread pool at all. Users are encouraged to use servers_per_port instead.

DocImpact

Change-Id: Ie76be5c8a74d60a1330627caace19e06d1b9383c
",git fetch https://review.opendev.org/openstack/swift refs/changes/64/310864/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/deployment_guide.rst', 'swift/common/manager.py', 'doc/manpages/object-server.conf.5', 'etc/object-server.conf-sample', 'swift/obj/diskfile.py']",5,9d6a055b31f267e2380d0470021cac44cdf36203,, self.threadpools = defaultdict(lambda: ThreadPool(nthreads=0))," threads_per_disk = int(conf.get('threads_per_disk', '0')) self.threadpools = defaultdict( lambda: ThreadPool(nthreads=threads_per_disk))",8,30
openstack%2Ftripleo-heat-templates~master~I77af9126abc61ace227cf1a69c2d3b5ceb735276,openstack/tripleo-heat-templates,master,I77af9126abc61ace227cf1a69c2d3b5ceb735276,deployment: remove Step7,MERGED,2016-05-09 19:15:29.000000000,2016-05-11 01:36:36.000000000,2016-05-11 01:36:35.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 20172}]","[{'number': 1, 'created': '2016-05-09 19:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ae2e2c12375bb7a6883637106c3acd94a8a1f158', 'message': 'deployment: remove Step7\n\nStep7 is not used anywhere and consumes some times for nothing.\nThis patch removes the step, so deployments and upgrades will be faster.\n\nChange-Id: I77af9126abc61ace227cf1a69c2d3b5ceb735276\n'}, {'number': 2, 'created': '2016-05-09 22:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/14956e445ffcba9a05d803e55e1b7bbdbb9cdc16', 'message': 'deployment: remove Step7\n\nStep7 is not used anywhere and consumes some times for nothing.\nThis patch removes the step, so deployments and upgrades will be faster.\n\nChange-Id: I77af9126abc61ace227cf1a69c2d3b5ceb735276\n'}, {'number': 3, 'created': '2016-05-10 13:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a899222c1fb7c5735ad22fae6bb91a722918cf49', 'message': 'deployment: remove Step7\n\nStep7 was created when we incremented the step of ringbuilder, by\nhttps://review.openstack.org/#q,9988bd25aa4bac1375ef4783d636c7adecedee92,n,z\n\nBut step7 is not used anywhere and consumes some times for nothing.\nThis patch removes the step, so deployments and upgrades will be faster.\n\nChange-Id: I77af9126abc61ace227cf1a69c2d3b5ceb735276\n'}, {'number': 4, 'created': '2016-05-10 18:24:23.000000000', 'files': ['puppet/controller-post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ff7c5c72ed6aa57bfa8e1e15a446211717c32dc6', 'message': 'deployment: remove Step7\n\nStep7 was created when we incremented the step of ringbuilder, by\nhttps://review.openstack.org/#q,9988bd25aa4bac1375ef4783d636c7adecedee92,n,z\n\nBut step7 is not used anywhere and consumes some times for nothing.\nThis patch removes the step, so deployments and upgrades will be faster.\n\nChange-Id: I77af9126abc61ace227cf1a69c2d3b5ceb735276\n'}]",0,314242,ff7c5c72ed6aa57bfa8e1e15a446211717c32dc6,33,9,4,3153,,,0,"deployment: remove Step7

Step7 was created when we incremented the step of ringbuilder, by
https://review.openstack.org/#q,9988bd25aa4bac1375ef4783d636c7adecedee92,n,z

But step7 is not used anywhere and consumes some times for nothing.
This patch removes the step, so deployments and upgrades will be faster.

Change-Id: I77af9126abc61ace227cf1a69c2d3b5ceb735276
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/314242/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/controller-post.yaml'],1,ae2e2c12375bb7a6883637106c3acd94a8a1f158,steps/drop7, depends_on: ControllerOvercloudServicesDeployment_Step6, ControllerOvercloudServicesDeployment_Step7: type: OS::Heat::StructuredDeployments depends_on: ControllerOvercloudServicesDeployment_Step6 properties: name: ControllerOvercloudServicesDeployment_Step7 servers: {get_param: servers} config: {get_resource: ControllerPuppetConfig} input_values: step: 7 update_identifier: {get_param: NodeConfigIdentifiers} depends_on: ControllerOvercloudServicesDeployment_Step7,1,12
openstack%2Fapi-site~master~I1e62a78ce6c9b7dd77579204a759f6f04d737dac,openstack/api-site,master,I1e62a78ce6c9b7dd77579204a759f6f04d737dac,Add popular IP protocols for security group,ABANDONED,2016-02-20 06:25:56.000000000,2016-05-11 01:19:50.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7805}, {'_account_id': 10497}, {'_account_id': 11343}]","[{'number': 1, 'created': '2016-02-20 06:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/d3f882779875f658a116b7545c6e68a8f1a52e82', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nThis is to update the documentation.\n\nChange-Id: I1e62a78ce6c9b7dd77579204a759f6f04d737dac\nCloses-Bug: #1542352\n'}, {'number': 2, 'created': '2016-02-24 23:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/c005453f305d348a72d86094c4a52977e7af217b', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nThis is to update the documentation.\n\nChange-Id: I1e62a78ce6c9b7dd77579204a759f6f04d737dac\nCloses-Bug: #1542352\n'}, {'number': 3, 'created': '2016-02-24 23:41:57.000000000', 'files': ['api-ref/src/wadls/networking-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/c9fe38e33d9e7d76088bc98c9d7a2b7b9f11e3fe', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nThis is to update the documentation.\n\nChange-Id: I1e62a78ce6c9b7dd77579204a759f6f04d737dac\nCloses-Bug: #1542352\n'}]",1,282613,c9fe38e33d9e7d76088bc98c9d7a2b7b9f11e3fe,17,7,3,7805,,,0,"Add popular IP protocols for security group

The patch for neutron is merged.
Link: https://review.openstack.org/252155

This is to update the documentation.

Change-Id: I1e62a78ce6c9b7dd77579204a759f6f04d737dac
Closes-Bug: #1542352
",git fetch https://review.opendev.org/openstack/api-site refs/changes/13/282613/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/netconn-api/src/common.ent', 'api-ref/src/wadls/networking-api/src/common.ent']",2,d3f882779875f658a116b7545c6e68a8f1a52e82,bug/1542352," <code>null</code>, <code>ah</code>, <code>dccp</code>, <code>egp</code>, <code>esp</code>, <code>gre</code>, <code>icmp</code>, <code>igmp</code>, <code>ipv6-encap</code>, <code>ipv6-frag</code>, <code>ipv6-icmp</code>, <code>ipv6-nonxt</code>, <code>ipv6-opts</code>, <code>ipv6-route</code>, <code>ospf</code>, <code>pgm</code>, <code>rsvp</code>, <code>sctp</code>, <code>tcp</code>, <code>udp</code>, <code>udplite</code>, or <code>vrrp</code>."," <code>null</code>, <code>icmp</code>, <code>icmpv6</code>, <code>tcp</code>, or <code>udp</code>.",16,4
openstack%2Fpython-neutronclient~master~If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e,openstack/python-neutronclient,master,If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e,Add popular IP protocols for security group,ABANDONED,2016-02-20 07:41:49.000000000,2016-05-11 01:19:36.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 7805}, {'_account_id': 8976}, {'_account_id': 11343}, {'_account_id': 14605}, {'_account_id': 15309}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-20 07:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/dfd7d9f969e06ae689bc2ae5764300f636ef5aa9', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 2, 'created': '2016-02-24 09:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/026bc0e491586e9b8e3d9b69dc674555e17a6608', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 3, 'created': '2016-02-26 03:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/46af23b2a6a291d93f64bfcc01bd70ef8f09af95', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 4, 'created': '2016-02-26 07:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f3acf7567df215484c805c0b34e72448bf4b3d1a', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 5, 'created': '2016-03-05 06:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4a427ea4f6aa9421bc21bab571081707c0578789', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 6, 'created': '2016-03-07 06:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e9a7d4d45a97320f76a3e86717fed271a9d2060f', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 7, 'created': '2016-03-08 02:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4cbf97ee76399fb57c9a3a7ed35600b15347edc3', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}, {'number': 8, 'created': '2016-03-17 01:36:10.000000000', 'files': ['neutronclient/neutron/v2_0/securitygroup.py', 'neutronclient/tests/unit/test_cli20_securitygroup.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/adb23e714d2824e721a88ff4a8d686a5159c8829', 'message': 'Add popular IP protocols for security group\n\nThe patch for neutron is merged.\nLink: https://review.openstack.org/252155\n\nChange-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e\nPartial-Bug: #1542352\n'}]",25,282621,adb23e714d2824e721a88ff4a8d686a5159c8829,41,9,8,7805,,,0,"Add popular IP protocols for security group

The patch for neutron is merged.
Link: https://review.openstack.org/252155

Change-Id: If3f890e1e47ad7b97d7752e5ebfea49ce6b1c74e
Partial-Bug: #1542352
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/21/282621/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/securitygroup.py', 'neutronclient/tests/unit/test_cli20_securitygroup.py']",2,dfd7d9f969e06ae689bc2ae5764300f636ef5aa9,bug/1542352, securitygroup.generate_default_ethertype('ipv6-icmp')), securitygroup.generate_default_ethertype('icmpv6')),6,3
openstack%2Fnova~master~I8d8bd09f72572caed1a45fa23f95a15d330c2f26,openstack/nova,master,I8d8bd09f72572caed1a45fa23f95a15d330c2f26,api-ref: method verification and fixes for servers.inc,MERGED,2016-05-06 11:34:28.000000000,2016-05-11 01:10:42.000000000,2016-05-09 18:47:57.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}]","[{'number': 1, 'created': '2016-05-06 11:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/449c76f0ee67b43ce6ff8a76546aba7328250694', 'message': 'api-ref: method verification and fixes for servers.inc\n\nUpdate the response codes for the methods based on what is in the\ncode. This follows the pattern of updating these error codes when\ndoing method verification that jichen has been doing.\n\nSome notes are left for the body_verification phase later, as that is\ngoing to take a while for this file.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I8d8bd09f72572caed1a45fa23f95a15d330c2f26\n'}, {'number': 2, 'created': '2016-05-09 10:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25e65ff1518b9d5644ef0aa2a6f4a21cbac65311', 'message': 'api-ref: method verification and fixes for servers.inc\n\nUpdate the response codes for the methods based on what is in the\ncode. This follows the pattern of updating these error codes when\ndoing method verification that jichen has been doing.\n\nSome notes are left for the body_verification phase later, as that is\ngoing to take a while for this file.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I8d8bd09f72572caed1a45fa23f95a15d330c2f26\n'}, {'number': 3, 'created': '2016-05-09 16:37:54.000000000', 'files': ['api-ref/source/servers.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/daad02b41de943d8a649ea218733151171af5b9c', 'message': 'api-ref: method verification and fixes for servers.inc\n\nUpdate the response codes for the methods based on what is in the\ncode. This follows the pattern of updating these error codes when\ndoing method verification that jichen has been doing.\n\nSome notes are left for the body_verification phase later, as that is\ngoing to take a while for this file.\n\nPart of bp:api-ref-in-rst\n\nChange-Id: I8d8bd09f72572caed1a45fa23f95a15d330c2f26\n'}]",8,313514,daad02b41de943d8a649ea218733151171af5b9c,37,12,3,2750,,,0,"api-ref: method verification and fixes for servers.inc

Update the response codes for the methods based on what is in the
code. This follows the pattern of updating these error codes when
doing method verification that jichen has been doing.

Some notes are left for the body_verification phase later, as that is
going to take a while for this file.

Part of bp:api-ref-in-rst

Change-Id: I8d8bd09f72572caed1a45fa23f95a15d330c2f26
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/313514/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/servers.inc'],1,449c76f0ee67b43ce6ff8a76546aba7328250694,bp/api-ref-in-rst,"Error response codes: badRequest(400), unauthorized(401), forbidden(403)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404), conflict(409), entityTooLarge(413) .. TODO(sdague): leave these notes for later when fixing the body language. They are commented out so they won't render, but are useful to not have to look this up again later. A conflict(409) is returned in the event of trying to allocated already allocated resources (such as networks) to the server in question. entityTooLarge(413) is returned if the ``user_data`` exceeds what is allowed by the backend. All other failure conditions map to 400, and will need to be disambiguated by the error string returned.Error response codes: badRequest(400), unauthorized(401), forbidden(403)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404)Error response codes: badRequest(400), unauthorized(401), forbidden(403), itemNotFound(404), conflict(409) .. TODO(sdague): for later phase of updating body. conflict is returned under 2 conditions. When the instance is locked, so can't be deleted, or if the instance is in some other state which makes it not possible to delete. ",".. needs:method_verificationError response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault (400, 500, …), serviceUnavailable (503), badRequest (400), unauthorized (401), forbidden (403), badMethod (405) Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)Error response codes: computeFault(400, 500), serviceUnavailable(503), badRequest(400), unauthorized(401), forbidden(403), badMethod(405), itemNotFound(404)",34,15
openstack%2Fkeystonemiddleware~master~I1fe13f0365ca4704717fe680a0c8f54c64a9f06c,openstack/keystonemiddleware,master,I1fe13f0365ca4704717fe680a0c8f54c64a9f06c,s3token config with auth URI,MERGED,2016-05-03 21:33:41.000000000,2016-05-11 01:09:55.000000000,2016-05-11 01:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-05-03 21:33:41.000000000', 'files': ['releasenotes/notes/s3token_auth_uri-490c1287d90b9df7.yaml', 'keystonemiddleware/tests/unit/test_s3_token_middleware.py', 'keystonemiddleware/s3_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8dee7458e3512c3dc4587f159efcee43fe7c9159', 'message': ""s3token config with auth URI\n\ns3token middleware only allows configuring host and port for the\nauth URI. This doesn't allow the auth server to be on a path.\n\nA new auth_uri config option is added that allows the deployer to\nspecify the full URL for auth. This overrides auth_host, auth_port,\nand auth_protocol. auth_host, auth_port, and auth_protocol are\ndeprecated.\n\nDocImpact\n\nChange-Id: I1fe13f0365ca4704717fe680a0c8f54c64a9f06c\n""}]",0,312260,8dee7458e3512c3dc4587f159efcee43fe7c9159,7,3,1,6486,,,0,"s3token config with auth URI

s3token middleware only allows configuring host and port for the
auth URI. This doesn't allow the auth server to be on a path.

A new auth_uri config option is added that allows the deployer to
specify the full URL for auth. This overrides auth_host, auth_port,
and auth_protocol. auth_host, auth_port, and auth_protocol are
deprecated.

DocImpact

Change-Id: I1fe13f0365ca4704717fe680a0c8f54c64a9f06c
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/60/312260/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/s3token_auth_uri-490c1287d90b9df7.yaml', 'keystonemiddleware/tests/unit/test_s3_token_middleware.py', 'keystonemiddleware/s3_token.py']",3,8dee7458e3512c3dc4587f159efcee43fe7c9159,s3_token_auth_uri,"from keystonemiddleware.i18n import _, _LI, _LW self._request_uri = conf.get('auth_uri') if not self._request_uri: self._logger.warning(_LW( ""Use of the auth_host, auth_port, and auth_protocol "" ""configuration options was deprecated in the Newton release "" ""in favor of auth_uri. These options may be removed in a "" ""future release."")) auth_host = conf.get('auth_host') auth_port = int(conf.get('auth_port', 35357)) auth_protocol = conf.get('auth_protocol', 'https') self._request_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port)","from keystonemiddleware.i18n import _, _LI auth_host = conf.get('auth_host') auth_port = int(conf.get('auth_port', 35357)) auth_protocol = conf.get('auth_protocol', 'https') self._request_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port)",33,21
openstack%2Foslo.config~stable%2Fliberty~I5683cd23ef25ecd938fa3df33b11b04731c9f396,openstack/oslo.config,stable/liberty,I5683cd23ef25ecd938fa3df33b11b04731c9f396,Updated from global requirements,MERGED,2016-04-29 22:48:17.000000000,2016-05-11 01:09:12.000000000,2016-05-11 01:09:11.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8688}]","[{'number': 1, 'created': '2016-04-29 22:48:17.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/32a7221f32d6a4b2a06adf3cc8fbc835d5fbe7ad', 'message': 'Updated from global requirements\n\nChange-Id: I5683cd23ef25ecd938fa3df33b11b04731c9f396\n'}]",0,311391,32a7221f32d6a4b2a06adf3cc8fbc835d5fbe7ad,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I5683cd23ef25ecd938fa3df33b11b04731c9f396
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/91/311391/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,32a7221f32d6a4b2a06adf3cc8fbc835d5fbe7ad,openstack/requirements,reno>=0.1.1 # Apache2,reno>=0.1.1 # Apache2,1,1
openstack%2Fneutron~stable%2Fmitaka~If764dec7dd7fc5ab45023ef80689d46dcd18211e,openstack/neutron,stable/mitaka,If764dec7dd7fc5ab45023ef80689d46dcd18211e,Imported Translations from Zanata,MERGED,2016-04-29 06:58:47.000000000,2016-05-11 01:08:43.000000000,2016-05-11 01:08:42.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14605}, {'_account_id': 14807}, {'_account_id': 20079}]","[{'number': 1, 'created': '2016-04-29 06:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d053fcba7ee07369c7d240ae28306332103ec8de', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 2, 'created': '2016-04-30 06:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d9836aff5fb9750d0aa99f87976deacf165b894', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 3, 'created': '2016-05-01 07:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c413d0093399cc19db8adbd3fa52c38552e3d82f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 4, 'created': '2016-05-02 07:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b1b9a37f4c38ddf9ae8a05def44c02a91b1f209', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 5, 'created': '2016-05-03 07:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/36a174485f1dbc883977c3f6d58454bdbf2b4dcc', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 6, 'created': '2016-05-04 06:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5cceb2596e1144e644a8af987b93a5adaed9ba9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 7, 'created': '2016-05-05 06:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc193607fc4d4037c02516b5dd94e8950ceebaab', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 8, 'created': '2016-05-06 07:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1fb2d8d3e08d52b107dd5d59e6a56cff95582d0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 9, 'created': '2016-05-07 06:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4e33674d3e346fb6076e1f471868b7e5630de61', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}, {'number': 10, 'created': '2016-05-10 07:00:08.000000000', 'files': ['neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron-log-error.pot', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/neutron-log-warning.pot'], 'web_link': 'https://opendev.org/openstack/neutron/commit/64bddf0d0e2c9b8feddaeaf6126b2b7009f11b83', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e\n'}]",0,311041,64bddf0d0e2c9b8feddaeaf6126b2b7009f11b83,80,12,10,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: If764dec7dd7fc5ab45023ef80689d46dcd18211e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/311041/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/locale/zh_CN/LC_MESSAGES/neutron.po'],1,d053fcba7ee07369c7d240ae28306332103ec8de,zanata/translations,"""Project-Id-Version: neutron 8.0.1.dev86\n""""POT-Creation-Date: 2016-04-28 22:35+0000\n""""PO-Revision-Date: 2016-04-28 04:43+0000\n""msgstr ""%(driver)s：内部驱动错误。""msgstr ""%(id)s 是无效 %(type)s 标识""msgstr ""对于 %(tunnel)s 供应商网络，已禁止 %(key)s""msgstr ""%s 是无效 VLAN 标记""msgstr ""VLAN 供应商网络中禁止 %s""msgstr ""在平面供应商网络中禁止 %s""msgstr ""在本地供应商网络中禁止 %s""msgstr ""“%(data)s”不在 %(valid_values)s 中""msgstr ""“%(data)s”太大 – 不能大于“%(limit)d”""msgstr ""“%(data)s”太小 - 必须至少为“%(limit)d”""msgstr ""“%(data)s”是不可识别的 IP子网 CIDR，建议使用“%(cidr)s”""msgstr ""“%(data)s”是无效 PQDN 或 FQDN。原因：%(reason)s""msgstr ""“%(host)s”是无效名称服务器。%(msg)s""msgstr ""“%s”不允许空白字符串""msgstr ""“%s”包含空格""msgstr ""“%s”是无效 RBAC 对象类型""msgstr ""“%s”是无效布尔值""msgstr ""“%s”是无效输入""msgstr ""“%s”没有采用 <key>=[value] 格式""msgstr ""“%s”必须为非负十进制数。""""（不推荐使用。请改为使用“--subproject neutron-SERVICE”。）要对其执行该命令的"" ""高级服务。""msgstr ""CIDR 前缀长度不允许为 0""msgstr ""作为 RFC3315 DUID-EN 所需的供应商注册私营企业号的十进制值。""""向 iptable 规则添加注释。设置为 false 以禁止向描述每个规则用途的已生成 "" ""iptable 添加注释。系统必须支持 iptable 注释模块以添加注释。""msgstr ""代理程序已更新：%(payload)s""msgstr ""允许自动对 L3 代理安排路由器。""msgstr ""允许运行元数据代理""msgstr ""允许的地址对必须是列表。""""要从 neutron.ml2.mechanism_drivers 名称空间装入的联网机制驱动程序入口点的有序"" ""列表。""msgstr ""无法从可用前缀集分配所请求的子网""msgstr ""无法创建浮动 IP 并将它绑定至 %s，因为它不是 IPv4 地址。""msgstr ""检查 keepalived IPv6 支持""""控制是否在服务器中启用 neutron 安全组 API。未使用安全组或使用 nova 安全组 ""msgstr ""在尝试 %(time)d 秒之后无法绑定 %(host)s:%(port)s""""在未指定供应商属性时，外部网络的缺省网络类型。缺省情况下为 None，这意味着如果"" ""在创建外部网络时未指定供应商属性，那么它们将与租户网络具有相同类型。""""会使用以下格式为高级服务定义供应商：<service_type>:<name>:<driver>[:default]""msgstr ""不再支持降级""msgstr ""要用于对缺省 L3 代理安排路由器的驱动程序""msgstr ""请求中的分段条目重复。""msgstr ""对虚拟路由器启用 HA 方式。""msgstr ""在 API 服务器上启用 SSL""""程序。允许交换机（支持重叠部分时）在本地响应 ARP 请求而不必执行成本高昂的 "" ""ARP 广播到重叠部分中。""msgstr ""遇到空组件。""msgstr ""VLAN 范围结束值比开始值小""msgstr ""等待地址以离开暂定状态时超过 %s 秒限制。""""退出代码：%(returncode)d；标准输入：%(stdin)s；标准输出：%(stdout)s；标准错"" ""误：%(stderr)s""msgstr ""外部 IP %s 和网关 IP 相同""msgstr ""FWaaS 插件是在服务器端配置的，但 FWaaS 在 L3 代理中被禁用。""msgstr ""将路由器 %(router_id)s 安排至 L3 代理 %(agent_id)s 失败。""msgstr ""设置 gid %s 失败""msgstr ""设置 uid %s 失败""msgstr ""对于 TCP/UDP 协议，port_range_min 必须小于或等于 port_range_max""msgstr ""强制 ip_lib 调用使用 root helper""msgstr ""路由器标识""msgstr ""对于所指定网络上的任何子网，IP 地址 %(ip_address)s 是无效 IP。""""IPTablesManager.apply 无法应用以下 iptables 规则集：\n""msgstr ""权限不足，无法移除缺省安全组。""msgstr ""进行子进程活性检查的时间间隔（秒），使用 0 表示禁用""msgstr ""采取两种测量措施的时间间隔""msgstr ""生成两个测量报告的时间间隔""msgstr """" ""ICMP %(field)s (%(attr)s) 的值 %(value)s 无效。它必须为 0 到 255 之间的值。""""跟踪数据库的当前资源配额使用量。那些未利用 Neutron 数据库的插件应将此标志设置"" ""为 False""msgstr ""Keepalived 未重新衍生""msgstr ""limit 必须是整数 0 或更大整数，而不是“%d”""""<physical_network>:<vlan_min>:<vlan_max> 或 <physical_network> 列表，用于指定"" ""对 VLAN 供应商和租户网络可用的物理网络名称，以及可分配至租户网络的每项上的 "" ""VLAN 标记。""msgstr ""通道端点的本地 IP 地址。""msgstr ""测量标签 %(label_id)s 不存在""""名称“%s”的长度必须在 1 到 63 个字符之间，其中每个字符只能是字母数字或连字符。""msgstr ""路由器名称空间""msgstr ""不支持为负变化量（降级）""""安排托管租户网络的 DHCP 代理数。如果此数目大于 1，那么调度程序会自动为所给定"" ""的租户网络分配多个 DHCP 代理，从而为 DHCP 服务提供高可用性。""msgstr ""服务的 RPC 执行程序编号。""msgstr ""用于配置元数据服务器套接字的储备请求数""msgstr ""用于配置套接字的储备请求数""msgstr ""保持重试监听的秒数""""针对服务的不同 API 执行程序的编号。如果没有指定，缺省为最佳性能下的可用 CPU "" ""数""msgstr ""一次仅允许更新一个安全概要文件的规则""msgstr ""路由器目录的路径""msgstr ""必须启用端口安全性，并且端口必须具有 IP 地址以使用安全组。""msgstr ""进程未在运行""""当启动定期任务调度程序以减少拥堵时要随机延迟的秒数范围。（通过设置为 0 来禁"" ""用）""""不推荐使用区分发行版的分支标签 (%s)。请切换到 expand@ 和 contract@ 标签。""""表示其负载要由代理报告的资源类型。可以是“networks”、“subnets”或“ports”。如果"" ""已指定（缺省值为“networks”），那么服务器将根据代理报告状态抽取特定负载（作为"" ""其代理配置对象的一部分发送），这是在每个 report_interval 要消耗的资源数。""msgstr ""配额功能部件中受支持的资源名称。不推荐使用此选项，即将移除。""msgstr ""在可能的情况下，要使用的 root helper 守护程序应用程序。""msgstr ""路由器 %(router_id)s 在子网 %(subnet_id)s 上没有任何接口""msgstr ""子网池已有分配""msgstr ""要用于 VXLAN 通道的 UDP 端口""msgstr ""通告间隔（以秒计）""""Neutron 用于唯一 DVR 实例的基本 MAC 地址。前三个八位元将保持不变。如果第四个"" ""八位元不为 00，那么也将使用该八位元。将随机生成其他八位元。“dvr_base_mac”必须"" ""不同于“base_mac”，以避免将它们与为租户端口分配的 MAC 混合使用。以下是一个具""msgstr ""以下 device_id %(device_id)s 不属于您的租户或与另一租户路由器匹配。""msgstr ""要绑定至的主机 IP""msgstr ""网络 %(network_id)s 已由 DHCP 代理 %(agent_id)s 托管。""msgstr ""网络 %(network_id)s 未由 DHCP 代理 %(agent_id)s 托管。""msgstr ""sort_keys 数与 sort_dirs 数必须相同""msgstr ""要绑定至的端口""msgstr ""请求的内容类型 %s 无效。""msgstr ""根据此策略，有一些路由器连接至此网络以用于访问。""msgstr ""无法确定 %s 的 MAC 地址""msgstr ""在 %s 中找不到资源的名称""msgstr ""无法通过 %s 标识目标字段。匹配项必须为以下格式：%%(<field_name>)s""msgstr ""无法验证该匹配项 %(match)s 为父资源：找不到 %(res)s ""msgstr ""未映射错误""msgstr ""正在更新的缺省安全组内容不被允许""msgstr ""VRRP 认证密码""msgstr ""VRRP 认证类型""msgstr """" ""必须为网桥提供配置文件 - --config-file 或 env[NEUTRON_TEST_CONFIG_FILE]""msgstr ""dhcp_agents_per_network 必须大于等于 1。“%s”无效。""msgstr ""ip 链路命令不受支持：%(reason)s""msgstr ""网络类型值“%s”不受支持""msgstr ""对于 VLAN 供应商网络，physical_network“%s”未知""msgstr ""平面供应商网络的物理网络“%s”为未知状态""msgstr ""对 %s 网络指定的 provider:physical_network""msgstr ""respawn_interval 必须大于或等于 0（如果已提供此项）。""msgstr ""segmentation_id 超出从 (%(min)s 到 %(max)s) 的范围""msgstr ""segmentation_id 需要 VLAN 供应商网络的 physical_network""""在命令行中提供了 uuid，以便 external_process 可通过 /proc/cmdline 接口跟踪我""","# Lucas Palm <lapalm@us.ibm.com>, 2015. #zanata # OpenStack Infra <zanata@openstack.org>, 2015. #zanata# Lucas Palm <lapalm@us.ibm.com>, 2016. #zanata""Project-Id-Version: neutron 8.0.1.dev68\n""""POT-Creation-Date: 2016-04-18 20:06+0000\n""""PO-Revision-Date: 2016-03-16 01:44+0000\n""msgstr ""%(driver)s: 内部驱动错误。""msgstr ""%(id)s 不是有效的 %(type)s 标识""msgstr ""对于 %(tunnel)s 提供程序网络，已禁止 %(key)s""msgstr ""%s 不是一个有效的标签""msgstr ""VLAN提供者网络中禁止%s""msgstr ""在平面供应商网络中禁止%s""msgstr ""在本地供应商网络中禁止%s""msgstr ""“%(data)s”没有在 %(valid_values)s 中""msgstr ""'%(data)s' 太大 - 必须不能大于 '%(limit)d'""msgstr ""'%(data)s' 太小 - 必须至少 '%(limit)d'""msgstr ""'%(data)s' 不是一个可识别的IP子网CIDR， 建议'%(cidr)s' ""msgstr ""“%(data)s”不是有效的 PQDN 或 FQDN。原因：%(reason)s""msgstr ""'%(host)s' 不是合法的nameserver %(msg)s""msgstr ""'%s' 不允许空白字符串""msgstr ""'%s' 包含空格""msgstr ""“%s”不是有效的 RBAC 对象类型""msgstr ""'%s' 不是一个有效的布尔值""msgstr ""“%s”不是有效的输入""msgstr ""“%s”没有采用格式 <键>=[值]""msgstr ""“%s”必须为一个非负十进制数。""""（建议不要使用。请改为使用“--subproject neutron-SERVICE”。）要对其执行该命令"" ""的高级服务。""msgstr ""0不允许作为CIDR前缀长度""msgstr ""作为 RFC3315 DUID-EN 所需要的供应商的已注册私营企业号的十进制值。""""向 iptable 规则添加注释。设置为 false 以禁止向描述规则用途的已生成 iptable 添"" ""加注释。系统必须支持 iptable 注释模块以添加注释。""msgstr ""进程更新: %(payload)s""msgstr ""允许自动对 L3 代理调度路由器。""msgstr ""允许运行 metadata代理""msgstr ""允许的地址对必须是一个列表。""""要从 neutron.ml2.mechanism_drivers 名称空间装入的联网机制驱动程序入口点的已排"" ""序列表。""msgstr ""无法从可用的一组前缀分配所请求的子网""msgstr ""无法创建浮动 IP 并将它绑定至 %s，因为这不是 IPv4 地址。""msgstr ""检查保持活动的 IPv6 支持""""控制是否在服务器中启用了 neutron 安全组 API。未使用安全组或使用 nova安全组 ""msgstr ""在尝试%(time)d 秒之后不能绑定 %(host)s:%(port)s """"在未指定提供者属性时，外部网络的缺省网络类型。缺省情况下，它为“无”，这意味着"" ""如果在创建外部网络时未指定提供者属性，那么它们将与租户网络具有相同类型。""""会使用以下格式为高级服务定义提供程序：<service_type>:<name>:<driver>[:"" ""default]""msgstr ""降级不再支持""msgstr ""要用于对缺省 L3 代理调度路由器的驱动程序""msgstr ""请求中的段条目重复。""msgstr ""为虚拟路由器启用HA模式。""msgstr ""在API 服务器上打开SSL""""程序。允许交换机（支持 Overlay 时）在本地响应ARP 请求而不必执行成本高昂的 ARP"" ""广播到 Overlay 中。""msgstr ""遇到空的组件。""msgstr ""VLAN范围结束值比开始值小""msgstr """" ""Exceeded %s second limit waiting for address to leave the tentative state.""""退出代码：%(returncode)d；Stdin：%(stdin)s；Stdout：%(stdout)s；Stderr："" ""%(stderr)s""msgstr ""外部 IP %s 和网关IP相同""msgstr ""FWaaS 插件是在服务器端配置的，但 FWaaS 在L3 代理中被禁用。""msgstr ""将路由器 %(router_id)s 调度到 L3 代理 %(agent_id)s 失败。""msgstr ""设置gid %s 失败""msgstr ""设置uid %s 失败""msgstr ""对于 TCP/UDP 协议，port_range_min 必须小于等于 port_range_max""msgstr ""强制ip_lib呼叫使用root helper""msgstr ""路由器ID""msgstr ""对于所指定网络上的任何子网，IP 地址 %(ip_address)s 不是有效 IP。""""IPTablesManager.apply 无法应用以下 iptables规则集：\n""msgstr ""权利不足，无法移除缺省安全组。""msgstr ""子进程活性检查之间的时间间隔（秒），使用 0 来进行禁用""msgstr ""在采取两种测量措施之间的时间间隔""msgstr ""在生成两个测量报告之间的时间间隔""msgstr ""ICMP %(field)s (%(attr)s) 的值 %(value)s 无效。它必须为 0 到 255。""""在当前资源配额使用量的数据库中保存跟踪。那些不利用 Neutron 数据库的插件应将此"" ""标志设置为 False""msgstr ""保持活动的未重新衍生""msgstr ""限制必须是整数 0 或更大整数，而不是“%d”""""为VLAN提供商和租户网络提供<physical_network>:<vlan_min>:<vlan_max> 或 "" ""<physical_network>专属物理网络名称，从事实现每个租户网络可以分配到相应的VLAN"" ""标识。""msgstr ""隧道端点的本地 IP 地址。""msgstr ""测量标签\t%(label_id)s 不存在""""名称“%s”的长度必须是 1 至 63 个字符，其中每个字符只能是字母数字或连字符。""msgstr ""路由器名字空间""msgstr ""不支持为负数的增量修订版（降级）""""已调度的主管租户网络的 DHCP 代理数。如果此数目大于 1，那么调度程序会自动为所"" ""给定的租户网络分配多个 DHCP 代理，从而为 DHCP 服务提供高可用性。""msgstr ""针对服务的RPC执行程序编号。""msgstr ""关于配置元数据服务器套接字的储备请求数""msgstr ""积压许多配置socket的请求""msgstr ""若干秒保持重试监听""""针对服务的不同API执行程序的编号。如果没有指定，默认等于最佳性能下的可用CPU的"" ""个数值""msgstr ""一次仅允许为一个安全概要文件更新规则""msgstr ""直连路由器的路径""msgstr ""必须启用端口安全性，并且端口必须具有 IP 地址，以便使用安全组。""msgstr ""进程未运行""""当启动定期任务调度程序以减少拥堵时要随机延迟的秒数范围.(通过设置为 0 来禁用)""""建议不要使用对发行版敏感的分支标签 (%s)。请切换到 expand@ 和 contract@ 标签。""""表示其负载要由代理报告的资源类型。这可以是“网络”、“子网”或“端口”。如果已指定"" ""（缺省值为“网络”），那么服务器将根据代理报告状态抽取特定负载（作为其代理配置"" ""对象的一部分发送），这是在每个 report_interval 要消耗的资源数。""msgstr """" ""存在配额功能部件中受支持的资源名称。现在，已建议不要使用此选项，会将其除去。""msgstr ""在可能的情况下，要使用的 Root Helper 守护程序应用程序。""msgstr ""路由器 %(router_id)s 在子网 %(subnet_id)s 上不具有任何接口""msgstr ""子网池具有现有分配""msgstr ""UDP端口用于VXLAN隧道""msgstr ""通告间隔（秒）""""由 Neutron 用于唯一 DVR 实例的基本 MAC 地址。前三个八位元将保持不变。如果第四"" ""个八位元不为 00，那么也将使用该八位元。将随机生成其他八位元。“dvr_base_mac”必"" ""须不同于“base_mac”，以避免将它们与为租户端口分配的 MAC 混合使用。以下是一个具""msgstr ""以下 device_id %(device_id)s 不属于您的租户或与另一租户路由器 匹配。""msgstr ""主机 IP 要绑定至""msgstr ""网络 %(network_id)s 已由 DHCP 代理 %(agent_id)s 主管。""msgstr ""网络 %(network_id)s 未由 DHCP 代理 %(agent_id)s 主管。""msgstr ""sort_keys 的数字与 sort_dirs 的数字必须相同""msgstr ""端口要绑定至""msgstr ""请求的内容类型%s非法。""msgstr ""根据此策略，有一些路由器附加至此网络以用于访问。""msgstr ""无法为 %s 确定网卡地址""msgstr ""在%s中找不到源的名称""msgstr ""无法从:%s中匹配目标域. 匹配应该使用以下形式%%(域名)s""msgstr ""无法验证该匹配%(match)s为父资源:未找到%(res)s""msgstr ""已取消映射错误""msgstr ""正在更新的默认安全组内容不合法""msgstr ""VRRP认证密码""msgstr ""VRRP认证类型""msgstr ""必须为网桥提供配置文件 - --config-file 或env[NEUTRON_TEST_CONFIG_FILE]""msgstr ""dhcp_agents_per_network 必须是>= 1. '%s' 是不合法的、""msgstr ""ip 链路命令未支持: %(reason)s""msgstr ""不支持的网络类型值 '%s'""msgstr ""对于 VLAN 提供程序网络，physical_network“%s”未知""msgstr ""平面供应商网络的物理网络 '%s'为未知状态""msgstr ""提供程序：已为%s 网络指定 physical_network""msgstr ""respawn_interval 必须不小于 0（如果已提供此项）。""msgstr ""segmentation_id 超出范围，从(%(min)s 到 %(max)s)""msgstr ""segmentation_id 需要 VLAN 提供程序网络的 physical_network""""从命令行中提供了 uuid，以便 external_process 可通过 /proc/cmdline 接口跟踪我""",138,141
openstack%2Fkeystoneauth~master~I3e3e656193d1c0304b08a6ebb94441db489a820d,openstack/keystoneauth,master,I3e3e656193d1c0304b08a6ebb94441db489a820d,Refactor variables for fixture and service,MERGED,2016-04-29 18:01:32.000000000,2016-05-11 00:59:39.000000000,2016-05-11 00:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 15742}, {'_account_id': 19861}, {'_account_id': 20259}]","[{'number': 1, 'created': '2016-04-29 18:01:32.000000000', 'files': ['keystoneauth1/tests/unit/client_fixtures.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/68fde05dee456e5df11b334526c1bed37088953d', 'message': 'Refactor variables for fixture and service\n\nThere is a couple of f and s variables to represent\nfixture and service objects, we must use a better name\nfor it.\n\nChange-Id: I3e3e656193d1c0304b08a6ebb94441db489a820d\n'}]",0,311216,68fde05dee456e5df11b334526c1bed37088953d,11,6,1,8866,,,0,"Refactor variables for fixture and service

There is a couple of f and s variables to represent
fixture and service objects, we must use a better name
for it.

Change-Id: I3e3e656193d1c0304b08a6ebb94441db489a820d
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/16/311216/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth1/tests/unit/client_fixtures.py'],1,68fde05dee456e5df11b334526c1bed37088953d,,"from keystoneauth1 import fixture as kfixture fixture = kfixture.V3Token( user_id='c4da488862bd435c9e6c0275a0d0e49a', user_name='exampleuser', user_domain_id='4e6893b7ba0b4006840c3845660b86ed', user_domain_name='exampledomain', expires='2010-11-01T03:32:15-05:00', project_id='225da22d3ce34b15877ea70b2a575f58', project_name='exampleproject', project_domain_id='4e6893b7ba0b4006840c3845660b86ed', project_domain_name='exampledomain') fixture.add_role(id='76e72a', name='admin') fixture.add_role(id='f4f392', name='member') service = fixture.add_service('volume') service.add_standard_endpoints( public='http://public.com:8776/v1/%s' % tenant, internal='http://internal:8776/v1/%s' % tenant, admin='http://admin:8776/v1/%s' % tenant, region=region) service = fixture.add_service('image') service.add_standard_endpoints(public='http://public.com:9292/v1', internal='http://internal:9292/v1', admin='http://admin:9292/v1', region=region) service = fixture.add_service('compute') service.add_standard_endpoints( public='http://public.com:8774/v2/%s' % tenant, internal='http://internal:8774/v2/%s' % tenant, admin='http://admin:8774/v2/%s' % tenant, region=region) service = fixture.add_service('ec2') service.add_standard_endpoints( public='http://public.com:8773/services/Cloud', internal='http://internal:8773/services/Cloud', admin='http://admin:8773/services/Admin', region=region) service = fixture.add_service('identity') service.add_standard_endpoints(public='http://public.com:5000/v3', internal='http://internal:5000/v3', admin='http://admin:35357/v3', region=region) return fixture fixture = kfixture.V3Token( user_id='c4da488862bd435c9e6c0275a0d0e49a', user_name='exampleuser', user_domain_id='4e6893b7ba0b4006840c3845660b86ed', user_domain_name='exampledomain', expires='2010-11-01T03:32:15-05:00', domain_id='8e9283b7ba0b1038840c3842058b86ab', domain_name='anotherdomain') fixture.add_role(id='76e72a', name='admin') fixture.add_role(id='f4f392', name='member') service = fixture.add_service('volume') service.add_standard_endpoints(public='http://public.com:8776/v1/None', internal='http://internal.com:8776/v1/None', admin='http://admin.com:8776/v1/None', region=region) service = fixture.add_service('image') service.add_standard_endpoints(public='http://public.com:9292/v1', internal='http://internal:9292/v1', admin='http://admin:9292/v1', region=region) service = fixture.add_service('compute') service.add_standard_endpoints(public='http://public.com:8774/v1.1/None', internal='http://internal:8774/v1.1/None', admin='http://admin:8774/v1.1/None', region=region) service = fixture.add_service('ec2') service.add_standard_endpoints( public='http://public.com:8773/services/Cloud', internal='http://internal:8773/services/Cloud', admin='http://admin:8773/services/Admin', region=region) service = fixture.add_service('identity') service.add_standard_endpoints(public='http://public.com:5000/v3', internal='http://internal:5000/v3', admin='http://admin:35357/v3', region=region) return fixture","from keystoneauth1 import fixture f = fixture.V3Token(user_id='c4da488862bd435c9e6c0275a0d0e49a', user_name='exampleuser', user_domain_id='4e6893b7ba0b4006840c3845660b86ed', user_domain_name='exampledomain', expires='2010-11-01T03:32:15-05:00', project_id='225da22d3ce34b15877ea70b2a575f58', project_name='exampleproject', project_domain_id='4e6893b7ba0b4006840c3845660b86ed', project_domain_name='exampledomain') f.add_role(id='76e72a', name='admin') f.add_role(id='f4f392', name='member') s = f.add_service('volume') s.add_standard_endpoints(public='http://public.com:8776/v1/%s' % tenant, internal='http://internal:8776/v1/%s' % tenant, admin='http://admin:8776/v1/%s' % tenant, region=region) s = f.add_service('image') s.add_standard_endpoints(public='http://public.com:9292/v1', internal='http://internal:9292/v1', admin='http://admin:9292/v1', region=region) s = f.add_service('compute') s.add_standard_endpoints(public='http://public.com:8774/v2/%s' % tenant, internal='http://internal:8774/v2/%s' % tenant, admin='http://admin:8774/v2/%s' % tenant, region=region) s = f.add_service('ec2') s.add_standard_endpoints(public='http://public.com:8773/services/Cloud', internal='http://internal:8773/services/Cloud', admin='http://admin:8773/services/Admin', region=region) s = f.add_service('identity') s.add_standard_endpoints(public='http://public.com:5000/v3', internal='http://internal:5000/v3', admin='http://admin:35357/v3', region=region) return f f = fixture.V3Token(user_id='c4da488862bd435c9e6c0275a0d0e49a', user_name='exampleuser', user_domain_id='4e6893b7ba0b4006840c3845660b86ed', user_domain_name='exampledomain', expires='2010-11-01T03:32:15-05:00', domain_id='8e9283b7ba0b1038840c3842058b86ab', domain_name='anotherdomain') f.add_role(id='76e72a', name='admin') f.add_role(id='f4f392', name='member') s = f.add_service('volume') s.add_standard_endpoints(public='http://public.com:8776/v1/None', internal='http://internal.com:8776/v1/None', admin='http://admin.com:8776/v1/None', region=region) s = f.add_service('image') s.add_standard_endpoints(public='http://public.com:9292/v1', internal='http://internal:9292/v1', admin='http://admin:9292/v1', region=region) s = f.add_service('compute') s.add_standard_endpoints(public='http://public.com:8774/v1.1/None', internal='http://internal:8774/v1.1/None', admin='http://admin:8774/v1.1/None', region=region) s = f.add_service('ec2') s.add_standard_endpoints(public='http://public.com:8773/services/Cloud', internal='http://internal:8773/services/Cloud', admin='http://admin:8773/services/Admin', region=region) s = f.add_service('identity') s.add_standard_endpoints(public='http://public.com:5000/v3', internal='http://internal:5000/v3', admin='http://admin:35357/v3', region=region) return f",79,73
openstack%2Foslo.utils~stable%2Fkilo~Ie03c8daff9207cc6503c39da45cb275d12ef02e2,openstack/oslo.utils,stable/kilo,Ie03c8daff9207cc6503c39da45cb275d12ef02e2,Updated from global requirements,MERGED,2016-04-29 22:57:43.000000000,2016-05-11 00:59:25.000000000,2016-05-11 00:59:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8688}]","[{'number': 1, 'created': '2016-04-29 22:57:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/25d950c490f0238bbb27b94598baa9ca0aa8b97e', 'message': 'Updated from global requirements\n\nChange-Id: Ie03c8daff9207cc6503c39da45cb275d12ef02e2\n'}]",0,311439,25d950c490f0238bbb27b94598baa9ca0aa8b97e,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie03c8daff9207cc6503c39da45cb275d12ef02e2
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/39/311439/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,25d950c490f0238bbb27b94598baa9ca0aa8b97e,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3,1,1
openstack%2Fneutron~master~Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025,openstack/neutron,master,Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025,Move address scope specific code out of iptables_manager,MERGED,2016-03-05 02:30:25.000000000,2016-05-11 00:58:31.000000000,2016-05-06 21:59:36.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 16806}]","[{'number': 1, 'created': '2016-03-05 02:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2660e176a0e9915b33ae991c8bdcc99724f72e08', 'message': 'Move address scope specific code out of iptables_manager\n\niptables_manager will be used by many features including security\ngroups, FWaaS, metering. The address scope specific code should be\nmoved out of iptables_manager, so that other feature will not get\nthe iptables rules that they will not use. For example, dhcp namespace\nwill not have the address scope iptables rules.\n\nThe change to the test code to adapt the change at [1], has also been\nreverted in this patch.\n\n[1] https://review.openstack.org/#/c/270001/\n\nChange-Id: Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025\nCloses-Bug: #1549513\n'}, {'number': 2, 'created': '2016-03-21 07:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e29fe1b5ef594d50d0ea9bc0b4abe0c3ce90d6e9', 'message': 'Move address scope specific code out of iptables_manager\n\niptables_manager will be used by many features including security\ngroups, FWaaS, metering. The address scope specific code should be\nmoved out of iptables_manager, so that other feature will not get\nthe iptables rules that they will not use. For example, dhcp namespace\nwill not have the address scope iptables rules.\n\nThe change to the test code to adapt the change at [1], has also been\nreverted in this patch.\n\n[1] https://review.openstack.org/#/c/270001/\n\nChange-Id: Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025\nCloses-Bug: #1549513\n'}, {'number': 3, 'created': '2016-05-04 09:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7413ec47ac621d9ec6fa60fde75fb205b88d4a1f', 'message': 'Move address scope specific code out of iptables_manager\n\niptables_manager will be used by many features including security\ngroups, FWaaS, metering. The address scope specific code should be\nmoved out of iptables_manager, so that other feature will not get\nthe iptables rules that they will not use. For example, dhcp namespace\nwill not have the address scope iptables rules.\n\nThe change to the test code to adapt the change at [1], has also been\nreverted in this patch.\n\n[1] https://review.openstack.org/#/c/270001/\n\nChange-Id: Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025\nCloses-Bug: #1549513\n'}, {'number': 4, 'created': '2016-05-06 08:16:08.000000000', 'files': ['neutron/agent/l3/router_info.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/tests/unit/agent/linux/test_iptables_manager.py', 'neutron/agent/l3/dvr_edge_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24f95f4877a72176be2bbe57120306ef5a847297', 'message': 'Move address scope specific code out of iptables_manager\n\niptables_manager will be used by many features including security\ngroups, FWaaS, metering. The address scope specific code should be\nmoved out of iptables_manager, so that other feature will not get\nthe iptables rules that they will not use. For example, dhcp namespace\nwill not have the address scope iptables rules.\n\nThe change to the test code to adapt the change at [1], has also been\nreverted in this patch. Instead, a couple of new test cases are added.\n\n[1] https://review.openstack.org/#/c/270001/\n\nChange-Id: Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025\nCloses-Bug: #1549513\n'}]",0,288828,24f95f4877a72176be2bbe57120306ef5a847297,49,14,4,11159,,,0,"Move address scope specific code out of iptables_manager

iptables_manager will be used by many features including security
groups, FWaaS, metering. The address scope specific code should be
moved out of iptables_manager, so that other feature will not get
the iptables rules that they will not use. For example, dhcp namespace
will not have the address scope iptables rules.

The change to the test code to adapt the change at [1], has also been
reverted in this patch. Instead, a couple of new test cases are added.

[1] https://review.openstack.org/#/c/270001/

Change-Id: Ifc8e7a381f8ab005a9e0216532cc7d0e7378c025
Closes-Bug: #1549513
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/288828/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/router_info.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/tests/unit/agent/linux/test_iptables_manager.py', 'neutron/agent/l3/dvr_edge_router.py']",5,2660e176a0e9915b33ae991c8bdcc99724f72e08,bug/1549513, self._initialize_address_scope_iptables(self.snat_iptables_manager),,85,150
openstack%2Fopenstack-manuals~master~I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8,openstack/openstack-manuals,master,I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8,"[network] Updates to ""Using SR-IOV functionality""",MERGED,2016-05-03 16:42:49.000000000,2016-05-11 00:26:59.000000000,2016-05-10 22:35:09.000000000,"[{'_account_id': 3}, {'_account_id': 9515}, {'_account_id': 10607}, {'_account_id': 12171}, {'_account_id': 14962}, {'_account_id': 15334}, {'_account_id': 17207}, {'_account_id': 17973}]","[{'number': 1, 'created': '2016-05-03 16:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0538fe4788069ad52153f04a05b41dda39788de1', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n- Filter should be PciPassthroughFilter not PCIDeviceScheduler.\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 2, 'created': '2016-05-03 18:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ea1aa65b5c88da479ede20908aee2d43e2b6c128', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 3, 'created': '2016-05-04 15:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8db025060f6c3d78b05bfd683e862a36063b8220', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 4, 'created': '2016-05-05 11:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4022d9199a6ecfa235f5db336a43361f3baca6d1', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 5, 'created': '2016-05-05 15:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1584e939db6175e5ed6898fcfe248d6cb593cf47', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 6, 'created': '2016-05-06 12:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bb8ab5ec4b968119425a91d79a15e585db9f61bc', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 7, 'created': '2016-05-10 11:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c4c104a7b914264c042d5b86531ea0941d08082b', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nbackport: mitaka liberty\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}, {'number': 8, 'created': '2016-05-10 14:16:02.000000000', 'files': ['doc/networking-guide/source/adv-config-sriov.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d291408ba2e0bcdb013709bcb6f267c05b5f50c1', 'message': '[network] Updates to ""Using SR-IOV functionality""\n\n- Indicate how a user can discover how many VFs a given PF can support.\n- PF interface need to be \'up\' else spawn will fail.\n\nbackport: mitaka liberty\n\nChange-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8\n'}]",43,312168,d291408ba2e0bcdb013709bcb6f267c05b5f50c1,49,8,8,17973,,,0,"[network] Updates to ""Using SR-IOV functionality""

- Indicate how a user can discover how many VFs a given PF can support.
- PF interface need to be 'up' else spawn will fail.

backport: mitaka liberty

Change-Id: I840f24f57fef5a1d42cc5cbc1f708e5f13f35cb8
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/312168/8 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/adv-config-sriov.rst'],1,0538fe4788069ad52153f04a05b41dda39788de1,sriov," Users can determine the maximum number of VFs a PF can support: .. code-block:: console # cat /sys/class/net/eth3/device/sriov_totalvfs If the interface is down, make sure it's set to 'up' before launching a guest (else the instance will fail to spawn): .. code-block:: console # ip link set eth3 up # ip link show eth3 8: eth3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT qlen 1000 link/ether a0:36:9f:8f:3f:b8 brd ff:ff:ff:ff:ff:ff vf 0 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 1 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 2 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 3 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 4 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 5 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 6 MAC 00:00:00:00:00:00, spoof checking on, link-state auto vf 7 MAC 00:00:00:00:00:00, spoof checking on, link-state auto PciPassthroughFilter to the scheduler_default_filters parameter", PCIDeviceScheduler to the scheduler_default_filters parameter,25,1
openstack%2Ftrove~master~I1d0f43a84a0e43b55a68f12a52036cd49d46c095,openstack/trove,master,I1d0f43a84a0e43b55a68f12a52036cd49d46c095,Updated from global requirements,MERGED,2016-05-06 22:24:04.000000000,2016-05-11 00:21:06.000000000,2016-05-11 00:21:06.000000000,"[{'_account_id': 3}, {'_account_id': 10215}, {'_account_id': 10295}]","[{'number': 1, 'created': '2016-05-06 22:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0eab1142921278ccbc7592ed3fe7f200f0a49e55', 'message': 'Updated from global requirements\n\nChange-Id: I1d0f43a84a0e43b55a68f12a52036cd49d46c095\n'}, {'number': 2, 'created': '2016-05-10 00:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/09971e5955398bcd5db7aa78fdb16e20fc4d9658', 'message': 'Updated from global requirements\n\nChange-Id: I1d0f43a84a0e43b55a68f12a52036cd49d46c095\n'}, {'number': 3, 'created': '2016-05-10 00:50:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/18a804f2791b3f423b4a6a57497a12d31c18e792', 'message': 'Updated from global requirements\n\nChange-Id: I1d0f43a84a0e43b55a68f12a52036cd49d46c095\n'}]",0,313778,18a804f2791b3f423b4a6a57497a12d31c18e792,15,3,3,11131,,,0,"Updated from global requirements

Change-Id: I1d0f43a84a0e43b55a68f12a52036cd49d46c095
",git fetch https://review.opendev.org/openstack/trove refs/changes/78/313778/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0eab1142921278ccbc7592ed3fe7f200f0a49e55,openstack/requirements,Babel>=2.3.4 # BSD,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",1,1
openstack%2Fneutron~master~Ie86334c79e103e6fa0a327fecaa2f33baf0fb90a,openstack/neutron,master,Ie86334c79e103e6fa0a327fecaa2f33baf0fb90a,Revise ICMPV6_ALLOWED_TYPES,MERGED,2016-04-28 22:55:35.000000000,2016-05-11 00:17:28.000000000,2016-05-06 21:34:24.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10558}, {'_account_id': 10692}, {'_account_id': 11255}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-28 22:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b65116149f101ea670e8b8c54b964388e135f6b', 'message': 'Revise ICMPV6_ALLOWED_TYPES\n\nPull ICMPV6_ALLOWED_TYPES back into Neutron constants from neutron-lib,\nThis constant defines the ICMPv6 types which are allowed to ingress\nthrough security groups before user rules are implemented. As such this\nconstant represents default policy more so than other constants.\n\nAllow ICMPv6 error message types (1-4): these allow an instance detect\nif a packet could not be delivered to its final destination and respond\naccordingly. Of particular note is Packet Too Big messages which allow\nthe instance to perform path MTU discovery, since fragmentation by\nintervening routers is not performed on IPv6.\n\nRemove rule allowing multicast listener discovery (MLD) report and done\nmessages, as these messages are sent my an end station and received by a\nmulticast router or underlying network switch. Should a user need to\noperate a multicast router on an instance, they should explicitly allow\nthese messages. Multicast listener discovery query messages are\npermitted, since and instance receiving these should reply with an MLD\nreport indicating which multicast groups it is participating in.\n\nPermit router advertisements so instances can discover IPv6 routers.\n\nChange-Id: Ie86334c79e103e6fa0a327fecaa2f33baf0fb90a\n'}, {'number': 2, 'created': '2016-05-06 00:42:39.000000000', 'files': ['neutron/common/constants.py', 'neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/agent/linux/test_iptables_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4368560cbc652224b8e34f0d3a18b1321e7806e5', 'message': 'Revise ICMPV6_ALLOWED_TYPES\n\nPull ICMPV6_ALLOWED_TYPES back into Neutron constants from neutron-lib,\nThis constant defines the ICMPv6 types which are allowed to ingress\nthrough security groups before user rules are implemented. As such this\nconstant represents default policy more so than other constants.\n\nRemove multicast listener discovery (MLD) report and done messages for\nlist of allowed message types, as these messages are sent by an end\nstation and received by a multicast router and/or underlying network\nswitch.  Should a user need to operate a multicast router on an\ninstance, they should explicitly allow these messages. Multicast\nlistener discovery query messages are permitted, since and instance\nreceiving these should reply with an MLD report indicating which\nmulticast groups it is participating in.\n\nPermit router advertisements so instances can discover IPv6 routers\nwithout sending router solicitation messages.\n\nChange-Id: Ie86334c79e103e6fa0a327fecaa2f33baf0fb90a\n'}]",4,310954,4368560cbc652224b8e34f0d3a18b1321e7806e5,35,13,2,11255,,,0,"Revise ICMPV6_ALLOWED_TYPES

Pull ICMPV6_ALLOWED_TYPES back into Neutron constants from neutron-lib,
This constant defines the ICMPv6 types which are allowed to ingress
through security groups before user rules are implemented. As such this
constant represents default policy more so than other constants.

Remove multicast listener discovery (MLD) report and done messages for
list of allowed message types, as these messages are sent by an end
station and received by a multicast router and/or underlying network
switch.  Should a user need to operate a multicast router on an
instance, they should explicitly allow these messages. Multicast
listener discovery query messages are permitted, since and instance
receiving these should reply with an MLD report indicating which
multicast groups it is participating in.

Permit router advertisements so instances can discover IPv6 routers
without sending router solicitation messages.

Change-Id: Ie86334c79e103e6fa0a327fecaa2f33baf0fb90a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/310954/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/agent/linux/test_iptables_firewall.py']",4,2b65116149f101ea670e8b8c54b964388e135f6b,allowed-icmpv6-types, for icmp6_type in n_const.ICMPV6_ALLOWED_TYPES:, for icmp6_type in constants.ICMPV6_ALLOWED_TYPES:,15,4
openstack%2Foslo.config~master~Ib70565b5dc547c1805ddf809b6d2a9abab94d7fc,openstack/oslo.config,master,Ib70565b5dc547c1805ddf809b6d2a9abab94d7fc,Fix typo in sphinxconfiggen docs,MERGED,2016-05-10 18:19:40.000000000,2016-05-11 00:07:53.000000000,2016-05-11 00:07:53.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-05-10 18:19:40.000000000', 'files': ['doc/source/sphinxconfiggen.rst'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/9c6bbb1a6c204cac5acde99156d78b7a4068ce00', 'message': 'Fix typo in sphinxconfiggen docs\n\nChange-Id: Ib70565b5dc547c1805ddf809b6d2a9abab94d7fc\n'}]",0,314709,9c6bbb1a6c204cac5acde99156d78b7a4068ce00,7,2,1,8158,,,0,"Fix typo in sphinxconfiggen docs

Change-Id: Ib70565b5dc547c1805ddf809b6d2a9abab94d7fc
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/09/314709/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/sphinxconfiggen.rst'],1,9c6bbb1a6c204cac5acde99156d78b7a4068ce00,fix-config-typo,more specific to the project name you can use the ``sample_config_basename``,more specific to the project name you can use the ``config_sample_basename``,1,1
openstack%2Fneutron~master~Ieafdd640777d4654fcd0ebb65ace25c30151c412,openstack/neutron,master,Ieafdd640777d4654fcd0ebb65ace25c30151c412,Add semaphore to ML2 create_port db operation,MERGED,2016-04-07 21:25:32.000000000,2016-05-11 00:03:46.000000000,2016-04-18 13:23:53.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 12912}, {'_account_id': 13768}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-07 21:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f79d450af0c4f344ca9325dfdf2dd010fd648b4b', 'message': 'Add semaphore to ML2 create_port db operation\n\nThis adds a semaphore scoped to the network ID of a port\ncreation in ML2 to ensure that all workers on a single server\nonly try to allocate an IP for that network one at a time.\n\nThis will alleviate the deadlock error retry mechanism being\nexceeded due to the related bug. It reduces the number of contenders\nfor a single IP allocation from number of workers to number of servers.\n\nIt will unblock the switch to pluggable ipam while the IP allocation\nstrategy is being revamped to be less racey.\n\nRelated-Bug: #1543094\nChange-Id: Ieafdd640777d4654fcd0ebb65ace25c30151c412\n'}, {'number': 2, 'created': '2016-04-07 21:43:00.000000000', 'files': ['neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/db817a9e39dbed10383cb2c70c0f95d4b1795aec', 'message': 'Add semaphore to ML2 create_port db operation\n\nThis adds a semaphore scoped to the network ID of a port\ncreation in ML2 to ensure that all workers on a single server\nonly try to allocate an IP for that network one at a time.\n\nThis will alleviate the deadlock error retry mechanism being\nexceeded due to the related bug. It reduces the number of contenders\nfor a single IP allocation from number of workers to number of servers.\n\nIt will unblock the switch to pluggable ipam while the IP allocation\nstrategy is being revamped to be less racey.\n\nPartial-Bug: #1543094\nChange-Id: Ieafdd640777d4654fcd0ebb65ace25c30151c412\n'}]",0,303085,db817a9e39dbed10383cb2c70c0f95d4b1795aec,30,13,2,7787,,,0,"Add semaphore to ML2 create_port db operation

This adds a semaphore scoped to the network ID of a port
creation in ML2 to ensure that all workers on a single server
only try to allocate an IP for that network one at a time.

This will alleviate the deadlock error retry mechanism being
exceeded due to the related bug. It reduces the number of contenders
for a single IP allocation from number of workers to number of servers.

It will unblock the switch to pluggable ipam while the IP allocation
strategy is being revamped to be less racey.

Partial-Bug: #1543094
Change-Id: Ieafdd640777d4654fcd0ebb65ace25c30151c412
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/303085/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,f79d450af0c4f344ca9325dfdf2dd010fd648b4b,bug/1543094,"from oslo_concurrency import lockutils # TODO(kevinbenton): remove when bug/1543094 is fixed. with lockutils.lock('create-port-lock', lock_file_prefix=port['port']['network_id'], external=True): result, mech_context = self._create_port_db(context, port)"," result, mech_context = self._create_port_db(context, port)",6,1
openstack%2Fneutron~master~Id7441ab5c3f3667aa1cc48100286a2a9d480e201,openstack/neutron,master,Id7441ab5c3f3667aa1cc48100286a2a9d480e201,Fix update target tenant RBAC external path,MERGED,2016-05-03 00:28:06.000000000,2016-05-10 23:57:09.000000000,2016-05-10 23:57:09.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-05-03 00:28:06.000000000', 'files': ['neutron/tests/tempest/api/admin/test_external_network_extension.py', 'neutron/db/external_net_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/89297919a73c1e7f86c61d08f3f3d15278f5763a', 'message': ""Fix update target tenant RBAC external path\n\nThis fixes the logic to allow updates to wildcard RBAC external\npolicies. It was broken for two reasons: first, it was using the\nwrong kwarg, second, it wasn't considering the target tenant when\ndetermining if the policy was required.\n\nThis patch fixes both issues and adds an API test exercising the\nupdate path.\n\nCloses-Bug: #1577100\nChange-Id: Id7441ab5c3f3667aa1cc48100286a2a9d480e201\n""}]",0,311897,89297919a73c1e7f86c61d08f3f3d15278f5763a,16,7,1,7787,,,0,"Fix update target tenant RBAC external path

This fixes the logic to allow updates to wildcard RBAC external
policies. It was broken for two reasons: first, it was using the
wrong kwarg, second, it wasn't considering the target tenant when
determining if the policy was required.

This patch fixes both issues and adds an API test exercising the
update path.

Closes-Bug: #1577100
Change-Id: Id7441ab5c3f3667aa1cc48100286a2a9d480e201
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/311897/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/tempest/api/admin/test_external_network_extension.py', 'neutron/db/external_net_db.py']",2,89297919a73c1e7f86c61d08f3f3d15278f5763a,bug/1577100, new_tenant = None if event == events.BEFORE_UPDATE: new_tenant = kwargs['policy_update']['target_tenant'] if new_tenant: # if this is an update we also need to ignore any router # interfaces that belong to the new target. router = router.filter(l3_db.Router.tenant_id != new_tenant), if event == events.BEFORE_UPDATE: new_tenant = kwargs['policy_tenant']['target_tenant'],21,1
openstack%2Ftempest~master~Ibe4b1105337b6527042aebe3fcb000006188e583,openstack/tempest,master,Ibe4b1105337b6527042aebe3fcb000006188e583,Using get method to get dictionary values,ABANDONED,2016-05-05 10:41:16.000000000,2016-05-10 23:30:48.000000000,,"[{'_account_id': 3}, {'_account_id': 4727}, {'_account_id': 6167}, {'_account_id': 6598}, {'_account_id': 7350}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 12024}, {'_account_id': 21302}]","[{'number': 1, 'created': '2016-05-05 10:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5dc756282131f55b01c050d03b1c55560ddc537a', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}, {'number': 2, 'created': '2016-05-05 11:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3e71c10d5239a45f6ba8b6255a0819bbcfc5d1b8', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}, {'number': 3, 'created': '2016-05-08 07:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2661fc5cd95c66190caeef50fe69a3255c0e8a82', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}, {'number': 4, 'created': '2016-05-08 07:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8bbdb873be4137ae750c59aa6ae094baf03002e', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}, {'number': 5, 'created': '2016-05-08 08:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/266a6e17cce4c7c3431795a655942e1ca459c2e3', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}, {'number': 6, 'created': '2016-05-08 10:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f01d88dee14433596383d0273c1faa03464ee3de', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}, {'number': 7, 'created': '2016-05-08 13:02:22.000000000', 'files': ['tempest/common/dynamic_creds.py', 'tempest/tests/common/test_dynamic_creds.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0d9c9c72483294e17a6f26b4b5ed7db0e1b96e0a', 'message': 'Using get method to get dictionary values\n\nModify _create_network_resources method to use\nget method to fetch values of network_resources\ndictionary.\n\nChange-Id: Ibe4b1105337b6527042aebe3fcb000006188e583\n'}]",5,312892,0d9c9c72483294e17a6f26b4b5ed7db0e1b96e0a,38,10,7,4727,,,0,"Using get method to get dictionary values

Modify _create_network_resources method to use
get method to fetch values of network_resources
dictionary.

Change-Id: Ibe4b1105337b6527042aebe3fcb000006188e583
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/312892/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/dynamic_creds.py'],1,5dc756282131f55b01c050d03b1c55560ddc537a,create-resources-get, if self.network_resources.get('router'): if (not self.network_resources.get('subnet') or not self.network_resources.get('network'): elif self.network_resources.get('subnet'): if not self.network_resources.get('network'): elif self.network_resources.get('dhcp'): if not self.network_resources or self.network_resources.get('network'): if not self.network_resources or self.network_resources.get('subnet'): if not self.network_resources or self.network_resources.get('router'):, if self.network_resources['router']: if (not self.network_resources['subnet'] or not self.network_resources['network']): elif self.network_resources['subnet']: if not self.network_resources['network']: elif self.network_resources['dhcp']: if not self.network_resources or self.network_resources['network']: if not self.network_resources or self.network_resources['subnet']: if not self.network_resources or self.network_resources['router']:,9,9
openstack%2Fkeystone~master~I490c0f728532939d92110b08f130b5cd0a07034e,openstack/keystone,master,I490c0f728532939d92110b08f130b5cd0a07034e,SQLAlchemy column type for materialized path,ABANDONED,2015-11-30 15:53:32.000000000,2016-05-10 22:59:58.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 10046}, {'_account_id': 13055}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-11-30 15:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e49b41602f9c2a2e0ecaae5731f89b95e47c9b8c', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, ang from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 2, 'created': '2015-12-01 15:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/123f4eea60d6fbf49e1cbcf4c0b0ff6f101d9403', 'message': 'SQLAlchemy column type for storing string arrays as flat strings\n(materialized path)\n\nA column type that converts array of strings to a flat string to store in\nthe database. It converts from the flat string to an array of strings on\nretrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e'}, {'number': 3, 'created': '2015-12-01 16:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a5f753d75ed05ccf90d16c15d0cef8b59e247c4f', 'message': 'SQLAlchemy column type for storing string arrays as flat strings\n(materialized path)\n\nA column type that converts array of strings to a flat string to store in\nthe database. It converts from the flat string to an array of strings on\nretrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e'}, {'number': 4, 'created': '2015-12-01 16:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4526f26502eb8db5a3072ed94127e7420f928f8b', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, ang from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 5, 'created': '2015-12-16 16:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/518baf0b06c46780f5fd9e0025e6bac532b4f75f', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, ang from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 6, 'created': '2015-12-16 16:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bc2ee0f497295cff5ca1bfed7ab09e9cc2f25f71', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, ang from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 7, 'created': '2015-12-16 16:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f839d6a3a01ea9eead099e1ac2822297de92f841', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, and from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e'}, {'number': 8, 'created': '2015-12-17 12:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/89c8a9dec594686dbdc80faad74350c63aa72719', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, and from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 9, 'created': '2015-12-22 13:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/37516dc3a46d1900e63ff5b86e38e044dc911dea', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, and from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 10, 'created': '2015-12-22 14:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f9b1a7ee75c2436fa3e9014fc3a8b43492e6ee1a', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, and from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 11, 'created': '2015-12-22 19:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7ab45049c35ee50e478f9b22a6d2cd2da201ffdb', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, and from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 12, 'created': '2016-01-18 16:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/95f234aa76236c49ebfffedc7aa9c2e3e46e9453', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store in the\ndatabase, and from the flat string to an array of strings on retrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}, {'number': 13, 'created': '2016-01-18 17:19:46.000000000', 'files': ['keystone/common/sql/core.py', 'keystone/tests/unit/common/test_sql_core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b7a913e7296b04ce176394000ed9e4c7d110af30', 'message': 'SQLAlchemy column type for materialized path\n\nThe column type converting array of strings to a flat string to store\nin the database, and from the flat string to an array of strings on\nretrieval.\n\nImplements bp materialized-path-column\n\nChange-Id: I490c0f728532939d92110b08f130b5cd0a07034e\n'}]",17,251445,b7a913e7296b04ce176394000ed9e4c7d110af30,35,7,13,13055,,,0,"SQLAlchemy column type for materialized path

The column type converting array of strings to a flat string to store
in the database, and from the flat string to an array of strings on
retrieval.

Implements bp materialized-path-column

Change-Id: I490c0f728532939d92110b08f130b5cd0a07034e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/251445/10 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/tests/unit/common/test_sql_core.py']",2,e49b41602f9c2a2e0ecaae5731f89b95e47c9b8c,bp/materialized-path-column,"from keystone.tests.unit.ksfixtures import database class ExampleWithPathColumn(ModelBase): __tablename__ = 'examplewithpathcolumn' id = sql.Column(sql.String(64), primary_key=True, unique=True) path1 = sql.Column(sql.MaterializedPathType(), default=[]) class TestMaterializedPathColumn(unit.SQLDriverOverrides, unit.TestCase): # Initialization def setUp(self): super(TestMaterializedPathColumn, self).setUp() self.useFixture(database.Database()) self.load_backends() ExampleWithPathColumn.__table__.create(sql.get_engine()) def config_files(self): config_files = super(TestMaterializedPathColumn, self).config_files() config_files.append(unit.dirs.tests_conf('backend_sql.conf')) return config_files # Tests @staticmethod def _create_node(): """"""Test node creation shortcut"""""" node = ExampleWithPathColumn(id=utils.new_uuid()) return node def test_create_node(self): """"""Created node has empty path"""""" node = self._create_node() self.assertFalse(node.path1) def test_path_column_stores_array(self): """"""Stored and returned value has type list"""""" node = self._create_node() example = [utils.new_uuid(), utils.new_uuid()] session = sql.get_session() session.add(node) with session.begin(): node.path1 = example instance = session.query(ExampleWithPathColumn).one() self.assertIsInstance(instance.path1, list)",,73,0
openstack%2Foslo-specs~master~I06493dec60f23671f8aca2534b44661ca91f53d3,openstack/oslo-specs,master,I06493dec60f23671f8aca2534b44661ca91f53d3,Allow policy registration from code,MERGED,2016-04-21 18:44:55.000000000,2016-05-10 22:58:54.000000000,2016-05-10 22:58:54.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5441}, {'_account_id': 5638}, {'_account_id': 5754}, {'_account_id': 7725}, {'_account_id': 16212}]","[{'number': 1, 'created': '2016-04-21 18:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/142c39c549fbe85ad04f4895a7d0e3b3684a9ece', 'message': 'Allow policy registration from code\n\nAdd a capability to olso.policy to register default policy rules in\ncode. This will allow consuming projects, if they register all of their\npolicies, to expose a few things:\n\n* Sample policy files can be generated from the code outlining all\n  available policy options.\n* Deployers will only need to configure policies that differ from these\n  defaults.\n* Given a RequestContext a list of policies that will pass for that\n  context can be generated. This can be built upon so that projects can\n  expose allowable actions to their users.\n\nChange-Id: I06493dec60f23671f8aca2534b44661ca91f53d3\n'}, {'number': 2, 'created': '2016-04-21 18:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/44f765129caad74db6fbc3795490539a225fd923', 'message': 'Allow policy registration from code\n\nAdd a capability to olso.policy to register default policy rules in\ncode. This will allow consuming projects, if they register all of their\npolicies, to expose a few things:\n\n* Deployers will only need to configure policies that differ from these\n  defaults.\n* Given a RequestContext a list of policies that will pass for that\n  context can be generated. This can be built upon so that projects can\n  expose allowable actions to their users.\n\nChange-Id: I06493dec60f23671f8aca2534b44661ca91f53d3\n'}, {'number': 3, 'created': '2016-04-21 19:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/17dc70a10053bd4231030c0ed5d9b0a377402b02', 'message': 'Allow policy registration from code\n\nAdd a capability to olso.policy to register default policy rules in\ncode. This will allow consuming projects, if they register all of their\npolicies, to expose a few things:\n\n* Deployers will only need to configure policies that differ from these\n  defaults.\n* Given a RequestContext a list of policies that will pass for that\n  context can be generated. This can be built upon so that projects can\n  expose allowable actions to their users.\n\nChange-Id: I06493dec60f23671f8aca2534b44661ca91f53d3\n'}, {'number': 4, 'created': '2016-05-03 14:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/78cb0d01094d15a4321548a78122363156e5feaf', 'message': 'Allow policy registration from code\n\nAdd a capability to olso.policy to register default policy rules in\ncode. This will allow consuming projects, if they register all of their\npolicies, to expose a few things:\n\n* Deployers will only need to configure policies that differ from these\n  defaults.\n* Given a RequestContext a list of policies that will pass for that\n  context can be generated. This can be built upon so that projects can\n  expose allowable actions to their users.\n\nChange-Id: I06493dec60f23671f8aca2534b44661ca91f53d3\n'}, {'number': 5, 'created': '2016-05-03 21:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/d4d0c4ff1420d29aabc777cc4b9a95d0d72537f3', 'message': 'Allow policy registration from code\n\nAdd a capability to olso.policy to register default policy rules in\ncode. This will allow consuming projects, if they register all of their\npolicies, to expose a few things:\n\n* Deployers will only need to configure policies that differ from these\n  defaults.\n* Given a RequestContext a list of policies that will pass for that\n  context can be generated. This can be built upon so that projects can\n  expose allowable actions to their users.\n\nChange-Id: I06493dec60f23671f8aca2534b44661ca91f53d3\n'}, {'number': 6, 'created': '2016-05-04 15:43:22.000000000', 'files': ['specs/newton/policy-in-code.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/c2aa12082e27ed5c4d9587c72c51747e2bea8030', 'message': 'Allow policy registration from code\n\nAdd a capability to olso.policy to register default policy rules in\ncode. This will allow consuming projects, if they register all of their\npolicies, to expose a few things:\n\n* Deployers will only need to configure policies that differ from these\n  defaults.\n* Given a RequestContext a list of policies that will pass for that\n  context can be generated. This can be built upon so that projects can\n  expose allowable actions to their users.\n\nChange-Id: I06493dec60f23671f8aca2534b44661ca91f53d3\n'}]",14,309152,c2aa12082e27ed5c4d9587c72c51747e2bea8030,23,8,6,5441,,,0,"Allow policy registration from code

Add a capability to olso.policy to register default policy rules in
code. This will allow consuming projects, if they register all of their
policies, to expose a few things:

* Deployers will only need to configure policies that differ from these
  defaults.
* Given a RequestContext a list of policies that will pass for that
  context can be generated. This can be built upon so that projects can
  expose allowable actions to their users.

Change-Id: I06493dec60f23671f8aca2534b44661ca91f53d3
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/52/309152/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/policy-in-code.rst'],1,142c39c549fbe85ad04f4895a7d0e3b3684a9ece,policy_generation,".. ============================= The title of your blueprint ============================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/oslo?searchtext=policy-in-code For a while now there has been a desire to embed sane policy defaults in code and allow for a policy file to override them. This would allow deployers to only configure policies that they specifically want to override which could reduce the size and complexity of those files. It would also allow for generating a sample policy file which includes an exhaustive list of all policies. Problem description =================== There are two issues being addressed here: Given a deployed policy file it is not trivial to determine how much it differs from the defaults that a project expects. This is due to there not being an authoritative place to find all policies and their defaults. Some projects provide sample files but they're not always exhaustive. And it's not easy to diff a production policy file against the sample file after extensive modification. Given an authenticated request context it is not possible to determine which policies will pass. This is because policy checks are ad hoc throughout the code with no central registry of all possible checks. And a policy file may not have all policies listed as some may be left to fallback to the default rule. Proposed change =============== The proposal is that any policy that should be checked in the code will be registered with a central Policy class, similar to how configuration registration is done. Any policy check within the code base will be converted to use this Policy class to ensure that all checks are defined. Any attempt to use a policy that is not registered should raise an exception. Registration will require two pieces of data: 1. The rule name, e.g. ""compute:get"" or ""os_compute_api:servers:index"" 2. The rule, e.g. ""rule:admin_or_owner"" or ""role:admin"" The rule name is needed for later lookups. The rule is necessary in order to set the defaults and generate a sample file. As an example, based on how Nova might use this:: -- nova/policy/create.py from nova import policy server_policies = [ (""os_compute_api:servers:create"", ""rule:admin_or_owner""), (""os_compute_api:servers:create:forced_host"", ""rule:admin_or_owner""), (""os_compute_api:servers:create:attach_volume"", ""rule:admin_or_owner""), (""os_compute_api:servers:create:attach_network"", ""rule:admin_or_owner""), ] policy_engine = policy.get_policy() # registration will error if a duplicate policy is defined policy_engine.register(server_policies) -- nova/api/openstack/compute/servers.py from nova import policy policy_engine = policy.get_policy() def create(self, context): ... policy_engine.enforce('os_compute_api:servers:create', target, creds) try: # This would error because the policy is not registered policy_engine.enforce( 'os_compute_api:servers:create_not_registered', target, creds) except: pass if volume_to_attach: policy_engine.enforce( 'os_compute_api:servers:create:attach_volume', target, creds) The proposed change to oslo.policy is that the Enforcer class will gain a ""register"" method. This method will process and store the registered policies. The ""load_rules"" method will be modified to merge rules loaded from policy files in with the registered defaults. Rules loaded from files will overwrite registered defaults. The ""enforce"" method will be updated so that attempting to check against a rule that doesn't exist will, optionally, be an error. In other words the default rule loses it's special status and is not a fallback for rules that are not defined. It will still remain as a reference for other rules to use. Files to change: * olso_policy/policy.py Alternatives ------------ Rather than modifying the Enforcer class in oslo_policy/policy.py a new Policy class could be added which handles registration and contains a new ""authorize"" method. The Policy class would mostly handle registration and storage of policies and would proxy to Enforcer for loading policy from files and handling the actual enforcement. Over time it may make sense to pull the loading of policy from files out of the Enforcer class and into Policy. Impact on Existing APIs ----------------------- A new ""register"" method will be added to the Enforcer class. Security impact --------------- There is no security impact from this change. The way that policies are enforced does not change, just where they're loaded from. Performance Impact ------------------ Registration of policies from code will have a slight peformance impact on startup, but this should be no different than loading configuration on startup. Configuration Impact -------------------- There is no direct configuration impact from this change. This change will allow projects who have registered policies to not need a policy file in order to use those defaults. This will allow deployers to trim down, or remove, their policy files if they are running close to the defaults. Developer Impact ---------------- It will not be required, but it will be encouraged, that projects switch to registering policy rules before using them. So developers will need to get in the habit of adding that registration before use, similar to adding a new configuration option. Testing Impact -------------- Unit testing should be sufficient here. This adds a new capability that can be used by other projects but it is not directly dependent on anything. Implementation ============== Assignee(s) ----------- Primary assignee: alaski Other contributors: None Milestones ---------- Target Milestone for completion: newton-1 Work Items ---------- * Add a ""register"" method to Enforcer for registration of rules * Update Enforcer.load_rules() to merge registered rules with file loaded rules * Update Enforcer.enforce to optionally error when checking against policies which are not registered. Incubation ========== N/A Adoption -------- N/A Library ------- N/A Anticipated API Stabilization ----------------------------- N/A Documentation Impact ==================== The ability to register policy rules will be documented in developer facing documentation. Any deployer facing changes will be the responsibility of consuming projects to document as they switch over to using policy registration. Dependencies ============ None References ========== Nova spec for this capability: https://review.openstack.org/#/c/290155/ .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,228,0
openstack%2Fkeystone~master~I3357fb655f2c502210a28f77f56c2ea0a320fb16,openstack/keystone,master,I3357fb655f2c502210a28f77f56c2ea0a320fb16,Use path hybrid property in query filtering,ABANDONED,2015-11-30 19:30:59.000000000,2016-05-10 22:58:20.000000000,,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 10046}, {'_account_id': 13055}, {'_account_id': 13063}, {'_account_id': 17123}]","[{'number': 1, 'created': '2015-11-30 19:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/45bfb561768515b7d73dba3c006dcc540003ae7b', 'message': 'Use path hybrid property in query filtering\n\nIn-place comparator factory for path hybrid property to be used in query\nfiltering: implemented eq and startswith.\n\nImplements bp materialized-path-column\n\nChange-Id: I3357fb655f2c502210a28f77f56c2ea0a320fb16\n'}, {'number': 2, 'created': '2015-12-01 16:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e44933b5e2a1a2f175640b87a1b9aeb3f9762985', 'message': 'Use path hybrid property in query filtering\n\nIn-place comparator factory for path hybrid property to be used in query\nfiltering: implemented eq and startswith.\n\nImplements bp materialized-path-column\n\nChange-Id: I3357fb655f2c502210a28f77f56c2ea0a320fb16\n'}, {'number': 3, 'created': '2015-12-17 13:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c9d4020a19b0eb0a1926bc0ed32f52dfd83a38f6', 'message': 'Use path hybrid property in query filtering\n\nIn-place comparator factory for path hybrid property to be used in query\nfiltering: implemented eq and startswith.\n\nImplements bp materialized-path-column\n\nChange-Id: I3357fb655f2c502210a28f77f56c2ea0a320fb16\n'}, {'number': 4, 'created': '2015-12-22 19:39:31.000000000', 'files': ['keystone/common/sql/core.py', 'keystone/tests/unit/common/test_sql_core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/935297c8441c834c0d9ecfb7317fdb1d473e4a72', 'message': 'Use path hybrid property in query filtering\n\nIn-place comparator factory for path hybrid property to be used in query\nfiltering: implemented eq and startswith.\n\nImplements bp materialized-path-column\n\nChange-Id: I3357fb655f2c502210a28f77f56c2ea0a320fb16\n'}]",9,251513,935297c8441c834c0d9ecfb7317fdb1d473e4a72,13,6,4,13055,,,0,"Use path hybrid property in query filtering

In-place comparator factory for path hybrid property to be used in query
filtering: implemented eq and startswith.

Implements bp materialized-path-column

Change-Id: I3357fb655f2c502210a28f77f56c2ea0a320fb16
",git fetch https://review.opendev.org/openstack/keystone refs/changes/13/251513/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/tests/unit/common/test_sql_core.py']",2,45bfb561768515b7d73dba3c006dcc540003ae7b,bp/materialized-path-column," def test_subtree_request(self): node1, node2, node3_1, node3_2 = \ [self._create_node() for _ in range(4)] session = sql.get_session() with session.begin(): session.add_all([node1, node2, node3_1, node3_2]) node2.parent1 = node1 node3_1.parent1 = node2 node3_2.parent1 = node2 stored_node2 = session.query(ExampleWithPathColumn).filter( ExampleWithPathColumn.parent1 == node1 ).one() self.assertEqual([node1.id], stored_node2.path1) subtree_query = session.query(ExampleWithPathColumn).filter( ExampleWithPathColumn.parent1.startswith(node2) ) self.assertEqual(2, subtree_query.count()) for i in subtree_query.all(): self.assertEqual([node1.id, node2.id], i.path1)",,53,0
openstack%2Fkeystone~master~I161ec170b74bee82311a3cc64b864353b29b006e,openstack/keystone,master,I161ec170b74bee82311a3cc64b864353b29b006e,Materialized path convenience wrapper,ABANDONED,2015-11-30 16:15:24.000000000,2016-05-10 22:57:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 10046}, {'_account_id': 13055}, {'_account_id': 13063}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-11-30 16:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d35a5539e72ccd2a228925064cb59df92c5f2cab', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 2, 'created': '2015-12-01 15:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eeda66874fe7521e56f99887354c76149be8609c', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 3, 'created': '2015-12-01 16:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c58c04020a6a8d6591e7963feb5dca7ce04be825', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 4, 'created': '2015-12-16 16:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/07273a7449c9348cb9443b862a6a46892508656c', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 5, 'created': '2015-12-16 17:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a96ab2c6d65e6ff31dcb06a62f01dde9096071c5', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 6, 'created': '2015-12-17 12:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7cdb6d95f9e06f16d1b8a8eb03341c5865734c25', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 7, 'created': '2015-12-17 13:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3e8036f7389601857eda3ff3b432c959b93964f6', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}, {'number': 8, 'created': '2015-12-22 19:39:22.000000000', 'files': ['keystone/common/sql/core.py', 'keystone/tests/unit/common/test_sql_core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/388804f1d8923308db3af8271f60f80eb253a584', 'message': 'Materialized path convenience wrapper\n\nSQLAlchemy hybrid property that should behave like an ordinary ""parent""\ncolumn in widely used adjacency list tree models.\nAssigning a node to be a ""parent"" for the current node updates current\nnode\'s corresponding path column.\n\nPath column name and id column name should be specified in the property\ndeclaration clause.\n\nImplements bp materialized-path-column\n\nChange-Id: I161ec170b74bee82311a3cc64b864353b29b006e\n'}]",8,251455,388804f1d8923308db3af8271f60f80eb253a584,22,6,8,13055,,,0,"Materialized path convenience wrapper

SQLAlchemy hybrid property that should behave like an ordinary ""parent""
column in widely used adjacency list tree models.
Assigning a node to be a ""parent"" for the current node updates current
node's corresponding path column.

Path column name and id column name should be specified in the property
declaration clause.

Implements bp materialized-path-column

Change-Id: I161ec170b74bee82311a3cc64b864353b29b006e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/55/251455/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/tests/unit/common/test_sql_core.py']",2,d35a5539e72ccd2a228925064cb59df92c5f2cab,bp/materialized-path-column," parent1 = sql.MaterializedPathParent('path1') def test_parent_assignment_updates_path(self): parent_node = self._create_node() child_node = self._create_node() self.assertFalse(child_node.path1) session = sql.get_session() session.add(parent_node) session.add(child_node) with session.begin(): child_node.parent1 = parent_node stored_child = session.query(ExampleWithPathColumn).get(child_node.id) self.assertEqual(parent_node.id, stored_child.parent1.id) self.assertEqual([parent_node.id], child_node.path1)",,72,0
openstack%2Fcinder~master~I4ff2cc5d0ea4585777911566bca2c5c1a9a3c756,openstack/cinder,master,I4ff2cc5d0ea4585777911566bca2c5c1a9a3c756,Fix LeftHand to work with nova evacuate,ABANDONED,2016-01-27 04:56:46.000000000,2016-05-10 22:46:28.000000000,,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10622}, {'_account_id': 11047}, {'_account_id': 11903}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19904}, {'_account_id': 19917}]","[{'number': 1, 'created': '2016-01-27 04:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c3150e57f28fccc0c22b41d91ce6c7bf23f0569a', 'message': ""Fix LeftHand to work with nova evacuate\n\nUse the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nChange-Id: I4ff2cc5d0ea4585777911566bca2c5c1a9a3c756\nPartial-Bug: #1537280\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 2, 'created': '2016-01-27 15:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb6492f192e4c1d018a074c8b5af9b021c77cfe3', 'message': ""Fix LeftHand to work with nova evacuate\n\nUse the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nChange-Id: I4ff2cc5d0ea4585777911566bca2c5c1a9a3c756\nPartial-Bug: #1537280\nDepends-On: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 3, 'created': '2016-01-30 06:51:47.000000000', 'files': ['cinder/volume/drivers/hpe/hpe_lefthand_iscsi.py', 'cinder/tests/unit/test_hpelefthand.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/de3960b8e27e782ceeadb2fc8a6bcdb3891bb57c', 'message': ""Fix LeftHand to work with nova evacuate\n\nUse the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nChange-Id: I4ff2cc5d0ea4585777911566bca2c5c1a9a3c756\nPartial-Bug: #1537280\nDepends-On: I822e31bf8a739588991fcca34976d55b71b8a227\n""}]",2,272899,de3960b8e27e782ceeadb2fc8a6bcdb3891bb57c,109,42,3,11047,,,0,"Fix LeftHand to work with nova evacuate

Use the connector['instance_host'] (when found) to
fix nova evacuate in situations where nova provides the
wrong connector.

To be useful, the dependent nova patch is needed to provide
instance_host.

Change-Id: I4ff2cc5d0ea4585777911566bca2c5c1a9a3c756
Partial-Bug: #1537280
Depends-On: I822e31bf8a739588991fcca34976d55b71b8a227
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/272899/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/hpe/hpe_lefthand_iscsi.py', 'cinder/tests/unit/test_hpelefthand.py']",2,c3150e57f28fccc0c22b41d91ce6c7bf23f0569a,bug/1537280," def test_terminate_connection_instance_host(self): """"""For evacuate fix, always use 'instance_host' when provided."""""" mock_client = self.setup_driver() with mock.patch.object(hpe_lefthand_iscsi.HPELeftHandISCSIDriver, '_create_client') as mock_do_setup: mock_do_setup.return_value = mock_client instance_host = 'right_host' connector = {'instance_host': instance_host, 'host': 'wrong_host'} self.driver.terminate_connection(self.volume, connector) mock_client.getServerByName.assert_called_once_with(instance_host) ",,20,1
openstack%2Fcinder~master~Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc,openstack/cinder,master,Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc,Fix 3PAR to work with nova evacuate,ABANDONED,2016-01-12 01:56:28.000000000,2016-05-10 22:46:12.000000000,,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11047}, {'_account_id': 11903}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19904}, {'_account_id': 19917}]","[{'number': 1, 'created': '2016-01-12 01:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/00c486c58360e3e479595594930a704490eab45e', 'message': ""W-I-P Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\nthis new info.\n\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 2, 'created': '2016-01-22 22:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0e398ddbc83edf5a82e8c8d94d564c488d41bc71', 'message': ""W-I-P Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\nthis new info.\n\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 3, 'created': '2016-01-24 04:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d96f7068329ea8bd8260a526001d9dc4a779c794', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 4, 'created': '2016-01-25 22:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8928bdb11921682dcd816e4d48d5aa6ccf255b5', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 5, 'created': '2016-01-27 00:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f340c1a40db0f4bd8e2e8a3e32c1eff4ba33366', 'message': ""Fix LeftHand to work with nova evacuate\n\nUse the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 6, 'created': '2016-01-27 04:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/69f04b6c1eeaee0a4f8864bd9fa07b1336585cd3', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDependsOn: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 7, 'created': '2016-01-27 15:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/518980f232336b0d0ac70280b7e5dd04e4090b01', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDepends-On: I793f2996fc0af1c321a240ad9348dc9bce816030\n""}, {'number': 8, 'created': '2016-01-30 06:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/445a5c0f9b14a1534504328e76c93f7188c6ea1a', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the dependent nova patch is needed to provide\ninstance_host.\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\nDepends-On: I822e31bf8a739588991fcca34976d55b71b8a227\n""}, {'number': 9, 'created': '2016-02-06 06:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c638d5d16a81c916f6d0a063b664e048bafcabb7', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the nova patch [1] is needed to provide\ninstance_host.\n\n[1] I822e31bf8a739588991fcca34976d55b71b8a227\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\n""}, {'number': 10, 'created': '2016-02-12 03:40:47.000000000', 'files': ['cinder/volume/drivers/hpe/hpe_3par_iscsi.py', 'cinder/tests/unit/test_hpe3par.py', 'cinder/volume/drivers/hpe/hpe_3par_fc.py', 'cinder/volume/drivers/hpe/hpe_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/79f97aa525d983593dd29f7cd0d771870829f2ed', 'message': ""Fix 3PAR to work with nova evacuate\n\nExamine the connector['instance_host'] (when found) to\nfix nova evacuate in situations where nova provides the\nwrong connector.\n\nTo be useful, the nova patch [1] is needed to provide\ninstance_host.\n\n[1] I822e31bf8a739588991fcca34976d55b71b8a227\n\nPartial-Bug: #1537280\nChange-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc\n""}]",1,266098,79f97aa525d983593dd29f7cd0d771870829f2ed,322,52,10,11047,,,0,"Fix 3PAR to work with nova evacuate

Examine the connector['instance_host'] (when found) to
fix nova evacuate in situations where nova provides the
wrong connector.

To be useful, the nova patch [1] is needed to provide
instance_host.

[1] I822e31bf8a739588991fcca34976d55b71b8a227

Partial-Bug: #1537280
Change-Id: Ib189ce5bd9b54776e207ad7fbaceddc6437c67fc
",git fetch https://review.opendev.org/openstack/cinder refs/changes/98/266098/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/hpe/hpe_3par_iscsi.py', 'cinder/volume/drivers/hpe/hpe_3par_fc.py', 'cinder/volume/drivers/hpe/hpe_3par_common.py']",3,00c486c58360e3e479595594930a704490eab45e,bug/1537280," def get_host_and_connector(self, connector): """"""Get the source host and connector using data in this connector."""""" hostname = self._safe_hostname(connector['host']) # Check instance_host. This allows evacuate to provide the original # instance host for evacuate. If the instance_host doesn't match the # connector, then build a new connector so that we don't use the wrong # initiator or wwpns. instance_host = connector.get('instance_host') if instance_host: instance_host = self._safe_hostname(instance_host) if hostname != instance_host: hostname = instance_host connector = {'initiator': None, 'wwpns': None} host = self._get_3par_host(hostname) if host: fc_paths = host.get('FCPaths') if fc_paths: connector['wwpns'] = [fc['wwn'] for fc in fc_paths] return hostname, connector ",,25,2
openstack%2Fnova~master~I822e31bf8a739588991fcca34976d55b71b8a227,openstack/nova,master,I822e31bf8a739588991fcca34976d55b71b8a227,Add instance host to evacuate terminate connector,ABANDONED,2016-01-30 05:15:24.000000000,2016-05-10 22:45:03.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1865}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 11047}, {'_account_id': 11903}, {'_account_id': 12299}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-01-30 05:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d142f8269c3c07ba02b303f4265212370ba7df3d', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to evacuate terminate connector.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 2, 'created': '2016-01-30 07:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1b564f3b91c7d6c9aa1dd6f13057b4fa5828bc8', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to evacuate terminate connector.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 3, 'created': '2016-02-03 21:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b177ccbb5c572e9b709089a6631ee1df0175e48', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to evacuate terminate connector.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 4, 'created': '2016-02-06 05:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a46ef601e46c4947dfa730ba307cf03bd9713639', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to evacuate terminate connector.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 5, 'created': '2016-02-08 17:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7a7c2b27df8384ff7f30531ed376832fb094225', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to evacuate terminate connector.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 6, 'created': '2016-02-12 03:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/757107525290afe902a2101fc0605c746b817c3d', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to evacuate terminate connector.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 7, 'created': '2016-02-12 04:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6cf62881fb6706ec57ac4844b970bf82cc68ed0a', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to the connector for evacuation.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 8, 'created': '2016-03-01 22:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4139923b77b741b32c8cd23881d78f2ec0e74f48', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to the connector for evacuation.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 9, 'created': '2016-03-07 10:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/255d7db2b4cc78c9af2c761f97f52d00af2fbec3', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to the connector for evacuation.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}, {'number': 10, 'created': '2016-03-07 18:43:16.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e1d9c8200bcdb51fcc7970495c5b2a8475f2053c', 'message': ""Add instance host to evacuate terminate connector\n\nWhen we only have the connector for the wrong host,\nadd instance host to the connector for evacuation.\n\nWhen calling terminate_connection for evacuate, the\nconnector should be for the original host and not\nthe new host. Patch [1] provides a fix by using\nthe connector from init_connection which is stashed\nin bdm.connection_info, but that approach cannot fix\nthis bug for volumes that were attached before that\npatch.\n\nTo allow a fix for existing attachments, add the\ninstance host in connector['instance_host']. This\nwill allow cinder drivers to be patched to check\nfor this defect and use the instance host and volume\nto provide a workaround (the rest of the bogus\ncurrent host connector is left as-is to avoid creating\nnew defects such as validation or type errors).\n\nFor example:\n\n* Using host and volume a cinder driver may be able\nto discover the initiator or wwpns that are needed, or\n\n* Using the instance host instead of the connector host,\nsome drivers may not need the other parts of the connnector, or\n\n* Detecting the mismatch would allow some drivers to\nraise an exception instead of just trying to disconnect\nthe wrong host connection which might succeed or fail or\nleave dangling connections.\n\n[1] I793f2996fc0af1c321a240ad9348dc9bce816030\n\nChange-Id: I822e31bf8a739588991fcca34976d55b71b8a227\nPartial-Bug: #1522496\n""}]",8,274318,e1d9c8200bcdb51fcc7970495c5b2a8475f2053c,133,20,10,11047,,,0,"Add instance host to evacuate terminate connector

When we only have the connector for the wrong host,
add instance host to the connector for evacuation.

When calling terminate_connection for evacuate, the
connector should be for the original host and not
the new host. Patch [1] provides a fix by using
the connector from init_connection which is stashed
in bdm.connection_info, but that approach cannot fix
this bug for volumes that were attached before that
patch.

To allow a fix for existing attachments, add the
instance host in connector['instance_host']. This
will allow cinder drivers to be patched to check
for this defect and use the instance host and volume
to provide a workaround (the rest of the bogus
current host connector is left as-is to avoid creating
new defects such as validation or type errors).

For example:

* Using host and volume a cinder driver may be able
to discover the initiator or wwpns that are needed, or

* Using the instance host instead of the connector host,
some drivers may not need the other parts of the connnector, or

* Detecting the mismatch would allow some drivers to
raise an exception instead of just trying to disconnect
the wrong host connection which might succeed or fail or
leave dangling connections.

[1] I793f2996fc0af1c321a240ad9348dc9bce816030

Change-Id: I822e31bf8a739588991fcca34976d55b71b8a227
Partial-Bug: #1522496
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/274318/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,d142f8269c3c07ba02b303f4265212370ba7df3d,bug/1522496," if not destroy_bdm and (connector.get('host') != instance.host): if connection_info and 'connector' in connection_info: connector = connection_info['connector'] else: # For attachments that existed before connector was # stashed in bdm.connection_info, we can only add # the instance_host to the local connector. # Cinder drivers can implement workarounds using this info. connector = connector.copy() connector['instance_host'] = instance.host", if connection_info and not destroy_bdm and ( connector.get('host') != instance.get('host')): connector = connection_info.get('connector') or connector,21,9
openstack%2Fhorizon~master~I5ae8cb798051a2db2b7256382d1474ef43c16208,openstack/horizon,master,I5ae8cb798051a2db2b7256382d1474ef43c16208,add a hz-required icon directive for forms,ABANDONED,2016-05-10 22:40:45.000000000,2016-05-10 22:43:04.000000000,,[],"[{'number': 1, 'created': '2016-05-10 22:40:45.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/create-keypair.html', 'horizon/static/framework/widgets/widgets.module.js', 'horizon/static/framework/widgets/form/form.module.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/details/details.html', 'horizon/static/framework/widgets/form/hz-required.directive.js', 'horizon/static/framework/widgets/form/hz-required.directive.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/containers/create-container-modal.html', 'horizon/static/framework/widgets/form/form.module.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/import-keypair.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9c6fbb29383507a3a47d059d2b99fbf5a5fbf917', 'message': 'add a hz-required icon directive for forms\n\nappends an asterisk to form label\n\nChange-Id: I5ae8cb798051a2db2b7256382d1474ef43c16208\n'}]",0,314797,9c6fbb29383507a3a47d059d2b99fbf5a5fbf917,2,0,1,9622,,,0,"add a hz-required icon directive for forms

appends an asterisk to form label

Change-Id: I5ae8cb798051a2db2b7256382d1474ef43c16208
",git fetch https://review.opendev.org/openstack/horizon refs/changes/97/314797/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/create-keypair.html', 'horizon/static/framework/widgets/widgets.module.js', 'horizon/static/framework/widgets/form/form.module.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/details/details.html', 'horizon/static/framework/widgets/form/hz-required.directive.js', 'horizon/static/framework/widgets/form/hz-required.directive.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/containers/create-container-modal.html', 'horizon/static/framework/widgets/form/form.module.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/import-keypair.html']",10,9c6fbb29383507a3a47d059d2b99fbf5a5fbf917,hzRequiredIcon," <label hz-required for=""keypair-name"" translate> <label hz-required for=""public-key"" translate>"," <label for=""keypair-name"" translate> <span class=""hz-icon-required fa fa-asterisk""></span> <label for=""public-key"" translate> <span class=""hz-icon-required fa fa-asterisk""></span>",172,22
openstack%2Fopenstack-manuals~master~Ie0e5d44d071864c487dd16dc6ae3615123327289,openstack/openstack-manuals,master,Ie0e5d44d071864c487dd16dc6ae3615123327289,[contributor] Update content of doc-tools directory,MERGED,2016-05-08 13:26:03.000000000,2016-05-10 22:41:17.000000000,2016-05-10 22:41:16.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 10497}, {'_account_id': 17207}]","[{'number': 1, 'created': '2016-05-08 13:26:03.000000000', 'files': ['doc/contributor-guide/source/doc-tools/scripts.rst', 'doc/contributor-guide/source/additional-git-workflow/backport.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4cf55cbed5d085b48cf1a0d10b0c424506fbb9e5', 'message': '[contributor] Update content of doc-tools directory\n\nChange-Id: Ie0e5d44d071864c487dd16dc6ae3615123327289\n'}]",0,313930,4cf55cbed5d085b48cf1a0d10b0c424506fbb9e5,8,4,1,16237,,,0,"[contributor] Update content of doc-tools directory

Change-Id: Ie0e5d44d071864c487dd16dc6ae3615123327289
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/30/313930/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/contributor-guide/source/additional-git-workflow/backport.rst', 'doc/contributor-guide/source/doc-tools/scripts.rst']",2,4cf55cbed5d085b48cf1a0d10b0c424506fbb9e5,newton,,openstack-generate-docbook Check translated docbook documentation builds. openstack-generate-pot Generate pot files from docbook files. ,2,8
openstack%2Fneutron~master~Ie087fb11213cc85911483c2d32c463fa9c973e54,openstack/neutron,master,Ie087fb11213cc85911483c2d32c463fa9c973e54,"Revert ""Remove threading before process forking""",MERGED,2016-05-05 21:07:21.000000000,2016-05-10 22:41:00.000000000,2016-05-06 01:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-05-05 21:07:21.000000000', 'files': ['neutron/worker.py', 'neutron/db/agentschedulers_db.py', 'neutron/tests/unit/db/test_agentschedulers_db.py', 'neutron/server/rpc_eventlet.py', 'neutron/services/metering/metering_plugin.py', 'neutron/tests/base.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/functional/test_server.py', 'neutron/server/wsgi_eventlet.py', 'neutron/wsgi.py', 'neutron/service.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/services/service_base.py', 'neutron/neutron_plugin_base_v2.py', 'neutron/db/l3_agentschedulers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1cdba1696f5d4ec71d37a773501bd4f9e0cddb9', 'message': 'Revert ""Remove threading before process forking""\n\nI think this needs a little more thought.  This broke OVN at least and\nI don\'t think that\'s good.  We need to figure out how to be compatible \nwith existing plugins, even out of tree ones.\n\nThis reverts commit 1cafff087194711399ad2a85a9f394f7204d7bdd.\n\nChange-Id: Ie087fb11213cc85911483c2d32c463fa9c973e54\n'}]",0,313159,b1cdba1696f5d4ec71d37a773501bd4f9e0cddb9,15,8,1,7448,,,0,"Revert ""Remove threading before process forking""

I think this needs a little more thought.  This broke OVN at least and
I don't think that's good.  We need to figure out how to be compatible 
with existing plugins, even out of tree ones.

This reverts commit 1cafff087194711399ad2a85a9f394f7204d7bdd.

Change-Id: Ie087fb11213cc85911483c2d32c463fa9c973e54
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/313159/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/worker.py', 'neutron/db/agentschedulers_db.py', 'neutron/tests/unit/db/test_agentschedulers_db.py', 'neutron/server/rpc_eventlet.py', 'neutron/services/metering/metering_plugin.py', 'neutron/tests/base.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/functional/test_server.py', 'neutron/server/wsgi_eventlet.py', 'neutron/wsgi.py', 'neutron/service.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/services/service_base.py', 'neutron/neutron_plugin_base_v2.py', 'neutron/db/l3_agentschedulers_db.py']",15,b1cdba1696f5d4ec71d37a773501bd4f9e0cddb9,threading_before_forking,," LOG.warning( _LW(""DEPRECATED method 'start_periodic_l3_agent_status_check'. "" ""Please use 'add_periodic_l3_agent_status_check' instead"") ) self.add_periodic_l3_agent_status_check() def add_periodic_l3_agent_status_check(self):",96,260
openstack%2Fkeystone~master~I33ccac0154841df60b43ad5b41a022a31d512a42,openstack/keystone,master,I33ccac0154841df60b43ad5b41a022a31d512a42,Create notification when invalid user name provided,ABANDONED,2016-02-17 00:47:23.000000000,2016-05-10 22:32:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 12980}, {'_account_id': 20066}]","[{'number': 1, 'created': '2016-02-17 00:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/360cd02f3b5a7cf694962463718700a43636cba6', 'message': 'Create notification when invalid user name provided\n\nWith notification is enabled, a notification was not created,\nif the provided user name is invalid for ""identity.authenticate""\nevent. This fix is to create a notification with ""outcome"":\n""failure"" under such condition.\n\nChange-Id: I33ccac0154841df60b43ad5b41a022a31d512a42\nCloses-Bug: 1537963\n'}, {'number': 2, 'created': '2016-02-17 00:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/594189502f8e2b6319a29000287e65423519d3ef', 'message': 'Create notification when invalid user name provided\n\nWith notification enabled, a notification was not created\nif the provided user name was invalid for ""identity.authenticate""\nevent. This fix is to create a notification with ""outcome"":\n""failure"" under such condition.\n\nChange-Id: I33ccac0154841df60b43ad5b41a022a31d512a42\nCloses-Bug: 1537963\n'}, {'number': 3, 'created': '2016-02-17 00:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a01814bf20e288a5297888297d674feb411459cd', 'message': 'Create notification when invalid user name provided\n\nWith notification enabled, a notification was not created\nif the provided user name was invalid for ""identity.authenticate""\nevent. This fix is to create a notification with ""outcome"":\n""failure"" under such condition.\n\nChange-Id: I33ccac0154841df60b43ad5b41a022a31d512a42\nCloses-Bug: 1537963\n'}, {'number': 4, 'created': '2016-02-17 00:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fce8fcaa56dda922cf263f1e9cab57af4978c27b', 'message': 'Create notification when invalid user name provided\n\nWith notification enabled, a notification was not created\nif the provided user name was invalid for ""identity.authenticate""\nevent. This fix is to create a notification with ""outcome"":\n""failure"" under such condition.\n\nChange-Id: I33ccac0154841df60b43ad5b41a022a31d512a42\nCloses-Bug: 1537963\n'}, {'number': 5, 'created': '2016-02-18 09:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/970d80b76f94448af560b7899a761511d5946f1d', 'message': 'Create notification when invalid user name provided\n\nWith notification enabled, a notification was not created\nif the provided user name was invalid for ""identity.authenticate""\nevent. This fix is to create a notification with ""outcome"":\n""failure"" under such condition.\n\nChange-Id: I33ccac0154841df60b43ad5b41a022a31d512a42\nCloses-Bug: 1537963\n'}, {'number': 6, 'created': '2016-02-22 23:25:34.000000000', 'files': ['keystone/token/controllers.py', 'keystone/identity/core.py', 'keystone/auth/plugins/external.py', 'keystone/auth/plugins/core.py', 'keystone/auth/plugins/mapped.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/tests/unit/test_auth.py', 'keystone/auth/plugins/password.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0e4e5656535d73973230719adb0e5aebc49e52c5', 'message': 'Create notification when invalid user name provided\n\nWith notification enabled, a notification was not created\nif the provided user name was invalid for ""identity.authenticate""\nevent. This fix is to create a notification with ""outcome"":\n""failure"" under such condition.\n\nChange-Id: I33ccac0154841df60b43ad5b41a022a31d512a42\nCloses-Bug: 1537963\n'}]",2,280994,0e4e5656535d73973230719adb0e5aebc49e52c5,22,7,6,12980,,,0,"Create notification when invalid user name provided

With notification enabled, a notification was not created
if the provided user name was invalid for ""identity.authenticate""
event. This fix is to create a notification with ""outcome"":
""failure"" under such condition.

Change-Id: I33ccac0154841df60b43ad5b41a022a31d512a42
Closes-Bug: 1537963
",git fetch https://review.opendev.org/openstack/keystone refs/changes/94/280994/6 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/plugins/core.py', 'keystone/auth/plugins/mapped.py', 'keystone/auth/plugins/password.py']",3,360cd02f3b5a7cf694962463718700a43636cba6,bug/1537963," # authentication failed because of invalid password except Exception: if user_info.user_id is None: print('################################300-1', user_info.user_id) # authentication failed because of invalid username or user id msg = _('Invalid username or password') raise exception.Unauthorized(msg) else: raise", # authentication failed because of invalid username or password,14,2
openstack%2Fnetworking-ovn~master~I45e7cba9cf0f132346bde56365dd5afb91e65601,openstack/networking-ovn,master,I45e7cba9cf0f132346bde56365dd5afb91e65601,Remove attributes deprecated warnings,MERGED,2016-05-10 01:27:09.000000000,2016-05-10 22:30:27.000000000,2016-05-10 22:30:26.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 8410}, {'_account_id': 14926}]","[{'number': 1, 'created': '2016-05-10 01:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b5813f2add54fa2f17a298463f80c4e53638a900', 'message': ""Remove attributes deprecated warnings\n\nAddressed the following warnings:\n\n    networking_ovn/plugin.py:247: DeprecationWarning: ATTR_NOT_SPECIFIED in version\n    'mitaka' and will be removed in version 'newton': moved to neutron_lib.constants\n\nAnd\n    networking_ovn/plugin.py:714: DeprecationWarning: Function\n    'neutron.api.v2.attributes.is_attr_set()' has moved to\n    'neutron_lib.api.validators.is_attr_set()' in version 'mitaka' and will be removed\n    in version 'ocata': moved to neutron_lib\n\nTrivialFix\n\nChange-Id: I45e7cba9cf0f132346bde56365dd5afb91e65601\n""}, {'number': 2, 'created': '2016-05-10 01:36:09.000000000', 'files': ['networking_ovn/ovn_nb_sync.py', 'networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/447c6e3944a22caaeb8c6dbb4a241eebb2fd9fe9', 'message': ""Remove attributes deprecated warnings\n\nAddressed the following warnings:\n\n    networking_ovn/plugin.py:247: DeprecationWarning: ATTR_NOT_SPECIFIED in version\n    'mitaka' and will be removed in version 'newton': moved to neutron_lib.constants\n\nAnd\n    networking_ovn/plugin.py:714: DeprecationWarning: Function\n    'neutron.api.v2.attributes.is_attr_set()' has moved to\n    'neutron_lib.api.validators.is_attr_set()' in version 'mitaka' and will be removed\n    in version 'ocata': moved to neutron_lib\n\nTrivialFix\n\nChange-Id: I45e7cba9cf0f132346bde56365dd5afb91e65601\n""}]",0,314391,447c6e3944a22caaeb8c6dbb4a241eebb2fd9fe9,23,4,2,1653,,,0,"Remove attributes deprecated warnings

Addressed the following warnings:

    networking_ovn/plugin.py:247: DeprecationWarning: ATTR_NOT_SPECIFIED in version
    'mitaka' and will be removed in version 'newton': moved to neutron_lib.constants

And
    networking_ovn/plugin.py:714: DeprecationWarning: Function
    'neutron.api.v2.attributes.is_attr_set()' has moved to
    'neutron_lib.api.validators.is_attr_set()' in version 'mitaka' and will be removed
    in version 'ocata': moved to neutron_lib

TrivialFix

Change-Id: I45e7cba9cf0f132346bde56365dd5afb91e65601
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/91/314391/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/ovn_nb_sync.py', 'networking_ovn/plugin.py']",2,b5813f2add54fa2f17a298463f80c4e53638a900,attributes,from neutron_lib.api import validators if res is const.ATTR_NOT_SPECIFIED: not validators.is_attr_set( validators.is_attr_set( if validators.is_attr_set(port.get(psec.PORTSECURITY)):, if res is attr.ATTR_NOT_SPECIFIED: not attr.is_attr_set( attr.is_attr_set( if attr.is_attr_set(port.get(psec.PORTSECURITY)):,7,6
openstack%2Fopenstack-manuals~master~I611141bd7992d3b4750d1d634ac60600d4677674,openstack/openstack-manuals,master,I611141bd7992d3b4750d1d634ac60600d4677674,Removes deprecated keystone CLI,MERGED,2016-05-09 01:15:29.000000000,2016-05-10 22:26:32.000000000,2016-05-10 22:26:32.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6482}, {'_account_id': 10497}, {'_account_id': 17207}]","[{'number': 1, 'created': '2016-05-09 01:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4071e63b35ed6d9af1f9b720c2f49bf17a6ea067', 'message': 'Removes deprecated keystone CLI\n\nChange-Id: I611141bd7992d3b4750d1d634ac60600d4677674\nCloses-Bug: #1578937\n'}, {'number': 2, 'created': '2016-05-09 03:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/929bb29f6ccc750ad0cf25cfa272482ff60c421d', 'message': 'Removes deprecated keystone CLI\n\nChange-Id: I611141bd7992d3b4750d1d634ac60600d4677674\nCloses-Bug: #1578937\n'}, {'number': 3, 'created': '2016-05-09 14:54:44.000000000', 'files': ['doc/cli-reference/source/index.rst', 'doc/admin-guide/source/identity_keystone_usage_and_features.rst', 'doc/cli-reference/source/keystone.rst', 'doc/user-guide/source/cli_cheat_sheet.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/983a41d9e799da9a27320181e1abebcaef34321c', 'message': 'Removes deprecated keystone CLI\n\nChange-Id: I611141bd7992d3b4750d1d634ac60600d4677674\nPartial-Bug: #1578937\n'}]",9,313952,983a41d9e799da9a27320181e1abebcaef34321c,19,5,3,16237,,,0,"Removes deprecated keystone CLI

Change-Id: I611141bd7992d3b4750d1d634ac60600d4677674
Partial-Bug: #1578937
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/52/313952/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/cli-reference/source/index.rst', 'doc/admin-guide/source/identity_keystone_usage_and_features.rst', 'doc/cli-reference/source/keystone.rst', 'doc/user-guide/source/cli_cheat_sheet.rst']",4,4071e63b35ed6d9af1f9b720c2f49bf17a6ea067,bug/1578937, $ openstack user-list $ openstack catalog list, $ keystone user-list $ keystone catalog,7,933
openstack%2Fopenstack-manuals~stable%2Fmitaka~I46f246381a0019bae78975c3d77d22f2f618948f,openstack/openstack-manuals,stable/mitaka,I46f246381a0019bae78975c3d77d22f2f618948f,[install] Added note to ignore any deprecation messages,MERGED,2016-05-10 14:46:04.000000000,2016-05-10 22:21:10.000000000,2016-05-10 22:21:09.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 10497}, {'_account_id': 21204}]","[{'number': 1, 'created': '2016-05-10 14:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6f9f9707f9780e6ab0e9924aba6561de794bfe2e', 'message': '[install] Added note to ignore any deprecation messages\n\nCloses-Bug: #1575610\nBackport: Mitaka\n\nChange-Id: I46f246381a0019bae78975c3d77d22f2f618948f\n'}, {'number': 2, 'created': '2016-05-10 14:46:35.000000000', 'files': ['doc/install-guide/source/trove-install.rst', 'doc/install-guide/source/keystone-install.rst', 'doc/install-guide/source/nova-controller-install.rst', 'doc/install-guide/source/heat-install.rst', 'doc/install-guide/source/cinder-controller-install.rst', 'doc/install-guide/source/manila-controller-install.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b082520e490669890a6b277c0114a0e9dd37ce6', 'message': '[install] Added note to ignore any deprecation messages\n\nCloses-Bug: #1575610\n\nChange-Id: I46f246381a0019bae78975c3d77d22f2f618948f\n'}]",1,314607,9b082520e490669890a6b277c0114a0e9dd37ce6,9,4,2,16237,,,0,"[install] Added note to ignore any deprecation messages

Closes-Bug: #1575610

Change-Id: I46f246381a0019bae78975c3d77d22f2f618948f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/314607/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/trove-install.rst', 'doc/install-guide/source/keystone-install.rst', 'doc/install-guide/source/nova-controller-install.rst', 'doc/install-guide/source/heat-install.rst', 'doc/install-guide/source/cinder-controller-install.rst', 'doc/install-guide/source/manila-controller-install.rst']",6,6f9f9707f9780e6ab0e9924aba6561de794bfe2e,bug/1575610, .. note:: Ignore any deprecation messages in this output. ,,24,0
openstack%2Fapi-site~master~Ia894c614491c3d6452a2c29310e45e94d78d523b,openstack/api-site,master,Ia894c614491c3d6452a2c29310e45e94d78d523b,Updated from openstack-manuals,MERGED,2016-05-10 20:22:36.000000000,2016-05-10 22:18:56.000000000,2016-05-10 22:18:56.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-10 20:22:36.000000000', 'files': ['common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/847f32c3bb363d78e2ba7c1d2a61a092976c2d38', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ia894c614491c3d6452a2c29310e45e94d78d523b\n'}]",0,314752,847f32c3bb363d78e2ba7c1d2a61a092976c2d38,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ia894c614491c3d6452a2c29310e45e94d78d523b
",git fetch https://review.opendev.org/openstack/api-site refs/changes/52/314752/1 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,847f32c3bb363d78e2ba7c1d2a61a092976c2d38,openstack/openstack-manuals,"To add to OpenStack glossary, clone the `openstack/openstack-manuals repository <https://git.openstack.org/cgit/openstack/openstack-manuals>`__ and update the source file ``doc/common/glossary.rst`` through the",".. comments This file is automatically generated, edit the master doc/glossary/glossary-terms.xml to update it. To add to OpenStack glossary, clone the `openstack/openstack-manuals repository <https://git.openstack.org/cgit/openstack/openstack-manuals>`__ and update the source file ``doc/glossary/glossary-terms.xml`` through the",4,5
openstack%2Finstallguide-cookiecutter~master~Icc1c187fcfa8f3b29af22de2d326a46035a4e542,openstack/installguide-cookiecutter,master,Icc1c187fcfa8f3b29af22de2d326a46035a4e542,Initial setup for cookiecutter,MERGED,2016-05-09 18:46:17.000000000,2016-05-10 22:14:46.000000000,2016-05-10 22:14:46.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-09 18:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/installguide-cookiecutter/commit/477237d1d06c4ebb6e12db029d02671db4334f50', 'message': 'Initial setup for cookiecutter\n\nAdd first files and README for a minimal working skeleton.\n\nChange-Id: Icc1c187fcfa8f3b29af22de2d326a46035a4e542\n'}, {'number': 2, 'created': '2016-05-09 18:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/installguide-cookiecutter/commit/15cd8bda579834cadbc5eba4a3295e6a4029715d', 'message': 'Initial setup for cookiecutter\n\nAdd first files and README for a minimal working skeleton.\n\nChange-Id: Icc1c187fcfa8f3b29af22de2d326a46035a4e542\n'}, {'number': 3, 'created': '2016-05-09 19:20:49.000000000', 'files': ['{{cookiecutter.repo_name}}/install-guide/source/index.rst', '{{cookiecutter.repo_name}}/install-guide/source/next-steps.rst', '{{cookiecutter.repo_name}}/install-guide/source/conf.py', 'README.rst', '{{cookiecutter.repo_name}}/install-guide/source/get_started.rst', '{{cookiecutter.repo_name}}/install-guide/source/verify.rst', 'cookiecutter.json', '{{cookiecutter.repo_name}}/install-guide/source/install.rst'], 'web_link': 'https://opendev.org/openstack/installguide-cookiecutter/commit/f445fa8993bb067aeb1fab52a78188ac3655c8fb', 'message': 'Initial setup for cookiecutter\n\nAdd first files and README for a minimal working skeleton.\n\nChange-Id: Icc1c187fcfa8f3b29af22de2d326a46035a4e542\n'}]",0,314229,f445fa8993bb067aeb1fab52a78188ac3655c8fb,11,4,3,6547,,,0,"Initial setup for cookiecutter

Add first files and README for a minimal working skeleton.

Change-Id: Icc1c187fcfa8f3b29af22de2d326a46035a4e542
",git fetch https://review.opendev.org/openstack/installguide-cookiecutter refs/changes/29/314229/3 && git format-patch -1 --stdout FETCH_HEAD,"['{{cookiecutter.repo_name}}/install-guide/source/index.rst', '{{cookiecutter.repo_name}}/install-guide/source/next-steps.rst', '{{cookiecutter.repo_name}}/install-guide/source/conf.py', 'README.rst', '{{cookiecutter.repo_name}}/install-guide/source/get_started.rst', '{{cookiecutter.repo_name}}/install-guide/source/verify.rst', 'cookiecutter.json', '{{cookiecutter.repo_name}}/install-guide/source/install.rst']",8,477237d1d06c4ebb6e12db029d02671db4334f50,base-setup,".. _install: Install and configure ~~~~~~~~~~~~~~~~~~~~~ This section describes how to install and configure the {{service}} service, code-named {{codename}}, on the controller node. This section assumes that you already have a working OpenStack environment with at least the following components installed: Compute, Image Service, Identity. Prerequisites ------------- Before you install and configure the {{service}} service, you must create a database, service credentials, and API endpoints. #. To create the database, complete these steps: * Use the database access client to connect to the database server as the ``root`` user: .. code-block:: console $ mysql -u root -p * Create the ``{{codename}}`` database: .. code-block:: console CREATE DATABASE {{codename}}; * Grant proper access to the ``{{codename}}`` database: .. code-block:: console GRANT ALL PRIVILEGES ON {{codename}}.* TO '{{codename}}'@'localhost' \ IDENTIFIED BY '{{codename|upper}}_DBPASS'; GRANT ALL PRIVILEGES ON {{codename}}.* TO '{{codename}}'@'%' \ IDENTIFIED BY '{{codename|upper}}_DBPASS'; Replace ``{{codename|upper}}_DBPASS`` with a suitable password. * Exit the database access client. #. Source the ``admin`` credentials to gain access to admin-only CLI commands: .. code-block:: console $ source admin-openrc.sh #. To create the service credentials, complete these steps: * Create the ``{{codename}}`` user: .. code-block:: console $ openstack user create --domain default --password-prompt {{codename}} Install and configure components -------------------------------- Finalize installation --------------------- ",,432,0
openstack%2Fsearchlight-ui~master~I4124fe2e510d82d674b1810294929642354faa03,openstack/searchlight-ui,master,I4124fe2e510d82d674b1810294929642354faa03,Add graceful handling for missing registry actions,MERGED,2016-05-06 23:31:07.000000000,2016-05-10 22:05:42.000000000,2016-05-10 22:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 9576}, {'_account_id': 10063}, {'_account_id': 14124}]","[{'number': 1, 'created': '2016-05-06 23:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/5cfc3e9b5ec0efba462977ee7b9bc4b11c8cdc89', 'message': ""Add graceful handling for missing registry actions\n\nThe action registry threw an error when OS::Nova::Hypervisor\nwasn't found. This may get fixed in horizon, but we should\ndo a little protective coding here so that the UI handles\nthis without completely barfing.\n\nThere may need to be follow up patches to more gracefully handle\nother registry usages.\n\nChange-Id: I4124fe2e510d82d674b1810294929642354faa03\nPartial-Bug: 1579262\n""}, {'number': 2, 'created': '2016-05-06 23:34:45.000000000', 'files': ['searchlight_ui/static/dashboard/project/search/table/search-table.controller.js'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/3899031b679876362d9e453db51687f21d572cbf', 'message': ""Add graceful handling for missing registry actions\n\nThe action registry threw an error when OS::Nova::Hypervisor [0]\nwasn't found. This may get fixed in horizon, but we should\ndo a little protective coding here so that the UI handles\nthis without completely barfing.\n\nThere may need to be follow up patches to more gracefully handle\nother registry usages.\n\n[0] https://review.openstack.org/#/c/297586/7\n\nChange-Id: I4124fe2e510d82d674b1810294929642354faa03\nPartial-Bug: 1579262\n""}]",0,313798,3899031b679876362d9e453db51687f21d572cbf,8,5,2,7665,,,0,"Add graceful handling for missing registry actions

The action registry threw an error when OS::Nova::Hypervisor [0]
wasn't found. This may get fixed in horizon, but we should
do a little protective coding here so that the UI handles
this without completely barfing.

There may need to be follow up patches to more gracefully handle
other registry usages.

[0] https://review.openstack.org/#/c/297586/7

Change-Id: I4124fe2e510d82d674b1810294929642354faa03
Partial-Bug: 1579262
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/98/313798/1 && git format-patch -1 --stdout FETCH_HEAD,['searchlight_ui/static/dashboard/project/search/table/search-table.controller.js'],1,5cfc3e9b5ec0efba462977ee7b9bc4b11c8cdc89,bug/1579262," '$log', $log, try { registry.initActions(type, $scope); } catch (err) { var errorMsg = gettext('Error initializing actions for plugin %(type)s: '); $log.error(interpolate(errorMsg, { type: type }, true) + err); }"," registry.initActions(type, $scope);",8,1
openstack%2Fneutron~master~I2b2cce37d9b0d40559a715a7d510a969b8ba9963,openstack/neutron,master,I2b2cce37d9b0d40559a715a7d510a969b8ba9963,Classes lack metaclass decoration,MERGED,2016-05-03 04:53:42.000000000,2016-05-10 21:44:23.000000000,2016-05-06 00:31:19.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7037}, {'_account_id': 7787}, {'_account_id': 8726}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 12906}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-05-03 04:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6a234aac769aa7e6d42ff5f82a9c59ee3e29478', 'message': 'Classes lack metaclass decoration\n\nAdd decorations where required.\n\nChange-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963\nCloses-Bug: #1577648\n'}, {'number': 2, 'created': '2016-05-03 04:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b350df8453c13b97b4ef65888c1d0ae78d6f75f5', 'message': 'Classes lack metaclass decoration\n\nAdd decorations where required.\n\nChange-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963\nCloses-Bug: #1577648\n'}, {'number': 3, 'created': '2016-05-03 05:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a3c915e56d2150c826c652d0470822d2f599a1b', 'message': 'Classes lack metaclass decoration\n\nAdd decorations where required.\n\nChange-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963\nCloses-Bug: #1577648\n'}, {'number': 4, 'created': '2016-05-03 05:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b4fcc7dc3f74201424c185f33b82ba7a3617da7', 'message': 'Classes lack metaclass decoration\n\nAdd decorations where required.\n\nChange-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963\nCloses-Bug: #1577648\n'}, {'number': 5, 'created': '2016-05-05 19:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2a5a6418aa872272db2ff051ea1fc3820a45ba1', 'message': ""Classes lack metaclass decoration\n\nAdd decorations where required.\n\nThere are roughly a dozen classes in Neutron that define abstract methods or\nproperties but are not decorated with @six.add_metaclass(abc.ABCMeta).\nWithout this decoration, children can be created without defining the required\nmethods or properties.\n\nDecorating RBACColumns in db/rbac_db_models.py causes failures and will be\nreported separately.\n\nDecorating unit tests is of dubious benifit and should be addressed\nseparately (if at all).\n\nThere are also several more places where metaclassing isn't correct, to be\ntaken care of in follow-on patches.\n\nFor example, BaseScheduler is using the fact the None doesn't have a\nfilter_agents() method, which gives developers confusing error messages\nwhen they incorrectly implement the interface, and they won't see any error\nuntil schedule() is called. As an aside, the docstring for this base class is\nalso incorrect.\n\nChange-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963\nCloses-Bug: #1577648\n""}, {'number': 6, 'created': '2016-05-05 19:34:33.000000000', 'files': ['neutron/extensions/l3.py', 'neutron/tests/unit/extensions/foxinsocks.py', 'neutron/extensions/dhcpagentscheduler.py', 'neutron/scheduler/base_scheduler.py', 'neutron/extensions/agent.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/agent/linux/dhcp.py', 'neutron/extensions/l3agentscheduler.py', 'neutron/scheduler/base_resource_filter.py', 'neutron/plugins/ml2/drivers/l2pop/rpc_manager/l2population_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/972cdef50cd32837b8328466e4d821bb36535130', 'message': ""Classes lack metaclass decoration\n\nAdd decorations where required.\n\nThere are roughly a dozen classes in Neutron that define abstract\nmethods or properties but are not decorated with\n@six.add_metaclass(abc.ABCMeta). Without this decoration, children\ncan be created without defining the required methods or properties.\n\nDecorating RBACColumns in db/rbac_db_models.py causes failures and will\nbe reported separately.\n\nDecorating unit tests is of dubious benifit and should be addressed\nseparately (if at all).\n\nThere are also several more places where metaclassing isn't correct, to\nbe taken care of in follow-on patches.\n\nFor example, BaseScheduler is using the fact the None doesn't have a\nfilter_agents() method, which gives developers confusing error messages\nwhen they incorrectly implement the interface, and they won't see any\nerror until schedule() is called. As an aside, the docstring for this\nbase class is also incorrect.\n\nChange-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963\nCloses-Bug: #1577648\n""}]",2,311930,972cdef50cd32837b8328466e4d821bb36535130,62,18,6,7037,,,0,"Classes lack metaclass decoration

Add decorations where required.

There are roughly a dozen classes in Neutron that define abstract
methods or properties but are not decorated with
@six.add_metaclass(abc.ABCMeta). Without this decoration, children
can be created without defining the required methods or properties.

Decorating RBACColumns in db/rbac_db_models.py causes failures and will
be reported separately.

Decorating unit tests is of dubious benifit and should be addressed
separately (if at all).

There are also several more places where metaclassing isn't correct, to
be taken care of in follow-on patches.

For example, BaseScheduler is using the fact the None doesn't have a
filter_agents() method, which gives developers confusing error messages
when they incorrectly implement the interface, and they won't see any
error until schedule() is called. As an aside, the docstring for this
base class is also incorrect.

Change-Id: I2b2cce37d9b0d40559a715a7d510a969b8ba9963
Closes-Bug: #1577648
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/311930/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/l3.py', 'neutron/extensions/dhcpagentscheduler.py', 'neutron/tests/unit/extensions/foxinsocks.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/extensions/agent.py', 'neutron/scheduler/base_scheduler.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/agent/linux/dhcp.py', 'neutron/extensions/l3agentscheduler.py', 'neutron/scheduler/base_resource_filter.py', 'neutron/plugins/ml2/drivers/l2pop/rpc_manager/l2population_rpc.py']",11,c6a234aac769aa7e6d42ff5f82a9c59ee3e29478,bug/1577648,@six.add_metaclass(abc.ABCMeta),,21,1
openstack%2Fdevstack~master~I9781010d6eb336d02939c7fd47f18bedeae5ccc6,openstack/devstack,master,I9781010d6eb336d02939c7fd47f18bedeae5ccc6,Export the 'short_source' function & don't keep PS4 in sudo,MERGED,2016-05-05 19:52:17.000000000,2016-05-10 21:42:54.000000000,2016-05-10 21:42:54.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5805}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12459}, {'_account_id': 14760}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-05-05 19:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2b1d7d2597f2becba3198d48d66abfb30be07a98', 'message': ""Export the 'short_source' function\n\nExport the 'short_source' function so that it will be present in the\nenvironment for child shell scripts. Do this because we are passing PS4\nto the child shell scripts and it is using 'short_source'\n\nChange-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6\n""}, {'number': 2, 'created': '2016-05-05 23:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/621e5e5e13fa739ad992c5872a2d8062ae2bbd37', 'message': ""Export the 'short_source' function\n\nExport the 'short_source' function so that it will be present in the\nenvironment for child shell scripts. Do this because we are passing PS4\nto the child shell scripts and it is using 'short_source'\n\nChange-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6\n""}, {'number': 3, 'created': '2016-05-06 00:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3986649fbc4f41584bbdd3114ca44049bdf08b4e', 'message': ""Export the 'short_source' function\n\nExport the 'short_source' function so that it will be present in the\nenvironment for child shell scripts. Do this because we are passing PS4\nto the child shell scripts and it is using 'short_source'\n\nChange-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6\nCloses-Bug: #563443\n""}, {'number': 4, 'created': '2016-05-06 00:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/77724b8fb69a95dd7390d908b8dbce9c640c548b', 'message': ""Export the 'short_source' function\n\nExport the 'short_source' function so that it will be present in the\nenvironment for child shell scripts. Do this because we are passing PS4\nto the child shell scripts and it is using 'short_source'\n\nChange-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6\nCloses-Bug: #1563443\n""}, {'number': 5, 'created': '2016-05-06 16:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f77daf689dafd645ce0d4c2b2f25535ab921e148', 'message': ""Export the 'short_source' function\n\nExport the 'short_source' function so that it will be present in the\nenvironment for child shell scripts. Do this because we are passing PS4\nto the child shell scripts and it is using 'short_source'\n\nAlso setup the sudoer file so that the function gets preserved when\ndoing a sudo.\n\nChange-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6\nCloses-Bug: #1563443\n""}, {'number': 6, 'created': '2016-05-06 17:52:22.000000000', 'files': ['functions', 'tools/create_userrc.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/daa7a41e219f435006f412e4ff45d93cf4c4827d', 'message': ""Export the 'short_source' function & don't keep PS4 in sudo\n\nExport the 'short_source' function so that it will be present in the\nenvironment for child shell scripts. Do this because we are passing PS4\nto the child shell scripts and it is using 'short_source'\n\nDon't do an 'env_keep' in the sudoers file for PS4, since it is\ndifficult to also pass along the 'short_source' function.\n\nChange-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6\nCloses-Bug: #1563443\n""}]",0,313132,daa7a41e219f435006f412e4ff45d93cf4c4827d,48,10,6,14760,,,0,"Export the 'short_source' function & don't keep PS4 in sudo

Export the 'short_source' function so that it will be present in the
environment for child shell scripts. Do this because we are passing PS4
to the child shell scripts and it is using 'short_source'

Don't do an 'env_keep' in the sudoers file for PS4, since it is
difficult to also pass along the 'short_source' function.

Change-Id: I9781010d6eb336d02939c7fd47f18bedeae5ccc6
Closes-Bug: #1563443
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/313132/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,2b1d7d2597f2becba3198d48d66abfb30be07a98,,export -f short_source,,1,0
openstack%2Fhorizon~master~Ifba7a19da669288cb19cfc8055bdfa7b94f00292,openstack/horizon,master,Ifba7a19da669288cb19cfc8055bdfa7b94f00292,Upgraded eslint-config-openstack to 1.2.4,MERGED,2016-02-24 15:59:32.000000000,2016-05-10 21:42:37.000000000,2016-05-10 21:42:37.000000000,"[{'_account_id': 3}, {'_account_id': 9622}, {'_account_id': 12281}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-02-24 15:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3f00f208e211f807d6916b920009a8825c228a02', 'message': 'Upgraded eslint-config-openstack to 1.2.4\n\nThis patch upgrades eslint to version 1.2.4, incorporating new rule\nchanges on no-undefined, brace-style, quote-props, space-in-parens,\nno-use-before-define, no-uneeded-ternary, and quote.\n\nFor now, rules that have been activated that cause checks to fail\nhave been switched to warning-only. Additionally, rules that\nhave been entirely disabled have been removed.\n\nChange-Id: Ifba7a19da669288cb19cfc8055bdfa7b94f00292\n'}, {'number': 2, 'created': '2016-02-25 13:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8d93861cb47f1120036695407ec5b1521cc6ae57', 'message': 'Upgraded eslint-config-openstack to 1.2.4\n\nThis patch upgrades eslint to version 1.2.4, incorporating new rule\nchanges on no-undefined, brace-style, quote-props, space-in-parens,\nno-use-before-define, no-uneeded-ternary, and quote.\n\nFor now, rules that have been activated that cause checks to fail\nhave been switched to warning-only. Additionally, rules that\nhave been entirely disabled have been removed.\n\nChange-Id: Ifba7a19da669288cb19cfc8055bdfa7b94f00292\n'}, {'number': 3, 'created': '2016-03-29 10:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0ac1fd96738f0f474364af6c05e5c646f187418b', 'message': 'Upgraded eslint-config-openstack to 1.2.4\n\nThis patch upgrades eslint to version 1.2.4, incorporating new rule\nchanges on no-undefined, brace-style, quote-props, space-in-parens,\nno-use-before-define, no-uneeded-ternary, and quote.\n\nFor now, rules that have been activated that cause checks to fail\nhave been switched to warning-only. Additionally, rules that\nhave been entirely disabled have been removed.\n\nChange-Id: Ifba7a19da669288cb19cfc8055bdfa7b94f00292\n'}, {'number': 4, 'created': '2016-04-13 12:14:53.000000000', 'files': ['.eslintrc', 'package.json'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a4d58e7101cb7ccded2d8cd233d051b48a45ee5c', 'message': 'Upgraded eslint-config-openstack to 1.2.4\n\nThis patch upgrades eslint to version 1.2.4, incorporating new rule\nchanges on no-undefined, brace-style, quote-props, space-in-parens,\nno-use-before-define, no-uneeded-ternary, and quote.\n\nFor now, rules that have been activated that cause checks to fail\nhave been switched to warning-only. Additionally, rules that\nhave been entirely disabled have been removed.\n\nChange-Id: Ifba7a19da669288cb19cfc8055bdfa7b94f00292\n'}]",1,284211,a4d58e7101cb7ccded2d8cd233d051b48a45ee5c,23,4,4,9717,,,0,"Upgraded eslint-config-openstack to 1.2.4

This patch upgrades eslint to version 1.2.4, incorporating new rule
changes on no-undefined, brace-style, quote-props, space-in-parens,
no-use-before-define, no-uneeded-ternary, and quote.

For now, rules that have been activated that cause checks to fail
have been switched to warning-only. Additionally, rules that
have been entirely disabled have been removed.

Change-Id: Ifba7a19da669288cb19cfc8055bdfa7b94f00292
",git fetch https://review.opendev.org/openstack/horizon refs/changes/11/284211/1 && git format-patch -1 --stdout FETCH_HEAD,"['.eslintrc', 'package.json']",2,3f00f208e211f807d6916b920009a8825c228a02,eslint," ""eslint-config-openstack"": ""1.2.4"","," ""eslint-config-openstack"": ""1.2.3"",",5,2
