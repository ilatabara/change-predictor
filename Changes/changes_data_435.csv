id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ftripleo-ui~master~If2a977be0ba1e5d943c627b06a4510b8c990fd49,openstack/tripleo-ui,master,If2a977be0ba1e5d943c627b06a4510b8c990fd49,Use execution_id in Zaqar messages handler,MERGED,2019-01-07 16:16:45.000000000,2019-01-08 15:24:49.000000000,2019-01-08 15:24:49.000000000,"[{'_account_id': 10112}, {'_account_id': 17888}, {'_account_id': 20970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 16:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/78f8ee231785f121c626095dc56131ffd742cd1a', 'message': ""Use execution_id in Zaqar messages handler\n\n'execution' is deprecated in Zaqar messages payload. UI codebase is\nready to work with execution_id instead as it re-fetches execution\nafter message is received. This change updates ZaqarActions to\nwork with execution_id rather than access the id from ecxecution\nobject.\n\nChange-Id: If2a977be0ba1e5d943c627b06a4510b8c990fd49\n""}, {'number': 2, 'created': '2019-01-08 07:59:53.000000000', 'files': ['src/js/actions/ZaqarActions.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/dbbfde4d9b01e8bf83fd968000106cab7815e3a6', 'message': ""Use execution_id in Zaqar messages handler\n\n'execution' is deprecated in Zaqar messages payload. UI codebase is\nready to work with execution_id instead as it re-fetches execution\nafter message is received. This change updates ZaqarActions to\nwork with execution_id rather than access the id from execution\nobject.\n\nChange-Id: If2a977be0ba1e5d943c627b06a4510b8c990fd49\n""}]",0,629007,dbbfde4d9b01e8bf83fd968000106cab7815e3a6,11,4,2,7509,,,0,"Use execution_id in Zaqar messages handler

'execution' is deprecated in Zaqar messages payload. UI codebase is
ready to work with execution_id instead as it re-fetches execution
after message is received. This change updates ZaqarActions to
work with execution_id rather than access the id from execution
object.

Change-Id: If2a977be0ba1e5d943c627b06a4510b8c990fd49
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/07/629007/1 && git format-patch -1 --stdout FETCH_HEAD,['src/js/actions/ZaqarActions.js'],1,78f8ee231785f121c626095dc56131ffd742cd1a,executionIdZaqarActions," handleWorkflowMessage(payload.execution_id, nodesRegistrationFinished) handleWorkflowMessage(payload.execution_id, undefined, pollTimeout) payload.execution_id, payload.execution_id, handleWorkflowMessage(payload.execution_id, downloadLogsFinished) handleWorkflowMessage(payload.execution_id, fetchAvailableRolesFinished) handleWorkflowMessage(payload.execution_id, selectRolesFinished) handleWorkflowMessage(payload.execution_id, fetchNetworksFinished) payload.execution_id,"," handleWorkflowMessage(payload.execution.id, nodesRegistrationFinished) handleWorkflowMessage(payload.execution.id, undefined, pollTimeout) payload.execution.id, payload.execution.id, handleWorkflowMessage(payload.execution.id, downloadLogsFinished) handleWorkflowMessage(payload.execution.id, fetchAvailableRolesFinished) handleWorkflowMessage(payload.execution.id, selectRolesFinished) handleWorkflowMessage(payload.execution.id, fetchNetworksFinished) payload.execution.id,",9,9
openstack%2Fnetworking-bagpipe~master~I6c9da7d1fe60c1254e4e3ffdd28f0303f191c21b,openstack/networking-bagpipe,master,I6c9da7d1fe60c1254e4e3ffdd28f0303f191c21b,fix tox python3 overrides,ABANDONED,2018-09-29 23:51:30.000000000,2019-01-08 15:19:40.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-09-29 23:51:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/104b4588c09a9b79b7379328e41004b4d9990a88', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I6c9da7d1fe60c1254e4e3ffdd28f0303f191c21b\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,606670,104b4588c09a9b79b7379328e41004b4d9990a88,3,1,1,2472,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: I6c9da7d1fe60c1254e4e3ffdd28f0303f191c21b
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/70/606670/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,104b4588c09a9b79b7379328e41004b4d9990a88,python3-first,basepython = python3basepython = python3basepython = python3basepython = python3,basepython = python2.7,4,1
openstack%2Fopenstacksdk~master~I0a91089309547d56d0e51392ec94829422be4064,openstack/openstacksdk,master,I0a91089309547d56d0e51392ec94829422be4064,Skip block storage v2 functional tests for a minute,MERGED,2019-01-08 12:18:01.000000000,2019-01-08 15:19:05.000000000,2019-01-08 15:19:04.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 12:18:01.000000000', 'files': ['openstack/tests/functional/block_storage/v2/base.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e18899d19fa3b138bb287d8a5aa0e3f3ce37c95d', 'message': ""Skip block storage v2 functional tests for a minute\n\nThere is something very sad going on with v2, discovery and block-storage.\nIt needs to be fixed, but at the moment it's proving hard to track down\nand the failures are blocking other fixes.\n\nSkip the four tests for now while we work on it.\n\nChange-Id: I0a91089309547d56d0e51392ec94829422be4064\n""}]",0,629162,e18899d19fa3b138bb287d8a5aa0e3f3ce37c95d,7,3,1,2,,,0,"Skip block storage v2 functional tests for a minute

There is something very sad going on with v2, discovery and block-storage.
It needs to be fixed, but at the moment it's proving hard to track down
and the failures are blocking other fixes.

Skip the four tests for now while we work on it.

Change-Id: I0a91089309547d56d0e51392ec94829422be4064
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/62/629162/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/block_storage/v2/base.py'],1,e18899d19fa3b138bb287d8a5aa0e3f3ce37c95d,," def setUp(self): super(BaseBlockStorageTest, self).setUp() self.skipTest('block-storage v2 functional tests broken')",,4,0
openstack%2Fnetworking-bgpvpn~master~I8ecc36ba2c86786f74e2f5f2cc816e43abeba243,openstack/networking-bgpvpn,master,I8ecc36ba2c86786f74e2f5f2cc816e43abeba243,use neutron-lib for model_query,MERGED,2019-01-02 20:17:09.000000000,2019-01-08 15:14:33.000000000,2019-01-08 15:14:33.000000000,"[{'_account_id': 55}, {'_account_id': 1131}, {'_account_id': 2888}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 20:17:09.000000000', 'files': ['networking_bgpvpn/neutron/db/bgpvpn_db.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/1a4cf31b9ce8d13c1721675df7acdd2cb4ec5a1e', 'message': ""use neutron-lib for model_query\n\nThis patch switches to code over to use neutron-lib's model_query\nmodule rather than neutrons.\n\nChange-Id: I8ecc36ba2c86786f74e2f5f2cc816e43abeba243\n""}]",0,628038,1a4cf31b9ce8d13c1721675df7acdd2cb4ec5a1e,8,5,1,5367,,,0,"use neutron-lib for model_query

This patch switches to code over to use neutron-lib's model_query
module rather than neutrons.

Change-Id: I8ecc36ba2c86786f74e2f5f2cc816e43abeba243
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/38/628038/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bgpvpn/neutron/db/bgpvpn_db.py'],1,1a4cf31b9ce8d13c1721675df7acdd2cb4ec5a1e,bp/neutronlib-decouple-db,from neutron_lib.db import model_query,from neutron.db import _model_query as model_query,1,1
openstack%2Fnetworking-bgpvpn~master~Ib69b92df3d8cf0566b01b96d1cc79f6bb6b599d1,openstack/networking-bgpvpn,master,Ib69b92df3d8cf0566b01b96d1cc79f6bb6b599d1,Update min tox version to 2.0,MERGED,2018-11-02 02:33:54.000000000,2019-01-08 15:14:32.000000000,2019-01-08 15:14:32.000000000,"[{'_account_id': 55}, {'_account_id': 2888}, {'_account_id': 12021}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 28174}, {'_account_id': 28935}]","[{'number': 1, 'created': '2018-11-02 02:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/8818861c51484fd9286b6683012c9a24b22fabb4', 'message': 'Update min tox version to 2.0\n\nThe commands used by constraints need at least tox 2.0.  Update to\nreflect reality, which should help with local running of constraints\ntargets.\n\nChange-Id: Ib69b92df3d8cf0566b01b96d1cc79f6bb6b599d1\n'}, {'number': 2, 'created': '2018-11-03 03:17:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/1ce7922a5c25204b9035191c6651e6f51f9d0bb7', 'message': 'Update min tox version to 2.0\n\nThe commands used by constraints need at least tox 2.0.  Update to\nreflect reality, which should help with local running of constraints\ntargets.\n\nChange-Id: Ib69b92df3d8cf0566b01b96d1cc79f6bb6b599d1\nCloses-Bug:  #1801463\n'}]",0,614919,1ce7922a5c25204b9035191c6651e6f51f9d0bb7,13,7,2,28543,,,0,"Update min tox version to 2.0

The commands used by constraints need at least tox 2.0.  Update to
reflect reality, which should help with local running of constraints
targets.

Change-Id: Ib69b92df3d8cf0566b01b96d1cc79f6bb6b599d1
Closes-Bug:  #1801463
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/19/614919/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8818861c51484fd9286b6683012c9a24b22fabb4,bug/1801463,minversion = 2.0 {[testenv:pep8]commands} ,minversion = 1.6 {[testenv:pep8]commands},2,2
openstack%2Ftripleo-ci~master~I9e18cde387aabf3271ae5d1b464fc62ebe286f43,openstack/tripleo-ci,master,I9e18cde387aabf3271ae5d1b464fc62ebe286f43,Avoid `du` timeouts by capping it to 300s,ABANDONED,2018-12-11 12:11:13.000000000,2019-01-08 15:14:00.000000000,,"[{'_account_id': 3153}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 8449}, {'_account_id': 8871}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-12-11 12:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/046a9de344f5d9a51cc6d863491fe52821274058', 'message': 'Avoid du timeouts by capping it to 120s\n\nOver time we seen many post failures around du report generation\nand this additional timeout should assure that du never runs for more\nthan 120s.\n\nBy running it with verbose swtich we can see in the logs when\nthe kill signal is sent allowing us to tune it.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 2, 'created': '2018-12-11 13:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d4de5ba05e7ba030f323fc712c2e5dc261aaf803', 'message': 'Avoid `du` timeouts by capping it to 300s\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nBy running it with verbose switch we can see in the logs when\nthe kill signal is sent, allowing us to tune it.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 3, 'created': '2018-12-12 10:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/02046a85010f270c5b24167c39a48769330a1488', 'message': 'Avoid `du` timeouts by capping it to 300s\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 4, 'created': '2018-12-13 09:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/65dade47cd0e269cef34fffbc935b635f9d9f49d', 'message': 'Avoid `du` timeouts by capping it to 300s\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 5, 'created': '2018-12-13 14:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/801bd90c84e05fc65f8225bcbd5e740fb9f76429', 'message': 'Avoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 6, 'created': '2018-12-13 14:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cb145d57c6bb4a5a14ca11ac3dd62391e5b586d5', 'message': 'Avoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 7, 'created': '2018-12-13 14:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6dc4e12ea0012a3329f23086c179288b101c4157', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT\n\nAvoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 8, 'created': '2018-12-13 14:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9de3646ac01990024b0cbc3197cb232d0fee644b', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT\n\nAvoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 9, 'created': '2018-12-13 18:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1e4e700160f782c3f43f24d7ea64cf209b85ef5a', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT\n\nAvoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 10, 'created': '2018-12-14 00:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f37738343025a408e7e36957827b6702c43335ea', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT\n\nAvoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 11, 'created': '2018-12-14 07:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b770af84ee43aeb3cc6e40e4a1fa9acc1459e120', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT\n\nAvoid `du` timeouts by capping it to 300s and improving its execution\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 12, 'created': '2018-12-14 11:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/708f9c87f4c4529fb2963c3dbd9a4ea2bae9deb2', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 13, 'created': '2018-12-14 15:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/36c23ecffbb245baa8db26535ad59e1f14a9ff70', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 14, 'created': '2018-12-15 10:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b3295733792fecc853b4a8c61088640b7886b86d', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 15, 'created': '2018-12-16 00:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cd7e4f1d3334772194c096c00a0be12a435bb278', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 16, 'created': '2018-12-16 11:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/65f2b7dc15e2ffffc8a25c48924c085c10609164', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 17, 'created': '2018-12-16 17:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7a470f5c56034754484dacbb138dc1f78d8e2e9d', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}, {'number': 18, 'created': '2018-12-17 14:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bb2d6f94c50ec8368bf14cbb2234b2822a41fe9c', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nDepends-On: https://review.openstack.org/625576\nRelated-Bug: 1807940\n'}, {'number': 19, 'created': '2018-12-17 14:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/efb21b72f69c86f203bd5006a36207cfb5e6698f', 'message': 'Avoid random POST-RUN END RESULT_TIMED_OUT due to du execution\n\nOver time we seen many post failures around `du` report generation.\n\nAny timeout attempts (even with SIGKILL) failed so we decided to let\nit run in background as producing of the stats was already a\nbest-effort approach.\n\nThis approach should also speedup the builds by avoiding and expensive\ndelay.\n\nAnother optimization that does speedup du around an order of magnitude\nis to use the threashold attribute, its only downside being that it\nwill skip reporting files or folder smaller than 100kb (still totals\nare still the same).\n\nIncludes a total runtime duration of du, which could prove useful for\ndebugging in the future.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nThis should also avoid that error we always got on the console:\nsort: write failed: standard output: Broken pipe\nSee: https://stackoverflow.com/a/41516237/99834\n\nRemoves the bash if conditional in POST task after we observed a weird\nline in zuul logs related to it.\nSee: http://paste.openstack.org/show/737224/\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nDepends-On: https://review.openstack.org/625576\nRelated-Bug: 1807940\n'}, {'number': 20, 'created': '2019-01-07 14:17:39.000000000', 'files': ['scripts/common_functions.sh', 'scripts/oooq_common_functions.sh', 'roles/run-test/templates/oooq_common_functions.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/eab5fe405249d345fcaa560f7c81b93a356d1b51', 'message': 'Avoid `du` timeouts by capping it to 300s\n\nOver time we seen many post failures around `du` report generation\nand this additional timeout should assure that du never runs for more\nthan 300s.\n\nClear message of du execution failure included in order to allow\nus to track its occurence.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1\n\nChange-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43\nRelated-Bug: 1807940\n'}]",4,624381,eab5fe405249d345fcaa560f7c81b93a356d1b51,80,16,20,24162,,,0,"Avoid `du` timeouts by capping it to 300s

Over time we seen many post failures around `du` report generation
and this additional timeout should assure that du never runs for more
than 300s.

Clear message of du execution failure included in order to allow
us to track its occurence.

http://logstash.openstack.org/#dashboard/file/logstash.json?query=(message%3A%20%5C%22FAILED%20with%20status%3A%20137%5C%22%20OR%20message%3A%20%5C%22FAILED%20with%20status%3A%20143%5C%22%20OR%20message%3A%20%5C%22POST-RUN%20END%20RESULT_TIMED_OUT%5C%22)%20AND%20tags%3A%20%5C%22console%5C%22%20AND%20voting%3A1

Change-Id: I9e18cde387aabf3271ae5d1b464fc62ebe286f43
Related-Bug: 1807940
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/81/624381/9 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/common_functions.sh', 'scripts/oooq_common_functions.sh', 'playbooks/tripleo-ci/templates/oooq_common_functions.sh.j2']",3,046a9de344f5d9a51cc6d863491fe52821274058,oooq/du-timeout,timeout -v 120s du -L -ch $LOGS_DIR/* | tail -n +1 | sort -rh | head -n 200 &> $LOGS_DIR/log-size.txt || true,du -L -ch $LOGS_DIR/* | tail -n +1 | sort -rh | head -n 200 &> $LOGS_DIR/log-size.txt || true,3,3
openstack%2Ftripleo-ci~master~I39ae7a2f16337f125f3a1e2841ecc3131ea07acd,openstack/tripleo-ci,master,I39ae7a2f16337f125f3a1e2841ecc3131ea07acd,Avoids sort: write failed: standard output: Broken pipe with du,ABANDONED,2018-10-10 13:45:43.000000000,2019-01-08 15:12:15.000000000,,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-10-10 13:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5638a34696980e6ee5ab10b4b69c63686750e3cb', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://unix.stackexchange.com/a/355164/16823\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 2, 'created': '2018-10-18 15:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f1989c174151a0d3abd3ffa2418e4ed47a5b3d1a', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://unix.stackexchange.com/a/355164/16823\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 3, 'created': '2018-10-19 10:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/de1cc7b3f58e9aa8365904050f2e6bd523cbf4d7', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://stackoverflow.com/a/41516237/99834\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 4, 'created': '2018-10-19 15:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5fd03c299b181cf16f3a5de803d2810b222551d5', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://stackoverflow.com/a/41516237/99834\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 5, 'created': '2018-11-06 13:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/784222233bc1b3df63b42d1bf279082b743ff4a9', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://stackoverflow.com/a/41516237/99834\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 6, 'created': '2018-12-12 14:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/012dfd806a679c11832d4bf1af99801bdb136af6', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://stackoverflow.com/a/41516237/99834\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 7, 'created': '2018-12-13 02:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c7031c93f06b61d8f968097a01aa7610b564434c', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://stackoverflow.com/a/41516237/99834\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}, {'number': 8, 'created': '2019-01-07 14:17:39.000000000', 'files': ['scripts/common_functions.sh', 'scripts/oooq_common_functions.sh', 'roles/run-test/templates/oooq_common_functions.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/95a0bba0b98355f53b625b39d2e94bf8932867ac', 'message': 'Avoids sort: write failed: standard output: Broken pipe with du\n\nRemoved confusing error from the console log files by\nimplementing workaround described at:\nhttps://stackoverflow.com/a/41516237/99834\n\nChange-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd\n'}]",3,609413,95a0bba0b98355f53b625b39d2e94bf8932867ac,31,8,8,24162,,,0,"Avoids sort: write failed: standard output: Broken pipe with du

Removed confusing error from the console log files by
implementing workaround described at:
https://stackoverflow.com/a/41516237/99834

Change-Id: I39ae7a2f16337f125f3a1e2841ecc3131ea07acd
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/13/609413/8 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/common_functions.sh', 'scripts/oooq_common_functions.sh', 'playbooks/tripleo-ci/templates/oooq_common_functions.sh.j2']",3,5638a34696980e6ee5ab10b4b69c63686750e3cb,oooq/du-timeout,"trap - PIPEtrap """" PIPE",,7,0
openstack%2Fkolla-ansible~master~I0c1d91f62f4e5dad2d9a45a2a7bb51b5121dbfda,openstack/kolla-ansible,master,I0c1d91f62f4e5dad2d9a45a2a7bb51b5121dbfda,Add the ironic_dnsmasq_dhcp_range prechecks for Ironic Dnsmasq,MERGED,2017-10-11 02:41:11.000000000,2019-01-08 15:05:43.000000000,2018-03-27 07:03:33.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 9414}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-10-11 02:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/240683cd94787800962a1ff638c909e337238bac', 'message': 'Fix the ironic_dnsmasq Restarting\n\nWhen deploy ironic, the ironic_dnsmasq keep restaring, the reason\nis: ""dnsmasq: bad dhcp-range at line 4 of /etc/dnsmasq.conf""\n\nChange-Id: I0c1d91f62f4e5dad2d9a45a2a7bb51b5121dbfda\n'}, {'number': 2, 'created': '2017-10-11 02:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ba3a1a71be14930e7b3875e0653135410bd719d6', 'message': 'Fix the ironic_dnsmasq Restarting\n\nWhen deploy ironic, the ironic_dnsmasq keep restaring, the reason\nis: ""dnsmasq: bad dhcp-range at line 4 of /etc/dnsmasq.conf"", and\nthe dhcp-range is useless, just ensure ironic_dnsmasq up.\n\nChange-Id: I0c1d91f62f4e5dad2d9a45a2a7bb51b5121dbfda\n'}, {'number': 3, 'created': '2018-01-30 13:39:37.000000000', 'files': ['ansible/roles/ironic/tasks/precheck.yml', 'etc/kolla/globals.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e5edf98266a3c679b99bc0ca497291590acce715', 'message': 'Add the ironic_dnsmasq_dhcp_range prechecks for Ironic Dnsmasq\n\nWhen deploy ironic, the ironic_dnsmasq keep restaring if\nironic_dnsmasq_dhcp_range is missing, so it necessary to add a\nprechecks to ensure it be set.\n\nChange-Id: I0c1d91f62f4e5dad2d9a45a2a7bb51b5121dbfda\n'}]",3,511091,e5edf98266a3c679b99bc0ca497291590acce715,19,9,3,22165,,,0,"Add the ironic_dnsmasq_dhcp_range prechecks for Ironic Dnsmasq

When deploy ironic, the ironic_dnsmasq keep restaring if
ironic_dnsmasq_dhcp_range is missing, so it necessary to add a
prechecks to ensure it be set.

Change-Id: I0c1d91f62f4e5dad2d9a45a2a7bb51b5121dbfda
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/91/511091/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ironic/defaults/main.yml'],1,240683cd94787800962a1ff638c909e337238bac,,"ironic_dnsmasq_dhcp_range: ""192.168.0.10,192.168.0.10""",ironic_dnsmasq_dhcp_range:,1,1
openstack%2Fdiskimage-builder~master~Ie8b5c425f846619ab4fc07f5bd1902dc83172a59,openstack/diskimage-builder,master,Ie8b5c425f846619ab4fc07f5bd1902dc83172a59,change to python36 for gentoo,MERGED,2019-01-08 11:00:01.000000000,2019-01-08 14:59:25.000000000,2019-01-08 14:59:25.000000000,"[{'_account_id': 10118}, {'_account_id': 12898}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-08 11:00:01.000000000', 'files': ['diskimage_builder/elements/gentoo/environment.d/00-gentoo-envars.bash', 'diskimage_builder/elements/gentoo/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cf786bb175eec207d3237f6bfd99be5493c5b100', 'message': 'change to python36 for gentoo\n\nfixes build issues since dev-util/glib-utils was updated\n\nChange-Id: Ie8b5c425f846619ab4fc07f5bd1902dc83172a59\n'}]",0,629145,cf786bb175eec207d3237f6bfd99be5493c5b100,9,5,1,14288,,,0,"change to python36 for gentoo

fixes build issues since dev-util/glib-utils was updated

Change-Id: Ie8b5c425f846619ab4fc07f5bd1902dc83172a59
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/45/629145/1 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage_builder/elements/gentoo/environment.d/00-gentoo-envars.bash', 'diskimage_builder/elements/gentoo/README.rst']",2,cf786bb175eec207d3237f6bfd99be5493c5b100,gentoo-change-to-py36," is a string as follows `""python2_7 python3_6""`. contents can be something like `python3.6`."," is a string as follows `""python2_7 python3_5""`. contents can be something like `python3.5`.",4,4
openstack%2Fansible-role-python_venv_build~master~I241e249c919bc52fcc0220737b9d96d9608afebf,openstack/ansible-role-python_venv_build,master,I241e249c919bc52fcc0220737b9d96d9608afebf,Create venv_install_destination_path parent directory,MERGED,2019-01-08 12:41:22.000000000,2019-01-08 14:54:42.000000000,2019-01-08 14:54:41.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2019-01-08 12:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/0d64a5be43c01c58f0188ab357dba026f29ce2b4', 'message': 'Create venv_install_destination_path parent directory\n\nBefore creating the venv, it is necessary to make sure that the\nparent directory exists otherwise venv creation will fail.\n\nChange-Id: I241e249c919bc52fcc0220737b9d96d9608afebf\n'}, {'number': 2, 'created': '2019-01-08 12:55:28.000000000', 'files': ['tasks/python_venv_install.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/44c421b5afbd6f5916f2a07114857e5136f15f38', 'message': 'Create venv_install_destination_path parent directory\n\nBefore creating the venv, it is necessary to make sure that the\nparent directory exists otherwise venv creation will fail.\n\nChange-Id: I241e249c919bc52fcc0220737b9d96d9608afebf\n'}]",2,629167,44c421b5afbd6f5916f2a07114857e5136f15f38,11,7,2,12393,,,0,"Create venv_install_destination_path parent directory

Before creating the venv, it is necessary to make sure that the
parent directory exists otherwise venv creation will fail.

Change-Id: I241e249c919bc52fcc0220737b9d96d9608afebf
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/67/629167/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/python_venv_install.yml'],1,0d64a5be43c01c58f0188ab357dba026f29ce2b4,fix_path,"- name: Create the venv_install_destination_path parent directory file: path: ""{{ venv_install_destination_path | dirname }}"" state: directory owner: root group: root mode: ""0755"" ",,8,0
openstack%2Fnetworking-midonet~master~I628126b75c09f918ad2ee78455f305c99cf77b21,openstack/networking-midonet,master,I628126b75c09f918ad2ee78455f305c99cf77b21,support local testing and lower-constraints via tox.ini,ABANDONED,2018-06-26 21:27:59.000000000,2019-01-08 14:52:00.000000000,,"[{'_account_id': 5367}, {'_account_id': 6854}, {'_account_id': 13995}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-26 21:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/2b86e2bb5a6299cd86c32af69c3e94ba71de30ea', 'message': 'support local testing and lower-constraints via tox.ini\n\nThis patch adds support for local tox.ini based testing as well as\nlower-constraints by:\n\n- Adding *-dev targets to tox and manually installing dependant src\nprojects.\n- Adding lower constraints targets to tox and the project .zuul.yaml.\n- Addessing a few pylint 1.7.1 errors in the code; and disabling a few\nothers.\n- Adding lower-constraints.txt.\n- Updating requirements.txt\n\nNote: this patch is only for master, it will have to be ported to\nqueens branch if needed.\n\nFor more details please see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-June/131801.html\n\nChange-Id: I628126b75c09f918ad2ee78455f305c99cf77b21\nPartial-Bug: #1778271\n'}, {'number': 2, 'created': '2018-06-27 12:57:30.000000000', 'files': ['midonet/neutron/db/data_state_db.py', 'doc/source/contributor/api/index.rst', 'requirements.txt', 'midonet/neutron/services/loadbalancer/v2_driver.py', 'test-requirements.txt', 'doc/source/contributor/index.rst', 'midonet/neutron/db/migration/alembic_migration/env.py', '.zuul.yaml', 'lower-constraints.txt', 'midonet/neutron/db/l3_db_midonet.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/16ccb21c36cbf35bf128bbc0f84f8f68df2d2839', 'message': 'support local testing and lower-constraints via tox.ini\n\nThis patch adds support for local tox.ini based testing as well as\nlower-constraints by:\n\n- Adding *-dev targets to tox and manually installing dependant src\nprojects.\n- Adding lower constraints targets to tox and the project .zuul.yaml.\n- Addressing a few pylint 1.7.1 errors in the code; and disabling a few\nothers.\n- Addressing a few doc build errors.\n- Adding lower-constraints.txt.\n- Updating requirements.txt\n\nNote: this patch is only for master, it will have to be ported to\nqueens branch if needed.\n\nFor more details please see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-June/131801.html\n\nChange-Id: I628126b75c09f918ad2ee78455f305c99cf77b21\nPartial-Bug: #1778271\n'}]",9,578212,16ccb21c36cbf35bf128bbc0f84f8f68df2d2839,11,4,2,5367,,,0,"support local testing and lower-constraints via tox.ini

This patch adds support for local tox.ini based testing as well as
lower-constraints by:

- Adding *-dev targets to tox and manually installing dependant src
projects.
- Adding lower constraints targets to tox and the project .zuul.yaml.
- Addressing a few pylint 1.7.1 errors in the code; and disabling a few
others.
- Addressing a few doc build errors.
- Adding lower-constraints.txt.
- Updating requirements.txt

Note: this patch is only for master, it will have to be ported to
queens branch if needed.

For more details please see:
http://lists.openstack.org/pipermail/openstack-dev/2018-June/131801.html

Change-Id: I628126b75c09f918ad2ee78455f305c99cf77b21
Partial-Bug: #1778271
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/12/578212/1 && git format-patch -1 --stdout FETCH_HEAD,"['midonet/neutron/db/data_state_db.py', 'requirements.txt', 'midonet/neutron/services/loadbalancer/v2_driver.py', 'test-requirements.txt', 'midonet/neutron/db/migration/alembic_migration/env.py', '.zuul.yaml', 'lower-constraints.txt', 'tox.ini']",8,2b86e2bb5a6299cd86c32af69c3e94ba71de30ea,bug/1778271,"[testenv:dev] # run locally (not in the gate) using editable mode # https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs # note that order is important to ensure dependencies don't override commands = pip install -q -e ""git+https://git.openstack.org/openstack/tap-as-a-service#egg=tap_as_a_service"" pip install -q -e ""git+https://git.openstack.org/openstack/networking-l2gw#egg=networking_l2gw"" pip install -q -e ""git+https://git.openstack.org/openstack/neutron-lbaas#egg=neutron_lbaas"" pip install -q -e ""git+https://git.openstack.org/openstack/neutron-fwaas#egg=neutron_fwaas"" pip install -q -e ""git+https://git.openstack.org/openstack/neutron-dynamic-routing#egg=neutron_dynamic_routing"" pip install -q -e ""git+https://git.openstack.org/openstack/neutron-vpnaas#egg=neutron_vpnaas"" pip install -q -e ""git+https://git.openstack.org/openstack/neutron#egg=neutron"" [testenv:py27-dev] commands = {[testenv:dev]commands} pip freeze stestr run {posargs} whitelist_externals = stestr [testenv:py3-dev] basepython = python3 commands = {[testenv:dev]commands} pip freeze stestr run {posargs} whitelist_externals = stestr [testenv:pep8-dev] basepython = python3 commands = {[testenv:dev]commands} pip freeze flake8 {toxinidir}/midonet doc8 doc/source devstack releasenotes/source specs rally-jobs {toxinidir}/tools/coding-checks.sh --pylint '{posargs}' neutron-db-manage --subproject networking-midonet check_migration {[testenv:bashate]commands} {[testenv:bandit]commands} whitelist_externals = bash [testenv:lower-constraints-dev] basepython = python3 commands = {[testenv:dev]commands} deps = -c{toxinidir}/lower-constraints.txt -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt [testenv:lower-constraints] basepython = python3 setenv = OS_TEST_TIMEOUT={env:OS_TEST_TIMEOUT:60} deps = -c{toxinidir}/lower-constraints.txt -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt",,254,11
openstack%2Fnetworking-onos~master~Ic4f7a9e751431587c81ea1a6a7494850edb94878,openstack/networking-onos,master,Ic4f7a9e751431587c81ea1a6a7494850edb94878,opt in for neutron-lib consumption patches,ABANDONED,2018-09-25 19:30:19.000000000,2019-01-08 14:51:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-09-25 19:30:19.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/77fb7bfeddba0761a657535feb8dd9644c303968', 'message': 'opt in for neutron-lib consumption patches\n\nAs part of the Denver PTG [1] we decided networking related projects\nthat are ""current"" and want to receive neutron-lib consumption patches\non an on-going basis should indicate such with a well defined comment\nin their requirements.txt. This allows us to easily find the list of\nproject to receive neutron-lib consumption patches [2] by searching for\nthe string.\n\nIn addition, projects opting-in for these patches are also attesting\nthey will stay up to date with TC and infra initiatives to ensure\nconsumption patches can flow freely.\n\nThis patch adds the ""neutron-lib-current"" string to requirements.txt\nopting in for neutron-lib consumption patches.\n\n[1] https://etherpad.openstack.org/p/neutron-stein-ptg\n[2] https://docs.openstack.org/neutron-lib/latest/contributor/contributing.html#phase-4-consume\n\nChange-Id: Ic4f7a9e751431587c81ea1a6a7494850edb94878\n'}]",0,605191,77fb7bfeddba0761a657535feb8dd9644c303968,3,1,1,5367,,,0,"opt in for neutron-lib consumption patches

As part of the Denver PTG [1] we decided networking related projects
that are ""current"" and want to receive neutron-lib consumption patches
on an on-going basis should indicate such with a well defined comment
in their requirements.txt. This allows us to easily find the list of
project to receive neutron-lib consumption patches [2] by searching for
the string.

In addition, projects opting-in for these patches are also attesting
they will stay up to date with TC and infra initiatives to ensure
consumption patches can flow freely.

This patch adds the ""neutron-lib-current"" string to requirements.txt
opting in for neutron-lib consumption patches.

[1] https://etherpad.openstack.org/p/neutron-stein-ptg
[2] https://docs.openstack.org/neutron-lib/latest/contributor/contributing.html#phase-4-consume

Change-Id: Ic4f7a9e751431587c81ea1a6a7494850edb94878
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/91/605191/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,77fb7bfeddba0761a657535feb8dd9644c303968,neutron-lib-current-optin, # The comment below indicates this project repo is current with neutron-lib # and should receive neutron-lib consumption patches as they are released # in neutron-lib. It also implies the project will stay current with TC # and infra initiatives ensuring consumption patches can land. # neutron-lib-current,,6,0
openstack%2Fpython-openstackclient~master~Idd2eba6c682f328999b0cfbb14575eb148bdb384,openstack/python-openstackclient,master,Idd2eba6c682f328999b0cfbb14575eb148bdb384,DNM: test updated segment API description,ABANDONED,2018-05-30 19:56:25.000000000,2019-01-08 14:50:33.000000000,,"[{'_account_id': 5367}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-05-30 19:56:25.000000000', 'files': ['openstackclient/tests/functional/network/v2/test_network_segment.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aea615c8d5a99b113ffd1dfa164e8a3ad33df3e3', 'message': 'DNM: test updated segment API description\n\nDO NOT MERGE\n\nThis patch is to test with the depends on patch.\n\nDepends-On: https://review.openstack.org/#/c/571292\nChange-Id: Idd2eba6c682f328999b0cfbb14575eb148bdb384\n'}]",0,571293,aea615c8d5a99b113ffd1dfa164e8a3ad33df3e3,4,2,1,5367,,,0,"DNM: test updated segment API description

DO NOT MERGE

This patch is to test with the depends on patch.

Depends-On: https://review.openstack.org/#/c/571292
Change-Id: Idd2eba6c682f328999b0cfbb14575eb148bdb384
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/93/571293/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/network/v2/test_network_segment.py'],1,aea615c8d5a99b113ffd1dfa164e8a3ad33df3e3,bug/1757513, # dummy change,,1,0
openstack%2Fnetworking-midonet~master~I58c45d5b6c5391b6d677aca5eec90394c99b81fc,openstack/networking-midonet,master,I58c45d5b6c5391b6d677aca5eec90394c99b81fc,fix doc build,ABANDONED,2018-05-04 15:39:28.000000000,2019-01-08 14:50:03.000000000,,"[{'_account_id': 6854}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-05-04 15:39:28.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/4641f1c42e958b2dd4a17ffb013347d4d1e15bde', 'message': ""fix doc build\n\nThe doc build is failing with:\n\nERROR: You must give at least one requirement to install\n\nFor example [1].\n\nThis patch fixes the error by checking if there's not args given to\ntox_install.sh, and if not then bypassing the invocation of pip.\n\n[1] http://logs.openstack.org/87/199387/112/check/\nbuild-openstack-sphinx-docs/8fb9133/job-output.txt.gz\n\nChange-Id: I58c45d5b6c5391b6d677aca5eec90394c99b81fc\n""}]",0,566347,4641f1c42e958b2dd4a17ffb013347d4d1e15bde,4,2,1,5367,,,0,"fix doc build

The doc build is failing with:

ERROR: You must give at least one requirement to install

For example [1].

This patch fixes the error by checking if there's not args given to
tox_install.sh, and if not then bypassing the invocation of pip.

[1] http://logs.openstack.org/87/199387/112/check/
build-openstack-sphinx-docs/8fb9133/job-output.txt.gz

Change-Id: I58c45d5b6c5391b6d677aca5eec90394c99b81fc
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/47/566347/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,4641f1c42e958b2dd4a17ffb013347d4d1e15bde,fix-doc-build,"if [ -z ""$*"" ]; then echo ""No install args given, skipping install command."" return 0 fi ",,5,0
openstack%2Fnetworking-midonet~master~I93ab299a032716691980d9b97173b53e100d384c,openstack/networking-midonet,master,I93ab299a032716691980d9b97173b53e100d384c,DNM: test stable/queens gate,ABANDONED,2018-06-21 14:00:45.000000000,2019-01-08 14:48:22.000000000,,"[{'_account_id': 5367}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-21 14:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/36ad826142ebb056eefa4bd27db4cfe3522c77e7', 'message': 'DNM: test stable/queens gate\n\nDO NOT MERGE\n\nThis is a test of stable/queens to see if\nhttps://bugs.launchpad.net/openstack-requirements/+bug/1778054 breaks\nthe gate.\n\nChange-Id: I93ab299a032716691980d9b97173b53e100d384c\n'}, {'number': 2, 'created': '2018-06-21 14:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/9eabbcb09bbc0b49e3b1938887e364b24fd9c48d', 'message': 'DNM: test stable/queens gate\n\nDO NOT MERGE\n\nThis is a test of stable/queens to see if\nhttps://bugs.launchpad.net/openstack-requirements/+bug/1778054 breaks\nthe gate.\n\nChange-Id: I93ab299a032716691980d9b97173b53e100d384c\n'}, {'number': 3, 'created': '2018-06-21 14:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/93bd2ba90c503c01ba8940b69dbd7af9b482186b', 'message': 'DNM: test stable/queens gate\n\nDO NOT MERGE\n\nThis is a test of stable/queens to see if\nhttps://bugs.launchpad.net/openstack-requirements/+bug/1778054 breaks\nthe gate.\n\nChange-Id: I93ab299a032716691980d9b97173b53e100d384c\n'}, {'number': 4, 'created': '2018-06-21 14:59:04.000000000', 'files': ['midonet/neutron/tests/unit/test_datastate.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/0a4d568dd2835cff8a76c9e8df8689ae698261ba', 'message': 'DNM: test stable/queens gate\n\nDO NOT MERGE\n\nThis is a test of stable/queens to see if\nhttps://bugs.launchpad.net/openstack-requirements/+bug/1778054 breaks\nthe gate.\n\nChange-Id: I93ab299a032716691980d9b97173b53e100d384c\n'}]",0,577167,0a4d568dd2835cff8a76c9e8df8689ae698261ba,9,2,4,5367,,,0,"DNM: test stable/queens gate

DO NOT MERGE

This is a test of stable/queens to see if
https://bugs.launchpad.net/openstack-requirements/+bug/1778054 breaks
the gate.

Change-Id: I93ab299a032716691980d9b97173b53e100d384c
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/67/577167/2 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/tests/unit/test_datastate.py'],1,36ad826142ebb056eefa4bd27db4cfe3522c77e7,test-queens-gate,# dummy change,,1,0
openstack%2Ftripleo-heat-templates~master~I23612ab78f858ad4fcd84268ada47160057a097d,openstack/tripleo-heat-templates,master,I23612ab78f858ad4fcd84268ada47160057a097d,Update hacking version,MERGED,2018-12-31 17:42:12.000000000,2019-01-08 14:44:31.000000000,2019-01-08 14:44:31.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2018-12-31 17:42:12.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13d0057c995a5d1e161f409a201265a511eb5a9b', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I23612ab78f858ad4fcd84268ada47160057a097d\n'}]",0,627883,13d0057c995a5d1e161f409a201265a511eb5a9b,9,5,1,23717,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I23612ab78f858ad4fcd84268ada47160057a097d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/627883/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,13d0057c995a5d1e161f409a201265a511eb5a9b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=0.11.0,<0.12 # Apache-2.0",1,1
openstack%2Ftripleo-common~master~Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32,openstack/tripleo-common,master,Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32,Mock swiftutils for overcloud config action test,MERGED,2018-11-01 21:58:53.000000000,2019-01-08 14:44:29.000000000,2019-01-08 14:44:29.000000000,"[{'_account_id': 3153}, {'_account_id': 7385}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-11-01 21:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9c648e3fd82bc78cdc2dfbc2f891a32ab061a41a', 'message': 'Mock swiftutils for overcloud config action test\n\nThis function is failing and we should properly mock out these external\ncalls in the unit tests.\n\nChange-Id: Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32\nCloses-Bug: #1801180\n'}, {'number': 2, 'created': '2018-11-02 14:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b72a6e0562c0f65fdecb691fa8c236508b2222f5', 'message': 'Mock swiftutils for overcloud config action test\n\nThis function is failing and we should properly mock out these external\ncalls in the unit tests.\n\nChange-Id: Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32\nCloses-Bug: #1801180\n'}, {'number': 3, 'created': '2018-12-10 17:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7f8e41fd956073de13d69682fd48c7f07a919586', 'message': 'Mock swiftutils for overcloud config action test\n\nThis function is failing and we should properly mock out these external\ncalls in the unit tests.\n\nChange-Id: Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32\nCloses-Bug: #1801180\n'}, {'number': 4, 'created': '2019-01-03 18:49:00.000000000', 'files': ['tripleo_common/tests/actions/test_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c8149a0fcc6150c9b1b26cdc6bdcd239c7d2dc34', 'message': 'Mock swiftutils for overcloud config action test\n\nThis function is failing and we should properly mock out these external\ncalls in the unit tests.\n\nChange-Id: Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32\nCloses-Bug: #1801180\n'}]",0,614881,c8149a0fcc6150c9b1b26cdc6bdcd239c7d2dc34,23,6,4,14985,,,0,"Mock swiftutils for overcloud config action test

This function is failing and we should properly mock out these external
calls in the unit tests.

Change-Id: Ib01d3940586a1fb2137c20cc4ea41d2c12f66a32
Closes-Bug: #1801180
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/81/614881/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/tests/actions/test_config.py'],1,9c648e3fd82bc78cdc2dfbc2f891a32ab061a41a,bug/1801180," @mock.patch('tripleo_common.utils.swift.delete_container') @mock.patch('tripleo_common.utils.swift.download_container') mock_orchestration_client, mock_swift_download, mock_swift_delete): mock_swift_download.assert_called_once_with( self.swift, self.config_container, '/tmp') mock_swift_delete.assert_called_once_with( self.swift, self.config_container)", mock_orchestration_client):,9,1
openstack%2Ftripleo-heat-templates~master~Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c,openstack/tripleo-heat-templates,master,Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c,Explicitly set KVM machine_type for migration compatibility,MERGED,2018-11-15 10:13:25.000000000,2019-01-08 14:44:28.000000000,2019-01-08 14:44:28.000000000,"[{'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 26458}]","[{'number': 1, 'created': '2018-11-15 10:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87462ef76598afb2eef0a4a6c6fb00ef92f4650f', 'message': ""Explicitly set KVM machine_type for migration compatibility\n\nCurrently when nova launches a guest instance, libvirt uses\ncurrent default KVM/QEMU machine type for guest.\nIf compute node is running on RHEL-7.3.0, then the guest will\nbe given rhel-7.3.0 machine type. If in future, deployment has\nadded additional compute nodes which uses a newer RHEL version,\nthe guests launched on those compute nodes will get a newer\nmachine type. eg. rhel-7.4.0\n\nIt is now impossible to migrate guests from RHEL-7.4 based compute\nnodes to a RHEL-7.3 based compute nodes, since RHEL-7.3 won't\nknow about RHEL-7.4 machine type.\n\nTo deal with this problem, the proposed change will explicitly\nset machine type across all compute nodes during deployment.\nNow even if additional compute nodes are added to deployment with\nnewer OS version, instances spawned on those will get the default\nmachine type explicitly set during initial deployment,\nallowing migrating instances from higher machine type compute\nnodes to lower machine type compute nodes.\n\nChange-Id: Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c\n""}, {'number': 2, 'created': '2018-11-19 10:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8b13096d24657d027046fc29e5992f03f38441b5', 'message': ""Explicitly set KVM machine_type for migration compatibility\n\nCurrently when nova launches a guest instance, libvirt uses\ncurrent default KVM/QEMU machine type for guest.\nIf compute node is running on RHEL-7.3.0, then the guest will\nbe given rhel-7.3.0 machine type. If in future, deployment has\nadded additional compute nodes which uses a newer RHEL version,\nthe guests launched on those compute nodes will get a newer\nmachine type. eg. rhel-7.4.0\n\nIt is now impossible to migrate guests from RHEL-7.4 based compute\nnodes to a RHEL-7.3 based compute nodes, since RHEL-7.3 won't\nknow about RHEL-7.4 machine type.\n\nTo deal with this problem, the proposed change will explicitly\nset machine type across all compute nodes during deployment.\nNow even if additional compute nodes are added to deployment with\nnewer OS version, instances spawned on those will get the default\nmachine type explicitly set during initial deployment,\nallowing migrating instances from higher machine type compute\nnodes to lower machine type compute nodes.\n\nChange-Id: Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c\n""}, {'number': 3, 'created': '2018-12-04 06:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c7335f83f029b07a07d7f5255678da5cf80d71b8', 'message': ""Explicitly set KVM machine_type for migration compatibility\n\nCurrently when nova launches a guest instance, libvirt uses\ncurrent default KVM/QEMU machine type for guest.\nIf compute node is running on RHEL-7.3.0, then the guest will\nbe given rhel-7.3.0 machine type. If in future, deployment has\nadded additional compute nodes which uses a newer RHEL version,\nthe guests launched on those compute nodes will get a newer\nmachine type. eg. rhel-7.4.0\n\nIt is now impossible to migrate guests from RHEL-7.4 based compute\nnodes to a RHEL-7.3 based compute nodes, since RHEL-7.3 won't\nknow about RHEL-7.4 machine type.\n\nTo deal with this problem, the proposed change will explicitly\nset machine type across all compute nodes during deployment.\nNow even if additional compute nodes are added to deployment with\nnewer OS version, instances spawned on those will get the default\nmachine type explicitly set during initial deployment,\nallowing migrating instances from higher machine type compute\nnodes to lower machine type compute nodes.\n\nCloses-Bug: 1806529\nChange-Id: Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c\n""}, {'number': 4, 'created': '2018-12-20 06:21:57.000000000', 'files': ['releasenotes/notes/hw-machine-type-6a0bd7bc3973c15a.yaml', 'puppet/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7707247400dc0a57097f99a04e23a0b57bf3c1f', 'message': ""Explicitly set KVM machine_type for migration compatibility\n\nCurrently when nova launches a guest instance, libvirt uses\ncurrent default KVM/QEMU machine type for guest.\nIf compute node is running on RHEL-7.3.0, then the guest will\nbe given rhel-7.3.0 machine type. If in future, deployment has\nadded additional compute nodes which uses a newer RHEL version,\nthe guests launched on those compute nodes will get a newer\nmachine type. eg. rhel-7.4.0\n\nIt is now impossible to migrate guests from RHEL-7.4 based compute\nnodes to a RHEL-7.3 based compute nodes, since RHEL-7.3 won't\nknow about RHEL-7.4 machine type.\n\nTo deal with this problem, the proposed change will explicitly\nset machine type across all compute nodes during deployment.\nNow even if additional compute nodes are added to deployment with\nnewer OS version, instances spawned on those will get the default\nmachine type explicitly set during initial deployment,\nallowing migrating instances from higher machine type compute\nnodes to lower machine type compute nodes.\n\nCloses-Bug: 1806529\nChange-Id: Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c\n""}]",5,618121,f7707247400dc0a57097f99a04e23a0b57bf3c1f,76,13,4,20733,,,0,"Explicitly set KVM machine_type for migration compatibility

Currently when nova launches a guest instance, libvirt uses
current default KVM/QEMU machine type for guest.
If compute node is running on RHEL-7.3.0, then the guest will
be given rhel-7.3.0 machine type. If in future, deployment has
added additional compute nodes which uses a newer RHEL version,
the guests launched on those compute nodes will get a newer
machine type. eg. rhel-7.4.0

It is now impossible to migrate guests from RHEL-7.4 based compute
nodes to a RHEL-7.3 based compute nodes, since RHEL-7.3 won't
know about RHEL-7.4 machine type.

To deal with this problem, the proposed change will explicitly
set machine type across all compute nodes during deployment.
Now even if additional compute nodes are added to deployment with
newer OS version, instances spawned on those will get the default
machine type explicitly set during initial deployment,
allowing migrating instances from higher machine type compute
nodes to lower machine type compute nodes.

Closes-Bug: 1806529
Change-Id: Ib57bfbb94e2acdfb3bb3a828ee3b085bf68d3b4c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/618121/4 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/nova-compute.yaml'],1,87462ef76598afb2eef0a4a6c6fb00ef92f4650f,bug/1806529," NovaHWMachineType: description: > To specify a default machine type per host architecture. default: 'x86_64=pc-i440fx-rhel7.6.0,aarch64=virt-rhel7.6.0,ppc64=pseries-rhel7.6.0,ppc64le=pseries-rhel7.6.0' type: string nova::compute::libvirt::libvirt_hw_machine_type: NovaHWMachineType NovaHWMachineType: {get_param: NovaHWMachineType}",,7,0
openstack%2Fironic-python-agent~master~I57da5d2f0827ce75ebac12962fc5b3f744613a18,openstack/ironic-python-agent,master,I57da5d2f0827ce75ebac12962fc5b3f744613a18,Remove dsvm from zuulv3 jobs,MERGED,2019-01-07 16:19:11.000000000,2019-01-08 14:41:56.000000000,2019-01-08 14:41:56.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-01-07 16:19:11.000000000', 'files': ['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a91a693685d7c454093e060e8084947606fb5cdc', 'message': 'Remove dsvm from zuulv3 jobs\n\nAccording to [1] the dsvm should be removed from zuulv3 jobs\n\n[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3\n\nChange-Id: I57da5d2f0827ce75ebac12962fc5b3f744613a18\n'}]",3,629008,a91a693685d7c454093e060e8084947606fb5cdc,12,6,1,15519,,,0,"Remove dsvm from zuulv3 jobs

According to [1] the dsvm should be removed from zuulv3 jobs

[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3

Change-Id: I57da5d2f0827ce75ebac12962fc5b3f744613a18
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/08/629008/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml']",2,a91a693685d7c454093e060e8084947606fb5cdc,zuulv3, - ipa-tempest-partition-bios-ipmi-direct-tinyipa-src - ipa-tempest-partition-bios-ipmi-iscsi-tinyipa-src - ipa-tempest-wholedisk-bios-ipmi-direct-tinyipa-src - ipa-tempest-wholedisk-bios-ipmi-iscsi-tinyipa-src - ipa-tempest-ironic-inspector-src: - ipa-tempest-partition-bios-ipmi-direct-tinyipa-src - ipa-tempest-partition-bios-ipmi-iscsi-tinyipa-src - ipa-tempest-wholedisk-bios-ipmi-direct-tinyipa-src - ipa-tempest-wholedisk-bios-ipmi-iscsi-tinyipa-src, - ipa-tempest-dsvm-partition-bios-ipmi-direct-tinyipa-src - ipa-tempest-dsvm-partition-bios-ipmi-iscsi-tinyipa-src - ipa-tempest-dsvm-wholedisk-bios-ipmi-direct-tinyipa-src - ipa-tempest-dsvm-wholedisk-bios-ipmi-iscsi-tinyipa-src - ipa-tempest-dsvm-ironic-inspector-src: - ipa-tempest-dsvm-partition-bios-ipmi-direct-tinyipa-src - ipa-tempest-dsvm-partition-bios-ipmi-iscsi-tinyipa-src - ipa-tempest-dsvm-wholedisk-bios-ipmi-direct-tinyipa-src - ipa-tempest-dsvm-wholedisk-bios-ipmi-iscsi-tinyipa-src,14,15
openstack%2Fironic-inspector~master~I5d470b5048e8d474c4c3271fcba85a0dc781827a,openstack/ironic-inspector,master,I5d470b5048e8d474c4c3271fcba85a0dc781827a,Remove dsvm from zuulv3 job names,MERGED,2019-01-07 16:24:01.000000000,2019-01-08 14:41:55.000000000,2019-01-08 14:41:55.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-01-07 16:24:01.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/ironic-inspector-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/9a8cb3a49c6c2ac49d3472874f6ac7c9661a1672', 'message': 'Remove dsvm from zuulv3 job names\n\nAccording to [1] the dsvm should be removed from zuulv3 jobs\n\n[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3\n\nChange-Id: I5d470b5048e8d474c4c3271fcba85a0dc781827a\n'}]",9,629011,9a8cb3a49c6c2ac49d3472874f6ac7c9661a1672,12,5,1,15519,,,0,"Remove dsvm from zuulv3 job names

According to [1] the dsvm should be removed from zuulv3 jobs

[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3

Change-Id: I5d470b5048e8d474c4c3271fcba85a0dc781827a
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/11/629011/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/ironic-inspector-jobs.yaml']",2,9a8cb3a49c6c2ac49d3472874f6ac7c9661a1672,zuulv3, name: ironic-inspector-base name: ironic-inspector-tempest-python3 description: ironic-inspector-tempest-python3 parent: ironic-inspector-base name: ironic-inspector-tempest-discovery description: ironic-inspector-tempest-discovery parent: ironic-inspector-base, name: ironic-inspector-dsvm-base name: ironic-inspector-tempest-dsvm-python3 description: ironic-inspector-tempest-dsvm-python3 parent: ironic-inspector-dsvm-base name: ironic-inspector-tempest-dsvm-discovery description: ironic-inspector-tempest-dsvm-discovery parent: ironic-inspector-dsvm-base,11,11
openstack%2Foslo.policy~master~I3af9de1b39b6360ecfcb448d8c37b463e1a42ca7,openstack/oslo.policy,master,I3af9de1b39b6360ecfcb448d8c37b463e1a42ca7,Fix sample config value when set_defaults is used,MERGED,2018-12-06 19:25:47.000000000,2019-01-08 14:39:09.000000000,2019-01-08 14:39:09.000000000,"[{'_account_id': 2472}, {'_account_id': 5314}, {'_account_id': 6928}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-06 19:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/3c18f3434d2e05150ad0b20b5435b9ee1db39407', 'message': ""Fix sample config value when set_defaults is used\n\nBy calling set_default on a conf object it only applies to opts\nregistered to that object. This causes an incorrect value to appear in\nthe generated sample config because it reads from the opts directly.\n\nTo fix this, we can call the global set_defaults on the cfg module\nwhich alters the opts directly. This is the method used in the cors\nmiddleware[1] and works as expected there.\n\nThis does complicate the unit tests, however. Because we're altering\nglobal state we need to save the original opts and restore them after\nthe test. Furthermore, the conf.reset() call in the config fixture\ndoesn't sufficiently reset the conf object to allow it to recognize\nthe replaced opts. For the purposes of this test we can just create\na standalone conf object though, which gets past that problem.\n\nIt's possible that we should fix reset() so it actually removes opts\nin groups completely, but I'm unsure what implications that might\nhave for other users of the function.\n\n1: https://github.com/openstack/oslo.middleware/blob/8c7fa5bb105cdfd15376c6b1f42ef1383b7cb3eb/oslo_middleware/cors.py#L88\n\nChange-Id: I3af9de1b39b6360ecfcb448d8c37b463e1a42ca7\nCloses-Bug: 1807184\n""}, {'number': 2, 'created': '2018-12-06 21:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/c21789fcdb8a015679a7ad19854ab0b296b4ff11', 'message': ""Fix sample config value when set_defaults is used\n\nBy calling set_default[1] on a conf object it only applies to opts\nregistered to that object. This causes an incorrect value to appear in\nthe generated sample config because it deals with a list of raw opts,\nnot a conf object.\n\nTo fix this, we can call the global set_defaults[2] on the cfg module\nwhich alters the opts directly. This is the method used in the cors\nmiddleware[3] and works as expected there.\n\nThis does complicate the unit tests, however. Because we're altering\nglobal state we need to save the original opts and restore them after\nthe test. Furthermore, the conf.reset() call in the config fixture\ndoesn't sufficiently reset the conf object to allow it to recognize\nthe replaced opts. For the purposes of this test we can just create\na standalone conf object though, which gets past that problem.\n\nIt's possible that we should fix reset() so it actually removes opts\nin groups completely, but I'm unsure what implications that might\nhave for other users of the function.\n\n1: https://github.com/openstack/oslo.config/blob/b5df53543fd3edbc369cacbdd1c3038bdce9085e/oslo_config/cfg.py#L2433\n2: https://github.com/openstack/oslo.config/blob/b5df53543fd3edbc369cacbdd1c3038bdce9085e/oslo_config/cfg.py#L391\n3: https://github.com/openstack/oslo.middleware/blob/8c7fa5bb105cdfd15376c6b1f42ef1383b7cb3eb/oslo_middleware/cors.py#L88\n\nChange-Id: I3af9de1b39b6360ecfcb448d8c37b463e1a42ca7\nCloses-Bug: 1807184\n""}, {'number': 3, 'created': '2019-01-07 18:11:41.000000000', 'files': ['oslo_policy/opts.py', 'oslo_policy/tests/test_opts.py'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/3d85afb24a014f43e961887c4e5b679e7eb7dec8', 'message': ""Fix sample config value when set_defaults is used\n\nBy calling set_default[1] on a conf object it only applies to opts\nregistered to that object. This causes an incorrect value to appear in\nthe generated sample config because it deals with a list of raw opts,\nnot a conf object.\n\nTo fix this, we can call the global set_defaults[2] on the cfg module\nwhich alters the opts directly. This is the method used in the cors\nmiddleware[3] and works as expected there.\n\nThis does complicate the unit tests, however. Because we're altering\nglobal state we need to save the original opts and restore them after\nthe test. Furthermore, the conf.reset() call in the config fixture\ndoesn't sufficiently reset the conf object to allow it to recognize\nthe replaced opts. For the purposes of this test we can just create\na standalone conf object though, which gets past that problem.\n\nIt's possible that we should fix reset() so it actually removes opts\nin groups completely, but I'm unsure what implications that might\nhave for other users of the function.\n\n1: https://github.com/openstack/oslo.config/blob/b5df53543fd3edbc369cacbdd1c3038bdce9085e/oslo_config/cfg.py#L2433\n2: https://github.com/openstack/oslo.config/blob/b5df53543fd3edbc369cacbdd1c3038bdce9085e/oslo_config/cfg.py#L391\n3: https://github.com/openstack/oslo.middleware/blob/8c7fa5bb105cdfd15376c6b1f42ef1383b7cb3eb/oslo_middleware/cors.py#L88\n\nChange-Id: I3af9de1b39b6360ecfcb448d8c37b463e1a42ca7\nCloses-Bug: 1807184\n""}]",2,623292,3d85afb24a014f43e961887c4e5b679e7eb7dec8,15,5,3,6928,,,0,"Fix sample config value when set_defaults is used

By calling set_default[1] on a conf object it only applies to opts
registered to that object. This causes an incorrect value to appear in
the generated sample config because it deals with a list of raw opts,
not a conf object.

To fix this, we can call the global set_defaults[2] on the cfg module
which alters the opts directly. This is the method used in the cors
middleware[3] and works as expected there.

This does complicate the unit tests, however. Because we're altering
global state we need to save the original opts and restore them after
the test. Furthermore, the conf.reset() call in the config fixture
doesn't sufficiently reset the conf object to allow it to recognize
the replaced opts. For the purposes of this test we can just create
a standalone conf object though, which gets past that problem.

It's possible that we should fix reset() so it actually removes opts
in groups completely, but I'm unsure what implications that might
have for other users of the function.

1: https://github.com/openstack/oslo.config/blob/b5df53543fd3edbc369cacbdd1c3038bdce9085e/oslo_config/cfg.py#L2433
2: https://github.com/openstack/oslo.config/blob/b5df53543fd3edbc369cacbdd1c3038bdce9085e/oslo_config/cfg.py#L391
3: https://github.com/openstack/oslo.middleware/blob/8c7fa5bb105cdfd15376c6b1f42ef1383b7cb3eb/oslo_middleware/cors.py#L88

Change-Id: I3af9de1b39b6360ecfcb448d8c37b463e1a42ca7
Closes-Bug: 1807184
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/92/623292/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_policy/opts.py', 'oslo_policy/tests/test_opts.py']",2,3c18f3434d2e05150ad0b20b5435b9ee1db39407,bug/1807184,import copy from oslo_config import cfg self.conf = cfg.ConfigOpts() self.original_opts = opts._options opts._options = copy.deepcopy(opts._options) def reset(): opts._options = self.original_opts self.addCleanup(reset), self.conf = self.useFixture(config.Config()).conf,11,2
openstack%2Frally-openstack~master~I0498a4671a9e2b17f59fa8b52e07dfdaa9c7296f,openstack/rally-openstack,master,I0498a4671a9e2b17f59fa8b52e07dfdaa9c7296f,Fix content of CONTRIBUTING.rst,MERGED,2019-01-08 08:49:03.000000000,2019-01-08 14:35:54.000000000,2019-01-08 14:35:54.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 08:49:03.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/b1e5af45f36d5506f591d0126d4ecdfd4e15495a', 'message': 'Fix content of CONTRIBUTING.rst\n\nFile CONTRIBUTING.rst was a soft link to doc file in Rally repo,\nhowever it got broken after split of rally-openstack. This patch\nadds a link to compiled user documentation.\n\nChange-Id: I0498a4671a9e2b17f59fa8b52e07dfdaa9c7296f\n'}]",0,629109,b1e5af45f36d5506f591d0126d4ecdfd4e15495a,6,2,1,5950,,,0,"Fix content of CONTRIBUTING.rst

File CONTRIBUTING.rst was a soft link to doc file in Rally repo,
however it got broken after split of rally-openstack. This patch
adds a link to compiled user documentation.

Change-Id: I0498a4671a9e2b17f59fa8b52e07dfdaa9c7296f
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/09/629109/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,b1e5af45f36d5506f591d0126d4ecdfd4e15495a,contrib-docs,Please refer to Rally contribution guide: https://docs.openstack.org/developer/rally/contribute.html ,,2,0
openstack%2Frally-openstack~master~Ia78653121e70c386d1a47a831c58316557bb2dc4,openstack/rally-openstack,master,Ia78653121e70c386d1a47a831c58316557bb2dc4,Bump version of os-faults to 0.2.0,MERGED,2019-01-08 08:42:30.000000000,2019-01-08 14:35:53.000000000,2019-01-08 14:35:53.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 08:42:30.000000000', 'files': ['requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/acbc587379737fc5a07c14fcdcb2797014275c36', 'message': 'Bump version of os-faults to 0.2.0\n\nOS-Faults version 0.2.0 does not link with Ansible directly\nto avoid GPL violation, so `ansible` package is not required\nto be installed by default. If needed, users may install Ansible\nmanually system-wide [1].\n\n[1] https://os-faults.readthedocs.io/en/latest/quickstart/installation.html\n\nChange-Id: Ia78653121e70c386d1a47a831c58316557bb2dc4\n'}]",1,629108,acbc587379737fc5a07c14fcdcb2797014275c36,6,2,1,5950,,,0,"Bump version of os-faults to 0.2.0

OS-Faults version 0.2.0 does not link with Ansible directly
to avoid GPL violation, so `ansible` package is not required
to be installed by default. If needed, users may install Ansible
manually system-wide [1].

[1] https://os-faults.readthedocs.io/en/latest/quickstart/installation.html

Change-Id: Ia78653121e70c386d1a47a831c58316557bb2dc4
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/08/629108/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'upper-constraints.txt']",2,acbc587379737fc5a07c14fcdcb2797014275c36,update-os-faults,os-faults===0.2.0,ansible===2.7.0os-faults===0.1.18,2,3
openstack%2Fopenstack-zuul-jobs~master~I608ba6801f36f834d4e82c0438b41ea1e90620e8,openstack/openstack-zuul-jobs,master,I608ba6801f36f834d4e82c0438b41ea1e90620e8,Implement workaround for ansible unmount bug,MERGED,2019-01-08 12:47:39.000000000,2019-01-08 14:35:35.000000000,2019-01-08 14:35:35.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 12:47:39.000000000', 'files': ['roles/configure-swap/tasks/ephemeral.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/5777cfe47928064f6ea7360dfa88383429b106fd', 'message': 'Implement workaround for ansible unmount bug\n\nIt seems that unmount can falsely report success but removing it from\nfstab seems to be a way to avoid that bug.\n\nExample build failure caused by it:\nhttp://logs.openstack.org/13/626613/1/check/tripleo-buildimage-overcloud-full-centos-7/e9d97b2/job-output.txt.gz\n\nSee https://github.com/ansible/ansible/issues/48313\n\nChange-Id: I608ba6801f36f834d4e82c0438b41ea1e90620e8\n'}]",0,629169,5777cfe47928064f6ea7360dfa88383429b106fd,8,9,1,24162,,,0,"Implement workaround for ansible unmount bug

It seems that unmount can falsely report success but removing it from
fstab seems to be a way to avoid that bug.

Example build failure caused by it:
http://logs.openstack.org/13/626613/1/check/tripleo-buildimage-overcloud-full-centos-7/e9d97b2/job-output.txt.gz

See https://github.com/ansible/ansible/issues/48313

Change-Id: I608ba6801f36f834d4e82c0438b41ea1e90620e8
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/69/629169/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/configure-swap/tasks/ephemeral.yaml'],1,5777cfe47928064f6ea7360dfa88383429b106fd,fix/unmount-workaround," state: ""{{ item }}"" with_items: - unmounted - absent # ^ https://github.com/ansible/ansible/issues/48313", state: unmounted,5,1
openstack%2Fpython-dracclient~master~Id2a9b1f54cfdbc9aee42f6fb4a6867fbd1cd824c,openstack/python-dracclient,master,Id2a9b1f54cfdbc9aee42f6fb4a6867fbd1cd824c,Updated is_boss_controller method with appropriate validation using controller's product name,ABANDONED,2019-01-04 07:58:02.000000000,2019-01-08 14:32:25.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-04 07:58:02.000000000', 'files': ['dracclient/resources/raid.py'], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/81879e043f93345086a0a66182954c85bb341d0a', 'message': ""Updated is_boss_controller method with appropriate validation using controller's product name\n\nChange-Id: Id2a9b1f54cfdbc9aee42f6fb4a6867fbd1cd824c\n""}]",0,628352,81879e043f93345086a0a66182954c85bb341d0a,3,1,1,29405,,,0,"Updated is_boss_controller method with appropriate validation using controller's product name

Change-Id: Id2a9b1f54cfdbc9aee42f6fb4a6867fbd1cd824c
",git fetch https://review.opendev.org/openstack/python-dracclient refs/changes/52/628352/1 && git format-patch -1 --stdout FETCH_HEAD,['dracclient/resources/raid.py'],1,81879e043f93345086a0a66182954c85bb341d0a,is_boss_controller_support," disk_controllers = self.list_raid_controllers() boss_controller = [controller.id for controller in disk_controllers if ""BOSS"" in controller.model and controller.id == raid_controller_fqdd] if boss_controller: return True else: return False", return raid_controller_fqdd.startswith('AHCI.'),9,1
openstack%2Fsahara-plugin-ambari~master~I0f616b96aaf98c051cd3653ca394f09ffc0c7c73,openstack/sahara-plugin-ambari,master,I0f616b96aaf98c051cd3653ca394f09ffc0c7c73,Add .gitreview and basic Zuul jobs,MERGED,2019-01-07 23:24:04.000000000,2019-01-08 14:27:41.000000000,2019-01-08 14:27:41.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 23:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-plugin-ambari/commit/aa33e48d356c3df050705cac282be592c78b82bd', 'message': 'Add .gitreview and basic Zuul jobs\n\nPEP8, unit tests, etc.\n\nChange-Id: I0f616b96aaf98c051cd3653ca394f09ffc0c7c73\n'}, {'number': 2, 'created': '2019-01-07 23:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-plugin-ambari/commit/fb15186ef4299ad7e800aa52075f996fb11e9d27', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: I0f616b96aaf98c051cd3653ca394f09ffc0c7c73\n'}, {'number': 3, 'created': '2019-01-07 23:57:39.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-ambari/commit/c54d78fe347bd6c97909023cf3d7964146d69062', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: I0f616b96aaf98c051cd3653ca394f09ffc0c7c73\n'}]",0,629069,c54d78fe347bd6c97909023cf3d7964146d69062,10,2,3,10459,,,0,"Add .gitreview and basic Zuul jobs

Most important tempest-plugin-jobs, which looks like openstack-python-jobs
but without the py27 job, which is failing right now (waiting for
the sahara patch which exports the plugin interface).

Change-Id: I0f616b96aaf98c051cd3653ca394f09ffc0c7c73
",git fetch https://review.opendev.org/openstack/sahara-plugin-ambari refs/changes/69/629069/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,aa33e48d356c3df050705cac282be592c78b82bd,,- project: templates: - openstack-lower-constraints-jobs - openstack-python-jobs - openstack-python35-jobs - openstack-python36-jobs - periodic-stable-jobs - publish-openstack-docs-pti - check-requirements - release-notes-jobs-python3 ,,14,0
openstack%2Frpm-packaging~master~I97a40f13fd88b21a53d677f98dc83c5e3c48fb53,openstack/rpm-packaging,master,I97a40f13fd88b21a53d677f98dc83c5e3c48fb53,monasca-ceilometer: Fix name of dependency,MERGED,2019-01-08 12:51:30.000000000,2019-01-08 14:26:33.000000000,2019-01-08 14:26:33.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-08 12:51:30.000000000', 'files': ['openstack/monasca-ceilometer/monasca-ceilometer.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4df24477abc65fd037a0fb40eae8926e5837c38b', 'message': ""monasca-ceilometer: Fix name of dependency\n\nThe subunit package is actually called 'python-python-subunit'.\n\nChange-Id: I97a40f13fd88b21a53d677f98dc83c5e3c48fb53\n""}]",0,629170,4df24477abc65fd037a0fb40eae8926e5837c38b,9,5,1,8482,,,0,"monasca-ceilometer: Fix name of dependency

The subunit package is actually called 'python-python-subunit'.

Change-Id: I97a40f13fd88b21a53d677f98dc83c5e3c48fb53
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/70/629170/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-ceilometer/monasca-ceilometer.spec.j2'],1,4df24477abc65fd037a0fb40eae8926e5837c38b,monasca-test,Requires: {{ py2pkg('python-subunit') }},Requires: {{ py2pkg('subunit') }},1,1
openstack%2Fopenstack-ansible-os_horizon~stable%2Frocky~I607546949d1df8e3caa2b240f1fe779377ce14e0,openstack/openstack-ansible-os_horizon,stable/rocky,I607546949d1df8e3caa2b240f1fe779377ce14e0,Rename SUSE vpnaas-ui package,MERGED,2018-12-23 13:44:35.000000000,2019-01-08 14:24:25.000000000,2018-12-30 20:22:16.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-23 13:44:35.000000000', 'files': ['vars/suse-42.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/b6eb4f1caf5b59fff84ee204f1c59ad0a3f54b42', 'message': 'Rename SUSE vpnaas-ui package\n\nThe package has been renamed, affecting both master and rocky.\n\nChange-Id: I607546949d1df8e3caa2b240f1fe779377ce14e0\nRelated-Bug: #1809460\n(cherry picked from commit 6c9285f5e02c444c4610282880c2521f05f93956)\n'}]",0,627074,b6eb4f1caf5b59fff84ee204f1c59ad0a3f54b42,22,5,1,25023,,,0,"Rename SUSE vpnaas-ui package

The package has been renamed, affecting both master and rocky.

Change-Id: I607546949d1df8e3caa2b240f1fe779377ce14e0
Related-Bug: #1809460
(cherry picked from commit 6c9285f5e02c444c4610282880c2521f05f93956)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/74/627074/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/suse-42.yml'],1,b6eb4f1caf5b59fff84ee204f1c59ad0a3f54b42,bug/1809460, - python-neutron-vpnaas-dashboard, - openstack-horizon-plugin-neutron-vpnaas-ui,1,1
openstack%2Fopenstack-helm~master~Ifd496299763d54aab27ffa463a78c46407bd9b35,openstack/openstack-helm,master,Ifd496299763d54aab27ffa463a78c46407bd9b35,WIP: Update ironic multinode periodic check nodeset,ABANDONED,2018-12-12 15:22:01.000000000,2019-01-08 14:20:27.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-12 15:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/735535ce0783fa95f9bd753039890eb132454f29', 'message': 'Update ironic multinode periodic check nodeset\n\nThis updates the nodeset used for the ironic multinode periodic\ncheck to the five node ubuntu nodeset used for the other\nmultinode jobs\n\nChange-Id: Ifd496299763d54aab27ffa463a78c46407bd9b35\n'}, {'number': 2, 'created': '2018-12-12 15:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1cfa9bab9c39b7bba63f94cbad46a7d3a8521725', 'message': 'WIP: Update ironic multinode periodic check nodeset\n\nThis updates the nodeset used for the ironic multinode periodic\ncheck to the five node ubuntu nodeset used for the other\nmultinode jobs\n\nChange-Id: Ifd496299763d54aab27ffa463a78c46407bd9b35\n'}, {'number': 3, 'created': '2018-12-17 16:11:35.000000000', 'files': ['tools/deployment/baremetal/110-compute-kit.sh', 'zuul.d/project.yaml', 'zuul.d/jobs-openstack-helm.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e37b7aa711e765bec4238e87837bf7fde3587a42', 'message': 'WIP: Update ironic multinode periodic check nodeset\n\nThis updates the nodeset used for the ironic multinode periodic\ncheck to the five node ubuntu nodeset used for the other\nmultinode jobs\n\nChange-Id: Ifd496299763d54aab27ffa463a78c46407bd9b35\n'}]",0,624734,e37b7aa711e765bec4238e87837bf7fde3587a42,14,2,3,17591,,,0,"WIP: Update ironic multinode periodic check nodeset

This updates the nodeset used for the ironic multinode periodic
check to the five node ubuntu nodeset used for the other
multinode jobs

Change-Id: Ifd496299763d54aab27ffa463a78c46407bd9b35
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/34/624734/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs-openstack-helm.yaml'],1,735535ce0783fa95f9bd753039890eb132454f29,gate/update_baremetal, nodeset: openstack-helm-five-node-ubuntu, nodeset: openstack-helm-ubuntu,1,1
openstack%2Fkuryr-kubernetes~master~I1055e0b9943d8bf21966e960654552b97720b60d,openstack/kuryr-kubernetes,master,I1055e0b9943d8bf21966e960654552b97720b60d,Use default subnet if another is not specified in NAD,MERGED,2018-12-28 11:12:15.000000000,2019-01-08 14:19:13.000000000,2019-01-08 14:19:13.000000000,"[{'_account_id': 11600}, {'_account_id': 14885}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 24604}, {'_account_id': 28396}]","[{'number': 1, 'created': '2018-12-28 11:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/3d5c13945c3689ff57f2bb17f443ec61a7f485ca', 'message': ""Use default subnet if another in not specified in NAD\n\nThis commit adds check of 'subnetId' field in used\nnet-attach-def. If 'subnetId' is not specified, default\nsubnet will be used.\n\nChange-Id: I1055e0b9943d8bf21966e960654552b97720b60d\nSigned-off-by: Danil Golov <d.golov@samsung.com>\n""}, {'number': 2, 'created': '2019-01-02 22:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/e23bc35d6e82f4d027f40a6c9e31d855158d2e85', 'message': ""Use default subnet if another is not specified in NAD\n\nThis commit adds check of 'subnetId' field in used\nnet-attach-def. If 'subnetId' is not specified, default\nsubnet will be used.\n\nChange-Id: I1055e0b9943d8bf21966e960654552b97720b60d\nFixes-Bug: https://bugs.launchpad.net/kuryr-kubernetes/+bug/1810344\nSigned-off-by: Danil Golov <d.golov@samsung.com>\n""}, {'number': 3, 'created': '2019-01-03 12:27:31.000000000', 'files': ['kuryr_kubernetes/controller/drivers/multi_vif.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/558eff14252eee86f87f68561b1167fa9425502e', 'message': ""Use default subnet if another is not specified in NAD\n\nThis commit adds check of 'subnetId' field in used\nnet-attach-def. If 'subnetId' is not specified, default\nsubnet will be used.\n\nChange-Id: I1055e0b9943d8bf21966e960654552b97720b60d\nCloses-Bug: 1810344\n""}]",2,627623,558eff14252eee86f87f68561b1167fa9425502e,31,6,3,24604,,,0,"Use default subnet if another is not specified in NAD

This commit adds check of 'subnetId' field in used
net-attach-def. If 'subnetId' is not specified, default
subnet will be used.

Change-Id: I1055e0b9943d8bf21966e960654552b97720b60d
Closes-Bug: 1810344
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/23/627623/2 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/drivers/multi_vif.py'],1,3d5c13945c3689ff57f2bb17f443ec61a7f485ca,bug/1810344,"from kuryr_kubernetes import config as kuryr_config subnet_id = config.get( constants.K8S_ANNOTATION_NPWG_CRD_SUBNET_ID, kuryr_config.CONF.neutron_defaults.pod_subnet )", subnet_id = config[constants.K8S_ANNOTATION_NPWG_CRD_SUBNET_ID],5,1
openstack%2Fcinder-specs~master~I840381e8205d1724cb53fce747a8f183c8f9cf8c,openstack/cinder-specs,master,I840381e8205d1724cb53fce747a8f183c8f9cf8c,Add Train specs directory,MERGED,2018-11-14 05:12:00.000000000,2019-01-08 14:14:03.000000000,2019-01-08 14:14:03.000000000,"[{'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 23083}, {'_account_id': 28239}]","[{'number': 1, 'created': '2018-11-14 05:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/e3d8d9704e3be717c0f3c1730cd2413ed4956490', 'message': 'Add placeholder for Train specs\n\nThe ""T"" release of OpenStack is officially ""Train"".\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-November/136464.html\n\nChange-Id: I840381e8205d1724cb53fce747a8f183c8f9cf8c\n'}, {'number': 2, 'created': '2018-11-14 05:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/668e739633ca2ccb8259a4c2976e92e91d31d18b', 'message': 'Add Train specs directory\n\nThe ""T"" release of OpenStack is officially ""Train"".\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-November/136464.html\n\nChange-Id: I840381e8205d1724cb53fce747a8f183c8f9cf8c\n'}, {'number': 3, 'created': '2018-12-17 12:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/57ac815d1e24c74ba625b24eec7a712c308f3243', 'message': 'Add Train specs directory\n\nThe ""T"" release of OpenStack is officially ""Train"".\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-November/136464.html\n\nChange-Id: I840381e8205d1724cb53fce747a8f183c8f9cf8c\n'}, {'number': 4, 'created': '2018-12-26 01:44:36.000000000', 'files': ['doc/source/index.rst', 'specs/train/.placeholder'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/2663a9b4f23e4099c4919d233b092080819c1eb4', 'message': 'Add Train specs directory\n\nThe ""T"" release of OpenStack is officially ""Train"".\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-November/136464.html\n\nChange-Id: I840381e8205d1724cb53fce747a8f183c8f9cf8c\n'}]",0,617874,2663a9b4f23e4099c4919d233b092080819c1eb4,16,11,4,27153,,,0,"Add Train specs directory

The ""T"" release of OpenStack is officially ""Train"".

http://lists.openstack.org/pipermail/openstack-dev/2018-November/136464.html

Change-Id: I840381e8205d1724cb53fce747a8f183c8f9cf8c
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/74/617874/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/train/.placeholder']",2,e3d8d9704e3be717c0f3c1730cd2413ed4956490,,,,8,0
openstack%2Ftripleo-common~stable%2Frocky~I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e,openstack/tripleo-common,stable/rocky,I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e,Fail node cleaning on timeout,MERGED,2019-01-07 13:45:18.000000000,2019-01-08 14:09:10.000000000,2019-01-08 14:09:10.000000000,"[{'_account_id': 1926}, {'_account_id': 3153}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-07 13:45:18.000000000', 'files': ['workbooks/baremetal.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0e1368bfedf82b20dfb881868a89652cbfd83163', 'message': 'Fail node cleaning on timeout\n\nThe Use of a retry with continue-on causes the task\nwait_for_provision_state to finish in success. We need another\ntask to test the provisioning state and conditionally fail\nbased on that.\n\nCloses-Bug: #1796293\nChange-Id: I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e\n(cherry picked from commit 70ed6378186dca5735f7ff8f51190de7eb7bf3ca)\n'}]",1,628968,0e1368bfedf82b20dfb881868a89652cbfd83163,14,7,1,21909,,,0,"Fail node cleaning on timeout

The Use of a retry with continue-on causes the task
wait_for_provision_state to finish in success. We need another
task to test the provisioning state and conditionally fail
based on that.

Closes-Bug: #1796293
Change-Id: I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e
(cherry picked from commit 70ed6378186dca5735f7ff8f51190de7eb7bf3ca)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/68/628968/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/baremetal.yaml'],1,0e1368bfedf82b20dfb881868a89652cbfd83163,bug/1796293-stable/rocky, on-complete: - send_message: <% task().result.provision_state = 'manageable' %> - state_not_reached: <% task().result.provision_state != 'manageable' %> state_not_reached: publish: status: FAILED message: Cleaning of node <% $.node_uuid %> timed out. on-complete: send_message, on-success: send_message,9,1
openstack%2Fpuppet-tripleo~master~I5dedb09a14e57509136e4f98520e8a7503a49f23,openstack/puppet-tripleo,master,I5dedb09a14e57509136e4f98520e8a7503a49f23,Replace tripleo scenario004-multinode with scenario004-standalone,MERGED,2018-12-27 13:09:14.000000000,2019-01-08 14:09:09.000000000,2019-01-08 14:09:09.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 8871}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-12-27 13:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/33e7017c1b9ed2e561b80e1cce3f359419bd1016', 'message': 'Replace tripleo scenario004-multinode with scenario004-standalone\n\nMore info and tracked by tripleo ci squad at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/us/534\n\nChange-Id: I5dedb09a14e57509136e4f98520e8a7503a49f23\n'}, {'number': 2, 'created': '2018-12-28 15:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1cf93864e3585f84e691f7f228c0ea9cd5aa1c29', 'message': 'Replace tripleo scenario004-multinode with scenario004-standalone\n\nMore info and tracked by tripleo ci squad at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/us/534\n\nChange-Id: I5dedb09a14e57509136e4f98520e8a7503a49f23\n'}, {'number': 3, 'created': '2019-01-04 14:22:35.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/20612955fecf2ec3ab0aa59c5b6f069f8851c4f9', 'message': 'Replace tripleo scenario004-multinode with scenario004-standalone\n\nMore info and tracked by tripleo ci squad at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/us/534\n\nChange-Id: I5dedb09a14e57509136e4f98520e8a7503a49f23\n'}]",0,627521,20612955fecf2ec3ab0aa59c5b6f069f8851c4f9,37,10,3,8449,,,0,"Replace tripleo scenario004-multinode with scenario004-standalone

More info and tracked by tripleo ci squad at [1]

[1] https://tree.taiga.io/project/tripleo-ci-board/us/534

Change-Id: I5dedb09a14e57509136e4f98520e8a7503a49f23
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/21/627521/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,33e7017c1b9ed2e561b80e1cce3f359419bd1016,replace-scen4, - tripleo-ci-centos-7-scenario004-standalone:, - tripleo-ci-centos-7-scenario004-multinode-oooq-container:,1,1
openstack%2Ftripleo-heat-templates~master~I58482996b8df5989a0ab0402abc1622f436927cd,openstack/tripleo-heat-templates,master,I58482996b8df5989a0ab0402abc1622f436927cd,Fix scenario001-standalone missing aodh/ceilo/heat/gnocchi services,MERGED,2019-01-02 12:44:10.000000000,2019-01-08 14:06:01.000000000,2019-01-08 14:06:01.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 8871}, {'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-01-02 12:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/02063fc460572c38a9c6c09b8b078d871ccc0138', 'message': 'Fix scenario001-standalone missing aodh/ceilo/heat/gnocchi services\n\nAs tracked by ci squad in [1] we are missing some of the scenario 1\nservices as they are overridden by the default standalone deploy\nenvironment which explicitly sets these are OS::Heat::None [2]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/task/448\n[2] https://github.com/openstack/tripleo-heat-templates/blob/18d77c17045b82e82b4a5b3880605e8a2154c3e6/environments/standalone/standalone-tripleo.yaml#L60\n\nChange-Id: I58482996b8df5989a0ab0402abc1622f436927cd\n'}, {'number': 2, 'created': '2019-01-03 07:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bb74c4f38409db8bbfee89c74f7f988c0688bacf', 'message': 'Fix scenario001-standalone missing aodh/ceilo/heat/gnocchi services\n\nAs tracked by ci squad in [1] we are missing some of the scenario 1\nservices as they are overridden by the default standalone deploy\nenvironment which explicitly sets these are OS::Heat::None [2]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/task/448\n[2] https://github.com/openstack/tripleo-heat-templates/blob/18d77c17045b82e82b4a5b3880605e8a2154c3e6/environments/standalone/standalone-tripleo.yaml#L60\n\nChange-Id: I58482996b8df5989a0ab0402abc1622f436927cd\n'}, {'number': 3, 'created': '2019-01-04 11:19:00.000000000', 'files': ['ci/environments/scenario001-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4c5b528f8495cf8285957e21ab6f3c133feff945', 'message': ""Fix scenario001-standalone missing aodh/ceilo/heat/gnocchi services\n\nAs tracked by ci squad in [1] we are missing some of the scenario 1\nservices as they are overridden by the default standalone deploy\nenvironment which explicitly sets these are OS::Heat::None [2].\n\nThis also disables swift and horizon as they aren't in scenario001\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/task/448\n[2] https://github.com/openstack/tripleo-heat-templates/blob/18d77c17045b82e82b4a5b3880605e8a2154c3e6/environments/standalone/standalone-tripleo.yaml#L60\n\nChange-Id: I58482996b8df5989a0ab0402abc1622f436927cd\n""}]",6,627965,4c5b528f8495cf8285957e21ab6f3c133feff945,22,9,3,8449,,,0,"Fix scenario001-standalone missing aodh/ceilo/heat/gnocchi services

As tracked by ci squad in [1] we are missing some of the scenario 1
services as they are overridden by the default standalone deploy
environment which explicitly sets these are OS::Heat::None [2].

This also disables swift and horizon as they aren't in scenario001

[1] https://tree.taiga.io/project/tripleo-ci-board/task/448
[2] https://github.com/openstack/tripleo-heat-templates/blob/18d77c17045b82e82b4a5b3880605e8a2154c3e6/environments/standalone/standalone-tripleo.yaml#L60

Change-Id: I58482996b8df5989a0ab0402abc1622f436927cd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/65/627965/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/standalone/standalone-tripleo.yaml', 'ci/environments/scenario001-standalone.yaml']",2,02063fc460572c38a9c6c09b8b078d871ccc0138,fix-scen1, OS::TripleO::Services::AodhApi: ../../deployment/aodh/aodh-api-container-puppet.yaml OS::TripleO::Services::AodhEvaluator: ../../deployment/aodh/aodh-evaluator-container-puppet.yaml OS::TripleO::Services::AodhListener: ../../deployment/aodh/aodh-listener-container-puppet.yaml OS::TripleO::Services::AodhNotifier: ../../deployment/aodh/aodh-notifier-container-puppet.yaml OS::TripleO::Services::CeilometerAgentCentral: ../../docker/services/ceilometer-agent-central.yaml OS::TripleO::Services::CeilometerAgentNotification: ../../docker/services/ceilometer-agent-notification.yaml OS::TripleO::Services::ComputeCeilometerAgent: ../../docker/services/ceilometer-agent-compute.yaml OS::TripleO::Services::GnocchiApi: ../../docker/services/gnocchi-api.yaml OS::TripleO::Services::GnocchiMetricd: ../../docker/services/gnocchi-metricd.yaml OS::TripleO::Services::GnocchiStatsd: ../../docker/services/gnocchi-statsd.yaml OS::TripleO::Services::HeatApi: ../../docker/services/heat-api.yaml OS::TripleO::Services::HeatApiCfn: ../../docker/services/heat-api-cfn.yaml OS::TripleO::Services::HeatApiCloudwatch: ../../puppet/services/disabled/heat-api-cloudwatch-disabled.yaml OS::TripleO::Services::HeatEngine: ../../docker/services/heat-engine.yaml ManagePipeline: true PipelinePublishers: - gnocchi://?archive_policy=ceilometer-high-rate EventPipelinePublishers: - gnocchi://?archive_policy=ceilometer-high-rate - panko:// GnocchiArchivePolicy: 'ceilometer-high-rate', GnocchiArchivePolicy: 'high',24,3
openstack%2Fpuppet-tripleo~stable%2Frocky~Icd199ca4ce4848c971488d8ab69e668add86b150,openstack/puppet-tripleo,stable/rocky,Icd199ca4ce4848c971488d8ab69e668add86b150,Remove some of the excessive rabbitmq bundle logging,MERGED,2018-12-20 15:29:19.000000000,2019-01-08 14:06:00.000000000,2019-01-08 14:06:00.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-12-20 15:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4cebc8b0ee484a244139f3431860c8438739b3cf', 'message': 'Remove some of the excessive rabbitmq bundle logging\n\nBy removing the pam-systemd optinal session line we get rid of the\nfollowing line:\npam_systemd(su:session): Failed to connect to system bus: No such file or directory\n\nIt is useless inside a container anyway since the pam_systemd module\nregisters user sessions.\n\nBy adding a sufficient pam_succeed_if call fo when the user belongs to the\nrabbitmq group we get rid of the following spurious log:\nOct 23 13:52:52 overcloud-controller-0 su: pam_unix(su:session): session opened for user rabbitmq by (uid=0)\nOct 23 13:52:54 overcloud-controller-0 su: pam_unix(su:session): session closed for user rabbitmq\n\nWe do not need this inside a container anyway. In the future (w/\npam_unix 1.2.0 and onwards we will be able to use the quiet option\ninstead).\n\nNB: cherry-pick not %100 clean due to slightly changed diff context\n\nDepends-On: Ic0789da4645a4ee186d82ad7d943de78d4d5c443\n\nChange-Id: Icd199ca4ce4848c971488d8ab69e668add86b150\nRelated-Bug: #1806451\n(cherry picked from commit 44985bd42d21ce705387c01b188f27711791f51f)\n'}, {'number': 2, 'created': '2019-01-07 07:42:30.000000000', 'files': ['manifests/profile/pacemaker/rabbitmq_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/608096fb3ce3cf291550278c39be3b0562bd18eb', 'message': 'Remove some of the excessive rabbitmq bundle logging\n\nBy removing the pam-systemd optinal session line we get rid of the\nfollowing line:\npam_systemd(su:session): Failed to connect to system bus: No such file or directory\n\nIt is useless inside a container anyway since the pam_systemd module\nregisters user sessions.\n\nBy adding a sufficient pam_succeed_if call fo when the user belongs to the\nrabbitmq group we get rid of the following spurious log:\nOct 23 13:52:52 overcloud-controller-0 su: pam_unix(su:session): session opened for user rabbitmq by (uid=0)\nOct 23 13:52:54 overcloud-controller-0 su: pam_unix(su:session): session closed for user rabbitmq\n\nWe do not need this inside a container anyway. In the future (w/\npam_unix 1.2.0 and onwards we will be able to use the quiet option\ninstead).\n\nNB: cherry-pick not %100 clean due to slightly changed diff context\n\nDepends-On: Ic0789da4645a4ee186d82ad7d943de78d4d5c443\n\nChange-Id: Icd199ca4ce4848c971488d8ab69e668add86b150\nRelated-Bug: #1806451\n(cherry picked from commit 44985bd42d21ce705387c01b188f27711791f51f)\n'}]",0,626597,608096fb3ce3cf291550278c39be3b0562bd18eb,18,6,2,20172,,,0,"Remove some of the excessive rabbitmq bundle logging

By removing the pam-systemd optinal session line we get rid of the
following line:
pam_systemd(su:session): Failed to connect to system bus: No such file or directory

It is useless inside a container anyway since the pam_systemd module
registers user sessions.

By adding a sufficient pam_succeed_if call fo when the user belongs to the
rabbitmq group we get rid of the following spurious log:
Oct 23 13:52:52 overcloud-controller-0 su: pam_unix(su:session): session opened for user rabbitmq by (uid=0)
Oct 23 13:52:54 overcloud-controller-0 su: pam_unix(su:session): session closed for user rabbitmq

We do not need this inside a container anyway. In the future (w/
pam_unix 1.2.0 and onwards we will be able to use the quiet option
instead).

NB: cherry-pick not %100 clean due to slightly changed diff context

Depends-On: Ic0789da4645a4ee186d82ad7d943de78d4d5c443

Change-Id: Icd199ca4ce4848c971488d8ab69e668add86b150
Related-Bug: #1806451
(cherry picked from commit 44985bd42d21ce705387c01b188f27711791f51f)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/97/626597/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/rabbitmq_bundle.pp'],1,4cebc8b0ee484a244139f3431860c8438739b3cf,bug/1806451," file_line { 'rabbitmq-pamd-systemd': ensure => absent, path => '/etc/pam.d/system-auth', match => '^-session\s+optional\s+pam_systemd.so', match_for_absence => true, } # Note that once we move to RHEL8 where pam_unix.so supports the quiet option # we can just add quiet to the pam_unix option for the session module and remove this one file_line { 'rabbitmq-pamd-succeed': ensure => present, path => '/etc/pam.d/system-auth', line => 'session sufficient pam_succeed_if.so quiet_success user ingroup rabbitmq', after => '^session.*pam_limits.so' }",,14,0
openstack%2Fdiskimage-builder~master~I145b3349feba9386f5cb7271a7ecd0151aa38b70,openstack/diskimage-builder,master,I145b3349feba9386f5cb7271a7ecd0151aa38b70,Use template for lower-constraints,MERGED,2018-12-20 20:56:21.000000000,2019-01-08 14:04:52.000000000,2019-01-08 14:04:52.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-20 20:56:21.000000000', 'files': ['.zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1cfe812a75a3cc95e7aba75ae32c4875867a422b', 'message': 'Use template for lower-constraints\n\nUse openstack-lower-constraints-jobs template, remove individual\njobs.\n\nChange-Id: I145b3349feba9386f5cb7271a7ecd0151aa38b70\nNeeded-By: https://review.openstack.org/623229\n'}]",0,626745,1cfe812a75a3cc95e7aba75ae32c4875867a422b,18,6,1,6547,,,0,"Use template for lower-constraints

Use openstack-lower-constraints-jobs template, remove individual
jobs.

Change-Id: I145b3349feba9386f5cb7271a7ecd0151aa38b70
Needed-By: https://review.openstack.org/623229
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/45/626745/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/jobs.yaml'],1,1cfe812a75a3cc95e7aba75ae32c4875867a422b,cd/py36-lower-constraints, - openstack-lower-constraints-jobs, - openstack-tox-lower-constraints - openstack-tox-lower-constraints,1,3
openstack%2Fsahara-plugin-storm~master~I78580b2d5dd4d6a5f7b1d0661ea82736f2bd734e,openstack/sahara-plugin-storm,master,I78580b2d5dd4d6a5f7b1d0661ea82736f2bd734e,Add .gitreview and basic Zuul jobs,MERGED,2019-01-08 13:31:56.000000000,2019-01-08 14:02:14.000000000,2019-01-08 14:02:14.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 13:31:56.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-storm/commit/b6434b3aee5b0d1e537796d68ac422c922b8e4ab', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: I78580b2d5dd4d6a5f7b1d0661ea82736f2bd734e\n'}]",0,629182,b6434b3aee5b0d1e537796d68ac422c922b8e4ab,6,2,1,10459,,,0,"Add .gitreview and basic Zuul jobs

Most important tempest-plugin-jobs, which looks like openstack-python-jobs
but without the py27 job, which is failing right now (waiting for
the sahara patch which exports the plugin interface).

Change-Id: I78580b2d5dd4d6a5f7b1d0661ea82736f2bd734e
",git fetch https://review.opendev.org/openstack/sahara-plugin-storm refs/changes/82/629182/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,b6434b3aee5b0d1e537796d68ac422c922b8e4ab,,- project: templates: - tempest-plugin-jobs - release-notes-jobs-python3 ,,8,0
openstack%2Fnetworking-bgpvpn~master~I161324745ff26abc260f6b1892217f5157f01dd8,openstack/networking-bgpvpn,master,I161324745ff26abc260f6b1892217f5157f01dd8,make tempest bgpvpn tests voting again,MERGED,2019-01-08 10:27:07.000000000,2019-01-08 14:02:13.000000000,2019-01-08 14:02:13.000000000,"[{'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 10:27:07.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/40951dbb0d622c0c0f5ad6711555fe9ac1c8d3c9', 'message': 'make tempest bgpvpn tests voting again\n\nWith the resolution brought by in networking-bagpipe,\nwe can make bgpvpn tempest tests voting again.\n\nChange-Id: I161324745ff26abc260f6b1892217f5157f01dd8\nDepends-On: https://review.openstack.org/629062\nRelated-Bug: 1807152\n'}]",0,629134,40951dbb0d622c0c0f5ad6711555fe9ac1c8d3c9,8,2,1,12021,,,0,"make tempest bgpvpn tests voting again

With the resolution brought by in networking-bagpipe,
we can make bgpvpn tempest tests voting again.

Change-Id: I161324745ff26abc260f6b1892217f5157f01dd8
Depends-On: https://review.openstack.org/629062
Related-Bug: 1807152
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/34/629134/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,40951dbb0d622c0c0f5ad6711555fe9ac1c8d3c9,bug/1807152,, voting: false # until bug 1807152 is resolved voting: false # until bug 1807152 is resolved,0,2
openstack%2Fsahara-plugin-vanilla~master~I172586b5af43d49c509602558c914ce6dc0259a3,openstack/sahara-plugin-vanilla,master,I172586b5af43d49c509602558c914ce6dc0259a3,Add .gitreview and basic Zuul jobs,MERGED,2019-01-08 13:32:11.000000000,2019-01-08 14:01:03.000000000,2019-01-08 14:01:02.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 13:32:11.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-vanilla/commit/0601bdf3ce0791603e4acc39ce1213d7ecffadd2', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: I172586b5af43d49c509602558c914ce6dc0259a3\n'}]",0,629183,0601bdf3ce0791603e4acc39ce1213d7ecffadd2,6,2,1,10459,,,0,"Add .gitreview and basic Zuul jobs

Most important tempest-plugin-jobs, which looks like openstack-python-jobs
but without the py27 job, which is failing right now (waiting for
the sahara patch which exports the plugin interface).

Change-Id: I172586b5af43d49c509602558c914ce6dc0259a3
",git fetch https://review.opendev.org/openstack/sahara-plugin-vanilla refs/changes/83/629183/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,0601bdf3ce0791603e4acc39ce1213d7ecffadd2,,- project: templates: - tempest-plugin-jobs - release-notes-jobs-python3 ,,8,0
openstack%2Fsahara-plugin-cdh~master~Idd9fc7f4bfb7d014d4c977873db6831271983e5e,openstack/sahara-plugin-cdh,master,Idd9fc7f4bfb7d014d4c977873db6831271983e5e,Add .gitreview and basic Zuul jobs,MERGED,2019-01-08 13:31:09.000000000,2019-01-08 14:01:02.000000000,2019-01-08 14:01:02.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 13:31:09.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-cdh/commit/334c9eca06e505658e49c40182a9de8caf0bfab6', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: Idd9fc7f4bfb7d014d4c977873db6831271983e5e\n'}]",0,629179,334c9eca06e505658e49c40182a9de8caf0bfab6,6,2,1,10459,,,0,"Add .gitreview and basic Zuul jobs

Most important tempest-plugin-jobs, which looks like openstack-python-jobs
but without the py27 job, which is failing right now (waiting for
the sahara patch which exports the plugin interface).

Change-Id: Idd9fc7f4bfb7d014d4c977873db6831271983e5e
",git fetch https://review.opendev.org/openstack/sahara-plugin-cdh refs/changes/79/629179/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,334c9eca06e505658e49c40182a9de8caf0bfab6,,- project: templates: - tempest-plugin-jobs - release-notes-jobs-python3 ,,8,0
openstack%2Fsahara-plugin-spark~master~I66e29b723e9e0ea13e50e0264c5a089c593c77e2,openstack/sahara-plugin-spark,master,I66e29b723e9e0ea13e50e0264c5a089c593c77e2,Add .gitreview and basic Zuul jobs,MERGED,2019-01-08 13:31:40.000000000,2019-01-08 14:01:01.000000000,2019-01-08 14:01:01.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 13:31:40.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-spark/commit/5b5dcbe796467cd9551e4495d220430aabe28ec2', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: I66e29b723e9e0ea13e50e0264c5a089c593c77e2\n'}]",0,629181,5b5dcbe796467cd9551e4495d220430aabe28ec2,6,2,1,10459,,,0,"Add .gitreview and basic Zuul jobs

Most important tempest-plugin-jobs, which looks like openstack-python-jobs
but without the py27 job, which is failing right now (waiting for
the sahara patch which exports the plugin interface).

Change-Id: I66e29b723e9e0ea13e50e0264c5a089c593c77e2
",git fetch https://review.opendev.org/openstack/sahara-plugin-spark refs/changes/81/629181/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,5b5dcbe796467cd9551e4495d220430aabe28ec2,,- project: templates: - tempest-plugin-jobs - release-notes-jobs-python3 ,,8,0
openstack%2Fsahara-plugin-mapr~master~If5731e14c8c0b68a3380b31c33d0b04a5be48c6e,openstack/sahara-plugin-mapr,master,If5731e14c8c0b68a3380b31c33d0b04a5be48c6e,Add .gitreview and basic Zuul jobs,MERGED,2019-01-08 13:31:25.000000000,2019-01-08 13:59:46.000000000,2019-01-08 13:59:46.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 13:31:25.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-mapr/commit/81603e60cdd97cec60c5debc759fd827ac65da23', 'message': 'Add .gitreview and basic Zuul jobs\n\nMost important tempest-plugin-jobs, which looks like openstack-python-jobs\nbut without the py27 job, which is failing right now (waiting for\nthe sahara patch which exports the plugin interface).\n\nChange-Id: If5731e14c8c0b68a3380b31c33d0b04a5be48c6e\n'}]",0,629180,81603e60cdd97cec60c5debc759fd827ac65da23,6,2,1,10459,,,0,"Add .gitreview and basic Zuul jobs

Most important tempest-plugin-jobs, which looks like openstack-python-jobs
but without the py27 job, which is failing right now (waiting for
the sahara patch which exports the plugin interface).

Change-Id: If5731e14c8c0b68a3380b31c33d0b04a5be48c6e
",git fetch https://review.opendev.org/openstack/sahara-plugin-mapr refs/changes/80/629180/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,81603e60cdd97cec60c5debc759fd827ac65da23,,- project: templates: - tempest-plugin-jobs - release-notes-jobs-python3 ,,8,0
openstack%2Fopenstack-ansible-galera_server~master~I07fd0872a76af9dab89414207e297946e84965cf,openstack/openstack-ansible-galera_server,master,I07fd0872a76af9dab89414207e297946e84965cf,Replace /etc/my.cnf.d if it exists for SUSE/CentOS,MERGED,2019-01-08 10:28:02.000000000,2019-01-08 13:57:53.000000000,2019-01-08 13:57:53.000000000,"[{'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-08 10:28:02.000000000', 'files': ['tasks/galera_install_yum.yml', 'tasks/galera_install_zypper.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/04f655f50c04dd09194e53752c734ac4d67fce21', 'message': 'Replace /etc/my.cnf.d if it exists for SUSE/CentOS\n\nIn SUSE/CentOS systems, /etc/my.cnf.d may already exist on the\nsystem. We need to ensure that it is removed if that is true so\nthat we can replace it with symlinks to the directories expected\nto be used by the MariaDB packages instead. By replacing it with\nsymlinks, we allow anything else on the system expecting those\npaths to be in place to still work as before, but we also ensure\nthat the MariaDB package expectations are met.\n\nChange-Id: I07fd0872a76af9dab89414207e297946e84965cf\n'}]",0,629135,04f655f50c04dd09194e53752c734ac4d67fce21,7,3,1,6816,,,0,"Replace /etc/my.cnf.d if it exists for SUSE/CentOS

In SUSE/CentOS systems, /etc/my.cnf.d may already exist on the
system. We need to ensure that it is removed if that is true so
that we can replace it with symlinks to the directories expected
to be used by the MariaDB packages instead. By replacing it with
symlinks, we allow anything else on the system expecting those
paths to be in place to still work as before, but we also ensure
that the MariaDB package expectations are met.

Change-Id: I07fd0872a76af9dab89414207e297946e84965cf
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/35/629135/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_install_yum.yml', 'tasks/galera_install_zypper.yml']",2,04f655f50c04dd09194e53752c734ac4d67fce21,,"# In SUSE/CentOS systems, /etc/my.cnf.d may already exist on the # system. We need to ensure that it is removed if that is true so # that we can replace it with symlinks to the directories expected # to be used by the MariaDB packages instead. - name: Stat /etc/my.cnf.d stat: path: /etc/my.cnf.d get_attributes: no get_checksum: no get_mime: no register: mycnfd_stat - name: Destroy my.cnf.d dir if is dir file: path: /etc/my.cnf.d state: absent force: true when: - mycnfd_stat.stat.isdir is defined - mycnfd_stat.stat.isdir == True # We replace the default paths for the system with symlinks to # the paths used by the MariaDB packages so ensure that any other # system expectations are still met.",,66,7
openstack%2Fopenstack-ansible-os_neutron~master~I6c8ac020c8425b9e727b656fa4f9f0c0fdb6fab6,openstack/openstack-ansible-os_neutron,master,I6c8ac020c8425b9e727b656fa4f9f0c0fdb6fab6,Provide support for network interface mappings without override,MERGED,2018-12-08 03:21:27.000000000,2019-01-08 13:51:49.000000000,2019-01-08 13:51:49.000000000,"[{'_account_id': 1004}, {'_account_id': 7353}, {'_account_id': 16011}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-08 03:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/5566c86b5dce3bc8f59da67bf7568f4a9f0b6b5e', 'message': 'Adds ability to create multiple OVS bridges when defined\n\nThis patch implements the ability to create multiple provider bridges\nwhen defined in openstack_user_config.yml or as neutron_provider_networks\noverride.\n\nChange-Id: I6c8ac020c8425b9e727b656fa4f9f0c0fdb6fab6\n'}, {'number': 2, 'created': '2018-12-20 15:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/4d92b382882dfbfe261ea59cc4a95b9881addbea', 'message': 'Provide support for network interface mappings without override\n\nThis patch aims to provide support for network interface mappings\nwithin the provider network definitions, in conjunction with the\nprovider_networks plugin, without having to define overrides. The previous\nimplementation supported only a single provider network w/ corresponding\nmapping, while this will support multiple provider networks and respective\nmappings.\n\nDepends-On: https://review.openstack.org/#/c/626594/\nChange-Id: I6c8ac020c8425b9e727b656fa4f9f0c0fdb6fab6\n'}, {'number': 3, 'created': '2018-12-21 13:44:51.000000000', 'files': ['doc/source/app-ovn.rst', 'doc/source/app-openvswitch-dvr.rst', 'tasks/providers/setup_ovs_ovn.yml', 'releasenotes/notes/neutron-ovs-interface-mappings-789902128b82e721.yaml', 'tasks/providers/ovs_config.yml', 'tasks/providers/ovn_config.yml', 'doc/source/app-openvswitch.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/11cf1be93b26f702b34adb3ace7d0e0d8e70c30d', 'message': 'Provide support for network interface mappings without override\n\nThis patch aims to provide support for network interface mappings\nwithin the provider network definitions, in conjunction with the\nprovider_networks plugin, without having to define overrides. The previous\nimplementation supported only a single provider network w/ corresponding\nmapping, while this will support multiple provider networks and respective\nmappings.\n\nDepends-On: https://review.openstack.org/#/c/626594/\nChange-Id: I6c8ac020c8425b9e727b656fa4f9f0c0fdb6fab6\n'}]",0,623620,11cf1be93b26f702b34adb3ace7d0e0d8e70c30d,21,6,3,16011,,,0,"Provide support for network interface mappings without override

This patch aims to provide support for network interface mappings
within the provider network definitions, in conjunction with the
provider_networks plugin, without having to define overrides. The previous
implementation supported only a single provider network w/ corresponding
mapping, while this will support multiple provider networks and respective
mappings.

Depends-On: https://review.openstack.org/#/c/626594/
Change-Id: I6c8ac020c8425b9e727b656fa4f9f0c0fdb6fab6
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/20/623620/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/providers/setup_ovs_ovn.yml', 'tasks/providers/ovs_config.yml']",2,5566c86b5dce3bc8f59da67bf7568f4a9f0b6b5e,bridge-mapping," bridge: ""{{ mapping.split(':')[1] }}"" with_items: ""{{ neutron_provider_networks.network_mappings.split(',') }}"" loop_control: loop_var: mapping"," bridge: ""{{ neutron_provider_networks.network_mappings.split(':')[1] }}""",10,2
openstack%2Fcharm-openstack-dashboard~master~Icc046ecbafe626d6af68bf65c0f62c424d370b2c,openstack/charm-openstack-dashboard,master,Icc046ecbafe626d6af68bf65c0f62c424d370b2c,Enable fwaas dashboard for >= Queens,MERGED,2018-12-14 10:58:25.000000000,2019-01-08 13:39:22.000000000,2019-01-08 13:39:22.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-14 10:58:25.000000000', 'files': ['hooks/horizon_utils.py', 'unit_tests/test_horizon_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/f365df6f0d35a9ac9c4e9b3ea314e88e356600f2', 'message': 'Enable fwaas dashboard for >= Queens\n\nOpenStack Queens or later requires the installation of the dashboard\npackage for FWaaS to expose this feature in Horizon.\n\nChange-Id: Icc046ecbafe626d6af68bf65c0f62c424d370b2c\nCloses-Bug: 1808168\n'}]",0,625212,f365df6f0d35a9ac9c4e9b3ea314e88e356600f2,11,4,1,935,,,0,"Enable fwaas dashboard for >= Queens

OpenStack Queens or later requires the installation of the dashboard
package for FWaaS to expose this feature in Horizon.

Change-Id: Icc046ecbafe626d6af68bf65c0f62c424d370b2c
Closes-Bug: 1808168
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/12/625212/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_utils.py', 'unit_tests/test_horizon_utils.py']",2,f365df6f0d35a9ac9c4e9b3ea314e88e356600f2,bug/1808168," 'python-heat-dashboard', 'python-neutron-fwaas-dashboard']))", 'python-heat-dashboard'])),3,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Ia553a60f57bdcd762dc0b92ebd64b91327261815,openstack/tripleo-heat-templates,stable/queens,Ia553a60f57bdcd762dc0b92ebd64b91327261815,Move [neutron] auth_url to KeystoneV3Internal,MERGED,2019-01-04 11:30:36.000000000,2019-01-08 13:33:12.000000000,2019-01-08 13:33:12.000000000,"[{'_account_id': 360}, {'_account_id': 10873}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-01-04 11:30:36.000000000', 'files': ['puppet/services/nova-base.yaml', 'releasenotes/notes/nova_change_neutron_auth_url_to_internal_endpoint-aaf0e550750335eb.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/86074ef418216816f2d0d7454093515e246b5c13', 'message': 'Move [neutron] auth_url to KeystoneV3Internal\n\nIn other sections we already use the internal endpoints for\nauthentication urls. With this change the auth_uri in the neutron\nsection gets moved from KeystoneV3Admin to KeystoneV3Internal.\n\nChange-Id: Ia553a60f57bdcd762dc0b92ebd64b91327261815\n(cherry picked from commit 228710fa21749f4d6ac2830cd6bdcd19d841fca7)\n(cherry picked from commit 7e9adc62e874c98736361709748e6f29ed6c890a)\n'}]",0,628404,86074ef418216816f2d0d7454093515e246b5c13,11,8,1,17216,,,0,"Move [neutron] auth_url to KeystoneV3Internal

In other sections we already use the internal endpoints for
authentication urls. With this change the auth_uri in the neutron
section gets moved from KeystoneV3Admin to KeystoneV3Internal.

Change-Id: Ia553a60f57bdcd762dc0b92ebd64b91327261815
(cherry picked from commit 228710fa21749f4d6ac2830cd6bdcd19d841fca7)
(cherry picked from commit 7e9adc62e874c98736361709748e6f29ed6c890a)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/04/628404/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/nova-base.yaml', 'releasenotes/notes/nova_change_neutron_auth_url_to_internal_endpoint-aaf0e550750335eb.yaml']",2,86074ef418216816f2d0d7454093515e246b5c13,auth_url_internal-queens,--- fixes: - | In other sections we already use the internal endpoints for authentication urls. With this change the auth_uri in the neutron section gets moved from KeystoneV3Admin to KeystoneV3Internal. ,,8,1
openstack%2Fopenstack-ansible-os_horizon~master~I607546949d1df8e3caa2b240f1fe779377ce14e0,openstack/openstack-ansible-os_horizon,master,I607546949d1df8e3caa2b240f1fe779377ce14e0,Rename SUSE vpnaas-ui package,MERGED,2018-12-21 14:05:28.000000000,2019-01-08 13:24:29.000000000,2018-12-21 16:36:17.000000000,"[{'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 14:05:28.000000000', 'files': ['vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/6c9285f5e02c444c4610282880c2521f05f93956', 'message': 'Rename SUSE vpnaas-ui package\n\nThe package has been renamed, affecting both master and rocky.\n\nChange-Id: I607546949d1df8e3caa2b240f1fe779377ce14e0\nRelated-Bug: #1809460\n'}]",0,626902,6c9285f5e02c444c4610282880c2521f05f93956,9,3,1,6816,,,0,"Rename SUSE vpnaas-ui package

The package has been renamed, affecting both master and rocky.

Change-Id: I607546949d1df8e3caa2b240f1fe779377ce14e0
Related-Bug: #1809460
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/02/626902/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/suse.yml'],1,6c9285f5e02c444c4610282880c2521f05f93956,bug/1809460, - python-neutron-vpnaas-dashboard, - openstack-horizon-plugin-neutron-vpnaas-ui,1,1
openstack%2Fnetworking-bgpvpn~master~I4b31e7747f0bb0f0ec5b739a9854f0fe3288427b,openstack/networking-bgpvpn,master,I4b31e7747f0bb0f0ec5b739a9854f0fe3288427b,DNM: Test CI on master branch,ABANDONED,2018-11-26 16:10:51.000000000,2019-01-08 13:20:34.000000000,,"[{'_account_id': 1736}, {'_account_id': 5367}, {'_account_id': 8871}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-26 16:10:51.000000000', 'files': ['networking_bgpvpn/tests/unit/services/test_plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/46c44fd66a3e463af3a9c1ce4f34f73134911779', 'message': 'DNM: Test CI on master branch\n\nDO NOT MERGE\n\nThis is a dummy change to test the CI on master.\n\nChange-Id: I4b31e7747f0bb0f0ec5b739a9854f0fe3288427b\n'}]",0,620098,46c44fd66a3e463af3a9c1ce4f34f73134911779,20,5,1,5367,,,0,"DNM: Test CI on master branch

DO NOT MERGE

This is a dummy change to test the CI on master.

Change-Id: I4b31e7747f0bb0f0ec5b739a9854f0fe3288427b
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/98/620098/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bgpvpn/tests/unit/services/test_plugin.py'],1,46c44fd66a3e463af3a9c1ce4f34f73134911779,ci-test,# dummy change,,1,0
openstack%2Fnetworking-bgpvpn~master~I0499986e5a63fa29798bb341139f61a1e402efb3,openstack/networking-bgpvpn,master,I0499986e5a63fa29798bb341139f61a1e402efb3,WIP: increase ssh timeout,ABANDONED,2018-12-10 18:41:12.000000000,2019-01-08 13:18:20.000000000,,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28961}]","[{'number': 1, 'created': '2018-12-10 18:41:12.000000000', 'files': ['networking_bgpvpn_tempest/tests/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/f6edf41c91f1500392ebab80fb6b206190892268', 'message': 'WIP: increase ssh timeout\n\nChange-Id: I0499986e5a63fa29798bb341139f61a1e402efb3\n'}]",0,624159,f6edf41c91f1500392ebab80fb6b206190892268,6,3,1,17685,,,0,"WIP: increase ssh timeout

Change-Id: I0499986e5a63fa29798bb341139f61a1e402efb3
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/59/624159/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bgpvpn_tempest/tests/scenario/manager.py'],1,f6edf41c91f1500392ebab80fb6b206190892268,," password=password, ssh_timeout=360)", password=password),2,1
openstack%2Fpython-monascaclient~master~I1c04fbf73d1fc44da7738c8f22296992d2e7a4f8,openstack/python-monascaclient,master,I1c04fbf73d1fc44da7738c8f22296992d2e7a4f8,Return status from running command,MERGED,2019-01-04 11:54:43.000000000,2019-01-08 13:14:25.000000000,2019-01-08 13:14:25.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-01-04 11:54:43.000000000', 'files': ['monascaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/0b14b4d492386938788efe83fc5acc9f833b6f3c', 'message': 'Return status from running command\n\nThis way when someone use code like `sys.exit(main())` it will have\nproper exit code on error (so different than `0`).\n\nStory: 2001246\nTask: 5776\n\nChange-Id: I1c04fbf73d1fc44da7738c8f22296992d2e7a4f8\n'}]",0,628412,0b14b4d492386938788efe83fc5acc9f833b6f3c,6,3,1,21922,,,0,"Return status from running command

This way when someone use code like `sys.exit(main())` it will have
proper exit code on error (so different than `0`).

Story: 2001246
Task: 5776

Change-Id: I1c04fbf73d1fc44da7738c8f22296992d2e7a4f8
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/12/628412/1 && git format-patch -1 --stdout FETCH_HEAD,['monascaclient/shell.py'],1,0b14b4d492386938788efe83fc5acc9f833b6f3c,fix/exit_code, return MonascaShell().run(args), MonascaShell().run(args),1,1
openstack%2Freleases~master~I8d22d54640156ebea030f6b9a20fef8cd19db2fe,openstack/releases,master,I8d22d54640156ebea030f6b9a20fef8cd19db2fe,Oslo releases for 2019-01-07,MERGED,2019-01-07 22:59:21.000000000,2019-01-08 13:14:11.000000000,2019-01-08 13:14:11.000000000,"[{'_account_id': 2472}, {'_account_id': 12898}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-01-07 22:59:21.000000000', 'files': ['deliverables/stein/tooz.yaml', 'deliverables/stein/oslo.utils.yaml', 'deliverables/stein/oslo.messaging.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b4aea5ef3b47b5a59c974006dda13fbb624c1db0', 'message': 'Oslo releases for 2019-01-07\n\nChange-Id: I8d22d54640156ebea030f6b9a20fef8cd19db2fe\n'}]",0,629064,b4aea5ef3b47b5a59c974006dda13fbb624c1db0,9,5,1,6928,,,0,"Oslo releases for 2019-01-07

Change-Id: I8d22d54640156ebea030f6b9a20fef8cd19db2fe
",git fetch https://review.opendev.org/openstack/releases refs/changes/64/629064/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/stein/tooz.yaml', 'deliverables/stein/oslo.utils.yaml', 'deliverables/stein/oslo.messaging.yaml']",3,b4aea5ef3b47b5a59c974006dda13fbb624c1db0,oslo-master, - projects: - hash: 344ec5e8bb4a3df92e50edeab8d670f79aad5eb4 repo: openstack/oslo.messaging version: 9.3.1,,12,0
openstack%2Fopenstack-ansible~stable%2Fqueens~I5b3a145c7195fd14aa8e6cea368e7e2d204e5017,openstack/openstack-ansible,stable/queens,I5b3a145c7195fd14aa8e6cea368e7e2d204e5017,Update all SHAs for 17.1.7,MERGED,2018-12-23 16:48:00.000000000,2019-01-08 13:12:59.000000000,2019-01-08 13:12:59.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 16:48:00.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'inventory/group_vars/all/all.yml', 'releasenotes/notes/remove-machinectl-workarounds-d67a4739f6385f54.yaml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e84e3f1e7e782fd99117f1523bcc9717fc4b0fff', 'message': 'Update all SHAs for 17.1.7\n\nThis patch:\n- updates all the roles to the latest available stable SHAs\n- copies the release notes from the updated roles into the integrated repo\n- updates all the OpenStack Service SHAs\n\nDepends-On: https://review.openstack.org/627080\nChange-Id: I5b3a145c7195fd14aa8e6cea368e7e2d204e5017\n'}]",0,627081,e84e3f1e7e782fd99117f1523bcc9717fc4b0fff,9,4,1,17068,,,0,"Update all SHAs for 17.1.7

This patch:
- updates all the roles to the latest available stable SHAs
- copies the release notes from the updated roles into the integrated repo
- updates all the OpenStack Service SHAs

Depends-On: https://review.openstack.org/627080
Change-Id: I5b3a145c7195fd14aa8e6cea368e7e2d204e5017
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/627081/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'inventory/group_vars/all/all.yml', 'releasenotes/notes/remove-machinectl-workarounds-d67a4739f6385f54.yaml', 'ansible-role-requirements.yml']",4,e84e3f1e7e782fd99117f1523bcc9717fc4b0fff,release_osa, version: 78c8b5f7e2a0724610c2b858a2712a74e7400f5f version: 059a8470126e4f0a6560b3cfde68eee38ad8f5b0 version: 5bd05fc238662b07cd78f18f9d9f8e50062b45d1 version: 4d565ba90a7b034afce2434589747905c9ca8795 version: 3607a6d4a7f8e810f1e6b5957b35214656527d43, version: 1ce63ac6de360b2f9695d7d714a756386429bc73 version: 42e8cc4ac5629cc169f0437f03a00381e0a30185 version: 03e3e83953218ad3a99c7c239037a94b60313ee7 version: 8b7ba25908727cff9393b977f725e595521d0b34 version: f5d6b919b504e787841d5b1703672c5ab77c14ea,52,45
openstack%2Fmonasca-api~master~Iacec60495d02b0a2b882044192058da24f484f97,openstack/monasca-api,master,Iacec60495d02b0a2b882044192058da24f484f97,Configure system encoding format,MERGED,2019-01-07 11:50:31.000000000,2019-01-08 13:05:28.000000000,2019-01-08 13:05:28.000000000,"[{'_account_id': 7102}, {'_account_id': 17669}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-01-07 11:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/b4b36f1a096ea1bbbd0467d0881d3f0e07d105cb', 'message': '[WIP] TEST !!!\n\nChange-Id: Iacec60495d02b0a2b882044192058da24f484f97\n'}, {'number': 2, 'created': '2019-01-07 12:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/c5902eab32362c993ee6a10fe370d9788d58ff6a', 'message': 'Configure system encoding format\n\nChange-Id: Iacec60495d02b0a2b882044192058da24f484f97\n'}, {'number': 3, 'created': '2019-01-07 12:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/c85636d4e8881859b66a2b69b9cb2d3924376d33', 'message': 'Configure system encoding format\n\nChange-Id: Iacec60495d02b0a2b882044192058da24f484f97\n'}, {'number': 4, 'created': '2019-01-08 08:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/011da0d0b57db85a813118cf2c67af5df61dae64', 'message': 'Configure system encoding format\n\nThis is needed to properly build monasca-common from repository\n\nChange-Id: Iacec60495d02b0a2b882044192058da24f484f97\n'}, {'number': 5, 'created': '2019-01-08 08:57:11.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/cd94a9ca03e5ae5384c58583e9ccb1bcac9b66ef', 'message': 'Configure system encoding format\n\nThis is needed to properly build monasca-common from repository\n\nChange-Id: Iacec60495d02b0a2b882044192058da24f484f97\n'}]",1,628936,cd94a9ca03e5ae5384c58583e9ccb1bcac9b66ef,19,5,5,26141,,,0,"Configure system encoding format

This is needed to properly build monasca-common from repository

Change-Id: Iacec60495d02b0a2b882044192058da24f484f97
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/36/628936/4 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,b4b36f1a096ea1bbbd0467d0881d3f0e07d105cb,test, export LANGUAGE=en_US.UTF-8 export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 export LC_TYPE=en_US.UTF-8,,4,0
openstack%2Fnetworking-bagpipe~master~I58773a7b19b26459fc23b673237142841c863b7d,openstack/networking-bagpipe,master,I58773a7b19b26459fc23b673237142841c863b7d,DNM gate test,ABANDONED,2019-01-03 14:09:29.000000000,2019-01-08 12:59:25.000000000,,"[{'_account_id': 5367}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 14:09:29.000000000', 'files': ['networking_bagpipe/opts.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/cbe2a16306296169749a40c82ec17f7e4ee03cde', 'message': 'DNM gate test\n\nDO NOT MERGE\n\nThis is a no-op patch to test the gate.\n\nChange-Id: I58773a7b19b26459fc23b673237142841c863b7d\n'}]",0,628188,cbe2a16306296169749a40c82ec17f7e4ee03cde,4,2,1,5367,,,0,"DNM gate test

DO NOT MERGE

This is a no-op patch to test the gate.

Change-Id: I58773a7b19b26459fc23b673237142841c863b7d
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/88/628188/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bagpipe/opts.py'],1,cbe2a16306296169749a40c82ec17f7e4ee03cde,gate-test,# dummy change,,1,0
openstack%2Fpuppet-openstack-integration~master~I9ba36f23acfb1af428d17e8ad519c4a40c5a1a52,openstack/puppet-openstack-integration,master,I9ba36f23acfb1af428d17e8ad519c4a40c5a1a52,"Revert ""Temporarily disable dynamic_routing and bgpvpn from scenario004""",MERGED,2018-12-31 06:07:20.000000000,2019-01-08 12:57:57.000000000,2019-01-08 12:57:57.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 16312}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-31 06:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/8aa3f349762a52e3e964052b5ed172f2304a6d2c', 'message': 'Revert ""Temporarily disable dynamic_routing and bgpvpn from scenario004""\n\npuppet-neutron has switched from ryu to os-ken in https://review.openstack.org/#/c/626914/ and the packages is in puppet-passed-ci now.\n\nThis reverts commit 4bc57e65410bde5ac2728919813dc99a2d88fd57.\n\nChange-Id: I9ba36f23acfb1af428d17e8ad519c4a40c5a1a52\n'}, {'number': 2, 'created': '2018-12-31 06:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/d4bced612132195189fed184fdd3fdfd9602f27f', 'message': 'Revert ""Temporarily disable dynamic_routing and bgpvpn from scenario004""\n\npuppet-neutron has switched from ryu to os-ken in [1] and the package\nis in puppet-passed-ci repo.\n\n[1] https://review.openstack.org/#/c/626914/\n\nThis reverts commit 4bc57e65410bde5ac2728919813dc99a2d88fd57.\n\nChange-Id: I9ba36f23acfb1af428d17e8ad519c4a40c5a1a52\n'}, {'number': 3, 'created': '2019-01-08 04:14:10.000000000', 'files': ['fixtures/scenario004.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/22a04c2a10b47d0d4fefe2b293c4fde857457874', 'message': 'Revert ""Temporarily disable dynamic_routing and bgpvpn from scenario004""\n\npuppet-neutron has switched from ryu to os-ken in [1] and the package\nis in puppet-passed-ci repo.\n\n[1] https://review.openstack.org/#/c/626914/\n\nThis reverts commit 4bc57e65410bde5ac2728919813dc99a2d88fd57.\n\nKeep bgp_dragent disabled for Ubuntu, as currently\n\'stein\' repos are not enabled for Ubuntu, see:\nhttps://review.openstack.org/#/c/620055/.\n\nChange-Id: I9ba36f23acfb1af428d17e8ad519c4a40c5a1a52\n'}]",0,627855,22a04c2a10b47d0d4fefe2b293c4fde857457874,16,9,3,13861,,,0,"Revert ""Temporarily disable dynamic_routing and bgpvpn from scenario004""

puppet-neutron has switched from ryu to os-ken in [1] and the package
is in puppet-passed-ci repo.

[1] https://review.openstack.org/#/c/626914/

This reverts commit 4bc57e65410bde5ac2728919813dc99a2d88fd57.

Keep bgp_dragent disabled for Ubuntu, as currently
'stein' repos are not enabled for Ubuntu, see:
https://review.openstack.org/#/c/620055/.

Change-Id: I9ba36f23acfb1af428d17e8ad519c4a40c5a1a52
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/55/627855/2 && git format-patch -1 --stdout FETCH_HEAD,['fixtures/scenario004.pp'],1,8aa3f349762a52e3e964052b5ed172f2304a6d2c,627855," $bgpvpn_enabled = true bgp_dragent_enabled => true, dr => true,"," $bgpvpn_enabled = false bgp_dragent_enabled => false, dr => false,",3,3
openstack%2Fkeystone~master~I4c6d1a26e05b9d941d24fd1ba2cd9c06467d89be,openstack/keystone,master,I4c6d1a26e05b9d941d24fd1ba2cd9c06467d89be,Deprecate token_setup and token_rotate,ABANDONED,2018-12-28 07:16:34.000000000,2019-01-08 12:50:07.000000000,,"[{'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-12-28 07:16:34.000000000', 'files': ['keystone/cmd/cli.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a6f02e04eb90e3bde3796036b9a4d9647edac46', 'message': 'Deprecate token_setup and token_rotate\n\nAccording to  [1], token_setup and token_rotate are not\nused anymore. Thus deprecating both.\n\n[1] https://docs.openstack.org/keystone/latest/cli/keystone-manage.html\n\nChange-Id: I4c6d1a26e05b9d941d24fd1ba2cd9c06467d89be\nbp: deprecated-as-of-stein\n'}]",0,627612,9a6f02e04eb90e3bde3796036b9a4d9647edac46,5,3,1,27621,,,0,"Deprecate token_setup and token_rotate

According to  [1], token_setup and token_rotate are not
used anymore. Thus deprecating both.

[1] https://docs.openstack.org/keystone/latest/cli/keystone-manage.html

Change-Id: I4c6d1a26e05b9d941d24fd1ba2cd9c06467d89be
bp: deprecated-as-of-stein
",git fetch https://review.opendev.org/openstack/keystone refs/changes/12/627612/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/cmd/cli.py'],1,9a6f02e04eb90e3bde3796036b9a4d9647edac46,bp/deprecated-as-of-stein, LOG.warning( 'This command is deprecated and no longer needed with the ' 'token formats. It will be removed in Train. It is recommended' 'that you remove usage of this command or use fernet_setup ' 'instead.' LOG.warning( 'This command is deprecated and no longer needed with the ' 'token formats. It will be removed in Train. It is recommended' 'that you remove usage of this command or use fernet_rotate ' 'instead.'," futils = fernet_utils.FernetUtils( # TODO(gagehugo) Change this to CONF.token CONF.fernet_tokens.key_repository, CONF.fernet_tokens.max_active_keys, 'fernet_tokens' keystone_user_id, keystone_group_id = cls.get_user_group() futils.create_key_directory(keystone_user_id, keystone_group_id) if futils.validate_key_repository(requires_write=True): futils.initialize_key_repository( keystone_user_id, keystone_group_id) futils = fernet_utils.FernetUtils( # TODO(gagehugo) Change this to CONF.token CONF.fernet_tokens.key_repository, CONF.fernet_tokens.max_active_keys, 'fernet_tokens' keystone_user_id, keystone_group_id = cls.get_user_group() if futils.validate_key_repository(requires_write=True): futils.rotate_keys(keystone_user_id, keystone_group_id) ",10,20
openstack%2Fpython-ironic-inspector-client~master~Iebcfc853d952b02e30a3a89babbff146721f2613,openstack/python-ironic-inspector-client,master,Iebcfc853d952b02e30a3a89babbff146721f2613,Remove dsvm from zuulv3 job names,MERGED,2019-01-07 16:30:24.000000000,2019-01-08 12:22:35.000000000,2019-01-08 12:22:35.000000000,"[{'_account_id': 10239}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-01-07 16:30:24.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/python-ironic-inspector-client-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/7b051723e9dd852609d29ad35ce4406bf62aa8b2', 'message': 'Remove dsvm from zuulv3 job names\n\nAccording to [1] the dsvm should be removed from zuulv3 jobs\n\n[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3\n\nChange-Id: Iebcfc853d952b02e30a3a89babbff146721f2613\n'}]",0,629012,7b051723e9dd852609d29ad35ce4406bf62aa8b2,8,4,1,15519,,,0,"Remove dsvm from zuulv3 job names

According to [1] the dsvm should be removed from zuulv3 jobs

[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3

Change-Id: Iebcfc853d952b02e30a3a89babbff146721f2613
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/12/629012/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/python-ironic-inspector-client-jobs.yaml']",2,7b051723e9dd852609d29ad35ce4406bf62aa8b2,zuulv3, name: python-ironic-inspector-client-tempest-python2 description: python-ironic-inspector-client-tempest-python2 name: python-ironic-inspector-client-tempest-python3 description: python-ironic-inspector-client-tempest-python3, name: python-ironic-inspector-client-tempest-dsvm-python2 description: python-ironic-inspector-client-tempest-dsvm-python2 name: python-ironic-inspector-client-tempest-dsvm-python3 description: python-ironic-inspector-client-tempest-dsvm-python3,8,8
openstack%2Fcinder~master~Ib701edb733567831ee80a317d0e3b3945a312760,openstack/cinder,master,Ib701edb733567831ee80a317d0e3b3945a312760,Hedvig Cinder driver implementation,MERGED,2017-02-13 23:55:18.000000000,2019-01-08 12:21:53.000000000,2019-01-07 23:53:07.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10058}, {'_account_id': 10118}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 13628}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18883}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 20395}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 21990}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22255}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 22510}, {'_account_id': 23308}, {'_account_id': 23602}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24241}, {'_account_id': 24496}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24757}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25677}, {'_account_id': 25678}, {'_account_id': 25838}, {'_account_id': 26028}, {'_account_id': 26077}, {'_account_id': 26212}, {'_account_id': 26347}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}]","[{'number': 1, 'created': '2017-02-13 23:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27623a94df2f4633696e186da6175b982d9daf19', 'message': 'implements: blueprint hedvig-cinder\n\nHedvig Cinder driver implementation and unit tests.\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@example.com>\n'}, {'number': 2, 'created': '2017-03-02 18:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8934e557857800253a129d41217cc2c90b6cf7d0', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 3, 'created': '2017-04-21 18:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b766d14f93caef7f65aaddd69f2dd56225fc560', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 4, 'created': '2017-04-21 21:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4c12799bcc4b1f3f64c2b1ff1242755f4e5d0833', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 5, 'created': '2017-05-03 20:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e102c4a7e5b9e74ed9adb9b961a667160e85328', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 6, 'created': '2017-05-03 20:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/912d8d842432baf2784d98949d5c971421e3d0b4', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 7, 'created': '2017-05-03 21:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dd348b1e7d8f80aa571af87d1e136decae46e2ab', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 8, 'created': '2017-05-03 22:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/00b8b83c3e4b7beca22cfb176e13ee733150fc83', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 9, 'created': '2017-05-04 00:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e6a33fb3e9c15158d25ed9cae0c44abd114b1de', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 10, 'created': '2017-05-04 20:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27718106785ad53cd3040e76ccf6777b899b8b53', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 11, 'created': '2017-05-05 00:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/034b60f00851215dcf32ad58e10a020f4170f678', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 12, 'created': '2017-05-15 21:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2279db4f807f7c291648d1f9759a48a3968e3b1e', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 13, 'created': '2017-05-16 21:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/79ff73de4bfeeb6c85b33faa16d914f6a845093d', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 14, 'created': '2017-05-17 01:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2086049cc4a9246ca9d8653919c8fec9188953a9', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 15, 'created': '2017-05-19 22:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3d6d45abcfdad369bc92308ec4ab6172ec8a514', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 16, 'created': '2017-05-23 17:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/23d2f372fe046cddb91bcc710f275a2ebe320756', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 17, 'created': '2017-05-24 19:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c48817fa3007d4ba419131687027a91ffcd94abf', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 18, 'created': '2017-05-26 23:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ae362ffdeb6182116c920b992ccdd8eef37e6bfa', 'message': 'Hedvig Cinder driver implementation and unit tests.\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 19, 'created': '2017-06-02 17:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4d383a34c456623733f9b9fb068f779634222fcc', 'message': 'Hedvig Cinder driver implementation\n\naddresing san_* variables and patch 18 review comments\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 20, 'created': '2017-06-02 20:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/94d622deedc4ef27f2c8f782c053304d4bf90521', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 21, 'created': '2017-06-04 16:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/93bd104fae9e2ebe3e47d44833f89a0803a40684', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 22, 'created': '2017-06-05 18:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1755f7c49421f00e941de6a9893b85882ae658a0', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 23, 'created': '2017-06-07 04:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2634a361be8e927b0d9ac026c0867927fcf1535a', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 24, 'created': '2017-10-06 18:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80ce07aeee64ad2f9fc6d44de05707e20de6056d', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 25, 'created': '2017-10-06 19:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd5016ee787d82611a8652a4a86038af1cd3945f', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 26, 'created': '2017-10-09 19:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ac0757116134ddc7442546e426cf8b496acbb1b1', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 27, 'created': '2017-10-11 20:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3a2e90f87ab6ad2261f125cce6d61873e3f9c39', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 28, 'created': '2017-10-18 21:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f3074d284c8570ed3e47284e8acb8457336d3992', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 29, 'created': '2017-11-08 15:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cebff1ebc05a21b3c4ca55c837f231f9df4a2577', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 30, 'created': '2017-11-21 19:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6c0f44c56881f7bd00919d972345680e8c036eec', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 31, 'created': '2017-11-21 19:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c7f91f7c50c6b33e5f1051a3458dc833215b44d9', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 32, 'created': '2018-04-24 00:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/97097dbaf4140e7af60877f4f2c42630c98fb299', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 33, 'created': '2018-04-24 20:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/541d4880717df1980beccad4fbaab8ca4620250e', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 34, 'created': '2018-04-24 21:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c33aad5652fab007615edc3ffe4670ee7c137f97', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 35, 'created': '2018-04-27 00:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/48ab185de37d9f689039b576bfd11960807cbc41', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 36, 'created': '2018-05-02 23:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a4818e64720a14092425b821adacfe954a4f3a7', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 37, 'created': '2018-05-03 01:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f3944f78ce920b6ddeb3679d727cf8edb71937e', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 38, 'created': '2018-05-04 18:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2da7f26a4d8d51cae03ea7dea30a4856bba7dc9a', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 39, 'created': '2018-05-04 22:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2dc3da51576f5f64af77d5973d5b3d2b2ec7a574', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 40, 'created': '2018-05-07 18:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d675337b4a5b8b70e588a516ad2e4c5b1c2f2006', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 41, 'created': '2018-05-08 00:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c3b63ad659d7105b179b00836b08dead95527a85', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 42, 'created': '2018-05-09 23:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e489b0cd42ddee16d95cadc7302cc5fcb6cdd4c3', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 43, 'created': '2018-05-11 20:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/78856d0481bc24163ad752455a45d7e3f37e4165', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 44, 'created': '2018-05-14 20:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/66c096ccf1ade9eba7cd466242027c0305e3cc1b', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 45, 'created': '2018-05-15 05:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2e9905564fa83144b5806b352d294361d08f9df5', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 46, 'created': '2018-05-15 18:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7e6f8070fb4416488d2e2f4a2234a1613faf93e7', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 47, 'created': '2018-05-16 01:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc5715131a4353af4ede317e97a0f47bea69aa53', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 48, 'created': '2018-05-16 04:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8c92df9b042697c35355668073a685309e547b2', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 49, 'created': '2018-05-17 18:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ccbed2e08e8048d726ffbdee858a69821b721279', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 50, 'created': '2018-09-17 20:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c7c6c0adab993b285ddb0f4f674110565f24e50f', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 51, 'created': '2018-09-19 18:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bdbd557afe29a3b0923f78f9d820a7c4948c261d', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 52, 'created': '2018-09-20 16:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9b74ecb79f2f6eb94606973daadb550e26b03d70', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 53, 'created': '2018-09-20 23:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65310dda7383ffa95e412288d6e592bfa5fe4247', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 54, 'created': '2018-09-24 05:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dae8c094261e86f919e9cc8c859ab6f7f973e5be', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 55, 'created': '2018-10-30 20:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4be6e523b58b283bf559db8a7911b3b37f2148c4', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 56, 'created': '2018-10-31 23:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d033fe7459b581ef3965c86383a50b9729b7aaf3', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 57, 'created': '2018-11-04 04:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8aaeb641a6f1b16b7ad241f721069341a7e45567', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 58, 'created': '2018-11-05 20:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b5b4456170fe2f6a67d3a0f27fd4a3549dfa0228', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 59, 'created': '2018-11-05 20:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a91c07bb31412d180a185a7ab07b9bd4f2153c48', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 60, 'created': '2018-11-15 05:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ae95e98daabd176f8359ffff158e7f5265a06387', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 61, 'created': '2018-11-15 20:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/81773b3e8522b0c20c74dfd377a55d44266ec121', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 62, 'created': '2018-11-28 00:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd92be5aca7dea6e79d2a6bf5e0fead74610e137', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 63, 'created': '2018-11-28 00:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a51f2adf1871d925c84505583694a9de7bc2843c', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 64, 'created': '2018-12-11 00:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21ebc89998031b54214eb8075c0b29aaec311de2', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 65, 'created': '2018-12-12 20:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/365f93a63311c0a407aea09b0292699a18260d7e', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 66, 'created': '2018-12-24 19:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/239896781a67a8fa9b4274e904644421d8076d1b', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 67, 'created': '2018-12-24 21:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7b9d77f63bef6129f350e5dbd545e1f29db5600f', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 68, 'created': '2018-12-24 22:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a07ff186cada8c392fc7bd87b9b097fbd272b36f', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 69, 'created': '2018-12-25 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a44f10df6f858f9b56b054fe7cccb0da73479dd', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 70, 'created': '2018-12-25 12:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b19a40cfe93358feb93c58ae74e1d661c6d0cac6', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 71, 'created': '2019-01-04 21:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e2c2f98fa20d540f5505a232798c20b3624e2a5', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}, {'number': 72, 'created': '2019-01-04 22:53:14.000000000', 'files': ['cinder/volume/drivers/hedvig/__init__.py', 'cinder/volume/drivers/hedvig/hedvig_cinder.py', 'doc/source/configuration/block-storage/volume-drivers.rst', 'cinder/tests/unit/volume/drivers/test_hedvig.py', 'cinder/volume/drivers/hedvig/rest_client.py', 'releasenotes/notes/hedvig-cinder-driver-e7b98f4bc214bc49.yaml', 'doc/source/configuration/block-storage/drivers/hedvig-volume-driver.rst', 'cinder/volume/drivers/hedvig/config.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e08707b06f788f4c10d69f7a9acef0956b9eacf9', 'message': 'Hedvig Cinder driver implementation\n\nThis patch introduces Hedvig cinder volume driver along with unit tests\n\nimplements: blueprint hedvig-cinder\n\nChange-Id: Ib701edb733567831ee80a317d0e3b3945a312760\nSigned-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>\n'}]",400,433341,e08707b06f788f4c10d69f7a9acef0956b9eacf9,1796,81,72,24757,,,0,"Hedvig Cinder driver implementation

This patch introduces Hedvig cinder volume driver along with unit tests

implements: blueprint hedvig-cinder

Change-Id: Ib701edb733567831ee80a317d0e3b3945a312760
Signed-off-by: Dhinesh Balasubramaniam <dhinesh@hedviginc.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/41/433341/65 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/hedvig/__init__.py', 'cinder/volume/drivers/hedvig/hedvig_cinder.py', 'cinder/volume/drivers/hedvig/Helper.py', 'cinder/tests/unit/volume/drivers/test_hedvig.py', 'cinder/volume/drivers/hedvig/HedvigOpCb.py', 'cinder/volume/drivers/hedvig/README.rst', 'cinder/volume/drivers/hedvig/HedvigConfig.py', 'cinder/volume/drivers/hedvig/hedvigpyc.py']",8,27623a94df2f4633696e186da6175b982d9daf19,bp/hedvig-cinder,"# This file was automatically generated by SWIG (http://www.swig.org). # Version 2.0.11 # # Do not make changes to this file unless you know what you are doing--modify # the SWIG interface file instead. from sys import version_info if version_info >= (2,6,0): def swig_import_helper(): from os.path import dirname import imp fp = None try: fp, pathname, description = imp.find_module('_hedvigpyc', [dirname(__file__)]) except ImportError: import _hedvigpyc return _hedvigpyc if fp is not None: try: _mod = imp.load_module('_hedvigpyc', fp, pathname, description) finally: fp.close() return _mod _hedvigpyc = swig_import_helper() del swig_import_helper else: import _hedvigpyc del version_info try: _swig_property = property except NameError: pass # Python < 2.2 doesn't have 'property'. def _swig_setattr_nondynamic(self,class_type,name,value,static=1): if (name == ""thisown""): return self.this.own(value) if (name == ""this""): if type(value).__name__ == 'SwigPyObject': self.__dict__[name] = value return method = class_type.__swig_setmethods__.get(name,None) if method: return method(self,value) if (not static): self.__dict__[name] = value else: raise AttributeError(""You cannot add attributes to %s"" % self) def _swig_setattr(self,class_type,name,value): return _swig_setattr_nondynamic(self,class_type,name,value,0) def _swig_getattr(self,class_type,name): if (name == ""thisown""): return self.this.own() method = class_type.__swig_getmethods__.get(name,None) if method: return method(self) raise AttributeError(name) def _swig_repr(self): try: strthis = ""proxy of "" + self.this.__repr__() except: strthis = """" return ""<%s.%s; %s >"" % (self.__class__.__module__, self.__class__.__name__, strthis,) try: _object = object _newclass = 1 except AttributeError: class _object : pass _newclass = 0 try: import weakref weakref_proxy = weakref.proxy except: weakref_proxy = lambda x: x class SwigPyIterator(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, SwigPyIterator, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, SwigPyIterator, name) def __init__(self, *args, **kwargs): raise AttributeError(""No constructor defined - class is abstract"") __repr__ = _swig_repr __swig_destroy__ = _hedvigpyc.delete_SwigPyIterator __del__ = lambda self : None; def value(self): return _hedvigpyc.SwigPyIterator_value(self) def incr(self, n=1): return _hedvigpyc.SwigPyIterator_incr(self, n) def decr(self, n=1): return _hedvigpyc.SwigPyIterator_decr(self, n) def distance(self, *args): return _hedvigpyc.SwigPyIterator_distance(self, *args) def equal(self, *args): return _hedvigpyc.SwigPyIterator_equal(self, *args) def copy(self): return _hedvigpyc.SwigPyIterator_copy(self) def next(self): return _hedvigpyc.SwigPyIterator_next(self) def __next__(self): return _hedvigpyc.SwigPyIterator___next__(self) def previous(self): return _hedvigpyc.SwigPyIterator_previous(self) def advance(self, *args): return _hedvigpyc.SwigPyIterator_advance(self, *args) def __eq__(self, *args): return _hedvigpyc.SwigPyIterator___eq__(self, *args) def __ne__(self, *args): return _hedvigpyc.SwigPyIterator___ne__(self, *args) def __iadd__(self, *args): return _hedvigpyc.SwigPyIterator___iadd__(self, *args) def __isub__(self, *args): return _hedvigpyc.SwigPyIterator___isub__(self, *args) def __add__(self, *args): return _hedvigpyc.SwigPyIterator___add__(self, *args) def __sub__(self, *args): return _hedvigpyc.SwigPyIterator___sub__(self, *args) def __iter__(self): return self SwigPyIterator_swigregister = _hedvigpyc.SwigPyIterator_swigregister SwigPyIterator_swigregister(SwigPyIterator) def cdata(*args): return _hedvigpyc.cdata(*args) cdata = _hedvigpyc.cdata def memmove(*args): return _hedvigpyc.memmove(*args) memmove = _hedvigpyc.memmove class map_string_string(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, map_string_string, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, map_string_string, name) __repr__ = _swig_repr def iterator(self): return _hedvigpyc.map_string_string_iterator(self) def __iter__(self): return self.iterator() def __nonzero__(self): return _hedvigpyc.map_string_string___nonzero__(self) def __bool__(self): return _hedvigpyc.map_string_string___bool__(self) def __len__(self): return _hedvigpyc.map_string_string___len__(self) def __iter__(self): return self.key_iterator() def iterkeys(self): return self.key_iterator() def itervalues(self): return self.value_iterator() def iteritems(self): return self.iterator() def __getitem__(self, *args): return _hedvigpyc.map_string_string___getitem__(self, *args) def __delitem__(self, *args): return _hedvigpyc.map_string_string___delitem__(self, *args) def has_key(self, *args): return _hedvigpyc.map_string_string_has_key(self, *args) def keys(self): return _hedvigpyc.map_string_string_keys(self) def values(self): return _hedvigpyc.map_string_string_values(self) def items(self): return _hedvigpyc.map_string_string_items(self) def __contains__(self, *args): return _hedvigpyc.map_string_string___contains__(self, *args) def key_iterator(self): return _hedvigpyc.map_string_string_key_iterator(self) def value_iterator(self): return _hedvigpyc.map_string_string_value_iterator(self) def __setitem__(self, *args): return _hedvigpyc.map_string_string___setitem__(self, *args) def asdict(self): return _hedvigpyc.map_string_string_asdict(self) def __init__(self, *args): this = _hedvigpyc.new_map_string_string(*args) try: self.this.append(this) except: self.this = this def empty(self): return _hedvigpyc.map_string_string_empty(self) def size(self): return _hedvigpyc.map_string_string_size(self) def clear(self): return _hedvigpyc.map_string_string_clear(self) def swap(self, *args): return _hedvigpyc.map_string_string_swap(self, *args) def get_allocator(self): return _hedvigpyc.map_string_string_get_allocator(self) def begin(self): return _hedvigpyc.map_string_string_begin(self) def end(self): return _hedvigpyc.map_string_string_end(self) def rbegin(self): return _hedvigpyc.map_string_string_rbegin(self) def rend(self): return _hedvigpyc.map_string_string_rend(self) def count(self, *args): return _hedvigpyc.map_string_string_count(self, *args) def erase(self, *args): return _hedvigpyc.map_string_string_erase(self, *args) def find(self, *args): return _hedvigpyc.map_string_string_find(self, *args) def lower_bound(self, *args): return _hedvigpyc.map_string_string_lower_bound(self, *args) def upper_bound(self, *args): return _hedvigpyc.map_string_string_upper_bound(self, *args) __swig_destroy__ = _hedvigpyc.delete_map_string_string __del__ = lambda self : None; map_string_string_swigregister = _hedvigpyc.map_string_string_swigregister map_string_string_swigregister(map_string_string) class map_int_string(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, map_int_string, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, map_int_string, name) __repr__ = _swig_repr def iterator(self): return _hedvigpyc.map_int_string_iterator(self) def __iter__(self): return self.iterator() def __nonzero__(self): return _hedvigpyc.map_int_string___nonzero__(self) def __bool__(self): return _hedvigpyc.map_int_string___bool__(self) def __len__(self): return _hedvigpyc.map_int_string___len__(self) def __iter__(self): return self.key_iterator() def iterkeys(self): return self.key_iterator() def itervalues(self): return self.value_iterator() def iteritems(self): return self.iterator() def __getitem__(self, *args): return _hedvigpyc.map_int_string___getitem__(self, *args) def __delitem__(self, *args): return _hedvigpyc.map_int_string___delitem__(self, *args) def has_key(self, *args): return _hedvigpyc.map_int_string_has_key(self, *args) def keys(self): return _hedvigpyc.map_int_string_keys(self) def values(self): return _hedvigpyc.map_int_string_values(self) def items(self): return _hedvigpyc.map_int_string_items(self) def __contains__(self, *args): return _hedvigpyc.map_int_string___contains__(self, *args) def key_iterator(self): return _hedvigpyc.map_int_string_key_iterator(self) def value_iterator(self): return _hedvigpyc.map_int_string_value_iterator(self) def __setitem__(self, *args): return _hedvigpyc.map_int_string___setitem__(self, *args) def asdict(self): return _hedvigpyc.map_int_string_asdict(self) def __init__(self, *args): this = _hedvigpyc.new_map_int_string(*args) try: self.this.append(this) except: self.this = this def empty(self): return _hedvigpyc.map_int_string_empty(self) def size(self): return _hedvigpyc.map_int_string_size(self) def clear(self): return _hedvigpyc.map_int_string_clear(self) def swap(self, *args): return _hedvigpyc.map_int_string_swap(self, *args) def get_allocator(self): return _hedvigpyc.map_int_string_get_allocator(self) def begin(self): return _hedvigpyc.map_int_string_begin(self) def end(self): return _hedvigpyc.map_int_string_end(self) def rbegin(self): return _hedvigpyc.map_int_string_rbegin(self) def rend(self): return _hedvigpyc.map_int_string_rend(self) def count(self, *args): return _hedvigpyc.map_int_string_count(self, *args) def erase(self, *args): return _hedvigpyc.map_int_string_erase(self, *args) def find(self, *args): return _hedvigpyc.map_int_string_find(self, *args) def lower_bound(self, *args): return _hedvigpyc.map_int_string_lower_bound(self, *args) def upper_bound(self, *args): return _hedvigpyc.map_int_string_upper_bound(self, *args) __swig_destroy__ = _hedvigpyc.delete_map_int_string __del__ = lambda self : None; map_int_string_swigregister = _hedvigpyc.map_int_string_swigregister map_int_string_swigregister(map_int_string) class blkId_vector(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, blkId_vector, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, blkId_vector, name) __repr__ = _swig_repr def iterator(self): return _hedvigpyc.blkId_vector_iterator(self) def __iter__(self): return self.iterator() def __nonzero__(self): return _hedvigpyc.blkId_vector___nonzero__(self) def __bool__(self): return _hedvigpyc.blkId_vector___bool__(self) def __len__(self): return _hedvigpyc.blkId_vector___len__(self) def pop(self): return _hedvigpyc.blkId_vector_pop(self) def __getslice__(self, *args): return _hedvigpyc.blkId_vector___getslice__(self, *args) def __setslice__(self, *args): return _hedvigpyc.blkId_vector___setslice__(self, *args) def __delslice__(self, *args): return _hedvigpyc.blkId_vector___delslice__(self, *args) def __delitem__(self, *args): return _hedvigpyc.blkId_vector___delitem__(self, *args) def __getitem__(self, *args): return _hedvigpyc.blkId_vector___getitem__(self, *args) def __setitem__(self, *args): return _hedvigpyc.blkId_vector___setitem__(self, *args) def append(self, *args): return _hedvigpyc.blkId_vector_append(self, *args) def empty(self): return _hedvigpyc.blkId_vector_empty(self) def size(self): return _hedvigpyc.blkId_vector_size(self) def clear(self): return _hedvigpyc.blkId_vector_clear(self) def swap(self, *args): return _hedvigpyc.blkId_vector_swap(self, *args) def get_allocator(self): return _hedvigpyc.blkId_vector_get_allocator(self) def begin(self): return _hedvigpyc.blkId_vector_begin(self) def end(self): return _hedvigpyc.blkId_vector_end(self) def rbegin(self): return _hedvigpyc.blkId_vector_rbegin(self) def rend(self): return _hedvigpyc.blkId_vector_rend(self) def pop_back(self): return _hedvigpyc.blkId_vector_pop_back(self) def erase(self, *args): return _hedvigpyc.blkId_vector_erase(self, *args) def __init__(self, *args): this = _hedvigpyc.new_blkId_vector(*args) try: self.this.append(this) except: self.this = this def push_back(self, *args): return _hedvigpyc.blkId_vector_push_back(self, *args) def front(self): return _hedvigpyc.blkId_vector_front(self) def back(self): return _hedvigpyc.blkId_vector_back(self) def assign(self, *args): return _hedvigpyc.blkId_vector_assign(self, *args) def resize(self, *args): return _hedvigpyc.blkId_vector_resize(self, *args) def insert(self, *args): return _hedvigpyc.blkId_vector_insert(self, *args) def reserve(self, *args): return _hedvigpyc.blkId_vector_reserve(self, *args) def capacity(self): return _hedvigpyc.blkId_vector_capacity(self) __swig_destroy__ = _hedvigpyc.delete_blkId_vector __del__ = lambda self : None; blkId_vector_swigregister = _hedvigpyc.blkId_vector_swigregister blkId_vector_swigregister(blkId_vector) class buffer_vector(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, buffer_vector, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, buffer_vector, name) __repr__ = _swig_repr def iterator(self): return _hedvigpyc.buffer_vector_iterator(self) def __iter__(self): return self.iterator() def __nonzero__(self): return _hedvigpyc.buffer_vector___nonzero__(self) def __bool__(self): return _hedvigpyc.buffer_vector___bool__(self) def __len__(self): return _hedvigpyc.buffer_vector___len__(self) def pop(self): return _hedvigpyc.buffer_vector_pop(self) def __getslice__(self, *args): return _hedvigpyc.buffer_vector___getslice__(self, *args) def __setslice__(self, *args): return _hedvigpyc.buffer_vector___setslice__(self, *args) def __delslice__(self, *args): return _hedvigpyc.buffer_vector___delslice__(self, *args) def __delitem__(self, *args): return _hedvigpyc.buffer_vector___delitem__(self, *args) def __getitem__(self, *args): return _hedvigpyc.buffer_vector___getitem__(self, *args) def __setitem__(self, *args): return _hedvigpyc.buffer_vector___setitem__(self, *args) def append(self, *args): return _hedvigpyc.buffer_vector_append(self, *args) def empty(self): return _hedvigpyc.buffer_vector_empty(self) def size(self): return _hedvigpyc.buffer_vector_size(self) def clear(self): return _hedvigpyc.buffer_vector_clear(self) def swap(self, *args): return _hedvigpyc.buffer_vector_swap(self, *args) def get_allocator(self): return _hedvigpyc.buffer_vector_get_allocator(self) def begin(self): return _hedvigpyc.buffer_vector_begin(self) def end(self): return _hedvigpyc.buffer_vector_end(self) def rbegin(self): return _hedvigpyc.buffer_vector_rbegin(self) def rend(self): return _hedvigpyc.buffer_vector_rend(self) def pop_back(self): return _hedvigpyc.buffer_vector_pop_back(self) def erase(self, *args): return _hedvigpyc.buffer_vector_erase(self, *args) def __init__(self, *args): this = _hedvigpyc.new_buffer_vector(*args) try: self.this.append(this) except: self.this = this def push_back(self, *args): return _hedvigpyc.buffer_vector_push_back(self, *args) def front(self): return _hedvigpyc.buffer_vector_front(self) def back(self): return _hedvigpyc.buffer_vector_back(self) def assign(self, *args): return _hedvigpyc.buffer_vector_assign(self, *args) def resize(self, *args): return _hedvigpyc.buffer_vector_resize(self, *args) def insert(self, *args): return _hedvigpyc.buffer_vector_insert(self, *args) def reserve(self, *args): return _hedvigpyc.buffer_vector_reserve(self, *args) def capacity(self): return _hedvigpyc.buffer_vector_capacity(self) __swig_destroy__ = _hedvigpyc.delete_buffer_vector __del__ = lambda self : None; buffer_vector_swigregister = _hedvigpyc.buffer_vector_swigregister buffer_vector_swigregister(buffer_vector) class set_string(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, set_string, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, set_string, name) __repr__ = _swig_repr def iterator(self): return _hedvigpyc.set_string_iterator(self) def __iter__(self): return self.iterator() def __nonzero__(self): return _hedvigpyc.set_string___nonzero__(self) def __bool__(self): return _hedvigpyc.set_string___bool__(self) def __len__(self): return _hedvigpyc.set_string___len__(self) def append(self, *args): return _hedvigpyc.set_string_append(self, *args) def __contains__(self, *args): return _hedvigpyc.set_string___contains__(self, *args) def __getitem__(self, *args): return _hedvigpyc.set_string___getitem__(self, *args) def add(self, *args): return _hedvigpyc.set_string_add(self, *args) def discard(self, *args): return _hedvigpyc.set_string_discard(self, *args) def __init__(self, *args): this = _hedvigpyc.new_set_string(*args) try: self.this.append(this) except: self.this = this def empty(self): return _hedvigpyc.set_string_empty(self) def size(self): return _hedvigpyc.set_string_size(self) def clear(self): return _hedvigpyc.set_string_clear(self) def swap(self, *args): return _hedvigpyc.set_string_swap(self, *args) def count(self, *args): return _hedvigpyc.set_string_count(self, *args) def begin(self): return _hedvigpyc.set_string_begin(self) def end(self): return _hedvigpyc.set_string_end(self) def rbegin(self): return _hedvigpyc.set_string_rbegin(self) def rend(self): return _hedvigpyc.set_string_rend(self) def erase(self, *args): return _hedvigpyc.set_string_erase(self, *args) def find(self, *args): return _hedvigpyc.set_string_find(self, *args) def lower_bound(self, *args): return _hedvigpyc.set_string_lower_bound(self, *args) def upper_bound(self, *args): return _hedvigpyc.set_string_upper_bound(self, *args) def equal_range(self, *args): return _hedvigpyc.set_string_equal_range(self, *args) def insert(self, *args): return _hedvigpyc.set_string_insert(self, *args) __swig_destroy__ = _hedvigpyc.delete_set_string __del__ = lambda self : None; set_string_swigregister = _hedvigpyc.set_string_swigregister set_string_swigregister(set_string) class map_tgt_string(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, map_tgt_string, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, map_tgt_string, name) __repr__ = _swig_repr def iterator(self): return _hedvigpyc.map_tgt_string_iterator(self) def __iter__(self): return self.iterator() def __nonzero__(self): return _hedvigpyc.map_tgt_string___nonzero__(self) def __bool__(self): return _hedvigpyc.map_tgt_string___bool__(self) def __len__(self): return _hedvigpyc.map_tgt_string___len__(self) def __iter__(self): return self.key_iterator() def iterkeys(self): return self.key_iterator() def itervalues(self): return self.value_iterator() def iteritems(self): return self.iterator() def __getitem__(self, *args): return _hedvigpyc.map_tgt_string___getitem__(self, *args) def __delitem__(self, *args): return _hedvigpyc.map_tgt_string___delitem__(self, *args) def has_key(self, *args): return _hedvigpyc.map_tgt_string_has_key(self, *args) def keys(self): return _hedvigpyc.map_tgt_string_keys(self) def values(self): return _hedvigpyc.map_tgt_string_values(self) def items(self): return _hedvigpyc.map_tgt_string_items(self) def __contains__(self, *args): return _hedvigpyc.map_tgt_string___contains__(self, *args) def key_iterator(self): return _hedvigpyc.map_tgt_string_key_iterator(self) def value_iterator(self): return _hedvigpyc.map_tgt_string_value_iterator(self) def __setitem__(self, *args): return _hedvigpyc.map_tgt_string___setitem__(self, *args) def asdict(self): return _hedvigpyc.map_tgt_string_asdict(self) def __init__(self, *args): this = _hedvigpyc.new_map_tgt_string(*args) try: self.this.append(this) except: self.this = this def empty(self): return _hedvigpyc.map_tgt_string_empty(self) def size(self): return _hedvigpyc.map_tgt_string_size(self) def clear(self): return _hedvigpyc.map_tgt_string_clear(self) def swap(self, *args): return _hedvigpyc.map_tgt_string_swap(self, *args) def get_allocator(self): return _hedvigpyc.map_tgt_string_get_allocator(self) def begin(self): return _hedvigpyc.map_tgt_string_begin(self) def end(self): return _hedvigpyc.map_tgt_string_end(self) def rbegin(self): return _hedvigpyc.map_tgt_string_rbegin(self) def rend(self): return _hedvigpyc.map_tgt_string_rend(self) def count(self, *args): return _hedvigpyc.map_tgt_string_count(self, *args) def erase(self, *args): return _hedvigpyc.map_tgt_string_erase(self, *args) def find(self, *args): return _hedvigpyc.map_tgt_string_find(self, *args) def lower_bound(self, *args): return _hedvigpyc.map_tgt_string_lower_bound(self, *args) def upper_bound(self, *args): return _hedvigpyc.map_tgt_string_upper_bound(self, *args) __swig_destroy__ = _hedvigpyc.delete_map_tgt_string __del__ = lambda self : None; map_tgt_string_swigregister = _hedvigpyc.map_tgt_string_swigregister map_tgt_string_swigregister(map_tgt_string) class Callback(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, Callback, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, Callback, name) __repr__ = _swig_repr def __init__(self): if self.__class__ == Callback: _self = None else: _self = self this = _hedvigpyc.new_Callback(_self, ) try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_Callback __del__ = lambda self : None; def call(self, *args): return _hedvigpyc.Callback_call(self, *args) def __disown__(self): self.this.disown() _hedvigpyc.disown_Callback(self) return weakref_proxy(self) Callback_swigregister = _hedvigpyc.Callback_swigregister Callback_swigregister(Callback) class ObjWithPyCallback(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, ObjWithPyCallback, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, ObjWithPyCallback, name) __repr__ = _swig_repr def __init__(self): this = _hedvigpyc.new_ObjWithPyCallback() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_ObjWithPyCallback __del__ = lambda self : None; def setCallback(self, *args): if len(args) == 1 and (not isinstance(args[0], Callback) and callable(args[0])): class CallableWrapper(Callback): def __init__(self, f): super(CallableWrapper, self).__init__() self.f_ = f def call(self, obj): self.f_(obj) args = tuple([CallableWrapper(args[0])]) args[0].__disown__() elif len(args) == 1 and isinstance(args[0], Callback): args[0].__disown__() return _hedvigpyc.ObjWithPyCallback_setCallback(self, *args) def call(self): return _hedvigpyc.ObjWithPyCallback_call(self) def getTgtInstance(self, *args): return _hedvigpyc.ObjWithPyCallback_getTgtInstance(self, *args) def describeVirtualDisk(self, *args): return _hedvigpyc.ObjWithPyCallback_describeVirtualDisk(self, *args) def getLunCinder(self, *args): return _hedvigpyc.ObjWithPyCallback_getLunCinder(self, *args) def addLun(self, *args): return _hedvigpyc.ObjWithPyCallback_addLun(self, *args) def deleteLun(self, *args): return _hedvigpyc.ObjWithPyCallback_deleteLun(self, *args) def addAccess(self, *args): return _hedvigpyc.ObjWithPyCallback_addAccess(self, *args) def snapshotFromTgt(self, *args): return _hedvigpyc.ObjWithPyCallback_snapshotFromTgt(self, *args) def snapshot(self, *args): return _hedvigpyc.ObjWithPyCallback_snapshot(self, *args) def deleteSnapshot(self, *args): return _hedvigpyc.ObjWithPyCallback_deleteSnapshot(self, *args) def createVirtualDisk(self, *args): return _hedvigpyc.ObjWithPyCallback_createVirtualDisk(self, *args) def resizeVirtualDisk(self, *args): return _hedvigpyc.ObjWithPyCallback_resizeVirtualDisk(self, *args) def deleteVirtualDisk(self, *args): return _hedvigpyc.ObjWithPyCallback_deleteVirtualDisk(self, *args) def getIqn(self, *args): return _hedvigpyc.ObjWithPyCallback_getIqn(self, *args) __swig_setmethods__[""errorCode_""] = _hedvigpyc.ObjWithPyCallback_errorCode__set __swig_getmethods__[""errorCode_""] = _hedvigpyc.ObjWithPyCallback_errorCode__get if _newclass:errorCode_ = _swig_property(_hedvigpyc.ObjWithPyCallback_errorCode__get, _hedvigpyc.ObjWithPyCallback_errorCode__set) __swig_setmethods__[""error_""] = _hedvigpyc.ObjWithPyCallback_error__set __swig_getmethods__[""error_""] = _hedvigpyc.ObjWithPyCallback_error__get if _newclass:error_ = _swig_property(_hedvigpyc.ObjWithPyCallback_error__get, _hedvigpyc.ObjWithPyCallback_error__set) __swig_setmethods__[""wfd_""] = _hedvigpyc.ObjWithPyCallback_wfd__set __swig_getmethods__[""wfd_""] = _hedvigpyc.ObjWithPyCallback_wfd__get if _newclass:wfd_ = _swig_property(_hedvigpyc.ObjWithPyCallback_wfd__get, _hedvigpyc.ObjWithPyCallback_wfd__set) ObjWithPyCallback_swigregister = _hedvigpyc.ObjWithPyCallback_swigregister ObjWithPyCallback_swigregister(ObjWithPyCallback) class HGetTgtInstanceOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HGetTgtInstanceOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HGetTgtInstanceOp, name) __repr__ = _swig_repr __swig_setmethods__[""host_""] = _hedvigpyc.HGetTgtInstanceOp_host__set __swig_getmethods__[""host_""] = _hedvigpyc.HGetTgtInstanceOp_host__get if _newclass:host_ = _swig_property(_hedvigpyc.HGetTgtInstanceOp_host__get, _hedvigpyc.HGetTgtInstanceOp_host__set) __swig_setmethods__[""tgtMap_""] = _hedvigpyc.HGetTgtInstanceOp_tgtMap__set __swig_getmethods__[""tgtMap_""] = _hedvigpyc.HGetTgtInstanceOp_tgtMap__get if _newclass:tgtMap_ = _swig_property(_hedvigpyc.HGetTgtInstanceOp_tgtMap__get, _hedvigpyc.HGetTgtInstanceOp_tgtMap__set) def __init__(self): this = _hedvigpyc.new_HGetTgtInstanceOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HGetTgtInstanceOp __del__ = lambda self : None; HGetTgtInstanceOp_swigregister = _hedvigpyc.HGetTgtInstanceOp_swigregister HGetTgtInstanceOp_swigregister(HGetTgtInstanceOp) class HDescribeVirtualDiskOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HDescribeVirtualDiskOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HDescribeVirtualDiskOp, name) __repr__ = _swig_repr __swig_setmethods__[""vDiskName_""] = _hedvigpyc.HDescribeVirtualDiskOp_vDiskName__set __swig_getmethods__[""vDiskName_""] = _hedvigpyc.HDescribeVirtualDiskOp_vDiskName__get if _newclass:vDiskName_ = _swig_property(_hedvigpyc.HDescribeVirtualDiskOp_vDiskName__get, _hedvigpyc.HDescribeVirtualDiskOp_vDiskName__set) __swig_setmethods__[""vDiskInfo_""] = _hedvigpyc.HDescribeVirtualDiskOp_vDiskInfo__set __swig_getmethods__[""vDiskInfo_""] = _hedvigpyc.HDescribeVirtualDiskOp_vDiskInfo__get if _newclass:vDiskInfo_ = _swig_property(_hedvigpyc.HDescribeVirtualDiskOp_vDiskInfo__get, _hedvigpyc.HDescribeVirtualDiskOp_vDiskInfo__set) def __init__(self): this = _hedvigpyc.new_HDescribeVirtualDiskOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HDescribeVirtualDiskOp __del__ = lambda self : None; HDescribeVirtualDiskOp_swigregister = _hedvigpyc.HDescribeVirtualDiskOp_swigregister HDescribeVirtualDiskOp_swigregister(HDescribeVirtualDiskOp) class HGetLunCinderOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HGetLunCinderOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HGetLunCinderOp, name) __repr__ = _swig_repr __swig_setmethods__[""tgtHost_""] = _hedvigpyc.HGetLunCinderOp_tgtHost__set __swig_getmethods__[""tgtHost_""] = _hedvigpyc.HGetLunCinderOp_tgtHost__get if _newclass:tgtHost_ = _swig_property(_hedvigpyc.HGetLunCinderOp_tgtHost__get, _hedvigpyc.HGetLunCinderOp_tgtHost__set) __swig_setmethods__[""tgtPort_""] = _hedvigpyc.HGetLunCinderOp_tgtPort__set __swig_getmethods__[""tgtPort_""] = _hedvigpyc.HGetLunCinderOp_tgtPort__get if _newclass:tgtPort_ = _swig_property(_hedvigpyc.HGetLunCinderOp_tgtPort__get, _hedvigpyc.HGetLunCinderOp_tgtPort__set) __swig_setmethods__[""vDiskName_""] = _hedvigpyc.HGetLunCinderOp_vDiskName__set __swig_getmethods__[""vDiskName_""] = _hedvigpyc.HGetLunCinderOp_vDiskName__get if _newclass:vDiskName_ = _swig_property(_hedvigpyc.HGetLunCinderOp_vDiskName__get, _hedvigpyc.HGetLunCinderOp_vDiskName__set) __swig_setmethods__[""lunNumber_""] = _hedvigpyc.HGetLunCinderOp_lunNumber__set __swig_getmethods__[""lunNumber_""] = _hedvigpyc.HGetLunCinderOp_lunNumber__get if _newclass:lunNumber_ = _swig_property(_hedvigpyc.HGetLunCinderOp_lunNumber__get, _hedvigpyc.HGetLunCinderOp_lunNumber__set) def __init__(self): this = _hedvigpyc.new_HGetLunCinderOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HGetLunCinderOp __del__ = lambda self : None; HGetLunCinderOp_swigregister = _hedvigpyc.HGetLunCinderOp_swigregister HGetLunCinderOp_swigregister(HGetLunCinderOp) class HAddLunOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HAddLunOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HAddLunOp, name) __repr__ = _swig_repr __swig_setmethods__[""tgtHost_""] = _hedvigpyc.HAddLunOp_tgtHost__set __swig_getmethods__[""tgtHost_""] = _hedvigpyc.HAddLunOp_tgtHost__get if _newclass:tgtHost_ = _swig_property(_hedvigpyc.HAddLunOp_tgtHost__get, _hedvigpyc.HAddLunOp_tgtHost__set) __swig_setmethods__[""tgtPort_""] = _hedvigpyc.HAddLunOp_tgtPort__set __swig_getmethods__[""tgtPort_""] = _hedvigpyc.HAddLunOp_tgtPort__get if _newclass:tgtPort_ = _swig_property(_hedvigpyc.HAddLunOp_tgtPort__get, _hedvigpyc.HAddLunOp_tgtPort__set) __swig_setmethods__[""vDiskInfo_""] = _hedvigpyc.HAddLunOp_vDiskInfo__set __swig_getmethods__[""vDiskInfo_""] = _hedvigpyc.HAddLunOp_vDiskInfo__get if _newclass:vDiskInfo_ = _swig_property(_hedvigpyc.HAddLunOp_vDiskInfo__get, _hedvigpyc.HAddLunOp_vDiskInfo__set) __swig_setmethods__[""lunNumber_""] = _hedvigpyc.HAddLunOp_lunNumber__set __swig_getmethods__[""lunNumber_""] = _hedvigpyc.HAddLunOp_lunNumber__get if _newclass:lunNumber_ = _swig_property(_hedvigpyc.HAddLunOp_lunNumber__get, _hedvigpyc.HAddLunOp_lunNumber__set) def __init__(self): this = _hedvigpyc.new_HAddLunOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HAddLunOp __del__ = lambda self : None; HAddLunOp_swigregister = _hedvigpyc.HAddLunOp_swigregister HAddLunOp_swigregister(HAddLunOp) class HDeleteLunOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HDeleteLunOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HDeleteLunOp, name) __repr__ = _swig_repr __swig_setmethods__[""tgtHost_""] = _hedvigpyc.HDeleteLunOp_tgtHost__set __swig_getmethods__[""tgtHost_""] = _hedvigpyc.HDeleteLunOp_tgtHost__get if _newclass:tgtHost_ = _swig_property(_hedvigpyc.HDeleteLunOp_tgtHost__get, _hedvigpyc.HDeleteLunOp_tgtHost__set) __swig_setmethods__[""tgtPort_""] = _hedvigpyc.HDeleteLunOp_tgtPort__set __swig_getmethods__[""tgtPort_""] = _hedvigpyc.HDeleteLunOp_tgtPort__get if _newclass:tgtPort_ = _swig_property(_hedvigpyc.HDeleteLunOp_tgtPort__get, _hedvigpyc.HDeleteLunOp_tgtPort__set) __swig_setmethods__[""vDiskName_""] = _hedvigpyc.HDeleteLunOp_vDiskName__set __swig_getmethods__[""vDiskName_""] = _hedvigpyc.HDeleteLunOp_vDiskName__get if _newclass:vDiskName_ = _swig_property(_hedvigpyc.HDeleteLunOp_vDiskName__get, _hedvigpyc.HDeleteLunOp_vDiskName__set) __swig_setmethods__[""lunNumber_""] = _hedvigpyc.HDeleteLunOp_lunNumber__set __swig_getmethods__[""lunNumber_""] = _hedvigpyc.HDeleteLunOp_lunNumber__get if _newclass:lunNumber_ = _swig_property(_hedvigpyc.HDeleteLunOp_lunNumber__get, _hedvigpyc.HDeleteLunOp_lunNumber__set) __swig_setmethods__[""result_""] = _hedvigpyc.HDeleteLunOp_result__set __swig_getmethods__[""result_""] = _hedvigpyc.HDeleteLunOp_result__get if _newclass:result_ = _swig_property(_hedvigpyc.HDeleteLunOp_result__get, _hedvigpyc.HDeleteLunOp_result__set) def __init__(self): this = _hedvigpyc.new_HDeleteLunOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HDeleteLunOp __del__ = lambda self : None; HDeleteLunOp_swigregister = _hedvigpyc.HDeleteLunOp_swigregister HDeleteLunOp_swigregister(HDeleteLunOp) class HAddAccessOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HAddAccessOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HAddAccessOp, name) __repr__ = _swig_repr __swig_setmethods__[""tgtHost_""] = _hedvigpyc.HAddAccessOp_tgtHost__set __swig_getmethods__[""tgtHost_""] = _hedvigpyc.HAddAccessOp_tgtHost__get if _newclass:tgtHost_ = _swig_property(_hedvigpyc.HAddAccessOp_tgtHost__get, _hedvigpyc.HAddAccessOp_tgtHost__set) __swig_setmethods__[""tgtPort_""] = _hedvigpyc.HAddAccessOp_tgtPort__set __swig_getmethods__[""tgtPort_""] = _hedvigpyc.HAddAccessOp_tgtPort__get if _newclass:tgtPort_ = _swig_property(_hedvigpyc.HAddAccessOp_tgtPort__get, _hedvigpyc.HAddAccessOp_tgtPort__set) __swig_setmethods__[""lunNumber_""] = _hedvigpyc.HAddAccessOp_lunNumber__set __swig_getmethods__[""lunNumber_""] = _hedvigpyc.HAddAccessOp_lunNumber__get if _newclass:lunNumber_ = _swig_property(_hedvigpyc.HAddAccessOp_lunNumber__get, _hedvigpyc.HAddAccessOp_lunNumber__set) __swig_setmethods__[""Ip_""] = _hedvigpyc.HAddAccessOp_Ip__set __swig_getmethods__[""Ip_""] = _hedvigpyc.HAddAccessOp_Ip__get if _newclass:Ip_ = _swig_property(_hedvigpyc.HAddAccessOp_Ip__get, _hedvigpyc.HAddAccessOp_Ip__set) __swig_setmethods__[""result_""] = _hedvigpyc.HAddAccessOp_result__set __swig_getmethods__[""result_""] = _hedvigpyc.HAddAccessOp_result__get if _newclass:result_ = _swig_property(_hedvigpyc.HAddAccessOp_result__get, _hedvigpyc.HAddAccessOp_result__set) def __init__(self): this = _hedvigpyc.new_HAddAccessOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HAddAccessOp __del__ = lambda self : None; HAddAccessOp_swigregister = _hedvigpyc.HAddAccessOp_swigregister HAddAccessOp_swigregister(HAddAccessOp) class HSnapshotFromTgtOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HSnapshotFromTgtOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HSnapshotFromTgtOp, name) __repr__ = _swig_repr __swig_setmethods__[""tgtHost_""] = _hedvigpyc.HSnapshotFromTgtOp_tgtHost__set __swig_getmethods__[""tgtHost_""] = _hedvigpyc.HSnapshotFromTgtOp_tgtHost__get if _newclass:tgtHost_ = _swig_property(_hedvigpyc.HSnapshotFromTgtOp_tgtHost__get, _hedvigpyc.HSnapshotFromTgtOp_tgtHost__set) __swig_setmethods__[""tgtPort_""] = _hedvigpyc.HSnapshotFromTgtOp_tgtPort__set __swig_getmethods__[""tgtPort_""] = _hedvigpyc.HSnapshotFromTgtOp_tgtPort__get if _newclass:tgtPort_ = _swig_property(_hedvigpyc.HSnapshotFromTgtOp_tgtPort__get, _hedvigpyc.HSnapshotFromTgtOp_tgtPort__set) __swig_setmethods__[""vDiskName_""] = _hedvigpyc.HSnapshotFromTgtOp_vDiskName__set __swig_getmethods__[""vDiskName_""] = _hedvigpyc.HSnapshotFromTgtOp_vDiskName__get if _newclass:vDiskName_ = _swig_property(_hedvigpyc.HSnapshotFromTgtOp_vDiskName__get, _hedvigpyc.HSnapshotFromTgtOp_vDiskName__set) __swig_setmethods__[""snapshot_""] = _hedvigpyc.HSnapshotFromTgtOp_snapshot__set __swig_getmethods__[""snapshot_""] = _hedvigpyc.HSnapshotFromTgtOp_snapshot__get if _newclass:snapshot_ = _swig_property(_hedvigpyc.HSnapshotFromTgtOp_snapshot__get, _hedvigpyc.HSnapshotFromTgtOp_snapshot__set) def __init__(self): this = _hedvigpyc.new_HSnapshotFromTgtOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HSnapshotFromTgtOp __del__ = lambda self : None; HSnapshotFromTgtOp_swigregister = _hedvigpyc.HSnapshotFromTgtOp_swigregister HSnapshotFromTgtOp_swigregister(HSnapshotFromTgtOp) class HSnapshotOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HSnapshotOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HSnapshotOp, name) __repr__ = _swig_repr __swig_setmethods__[""vDiskName_""] = _hedvigpyc.HSnapshotOp_vDiskName__set __swig_getmethods__[""vDiskName_""] = _hedvigpyc.HSnapshotOp_vDiskName__get if _newclass:vDiskName_ = _swig_property(_hedvigpyc.HSnapshotOp_vDiskName__get, _hedvigpyc.HSnapshotOp_vDiskName__set) __swig_setmethods__[""snapshotInfo_""] = _hedvigpyc.HSnapshotOp_snapshotInfo__set __swig_getmethods__[""snapshotInfo_""] = _hedvigpyc.HSnapshotOp_snapshotInfo__get if _newclass:snapshotInfo_ = _swig_property(_hedvigpyc.HSnapshotOp_snapshotInfo__get, _hedvigpyc.HSnapshotOp_snapshotInfo__set) def __init__(self): this = _hedvigpyc.new_HSnapshotOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HSnapshotOp __del__ = lambda self : None; HSnapshotOp_swigregister = _hedvigpyc.HSnapshotOp_swigregister HSnapshotOp_swigregister(HSnapshotOp) class HDeleteSnapshotOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HDeleteSnapshotOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HDeleteSnapshotOp, name) __repr__ = _swig_repr __swig_setmethods__[""snapshotName_""] = _hedvigpyc.HDeleteSnapshotOp_snapshotName__set __swig_getmethods__[""snapshotName_""] = _hedvigpyc.HDeleteSnapshotOp_snapshotName__get if _newclass:snapshotName_ = _swig_property(_hedvigpyc.HDeleteSnapshotOp_snapshotName__get, _hedvigpyc.HDeleteSnapshotOp_snapshotName__set) def __init__(self): this = _hedvigpyc.new_HDeleteSnapshotOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HDeleteSnapshotOp __del__ = lambda self : None; HDeleteSnapshotOp_swigregister = _hedvigpyc.HDeleteSnapshotOp_swigregister HDeleteSnapshotOp_swigregister(HDeleteSnapshotOp) class HCreateVirtualDiskOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HCreateVirtualDiskOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HCreateVirtualDiskOp, name) __repr__ = _swig_repr __swig_setmethods__[""vDiskInfo_""] = _hedvigpyc.HCreateVirtualDiskOp_vDiskInfo__set __swig_getmethods__[""vDiskInfo_""] = _hedvigpyc.HCreateVirtualDiskOp_vDiskInfo__get if _newclass:vDiskInfo_ = _swig_property(_hedvigpyc.HCreateVirtualDiskOp_vDiskInfo__get, _hedvigpyc.HCreateVirtualDiskOp_vDiskInfo__set) def __init__(self): this = _hedvigpyc.new_HCreateVirtualDiskOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HCreateVirtualDiskOp __del__ = lambda self : None; HCreateVirtualDiskOp_swigregister = _hedvigpyc.HCreateVirtualDiskOp_swigregister HCreateVirtualDiskOp_swigregister(HCreateVirtualDiskOp) class HResizeVirtualDiskOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HResizeVirtualDiskOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HResizeVirtualDiskOp, name) __repr__ = _swig_repr __swig_setmethods__[""vDiskInfo_""] = _hedvigpyc.HResizeVirtualDiskOp_vDiskInfo__set __swig_getmethods__[""vDiskInfo_""] = _hedvigpyc.HResizeVirtualDiskOp_vDiskInfo__get if _newclass:vDiskInfo_ = _swig_property(_hedvigpyc.HResizeVirtualDiskOp_vDiskInfo__get, _hedvigpyc.HResizeVirtualDiskOp_vDiskInfo__set) def __init__(self): this = _hedvigpyc.new_HResizeVirtualDiskOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HResizeVirtualDiskOp __del__ = lambda self : None; HResizeVirtualDiskOp_swigregister = _hedvigpyc.HResizeVirtualDiskOp_swigregister HResizeVirtualDiskOp_swigregister(HResizeVirtualDiskOp) class HDeleteVirtualDiskOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HDeleteVirtualDiskOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HDeleteVirtualDiskOp, name) __repr__ = _swig_repr __swig_setmethods__[""vDiskName_""] = _hedvigpyc.HDeleteVirtualDiskOp_vDiskName__set __swig_getmethods__[""vDiskName_""] = _hedvigpyc.HDeleteVirtualDiskOp_vDiskName__get if _newclass:vDiskName_ = _swig_property(_hedvigpyc.HDeleteVirtualDiskOp_vDiskName__get, _hedvigpyc.HDeleteVirtualDiskOp_vDiskName__set) def __init__(self): this = _hedvigpyc.new_HDeleteVirtualDiskOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HDeleteVirtualDiskOp __del__ = lambda self : None; HDeleteVirtualDiskOp_swigregister = _hedvigpyc.HDeleteVirtualDiskOp_swigregister HDeleteVirtualDiskOp_swigregister(HDeleteVirtualDiskOp) class HGetIqnOp(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, HGetIqnOp, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, HGetIqnOp, name) __repr__ = _swig_repr __swig_setmethods__[""hostname_""] = _hedvigpyc.HGetIqnOp_hostname__set __swig_getmethods__[""hostname_""] = _hedvigpyc.HGetIqnOp_hostname__get if _newclass:hostname_ = _swig_property(_hedvigpyc.HGetIqnOp_hostname__get, _hedvigpyc.HGetIqnOp_hostname__set) __swig_setmethods__[""iqn_""] = _hedvigpyc.HGetIqnOp_iqn__set __swig_getmethods__[""iqn_""] = _hedvigpyc.HGetIqnOp_iqn__get if _newclass:iqn_ = _swig_property(_hedvigpyc.HGetIqnOp_iqn__get, _hedvigpyc.HGetIqnOp_iqn__set) def __init__(self): this = _hedvigpyc.new_HGetIqnOp() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_HGetIqnOp __del__ = lambda self : None; HGetIqnOp_swigregister = _hedvigpyc.HGetIqnOp_swigregister HGetIqnOp_swigregister(HGetIqnOp) class ObjectStoreType(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, ObjectStoreType, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, ObjectStoreType, name) __repr__ = _swig_repr OpenStack = _hedvigpyc.ObjectStoreType_OpenStack S3 = _hedvigpyc.ObjectStoreType_S3 def __init__(self): this = _hedvigpyc.new_ObjectStoreType() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_ObjectStoreType __del__ = lambda self : None; ObjectStoreType_swigregister = _hedvigpyc.ObjectStoreType_swigregister ObjectStoreType_swigregister(ObjectStoreType) class ObjectStoreFilter(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, ObjectStoreFilter, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, ObjectStoreFilter, name) __repr__ = _swig_repr PREFIX = _hedvigpyc.ObjectStoreFilter_PREFIX MAX_ENTRIES = _hedvigpyc.ObjectStoreFilter_MAX_ENTRIES DIR_PATH = _hedvigpyc.ObjectStoreFilter_DIR_PATH def __init__(self): this = _hedvigpyc.new_ObjectStoreFilter() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_ObjectStoreFilter __del__ = lambda self : None; ObjectStoreFilter_swigregister = _hedvigpyc.ObjectStoreFilter_swigregister ObjectStoreFilter_swigregister(ObjectStoreFilter) class DiskResidence(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, DiskResidence, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, DiskResidence, name) __repr__ = _swig_repr Flash = _hedvigpyc.DiskResidence_Flash HDD = _hedvigpyc.DiskResidence_HDD def __init__(self): this = _hedvigpyc.new_DiskResidence() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_DiskResidence __del__ = lambda self : None; DiskResidence_swigregister = _hedvigpyc.DiskResidence_swigregister DiskResidence_swigregister(DiskResidence) class DiskType(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, DiskType, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, DiskType, name) __repr__ = _swig_repr BLOCK = _hedvigpyc.DiskType_BLOCK NFS_MASTER_DISK = _hedvigpyc.DiskType_NFS_MASTER_DISK NFS_CHILD_DISK = _hedvigpyc.DiskType_NFS_CHILD_DISK OBJECT_STORE_DISK = _hedvigpyc.DiskType_OBJECT_STORE_DISK def __init__(self): this = _hedvigpyc.new_DiskType() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_DiskType __del__ = lambda self : None; DiskType_swigregister = _hedvigpyc.DiskType_swigregister DiskType_swigregister(DiskType) cvar = _hedvigpyc.cvar _DiskResidence_VALUES_TO_NAMES = cvar._DiskResidence_VALUES_TO_NAMES class ReplicationPolicy(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, ReplicationPolicy, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, ReplicationPolicy, name) __repr__ = _swig_repr Agnostic = _hedvigpyc.ReplicationPolicy_Agnostic RackAware = _hedvigpyc.ReplicationPolicy_RackAware DataCenterAware = _hedvigpyc.ReplicationPolicy_DataCenterAware def __init__(self): this = _hedvigpyc.new_ReplicationPolicy() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_ReplicationPolicy __del__ = lambda self : None; ReplicationPolicy_swigregister = _hedvigpyc.ReplicationPolicy_swigregister ReplicationPolicy_swigregister(ReplicationPolicy) _DiskType_VALUES_TO_NAMES = cvar._DiskType_VALUES_TO_NAMES class Consistency(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, Consistency, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, Consistency, name) __repr__ = _swig_repr WEAK = _hedvigpyc.Consistency_WEAK STRONG = _hedvigpyc.Consistency_STRONG def __init__(self): this = _hedvigpyc.new_Consistency() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_Consistency __del__ = lambda self : None; Consistency_swigregister = _hedvigpyc.Consistency_swigregister Consistency_swigregister(Consistency) _ReplicationPolicy_VALUES_TO_NAMES = cvar._ReplicationPolicy_VALUES_TO_NAMES class CloudProvider(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, CloudProvider, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, CloudProvider, name) __repr__ = _swig_repr NONE = _hedvigpyc.CloudProvider_NONE AMAZON = _hedvigpyc.CloudProvider_AMAZON GOOGLE = _hedvigpyc.CloudProvider_GOOGLE def __init__(self): this = _hedvigpyc.new_CloudProvider() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_CloudProvider __del__ = lambda self : None; CloudProvider_swigregister = _hedvigpyc.CloudProvider_swigregister CloudProvider_swigregister(CloudProvider) _Consistency_VALUES_TO_NAMES = cvar._Consistency_VALUES_TO_NAMES class TypeOfClone(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, TypeOfClone, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, TypeOfClone, name) __repr__ = _swig_repr Deep = _hedvigpyc.TypeOfClone_Deep Shallow = _hedvigpyc.TypeOfClone_Shallow def __init__(self): this = _hedvigpyc.new_TypeOfClone() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_TypeOfClone __del__ = lambda self : None; TypeOfClone_swigregister = _hedvigpyc.TypeOfClone_swigregister TypeOfClone_swigregister(TypeOfClone) _CloudProvider_VALUES_TO_NAMES = cvar._CloudProvider_VALUES_TO_NAMES class _CloneInfo__isset(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, _CloneInfo__isset, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, _CloneInfo__isset, name) __repr__ = _swig_repr def __init__(self): this = _hedvigpyc.new__CloneInfo__isset() try: self.this.append(this) except: self.this = this __swig_setmethods__[""baseDisk""] = _hedvigpyc._CloneInfo__isset_baseDisk_set __swig_getmethods__[""baseDisk""] = _hedvigpyc._CloneInfo__isset_baseDisk_get if _newclass:baseDisk = _swig_property(_hedvigpyc._CloneInfo__isset_baseDisk_get, _hedvigpyc._CloneInfo__isset_baseDisk_set) __swig_setmethods__[""snapshot""] = _hedvigpyc._CloneInfo__isset_snapshot_set __swig_getmethods__[""snapshot""] = _hedvigpyc._CloneInfo__isset_snapshot_get if _newclass:snapshot = _swig_property(_hedvigpyc._CloneInfo__isset_snapshot_get, _hedvigpyc._CloneInfo__isset_snapshot_set) __swig_setmethods__[""baseVersion""] = _hedvigpyc._CloneInfo__isset_baseVersion_set __swig_getmethods__[""baseVersion""] = _hedvigpyc._CloneInfo__isset_baseVersion_get if _newclass:baseVersion = _swig_property(_hedvigpyc._CloneInfo__isset_baseVersion_get, _hedvigpyc._CloneInfo__isset_baseVersion_set) __swig_setmethods__[""typeOfClone""] = _hedvigpyc._CloneInfo__isset_typeOfClone_set __swig_getmethods__[""typeOfClone""] = _hedvigpyc._CloneInfo__isset_typeOfClone_get if _newclass:typeOfClone = _swig_property(_hedvigpyc._CloneInfo__isset_typeOfClone_get, _hedvigpyc._CloneInfo__isset_typeOfClone_set) __swig_destroy__ = _hedvigpyc.delete__CloneInfo__isset __del__ = lambda self : None; _CloneInfo__isset_swigregister = _hedvigpyc._CloneInfo__isset_swigregister _CloneInfo__isset_swigregister(_CloneInfo__isset) _TypeOfClone_VALUES_TO_NAMES = cvar._TypeOfClone_VALUES_TO_NAMES class CloneInfo(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, CloneInfo, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, CloneInfo, name) __repr__ = _swig_repr __swig_setmethods__[""baseDisk""] = _hedvigpyc.CloneInfo_baseDisk_set __swig_getmethods__[""baseDisk""] = _hedvigpyc.CloneInfo_baseDisk_get if _newclass:baseDisk = _swig_property(_hedvigpyc.CloneInfo_baseDisk_get, _hedvigpyc.CloneInfo_baseDisk_set) __swig_setmethods__[""snapshot""] = _hedvigpyc.CloneInfo_snapshot_set __swig_getmethods__[""snapshot""] = _hedvigpyc.CloneInfo_snapshot_get if _newclass:snapshot = _swig_property(_hedvigpyc.CloneInfo_snapshot_get, _hedvigpyc.CloneInfo_snapshot_set) __swig_setmethods__[""baseVersion""] = _hedvigpyc.CloneInfo_baseVersion_set __swig_getmethods__[""baseVersion""] = _hedvigpyc.CloneInfo_baseVersion_get if _newclass:baseVersion = _swig_property(_hedvigpyc.CloneInfo_baseVersion_get, _hedvigpyc.CloneInfo_baseVersion_set) __swig_setmethods__[""typeOfClone""] = _hedvigpyc.CloneInfo_typeOfClone_set __swig_getmethods__[""typeOfClone""] = _hedvigpyc.CloneInfo_typeOfClone_get if _newclass:typeOfClone = _swig_property(_hedvigpyc.CloneInfo_typeOfClone_get, _hedvigpyc.CloneInfo_typeOfClone_set) __swig_setmethods__[""__isset""] = _hedvigpyc.CloneInfo___isset_set __swig_getmethods__[""__isset""] = _hedvigpyc.CloneInfo___isset_get if _newclass:__isset = _swig_property(_hedvigpyc.CloneInfo___isset_get, _hedvigpyc.CloneInfo___isset_set) def __init__(self): this = _hedvigpyc.new_CloneInfo() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_CloneInfo __del__ = lambda self : None; CloneInfo_swigregister = _hedvigpyc.CloneInfo_swigregister CloneInfo_swigregister(CloneInfo) class _ReplicationPolicyInfo__isset(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, _ReplicationPolicyInfo__isset, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, _ReplicationPolicyInfo__isset, name) __repr__ = _swig_repr def __init__(self): this = _hedvigpyc.new__ReplicationPolicyInfo__isset() try: self.this.append(this) except: self.this = this __swig_setmethods__[""dataCenterNames""] = _hedvigpyc._ReplicationPolicyInfo__isset_dataCenterNames_set __swig_getmethods__[""dataCenterNames""] = _hedvigpyc._ReplicationPolicyInfo__isset_dataCenterNames_get if _newclass:dataCenterNames = _swig_property(_hedvigpyc._ReplicationPolicyInfo__isset_dataCenterNames_get, _hedvigpyc._ReplicationPolicyInfo__isset_dataCenterNames_set) __swig_destroy__ = _hedvigpyc.delete__ReplicationPolicyInfo__isset __del__ = lambda self : None; _ReplicationPolicyInfo__isset_swigregister = _hedvigpyc._ReplicationPolicyInfo__isset_swigregister _ReplicationPolicyInfo__isset_swigregister(_ReplicationPolicyInfo__isset) class ReplicationPolicyInfo(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, ReplicationPolicyInfo, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, ReplicationPolicyInfo, name) __repr__ = _swig_repr __swig_setmethods__[""dataCenterNames""] = _hedvigpyc.ReplicationPolicyInfo_dataCenterNames_set __swig_getmethods__[""dataCenterNames""] = _hedvigpyc.ReplicationPolicyInfo_dataCenterNames_get if _newclass:dataCenterNames = _swig_property(_hedvigpyc.ReplicationPolicyInfo_dataCenterNames_get, _hedvigpyc.ReplicationPolicyInfo_dataCenterNames_set) __swig_setmethods__[""__isset""] = _hedvigpyc.ReplicationPolicyInfo___isset_set __swig_getmethods__[""__isset""] = _hedvigpyc.ReplicationPolicyInfo___isset_get if _newclass:__isset = _swig_property(_hedvigpyc.ReplicationPolicyInfo___isset_get, _hedvigpyc.ReplicationPolicyInfo___isset_set) def __init__(self): this = _hedvigpyc.new_ReplicationPolicyInfo() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_ReplicationPolicyInfo __del__ = lambda self : None; ReplicationPolicyInfo_swigregister = _hedvigpyc.ReplicationPolicyInfo_swigregister ReplicationPolicyInfo_swigregister(ReplicationPolicyInfo) class _VDiskInfo__isset(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, _VDiskInfo__isset, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, _VDiskInfo__isset, name) __repr__ = _swig_repr def __init__(self): this = _hedvigpyc.new__VDiskInfo__isset() try: self.this.append(this) except: self.this = this __swig_setmethods__[""vDiskName""] = _hedvigpyc._VDiskInfo__isset_vDiskName_set __swig_getmethods__[""vDiskName""] = _hedvigpyc._VDiskInfo__isset_vDiskName_get if _newclass:vDiskName = _swig_property(_hedvigpyc._VDiskInfo__isset_vDiskName_get, _hedvigpyc._VDiskInfo__isset_vDiskName_set) __swig_setmethods__[""createdBy""] = _hedvigpyc._VDiskInfo__isset_createdBy_set __swig_getmethods__[""createdBy""] = _hedvigpyc._VDiskInfo__isset_createdBy_get if _newclass:createdBy = _swig_property(_hedvigpyc._VDiskInfo__isset_createdBy_get, _hedvigpyc._VDiskInfo__isset_createdBy_set) __swig_setmethods__[""size""] = _hedvigpyc._VDiskInfo__isset_size_set __swig_getmethods__[""size""] = _hedvigpyc._VDiskInfo__isset_size_get if _newclass:size = _swig_property(_hedvigpyc._VDiskInfo__isset_size_get, _hedvigpyc._VDiskInfo__isset_size_set) __swig_setmethods__[""replicationFactor""] = _hedvigpyc._VDiskInfo__isset_replicationFactor_set __swig_getmethods__[""replicationFactor""] = _hedvigpyc._VDiskInfo__isset_replicationFactor_get if _newclass:replicationFactor = _swig_property(_hedvigpyc._VDiskInfo__isset_replicationFactor_get, _hedvigpyc._VDiskInfo__isset_replicationFactor_set) __swig_setmethods__[""residence""] = _hedvigpyc._VDiskInfo__isset_residence_set __swig_getmethods__[""residence""] = _hedvigpyc._VDiskInfo__isset_residence_get if _newclass:residence = _swig_property(_hedvigpyc._VDiskInfo__isset_residence_get, _hedvigpyc._VDiskInfo__isset_residence_set) __swig_setmethods__[""replicationPolicy""] = _hedvigpyc._VDiskInfo__isset_replicationPolicy_set __swig_getmethods__[""replicationPolicy""] = _hedvigpyc._VDiskInfo__isset_replicationPolicy_get if _newclass:replicationPolicy = _swig_property(_hedvigpyc._VDiskInfo__isset_replicationPolicy_get, _hedvigpyc._VDiskInfo__isset_replicationPolicy_set) __swig_setmethods__[""mntLocation""] = _hedvigpyc._VDiskInfo__isset_mntLocation_set __swig_getmethods__[""mntLocation""] = _hedvigpyc._VDiskInfo__isset_mntLocation_get if _newclass:mntLocation = _swig_property(_hedvigpyc._VDiskInfo__isset_mntLocation_get, _hedvigpyc._VDiskInfo__isset_mntLocation_set) __swig_setmethods__[""description""] = _hedvigpyc._VDiskInfo__isset_description_set __swig_getmethods__[""description""] = _hedvigpyc._VDiskInfo__isset_description_get if _newclass:description = _swig_property(_hedvigpyc._VDiskInfo__isset_description_get, _hedvigpyc._VDiskInfo__isset_description_set) __swig_setmethods__[""generationNbr""] = _hedvigpyc._VDiskInfo__isset_generationNbr_set __swig_getmethods__[""generationNbr""] = _hedvigpyc._VDiskInfo__isset_generationNbr_get if _newclass:generationNbr = _swig_property(_hedvigpyc._VDiskInfo__isset_generationNbr_get, _hedvigpyc._VDiskInfo__isset_generationNbr_set) __swig_setmethods__[""blockSize""] = _hedvigpyc._VDiskInfo__isset_blockSize_set __swig_getmethods__[""blockSize""] = _hedvigpyc._VDiskInfo__isset_blockSize_get if _newclass:blockSize = _swig_property(_hedvigpyc._VDiskInfo__isset_blockSize_get, _hedvigpyc._VDiskInfo__isset_blockSize_set) __swig_setmethods__[""clusteredfilesystem""] = _hedvigpyc._VDiskInfo__isset_clusteredfilesystem_set __swig_getmethods__[""clusteredfilesystem""] = _hedvigpyc._VDiskInfo__isset_clusteredfilesystem_get if _newclass:clusteredfilesystem = _swig_property(_hedvigpyc._VDiskInfo__isset_clusteredfilesystem_get, _hedvigpyc._VDiskInfo__isset_clusteredfilesystem_set) __swig_setmethods__[""versionCounter""] = _hedvigpyc._VDiskInfo__isset_versionCounter_set __swig_getmethods__[""versionCounter""] = _hedvigpyc._VDiskInfo__isset_versionCounter_get if _newclass:versionCounter = _swig_property(_hedvigpyc._VDiskInfo__isset_versionCounter_get, _hedvigpyc._VDiskInfo__isset_versionCounter_set) __swig_setmethods__[""vTreeBuffer""] = _hedvigpyc._VDiskInfo__isset_vTreeBuffer_set __swig_getmethods__[""vTreeBuffer""] = _hedvigpyc._VDiskInfo__isset_vTreeBuffer_get if _newclass:vTreeBuffer = _swig_property(_hedvigpyc._VDiskInfo__isset_vTreeBuffer_get, _hedvigpyc._VDiskInfo__isset_vTreeBuffer_set) __swig_setmethods__[""cloneInfo""] = _hedvigpyc._VDiskInfo__isset_cloneInfo_set __swig_getmethods__[""cloneInfo""] = _hedvigpyc._VDiskInfo__isset_cloneInfo_get if _newclass:cloneInfo = _swig_property(_hedvigpyc._VDiskInfo__isset_cloneInfo_get, _hedvigpyc._VDiskInfo__isset_cloneInfo_set) __swig_setmethods__[""isClone""] = _hedvigpyc._VDiskInfo__isset_isClone_set __swig_getmethods__[""isClone""] = _hedvigpyc._VDiskInfo__isset_isClone_get if _newclass:isClone = _swig_property(_hedvigpyc._VDiskInfo__isset_isClone_get, _hedvigpyc._VDiskInfo__isset_isClone_set) __swig_setmethods__[""replicationPolicyInfo""] = _hedvigpyc._VDiskInfo__isset_replicationPolicyInfo_set __swig_getmethods__[""replicationPolicyInfo""] = _hedvigpyc._VDiskInfo__isset_replicationPolicyInfo_get if _newclass:replicationPolicyInfo = _swig_property(_hedvigpyc._VDiskInfo__isset_replicationPolicyInfo_get, _hedvigpyc._VDiskInfo__isset_replicationPolicyInfo_set) __swig_setmethods__[""targetLocations""] = _hedvigpyc._VDiskInfo__isset_targetLocations_set __swig_getmethods__[""targetLocations""] = _hedvigpyc._VDiskInfo__isset_targetLocations_get if _newclass:targetLocations = _swig_property(_hedvigpyc._VDiskInfo__isset_targetLocations_get, _hedvigpyc._VDiskInfo__isset_targetLocations_set) __swig_setmethods__[""scsisn""] = _hedvigpyc._VDiskInfo__isset_scsisn_set __swig_getmethods__[""scsisn""] = _hedvigpyc._VDiskInfo__isset_scsisn_get if _newclass:scsisn = _swig_property(_hedvigpyc._VDiskInfo__isset_scsisn_get, _hedvigpyc._VDiskInfo__isset_scsisn_set) __swig_setmethods__[""exportedBlockSize""] = _hedvigpyc._VDiskInfo__isset_exportedBlockSize_set __swig_getmethods__[""exportedBlockSize""] = _hedvigpyc._VDiskInfo__isset_exportedBlockSize_get if _newclass:exportedBlockSize = _swig_property(_hedvigpyc._VDiskInfo__isset_exportedBlockSize_get, _hedvigpyc._VDiskInfo__isset_exportedBlockSize_set) __swig_setmethods__[""cacheEnable""] = _hedvigpyc._VDiskInfo__isset_cacheEnable_set __swig_getmethods__[""cacheEnable""] = _hedvigpyc._VDiskInfo__isset_cacheEnable_get if _newclass:cacheEnable = _swig_property(_hedvigpyc._VDiskInfo__isset_cacheEnable_get, _hedvigpyc._VDiskInfo__isset_cacheEnable_set) __swig_setmethods__[""diskType""] = _hedvigpyc._VDiskInfo__isset_diskType_set __swig_getmethods__[""diskType""] = _hedvigpyc._VDiskInfo__isset_diskType_get if _newclass:diskType = _swig_property(_hedvigpyc._VDiskInfo__isset_diskType_get, _hedvigpyc._VDiskInfo__isset_diskType_set) __swig_setmethods__[""immutable""] = _hedvigpyc._VDiskInfo__isset_immutable_set __swig_getmethods__[""immutable""] = _hedvigpyc._VDiskInfo__isset_immutable_get if _newclass:immutable = _swig_property(_hedvigpyc._VDiskInfo__isset_immutable_get, _hedvigpyc._VDiskInfo__isset_immutable_set) __swig_setmethods__[""compressed""] = _hedvigpyc._VDiskInfo__isset_compressed_set __swig_getmethods__[""compressed""] = _hedvigpyc._VDiskInfo__isset_compressed_get if _newclass:compressed = _swig_property(_hedvigpyc._VDiskInfo__isset_compressed_get, _hedvigpyc._VDiskInfo__isset_compressed_set) __swig_setmethods__[""dedup""] = _hedvigpyc._VDiskInfo__isset_dedup_set __swig_getmethods__[""dedup""] = _hedvigpyc._VDiskInfo__isset_dedup_get if _newclass:dedup = _swig_property(_hedvigpyc._VDiskInfo__isset_dedup_get, _hedvigpyc._VDiskInfo__isset_dedup_set) __swig_setmethods__[""dedupBuckets""] = _hedvigpyc._VDiskInfo__isset_dedupBuckets_set __swig_getmethods__[""dedupBuckets""] = _hedvigpyc._VDiskInfo__isset_dedupBuckets_get if _newclass:dedupBuckets = _swig_property(_hedvigpyc._VDiskInfo__isset_dedupBuckets_get, _hedvigpyc._VDiskInfo__isset_dedupBuckets_set) __swig_setmethods__[""cloudEnabled""] = _hedvigpyc._VDiskInfo__isset_cloudEnabled_set __swig_getmethods__[""cloudEnabled""] = _hedvigpyc._VDiskInfo__isset_cloudEnabled_get if _newclass:cloudEnabled = _swig_property(_hedvigpyc._VDiskInfo__isset_cloudEnabled_get, _hedvigpyc._VDiskInfo__isset_cloudEnabled_set) __swig_setmethods__[""cloudProvider""] = _hedvigpyc._VDiskInfo__isset_cloudProvider_set __swig_getmethods__[""cloudProvider""] = _hedvigpyc._VDiskInfo__isset_cloudProvider_get if _newclass:cloudProvider = _swig_property(_hedvigpyc._VDiskInfo__isset_cloudProvider_get, _hedvigpyc._VDiskInfo__isset_cloudProvider_set) __swig_setmethods__[""masterVDiskName""] = _hedvigpyc._VDiskInfo__isset_masterVDiskName_set __swig_getmethods__[""masterVDiskName""] = _hedvigpyc._VDiskInfo__isset_masterVDiskName_get if _newclass:masterVDiskName = _swig_property(_hedvigpyc._VDiskInfo__isset_masterVDiskName_get, _hedvigpyc._VDiskInfo__isset_masterVDiskName_set) __swig_destroy__ = _hedvigpyc.delete__VDiskInfo__isset __del__ = lambda self : None; _VDiskInfo__isset_swigregister = _hedvigpyc._VDiskInfo__isset_swigregister _VDiskInfo__isset_swigregister(_VDiskInfo__isset) class VDiskInfo(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, VDiskInfo, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, VDiskInfo, name) __repr__ = _swig_repr __swig_setmethods__[""vDiskName""] = _hedvigpyc.VDiskInfo_vDiskName_set __swig_getmethods__[""vDiskName""] = _hedvigpyc.VDiskInfo_vDiskName_get if _newclass:vDiskName = _swig_property(_hedvigpyc.VDiskInfo_vDiskName_get, _hedvigpyc.VDiskInfo_vDiskName_set) __swig_setmethods__[""createdBy""] = _hedvigpyc.VDiskInfo_createdBy_set __swig_getmethods__[""createdBy""] = _hedvigpyc.VDiskInfo_createdBy_get if _newclass:createdBy = _swig_property(_hedvigpyc.VDiskInfo_createdBy_get, _hedvigpyc.VDiskInfo_createdBy_set) __swig_setmethods__[""size""] = _hedvigpyc.VDiskInfo_size_set __swig_getmethods__[""size""] = _hedvigpyc.VDiskInfo_size_get if _newclass:size = _swig_property(_hedvigpyc.VDiskInfo_size_get, _hedvigpyc.VDiskInfo_size_set) __swig_setmethods__[""replicationFactor""] = _hedvigpyc.VDiskInfo_replicationFactor_set __swig_getmethods__[""replicationFactor""] = _hedvigpyc.VDiskInfo_replicationFactor_get if _newclass:replicationFactor = _swig_property(_hedvigpyc.VDiskInfo_replicationFactor_get, _hedvigpyc.VDiskInfo_replicationFactor_set) __swig_setmethods__[""residence""] = _hedvigpyc.VDiskInfo_residence_set __swig_getmethods__[""residence""] = _hedvigpyc.VDiskInfo_residence_get if _newclass:residence = _swig_property(_hedvigpyc.VDiskInfo_residence_get, _hedvigpyc.VDiskInfo_residence_set) __swig_setmethods__[""replicationPolicy""] = _hedvigpyc.VDiskInfo_replicationPolicy_set __swig_getmethods__[""replicationPolicy""] = _hedvigpyc.VDiskInfo_replicationPolicy_get if _newclass:replicationPolicy = _swig_property(_hedvigpyc.VDiskInfo_replicationPolicy_get, _hedvigpyc.VDiskInfo_replicationPolicy_set) __swig_setmethods__[""mntLocation""] = _hedvigpyc.VDiskInfo_mntLocation_set __swig_getmethods__[""mntLocation""] = _hedvigpyc.VDiskInfo_mntLocation_get if _newclass:mntLocation = _swig_property(_hedvigpyc.VDiskInfo_mntLocation_get, _hedvigpyc.VDiskInfo_mntLocation_set) __swig_setmethods__[""description""] = _hedvigpyc.VDiskInfo_description_set __swig_getmethods__[""description""] = _hedvigpyc.VDiskInfo_description_get if _newclass:description = _swig_property(_hedvigpyc.VDiskInfo_description_get, _hedvigpyc.VDiskInfo_description_set) __swig_setmethods__[""generationNbr""] = _hedvigpyc.VDiskInfo_generationNbr_set __swig_getmethods__[""generationNbr""] = _hedvigpyc.VDiskInfo_generationNbr_get if _newclass:generationNbr = _swig_property(_hedvigpyc.VDiskInfo_generationNbr_get, _hedvigpyc.VDiskInfo_generationNbr_set) __swig_setmethods__[""blockSize""] = _hedvigpyc.VDiskInfo_blockSize_set __swig_getmethods__[""blockSize""] = _hedvigpyc.VDiskInfo_blockSize_get if _newclass:blockSize = _swig_property(_hedvigpyc.VDiskInfo_blockSize_get, _hedvigpyc.VDiskInfo_blockSize_set) __swig_setmethods__[""clusteredfilesystem""] = _hedvigpyc.VDiskInfo_clusteredfilesystem_set __swig_getmethods__[""clusteredfilesystem""] = _hedvigpyc.VDiskInfo_clusteredfilesystem_get if _newclass:clusteredfilesystem = _swig_property(_hedvigpyc.VDiskInfo_clusteredfilesystem_get, _hedvigpyc.VDiskInfo_clusteredfilesystem_set) __swig_setmethods__[""versionCounter""] = _hedvigpyc.VDiskInfo_versionCounter_set __swig_getmethods__[""versionCounter""] = _hedvigpyc.VDiskInfo_versionCounter_get if _newclass:versionCounter = _swig_property(_hedvigpyc.VDiskInfo_versionCounter_get, _hedvigpyc.VDiskInfo_versionCounter_set) __swig_setmethods__[""vTreeBuffer""] = _hedvigpyc.VDiskInfo_vTreeBuffer_set __swig_getmethods__[""vTreeBuffer""] = _hedvigpyc.VDiskInfo_vTreeBuffer_get if _newclass:vTreeBuffer = _swig_property(_hedvigpyc.VDiskInfo_vTreeBuffer_get, _hedvigpyc.VDiskInfo_vTreeBuffer_set) __swig_setmethods__[""cloneInfo""] = _hedvigpyc.VDiskInfo_cloneInfo_set __swig_getmethods__[""cloneInfo""] = _hedvigpyc.VDiskInfo_cloneInfo_get if _newclass:cloneInfo = _swig_property(_hedvigpyc.VDiskInfo_cloneInfo_get, _hedvigpyc.VDiskInfo_cloneInfo_set) __swig_setmethods__[""isClone""] = _hedvigpyc.VDiskInfo_isClone_set __swig_getmethods__[""isClone""] = _hedvigpyc.VDiskInfo_isClone_get if _newclass:isClone = _swig_property(_hedvigpyc.VDiskInfo_isClone_get, _hedvigpyc.VDiskInfo_isClone_set) __swig_setmethods__[""replicationPolicyInfo""] = _hedvigpyc.VDiskInfo_replicationPolicyInfo_set __swig_getmethods__[""replicationPolicyInfo""] = _hedvigpyc.VDiskInfo_replicationPolicyInfo_get if _newclass:replicationPolicyInfo = _swig_property(_hedvigpyc.VDiskInfo_replicationPolicyInfo_get, _hedvigpyc.VDiskInfo_replicationPolicyInfo_set) __swig_setmethods__[""targetLocations""] = _hedvigpyc.VDiskInfo_targetLocations_set __swig_getmethods__[""targetLocations""] = _hedvigpyc.VDiskInfo_targetLocations_get if _newclass:targetLocations = _swig_property(_hedvigpyc.VDiskInfo_targetLocations_get, _hedvigpyc.VDiskInfo_targetLocations_set) __swig_setmethods__[""scsisn""] = _hedvigpyc.VDiskInfo_scsisn_set __swig_getmethods__[""scsisn""] = _hedvigpyc.VDiskInfo_scsisn_get if _newclass:scsisn = _swig_property(_hedvigpyc.VDiskInfo_scsisn_get, _hedvigpyc.VDiskInfo_scsisn_set) __swig_setmethods__[""exportedBlockSize""] = _hedvigpyc.VDiskInfo_exportedBlockSize_set __swig_getmethods__[""exportedBlockSize""] = _hedvigpyc.VDiskInfo_exportedBlockSize_get if _newclass:exportedBlockSize = _swig_property(_hedvigpyc.VDiskInfo_exportedBlockSize_get, _hedvigpyc.VDiskInfo_exportedBlockSize_set) __swig_setmethods__[""cacheEnable""] = _hedvigpyc.VDiskInfo_cacheEnable_set __swig_getmethods__[""cacheEnable""] = _hedvigpyc.VDiskInfo_cacheEnable_get if _newclass:cacheEnable = _swig_property(_hedvigpyc.VDiskInfo_cacheEnable_get, _hedvigpyc.VDiskInfo_cacheEnable_set) __swig_setmethods__[""diskType""] = _hedvigpyc.VDiskInfo_diskType_set __swig_getmethods__[""diskType""] = _hedvigpyc.VDiskInfo_diskType_get if _newclass:diskType = _swig_property(_hedvigpyc.VDiskInfo_diskType_get, _hedvigpyc.VDiskInfo_diskType_set) __swig_setmethods__[""immutable""] = _hedvigpyc.VDiskInfo_immutable_set __swig_getmethods__[""immutable""] = _hedvigpyc.VDiskInfo_immutable_get if _newclass:immutable = _swig_property(_hedvigpyc.VDiskInfo_immutable_get, _hedvigpyc.VDiskInfo_immutable_set) __swig_setmethods__[""compressed""] = _hedvigpyc.VDiskInfo_compressed_set __swig_getmethods__[""compressed""] = _hedvigpyc.VDiskInfo_compressed_get if _newclass:compressed = _swig_property(_hedvigpyc.VDiskInfo_compressed_get, _hedvigpyc.VDiskInfo_compressed_set) __swig_setmethods__[""dedup""] = _hedvigpyc.VDiskInfo_dedup_set __swig_getmethods__[""dedup""] = _hedvigpyc.VDiskInfo_dedup_get if _newclass:dedup = _swig_property(_hedvigpyc.VDiskInfo_dedup_get, _hedvigpyc.VDiskInfo_dedup_set) __swig_setmethods__[""dedupBuckets""] = _hedvigpyc.VDiskInfo_dedupBuckets_set __swig_getmethods__[""dedupBuckets""] = _hedvigpyc.VDiskInfo_dedupBuckets_get if _newclass:dedupBuckets = _swig_property(_hedvigpyc.VDiskInfo_dedupBuckets_get, _hedvigpyc.VDiskInfo_dedupBuckets_set) __swig_setmethods__[""cloudEnabled""] = _hedvigpyc.VDiskInfo_cloudEnabled_set __swig_getmethods__[""cloudEnabled""] = _hedvigpyc.VDiskInfo_cloudEnabled_get if _newclass:cloudEnabled = _swig_property(_hedvigpyc.VDiskInfo_cloudEnabled_get, _hedvigpyc.VDiskInfo_cloudEnabled_set) __swig_setmethods__[""cloudProvider""] = _hedvigpyc.VDiskInfo_cloudProvider_set __swig_getmethods__[""cloudProvider""] = _hedvigpyc.VDiskInfo_cloudProvider_get if _newclass:cloudProvider = _swig_property(_hedvigpyc.VDiskInfo_cloudProvider_get, _hedvigpyc.VDiskInfo_cloudProvider_set) __swig_setmethods__[""masterVDiskName""] = _hedvigpyc.VDiskInfo_masterVDiskName_set __swig_getmethods__[""masterVDiskName""] = _hedvigpyc.VDiskInfo_masterVDiskName_get if _newclass:masterVDiskName = _swig_property(_hedvigpyc.VDiskInfo_masterVDiskName_get, _hedvigpyc.VDiskInfo_masterVDiskName_set) __swig_setmethods__[""__isset""] = _hedvigpyc.VDiskInfo___isset_set __swig_getmethods__[""__isset""] = _hedvigpyc.VDiskInfo___isset_get if _newclass:__isset = _swig_property(_hedvigpyc.VDiskInfo___isset_get, _hedvigpyc.VDiskInfo___isset_set) def __init__(self): this = _hedvigpyc.new_VDiskInfo() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_VDiskInfo __del__ = lambda self : None; VDiskInfo_swigregister = _hedvigpyc.VDiskInfo_swigregister VDiskInfo_swigregister(VDiskInfo) class _SnapshotInfo__isset(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, _SnapshotInfo__isset, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, _SnapshotInfo__isset, name) __repr__ = _swig_repr def __init__(self): this = _hedvigpyc.new__SnapshotInfo__isset() try: self.this.append(this) except: self.this = this __swig_setmethods__[""snapshot""] = _hedvigpyc._SnapshotInfo__isset_snapshot_set __swig_getmethods__[""snapshot""] = _hedvigpyc._SnapshotInfo__isset_snapshot_get if _newclass:snapshot = _swig_property(_hedvigpyc._SnapshotInfo__isset_snapshot_get, _hedvigpyc._SnapshotInfo__isset_snapshot_set) __swig_setmethods__[""vDiskInfo""] = _hedvigpyc._SnapshotInfo__isset_vDiskInfo_set __swig_getmethods__[""vDiskInfo""] = _hedvigpyc._SnapshotInfo__isset_vDiskInfo_get if _newclass:vDiskInfo = _swig_property(_hedvigpyc._SnapshotInfo__isset_vDiskInfo_get, _hedvigpyc._SnapshotInfo__isset_vDiskInfo_set) __swig_setmethods__[""details""] = _hedvigpyc._SnapshotInfo__isset_details_set __swig_getmethods__[""details""] = _hedvigpyc._SnapshotInfo__isset_details_get if _newclass:details = _swig_property(_hedvigpyc._SnapshotInfo__isset_details_get, _hedvigpyc._SnapshotInfo__isset_details_set) __swig_destroy__ = _hedvigpyc.delete__SnapshotInfo__isset __del__ = lambda self : None; _SnapshotInfo__isset_swigregister = _hedvigpyc._SnapshotInfo__isset_swigregister _SnapshotInfo__isset_swigregister(_SnapshotInfo__isset) class SnapshotInfo(_object): __swig_setmethods__ = {} __setattr__ = lambda self, name, value: _swig_setattr(self, SnapshotInfo, name, value) __swig_getmethods__ = {} __getattr__ = lambda self, name: _swig_getattr(self, SnapshotInfo, name) __repr__ = _swig_repr __swig_setmethods__[""snapshot""] = _hedvigpyc.SnapshotInfo_snapshot_set __swig_getmethods__[""snapshot""] = _hedvigpyc.SnapshotInfo_snapshot_get if _newclass:snapshot = _swig_property(_hedvigpyc.SnapshotInfo_snapshot_get, _hedvigpyc.SnapshotInfo_snapshot_set) __swig_setmethods__[""vDiskInfo""] = _hedvigpyc.SnapshotInfo_vDiskInfo_set __swig_getmethods__[""vDiskInfo""] = _hedvigpyc.SnapshotInfo_vDiskInfo_get if _newclass:vDiskInfo = _swig_property(_hedvigpyc.SnapshotInfo_vDiskInfo_get, _hedvigpyc.SnapshotInfo_vDiskInfo_set) __swig_setmethods__[""details""] = _hedvigpyc.SnapshotInfo_details_set __swig_getmethods__[""details""] = _hedvigpyc.SnapshotInfo_details_get if _newclass:details = _swig_property(_hedvigpyc.SnapshotInfo_details_get, _hedvigpyc.SnapshotInfo_details_set) __swig_setmethods__[""__isset""] = _hedvigpyc.SnapshotInfo___isset_set __swig_getmethods__[""__isset""] = _hedvigpyc.SnapshotInfo___isset_get if _newclass:__isset = _swig_property(_hedvigpyc.SnapshotInfo___isset_get, _hedvigpyc.SnapshotInfo___isset_set) def __init__(self): this = _hedvigpyc.new_SnapshotInfo() try: self.this.append(this) except: self.this = this __swig_destroy__ = _hedvigpyc.delete_SnapshotInfo __del__ = lambda self : None; SnapshotInfo_swigregister = _hedvigpyc.SnapshotInfo_swigregister SnapshotInfo_swigregister(SnapshotInfo) def hedvigpycInit(*args): return _hedvigpyc.hedvigpycInit(*args) hedvigpycInit = _hedvigpyc.hedvigpycInit def hedvigpycShutdown(): return _hedvigpyc.hedvigpycShutdown() hedvigpycShutdown = _hedvigpyc.hedvigpycShutdown # This file is compatible with both classic and new-style classes. ",,2741,0
openstack%2Fopenstack-ansible~stable%2Fpike~I8ad53107bf42997864fb9322d0271419f85498d8,openstack/openstack-ansible,stable/pike,I8ad53107bf42997864fb9322d0271419f85498d8,Update all SHAs for 16.0.25,MERGED,2018-12-23 17:00:01.000000000,2019-01-08 12:17:29.000000000,2019-01-08 12:17:29.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 17:00:01.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'group_vars/all/all.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/remove-machinectl-workarounds-d67a4739f6385f54.yaml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f4c7cd442cedf723792ec4c01dd64c041129c0f8', 'message': 'Update all SHAs for 16.0.25\n\nThis patch:\n- updates all the roles to the latest available stable SHAs\n- copies the release notes from the updated roles into the integrated repo\n- updates all the OpenStack Service SHAs\n\nDepends-On: https://review.openstack.org/627082\nChange-Id: I8ad53107bf42997864fb9322d0271419f85498d8\n'}]",0,627083,f4c7cd442cedf723792ec4c01dd64c041129c0f8,8,4,1,17068,,,0,"Update all SHAs for 16.0.25

This patch:
- updates all the roles to the latest available stable SHAs
- copies the release notes from the updated roles into the integrated repo
- updates all the OpenStack Service SHAs

Depends-On: https://review.openstack.org/627082
Change-Id: I8ad53107bf42997864fb9322d0271419f85498d8
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/83/627083/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'group_vars/all/all.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/remove-machinectl-workarounds-d67a4739f6385f54.yaml', 'ansible-role-requirements.yml']",5,f4c7cd442cedf723792ec4c01dd64c041129c0f8,release_osa, version: 0eb4f4c98ed12175ceedd005272c562509fd6b99 version: fc9df14b01908b5b8b038f6fbc9edb52c4765ddc, version: 86d1ca845fcd09a3322109da8b61474e5e77c4d1 version: 0b4eb4162a34d2f9947aca2f9e7f42504b5ba010,43,36
openstack%2Ftempest~master~Ie818a17a0c5d5f2ddc3d778a100cecc8ca08ec81,openstack/tempest,master,Ie818a17a0c5d5f2ddc3d778a100cecc8ca08ec81,Change execfile()d with  to execfile with,ABANDONED,2018-12-12 08:45:46.000000000,2019-01-08 12:05:01.000000000,,"[{'_account_id': 5689}, {'_account_id': 10068}, {'_account_id': 10385}, {'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-12 08:45:46.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d3cd260cefe3799aa57e9914eab2d86c46788b48', 'message': 'Change execfile()d with  to execfile with\n\nOccasionally I saw this mistake and tried to correct it.\n\nChange-Id: Ie818a17a0c5d5f2ddc3d778a100cecc8ca08ec81\nSigned-off-by: lixiaoli <li.xiaoli@99cloud.net>\n'}]",2,624609,d3cd260cefe3799aa57e9914eab2d86c46788b48,7,5,1,29655,,,0,"Change execfile()d with  to execfile with

Occasionally I saw this mistake and tried to correct it.

Change-Id: Ie818a17a0c5d5f2ddc3d778a100cecc8ca08ec81
Signed-off-by: lixiaoli <li.xiaoli@99cloud.net>
",git fetch https://review.opendev.org/openstack/tempest refs/changes/09/624609/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,d3cd260cefe3799aa57e9914eab2d86c46788b48,fix_docs,# This file is execfile with the current directory set to its containing dir.,# This file is execfile()d with the current directory set to its containing dir.,1,1
openstack%2Fansible-hardening~master~I7c68f4e5f7248aedd3cdae734aac6d97a8ce058b,openstack/ansible-hardening,master,I7c68f4e5f7248aedd3cdae734aac6d97a8ce058b,cleanup: use updated conditionals,MERGED,2019-01-07 17:56:20.000000000,2019-01-08 11:58:31.000000000,2019-01-08 09:20:19.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-07 17:56:20.000000000', 'files': ['tasks/main.yml', 'tasks/rhel7stig/auth.yml', 'tasks/rhel7stig/aide.yml', 'tasks/rhel7stig/zypper.yml', 'tasks/rhel7stig/rpm.yml', 'tasks/rhel7stig/file_perms.yml', 'tasks/rhel7stig/lsm.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/b792753b346cd2a3d1999296e5b525a3311f71c4', 'message': 'cleanup: use updated conditionals\n\nThis role made use of conditionals that still used filters, this\npatch removes them all and switches them to the new system.\n\nChange-Id: I7c68f4e5f7248aedd3cdae734aac6d97a8ce058b\n'}]",0,629022,b792753b346cd2a3d1999296e5b525a3311f71c4,8,3,1,1004,,,0,"cleanup: use updated conditionals

This role made use of conditionals that still used filters, this
patch removes them all and switches them to the new system.

Change-Id: I7c68f4e5f7248aedd3cdae734aac6d97a8ce058b
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/22/629022/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/rhel7stig/auth.yml', 'tasks/rhel7stig/aide.yml', 'tasks/rhel7stig/zypper.yml', 'tasks/rhel7stig/rpm.yml', 'tasks/rhel7stig/file_perms.yml', 'tasks/rhel7stig/lsm.yml']",7,b792753b346cd2a3d1999296e5b525a3311f71c4,, changed_when: selinux_status_change is changed and ansible_selinux.status != 'disabled', changed_when: selinux_status_change | changed and ansible_selinux.status != 'disabled',10,10
openstack%2Fdevstack-gate~master~I5fea31810ef572a397d682415ba160f3c0ccfc18,openstack/devstack-gate,master,I5fea31810ef572a397d682415ba160f3c0ccfc18,Include TEMPEST_PLUGINS in reproduce.sh,ABANDONED,2017-07-26 13:34:09.000000000,2019-01-08 11:57:59.000000000,,"[{'_account_id': 3}, {'_account_id': 13252}]","[{'number': 1, 'created': '2017-07-26 13:34:09.000000000', 'files': ['devstack-vm-gate.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/066be77a3215eb14aa2b34f521be3edb5261af23', 'message': 'Include TEMPEST_PLUGINS in reproduce.sh\n\nWhen tempest plugins are distinct from their primary repository, we need\nto set TEMPEST_PLUGINS in local.conf in order for devstack to pick it\nup. Without this patch, reproduce.sh ignores this setting, which makes\nit impossible to reproduce a build using a tempest plugin. This patch\nadds the parameter to the environment filter in the reproduce function\nand ensures that the localrc uses it if found.\n\nChange-Id: I5fea31810ef572a397d682415ba160f3c0ccfc18\n'}]",1,487421,066be77a3215eb14aa2b34f521be3edb5261af23,4,2,1,8482,,,0,"Include TEMPEST_PLUGINS in reproduce.sh

When tempest plugins are distinct from their primary repository, we need
to set TEMPEST_PLUGINS in local.conf in order for devstack to pick it
up. Without this patch, reproduce.sh ignores this setting, which makes
it impossible to reproduce a build using a tempest plugin. This patch
adds the parameter to the environment filter in the reproduce function
and ensures that the localrc uses it if found.

Change-Id: I5fea31810ef572a397d682415ba160f3c0ccfc18
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/21/487421/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'functions.sh']",2,066be77a3215eb14aa2b34f521be3edb5261af23,reproduce_tempest_plugins, for KEY in $(printenv -0 | grep -z -Z '\(DEVSTACK\|GRENADE_PLUGINRC\|TEMPEST_PLUGINS\|ZUUL\)' | sed -z -n 's/^\([^=]\+\)=.*/\1\n/p'); do, for KEY in $(printenv -0 | grep -z -Z '\(DEVSTACK\|GRENADE_PLUGINRC\|ZUUL\)' | sed -z -n 's/^\([^=]\+\)=.*/\1\n/p'); do,2,1
openstack%2Fansible-role-tripleo-modify-image~master~I9f411b8f2b50e585f378e3787da9a4834c8e4149,openstack/ansible-role-tripleo-modify-image,master,I9f411b8f2b50e585f378e3787da9a4834c8e4149,Replace scenario001-multinode with scenario001-standalone,MERGED,2018-11-27 12:20:37.000000000,2019-01-08 11:44:13.000000000,2019-01-08 11:44:13.000000000,"[{'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27898}]","[{'number': 1, 'created': '2018-11-27 12:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/1f828d44793a2ffe71196f15362c8ff93c32274f', 'message': 'Replace scenario001-multinode with scenario001-standalone\n\nThe scenario001-standalone job is added in the depends-on below.\nTracked by tripleo ci squad at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/us/191\nDepends-On: https://review.openstack.org/619508\n\nChange-Id: I9f411b8f2b50e585f378e3787da9a4834c8e4149\n'}, {'number': 2, 'created': '2019-01-07 14:19:13.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/d67f1ef7942ada52cb9609584e20eea08e17994e', 'message': 'Replace scenario001-multinode with scenario001-standalone\n\nThe scenario001-standalone job is added in the depends-on below.\nTracked by tripleo ci squad at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/us/191\nDepends-On: https://review.openstack.org/619508\n\nChange-Id: I9f411b8f2b50e585f378e3787da9a4834c8e4149\n'}]",0,620301,d67f1ef7942ada52cb9609584e20eea08e17994e,23,7,2,8449,,,0,"Replace scenario001-multinode with scenario001-standalone

The scenario001-standalone job is added in the depends-on below.
Tracked by tripleo ci squad at [1]

[1] https://tree.taiga.io/project/tripleo-ci-board/us/191
Depends-On: https://review.openstack.org/619508

Change-Id: I9f411b8f2b50e585f378e3787da9a4834c8e4149
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-modify-image refs/changes/01/620301/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,1f828d44793a2ffe71196f15362c8ff93c32274f,replace-scen1, - tripleo-ci-centos-7-scenario001-standalone - tripleo-ci-centos-7-scenario001-standalone, - tripleo-ci-centos-7-scenario001-multinode-oooq-container - tripleo-ci-centos-7-scenario001-multinode-oooq-container,2,2
openstack%2Fmanila~master~Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd,openstack/manila,master,Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd,Publish sample config file in the genconfig job,MERGED,2019-01-03 20:10:34.000000000,2019-01-08 11:44:13.000000000,2019-01-08 11:37:40.000000000,"[{'_account_id': 7102}, {'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-01-03 20:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cd6a11718eaca2d059e22a226c54f9bba822c68f', 'message': 'Debug: genconfig o/p collection\n\nChange-Id: Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd\n'}, {'number': 2, 'created': '2019-01-03 20:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/72c10d3e906ed9bd8b716407ae95dd7e3c8cc7bf', 'message': 'Debug: genconfig o/p collection\n\nChange-Id: Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd\n'}, {'number': 3, 'created': '2019-01-03 20:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a4783abd0782a143fdc05facde88ce83358ae1a0', 'message': 'Publish sample config file in the genconfig job\n\nAdd a post run to enable copying the sample file\ngenerated to zuul logs.\n\nChange-Id: Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd\n'}, {'number': 4, 'created': '2019-01-04 04:02:13.000000000', 'files': ['playbooks/manila-tox-genconfig/post.yaml', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/116becf381d2654581e3ad61eb40538faebec095', 'message': 'Publish sample config file in the genconfig job\n\nAdd a post run to enable copying the sample file\ngenerated to zuul logs.\n\nChange-Id: Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd\n'}]",0,628287,116becf381d2654581e3ad61eb40538faebec095,51,15,4,16643,,,0,"Publish sample config file in the genconfig job

Add a post run to enable copying the sample file
generated to zuul logs.

Change-Id: Ifc1e71ce486ef9cefc07dbe9fb7c78ce150317bd
",git fetch https://review.opendev.org/openstack/manila refs/changes/87/628287/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/manila-tox-genconfig/post.yaml', '.zuul.yaml']",2,cd6a11718eaca2d059e22a226c54f9bba822c68f,tox-genconfig, post-run: playbooks/manila-tox-genconfig/post.yaml, - publish-openstack-docs-pti - openstack-cover-jobs - openstack-lower-constraints-jobs - openstack-python36-jobs - openstack-python37-jobs - check-requirements - release-notes-jobs-python3 - periodic-stable-jobs - manila-tempest-dsvm-mysql-generic: voting: false - manila-tempest-dsvm-postgres-container: voting: false - manila-tempest-dsvm-postgres-zfsonlinux: voting: false - manila-tempest-dsvm-postgres-generic-singlebackend: voting: false - manila-tempest-dsvm-generic-no-share-servers: voting: false - manila-tempest-dsvm-scenario: voting: false - manila-tempest-minimal-dsvm-cephfs-native-centos-7: voting: false - manila-tempest-minimal-dsvm-cephfs-nfs-centos-7: voting: false - manila-tempest-minimal-dsvm-dummy - manila-tempest-minimal-dsvm-lvm - manila-grenade: voting: false - manila-rally-multibackend: voting: false - manila-rally-multibackend-no-ss: voting: false - openstack-tox-pylint: voting: false - openstack-tox-cover: voting: false,17,36
openstack%2Fnetworking-bagpipe~master~If63975e68bacf85ca5a8823fafa8c2cc65e540cc,openstack/networking-bagpipe,master,If63975e68bacf85ca5a8823fafa8c2cc65e540cc,agent extension: smoother handling of bagpipe-bgp unavailability,MERGED,2019-01-07 22:41:33.000000000,2019-01-08 11:40:23.000000000,2019-01-08 11:40:22.000000000,"[{'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 22:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/462d8b5381635add0583451d7b5874097c4690ef', 'message': 'DNM: agent extension: smooth handling of failure to connect bagpipe-bgp\n\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\nRelated-Bug: 1807152\n'}, {'number': 2, 'created': '2019-01-07 22:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/62bd1fc730d387ab63f62dcfceabed77d13bd06b', 'message': 'DNM: agent extension: smooth handling of failure to connect bagpipe-bgp\n\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\nRelated-Bug: 1807152\n'}, {'number': 3, 'created': '2019-01-08 06:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/e6ff687fd13ecf442764e77c1da4284c841cc6d7', 'message': 'agent extension: smoother handling of bagpipe-bgp unavailability\n\nCatch all exceptions in _request_ping to avoid interrupting\nthe loop testing the availability of bagpipe-bgp.\n\nCloses-Bug: 1807152\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\n'}, {'number': 4, 'created': '2019-01-08 07:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/ed40f83f6a5d115c7e026cd0029b33d42eb929d4', 'message': 'agent extension: smoother handling of bagpipe-bgp unavailability\n\nCatch all exceptions in _request_ping to avoid interrupting\nthe loop testing the availability of bagpipe-bgp.\n\nCloses-Bug: 1807152\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\n'}, {'number': 5, 'created': '2019-01-08 08:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/b6eb82b5846469b4211ea8a5083ca8d6a1a36464', 'message': 'agent extension: smoother handling of bagpipe-bgp unavailability\n\nCatch all exceptions in _request_ping to avoid interrupting\nthe loop testing the availability of bagpipe-bgp.\n\nTo unbreak the gate, this change also needs to include\nlower constraints upgrades.\n\nCloses-Bug: 1807152\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\n'}, {'number': 6, 'created': '2019-01-08 08:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/e5aee9a8edc96198cc6ff1b74af7139d47111a7e', 'message': 'agent extension: smoother handling of bagpipe-bgp unavailability\n\nCatch all exceptions in _request_ping to avoid interrupting\nthe loop testing the availability of bagpipe-bgp.\n\nTo unbreak the gate, this change also needs to include\nlower constraints upgrades.\n\nCloses-Bug: 1807152\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\n'}, {'number': 7, 'created': '2019-01-08 08:45:04.000000000', 'files': ['networking_bagpipe/agent/bagpipe_bgp_agent.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/5afc9f5c1f10887f094644399543d807b2ee0c82', 'message': 'agent extension: smoother handling of bagpipe-bgp unavailability\n\nCatch all exceptions in _request_ping to avoid interrupting\nthe loop testing the availability of bagpipe-bgp.\n\nTo unbreak the gate, this change also needs to include\nlower constraints upgrades.\n\nCloses-Bug: 1807152\nChange-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc\n'}]",0,629062,5afc9f5c1f10887f094644399543d807b2ee0c82,13,2,7,12021,,,0,"agent extension: smoother handling of bagpipe-bgp unavailability

Catch all exceptions in _request_ping to avoid interrupting
the loop testing the availability of bagpipe-bgp.

To unbreak the gate, this change also needs to include
lower constraints upgrades.

Closes-Bug: 1807152
Change-Id: If63975e68bacf85ca5a8823fafa8c2cc65e540cc
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/62/629062/3 && git format-patch -1 --stdout FETCH_HEAD,['networking_bagpipe/agent/bagpipe_bgp_agent.py'],1,462d8b5381635add0583451d7b5874097c4690ef,bug/1807152," except (socket.error, IOError, httplib2.ResponseNotReady) as e: except Exception as e:"," except (socket.error, IOError) as e: except BaGPipeBGPException as e:",2,2
openstack%2Fopenstack-ansible~master~I713d647117fb3f166e3b426af7e2aa98ce7fb819,openstack/openstack-ansible,master,I713d647117fb3f166e3b426af7e2aa98ce7fb819,Define octavia_glance_image_tag for AIO config,ABANDONED,2018-08-23 06:26:34.000000000,2019-01-08 11:35:57.000000000,,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-23 06:26:34.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables_octavia.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/61754a493dc2531bb3c6e5fb859678507af006ba', 'message': 'Define octavia_glance_image_tag for AIO config\n\nos_octavia needs a non-empty value for octavia_glance_image_tag.\n\nChange-Id: I713d647117fb3f166e3b426af7e2aa98ce7fb819\n'}]",1,595499,61754a493dc2531bb3c6e5fb859678507af006ba,5,3,1,819,,,0,"Define octavia_glance_image_tag for AIO config

os_octavia needs a non-empty value for octavia_glance_image_tag.

Change-Id: I713d647117fb3f166e3b426af7e2aa98ce7fb819
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/99/595499/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/templates/user_variables_octavia.yml.j2'],1,61754a493dc2531bb3c6e5fb859678507af006ba,aio-octavia-glance-image-tag,octavia_glance_image_tag: octavia-amphora-image,octavia_glance_image_tag:,1,1
openstack%2Ftripleo-heat-templates~master~I666dc4985cdb3a86fac0a8421518ff3d7c784214,openstack/tripleo-heat-templates,master,I666dc4985cdb3a86fac0a8421518ff3d7c784214,ceilometer: --skip-metering-database is gone,ABANDONED,2018-12-22 20:21:33.000000000,2019-01-08 11:33:57.000000000,,"[{'_account_id': 360}, {'_account_id': 2813}, {'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-22 20:21:33.000000000', 'files': ['docker/services/ceilometer-agent-central.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a563df2d8bb53facabe317fda7ed49d134dfd629', 'message': 'ceilometer: --skip-metering-database is gone\n\nOption --skip-metering-database is gone since OSP13\n(I6b262dd440a72f25662b64d938ab9e5328709a97).\n\nThis change removes it.\n\nCloses-bug: #1743563\n\nChange-Id: I666dc4985cdb3a86fac0a8421518ff3d7c784214\n(cherry picked from commit 60f6300e9bbd255a8a8f65d7ed5b50cbb5e4e662)\n'}]",0,627047,a563df2d8bb53facabe317fda7ed49d134dfd629,8,5,1,5241,,,0,"ceilometer: --skip-metering-database is gone

Option --skip-metering-database is gone since OSP13
(I6b262dd440a72f25662b64d938ab9e5328709a97).

This change removes it.

Closes-bug: #1743563

Change-Id: I666dc4985cdb3a86fac0a8421518ff3d7c784214
(cherry picked from commit 60f6300e9bbd255a8a8f65d7ed5b50cbb5e4e662)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/627047/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceilometer-agent-central.yaml'],1,a563df2d8bb53facabe317fda7ed49d134dfd629,bug/1743563," - ""su ceilometer -s /bin/bash -c 'for n in {1..10}; do /usr/bin/ceilometer-upgrade && exit 0 || sleep 30; done; exit 1'"""," - ""su ceilometer -s /bin/bash -c 'for n in {1..10}; do /usr/bin/ceilometer-upgrade --skip-metering-database && exit 0 || sleep 30; done; exit 1'""",1,1
openstack%2Fnetworking-ovn~master~I58776e202ab0b1634a2398badf1eb75080bf55dc,openstack/networking-ovn,master,I58776e202ab0b1634a2398badf1eb75080bf55dc,dnm: Omit migration tests from dsvm-functional,ABANDONED,2019-01-03 11:23:34.000000000,2019-01-08 11:33:56.000000000,,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-01-03 11:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5d763f6f5cfea387bb239a557e3f6b92bc859590', 'message': 'dnm: Run functional tests serially\n\nChange-Id: I58776e202ab0b1634a2398badf1eb75080bf55dc\nRelated-bug: #1808146\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 2, 'created': '2019-01-03 11:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/45ac18907cca9627eb86907f4ea7321d157d5024', 'message': 'dnm: Run functional tests serially\n\nChange-Id: I58776e202ab0b1634a2398badf1eb75080bf55dc\nRelated-bug: #1808146\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 3, 'created': '2019-01-03 14:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9405d4ef2284fe14fdb19d7fb7027ca988206251', 'message': 'dnm: Run functional tests serially\n\nChange-Id: I58776e202ab0b1634a2398badf1eb75080bf55dc\nRelated-bug: #1808146\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 4, 'created': '2019-01-03 17:27:38.000000000', 'files': ['networking_ovn/tests/functional/db/test_migrations.py', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/1a77b1e9e6715447a983b2bab6812f1545fb57ff', 'message': 'dnm: Omit migration tests from dsvm-functional\n\nChange-Id: I58776e202ab0b1634a2398badf1eb75080bf55dc\nRelated-bug: #1808146\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}]",0,628157,1a77b1e9e6715447a983b2bab6812f1545fb57ff,29,3,4,23804,,,0,"dnm: Omit migration tests from dsvm-functional

Change-Id: I58776e202ab0b1634a2398badf1eb75080bf55dc
Related-bug: #1808146
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/57/628157/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/functional/test_impl_idl.py', 'networking_ovn/tests/contrib/post_test_hook.sh', 'zuul.d/project.yaml']",3,5d763f6f5cfea387bb239a557e3f6b92bc859590,bug/1808146,," templates: - openstack-python-jobs-neutron - publish-openstack-docs-pti - release-notes-jobs-python3 - check-requirements - openstack-python35-jobs-neutron - openstack-python36-jobs-neutron - networking-ovn-tempest-dsvm-ovs-master: voting: false - networking-ovn-tempest-dsvm-ovs-release - networking-ovn-tempest-dsvm-ovs-release-python2 - networking-ovn-rally-task # TripleO jobs that deploy OVN. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # tripleo-ci-centos-7-scenario007-multinode-oooq-container will # run in Pike and beyond. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. - tripleo-ci-centos-7-scenario007-multinode-oooq-container - openstack-tox-lower-constraints - networking-ovn-dsvm-grenade: branches: ^(?!stable/(ocata|pike|queens)).*$ voting: false - openstack-tox-cover: required-projects: - openstack/neutron voting: false",2,29
openstack%2Fnetworking-ovn~master~Ie7b4dd1a2db1a6c848909f95449d27d60416f939,openstack/networking-ovn,master,Ie7b4dd1a2db1a6c848909f95449d27d60416f939,DNM: remove alembic migrations from func tests,ABANDONED,2018-12-24 14:56:42.000000000,2019-01-08 11:33:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-12-24 14:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b6d1daee1511e4655b3ad108e5db5853dc107dce', 'message': 'DNM: remove alembic migrations from func tests\n\nAttempt to see if removing alembic migrations makes func\ntests to not fail anymore.\n\nPartial-Bug: #1808146\n\nChange-Id: Ie7b4dd1a2db1a6c848909f95449d27d60416f939\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 2, 'created': '2019-01-04 08:19:20.000000000', 'files': ['networking_ovn/tests/functional/db/test_migrations.py', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/61891b5f58520e2f3d09a095ad4a5890d3ba7cda', 'message': 'DNM: remove alembic migrations from func tests\n\nAttempt to see if removing alembic migrations makes func\ntests to not fail anymore.\n\nPartial-Bug: #1808146\n\nChange-Id: Ie7b4dd1a2db1a6c848909f95449d27d60416f939\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}]",0,627190,61891b5f58520e2f3d09a095ad4a5890d3ba7cda,14,2,2,23804,,,0,"DNM: remove alembic migrations from func tests

Attempt to see if removing alembic migrations makes func
tests to not fail anymore.

Partial-Bug: #1808146

Change-Id: Ie7b4dd1a2db1a6c848909f95449d27d60416f939
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/90/627190/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/functional/db/test_migrations.py', 'zuul.d/project.yaml']",2,b6d1daee1511e4655b3ad108e5db5853dc107dce,bug/1808146,," - networking-ovn-tempest-dsvm-ovs-master: voting: false - networking-ovn-tempest-dsvm-ovs-release - networking-ovn-tempest-dsvm-ovs-release-python2 - networking-ovn-rally-task # TripleO jobs that deploy OVN. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # tripleo-ci-centos-7-scenario007-multinode-oooq-container will # run in Pike and beyond. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. - tripleo-ci-centos-7-scenario007-multinode-oooq-container - openstack-tox-lower-constraints - networking-ovn-dsvm-grenade: branches: ^(?!stable/(ocata|pike|queens)).*$ voting: false - openstack-tox-cover: required-projects: - openstack/neutron voting: false",0,85
openstack%2Fnetworking-ovn~master~Ib8dca4a42dc3abf3c4b58ca08291fb494815578f,openstack/networking-ovn,master,Ib8dca4a42dc3abf3c4b58ca08291fb494815578f,DO NOT REVIEW: DB FAILURE,ABANDONED,2019-01-04 12:33:15.000000000,2019-01-08 11:32:04.000000000,,"[{'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 12:33:15.000000000', 'files': ['networking_ovn/tests/functional/test_qos_driver.py', 'networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/tests/functional/test_ovn_db_resources.py', 'zuul.d/project.yaml', 'networking_ovn/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/422849a57f97af9bd44c7398ef13857bda1cff52', 'message': 'DO NOT REVIEW: DB FAILURE\n\nChange-Id: Ib8dca4a42dc3abf3c4b58ca08291fb494815578f\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",0,628424,422849a57f97af9bd44c7398ef13857bda1cff52,8,2,1,6773,,,0,"DO NOT REVIEW: DB FAILURE

Change-Id: Ib8dca4a42dc3abf3c4b58ca08291fb494815578f
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/24/628424/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/functional/test_qos_driver.py', 'networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/tests/functional/test_ovn_db_resources.py', 'zuul.d/project.yaml', 'networking_ovn/tests/functional/base.py']",5,422849a57f97af9bd44c7398ef13857bda1cff52,bug/1808146-func-dbnonexistenttable," _extension_drivers = ['port_security', 'qos', 'dns']", _extension_drivers = ['port_security'],29,33
openstack%2Fbifrost~stable%2Fpike~I685efd14bf3567a126311b676a50b0abb0f043db,openstack/bifrost,stable/pike,I685efd14bf3567a126311b676a50b0abb0f043db,Perform ironic online data migrations,MERGED,2019-01-06 08:09:38.000000000,2019-01-08 11:31:24.000000000,2019-01-08 11:31:24.000000000,"[{'_account_id': 6133}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-06 08:09:38.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/50eda2221f01b4ca040b07b21706c499fdcc2e75', 'message': 'Perform ironic online data migrations\n\nOnline data migrations are necessary for performing an upgrade of\nironic. Without this change, an error such as the following may be seen\nin task \'bifrost-ironic-install : Upgrade ironic DB Schema\'.\n\nThe database is not compatible with this release of ironic (10.1.7).\nPlease run ""ironic-dbsync online_data_migrations"" using the previous\nrelease.\n\nChange-Id: I685efd14bf3567a126311b676a50b0abb0f043db\nStory: 2004670\nTask: 28658\n(cherry picked from commit 705a58f6ebbc0948a703648952dfc1301334c75c)\n'}]",0,628758,50eda2221f01b4ca040b07b21706c499fdcc2e75,7,3,1,14826,,,0,"Perform ironic online data migrations

Online data migrations are necessary for performing an upgrade of
ironic. Without this change, an error such as the following may be seen
in task 'bifrost-ironic-install : Upgrade ironic DB Schema'.

The database is not compatible with this release of ironic (10.1.7).
Please run ""ironic-dbsync online_data_migrations"" using the previous
release.

Change-Id: I685efd14bf3567a126311b676a50b0abb0f043db
Story: 2004670
Task: 28658
(cherry picked from commit 705a58f6ebbc0948a703648952dfc1301334c75c)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/58/628758/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml']",4,50eda2221f01b4ca040b07b21706c499fdcc2e75,story/2004670-stable/pike,--- features: - | Adds support for performing ironic online data migrations. ,,32,0
openstack%2Fbifrost~stable%2Fqueens~I685efd14bf3567a126311b676a50b0abb0f043db,openstack/bifrost,stable/queens,I685efd14bf3567a126311b676a50b0abb0f043db,Perform ironic online data migrations,MERGED,2019-01-06 08:09:26.000000000,2019-01-08 11:31:22.000000000,2019-01-08 11:31:22.000000000,"[{'_account_id': 6133}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-06 08:09:26.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/ec45739c7e8ea537ab553b069a143f5e4a157645', 'message': 'Perform ironic online data migrations\n\nOnline data migrations are necessary for performing an upgrade of\nironic. Without this change, an error such as the following may be seen\nin task \'bifrost-ironic-install : Upgrade ironic DB Schema\'.\n\nThe database is not compatible with this release of ironic (10.1.7).\nPlease run ""ironic-dbsync online_data_migrations"" using the previous\nrelease.\n\nChange-Id: I685efd14bf3567a126311b676a50b0abb0f043db\nStory: 2004670\nTask: 28658\n(cherry picked from commit 705a58f6ebbc0948a703648952dfc1301334c75c)\n'}]",0,628757,ec45739c7e8ea537ab553b069a143f5e4a157645,7,3,1,14826,,,0,"Perform ironic online data migrations

Online data migrations are necessary for performing an upgrade of
ironic. Without this change, an error such as the following may be seen
in task 'bifrost-ironic-install : Upgrade ironic DB Schema'.

The database is not compatible with this release of ironic (10.1.7).
Please run ""ironic-dbsync online_data_migrations"" using the previous
release.

Change-Id: I685efd14bf3567a126311b676a50b0abb0f043db
Story: 2004670
Task: 28658
(cherry picked from commit 705a58f6ebbc0948a703648952dfc1301334c75c)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/57/628757/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml']",4,ec45739c7e8ea537ab553b069a143f5e4a157645,story/2004670-stable/queens,--- features: - | Adds support for performing ironic online data migrations. ,,32,0
openstack%2Ftripleo-ci~master~I6ebfba501e9cee84687294ce9fa1c582ab094f0a,openstack/tripleo-ci,master,I6ebfba501e9cee84687294ce9fa1c582ab094f0a,DNM: To run periodics at check,ABANDONED,2018-10-05 06:37:08.000000000,2019-01-08 11:29:56.000000000,,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-05 06:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/61e865ed4a13bc4c689114746bb28e6ac69663db', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 2, 'created': '2018-10-05 08:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7afd0e10a3c2fb7719e9a60290c442c4cb049e02', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 3, 'created': '2018-10-05 10:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b8a88ff0ce055bac0a26e17806cc9d797f2f3148', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 4, 'created': '2018-10-05 10:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e40aa98185c18f5e39428f1c90e087a9ef9e3de1', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 5, 'created': '2018-10-05 10:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/427f5625244de06be75ededcf8d45a51444e407b', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 6, 'created': '2018-10-05 10:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5e9177fd8e3e190faa17ae9b631550a9be4a6005', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 7, 'created': '2018-10-05 10:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/985aefe85e87ff243190327170b803869c47489e', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 8, 'created': '2018-10-05 10:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/add11c188f372b27c2c6ec3a95dcb027c86d0742', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 9, 'created': '2018-10-05 11:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1eec5e038d8a71189300472400fe2791124aff52', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}, {'number': 10, 'created': '2018-10-08 07:22:15.000000000', 'files': ['playbooks/tripleo-ci/run-v3.yaml', 'playbooks/tripleo-ci/vars/common.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/02589ae264370dd2d5cd07db9d7bd9bf19856984', 'message': 'DNM: To run periodics at check\n\nChange-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a\n'}]",0,608166,02589ae264370dd2d5cd07db9d7bd9bf19856984,21,6,10,27898,,,0,"DNM: To run periodics at check

Change-Id: I6ebfba501e9cee84687294ce9fa1c582ab094f0a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/66/608166/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tripleo-ci/vars/common.yaml'],1,61e865ed4a13bc4c689114746bb28e6ac69663db,608166, {% if 'check' in zuul.pipeline -%}, {% if 'periodic' in zuul.pipeline -%},1,1
openstack%2Fneutron-lbaas-dashboard~master~Ie99901e8799670221a20b6ae7eda83ecdc1cf488,openstack/neutron-lbaas-dashboard,master,Ie99901e8799670221a20b6ae7eda83ecdc1cf488,Use template for lower-constraints,MERGED,2018-12-20 20:22:26.000000000,2019-01-08 11:25:06.000000000,2019-01-08 11:25:06.000000000,"[{'_account_id': 2245}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-20 20:22:26.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas-dashboard/commit/2a9d51344d1bc11279ad3bee577e3f689e740304', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nChange-Id: Ie99901e8799670221a20b6ae7eda83ecdc1cf488\nNeeded-By: https://review.openstack.org/623229\n'}]",0,626711,2a9d51344d1bc11279ad3bee577e3f689e740304,7,3,1,6547,,,0,"Use template for lower-constraints

Small cleanups:

* Use openstack-lower-constraints-jobs template, remove individual
  jobs.
* Sort list of templates

Change-Id: Ie99901e8799670221a20b6ae7eda83ecdc1cf488
Needed-By: https://review.openstack.org/623229
",git fetch https://review.opendev.org/openstack/neutron-lbaas-dashboard refs/changes/11/626711/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2a9d51344d1bc11279ad3bee577e3f689e740304,cd/py36-lower-constraints, - openstack-lower-constraints-jobs, - openstack-tox-lower-constraints - openstack-tox-lower-constraints,1,2
openstack%2Fneutron-lbaas-dashboard~master~Ia4243be7dc58dd2943973b08ead99bc7696decb8,openstack/neutron-lbaas-dashboard,master,Ia4243be7dc58dd2943973b08ead99bc7696decb8,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 05:35:34.000000000,2019-01-08 11:23:54.000000000,2019-01-08 11:23:54.000000000,"[{'_account_id': 2245}, {'_account_id': 6579}, {'_account_id': 10850}, {'_account_id': 22348}, {'_account_id': 28637}]","[{'number': 1, 'created': '2018-12-04 05:35:34.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas-dashboard/commit/ac4c333cb2160726a0af6705ed5fa49d90ecee64', 'message': 'Change openstack-dev to openstack-discuss\n\nMailing lists have been updated. Openstack-discuss replaces\nopenstack-dev.\n\nChange-Id: Ia4243be7dc58dd2943973b08ead99bc7696decb8\n'}]",0,621997,ac4c333cb2160726a0af6705ed5fa49d90ecee64,8,5,1,29313,,,0,"Change openstack-dev to openstack-discuss

Mailing lists have been updated. Openstack-discuss replaces
openstack-dev.

Change-Id: Ia4243be7dc58dd2943973b08ead99bc7696decb8
",git fetch https://review.opendev.org/openstack/neutron-lbaas-dashboard refs/changes/97/621997/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ac4c333cb2160726a0af6705ed5fa49d90ecee64,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fzaqar~master~I1630fea3956cef601128769fa4526d44aa2c1d64,openstack/zaqar,master,I1630fea3956cef601128769fa4526d44aa2c1d64,Replace tripleo-scenario002-multinode with scenario002-standalone,MERGED,2019-01-03 19:08:27.000000000,2019-01-08 11:23:53.000000000,2019-01-08 11:23:53.000000000,"[{'_account_id': 7385}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 27898}, {'_account_id': 28035}]","[{'number': 1, 'created': '2019-01-03 19:08:27.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2438c565d2af450e93856509207c61a7c58d9c6e', 'message': 'Replace tripleo-scenario002-multinode with scenario002-standalone\n\nChange-Id: I1630fea3956cef601128769fa4526d44aa2c1d64\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/532\n'}]",0,628268,2438c565d2af450e93856509207c61a7c58d9c6e,11,6,1,8175,,,0,"Replace tripleo-scenario002-multinode with scenario002-standalone

Change-Id: I1630fea3956cef601128769fa4526d44aa2c1d64
Story: https://tree.taiga.io/project/tripleo-ci-board/us/532
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/68/628268/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2438c565d2af450e93856509207c61a7c58d9c6e,replace-scen2, - tripleo-ci-centos-7-scenario002-standalone - tripleo-ci-centos-7-scenario002-standalone, - tripleo-ci-centos-7-scenario002-multinode-oooq-container - tripleo-ci-centos-7-scenario002-multinode-oooq-container,2,2
openstack%2Fbifrost~stable%2Frocky~I685efd14bf3567a126311b676a50b0abb0f043db,openstack/bifrost,stable/rocky,I685efd14bf3567a126311b676a50b0abb0f043db,Perform ironic online data migrations,MERGED,2019-01-06 08:08:06.000000000,2019-01-08 11:23:32.000000000,2019-01-08 11:23:32.000000000,"[{'_account_id': 6133}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-06 08:08:06.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/640bdeeb332aeb42f0c694fb60cf868afb139233', 'message': 'Perform ironic online data migrations\n\nOnline data migrations are necessary for performing an upgrade of\nironic. Without this change, an error such as the following may be seen\nin task \'bifrost-ironic-install : Upgrade ironic DB Schema\'.\n\nThe database is not compatible with this release of ironic (10.1.7).\nPlease run ""ironic-dbsync online_data_migrations"" using the previous\nrelease.\n\nChange-Id: I685efd14bf3567a126311b676a50b0abb0f043db\nStory: 2004670\nTask: 28658\n(cherry picked from commit 705a58f6ebbc0948a703648952dfc1301334c75c)\n'}]",0,628756,640bdeeb332aeb42f0c694fb60cf868afb139233,7,3,1,14826,,,0,"Perform ironic online data migrations

Online data migrations are necessary for performing an upgrade of
ironic. Without this change, an error such as the following may be seen
in task 'bifrost-ironic-install : Upgrade ironic DB Schema'.

The database is not compatible with this release of ironic (10.1.7).
Please run ""ironic-dbsync online_data_migrations"" using the previous
release.

Change-Id: I685efd14bf3567a126311b676a50b0abb0f043db
Story: 2004670
Task: 28658
(cherry picked from commit 705a58f6ebbc0948a703648952dfc1301334c75c)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/56/628756/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml']",4,640bdeeb332aeb42f0c694fb60cf868afb139233,story/2004670-stable/rocky,--- features: - | Adds support for performing ironic online data migrations. ,,32,0
openstack%2Fbifrost~master~I3b044fb2b2eae01d424cf9b444031a76caa28333,openstack/bifrost,master,I3b044fb2b2eae01d424cf9b444031a76caa28333,Remove those copy words occured twice times in README.md,MERGED,2019-01-07 00:57:00.000000000,2019-01-08 11:22:57.000000000,2019-01-08 11:22:57.000000000,"[{'_account_id': 6133}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 00:57:00.000000000', 'files': ['playbooks/roles/bifrost-deploy-nodes-dynamic/README.md'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1fcd7d2475223639efda333027b35b7c2b9895ba', 'message': 'Remove those copy words occured twice times in README.md\n\nChange-Id: I3b044fb2b2eae01d424cf9b444031a76caa28333\n'}]",0,628790,1fcd7d2475223639efda333027b35b7c2b9895ba,7,3,1,29423,,,0,"Remove those copy words occured twice times in README.md

Change-Id: I3b044fb2b2eae01d424cf9b444031a76caa28333
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/90/628790/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-deploy-nodes-dynamic/README.md'],1,1fcd7d2475223639efda333027b35b7c2b9895ba,, allows a user to change that default if they have, allows a user to change that default if they they have,1,1
openstack%2Fnetworking-bagpipe~master~I587a3cb929860f614650816c16df188a84b3c012,openstack/networking-bagpipe,master,I587a3cb929860f614650816c16df188a84b3c012,set legacy-tempest-dsvm-networking-bgpvpn-bagpipe as non-voting,ABANDONED,2019-01-07 07:43:47.000000000,2019-01-08 11:22:56.000000000,,"[{'_account_id': 8871}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 07:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/c7c1317192843eec41796dad1a62289b748bc6b3', 'message': 'set legacy-tempest-dsvm-networking-bgpvpn-bagpipe as non-voting\n\nTo be reverted once bug 1807152 is resolved.\n\nChange-Id: I587a3cb929860f614650816c16df188a84b3c012\n'}, {'number': 2, 'created': '2019-01-07 13:26:36.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/9394bc7d23001b9265eeb2222dfdb3c9764b4e6a', 'message': 'set legacy-tempest-dsvm-networking-bgpvpn-bagpipe as non-voting\n\nTo be reverted once bug 1807152 is resolved.\n\nChange-Id: I587a3cb929860f614650816c16df188a84b3c012\n'}]",0,628898,9394bc7d23001b9265eeb2222dfdb3c9764b4e6a,13,3,2,12021,,,0,"set legacy-tempest-dsvm-networking-bgpvpn-bagpipe as non-voting

To be reverted once bug 1807152 is resolved.

Change-Id: I587a3cb929860f614650816c16df188a84b3c012
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/98/628898/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c7c1317192843eec41796dad1a62289b748bc6b3,bug/1807152, voting: false,,1,0
openstack%2Fbifrost~master~Iae491e0dd3e2a8128490ceca3f8a0bfe17646d87,openstack/bifrost,master,Iae491e0dd3e2a8128490ceca3f8a0bfe17646d87,Dumplicate words was deleted in  README.md,MERGED,2019-01-07 06:15:51.000000000,2019-01-08 11:21:41.000000000,2019-01-08 11:21:41.000000000,"[{'_account_id': 6133}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 06:15:51.000000000', 'files': ['playbooks/roles/bifrost-create-vm-nodes/README.md'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/847cef33cc6285feae5f2ac085aeb164eae03c13', 'message': 'Dumplicate words was deleted in  README.md\n\nChange-Id: Iae491e0dd3e2a8128490ceca3f8a0bfe17646d87\n'}]",0,628866,847cef33cc6285feae5f2ac085aeb164eae03c13,7,3,1,29423,,,0,"Dumplicate words was deleted in  README.md

Change-Id: Iae491e0dd3e2a8128490ceca3f8a0bfe17646d87
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/66/628866/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-create-vm-nodes/README.md'],1,847cef33cc6285feae5f2ac085aeb164eae03c13,,test_vm_network_dhcp_end: End of DHCP range for 'test_vm_network'.,test_vm_network_dhcp_end: End of of DHCP range for 'test_vm_network'.,1,1
openstack%2Ftripleo-ci~master~I0958322448d2e0cf2c3a2708b9e797ae9a597109,openstack/tripleo-ci,master,I0958322448d2e0cf2c3a2708b9e797ae9a597109,Avoid using hardcoded zuul user path in run-v3,ABANDONED,2018-12-19 17:14:33.000000000,2019-01-08 11:13:04.000000000,,"[{'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-12-19 17:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/94fc2624f8eeec7c49a1012fedbf424fd6e30f7d', 'message': 'Avoid using hardcoded zuul user path in run-v3\n\nAs remarked in https://review.openstack.org/#/c/625896/ removing\nthe hardcoded paths to src directory.\n\nChange-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109\n'}, {'number': 2, 'created': '2018-12-19 18:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/40011459b830fbdf1117adff5da34bb929c6a5ab', 'message': 'Avoid using hardcoded zuul user path in run-v3\n\nAs remarked in https://review.openstack.org/#/c/625896/ removing\nthe hardcoded paths to src directory.\n\nChange-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109\n'}, {'number': 3, 'created': '2018-12-27 15:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/66b9b8c324ee2b74cd30ec447e34065cf7b7d16f', 'message': 'Avoid using hardcoded zuul user path in run-v3\n\nAs remarked in https://review.openstack.org/#/c/625896/ removing\nthe hardcoded paths to src directory.\n\nChange-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109\n'}, {'number': 4, 'created': '2018-12-27 22:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4399641effde7c182a683a183f00354031727aa0', 'message': 'Avoid using hardcoded zuul user path in run-v3\n\nAs remarked in https://review.openstack.org/#/c/625896/ removing\nthe hardcoded paths to src directory.\n\nChange-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109\n'}, {'number': 5, 'created': '2018-12-28 11:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c8bbbf858bf70bd64b7cf8f06d9488a4b20f270a', 'message': 'Avoid using hardcoded zuul user path in run-v3\n\nAs remarked in https://review.openstack.org/#/c/625896/ removing\nthe hardcoded paths to src directory.\n\nChange-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109\n'}, {'number': 6, 'created': '2019-01-07 13:45:03.000000000', 'files': ['playbooks/tripleo-ci/run-v3.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1d8821ef546be0fd7126ca8808b7f85ffb148c68', 'message': 'Avoid using hardcoded zuul user path in run-v3\n\nAs remarked in https://review.openstack.org/#/c/625896/ removing\nthe hardcoded paths to src directory.\n\nChange-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109\n'}]",12,626364,1d8821ef546be0fd7126ca8808b7f85ffb148c68,37,11,6,24162,,,0,"Avoid using hardcoded zuul user path in run-v3

As remarked in https://review.openstack.org/#/c/625896/ removing
the hardcoded paths to src directory.

Change-Id: I0958322448d2e0cf2c3a2708b9e797ae9a597109
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/64/626364/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tripleo-ci/run-v3.yaml'],1,94fc2624f8eeec7c49a1012fedbf424fd6e30f7d,oooq/avoid-unsafe-umask," path: ""/{{ ansible_user_dir }}/src/"" cp -dR --reflink=auto {{ zuul.projects['git.openstack.org/openstack-infra/tripleo-ci'].src_dir }} .", path: /home/zuul/src/ cp -dR --reflink=auto /home/zuul/src/git.openstack.org/openstack-infra/tripleo-ci .,2,2
openstack%2Fnetworking-sfc~master~I51ac8d7cf34ef6b59ae38877524853d8ed7cfd8a,openstack/networking-sfc,master,I51ac8d7cf34ef6b59ae38877524853d8ed7cfd8a,Upgrade pylint to a version that works with python3,MERGED,2018-12-26 06:53:32.000000000,2019-01-08 11:04:50.000000000,2019-01-08 11:04:50.000000000,"[{'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 12021}, {'_account_id': 18955}, {'_account_id': 21883}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-26 06:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/30ac967b8587cf587936776e0ac1c54186aea36d', 'message': 'Upgrade pylint to a version that works with python3\n\nFixes import order.\n\nnconsistent-return-statements and no-else-return rules are\nadded to the ignore list in .pylintrc because they are\npatterns commonly used in the neutron stadium and\nalready ignored in the neutron repo.\n\nChange-Id: I51ac8d7cf34ef6b59ae38877524853d8ed7cfd8a\n'}, {'number': 2, 'created': '2019-01-08 06:24:16.000000000', 'files': ['.pylintrc', 'test-requirements.txt', 'networking_sfc/extensions/tap.py', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/b29f07db7c62c26b8e9918f07e00734c14346ffc', 'message': 'Upgrade pylint to a version that works with python3\n\nFixes import order.\n\ninconsistent-return-statements and no-else-return rules are\nadded to the ignore list in .pylintrc because they are\npatterns commonly used in the neutron stadium and\nalready ignored in the neutron repo.\n\nChange-Id: I51ac8d7cf34ef6b59ae38877524853d8ed7cfd8a\n'}]",14,627352,b29f07db7c62c26b8e9918f07e00734c14346ffc,16,8,2,841,,,0,"Upgrade pylint to a version that works with python3

Fixes import order.

inconsistent-return-statements and no-else-return rules are
added to the ignore list in .pylintrc because they are
patterns commonly used in the neutron stadium and
already ignored in the neutron repo.

Change-Id: I51ac8d7cf34ef6b59ae38877524853d8ed7cfd8a
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/52/627352/1 && git format-patch -1 --stdout FETCH_HEAD,"['.pylintrc', 'test-requirements.txt', 'networking_sfc/extensions/tap.py', 'lower-constraints.txt', 'tox.ini']",5,30ac967b8587cf587936776e0ac1c54186aea36d,python3-first,basepython = python3,,8,4
openstack%2Fironic~stable%2Fpike~I8786cc9df4c1c936543f9ac528cdb8a0822b5065,openstack/ironic,stable/pike,I8786cc9df4c1c936543f9ac528cdb8a0822b5065,[TEST/DNM] testing multinode multitenant job,ABANDONED,2018-12-21 14:55:24.000000000,2019-01-08 10:56:14.000000000,,"[{'_account_id': 10118}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2018-12-21 14:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/354719bd8dcb94f4a7f291685322ebbb0003e14d', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I8786cc9df4c1c936543f9ac528cdb8a0822b5065\n'}, {'number': 2, 'created': '2019-01-02 14:25:05.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a4f1aee7580106539b72131e674f5620510e6479', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I8786cc9df4c1c936543f9ac528cdb8a0822b5065\n'}]",0,626915,a4f1aee7580106539b72131e674f5620510e6479,14,6,2,23851,,,0,"[TEST/DNM] testing multinode multitenant job

Change-Id: I8786cc9df4c1c936543f9ac528cdb8a0822b5065
",git fetch https://review.opendev.org/openstack/ironic refs/changes/15/626915/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,354719bd8dcb94f4a7f291685322ebbb0003e14d,test_multignt,, - ironic-dsvm-standalone - ironic-tempest-dsvm-bfv - ironic-tempest-dsvm-ipa-partition-redfish-tinyipa - ironic-tempest-dsvm-ipa-partition-uefi-pxe_ipmitool-tinyipa - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode - ironic-tempest-dsvm-ipa-wholedisk-bios-agent_ipmitool-tinyipa # Non-voting jobs - ironic-tempest-dsvm-ipa-wholedisk-bios-pxe_snmp-tinyipa: voting: false - ironic-tempest-dsvm-ironic-inspector: voting: false - ironic-tempest-dsvm-pxe_ipmitool-postgres: voting: false - openstack-tox-cover - ironic-dsvm-standalone - ironic-tempest-dsvm-bfv - ironic-tempest-dsvm-ipa-partition-redfish-tinyipa - ironic-tempest-dsvm-ipa-partition-uefi-pxe_ipmitool-tinyipa - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode - ironic-tempest-dsvm-ipa-wholedisk-bios-agent_ipmitool-tinyipa - openstack-tox-cover post: jobs: - openstack-tox-cover,0,24
openstack%2Fopenstack-ansible-os_neutron~master~I4087093a91f94e1b14fc656f13e6e187bbc32189,openstack/openstack-ansible-os_neutron,master,I4087093a91f94e1b14fc656f13e6e187bbc32189,cleanup: remove metadata checksum fixes tasks,MERGED,2018-12-29 23:53:12.000000000,2019-01-08 10:53:09.000000000,2019-01-08 10:53:09.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 21883}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-29 23:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/c01568c4cfab5721046c21b7c68e57ba50733e65', 'message': 'cleanup: remove metadata checksum fixes tasks\n\nWe installed tasks which resolved plenty of checksum issues and\nthose should have been ran by Rocky.  We can now drop those\nout of our role.\n\nChange-Id: I4087093a91f94e1b14fc656f13e6e187bbc32189\n'}, {'number': 2, 'created': '2019-01-08 08:46:03.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu.yml', 'tasks/neutron_post_install.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/cba3c437b8582eba482b9eb5a6356e2870438b9d', 'message': 'cleanup: remove metadata checksum fixes tasks\n\nWe installed tasks which resolved plenty of checksum issues and\nthose should have been ran by Rocky.  We can now drop those\nout of our role.\n\nChange-Id: I4087093a91f94e1b14fc656f13e6e187bbc32189\n'}]",0,627792,cba3c437b8582eba482b9eb5a6356e2870438b9d,13,4,2,1004,,,0,"cleanup: remove metadata checksum fixes tasks

We installed tasks which resolved plenty of checksum issues and
those should have been ran by Rocky.  We can now drop those
out of our role.

Change-Id: I4087093a91f94e1b14fc656f13e6e187bbc32189
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/92/627792/2 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu.yml', 'tasks/neutron_post_install.yml', 'vars/suse.yml']",4,c01568c4cfab5721046c21b7c68e57ba50733e65,osa-speedups,,# NOTE: Remove this in S # This option has been removed with the implementation of networkd within the # host and container. Additionally the execution of this script is now # controlled by a systemd oneshot service so the legacy configs are no longer # needed. neutron_checksum_script: /etc/sysconfig/network/scripts/ifup-post-metadata-checksum ,0,34
openstack%2Fopenstack-ansible-galera_client~master~I737b65c61f8f4a0cfad7f35394332433c0b2b053,openstack/openstack-ansible-galera_client,master,I737b65c61f8f4a0cfad7f35394332433c0b2b053,"Revert ""cleanup: stop managing files inside /etc""",ABANDONED,2019-01-08 09:59:39.000000000,2019-01-08 10:39:26.000000000,,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-08 09:59:39.000000000', 'files': ['tasks/galera_client_install_yum.yml', 'tests/test.yml', 'tasks/galera_client_install_zypper.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/0c929d2e364016bf7a64c915c021af13dc02f235', 'message': 'Revert ""cleanup: stop managing files inside /etc""\n\nThis reverts commit 30cb1e72d6736bae9dacbed0c3e6ef8fb174aaeb.\n\nThese tasks normalize CentOS/SUSE to make them look like Ubuntu.\nWith this patch, the builds that do not use containers began to fail.\nUntil that issue is worked out and resolved, we should revert this.\n\nChange-Id: I737b65c61f8f4a0cfad7f35394332433c0b2b053\n'}]",0,629122,0c929d2e364016bf7a64c915c021af13dc02f235,7,6,1,6816,,,0,"Revert ""cleanup: stop managing files inside /etc""

This reverts commit 30cb1e72d6736bae9dacbed0c3e6ef8fb174aaeb.

These tasks normalize CentOS/SUSE to make them look like Ubuntu.
With this patch, the builds that do not use containers began to fail.
Until that issue is worked out and resolved, we should revert this.

Change-Id: I737b65c61f8f4a0cfad7f35394332433c0b2b053
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/22/629122/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_client_install_yum.yml', 'tests/test.yml', 'tasks/galera_client_install_zypper.yml']",3,0c929d2e364016bf7a64c915c021af13dc02f235,osa-speedups,"- name: Stats /etc/my.cnf.d stat: path: /etc/my.cnf.d register: mycnfd_stat - name: Destroy my.cnf.d dir if is dir file: path: /etc/my.cnf.d state: absent force: true when: - mycnfd_stat.stat.isdir is defined - mycnfd_stat.stat.isdir == True - name: Update the local file system CRUD file: src: ""{{ item.src|default(omit) }}"" path: ""{{ item.path }}"" state: ""{{ item.state }}"" force: ""{{ item.force|default(omit) }}"" with_items: - { path: ""/etc/mysql"", state: ""directory"" } - { path: ""/etc/mysql/conf.d"", state: ""directory"" } - { src: ""/etc/mysql/conf.d"", path: ""/etc/my.cnf.d"", state: ""link"", force: true } - { src: ""/etc/mysql/my.cnf"", path: ""/etc/my.cnf"", state: ""link"", force: true } tags: - galera-config ",,80,0
openstack%2Ftripleo-heat-templates~master~I68b72cf736bc6c3597e2417c6c0b5afe9ff79d30,openstack/tripleo-heat-templates,master,I68b72cf736bc6c3597e2417c6c0b5afe9ff79d30,Replace tripleo-scenario002-multinode with scenario002-standalone,MERGED,2019-01-03 18:54:39.000000000,2019-01-08 10:37:55.000000000,2019-01-08 10:37:54.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-01-03 18:54:39.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/340afe288a572077961989aab36707c3a9184a81', 'message': 'Replace tripleo-scenario002-multinode with scenario002-standalone\n\nChange-Id: I68b72cf736bc6c3597e2417c6c0b5afe9ff79d30\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/532\n'}]",0,628264,340afe288a572077961989aab36707c3a9184a81,8,4,1,8175,,,0,"Replace tripleo-scenario002-multinode with scenario002-standalone

Change-Id: I68b72cf736bc6c3597e2417c6c0b5afe9ff79d30
Story: https://tree.taiga.io/project/tripleo-ci-board/us/532
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/628264/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,340afe288a572077961989aab36707c3a9184a81,replace-scen2, - tripleo-ci-centos-7-scenario002-standalone: - ci/environments/scenario002-standalone.yaml, - tripleo-ci-centos-7-scenario002-multinode-oooq-container: - ci/environments/scenario002-multinode-containers.yaml,2,2
openstack%2Ftenks~master~I8c42e85c8b3abe8712879c5737d85ee72e231f9e,openstack/tenks,master,I8c42e85c8b3abe8712879c5737d85ee72e231f9e,Check for specific error messages in ironic version check,MERGED,2018-12-20 15:47:14.000000000,2019-01-08 10:37:10.000000000,2019-01-08 10:37:10.000000000,"[{'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-20 15:47:14.000000000', 'files': ['ansible/roles/ironic-enrolment/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tenks/commit/ff3a73f37dfadb46eccb72ebe8a57e30148c6a69', 'message': 'Check for specific error messages in ironic version check\n\nWhen checking for the 1.34 ironic API version for physnet support, explicitly\ncheck for known error messages to make it more robust.\n\nChange-Id: I8c42e85c8b3abe8712879c5737d85ee72e231f9e\n'}]",0,626600,ff3a73f37dfadb46eccb72ebe8a57e30148c6a69,6,2,1,14826,,,0,"Check for specific error messages in ironic version check

When checking for the 1.34 ironic API version for physnet support, explicitly
check for known error messages to make it more robust.

Change-Id: I8c42e85c8b3abe8712879c5737d85ee72e231f9e
",git fetch https://review.opendev.org/openstack/tenks refs/changes/00/626600/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ironic-enrolment/tasks/main.yml'],1,ff3a73f37dfadb46eccb72ebe8a57e30148c6a69,standalone," failed_when: - api_version_result.rc != 0 # 'invalid choice' if the client doesn't support 1.34. - ""'invalid choice' not in api_version_result.stderr"" # 'not supported' if the server doesn't support 1.34. - ""'not supported' not in api_version_result.stderr""", failed_when: false,6,1
openstack%2Fopenstack-ansible-lxc_container_create~master~If9e912641b5b6cb7791221b40dd4d56e215c2b98,openstack/openstack-ansible-lxc_container_create,master,If9e912641b5b6cb7791221b40dd4d56e215c2b98,Resolve btrfs backing store variable inconsistency,MERGED,2019-01-07 14:25:44.000000000,2019-01-08 10:30:52.000000000,2019-01-07 20:17:51.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-07 14:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/12ce0aca0b34c41bd9d5629aced1de489b88fa58', 'message': 'Correct variable names for qgroup/quota limit tasks\n\nIn Ica79472568799098ebf83c6cefc585f117975f37 some incorrect\nvariable names were used. This patch corrects them.\n\nChange-Id: If9e912641b5b6cb7791221b40dd4d56e215c2b98\n'}, {'number': 2, 'created': '2019-01-07 15:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/b9a9ad38ba86447c83fa696ab5dca8db749451c7', 'message': 'Correct variable names for qgroup/quota limit tasks\n\nIn Ica79472568799098ebf83c6cefc585f117975f37 some incorrect\nvariable names were used. This patch corrects them.\n\nChange-Id: If9e912641b5b6cb7791221b40dd4d56e215c2b98\n'}, {'number': 3, 'created': '2019-01-07 17:18:44.000000000', 'files': ['releasenotes/notes/lxc-host-machine-vars-5d11b1f269167fd3.yaml', 'tasks/lxc_container_create_cow.yml', 'defaults/main.yml', 'tasks/lxc_container_create_machinectl.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/a14dcc84891249e2b0065cefc50035ef8e5c2dcf', 'message': 'Resolve btrfs backing store variable inconsistency\n\nIn Ica79472568799098ebf83c6cefc585f117975f37 some incorrect\nvariable names were used. This patch changes the variable\nnames to suit their purpose and ensures that they are used\nconsistently throughout the role.\n\nChange-Id: If9e912641b5b6cb7791221b40dd4d56e215c2b98\n'}]",3,628982,a14dcc84891249e2b0065cefc50035ef8e5c2dcf,17,4,3,6816,,,0,"Resolve btrfs backing store variable inconsistency

In Ica79472568799098ebf83c6cefc585f117975f37 some incorrect
variable names were used. This patch changes the variable
names to suit their purpose and ensures that they are used
consistently throughout the role.

Change-Id: If9e912641b5b6cb7791221b40dd4d56e215c2b98
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/82/628982/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_container_create_cow.yml'],1,12ce0aca0b34c41bd9d5629aced1de489b88fa58,628982," - ""-e {{ lxc_host_qgroup_space_limit }}"" - ""-c {{ lxc_host_qgroup_compression_limit }}"" when: - not lxc_host_machine_quota_disabled setting `lxc_host_machine_quota_disabled` to true."," - ""-e {{ nspawn_host_qgroup_space_limit }}"" - ""-c {{ nspawn_host_qgroup_compression_limit }}"" when: - not nspawn_host_machine_quota_disabled setting `nspawn_host_machine_quota_disabled` to true.",4,4
openstack%2Fnetworking-bgpvpn~master~I0eb018c344b5ae0bb76d9eb13827dcb2b79dfac4,openstack/networking-bgpvpn,master,I0eb018c344b5ae0bb76d9eb13827dcb2b79dfac4,DNM: test with only 2 BGPVPN tempest scenario tests,ABANDONED,2018-12-21 13:47:24.000000000,2019-01-08 10:28:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-21 13:47:24.000000000', 'files': ['devstack/devstack-gate-bagpipe-rc'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/14bfc67d2c2ebfcb5bdb3c5f8f21917459f4689c', 'message': 'DNM: test with only 2 BGPVPN tempest scenario tests\n\nSee if it helps understanding bug 1807152.\n\nChange-Id: I0eb018c344b5ae0bb76d9eb13827dcb2b79dfac4\n'}]",0,626896,14bfc67d2c2ebfcb5bdb3c5f8f21917459f4689c,3,1,1,12021,,,0,"DNM: test with only 2 BGPVPN tempest scenario tests

See if it helps understanding bug 1807152.

Change-Id: I0eb018c344b5ae0bb76d9eb13827dcb2b79dfac4
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/96/626896/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstack-gate-bagpipe-rc'],1,14bfc67d2c2ebfcb5bdb3c5f8f21917459f4689c,bug/1807152," export DEVSTACK_GATE_TEMPEST_REGEX=""^networking_bgpvpn_tempest\.tests\.scenario\.test_bgpvpn_basic\.TestBGPVPNBasic\.(test_bgpvpn_basic|test_bgpvpn_negative_delete_bgpvpn)"""," export DEVSTACK_GATE_TEMPEST_REGEX=""^networking_bgpvpn_tempest\.tests\.scenario\.test_bgpvpn_basic\.TestBGPVPNBasic\.test_bgpvpn_basic""",1,1
openstack%2Fnetworking-bgpvpn~master~I3f9f5b73e498d318e583e3e76ca3e37924383dd0,openstack/networking-bgpvpn,master,I3f9f5b73e498d318e583e3e76ca3e37924383dd0,DNM: test with only a single BGPVPN tempest scenario test,ABANDONED,2018-12-21 13:45:13.000000000,2019-01-08 10:28:34.000000000,,"[{'_account_id': 12021}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 13:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/3a7cd7cff1e52f42a9e39823114a1fe43f075c50', 'message': 'DNM: test with only a single BGPVPN tempest scenario test\n\nChange-Id: I3f9f5b73e498d318e583e3e76ca3e37924383dd0\n'}, {'number': 2, 'created': '2018-12-21 14:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/ee5c4001a402cc72337ff6ae9fa13979571ab045', 'message': 'DNM: test with only a single BGPVPN tempest scenario test\n\nChange-Id: I3f9f5b73e498d318e583e3e76ca3e37924383dd0\n'}, {'number': 3, 'created': '2018-12-21 15:14:27.000000000', 'files': ['networking_bgpvpn_tempest/tests/scenario/test_bgpvpn_basic.py', 'devstack/devstack-gate-bagpipe-rc'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/4251418b3bf29361c759f667785a8701a497ad96', 'message': 'DNM: test with only a single BGPVPN tempest scenario test\n\nChange-Id: I3f9f5b73e498d318e583e3e76ca3e37924383dd0\n'}]",0,626895,4251418b3bf29361c759f667785a8701a497ad96,13,3,3,12021,,,0,"DNM: test with only a single BGPVPN tempest scenario test

Change-Id: I3f9f5b73e498d318e583e3e76ca3e37924383dd0
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/95/626895/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstack-gate-bagpipe-rc'],1,3a7cd7cff1e52f42a9e39823114a1fe43f075c50,freeze_to_debug_1807152," export DEVSTACK_GATE_TEMPEST_REGEX=""^networking_bgpvpn_tempest\.tests\.scenario\.test_bgpvpn_basic\.TestBGPVPNBasic\.test_bgpvpn_basic"""," export DEVSTACK_GATE_TEMPEST_REGEX=""^networking_bgpvpn_tempest\.""",1,1
openstack%2Fmagnum~master~Iaa618309375cf17d6511ae371a6a15a3345d4d6d,openstack/magnum,master,Iaa618309375cf17d6511ae371a6a15a3345d4d6d,Change docker image pulling policy from Always to IfNotPresent,MERGED,2018-12-20 01:24:09.000000000,2019-01-08 10:21:14.000000000,2019-01-08 10:21:14.000000000,"[{'_account_id': 6484}, {'_account_id': 13861}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 29425}]","[{'number': 1, 'created': '2018-12-20 01:24:09.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/enable-prometheus-monitoring.sh', 'magnum/drivers/common/templates/kubernetes/fragments/core-dns-service.sh', 'magnum/drivers/k8s_coreos_v1/templates/fragments/enable-coredns.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/26c28a03d2849b940253fc3096316469985651f3', 'message': 'Change docker image pulling policy from Always to IfNotPresent\n\nDo not repeat pulling images when container recreate in magnum cluster.\n\nChange-Id: Iaa618309375cf17d6511ae371a6a15a3345d4d6d\nStory:2004644\nTask:28595\n'}]",0,626417,26c28a03d2849b940253fc3096316469985651f3,9,6,1,25493,,,0,"Change docker image pulling policy from Always to IfNotPresent

Do not repeat pulling images when container recreate in magnum cluster.

Change-Id: Iaa618309375cf17d6511ae371a6a15a3345d4d6d
Story:2004644
Task:28595
",git fetch https://review.opendev.org/openstack/magnum refs/changes/17/626417/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/fragments/enable-prometheus-monitoring.sh', 'magnum/drivers/common/templates/kubernetes/fragments/core-dns-service.sh', 'magnum/drivers/k8s_coreos_v1/templates/fragments/enable-coredns.yaml']",3,26c28a03d2849b940253fc3096316469985651f3,change_image_policy, imagePullPolicy: IfNotPresent, imagePullPolicy: Always,3,3
openstack%2Ftripleo-ci~master~I046aeea86b3b63cae0b44865dc8ee0a59a3f7f5f,openstack/tripleo-ci,master,I046aeea86b3b63cae0b44865dc8ee0a59a3f7f5f,Remove duplicated tasks from build jobs,MERGED,2019-01-07 14:33:31.000000000,2019-01-08 10:13:23.000000000,2019-01-08 10:13:23.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 9592}, {'_account_id': 10239}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-01-07 14:33:31.000000000', 'files': ['playbooks/tripleo-buildcontainers/run.yaml', 'playbooks/tripleo-buildimage/run-v3.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c1327819bb0887bad55902c3b89dc397fb2e5a07', 'message': ""Remove duplicated tasks from build jobs\n\nhttps://review.openstack.org/#/c/607288/ shuffled some basic setup tasks\naround and put them in tripleo-ci/pre.yaml. Unfortunately the\nconfigure-swap task isn't idempotent so let's stop duplicating the tasks\nin the build jobs now.\n\nChange-Id: I046aeea86b3b63cae0b44865dc8ee0a59a3f7f5f\nCloses-Bug: #1810777\n""}]",0,628984,c1327819bb0887bad55902c3b89dc397fb2e5a07,21,9,1,14985,,,0,"Remove duplicated tasks from build jobs

https://review.openstack.org/#/c/607288/ shuffled some basic setup tasks
around and put them in tripleo-ci/pre.yaml. Unfortunately the
configure-swap task isn't idempotent so let's stop duplicating the tasks
in the build jobs now.

Change-Id: I046aeea86b3b63cae0b44865dc8ee0a59a3f7f5f
Closes-Bug: #1810777
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/84/628984/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/tripleo-buildcontainers/run.yaml', 'playbooks/tripleo-buildimage/run-v3.yaml']",2,c1327819bb0887bad55902c3b89dc397fb2e5a07,bug/1810777,, - name: Swap is essential as we are not meeting memory requirements include_role: name: configure-swap - name: Set legacy log path include_role: name: set-zuul-log-path-fact - name: Ensure legacy workspace directory file: path: '{{ workspace }}' state: directory - name: Ensure legacy logs directory file: path: '{{ workspace }}/logs' state: directory ,0,36
openstack%2Fopenstack-ansible-os_tempest~master~I7927f6f377bf088456ac1a8b5b3066457749bfaa,openstack/openstack-ansible-os_tempest,master,I7927f6f377bf088456ac1a8b5b3066457749bfaa,Synced tempest plugins names and services,MERGED,2019-01-07 10:03:54.000000000,2019-01-08 10:11:32.000000000,2019-01-08 10:11:32.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-07 10:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/1c703e302fed5968d9493a0310ce48122d8eb3ae', 'message': 'Updated tempest plugin pkgs list for Red Hat distros\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 2, 'created': '2019-01-07 10:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/8e483660217ca55bcde9cdc239188132a30a1442', 'message': 'Updated tempest plugin pkgs list for Red Hat distros\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 3, 'created': '2019-01-07 11:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/963975e497dd4cf395e06458ece94d2173596af3', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 4, 'created': '2019-01-07 12:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5cb0d60e6c2d7d5f649ea10b8b6dbbbcf9ca1e50', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 5, 'created': '2019-01-07 12:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/1fe489dae262dfa03be6e1aeabd25a2661fd50ce', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 6, 'created': '2019-01-07 13:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/924ba6de7fbb915a2f645870d9efc9f3b614878e', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 7, 'created': '2019-01-07 15:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/b25ca3aea0d883378229addc418583ca02c8fe6d', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 8, 'created': '2019-01-07 16:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/99c8b648e4dc28e198e8ce483fd8d374d1aa7d18', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}, {'number': 9, 'created': '2019-01-08 05:17:29.000000000', 'files': ['vars/redhat-7.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/25b5533c30e328c80d29348dff0cfc0f2ac5e88f', 'message': 'Synced tempest plugins names and services\n\nIt updates the package names and service availability flag\nfor all the tempest plugins defined in defaults/main.yml.\n\nChange-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa\n'}]",12,628926,25b5533c30e328c80d29348dff0cfc0f2ac5e88f,28,8,9,12393,,,0,"Synced tempest plugins names and services

It updates the package names and service availability flag
for all the tempest plugins defined in defaults/main.yml.

Change-Id: I7927f6f377bf088456ac1a8b5b3066457749bfaa
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/26/628926/9 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,1c703e302fed5968d9493a0310ce48122d8eb3ae,tempest_plugins," - ""{{ (tempest_service_available_designate | bool) | ternary('python-designate-tests-tempest', '') }}"" - ""{{ (tempest_service_available_barbican | bool) | ternary('python-barbican-tests-tempest', '') }}"" - ""{{ (tempest_service_available_octavia | bool) | ternary('python-octavia-tests-tempest', '') }}"" - ""{{ (tempest_service_available_manila | bool) | ternary('python-manila-tests-tempest', '') }}"" - ""{{ (tempest_service_available_magnum | bool) | ternary('python-magnum-tests-tempest', '') }}""",,5,1
openstack%2Fopenstack-ansible-galera_client~master~I49790baa8394d9d6d412bf06252e9812f766ea30,openstack/openstack-ansible-galera_client,master,I49790baa8394d9d6d412bf06252e9812f766ea30,cleanup: stop managing files inside /etc,MERGED,2018-12-29 22:44:23.000000000,2019-01-08 09:59:39.000000000,2019-01-03 09:20:25.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-29 22:44:23.000000000', 'files': ['tasks/galera_client_install_yum.yml', 'tests/test.yml', 'tasks/galera_client_install_zypper.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/30cb1e72d6736bae9dacbed0c3e6ef8fb174aaeb', 'message': ""cleanup: stop managing files inside /etc\n\nIf we're installing a client, there's absolutely no need for us\nto be touching things inside /etc.  This is not being done inside\nthe process installing on Debian based operating systems however\nit is being done under CentOS and SUSE.\n\nChange-Id: I49790baa8394d9d6d412bf06252e9812f766ea30\n""}]",1,627785,30cb1e72d6736bae9dacbed0c3e6ef8fb174aaeb,9,3,1,1004,,,0,"cleanup: stop managing files inside /etc

If we're installing a client, there's absolutely no need for us
to be touching things inside /etc.  This is not being done inside
the process installing on Debian based operating systems however
it is being done under CentOS and SUSE.

Change-Id: I49790baa8394d9d6d412bf06252e9812f766ea30
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/85/627785/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_client_install_yum.yml', 'tests/test.yml', 'tasks/galera_client_install_zypper.yml']",3,30cb1e72d6736bae9dacbed0c3e6ef8fb174aaeb,osa-speedups,,"- name: Stats /etc/my.cnf.d stat: path: /etc/my.cnf.d register: mycnfd_stat - name: Destroy my.cnf.d dir if is dir file: path: /etc/my.cnf.d state: absent force: true when: - mycnfd_stat.stat.isdir is defined - mycnfd_stat.stat.isdir == True - name: Update the local file system CRUD file: src: ""{{ item.src|default(omit) }}"" path: ""{{ item.path }}"" state: ""{{ item.state }}"" force: ""{{ item.force|default(omit) }}"" with_items: - { path: ""/etc/mysql"", state: ""directory"" } - { path: ""/etc/mysql/conf.d"", state: ""directory"" } - { src: ""/etc/mysql/conf.d"", path: ""/etc/my.cnf.d"", state: ""link"", force: true } - { src: ""/etc/mysql/my.cnf"", path: ""/etc/my.cnf"", state: ""link"", force: true } tags: - galera-config ",0,80
openstack%2Ftripleo-heat-templates~master~I4324cd8c9bb62a482efc7e68020e110b47a7973d,openstack/tripleo-heat-templates,master,I4324cd8c9bb62a482efc7e68020e110b47a7973d,WIP - DO NOT MERGE Flatten RabbitMQ service configuration,ABANDONED,2018-12-20 13:29:06.000000000,2019-01-08 09:56:32.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-12-20 13:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/456cf7f26a7f803a1a43b2487fe5ddf185b4f78a', 'message': 'WIP - DO NOT MERGE\nFlatten RabbitMQ service configuration\n\nThis change combines the previous puppet and docker files into a single file that\nperforms the docker service installation and configuration.\n\nWith this patch the baremetal version of RabbitMQ service has been removed.\n\nChange-Id: I4324cd8c9bb62a482efc7e68020e110b47a7973d\nRelated-Blueprint: services-yaml-flattening\n'}, {'number': 2, 'created': '2019-01-04 06:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e031bb79b6b6cf16ed2acb856f4e52d1f4ef3370', 'message': 'WIP - DO NOT MERGE\nFlatten RabbitMQ service configuration\n\nThis change combines the previous puppet and docker files into a single file that\nperforms the docker service installation and configuration.\n\nWith this patch the baremetal version of RabbitMQ service has been removed.\n\nChange-Id: I4324cd8c9bb62a482efc7e68020e110b47a7973d\nRelated-Blueprint: services-yaml-flattening\n'}, {'number': 3, 'created': '2019-01-08 06:24:25.000000000', 'files': ['puppet/services/messaging/notify-rabbitmq.yaml', 'ci/environments/multinode-3nodes-registry.yaml', 'environments/docker-ha.yaml', 'ci/environments/scenario003-standalone.yaml', 'docker/services/messaging/rpc-rabbitmq.yaml', 'environments/baremetal-services.yaml', 'ci/environments/scenario001-standalone.yaml', 'ci/environments/scenario004-multinode-containers.yaml', 'deployment/rabbitmq/rabbitmq-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'sample-env-generator/messaging.yaml', 'docker/services/messaging/notify-rabbitmq-shared.yaml', 'environments/messaging/rpc-qdrouterd-notify-rabbitmq-hybrid.yaml', 'tools/yaml-validate.py', 'deployment/rabbitmq/rabbitmq-messaging-notify-shared-puppet.yaml', 'ci/environments/scenario012-multinode-containers.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'puppet/services/pacemaker/rabbitmq.yaml', 'environments/nonha-arch.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'environments/messaging/rpc-rabbitmq-notify-rabbitmq-shared.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'environments/docker-uc-light.yaml', 'sample-env-generator/ssl.yaml', 'ci/environments/scenario004-standalone.yaml', 'puppet/services/rabbitmq.yaml', 'ci/environments/scenario000-multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'puppet/services/messaging/rpc-rabbitmq.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml', 'docker/services/rabbitmq.yaml', 'ci/environments/scenario003-multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2ccc6c9f007687925443c96b939144bae20f25fc', 'message': 'WIP - DO NOT MERGE\nFlatten RabbitMQ service configuration\n\nThis change combines the previous puppet and docker files into a single file that\nperforms the docker service installation and configuration.\n\nWith this patch the baremetal version of RabbitMQ service has been removed.\n\nChange-Id: I4324cd8c9bb62a482efc7e68020e110b47a7973d\nRelated-Blueprint: services-yaml-flattening\n'}]",0,626573,2ccc6c9f007687925443c96b939144bae20f25fc,11,3,3,28223,,,0,"WIP - DO NOT MERGE
Flatten RabbitMQ service configuration

This change combines the previous puppet and docker files into a single file that
performs the docker service installation and configuration.

With this patch the baremetal version of RabbitMQ service has been removed.

Change-Id: I4324cd8c9bb62a482efc7e68020e110b47a7973d
Related-Blueprint: services-yaml-flattening
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/73/626573/2 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/messaging/notify-rabbitmq.yaml', 'ci/environments/multinode-3nodes-registry.yaml', 'environments/docker-ha.yaml', 'ci/environments/scenario003-standalone.yaml', 'docker/services/messaging/rpc-rabbitmq.yaml', 'environments/baremetal-services.yaml', 'ci/environments/scenario001-standalone.yaml', 'ci/environments/scenario004-multinode-containers.yaml', 'deployment/rabbitmq/rabbitmq-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'sample-env-generator/messaging.yaml', 'docker/services/messaging/notify-rabbitmq-shared.yaml', 'environments/messaging/rpc-qdrouterd-notify-rabbitmq-hybrid.yaml', 'tools/yaml-validate.py', 'deployment/rabbitmq/rabbitmq-messaging-notify-shared-puppet.yaml', 'ci/environments/scenario012-multinode-containers.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'puppet/services/pacemaker/rabbitmq.yaml', 'environments/nonha-arch.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'environments/messaging/rpc-rabbitmq-notify-rabbitmq-shared.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'environments/docker-uc-light.yaml', 'sample-env-generator/ssl.yaml', 'ci/environments/scenario004-standalone.yaml', 'puppet/services/rabbitmq.yaml', 'ci/environments/scenario000-multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'puppet/services/messaging/rpc-rabbitmq.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml', 'docker/services/rabbitmq.yaml', 'ci/environments/scenario003-multinode-containers.yaml']",35,456cf7f26a7f803a1a43b2487fe5ddf185b4f78a,bp/services-yaml-flattening, OS::TripleO::Services::OsloMessagingNotify: ../../deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml, OS::TripleO::Services::OsloMessagingNotify: ../../docker/services/pacemaker/notify-rabbitmq.yaml,606,1173
openstack%2Fneutron~master~I427a497940efe6ff60338390a262d178f834dc8f,openstack/neutron,master,I427a497940efe6ff60338390a262d178f834dc8f,Update SR-IOV configuration admin docs,MERGED,2018-12-25 15:36:59.000000000,2019-01-08 09:47:03.000000000,2019-01-08 08:38:29.000000000,"[{'_account_id': 841}, {'_account_id': 7776}, {'_account_id': 11604}, {'_account_id': 11975}, {'_account_id': 12171}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}, {'_account_id': 28714}]","[{'number': 1, 'created': '2018-12-25 15:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1632f91cd36e2ee907500fe8806a45c646098054', 'message': 'Update SR-IOV configuration admin docs\n\nMellanox ConnectX-3 network adapter family requires\nadditional configuration in Neutron sriov agent when\nusing a dual port adapter.\n\nUpdated the relevant document to reflect the needed\nchange to allow Neutron sriov agent to properly utilize\nthe generated VFs.\n\nChange-Id: I427a497940efe6ff60338390a262d178f834dc8f\n'}, {'number': 2, 'created': '2019-01-03 18:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a889ced62a82d1eae8903e6a7b1e6c8d2390b6e', 'message': 'Update SR-IOV configuration admin docs\n\nMellanox ConnectX-3 network adapter family requires\nadditional configuration in Neutron sriov agent when\nusing a dual port adapter.\n\nUpdated the relevant document to reflect the needed\nchange to allow Neutron sriov agent to properly utilize\nthe generated VFs.\n\nChange-Id: I427a497940efe6ff60338390a262d178f834dc8f\n'}, {'number': 3, 'created': '2019-01-06 08:18:29.000000000', 'files': ['doc/source/admin/config-sriov.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f36a3b35f6080364ee3fc3d314e745784b795081', 'message': 'Update SR-IOV configuration admin docs\n\nMellanox ConnectX-3 network adapter family requires\nadditional configuration in Neutron sriov agent when\nusing a dual port adapter.\n\nUpdated the relevant document to reflect the needed\nchange to allow Neutron sriov agent to properly utilize\nthe generated VFs.\n\nChange-Id: I427a497940efe6ff60338390a262d178f834dc8f\n'}]",20,627312,f36a3b35f6080364ee3fc3d314e745784b795081,25,10,3,28714,,,0,"Update SR-IOV configuration admin docs

Mellanox ConnectX-3 network adapter family requires
additional configuration in Neutron sriov agent when
using a dual port adapter.

Updated the relevant document to reflect the needed
change to allow Neutron sriov agent to properly utilize
the generated VFs.

Change-Id: I427a497940efe6ff60338390a262d178f834dc8f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/627312/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/config-sriov.rst'],1,1632f91cd36e2ee907500fe8806a45c646098054,multiple_esw_per_pf,"For information on **Mellanox SR-IOV Ethernet ConnectX cards**, see: - `Mellanox: How To Configure SR-IOV VFs on ConnectX-4 or newer <https://community.mellanox.com/s/article/howto-configure-sr-iov-for-connectx-4-connectx-5-with-kvm--ethernet-x>`_. - `Mellanox: How To Configure SR-IOV VFs on ConnectX-3/ConnectX-3 Pro <https://community.mellanox.com/docs/DOC-1484>`_.SR-IOV with ConnectX-3/ConnectX-3 Pro Dual Port Ethernet ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In contrast to Mellanox newer generation NICs, ConnectX-3 family network adapters exposes a single PCI device (PF) in the system regardless of the number of physical ports. when the device is **dual port** and SR-IOV is enabled and configured we can observe some inconsistencies in linux networking subsystem. .. note:: In the example below ``enp4s0`` represents PF net device associated with physical port 1 and ``enp4s0d1`` represents PF net device associated with physical port 2. **Example:** A system with ConnectX-3 dual port device and a total of four VFs configured, two VFs assigned to port one and two VFs assigned to port two. .. code-block:: console $ lspci | grep Mellanox 04:00.0 Network controller: Mellanox Technologies MT27520 Family [ConnectX-3 Pro] 04:00.1 Network controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function] 04:00.2 Network controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function] 04:00.3 Network controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function] 04:00.4 Network controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function] Four VFs are available in the system, however, .. code-block:: console $ ip link show 31: enp4s0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop master ovs-system state DOWN mode DEFAULT group default qlen 1000 link/ether f4:52:14:01:d9:e1 brd ff:ff:ff:ff:ff:ff vf 0 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto vf 1 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto vf 2 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto vf 3 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto 32: enp4s0d1: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether f4:52:14:01:d9:e2 brd ff:ff:ff:ff:ff:ff vf 0 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto vf 1 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto vf 2 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto vf 3 MAC 00:00:00:00:00:00, vlan 4095, spoof checking off, link-state auto **ip** command identifies each PF associated net device as having four VFs *each*. .. note:: Mellanox ``mlx4`` driver allows *ip* commands to perform configuration of *all* VFs from either PF associated network devices. To allow neutron SR-IOV agent to properly identify the VFs that belong to the correct PF network device (thus to the correct network port) Admin is required to provide the `exclude_devices` configuration option in ``sriov_agent.ini`` **Step 1**: derive the VF to Port mapping from mlx4 driver configuration file: ``/etc/modprobe.d/mlnx.conf`` or ``/etc/modprobe.d/mlx4.conf`` .. code-block:: console $ cat /etc/modprobe.d/mlnx.conf | grep ""options mlx4_core"" options mlx4_core port_type_array=2,2 num_vfs=2,2,0 probe_vf=2,2,0 log_num_mgm_entry_size=-1 Where :: `num_vfs=n1,n2,n3` - The driver will enable `n1` VFs on physical port 1, `n2` VFs on physical port 2 and `n3` dual port VFs (applies only to dual port HCA when all ports are Ethernet ports). :: `probe_vfs=m1,m2,m3` - the driver probes `m1` single port VFs on physical port 1, `m2` single port VFs on physical port 2 (applies only if such a port exist) `m3` dual port VFs. Those VFs are attached to the hypervisor. (applies only if all ports are configured as Ethernet). The VFs will be enumerated in the following order: 1. port 1 VFs 2. port 2 VFs 3. dual port VFs In our example: | 04:00.0 : PF associated to **both** ports. | 04:00.1 : VF associated to port **1** | 04:00.2 : VF associated to port **1** | 04:00.3 : VF associated to port **2** | 04:00.4 : VF associated to port **2** **Step 2:** Update `exclude_devices` configuration option in ``sriov_agent.ini`` with the correct mapping Each PF associated net device shall exclude the **other** port's VFs .. code-block:: ini [sriov_nic] physical_device_mappings = physnet1:enp4s0,physnet2:enp4s0d exclude_devices = enp4s0:0000:04:00.3;0000:04:00.4,enp4s0d1:0000:04:00.1;0000:04:00.2 .. code-block:: ini","For information on **Mellanox SR-IOV Ethernet ConnectX-3/ConnectX-3 Pro cards**, see `Mellanox: How To Configure SR-IOV VFs <https://community.mellanox.com/docs/DOC-1484>`_. .. code-block:: none",102,4
openstack%2Freleases~master~I742ab96de6d8aaf52a82cb48e44ffd3daf1fa67b,openstack/releases,master,I742ab96de6d8aaf52a82cb48e44ffd3daf1fa67b,Update -milestone doc references to -rc,MERGED,2019-01-07 18:43:47.000000000,2019-01-08 09:37:38.000000000,2019-01-08 09:37:38.000000000,"[{'_account_id': 2472}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-01-07 18:43:47.000000000', 'files': ['doc/source/reference/using.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/16ceedd300e8c7afb535368419c4dab427dbc443', 'message': 'Update -milestone doc references to -rc\n\nChange-Id: I742ab96de6d8aaf52a82cb48e44ffd3daf1fa67b\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,629027,16ceedd300e8c7afb535368419c4dab427dbc443,8,4,1,11904,,,0,"Update -milestone doc references to -rc

Change-Id: I742ab96de6d8aaf52a82cb48e44ffd3daf1fa67b
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/27/629027/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/using.rst'],1,16ceedd300e8c7afb535368419c4dab427dbc443,rc-docs, projects using the cycle-with-rc release model. projects using the cycle-with-rc release model., projects using the cycle-with-milestone release model. projects using the cycle-with-milestone release model.,2,2
openstack%2Freleases~master~I7403b0ab2264ef7828c012a943cf093da2951d68,openstack/releases,master,I7403b0ab2264ef7828c012a943cf093da2951d68,improve list-changes handling for first releases,MERGED,2019-01-07 15:28:44.000000000,2019-01-08 09:32:33.000000000,2019-01-08 09:32:33.000000000,"[{'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-01-07 15:28:44.000000000', 'files': ['openstack_releases/cmds/list_changes.py', 'openstack_releases/gitutils.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/f8b4412fae75f7544876b6bd379e19a04ee01a68', 'message': ""improve list-changes handling for first releases\n\nBefore this change we always had a start revision value because\nget_latest_tag() returned a SHA if it didn't have a real tag. The way\nthat SHA is determined leads to not including all changes in the\nreport about the release, so we don't want to use the value. This\nchange allows get_latest_tag() to return None and in that case use an\nempty starting point for the diff range when computing the release\nnotes contents.\n\nChange-Id: I7403b0ab2264ef7828c012a943cf093da2951d68\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,628997,f8b4412fae75f7544876b6bd379e19a04ee01a68,8,4,1,2472,,,0,"improve list-changes handling for first releases

Before this change we always had a start revision value because
get_latest_tag() returned a SHA if it didn't have a real tag. The way
that SHA is determined leads to not including all changes in the
report about the release, so we don't want to use the value. This
change allows get_latest_tag() to return None and in that case use an
empty starting point for the diff range when computing the release
notes contents.

Change-Id: I7403b0ab2264ef7828c012a943cf093da2951d68
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/97/628997/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_releases/cmds/list_changes.py', 'openstack_releases/gitutils.py']",2,f8b4412fae75f7544876b6bd379e19a04ee01a68,cd/release-stub-placement,"def get_latest_tag(workdir, repo, sha=None, always=True): cmd = ['git', 'describe', '--abbrev=0'] if always: cmd.append('--always') LOG.debug(' '.join(cmd))","def get_latest_tag(workdir, repo, sha=None): cmd = ['git', 'describe', '--abbrev=0', '--always']",8,4
openstack%2Ftripleo-heat-templates~master~I889dcf632b3306ce7e56ac5394884c7c72481833,openstack/tripleo-heat-templates,master,I889dcf632b3306ce7e56ac5394884c7c72481833,Use templating for nova cell transport-url,MERGED,2018-12-19 14:20:17.000000000,2019-01-08 09:30:50.000000000,2019-01-08 09:30:50.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 8871}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-12-19 14:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f9535032b5fb97ae7dcb00050a3c2f3f1d970333', 'message': ""Use templating for nova cell transport-url\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated transport_url urls as part 2.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nChange-Id: I889dcf632b3306ce7e56ac5394884c7c72481833\nRelated-Bug: 1808134\n""}, {'number': 2, 'created': '2018-12-20 14:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf061a1fc5c22715a83717e8ac7afcad5af8f1eb', 'message': ""Use templating for nova cell transport-url\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated transport_url urls as part 2.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nChange-Id: I889dcf632b3306ce7e56ac5394884c7c72481833\nRelated-Bug: 1808134\n""}, {'number': 3, 'created': '2019-01-07 14:20:02.000000000', 'files': ['releasenotes/notes/nova_templated_cells_transport_url-275f0b707d9227ab.yaml', 'docker/services/nova-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/20b677d70a827003cfde91a177fc8625cc183b04', 'message': ""Use templating for nova cell transport-url\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated transport_url urls as part 2.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nChange-Id: I889dcf632b3306ce7e56ac5394884c7c72481833\nRelated-Bug: 1808134\n""}]",0,626177,20b677d70a827003cfde91a177fc8625cc183b04,37,12,3,17216,,,0,"Use templating for nova cell transport-url

Nova now allows use of templated urls in the database and mq
connections which will allow static configuration elements to be
applied to the urls read from the database per-node. This should
be a simpler and less obscure method of configuring things like
the per-node bind_address necessary for director's HA arrangement.

This patch addresses the templated transport_url urls as part 2.

Nova support added here:
https://review.openstack.org/#/c/578163/

Change-Id: I889dcf632b3306ce7e56ac5394884c7c72481833
Related-Bug: 1808134
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/77/626177/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/nova_templated_cells_transport_url-275f0b707d9227ab.yaml', 'docker/services/nova-api.yaml']",2,f9535032b5fb97ae7dcb00050a3c2f3f1d970333,bug/1808134," su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 update_cell --cell_uuid $DEFID --name=default --database_connection='CELLDB' --transport-url='TRANSPORTURL'"" su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 create_cell --name=default --database_connection='CELLDB' --transport-url='TRANSPORTURL'"" TRANSPORTURL: list_join: - '' - - '{scheme}' - '://' - '{username}' - ':' - '{password}' - '@' - '{hostname}' - ':{port}' - '/' - '?' - '{query}' template: nova-manage cell_v2 map_cell0 --database_connection='CELL0DB' --transport-url='TRANSPORTURL' TRANSPORTURL: list_join: - '' - - '{scheme}' - '://' - '{username}' - ':' - '{password}' - '@' - '{hostname}' - ':{port}' - '/' - '?' - '{query}'"," su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 update_cell --cell_uuid $DEFID --name=default --database_connection='CELLDB'"" su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 create_cell --name=default --database_connection='CELLDB'"" template: nova-manage cell_v2 map_cell0 --database_connection='CELL0DB'",41,3
openstack%2Fpuppet-ceph~master~Icb5d5b5f3c5348fda00035189591f006bf2fac5d,openstack/puppet-ceph,master,Icb5d5b5f3c5348fda00035189591f006bf2fac5d,Do not check for ldap secret with Fedora and RedHat > 7,MERGED,2018-12-26 10:51:14.000000000,2019-01-08 09:30:47.000000000,2019-01-08 09:30:47.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-26 10:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/3bf21da99dd2997db451d1514746686497a557aa', 'message': '[DNM] Testing radosgw with Fedora and python3\n\nChange-Id: Icb5d5b5f3c5348fda00035189591f006bf2fac5d\n'}, {'number': 2, 'created': '2018-12-26 10:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/a33eac92ea46afec4b4ee0c13bf4b13cf10a8a9e', 'message': '[DNM] Testing radosgw with Fedora and python3\n\nChange-Id: Icb5d5b5f3c5348fda00035189591f006bf2fac5d\n'}, {'number': 3, 'created': '2018-12-26 10:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/4d18dafdd08da8e47b086ecbf0845de86aac5d1f', 'message': '[DNM] Testing radosgw with Fedora and python3\n\nChange-Id: Icb5d5b5f3c5348fda00035189591f006bf2fac5d\n'}, {'number': 4, 'created': '2019-01-07 06:36:47.000000000', 'files': ['manifests/rgw/keystone.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/764bcf93de83dec7d4c9efd161dbc459d8a6632e', 'message': 'Do not check for ldap secret with Fedora and RedHat > 7\n\nCeph rgw fails when running with Fedora as it checks\nfor not existing file: /etc/openldap/secret which is\nonly required when enabling ldap [1].\n\nThis patch explicitly set rgw_ldap_secret to null to\nskip ldap_secret check. This can be cleared up once\nissue[1] is fixed in ceph luminous.\n\n[1] https://tracker.ceph.com/issues/24228\n\nChange-Id: Icb5d5b5f3c5348fda00035189591f006bf2fac5d\n'}]",0,627378,764bcf93de83dec7d4c9efd161dbc459d8a6632e,23,6,4,13861,,,0,"Do not check for ldap secret with Fedora and RedHat > 7

Ceph rgw fails when running with Fedora as it checks
for not existing file: /etc/openldap/secret which is
only required when enabling ldap [1].

This patch explicitly set rgw_ldap_secret to null to
skip ldap_secret check. This can be cleared up once
issue[1] is fixed in ceph luminous.

[1] https://tracker.ceph.com/issues/24228

Change-Id: Icb5d5b5f3c5348fda00035189591f006bf2fac5d
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/78/627378/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/rgw/keystone.pp', '.zuul.yaml']",2,3bf21da99dd2997db451d1514746686497a557aa,py3-enable,#- project: # templates: # - puppet-openstack-check-jobs # - puppet-openstack-module-unit-jobs # - puppet-openstack-integration-jobs-scenario001 # - puppet-openstack-integration-jobs-scenario004 # - release-notes-jobs-python3,- project: templates: - puppet-openstack-check-jobs - puppet-openstack-module-unit-jobs - puppet-openstack-integration-jobs-scenario001 - puppet-openstack-integration-jobs-scenario004 - release-notes-jobs-python3,8,7
openstack%2Frpm-packaging~master~I7f927b98d9269acdced168fa5b9b103aad7785fa,openstack/rpm-packaging,master,I7f927b98d9269acdced168fa5b9b103aad7785fa,Update to 2019 oslo releases,MERGED,2019-01-05 10:29:14.000000000,2019-01-08 09:29:25.000000000,2019-01-08 09:29:25.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-05 10:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d68e67eba022755d72e38f582fa84585ed684eef', 'message': 'Update to 2019 oslo releases\n\nChange-Id: I7f927b98d9269acdced168fa5b9b103aad7785fa\n'}, {'number': 2, 'created': '2019-01-07 00:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0ca5fc5b29a1dd3dddb2842f01342120b1a7bcee', 'message': 'Update to 2019 oslo releases\n\nChange-Id: I7f927b98d9269acdced168fa5b9b103aad7785fa\n'}, {'number': 3, 'created': '2019-01-07 09:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bac4e2897b7dde7f694fb51e959d0efe54b7ec70', 'message': 'Update to 2019 oslo releases\n\nChange-Id: I7f927b98d9269acdced168fa5b9b103aad7785fa\n'}, {'number': 4, 'created': '2019-01-07 14:35:32.000000000', 'files': ['openstack/oslo.middleware/oslo.middleware.spec.j2', 'openstack/oslo.utils/oslo.utils.spec.j2', 'openstack/oslo.cache/oslo.cache.spec.j2', 'openstack/oslotest/oslotest.spec.j2', 'openstack/oslo.db/oslo.db.spec.j2', 'openstack/oslo.service/oslo.service.spec.j2', 'openstack/oslo.i18n/oslo.i18n.spec.j2', 'openstack/oslo.context/oslo.context.spec.j2', 'openstack/oslo.log/oslo.log.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4c58a13d41d28163ce34831652fb324a0084c833', 'message': 'Update to 2019 oslo releases\n\nChange-Id: I7f927b98d9269acdced168fa5b9b103aad7785fa\n'}]",0,628728,4c58a13d41d28163ce34831652fb324a0084c833,22,6,4,6593,,,0,"Update to 2019 oslo releases

Change-Id: I7f927b98d9269acdced168fa5b9b103aad7785fa
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/28/628728/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/oslo.middleware/oslo.middleware.spec.j2', 'openstack/oslo.cache/oslo.cache.spec.j2', 'openstack/oslo.utils/oslo.utils.spec.j2', 'openstack/oslotest/oslotest.spec.j2', 'openstack/oslo.db/oslo.db.spec.j2', 'openstack/oslo.privsep/oslo.privsep.spec.j2', 'openstack/oslo.i18n/oslo.i18n.spec.j2', 'openstack/oslo.service/oslo.service.spec.j2', 'openstack/oslo.context/oslo.context.spec.j2', 'openstack/oslo.log/oslo.log.spec.j2', 'openstack/oslo.policy/oslo.policy.spec.j2']",11,d68e67eba022755d72e38f582fa84585ed684eef,oslo_2019,{% set upstream_version = upstream_version('1.44.0') %},{% set upstream_version = upstream_version('1.39.1') %},11,11
openstack%2Fhorizon~master~I3c9260f323ed78bc16e4e9b0ba31c4ded30c5b50,openstack/horizon,master,I3c9260f323ed78bc16e4e9b0ba31c4ded30c5b50,Imported Translations from Zanata,MERGED,2019-01-08 06:55:13.000000000,2019-01-08 09:23:05.000000000,2019-01-08 09:23:05.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 06:55:13.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/djangojs.po', 'doc/source/locale/zh_CN/LC_MESSAGES/doc.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d234cc6bab9a2c8938156594f29cf918623ef1c5', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3c9260f323ed78bc16e4e9b0ba31c4ded30c5b50\n'}]",0,629097,d234cc6bab9a2c8938156594f29cf918623ef1c5,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3c9260f323ed78bc16e4e9b0ba31c4ded30c5b50
",git fetch https://review.opendev.org/openstack/horizon refs/changes/97/629097/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/djangojs.po', 'doc/source/locale/zh_CN/LC_MESSAGES/doc.po']",2,d234cc6bab9a2c8938156594f29cf918623ef1c5,zanata/translations,"# Horace Li <haoyang@openstack.org>, 2019. #zanata msgid """" msgstr """" ""Project-Id-Version: horizon 15.0.0.0b2.dev191\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2019-01-07 04:22-0600\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2019-01-07 12:56+0000\n"" ""Last-Translator: Horace Li <haoyang@openstack.org>\n"" ""Language-Team: Chinese (China)\n"" ""Language: zh_CN\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=1; plural=0\n"" msgid "":ref:`genindex`"" msgstr "":ref:`genindex`"" msgid "":ref:`modindex`"" msgstr "":ref:`modindex`"" msgid """" ""A Python class representing a sub-navigation item (e.g. \""instances\"") which "" ""contains all the necessary logic (views, forms, tests, etc.) for that "" ""interface."" msgstr """" ""表示一个子导航项 (例如“实例”)的一个 Python 类，它包含该接口的所有必要逻辑（视"" ""图，表单，测试等）。"" msgid """" ""A Python class representing a top-level navigation item (e.g. \""project\"") "" ""which provides a consistent API for Horizon-compatible applications."" msgstr """" ""表示一个顶层导航项 (例如“项目”) 的一个 Python 类，它为 Horizon 兼容的应用提供"" ""了一致的API。"" msgid ""Contributor Docs"" msgstr ""贡献者文档"" msgid ""Dashboard"" msgstr ""仪表板"" msgid """" ""For a more in-depth look at Horizon and its architecture, see the :ref:"" ""`contributor-intro`."" msgstr ""有关Horizon及其架构的更深入了解，参阅： :ref:`quickstart`。"" msgid """" ""For those wishing to develop Horizon itself, or go in-depth with building "" ""your own :class:`~horizon.Dashboard` or :class:`~horizon.Panel` classes, the "" ""following documentation is provided."" msgstr """" ""对于那些希望开发 Horizon 本身的开发者，或者想深入了解构建自己的 :class:"" ""`~horizon.Dashboard` 或者 :class:`~horizon.Panel` 类，以下文档被提供。"" msgid ""Glossary"" msgstr ""术语表"" msgid ""Horizon"" msgstr ""Horizon"" msgid """" ""Horizon is the canonical implementation of `OpenStack's Dashboard <https://"" ""github.com/openstack/horizon>`_, which provides a web based user interface "" ""to OpenStack services including Nova, Swift, Keystone, etc."" msgstr """" ""Horizon 是 `OpenStack 仪表板 <https://github.com/openstack/horizon>`_ 的规范"" ""实现，它为 OpenStack 服务，包括 Nova，Swift，Keystone 等，提供了基于网络的用"" ""户界面。"" msgid ""Horizon: The OpenStack Dashboard Project"" msgstr ""Horizon：OpenStack 仪表板项目"" msgid ""How to use Horizon in your own projects."" msgstr ""如何在你自己的项目中使用 Horizon"" msgid ""Information"" msgstr ""信息"" msgid ""Introduction"" msgstr ""介绍"" msgid ""Panel"" msgstr ""面板"" msgid ""Project"" msgstr ""项目"" msgid ""Release Notes"" msgstr ""发行说明"" msgid ""See https://docs.openstack.org/releasenotes/horizon/."" msgstr ""参见 https://docs.openstack.org/releasenotes/horizon/。"" msgid """" ""The OpenStack dashboard project. Also the name of the top-level Python "" ""object which handles registration for the app."" msgstr ""OpenStack 仪表板项目。也是处理应用注册的顶层 Python 对象的名字。"" msgid ""To learn what you need to know to get going, see the :ref:`quickstart`."" msgstr ""要了解你需要了解的内容，参阅： :ref:`quickstart`。"" msgid """" ""Used in user-facing text in place of the term \""Tenant\"" which is Keystone's "" ""word."" msgstr ""被使用在面向用户的文本里代替 Keystone 的术语“租户”。"" msgid ""Using Horizon"" msgstr ""使用 Horizon"" ",,129,3
openstack%2Fsolum~master~I8d1d3bbc30991067841d29a92a38f47fd2a902de,openstack/solum,master,I8d1d3bbc30991067841d29a92a38f47fd2a902de,Use threading  executor,MERGED,2019-01-08 05:14:26.000000000,2019-01-08 09:17:04.000000000,2019-01-08 09:17:04.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 05:14:26.000000000', 'files': ['solum/common/rpc/service.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/6ad88a8937d7cab7d39091682f2d7ef419cdfeed', 'message': 'Use threading  executor\n\nChange-Id: I8d1d3bbc30991067841d29a92a38f47fd2a902de\n'}]",0,629090,6ad88a8937d7cab7d39091682f2d7ef419cdfeed,6,2,1,14107,,,0,"Use threading  executor

Change-Id: I8d1d3bbc30991067841d29a92a38f47fd2a902de
",git fetch https://review.opendev.org/openstack/solum refs/changes/90/629090/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/common/rpc/service.py'],1,6ad88a8937d7cab7d39091682f2d7ef419cdfeed,," executor='threading',",,1,0
openstack%2Fopenstacksdk~master~I9e5ef81a63418748f0c03b063ec0db77648336aa,openstack/openstacksdk,master,I9e5ef81a63418748f0c03b063ec0db77648336aa,Enable pagination for Floating IPs,ABANDONED,2019-01-07 12:56:01.000000000,2019-01-08 09:00:17.000000000,,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 26250}]","[{'number': 1, 'created': '2019-01-07 12:56:01.000000000', 'files': ['openstack/network/v2/floating_ip.py', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/tests/unit/test_proxy_base.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e04ed94598acda4304f6b1f9789d769c23ce303f', 'message': ""Enable pagination for Floating IPs\n\nWe've got a lot of floating IPs in production and were wondering, why\n``openstack floating ip show <IP>`` didn't find a specific IP and why it\nwas only listed in ``openstack floating ip list`` when using filters..\nThe reason was, that ``python-openstackclient`` uses\n``find_ip``/``list`` of ``openstack.network.v2.proxy.Proxy`` which\ndidn't use pagination.\n\nTherefore, this commit enables pagination for floating ips.\n\nChange-Id: I9e5ef81a63418748f0c03b063ec0db77648336aa\n""}]",0,628950,e04ed94598acda4304f6b1f9789d769c23ce303f,5,3,1,26250,,,0,"Enable pagination for Floating IPs

We've got a lot of floating IPs in production and were wondering, why
``openstack floating ip show <IP>`` didn't find a specific IP and why it
was only listed in ``openstack floating ip list`` when using filters..
The reason was, that ``python-openstackclient`` uses
``find_ip``/``list`` of ``openstack.network.v2.proxy.Proxy`` which
didn't use pagination.

Therefore, this commit enables pagination for floating ips.

Change-Id: I9e5ef81a63418748f0c03b063ec0db77648336aa
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/50/628950/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/floating_ip.py', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/tests/unit/test_proxy_base.py']",4,e04ed94598acda4304f6b1f9789d769c23ce303f,," expected_kwargs = kwargs.pop(""expected_kwargs"", {})", expected_kwargs = {},8,6
openstack%2Fironic~master~I6af132e2bfa6e4f7b93bd20f22a668790a22a30e,openstack/ironic,master,I6af132e2bfa6e4f7b93bd20f22a668790a22a30e,Allocation API: database and RPC,MERGED,2018-12-10 16:14:03.000000000,2019-01-08 08:49:30.000000000,2019-01-08 08:49:29.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 28429}]","[{'number': 1, 'created': '2018-12-10 16:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa02d522f36460aed77b1ccd1a11b85ebb5f9cd1', 'message': '[WIP] Allocation API: database and RPC\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}, {'number': 2, 'created': '2018-12-11 14:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2fc58d4f324426813ec7e617c02e2a4cc89e6375', 'message': '[WIP] Allocation API: database and RPC\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}, {'number': 3, 'created': '2018-12-11 15:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/248b841ba72da4a2797f0287ec1ab31b98f5c147', 'message': 'Allocation API: database and RPC\n\nThis change adds the database models and API, as well as RPC objects\nfor the allocation API. Also the node database API is extended with\nquery by power state and list of UUIDs.\n\nThere is one discrepancy from the initially approved spec: since we\ndo not have to separately update traits in an allocation, the planned\nallocation_traits table was replaced by a simple field.\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}, {'number': 4, 'created': '2018-12-11 17:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d90fc649269d62bc3d83800bd5b0ca7158415911', 'message': 'Allocation API: database and RPC\n\nThis change adds the database models and API, as well as RPC objects\nfor the allocation API. Also the node database API is extended with\nquery by power state and list of UUIDs.\n\nThere is one discrepancy from the initially approved spec: since we\ndo not have to separately update traits in an allocation, the planned\nallocation_traits table was replaced by a simple field.\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}, {'number': 5, 'created': '2018-12-12 10:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/59f6bc746d913f06b6e54ab1f67e00c07a903269', 'message': 'Allocation API: database and RPC\n\nThis change adds the database models and API, as well as RPC objects\nfor the allocation API. Also the node database API is extended with\nquery by power state and list of UUIDs.\n\nThere is one discrepancy from the initially approved spec: since we\ndo not have to separately update traits in an allocation, the planned\nallocation_traits table was replaced by a simple field.\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}, {'number': 6, 'created': '2018-12-13 15:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36b047ff5e1b0c1cf64d4b58bf8a9ce3bcc87e85', 'message': 'Allocation API: database and RPC\n\nThis change adds the database models and API, as well as RPC objects\nfor the allocation API. Also the node database API is extended with\nquery by power state and list of UUIDs.\n\nThere is one discrepancy from the initially approved spec: since we\ndo not have to separately update traits in an allocation, the planned\nallocation_traits table was replaced by a simple field.\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}, {'number': 7, 'created': '2019-01-07 11:51:23.000000000', 'files': ['ironic/tests/unit/api/utils.py', 'ironic/db/sqlalchemy/alembic/versions/dd67b91a1981_add_allocations_table.py', 'ironic/objects/allocation.py', 'ironic/cmd/dbsync.py', 'ironic/objects/node.py', 'ironic/tests/unit/db/test_allocations.py', 'ironic/common/exception.py', 'ironic/db/sqlalchemy/api.py', 'ironic/tests/unit/db/utils.py', 'ironic/tests/unit/db/test_nodes.py', 'ironic/tests/unit/objects/test_allocation.py', 'ironic/common/release_mappings.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/db/sqlalchemy/models.py', 'ironic/tests/unit/db/sqlalchemy/test_migrations.py', 'ironic/db/api.py', 'ironic/objects/__init__.py', 'ironic/tests/unit/objects/test_node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a4717d9958c5b434ab01afaca095e018db5aaa7d', 'message': 'Allocation API: database and RPC\n\nThis change adds the database models and API, as well as RPC objects\nfor the allocation API. Also the node database API is extended with\nquery by power state and list of UUIDs.\n\nThere is one discrepancy from the initially approved spec: since we\ndo not have to separately update traits in an allocation, the planned\nallocation_traits table was replaced by a simple field.\n\nChange-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e\nStory: #2004341\nTask: #28367\n'}]",21,624119,a4717d9958c5b434ab01afaca095e018db5aaa7d,105,9,7,10239,,,0,"Allocation API: database and RPC

This change adds the database models and API, as well as RPC objects
for the allocation API. Also the node database API is extended with
query by power state and list of UUIDs.

There is one discrepancy from the initially approved spec: since we
do not have to separately update traits in an allocation, the planned
allocation_traits table was replaced by a simple field.

Change-Id: I6af132e2bfa6e4f7b93bd20f22a668790a22a30e
Story: #2004341
Task: #28367
",git fetch https://review.opendev.org/openstack/ironic refs/changes/19/624119/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/db/sqlalchemy/alembic/versions/dd67b91a1981_add_allocations_table.py', 'ironic/db/sqlalchemy/api.py', 'ironic/objects/allocation.py', 'ironic/common/release_mappings.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/db/sqlalchemy/models.py', 'ironic/tests/unit/db/sqlalchemy/test_migrations.py', 'ironic/db/api.py', 'ironic/objects/__init__.py']",9,aa02d522f36460aed77b1ccd1a11b85ebb5f9cd1,story/2004341, __import__('ironic.objects.allocation'),,601,0
openstack%2Fheat-dashboard~master~Ice8649d24fd6386a70eac10c64a8d1b990fd3469,openstack/heat-dashboard,master,Ice8649d24fd6386a70eac10c64a8d1b990fd3469,fix bug link in readme,MERGED,2018-08-29 13:58:37.000000000,2019-01-08 08:35:16.000000000,2019-01-08 08:35:16.000000000,"[{'_account_id': 1736}, {'_account_id': 19224}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-08-29 13:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/53054fbf6a018bb33ba682927441372d3340214c', 'message': 'fix bug link in readme\n\nThis patch fixes the bug tracker link in the readme. It is set to\ndepend on a job definition change in project-config so we can use this\npatch to test the new release jobs.\n\nChange-Id: Ice8649d24fd6386a70eac10c64a8d1b990fd3469\n'}, {'number': 2, 'created': '2018-08-29 13:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/9545e3d1ff2f625f4e3868147186b25cb76e086f', 'message': 'fix bug link in readme\n\nThis patch fixes the bug tracker link in the readme. It is set to\ndepend on a job definition change in project-config so we can use this\npatch to test the new release jobs.\n\nChange-Id: Ice8649d24fd6386a70eac10c64a8d1b990fd3469\n'}, {'number': 3, 'created': '2018-12-08 17:32:25.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/49594102ba92f3d10589bf43fe67f7f39cc5cf3d', 'message': 'fix bug link in readme\n\nThis patch fixes the bug tracker link in the readme. It is set to\ndepend on a job definition change in project-config so we can use this\npatch to test the new release jobs.\n\nChange-Id: Ice8649d24fd6386a70eac10c64a8d1b990fd3469\n'}]",0,597535,49594102ba92f3d10589bf43fe67f7f39cc5cf3d,13,6,3,21691,,,0,"fix bug link in readme

This patch fixes the bug tracker link in the readme. It is set to
depend on a job definition change in project-config so we can use this
patch to test the new release jobs.

Change-Id: Ice8649d24fd6386a70eac10c64a8d1b990fd3469
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/35/597535/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,53054fbf6a018bb33ba682927441372d3340214c,,* Bugs: https://storyboard.openstack.org/#!/project/openstack/heat-dashboard,* Bugs: https://bugs.launchpad.net/heat-dashboard,1,1
openstack%2Fblazar~master~I20f5a43bc6ff5b2bea7ec4c9c00526dd9d8e5a19,openstack/blazar,master,I20f5a43bc6ff5b2bea7ec4c9c00526dd9d8e5a19,Use template for lower-constraints,MERGED,2018-12-20 19:49:18.000000000,2019-01-08 08:12:41.000000000,2019-01-08 08:12:41.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25553}]","[{'number': 1, 'created': '2018-12-20 19:49:18.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/blazar/commit/37ff8b22b728fc9dbbe1b87a86e8fda0cf2ed839', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nChange-Id: I20f5a43bc6ff5b2bea7ec4c9c00526dd9d8e5a19\nNeeded-By: https://review.openstack.org/623229\n'}]",0,626671,37ff8b22b728fc9dbbe1b87a86e8fda0cf2ed839,8,4,1,6547,,,0,"Use template for lower-constraints

Small cleanups:

* Use openstack-lower-constraints-jobs template, remove individual
  jobs.
* Sort list of templates

Change-Id: I20f5a43bc6ff5b2bea7ec4c9c00526dd9d8e5a19
Needed-By: https://review.openstack.org/623229
",git fetch https://review.opendev.org/openstack/blazar refs/changes/71/626671/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,37ff8b22b728fc9dbbe1b87a86e8fda0cf2ed839,cd/py36-lower-constraints, - openstack-lower-constraints-jobs - openstack-python-jobs, - openstack-python-jobs - openstack-tox-lower-constraints - openstack-tox-lower-constraints,2,3
openstack%2Ffreezer-api~master~I7b63bcb4e5c13b524a5c2e6edb6e061fb17c0f06,openstack/freezer-api,master,I7b63bcb4e5c13b524a5c2e6edb6e061fb17c0f06,register elasticv2 backend options,NEW,2018-10-31 06:29:17.000000000,2019-01-08 08:12:23.000000000,,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}, {'_account_id': 25562}]","[{'number': 1, 'created': '2018-10-31 06:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/21ac0db074e34b8d8b902c196048e7428201406b', 'message': 'register elasticv2 backend options\n\nWe need to register the group and options to CONF in elasticv2 just\nlike in the elastic backend. Otherwise elasticv2 will not work and\nfreezer API will fail.\n\nChange-Id: I7b63bcb4e5c13b524a5c2e6edb6e061fb17c0f06\n'}, {'number': 2, 'created': '2018-10-31 06:32:11.000000000', 'files': ['freezer_api/storage/elasticv2.py'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/be2ea46de7278bbf96e9d169db59d5ed6f9f2361', 'message': 'register elasticv2 backend options\n\nWe need to register the group and options to CONF in elasticv2 just\nlike in the elastic backend. Otherwise elasticv2 will not work and\nfreezer API will fail.\n\nChange-Id: I7b63bcb4e5c13b524a5c2e6edb6e061fb17c0f06\n'}]",0,614409,be2ea46de7278bbf96e9d169db59d5ed6f9f2361,10,4,2,25562,,,0,"register elasticv2 backend options

We need to register the group and options to CONF in elasticv2 just
like in the elastic backend. Otherwise elasticv2 will not work and
freezer API will fail.

Change-Id: I7b63bcb4e5c13b524a5c2e6edb6e061fb17c0f06
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/09/614409/2 && git format-patch -1 --stdout FETCH_HEAD,['freezer_api/storage/elasticv2.py'],1,21ac0db074e34b8d8b902c196048e7428201406b,register-backend-in-elasticv2," _OPTS = [ cfg.ListOpt('hosts', default=['http://127.0.0.1:9200'], help='specify the storage hosts'), cfg.StrOpt('index', default='freezer', help='specify the name of the elasticsearch index'), cfg.IntOpt('timeout', default=60, help='specify the connection timeout'), cfg.IntOpt('retries', default=20, help='number of retries to allow before raising and error'), cfg.BoolOpt('use_ssl', default=False, help='explicitly turn on SSL'), cfg.BoolOpt('verify_certs', default=False, help='turn on SSL certs verification'), cfg.StrOpt('ca_certs', help='path to CA certs on disk'), cfg.IntOpt('number_of_replicas', default=0, help='Number of replicas for elk cluster. Default is 0. ' 'Use 0 for no replicas. This should be set to (number ' 'of node in the ES cluter -1).') ] CONF.register_opts(self._OPTS, group=backend)",,29,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Iefb47eaf307f942b10de59fd95821e9bdc0b7e19,openstack/tripleo-heat-templates,stable/queens,Iefb47eaf307f942b10de59fd95821e9bdc0b7e19,"Revert ""[Ocata/Pike/Queens] Make rhel-registration scripts location absolute.""",MERGED,2018-12-18 10:57:01.000000000,2019-01-08 07:36:58.000000000,2019-01-04 20:38:03.000000000,"[{'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11166}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-12-18 10:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b843f3846c410970e35f4218f6d63bc28fe8ca5d', 'message': 'Revert ""[Ocata/Pike/Queens] Make rhel-registration scripts location absolute.""\n\nThis reverts commit 91746c290be5fc374ad2389694779a7b57351c81.\nThe patch is causing issues when deploying TripleO using rhel-registration scripts.\n\nChange-Id: Iefb47eaf307f942b10de59fd95821e9bdc0b7e19\nCloses-Bug:#1808965\n'}, {'number': 2, 'created': '2019-01-02 11:35:48.000000000', 'files': ['extraconfig/pre_deploy/rhel-registration/rhel-registration.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1baecc6b5b82df1b822ecda038e52e2c4d6052ab', 'message': 'Revert ""[Ocata/Pike/Queens] Make rhel-registration scripts location absolute.""\n\nThis reverts commit 91746c290be5fc374ad2389694779a7b57351c81.\nThe patch is causing issues when deploying TripleO using rhel-registration scripts.\n\nChange-Id: Iefb47eaf307f942b10de59fd95821e9bdc0b7e19\nCloses-Bug:#1808965\n'}]",0,625877,1baecc6b5b82df1b822ecda038e52e2c4d6052ab,18,9,2,26343,,,0,"Revert ""[Ocata/Pike/Queens] Make rhel-registration scripts location absolute.""

This reverts commit 91746c290be5fc374ad2389694779a7b57351c81.
The patch is causing issues when deploying TripleO using rhel-registration scripts.

Change-Id: Iefb47eaf307f942b10de59fd95821e9bdc0b7e19
Closes-Bug:#1808965
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/77/625877/2 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/pre_deploy/rhel-registration/rhel-registration.yaml'],1,b843f3846c410970e35f4218f6d63bc28fe8ca5d,bug/1797138, config: {get_file: scripts/rhel-registration} config: {get_file: scripts/rhel-unregistration}, config: {get_file: /usr/share/openstack-tripleo-heat-templates/extraconfig/pre_deploy/rhel-registration/scripts/rhel-registration} config: {get_file: /usr/share/openstack-tripleo-heat-templates/extraconfig/pre_deploy/rhel-registration/scripts/rhel-unregistration},2,2
openstack%2Fneutron~master~I1550075fa5fa2aa2f1a88ee7189d311a1fe78391,openstack/neutron,master,I1550075fa5fa2aa2f1a88ee7189d311a1fe78391,remove the neutron.db._resource_extend module,MERGED,2019-01-02 20:02:16.000000000,2019-01-08 07:21:45.000000000,2019-01-08 07:21:44.000000000,"[{'_account_id': 841}, {'_account_id': 5367}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 17120}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-01-02 20:02:16.000000000', 'files': ['neutron/db/l3_gateway_ip_qos.py', 'neutron/db/securitygroups_db.py', 'neutron/services/segments/db.py', 'neutron/db/l3_fip_port_details.py', 'neutron/db/l3_gwmode_db.py', 'neutron/services/segments/plugin.py', 'neutron/db/address_scope_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/portbindings_base.py', 'neutron/db/l3_fip_qos.py', 'neutron/tests/unit/extensions/test_data_plane_status.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/functional/db/test_network.py', 'neutron/db/availability_zone/network.py', 'neutron/db/vlantransparent_db.py', 'neutron/tests/unit/extensions/test_uplink_status_propagation.py', 'neutron/services/qos/qos_plugin.py', 'neutron/services/auto_allocate/db.py', 'neutron/db/allowedaddresspairs_db.py', 'neutron/db/subnet_service_type_mixin.py', 'neutron/db/dns_db.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py', 'neutron/services/tag/tag_plugin.py', 'neutron/db/external_net_db.py', 'neutron/db/l3_attrs_db.py', 'neutron/services/trunk/plugin.py', 'neutron/services/portforwarding/pf_plugin.py', 'neutron/db/db_base_plugin_common.py', 'neutron/db/extradhcpopt_db.py', 'neutron/db/extraroute_db.py', 'neutron/services/revisions/revision_plugin.py', 'neutron/db/portsecurity_db.py', 'neutron/db/standardattrdescription_db.py', 'neutron/services/timestamp/timestamp_db.py', 'neutron/db/availability_zone/router.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/db/_resource_extend.py', 'neutron/db/portbindings_db.py', 'neutron/db/common_db_mixin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/29f56478d1b0f5d9e28caf8096d99729d3f62d60', 'message': 'remove the neutron.db._resource_extend module\n\nThe _resource_extend module is already rehomed into neutron-lib and is\nshimmed in neutron. This patch removes the module as no active\nconsumers are using it.\n\nNeutronLibImpact\n\nChange-Id: I1550075fa5fa2aa2f1a88ee7189d311a1fe78391\n'}]",0,628033,29f56478d1b0f5d9e28caf8096d99729d3f62d60,14,10,1,5367,,,0,"remove the neutron.db._resource_extend module

The _resource_extend module is already rehomed into neutron-lib and is
shimmed in neutron. This patch removes the module as no active
consumers are using it.

NeutronLibImpact

Change-Id: I1550075fa5fa2aa2f1a88ee7189d311a1fe78391
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/628033/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_gateway_ip_qos.py', 'neutron/db/securitygroups_db.py', 'neutron/services/segments/db.py', 'neutron/db/l3_fip_port_details.py', 'neutron/db/l3_gwmode_db.py', 'neutron/services/segments/plugin.py', 'neutron/db/address_scope_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/portbindings_base.py', 'neutron/db/l3_fip_qos.py', 'neutron/tests/unit/extensions/test_data_plane_status.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/functional/db/test_network.py', 'neutron/db/availability_zone/network.py', 'neutron/db/vlantransparent_db.py', 'neutron/tests/unit/extensions/test_uplink_status_propagation.py', 'neutron/services/qos/qos_plugin.py', 'neutron/services/auto_allocate/db.py', 'neutron/db/allowedaddresspairs_db.py', 'neutron/db/subnet_service_type_mixin.py', 'neutron/db/dns_db.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py', 'neutron/services/tag/tag_plugin.py', 'neutron/db/external_net_db.py', 'neutron/db/l3_attrs_db.py', 'neutron/services/trunk/plugin.py', 'neutron/services/portforwarding/pf_plugin.py', 'neutron/db/db_base_plugin_common.py', 'neutron/db/extradhcpopt_db.py', 'neutron/db/extraroute_db.py', 'neutron/services/revisions/revision_plugin.py', 'neutron/db/portsecurity_db.py', 'neutron/db/standardattrdescription_db.py', 'neutron/services/timestamp/timestamp_db.py', 'neutron/db/availability_zone/router.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/db/_resource_extend.py', 'neutron/db/portbindings_db.py', 'neutron/db/common_db_mixin.py']",40,29f56478d1b0f5d9e28caf8096d99729d3f62d60,bp/neutronlib-decouple-db,"from neutron_lib.db import resource_extend resource_extend.register_funcs(resource, funcs)","from neutron.db import _resource_extend _resource_extend.register_funcs(resource, funcs)",41,71
openstack%2Fnetworking-sfc~master~I6e5302291646155f519e67128ab43c38178975be,openstack/networking-sfc,master,I6e5302291646155f519e67128ab43c38178975be,add python 3.6 unit test job,MERGED,2018-08-30 00:05:38.000000000,2019-01-08 07:17:20.000000000,2019-01-08 07:17:20.000000000,"[{'_account_id': 1131}, {'_account_id': 12021}, {'_account_id': 18955}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 25903}, {'_account_id': 27153}, {'_account_id': 28174}]","[{'number': 1, 'created': '2018-08-30 00:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/b9edde87e3f782c8781c424b65fb5f9ee5e1b119', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I6e5302291646155f519e67128ab43c38178975be\nStory: #2002586\nTask: #24314\n'}, {'number': 2, 'created': '2018-11-06 04:04:06.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/259ae375e5d3c69de9d6a9500e7fc5f7a67afef2', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I6e5302291646155f519e67128ab43c38178975be\nStory: #2002586\nTask: #24314\n'}]",0,597879,259ae375e5d3c69de9d6a9500e7fc5f7a67afef2,18,8,2,2472,,,0,"add python 3.6 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.6 as part of the python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I6e5302291646155f519e67128ab43c38178975be
Story: #2002586
Task: #24314
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/79/597879/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,b9edde87e3f782c8781c424b65fb5f9ee5e1b119,python3-first, - openstack-python36-jobs-neutron,,1,0
openstack%2Fproject-config~master~Ic5923f1e519713c4d02c8ab1ec0ff643d505992b,openstack/project-config,master,Ic5923f1e519713c4d02c8ab1ec0ff643d505992b,Normalize projects.yaml,MERGED,2019-01-08 06:03:49.000000000,2019-01-08 07:16:46.000000000,2019-01-08 07:16:46.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 06:03:49.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/51d4e6cc87201ad1a76cdcfa144ebb1678d39d7e', 'message': 'Normalize projects.yaml\n\nChange-Id: Ic5923f1e519713c4d02c8ab1ec0ff643d505992b\n'}]",0,629095,51d4e6cc87201ad1a76cdcfa144ebb1678d39d7e,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: Ic5923f1e519713c4d02c8ab1ec0ff643d505992b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/629095/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,51d4e6cc87201ad1a76cdcfa144ebb1678d39d7e,project-yaml-normalization,, upstream: https://github.com/tellesnobrega/sahara-plugin-ambari upstream: https://github.com/tellesnobrega/sahara-plugin-cdh upstream: https://github.com/tellesnobrega/sahara-plugin-mapr upstream: https://github.com/tellesnobrega/sahara-plugin-spark upstream: https://github.com/tellesnobrega/sahara-plugin-storm upstream: https://github.com/tellesnobrega/sahara-plugin-vanilla,0,6
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ia553a60f57bdcd762dc0b92ebd64b91327261815,openstack/tripleo-heat-templates,stable/rocky,Ia553a60f57bdcd762dc0b92ebd64b91327261815,Move [neutron] auth_url to KeystoneV3Internal,MERGED,2019-01-04 11:23:52.000000000,2019-01-08 07:13:18.000000000,2019-01-08 07:13:18.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-01-04 11:23:52.000000000', 'files': ['puppet/services/nova-base.yaml', 'releasenotes/notes/nova_change_neutron_auth_url_to_internal_endpoint-aaf0e550750335eb.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7e9adc62e874c98736361709748e6f29ed6c890a', 'message': 'Move [neutron] auth_url to KeystoneV3Internal\n\nIn other sections we already use the internal endpoints for\nauthentication urls. With this change the auth_uri in the neutron\nsection gets moved from KeystoneV3Admin to KeystoneV3Internal.\n\nChange-Id: Ia553a60f57bdcd762dc0b92ebd64b91327261815\n(cherry picked from commit 228710fa21749f4d6ac2830cd6bdcd19d841fca7)\n'}]",0,628402,7e9adc62e874c98736361709748e6f29ed6c890a,10,8,1,17216,,,0,"Move [neutron] auth_url to KeystoneV3Internal

In other sections we already use the internal endpoints for
authentication urls. With this change the auth_uri in the neutron
section gets moved from KeystoneV3Admin to KeystoneV3Internal.

Change-Id: Ia553a60f57bdcd762dc0b92ebd64b91327261815
(cherry picked from commit 228710fa21749f4d6ac2830cd6bdcd19d841fca7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/628402/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/nova-base.yaml', 'releasenotes/notes/nova_change_neutron_auth_url_to_internal_endpoint-aaf0e550750335eb.yaml']",2,7e9adc62e874c98736361709748e6f29ed6c890a,auth_url_internal-rocky,--- fixes: - | In other sections we already use the internal endpoints for authentication urls. With this change the auth_uri in the neutron section gets moved from KeystoneV3Admin to KeystoneV3Internal. ,,8,1
openstack%2Ftripleo-heat-templates~master~I3031977a0daabb093cb8f61bcfc22b68e8e35bed,openstack/tripleo-heat-templates,master,I3031977a0daabb093cb8f61bcfc22b68e8e35bed,Add default to network.mtu in j2 in nic configs,MERGED,2019-01-07 21:16:06.000000000,2019-01-08 07:13:17.000000000,2019-01-08 07:13:17.000000000,"[{'_account_id': 17280}, {'_account_id': 18575}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-07 21:16:06.000000000', 'files': ['net-config-noop.j2.yaml', 'net-config-linux-bridge.j2.yaml', 'network/config/single-nic-vlans/controller-no-external.j2.yaml', 'net-config-static-bridge.j2.yaml', 'net-config-standalone.j2.yaml', 'network/config/single-nic-linux-bridge-vlans/role.role.j2.yaml', 'network/config/multiple-nics/controller-v6.j2.yaml', 'network/config/single-nic-vlans/controller-v6.j2.yaml', 'network/config/single-nic-vlans/role.role.j2.yaml', 'net-config-bridge.j2.yaml', 'net-config-static-bridge-with-external-dhcp.j2.yaml', 'net-config-undercloud.j2.yaml', 'network/config/bond-with-vlans/controller-no-external.j2.yaml', 'network/config/bond-with-vlans/controller-v6.j2.yaml', 'network/config/multiple-nics/compute-dvr.j2.yaml', 'net-config-bond.j2.yaml', 'network/config/bond-with-vlans/role.role.j2.yaml', 'network/config/multiple-nics/role.role.j2.yaml', 'network/config/single-nic-linux-bridge-vlans/controller-v6.j2.yaml', 'net-config-static.j2.yaml', 'network/config/2-linux-bonds-vlans/role.role.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cf333d3a07c74353e7f173b1caaefff69a2a59cf', 'message': ""Add default to network.mtu in j2 in nic configs\n\nPreviously all networks was rendered for all roles, and\nthus the default set in network/network.j2#L83 would\npropgate to the nic config for any role. Since we now\nonly include properties for network's in role.networks\nwhen passing parameters puppet/role.role.j2.yaml this\ndefault may not propagate to the nic config and can\ncause problems if merge-new-params-nic-config-script.py\nwas used to add new parameters with a role missmatch.\n\n(i.e Updating the Compute roles NIC config file while\nspecifying the Controller role in  merge-new-params\ntool would add the parameter with no default which\ncauses Property {{network.name}}Mtu not assigned\nerror when deploying.\n\nChange-Id: I3031977a0daabb093cb8f61bcfc22b68e8e35bed\n""}]",0,629048,cf333d3a07c74353e7f173b1caaefff69a2a59cf,9,5,1,24245,,,0,"Add default to network.mtu in j2 in nic configs

Previously all networks was rendered for all roles, and
thus the default set in network/network.j2#L83 would
propgate to the nic config for any role. Since we now
only include properties for network's in role.networks
when passing parameters puppet/role.role.j2.yaml this
default may not propagate to the nic config and can
cause problems if merge-new-params-nic-config-script.py
was used to add new parameters with a role missmatch.

(i.e Updating the Compute roles NIC config file while
specifying the Controller role in  merge-new-params
tool would add the parameter with no default which
causes Property {{network.name}}Mtu not assigned
error when deploying.

Change-Id: I3031977a0daabb093cb8f61bcfc22b68e8e35bed
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/629048/1 && git format-patch -1 --stdout FETCH_HEAD,"['net-config-noop.j2.yaml', 'net-config-linux-bridge.j2.yaml', 'network/config/single-nic-vlans/controller-no-external.j2.yaml', 'net-config-static-bridge.j2.yaml', 'net-config-standalone.j2.yaml', 'network/config/single-nic-linux-bridge-vlans/role.role.j2.yaml', 'network/config/multiple-nics/controller-v6.j2.yaml', 'network/config/single-nic-vlans/controller-v6.j2.yaml', 'network/config/single-nic-vlans/role.role.j2.yaml', 'net-config-bridge.j2.yaml', 'net-config-static-bridge-with-external-dhcp.j2.yaml', 'net-config-undercloud.j2.yaml', 'network/config/bond-with-vlans/controller-no-external.j2.yaml', 'network/config/bond-with-vlans/controller-v6.j2.yaml', 'network/config/multiple-nics/compute-dvr.j2.yaml', 'net-config-bond.j2.yaml', 'network/config/bond-with-vlans/role.role.j2.yaml', 'network/config/multiple-nics/role.role.j2.yaml', 'network/config/single-nic-linux-bridge-vlans/controller-v6.j2.yaml', 'net-config-static.j2.yaml', 'network/config/2-linux-bonds-vlans/role.role.j2.yaml']",21,cf333d3a07c74353e7f173b1caaefff69a2a59cf,set-mtu-default-in-nic-config-templates, default: {{network.mtu|default('1500')}}, default: {{network.mtu}},21,21
openstack%2Fopenstack-helm-infra~master~I3bef7f6323d1de7c62320ccd423c929349bedb42,openstack/openstack-helm-infra,master,I3bef7f6323d1de7c62320ccd423c929349bedb42,[CEPH] OSD directory permission fixes,MERGED,2019-01-07 21:39:36.000000000,2019-01-08 07:07:15.000000000,2019-01-08 07:07:15.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-07 21:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6a404ad182eb7739cf601302143e744eac4863f6', 'message': '[CEPH] OSD directory permission fixes\n\nIn the event the base image is changed, the uid of the ceph OSD\ndirectory may not align with the uid of the ceph user of the image.\nIn this case we check permissions and set them correctly.\n\nChange-Id: I3bef7f6323d1de7c62320ccd423c929349bedb42\n'}, {'number': 2, 'created': '2019-01-08 01:08:17.000000000', 'files': ['ceph-osd/templates/bin/osd/_directory.sh.tpl', 'ceph-osd/templates/bin/osd/_block.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4a85c21996c4771bbebcfbeb3b6a42126370938a', 'message': '[CEPH] OSD directory permission fixes\n\nIn the event the base image is changed, the uid of the ceph OSD\ndirectory may not align with the uid of the ceph user of the image.\nIn this case we check permissions and set them correctly.\n\nChange-Id: I3bef7f6323d1de7c62320ccd423c929349bedb42\n'}]",2,629049,4a85c21996c4771bbebcfbeb3b6a42126370938a,12,5,2,29268,,,0,"[CEPH] OSD directory permission fixes

In the event the base image is changed, the uid of the ceph OSD
directory may not align with the uid of the ceph user of the image.
In this case we check permissions and set them correctly.

Change-Id: I3bef7f6323d1de7c62320ccd423c929349bedb42
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/49/629049/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-osd/templates/bin/osd/_directory.sh.tpl', 'ceph-osd/templates/bin/osd/_block.sh.tpl']",2,6a404ad182eb7739cf601302143e744eac4863f6,mimic_fixes,"# NOTE(supamatt): Just in case permissions do not align up, we recursively set them correctly. if [ $(ls -ld ${OSD_PATH} | awk '{print $3}') != ceph ]; then chown -R ceph. ${OSD_PATH}; fi ",,10,0
openstack%2Ftripleo-heat-templates~master~I5a9dbbee5fde81c3f7ecc41a557f15d54d6e070a,openstack/tripleo-heat-templates,master,I5a9dbbee5fde81c3f7ecc41a557f15d54d6e070a,docker-puppet.py: move entrypoint mount to latest in order,MERGED,2019-01-04 13:42:03.000000000,2019-01-08 06:53:32.000000000,2019-01-08 06:53:32.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 8833}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-01-04 13:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bed1e9e03c33e8a0cf32e979bcc6949b58187a4a', 'message': 'docker-puppet.py: move entrypoint mount to latest in order\n\nPut the entrypoint bind as the last one so to be sure it is accessible.\nSee https://github.com/containers/libpod/issues/1844#issuecomment-451442611\n\nChange-Id: I5a9dbbee5fde81c3f7ecc41a557f15d54d6e070a\n'}, {'number': 2, 'created': '2019-01-04 15:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5d64c30e27baa12b40a687b9ec8fc5691582a21d', 'message': 'docker-puppet.py: move entrypoint mount to latest in order\n\nPut the entrypoint bind as the last one so to be sure it is accessible.\nSee https://github.com/containers/libpod/issues/1844#issuecomment-451442611\n\nChange-Id: I5a9dbbee5fde81c3f7ecc41a557f15d54d6e070a\n'}, {'number': 3, 'created': '2019-01-07 22:01:33.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1d34c98bc031a08e62c2e88e34a6df2068be145', 'message': 'docker-puppet.py: move entrypoint mount to latest in order\n\nPut the entrypoint bind as the last one so to be sure it is accessible.\nSee https://github.com/containers/libpod/issues/1844#issuecomment-451442611\n\nChange-Id: I5a9dbbee5fde81c3f7ecc41a557f15d54d6e070a\n'}]",0,628441,b1d34c98bc031a08e62c2e88e34a6df2068be145,24,8,3,3153,,,0,"docker-puppet.py: move entrypoint mount to latest in order

Put the entrypoint bind as the last one so to be sure it is accessible.
See https://github.com/containers/libpod/issues/1844#issuecomment-451442611

Change-Id: I5a9dbbee5fde81c3f7ecc41a557f15d54d6e070a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/41/628441/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,bed1e9e03c33e8a0cf32e979bcc6949b58187a4a,order," '--volume', '/dev/log:/dev/log:rw'] # script injection as the last mount to make sure it's accessible # https://github.com/containers/libpod/issues/1844 dcmd.extend(['--volume', '%s:%s:ro' % (sh_script, sh_script)] "," '--volume', '/dev/log:/dev/log:rw', # script injection '--volume', '%s:%s:ro' % (sh_script, sh_script) ]",6,3
openstack%2Fopenstack-helm-addons~master~I00be7d51309889fcaf3b2a9756e38dcf49c31312,openstack/openstack-helm-addons,master,I00be7d51309889fcaf3b2a9756e38dcf49c31312,make publishing Sonobuoy results optional,MERGED,2019-01-03 17:34:53.000000000,2019-01-08 06:52:46.000000000,2019-01-08 06:52:46.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 17887}, {'_account_id': 20378}, {'_account_id': 20466}, {'_account_id': 21473}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23625}, {'_account_id': 23899}, {'_account_id': 23928}, {'_account_id': 25907}, {'_account_id': 26365}, {'_account_id': 26449}, {'_account_id': 26815}, {'_account_id': 28701}, {'_account_id': 28718}, {'_account_id': 29441}, {'_account_id': 29585}]","[{'number': 1, 'created': '2019-01-03 17:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/80e9008b379244329e3b95e717c06e4873113799', 'message': 'make publishing Sonobuoy results optional\n\nThis change enables operators to disable results publishing where Swift\nand Ceph may not be setup.\n\nThis configuration option does not prevent deploying other jobs such as\nks-user. The operator will want to disable those via the `manifests`\ndictionary in `values.yaml`.\n\nChange-Id: I00be7d51309889fcaf3b2a9756e38dcf49c31312\n'}, {'number': 2, 'created': '2019-01-03 18:54:12.000000000', 'files': ['sonobuoy/values.yaml', 'sonobuoy/templates/pod-api.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/fa705f1aaa6394505ac9190eba940249fd37fd58', 'message': 'make publishing Sonobuoy results optional\n\nThis change enables operators to disable results publishing where Swift\nand Ceph may not be setup.\n\nThis configuration option does not prevent deploying other resources\nsuch as ks-user. The operator will want to disable those via the\n`manifests` dictionary in `values.yaml`.\n\nChange-Id: I00be7d51309889fcaf3b2a9756e38dcf49c31312\n'}]",2,628231,fa705f1aaa6394505ac9190eba940249fd37fd58,19,20,2,28701,,,0,"make publishing Sonobuoy results optional

This change enables operators to disable results publishing where Swift
and Ceph may not be setup.

This configuration option does not prevent deploying other resources
such as ks-user. The operator will want to disable those via the
`manifests` dictionary in `values.yaml`.

Change-Id: I00be7d51309889fcaf3b2a9756e38dcf49c31312
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/31/628231/1 && git format-patch -1 --stdout FETCH_HEAD,"['sonobuoy/values.yaml', 'sonobuoy/templates/pod-api.yaml']",2,80e9008b379244329e3b95e717c06e4873113799,,{{- if $envAll.Values.conf.publish_results }}{{- end }},,3,0
openstack%2Ftripleo-heat-templates~master~I87e112a0f1973fa3b0e959777e00071c2bbf7c9c,openstack/tripleo-heat-templates,master,I87e112a0f1973fa3b0e959777e00071c2bbf7c9c,flatten sshd service configuration,MERGED,2018-12-18 17:54:06.000000000,2019-01-08 06:50:54.000000000,2019-01-08 06:50:54.000000000,"[{'_account_id': 360}, {'_account_id': 7385}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 27427}]","[{'number': 1, 'created': '2018-12-18 17:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1459b7a59db0e1c37fd0db2b3078bd99bb7a0e6e', 'message': 'flatten sshd service configuration\n\nThis change realigns the sshd baremetal and sshd container puppet\nfiles into a common hierachy as with the rest of this blueprint.\n\nChange-Id: I87e112a0f1973fa3b0e959777e00071c2bbf7c9c\nRelated-Blueprint: services-yaml-flattening\n'}, {'number': 2, 'created': '2018-12-18 18:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d85049a926b2c1ce2e1e85a317c6ddda2ccd958c', 'message': 'flatten sshd service configuration\n\nThis change realigns the sshd baremetal and sshd container puppet\nfiles into a common hierachy as with the rest of this blueprint.\n\nChange-Id: I87e112a0f1973fa3b0e959777e00071c2bbf7c9c\nRelated-Blueprint: services-yaml-flattening\n'}, {'number': 3, 'created': '2018-12-19 17:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5ca37704d644fe798d5ee38f3f9708b386f50fb9', 'message': 'flatten sshd service configuration\n\nThis change realigns the sshd baremetal puppet service yaml config\nfiles into a common hierachy as with the rest of this blueprint.\n\nThis change also removes container functionality, since this was a\ntemporary measure to proxy live-migration connections from\nnon-containerized to containerized compute nodes during upgrade.\n\nChange-Id: I87e112a0f1973fa3b0e959777e00071c2bbf7c9c\nRelated-Blueprint: services-yaml-flattening\n'}, {'number': 4, 'created': '2018-12-19 18:04:17.000000000', 'files': ['overcloud-resource-registry-puppet.j2.yaml', 'deployment/sshd/sshd-baremetal-puppet.yaml', 'environments/baremetal-services.yaml', 'docker/services/nova-migration-target.yaml', 'tools/yaml-validate.py', 'docker/services/sshd.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/67e74a676cdffdc82ae655f110acdf8f94921d03', 'message': 'flatten sshd service configuration\n\nThis change realigns the sshd baremetal puppet service yaml config\nfiles into a common hierachy as with the rest of this blueprint.\n\nThis change also removes container functionality, since this was a\ntemporary measure to proxy live-migration connections from\nnon-containerized to containerized compute nodes during upgrade.\n\nChange-Id: I87e112a0f1973fa3b0e959777e00071c2bbf7c9c\nRelated-Blueprint: services-yaml-flattening\n'}]",2,625979,67e74a676cdffdc82ae655f110acdf8f94921d03,23,8,4,27427,,,0,"flatten sshd service configuration

This change realigns the sshd baremetal puppet service yaml config
files into a common hierachy as with the rest of this blueprint.

This change also removes container functionality, since this was a
temporary measure to proxy live-migration connections from
non-containerized to containerized compute nodes during upgrade.

Change-Id: I87e112a0f1973fa3b0e959777e00071c2bbf7c9c
Related-Blueprint: services-yaml-flattening
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/625979/4 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.j2.yaml', 'deployment/sshd/sshd-baremetal-puppet.yaml', 'deployment/sshd/sshd-container-puppet.yaml', 'environments/baremetal-services.yaml', 'docker/services/nova-migration-target.yaml', 'tools/yaml-validate.py']",6,1459b7a59db0e1c37fd0db2b3078bd99bb7a0e6e,bp/services-yaml-flattening," # ./deployment/sshd/sshd-container-puppet.yaml is a variation of the puppet sshd service './deployment/sshd/sshd-container-puppet.yaml': True, # ./deployment/sshd/sshd-container-puppet.yaml is a variation of the puppet sshd service './deployment/sshd/sshd-container-puppet.yaml': False"," # docker/service/sshd.yaml is a variation of the puppet sshd service './docker/services/sshd.yaml': True, # docker/service/sshd.yaml is a variation of the puppet sshd service './docker/services/sshd.yaml': False,",8,8
openstack%2Ffreezer-dr~master~I62c7b95da8de4e466cd9b4bd48d14af662e4d140,openstack/freezer-dr,master,I62c7b95da8de4e466cd9b4bd48d14af662e4d140,Created VM monitoring and migration plugins,ABANDONED,2017-07-17 14:30:09.000000000,2019-01-08 06:41:56.000000000,,"[{'_account_id': 22348}, {'_account_id': 27068}]","[{'number': 1, 'created': '2017-07-17 14:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/10f57145af5e73069f871108a12bb72422613ef3', 'message': 'Created VM monitoring and migration plugins\n\nChange-Id: I62c7b95da8de4e466cd9b4bd48d14af662e4d140\n'}, {'number': 2, 'created': '2017-07-17 14:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/0166b8084a3206dbe3ebc256f6c04f1c6e54d054', 'message': 'Created VM monitoring and migration plugins\n\nChange-Id: I62c7b95da8de4e466cd9b4bd48d14af662e4d140\n'}, {'number': 3, 'created': '2017-07-17 16:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/9ee07b1a7f37e3e7304d204fac48487be796c543', 'message': 'Created VM monitoring and migration plugins\n\nChange-Id: I62c7b95da8de4e466cd9b4bd48d14af662e4d140\n'}, {'number': 4, 'created': '2018-08-09 08:20:01.000000000', 'files': ['freezer_dr/monitors/common/manager.py', 'requirements.txt', 'freezer_dr/evacuators/common/driver.py', 'freezer_dr/monitors/drivers/vms/driver.py', 'freezer_dr/evacuators/drivers/vm_start/__init__.py', 'freezer_dr/evacuators/drivers/vm_start/driver.py', 'freezer_dr/notifiers/drivers/dummy/dummy.py', 'freezer_dr/monitors/drivers/vms/__init__.py', 'freezer_dr/notifiers/drivers/dummy/__init__.py', 'freezer_dr/common/osclient.py'], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/c478369be72e0d9e34cf53edfc9269778b634da3', 'message': 'Created VM monitoring and migration plugins\n\nChange-Id: I62c7b95da8de4e466cd9b4bd48d14af662e4d140\n'}]",0,484385,c478369be72e0d9e34cf53edfc9269778b634da3,11,2,4,14509,,,0,"Created VM monitoring and migration plugins

Change-Id: I62c7b95da8de4e466cd9b4bd48d14af662e4d140
",git fetch https://review.opendev.org/openstack/freezer-dr refs/changes/85/484385/4 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_dr/monitors/common/manager.py', 'freezer_dr/evacuators/common/driver.py', 'freezer_dr/monitors/drivers/vms/driver.py', 'freezer_dr/evacuators/drivers/vm_start/__init__.py', 'freezer_dr/evacuators/drivers/vm_start/driver.py', 'freezer_dr/notifiers/drivers/dummy/dummy.py', 'freezer_dr/monitors/drivers/vms/__init__.py', 'freezer_dr/notifiers/drivers/dummy/__init__.py', 'freezer_dr/common/osclient.py']",9,10f57145af5e73069f871108a12bb72422613ef3,," def novaservers(self): nova = self.get_novaclient() servers = nova.servers.list() nova_servers = [] for server in servers: nova_servers.append(server.to_dict()) return nova_servers def start_nova_server(self, name=None, id=None): nova = self.get_novaclient() if id: return nova.servers.start(server=id) elif name: server = [server for server in nova.servers.list() if server.name == name] if len(server) != 1: raise(""Couldn't find a unique server to start with"" "" name: {}"".format(name)) return server[0].start() ",,353,0
openstack%2Fopenstack-helm-images~master~Ib2f8043816a24d91716a565cf011c25519bc0a92,openstack/openstack-helm-images,master,Ib2f8043816a24d91716a565cf011c25519bc0a92,Add s3cmd to the ceph-config-helper dockerfile,MERGED,2019-01-04 22:01:05.000000000,2019-01-08 06:21:17.000000000,2019-01-08 06:21:17.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-01-04 22:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/623aeb68bd26614573f8c5d9bd4c5280ef020a22', 'message': 'Add s3cmd to the ceph-config-helper dockerfile\n\nAs a useful tool, s3cmd can be used for for communicating to the\nS3 interface of RGW in lieu of radosgw-admin.\n\nChange-Id: Ib2f8043816a24d91716a565cf011c25519bc0a92\n'}, {'number': 2, 'created': '2019-01-04 22:15:55.000000000', 'files': ['ceph-config-helper/Dockerfile.suse_15', 'ceph-config-helper/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d972557ae59a897a57fef14a588dbd0e6778829c', 'message': 'Add s3cmd to the ceph-config-helper dockerfile\n\nAs a useful tool, s3cmd can be used for for communicating to the\nS3 interface of RGW in lieu of radosgw-admin.\n\nChange-Id: Ib2f8043816a24d91716a565cf011c25519bc0a92\n'}]",0,628690,d972557ae59a897a57fef14a588dbd0e6778829c,10,4,2,29268,,,0,"Add s3cmd to the ceph-config-helper dockerfile

As a useful tool, s3cmd can be used for for communicating to the
S3 interface of RGW in lieu of radosgw-admin.

Change-Id: Ib2f8043816a24d91716a565cf011c25519bc0a92
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/90/628690/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-config-helper/Dockerfile.suse_15', 'ceph-config-helper/Dockerfile.ubuntu_xenial']",2,623aeb68bd26614573f8c5d9bd4c5280ef020a22,config-helper, s3cmd \,,2,0
openstack%2Ffreezer~master~I65ea0d049586364af48ea9ea1ce91f244473b3fc,openstack/freezer,master,I65ea0d049586364af48ea9ea1ce91f244473b3fc,Use template for lower-constraints,MERGED,2018-12-20 19:57:54.000000000,2019-01-08 06:07:29.000000000,2019-01-08 06:07:29.000000000,"[{'_account_id': 6547}, {'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}]","[{'number': 1, 'created': '2018-12-20 19:57:54.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer/commit/7fe7898bd7f806f5f5266ff6e60cdd033fd681b9', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nChange-Id: I65ea0d049586364af48ea9ea1ce91f244473b3fc\nNeeded-By: https://review.openstack.org/623229\n'}]",0,626681,7fe7898bd7f806f5f5266ff6e60cdd033fd681b9,9,4,1,6547,,,0,"Use template for lower-constraints

Small cleanups:

* Use openstack-lower-constraints-jobs template, remove individual
  jobs.
* Sort list of templates

Change-Id: I65ea0d049586364af48ea9ea1ce91f244473b3fc
Needed-By: https://review.openstack.org/623229
",git fetch https://review.opendev.org/openstack/freezer refs/changes/81/626681/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,7fe7898bd7f806f5f5266ff6e60cdd033fd681b9,cd/py36-lower-constraints, - check-requirements - openstack-lower-constraints-jobs, - check-requirements - openstack-tox-lower-constraints - openstack-tox-lower-constraints,2,3
openstack%2Fsolum-tempest-plugin~master~I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6,openstack/solum-tempest-plugin,master,I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6,Add to tempest plugin,MERGED,2019-01-07 10:27:35.000000000,2019-01-08 05:43:54.000000000,2019-01-08 05:43:54.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 10:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-tempest-plugin/commit/ac771af2d6267fd00312c5b0df88bee43ec35ee3', 'message': 'Add to tempest plugin\n\nChange-Id: I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6\n'}, {'number': 2, 'created': '2019-01-07 11:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-tempest-plugin/commit/9fb0ea32652916f9791d11e90b6f2887bba4de11', 'message': 'Add to tempest plugin\n\nChange-Id: I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6\n'}, {'number': 3, 'created': '2019-01-07 11:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-tempest-plugin/commit/8660cad0e3479c8b0561a62d0e636742f75c1e10', 'message': 'Add to tempest plugin\n\nChange-Id: I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6\n'}, {'number': 4, 'created': '2019-01-08 00:50:57.000000000', 'files': ['solum_tempest_plugin/tests/application_deployment/v1/test_root.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/test_plans.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_assembly.py', 'solum_tempest_plugin/tests/application_deployment/v1/__init__.py', 'solum_tempest_plugin/tests/application_deployment/camp/test_platform_endpoints.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_language_pack.py', 'solum_tempest_plugin/tests/application_deployment/test_versions.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/test_parameter_definitions.py', 'solum_tempest_plugin/config.py', 'solum_tempest_plugin/tests/__init__.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/test_type_definitions.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_service.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/__init__.py', 'solum_tempest_plugin/plugin.py', 'solum_tempest_plugin/tests/application_deployment/test_release.py', 'solum_tempest_plugin/tests/application_deployment/__init__.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/test_platform.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_app.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_sensor.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/test_formats.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_plan.py', 'solum_tempest_plugin/tests/application_deployment/camp/v1_1/test_assemblies.py', 'solum_tempest_plugin/tests/application_deployment/v1/public/test_trigger.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_operation.py', 'solum_tempest_plugin/tests/application_deployment/camp/__init__.py', 'solum_tempest_plugin/tests/application_deployment/v1/test_component.py', 'solum_tempest_plugin/tests/application_deployment/v1/public/__init__.py', 'setup.cfg', 'solum_tempest_plugin/tests/application_deployment/v1/test_extension.py'], 'web_link': 'https://opendev.org/openstack/solum-tempest-plugin/commit/7dd9df92658ad130a3b60825d28e54d7bc3bebe0', 'message': 'Add to tempest plugin\n\nChange-Id: I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6\n'}]",0,628929,7dd9df92658ad130a3b60825d28e54d7bc3bebe0,12,2,4,14107,,,0,"Add to tempest plugin

Change-Id: I6b41d57bf17d3bf7c815bc83370bc27e8987ccb6
",git fetch https://review.opendev.org/openstack/solum-tempest-plugin refs/changes/29/628929/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum_tempest_plugin/tests/v1/test_language_pack.py', 'solum_tempest_plugin/tests/camp/v1_1/test_formats.py', 'solum_tempest_plugin/tests/v1/test_service.py', 'solum_tempest_plugin/tests/v1/__init__.py', 'solum_tempest_plugin/config.py', 'solum_tempest_plugin/tests/__init__.py', 'solum_tempest_plugin/tests/v1/test_component.py', 'solum_tempest_plugin/tests/v1/test_operation.py', 'solum_tempest_plugin/tests/camp/v1_1/__init__.py', 'solum_tempest_plugin/tests/v1/test_extension.py', 'solum_tempest_plugin/tests/camp/v1_1/test_plans.py', 'solum_tempest_plugin/tests/camp/v1_1/test_parameter_definitions.py', 'solum_tempest_plugin/plugin.py', 'solum_tempest_plugin/tests/camp/test_platform_endpoints.py', 'solum_tempest_plugin/tests/v1/test_plan.py', 'solum_tempest_plugin/tests/test_versions.py', 'solum_tempest_plugin/tests/common/apputils.py', 'solum_tempest_plugin/tests/v1/test_root.py', 'solum_tempest_plugin/tests/camp/v1_1/test_type_definitions.py', 'solum_tempest_plugin/tests/camp/v1_1/test_assemblies.py', 'solum_tempest_plugin/tests/camp/v1_1/test_platform.py', 'solum_tempest_plugin/tests/test_release.py', 'solum_tempest_plugin/tests/camp/__init__.py', 'solum_tempest_plugin/tests/v1/test_app.py', 'solum_tempest_plugin/tests/v1/test_sensor.py', 'solum_tempest_plugin/tests/v1/public/__init__.py', 'solum_tempest_plugin/tests/common/__init__.py', 'solum_tempest_plugin/tests/v1/test_assembly.py', 'setup.cfg', 'solum_tempest_plugin/tests/v1/public/test_trigger.py']",30,ac771af2d6267fd00312c5b0df88bee43ec35ee3,,,,59,0
openstack%2Ffreezer-api~master~Ia1851f2e162c7bf024349c17629cbaf70ea925cd,openstack/freezer-api,master,Ia1851f2e162c7bf024349c17629cbaf70ea925cd,Drop astroid requirement,MERGED,2019-01-04 10:37:54.000000000,2019-01-08 05:42:05.000000000,2019-01-08 05:42:04.000000000,"[{'_account_id': 11151}, {'_account_id': 13940}, {'_account_id': 14101}, {'_account_id': 14340}, {'_account_id': 14509}, {'_account_id': 16768}, {'_account_id': 21069}, {'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22405}, {'_account_id': 22484}, {'_account_id': 27068}]","[{'number': 1, 'created': '2019-01-04 10:37:54.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/6d37fa99405b60a27c1fa8b7177e253b48d16d82', 'message': 'Drop astroid requirement\n\nIt is not needed.\n\nChange-Id: Ia1851f2e162c7bf024349c17629cbaf70ea925cd\n'}]",0,628394,6d37fa99405b60a27c1fa8b7177e253b48d16d82,8,12,1,7102,,,0,"Drop astroid requirement

It is not needed.

Change-Id: Ia1851f2e162c7bf024349c17629cbaf70ea925cd
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/94/628394/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt']",2,6d37fa99405b60a27c1fa8b7177e253b48d16d82,,,astroid==1.3.8,0,2
openstack%2Fsenlin~master~I65449cabc1af1a401443dad7c56c49c59367ba50,openstack/senlin,master,I65449cabc1af1a401443dad7c56c49c59367ba50,"Fix the misspelling of ""except""",MERGED,2019-01-04 08:57:52.000000000,2019-01-08 05:38:16.000000000,2019-01-08 05:38:16.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 22998}, {'_account_id': 25553}]","[{'number': 1, 'created': '2019-01-04 08:57:52.000000000', 'files': ['senlin/tests/unit/api/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/125e403321923a727dfb5e9bc2d92aae7635cc16', 'message': 'Fix the misspelling of ""except""\n\nChange-Id: I65449cabc1af1a401443dad7c56c49c59367ba50\n'}]",0,628361,125e403321923a727dfb5e9bc2d92aae7635cc16,8,4,1,29721,,,0,"Fix the misspelling of ""except""

Change-Id: I65449cabc1af1a401443dad7c56c49c59367ba50
",git fetch https://review.opendev.org/openstack/senlin refs/changes/61/628361/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/unit/api/common/test_wsgi.py'],1,125e403321923a727dfb5e9bc2d92aae7635cc16,," def __init__(self, exception_to_raise): self.exception_to_raise = exception_to_raise raise self.exception_to_raise()"," def __init__(self, excpetion_to_raise): self.excpetion_to_raise = excpetion_to_raise raise self.excpetion_to_raise()",3,3
openstack%2Fcinder~master~I72354ace0de850e162c5ce804503a62f7161c07f,openstack/cinder,master,I72354ace0de850e162c5ce804503a62f7161c07f,VMAX Driver - Failover Unisphere Support,MERGED,2018-05-24 14:09:25.000000000,2019-01-08 05:37:43.000000000,2019-01-08 05:37:43.000000000,"[{'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12670}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13628}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25677}, {'_account_id': 25678}, {'_account_id': 25805}, {'_account_id': 26077}, {'_account_id': 26402}, {'_account_id': 26537}, {'_account_id': 26561}, {'_account_id': 28801}, {'_account_id': 29705}]","[{'number': 1, 'created': '2018-05-24 14:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/14fce0af79e0ba59c71eded52136b6b7fe0fcb4a', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 2, 'created': '2018-05-24 15:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ee2a220dc701d781ea3a6aa961cd8b26c00fbc73', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 3, 'created': '2018-05-28 15:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/11b2b27b07d6598c0a4d1bb999628c649f1f94e0', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 4, 'created': '2018-05-29 14:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/faaff93b98e187d4b8be7000c2200d942bdc5f9c', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 5, 'created': '2018-06-12 13:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6b39e035b5b34fb069aa82f84d385242cab7fc8', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 6, 'created': '2018-06-13 13:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/994dc04c6088452d55d758248fc14fbaf784abe2', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 7, 'created': '2018-10-03 11:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2464f36b06de014fa37bee94b646dfe87993975d', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 8, 'created': '2018-11-25 21:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/edc8876be48df58b18ce2960bc5b4a2d395ebf94', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 9, 'created': '2018-11-29 11:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03ce1a30dbe2bede098733dcdd485e18ed070edb', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 10, 'created': '2018-11-29 16:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3cbd64b1f01118d33fcff00dea294dc971c905b8', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 11, 'created': '2018-12-04 16:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b317dc77451a2da0fce54ea754dc343ea239dfd', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 12, 'created': '2018-12-07 15:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f0d159e7c138063d686918ff181d0152ba0afb32', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 13, 'created': '2018-12-11 10:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6c1f180da4280da0710d35d25de60d5e4a1cbcb9', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 14, 'created': '2018-12-19 11:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/690983bae3ebf2705ed54e7fecea8028a005267f', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 15, 'created': '2018-12-19 15:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b34e004928555a7a980be1e3aebe0c284c9340e7', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 16, 'created': '2018-12-21 14:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc00574e7e083d4604c769da2630ded2774a7d57', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}, {'number': 17, 'created': '2018-12-21 15:16:31.000000000', 'files': ['cinder/volume/drivers/dell_emc/vmax/fc.py', 'cinder/volume/drivers/dell_emc/vmax/rest.py', 'cinder/tests/unit/volume/drivers/dell_emc/vmax/test_vmax.py', 'cinder/volume/drivers/dell_emc/vmax/iscsi.py', 'cinder/volume/drivers/dell_emc/vmax/common.py', 'releasenotes/notes/vmax-failover-unisphere-2de78d1f76b5f836.yaml', 'cinder/volume/drivers/dell_emc/vmax/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/44aea00c70788cff034fa18d5e119b17923a657e', 'message': 'VMAX Driver - Failover Unisphere Support\n\nVMAX support for failing over to backup instances of Unisphere.\n\nChange-Id: I72354ace0de850e162c5ce804503a62f7161c07f\nImplements: blueprint vmax-unisphere-failover\n'}]",8,570401,44aea00c70788cff034fa18d5e119b17923a657e,462,57,17,23601,,,0,"VMAX Driver - Failover Unisphere Support

VMAX support for failing over to backup instances of Unisphere.

Change-Id: I72354ace0de850e162c5ce804503a62f7161c07f
Implements: blueprint vmax-unisphere-failover
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/570401/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/vmax/fc.py', 'cinder/volume/drivers/dell_emc/vmax/rest.py', 'cinder/tests/unit/volume/drivers/dell_emc/vmax/test_vmax.py', 'cinder/volume/drivers/dell_emc/vmax/common.py', 'cinder/volume/drivers/dell_emc/vmax/iscsi.py', 'cinder/volume/drivers/dell_emc/vmax/utils.py', 'releasenotes/notes/vmax-failover-unisphere-2de78d1f76b5f836.yaml']",7,14fce0af79e0ba59c71eded52136b6b7fe0fcb4a,bp/vmax-unisphere-failover,--- features: - Dell EMC VMAX driver has added support for failover to second instance of Unisphere. ,,393,36
openstack%2Fcinder~master~Ic011fe30b4840e5098db1a594ea276ec98768bff,openstack/cinder,master,Ic011fe30b4840e5098db1a594ea276ec98768bff,cinder-volume: Stop masking IOError different than ENOSPC,MERGED,2018-10-22 13:39:45.000000000,2019-01-08 05:31:07.000000000,2019-01-08 02:47:09.000000000,"[{'_account_id': 4128}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 20722}, {'_account_id': 20813}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 22510}, {'_account_id': 23561}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26458}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}]","[{'number': 1, 'created': '2018-10-22 13:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe7d677ab1f07fb7c0153fcb0cde649e35ad3190', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a GlanceConnectionFailed exception is raised in this case,\nwhich makes the volume creation process fail.\n\nFixes #1799221.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\n'}, {'number': 2, 'created': '2018-10-22 13:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/69dfe031928b8726f6757ec8ac71bebb83eb5140', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a GlanceConnectionFailed exception is raised in this case,\nwhich makes the volume creation process fail.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 3, 'created': '2018-10-23 06:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/18853148256984d559bae35d7c5a8c3705fe6c36', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a GlanceConnectionFailed exception is raised in this case,\nwhich makes the volume creation process fail.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 4, 'created': '2018-10-23 06:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3951c0a8d9e5be66d3aa6a8ee6d058203b896a8b', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a GlanceConnectionFailed exception is raised in this case,\nwhich makes the volume creation process fail.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 5, 'created': '2018-10-23 06:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d9f6912066d93f34610441fb319566888ce3e8a', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a GlanceConnectionFailed exception is raised in this case,\nwhich makes the volume creation process fail.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 6, 'created': '2018-10-23 08:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9316519fbcff89ec0f1513202a9952fe66c33695', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 7, 'created': '2018-10-23 08:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d9a9503e87d909e05696304ba0872af36e12140', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 8, 'created': '2018-10-25 08:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fd5c4ae016937e7de07746682a8b08f512371fa6', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 9, 'created': '2018-10-25 09:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9b37b3138094aff0efb0e2c1d8ff2e012c989a71', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 10, 'created': '2018-10-25 14:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f936c0f8888cb11330ca8c01076544231bfc8c76', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 11, 'created': '2018-12-10 08:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1c679211d3333b61ad17b212a9de07d4990081d2', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 12, 'created': '2018-12-13 14:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/216503d826c8717d5db0bb611ff60136a80cad5a', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation process.\nThe result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in this\ncase, which makes the volume creation process fail and gives enough information\nto operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 13, 'created': '2018-12-13 14:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e7c580eee9cac085db7306e8fd65948caba60f45', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was truncated volumes being successfuly created.\n\nWith the patch, a new exception named ImageDownloadFailed is raised in\nthis case, which makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 14, 'created': '2018-12-13 14:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2de3294253e2b451114acde3e5c861c47e16e72d', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was truncated volumes being successfuly created.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 15, 'created': '2018-12-14 09:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2072c987fb358a5c336d7653e37c7c99b2ecc50c', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was truncated volumes being successfuly created.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 16, 'created': '2018-12-14 15:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/df0ef8ff7adf9822fa4c26d9a602cdfd3a9fdc16', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was truncated volumes being successfuly created.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 17, 'created': '2018-12-17 20:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7cbfd4e3ee43e9f95f23afa6e73b48d4e8f33128', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was volumes with invalid content being successfuly\ncreated.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 18, 'created': '2018-12-18 08:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cb46e2f5ea7e24547d0f535cc85f448e0d5a8b19', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was volumes with invalid content being successfuly\ncreated.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 19, 'created': '2018-12-21 14:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/df0e80bcb14ed72826973c74e07faf5446fe7a5c', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was volumes with invalid content being successfuly\ncreated.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 20, 'created': '2018-12-22 20:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f86bfca4b3a14db2420a3de6377c9b77612c32cf', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was volumes with invalid content being successfuly\ncreated.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}, {'number': 21, 'created': '2019-01-04 18:09:46.000000000', 'files': ['releasenotes/notes/bug-1799221-fix-truncated-volumes-in-case-of-glance-errors-6cae19218249c3cf.yaml', 'cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/864c074ff15db601c896dadc2842ae703861c0dd', 'message': 'cinder-volume: Stop masking IOError different than ENOSPC\n\nWhen glanceclient raises an IOError with a different errno than ENOSPC,\ncinder-volume silently masked it and continued its volume creation\nprocess. The result was volumes with invalid content being successfuly\ncreated.\n\nWith the patch, an ImageDownloadFailed exception is raised in this case,\nwhich makes the volume creation process fail and gives enough\ninformation to operators for troubleshooting.\n\nChange-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff\nCloses-Bug: #1799221\n'}]",29,612393,864c074ff15db601c896dadc2842ae703861c0dd,389,53,21,4128,,,0,"cinder-volume: Stop masking IOError different than ENOSPC

When glanceclient raises an IOError with a different errno than ENOSPC,
cinder-volume silently masked it and continued its volume creation
process. The result was volumes with invalid content being successfuly
created.

With the patch, an ImageDownloadFailed exception is raised in this case,
which makes the volume creation process fail and gives enough
information to operators for troubleshooting.

Change-Id: Ic011fe30b4840e5098db1a594ea276ec98768bff
Closes-Bug: #1799221
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/612393/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py']",2,fe7d677ab1f07fb7c0153fcb0cde649e35ad3190,bug/1799221," def test_fetch_ioerror(self): context = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id e = IOError() e.errno = errno.ECONNRESET image_service.download.side_effect = e path = '/test_path' _user_id = mock.sentinel._user_id _project_id = mock.sentinel._project_id with mock.patch('cinder.image.image_utils.open', new=mock.mock_open(), create=True): self.assertRaises(exception.GlanceConnectionFailed, image_utils.fetch, context, image_service, image_id, path, _user_id, _project_id) ",,20,0
openstack%2Fnetworking-midonet~master~Ibb419281af0d0503a1c00b01f5456d049895e62f,openstack/networking-midonet,master,Ibb419281af0d0503a1c00b01f5456d049895e62f,use neutron-lib for common exception,MERGED,2019-01-02 16:38:31.000000000,2019-01-08 05:17:14.000000000,2019-01-08 05:17:02.000000000,"[{'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 9925}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 16:38:31.000000000', 'files': ['midonet/neutron/common/utils.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/bcf334ba070c6e08bc735be9807a385d5bde66c2', 'message': ""use neutron-lib for common exception\n\nThis patch switches the code over to use neutron-lib's common exceptions\nrather than neutrons.\n\nChange-Id: Ibb419281af0d0503a1c00b01f5456d049895e62f\n""}]",0,628002,bcf334ba070c6e08bc735be9807a385d5bde66c2,8,4,1,5367,,,0,"use neutron-lib for common exception

This patch switches the code over to use neutron-lib's common exceptions
rather than neutrons.

Change-Id: Ibb419281af0d0503a1c00b01f5456d049895e62f
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/02/628002/1 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/common/utils.py'],1,bcf334ba070c6e08bc735be9807a385d5bde66c2,use-lib-rpc,from neutron_lib import exceptions as n_exc, from neutron.common import exceptions as n_exc,1,2
openstack%2Fdiskimage-builder~master~I7db3f2a1ed4e0460db60635ab00367050b0300a5,openstack/diskimage-builder,master,I7db3f2a1ed4e0460db60635ab00367050b0300a5,source-repositories: Replace documentation http with https links,MERGED,2018-11-23 10:03:33.000000000,2019-01-08 05:16:18.000000000,2019-01-08 05:16:18.000000000,"[{'_account_id': 6133}, {'_account_id': 7118}, {'_account_id': 22348}, {'_account_id': 25747}, {'_account_id': 26776}, {'_account_id': 29222}, {'_account_id': 29558}]","[{'number': 1, 'created': '2018-11-23 10:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/39341964c0602848025a6915bf59fc85a4d73029', 'message': 'fix links\n\nChange-Id: I7db3f2a1ed4e0460db60635ab00367050b0300a5\n'}, {'number': 2, 'created': '2019-01-08 04:50:27.000000000', 'files': ['diskimage_builder/elements/source-repositories/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/079a104c1ad7e49e92e2274aa23c68f06d630958', 'message': 'source-repositories: Replace documentation http with https links\n\nChange-Id: I7db3f2a1ed4e0460db60635ab00367050b0300a5\n'}]",0,619699,079a104c1ad7e49e92e2274aa23c68f06d630958,13,7,2,27549,,,0,"source-repositories: Replace documentation http with https links

Change-Id: I7db3f2a1ed4e0460db60635ab00367050b0300a5
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/99/619699/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/source-repositories/README.rst'],1,39341964c0602848025a6915bf59fc85a4d73029,619699,set to https://git.openstack.org/openstack/nova.git will result in use of the,set to http://git.openstack.org/openstack/nova.git will result in use of the,1,1
openstack%2Fglance~master~I1cb39a1ec1b2927d123b63c7b9df29499565e168,openstack/glance,master,I1cb39a1ec1b2927d123b63c7b9df29499565e168,Add missing ws seperator between words,MERGED,2018-11-19 05:41:27.000000000,2019-01-08 04:44:41.000000000,2019-01-08 04:44:41.000000000,"[{'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 18791}, {'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-19 05:41:27.000000000', 'files': ['glance/common/wsgi.py', 'glance/notifier.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/daf393f8fe40b52edf17c73ec57c9a6c409ed1bc', 'message': 'Add missing ws seperator between words\n\nThis is to add missing ws seperator between words, usually\nin log messages.\n\nChange-Id: I1cb39a1ec1b2927d123b63c7b9df29499565e168\n'}]",0,618675,daf393f8fe40b52edf17c73ec57c9a6c409ed1bc,14,9,1,20190,,,0,"Add missing ws seperator between words

This is to add missing ws seperator between words, usually
in log messages.

Change-Id: I1cb39a1ec1b2927d123b63c7b9df29499565e168
",git fetch https://review.opendev.org/openstack/glance refs/changes/75/618675/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/common/wsgi.py', 'glance/notifier.py']",2,daf393f8fe40b52edf17c73ec57c9a6c409ed1bc,missing_ws," msg = (_(""Unable to upload duplicate image data for image """," msg = (_(""Unable to upload duplicate image data for image""",2,2
openstack%2Fnova~master~I2d3ed7911ac4033541692dbccbacbd3ad6f097e2,openstack/nova,master,I2d3ed7911ac4033541692dbccbacbd3ad6f097e2,Change to debug repetitive info messages,MERGED,2019-01-02 22:31:46.000000000,2019-01-08 04:44:37.000000000,2019-01-08 04:44:37.000000000,"[{'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-02 22:31:46.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e542e512a95382b7a8eba631eb0e67ca49176971', 'message': 'Change to debug repetitive info messages\n\nThe log level of ""Final resource view"" and ""Libvirt baseline CPU""\nmessages was changed to debug.\n\nChange-Id: I2d3ed7911ac4033541692dbccbacbd3ad6f097e2\nCloses-Bug: #1810340\n'}]",1,628058,e542e512a95382b7a8eba631eb0e67ca49176971,52,17,1,2033,,,0,"Change to debug repetitive info messages

The log level of ""Final resource view"" and ""Libvirt baseline CPU""
messages was changed to debug.

Change-Id: I2d3ed7911ac4033541692dbccbacbd3ad6f097e2
Closes-Bug: #1810340
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/628058/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/compute/resource_tracker.py']",2,e542e512a95382b7a8eba631eb0e67ca49176971,bug/1810340," LOG.debug(""Final resource view: "" ""name=%(node)s "" ""phys_ram=%(phys_ram)sMB "" ""used_ram=%(used_ram)sMB "" ""phys_disk=%(phys_disk)sGB "" ""used_disk=%(used_disk)sGB "" ""total_vcpus=%(total_vcpus)s "" ""used_vcpus=%(used_vcpus)s "" ""pci_stats=%(pci_stats)s"", {'node': nodename, 'phys_ram': cn.memory_mb, 'used_ram': cn.memory_mb_used, 'phys_disk': cn.local_gb, 'used_disk': cn.local_gb_used, 'total_vcpus': tcpu, 'used_vcpus': ucpu, 'pci_stats': pci_stats})"," LOG.info(""Final resource view: "" ""name=%(node)s "" ""phys_ram=%(phys_ram)sMB "" ""used_ram=%(used_ram)sMB "" ""phys_disk=%(phys_disk)sGB "" ""used_disk=%(used_disk)sGB "" ""total_vcpus=%(total_vcpus)s "" ""used_vcpus=%(used_vcpus)s "" ""pci_stats=%(pci_stats)s"", {'node': nodename, 'phys_ram': cn.memory_mb, 'used_ram': cn.memory_mb_used, 'phys_disk': cn.local_gb, 'used_disk': cn.local_gb_used, 'total_vcpus': tcpu, 'used_vcpus': ucpu, 'pci_stats': pci_stats})",18,18
openstack%2Fneutron-vpnaas~master~Ie0d1293d9352b29627801ed6103aa1e9ce8915dd,openstack/neutron-vpnaas,master,Ie0d1293d9352b29627801ed6103aa1e9ce8915dd,doc: Add policy reference,MERGED,2018-12-16 11:32:43.000000000,2019-01-08 04:39:01.000000000,2019-01-08 04:39:01.000000000,"[{'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 8871}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-16 11:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/4ebbd783eb735c93640e715581f51d2b550655f8', 'message': 'doc: Add policy reference\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ie0d1293d9352b29627801ed6103aa1e9ce8915dd\n'}, {'number': 2, 'created': '2018-12-16 13:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/31b04035ce881dfcb48db2117d9ce7b60cf12f5f', 'message': 'doc: Add policy reference\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ie0d1293d9352b29627801ed6103aa1e9ce8915dd\n'}, {'number': 3, 'created': '2018-12-16 20:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/dd7ba5981f638927e9d464ad00c596d0022d95b2', 'message': 'doc: Add policy reference\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ie0d1293d9352b29627801ed6103aa1e9ce8915dd\n'}, {'number': 4, 'created': '2018-12-20 05:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/02deeb13e556a5da8a72ddfafa46e61d715d7e0a', 'message': 'doc: Add policy reference\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ie0d1293d9352b29627801ed6103aa1e9ce8915dd\n'}, {'number': 5, 'created': '2019-01-07 16:38:45.000000000', 'files': ['doc/source/configuration/index.rst', '.gitignore', 'doc/source/configuration/policy-sample.rst', 'doc/source/conf.py', 'doc/source/configuration/policy.rst'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/c561e8940a64926d95e4386b195db83bcbc4b45f', 'message': 'doc: Add policy reference\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ie0d1293d9352b29627801ed6103aa1e9ce8915dd\n'}]",0,625424,c561e8940a64926d95e4386b195db83bcbc4b45f,20,5,5,841,,,0,"doc: Add policy reference

Partially Implements: blueprint neutron-policy-in-code

Change-Id: Ie0d1293d9352b29627801ed6103aa1e9ce8915dd
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/24/625424/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration/index.rst', '.gitignore', 'doc/source/configuration/policy-sample.rst', 'doc/source/conf.py', 'doc/source/configuration/policy.rst']",5,4ebbd783eb735c93640e715581f51d2b550655f8,bp/neutron-policy-in-code,"======================= neutron-vpnaas policies ======================= The following is an overview of all available policies in neutron-vpnaas. For a sample configuration file, refer to :doc:`/configuration/policy-sample`. .. show-policy:: :config-file: etc/oslo-policy-generator/policy.conf ",,56,14
openstack%2Fneutron-vpnaas~master~Ic0bf99b69a792197399e38ace6d23ea18874892a,openstack/neutron-vpnaas,master,Ic0bf99b69a792197399e38ace6d23ea18874892a,Convert policy.json into policy-in-code,MERGED,2018-12-16 11:20:45.000000000,2019-01-08 04:39:01.000000000,2019-01-08 04:39:00.000000000,"[{'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-16 11:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/4a02fd4a0bdf13c3667b552c797474c3db0fcd32', 'message': 'Convert policy.json into policy-in-code\n\nThis commit defines the default policies in code. VPNaaS has\nno policy.json so far, so all policy definitions are newly created.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ic0bf99b69a792197399e38ace6d23ea18874892a\n'}, {'number': 2, 'created': '2018-12-16 13:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/a0bc55acdc9670c74823968d8ab8a8e45a758515', 'message': 'Convert policy.json into policy-in-code\n\nThis commit defines the default policies in code. VPNaaS has\nno policy.json so far, so all policy definitions are newly created.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ic0bf99b69a792197399e38ace6d23ea18874892a\n'}, {'number': 3, 'created': '2018-12-16 20:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/85c25677a738b7e0fbc90031fba4b848b21fad28', 'message': 'Convert policy.json into policy-in-code\n\nThis commit defines the default policies in code. VPNaaS has\nno policy.json so far, so all policy definitions are newly created.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ic0bf99b69a792197399e38ace6d23ea18874892a\n'}, {'number': 4, 'created': '2019-01-07 16:38:16.000000000', 'files': ['neutron_vpnaas/policies/ike_policy.py', 'neutron_vpnaas/policies/vpnservice.py', 'neutron_vpnaas/policies/ipsec_site_connection.py', 'neutron_vpnaas/policies/base.py', 'etc/oslo-policy-generator/policy.conf', 'neutron_vpnaas/policies/ipsec_policy.py', 'setup.cfg', 'neutron_vpnaas/policies/endpoint_group.py', 'tox.ini', 'neutron_vpnaas/policies/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b0c4a6aefbf206a8e8ecb5abccdacf89d1de4237', 'message': 'Convert policy.json into policy-in-code\n\nThis commit defines the default policies in code. VPNaaS has\nno policy.json so far, so all policy definitions are newly created.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: Ic0bf99b69a792197399e38ace6d23ea18874892a\n'}]",1,625423,b0c4a6aefbf206a8e8ecb5abccdacf89d1de4237,20,4,4,841,,,0,"Convert policy.json into policy-in-code

This commit defines the default policies in code. VPNaaS has
no policy.json so far, so all policy definitions are newly created.

Partially Implements: blueprint neutron-policy-in-code

Change-Id: Ic0bf99b69a792197399e38ace6d23ea18874892a
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/23/625423/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/policies/ike_policy.py', 'neutron_vpnaas/policies/ipsec_site_connection.py', 'neutron_vpnaas/policies/vpnservice.py', 'neutron_vpnaas/policies/base.py', 'etc/oslo-policy-generator/policy.conf', 'neutron_vpnaas/policies/ipsec_policy.py', 'setup.cfg', 'neutron_vpnaas/policies/endpoint_group.py', 'tox.ini', 'neutron_vpnaas/policies/__init__.py']",10,4a02fd4a0bdf13c3667b552c797474c3db0fcd32,bp/neutron-policy-in-code,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import itertools from neutron_vpnaas.policies import endpoint_group from neutron_vpnaas.policies import ike_policy from neutron_vpnaas.policies import ipsec_policy from neutron_vpnaas.policies import ipsec_site_connection from neutron_vpnaas.policies import vpnservice def list_rules(): return itertools.chain( endpoint_group.list_rules(), ike_policy.list_rules(), ipsec_policy.list_rules(), ipsec_site_connection.list_rules(), vpnservice.list_rules(), ) ",,412,0
openstack%2Fmonasca-api~stable%2Frocky~I94e853f869db7b0a434a1a05517255ae62131132,openstack/monasca-api,stable/rocky,I94e853f869db7b0a434a1a05517255ae62131132,Support standard config file path for monasca-api,ABANDONED,2019-01-07 13:01:04.000000000,2019-01-08 04:36:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-07 13:01:04.000000000', 'files': ['releasenotes/notes/use-standard-config-file-path-a4c1a29d9d3fcc07.yaml', 'monasca_api/config.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/d709bd8bc7c63be256108a77ef19836b5c7d4d39', 'message': 'Support standard config file path for monasca-api\n\nThe standard path is /etc/monasca/monasca-api.conf (instead of\n/etc/monasca/api.conf).\n\n/etc/monasca/api.conf and /etc/monasca/api-config.conf are still\nsupported but a deprectation message is printed.\n\nChange-Id: I94e853f869db7b0a434a1a05517255ae62131132\nStory: 2004708\nTask:  28738\n(cherry picked from commit 265c6043c517fbf0ce1b57926ec64fc6f85f346c)\n'}]",0,628951,d709bd8bc7c63be256108a77ef19836b5c7d4d39,3,1,1,7102,,,0,"Support standard config file path for monasca-api

The standard path is /etc/monasca/monasca-api.conf (instead of
/etc/monasca/api.conf).

/etc/monasca/api.conf and /etc/monasca/api-config.conf are still
supported but a deprectation message is printed.

Change-Id: I94e853f869db7b0a434a1a05517255ae62131132
Story: 2004708
Task:  28738
(cherry picked from commit 265c6043c517fbf0ce1b57926ec64fc6f85f346c)
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/51/628951/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/use-standard-config-file-path-a4c1a29d9d3fcc07.yaml', 'monasca_api/config.py']",2,d709bd8bc7c63be256108a77ef19836b5c7d4d39,stable-rocky,"def parse_args(argv=None): prog=sys.argv[1:], default_config_files=_get_config_files(),def _get_config_files(): """"""Get the possible configuration files accepted by oslo.config This also includes the deprecated ones # default files conf_files = cfg.find_config_files(project='monasca', prog='monasca-api') # deprecated config files for prog_name in ['api', 'api-config']: old_conf_files = cfg.find_config_files(project='monasca', prog=prog_name) if len(old_conf_files) > 0: LOG.warning('Found deprecated old location ""{}"" ' 'of main configuration file'.format(old_conf_files)) conf_files += old_conf_files return conf_files","def parse_args(argv=None, config_file=None): prog='api', default_config_files=get_config_file(config_file),def get_config_file(config_file): """"""Get config file in a format suitable for CONF constructor Returns the config file name as a single element array. If a config file was explicitly, specified, that file's name is returned. If there isn't and a legacy config file is present that one is returned. Otherwise we return None. This is what the CONF constructor expects for its default_config_files keyword argument. if config_file is not None: return [config_file] return _get_deprecated_config_file() def _get_deprecated_config_file(): """"""Get deprecated config file. Responsible for keeping backward compatibility with old name of the configuration file i.e. api-config.conf. New name is => api.conf as prog=api. Note: Old configuration file name did not follow a convention oslo_config expects. """""" old_files = cfg.find_config_files(project='monasca', prog='api-config') if old_files is not None and len(old_files) > 0: LOG.warning('Detected old location ""/etc/monasca/api-config.conf"" ' 'of main configuration file') return [old_files[0]] return None",23,34
openstack%2Fmanila-tempest-plugin~master~Icaa6cf9930913a728fcacba7d673f0631cf68ba8,openstack/manila-tempest-plugin,master,Icaa6cf9930913a728fcacba7d673f0631cf68ba8,Extend testing for reset state operation,MERGED,2019-01-03 09:56:35.000000000,2019-01-08 04:27:45.000000000,2019-01-08 04:27:45.000000000,"[{'_account_id': 6491}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 19262}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 29455}]","[{'number': 1, 'created': '2019-01-03 09:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/1fb74e2c28350bd8a16bbb2e14614c90ac1900ee', 'message': 'Extend testing for reset state operation\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}, {'number': 2, 'created': '2019-01-03 10:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/83af6730f0b1c1195ab8c252c271094cab43fbac', 'message': 'Extend testing for reset state operation\n\nAdd ""error_deleting"", ""deleting"", ""creating"" statuses resource\nfor reset state operation.\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}, {'number': 3, 'created': '2019-01-03 13:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/d26b43ed79cc0fc87b9ad7576d010adb0b5066d5', 'message': 'Extend testing for reset state operation\n\nAdd ""error_deleting"", ""deleting"", ""creating"" statuses resource\nfor reset state operation.\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}, {'number': 4, 'created': '2019-01-03 13:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/59fce18aaa0553e7fef857dc62db39ef9715aee2', 'message': 'Extend testing for reset state operation\n\nAdd ""error_deleting"", ""deleting"", ""creating"" statuses resource\nfor reset state operation.\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}, {'number': 5, 'created': '2019-01-03 18:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/6792a8f99127f515d47a0ced586b0fe72e270d7b', 'message': 'Extend testing for reset state operation\n\nAdd ""error_deleting"", ""deleting"", ""creating"" statuses resource\nfor reset state operation.\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}, {'number': 6, 'created': '2019-01-03 20:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/aba8ec54df19324cee979488770377fe0edd6adb', 'message': 'Extend testing for reset state operation\n\nAdd ""error_deleting"", ""deleting"", ""creating"" statuses resource\nfor reset state operation.\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}, {'number': 7, 'created': '2019-01-06 08:13:41.000000000', 'files': ['manila_tempest_tests/tests/api/admin/test_admin_actions.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/df4ab076125ebdb264e66fa39f91dee5816dc30f', 'message': 'Extend testing for reset state operation\n\nAdd ""error_deleting"", ""deleting"", ""creating"" statuses resource\nfor reset state operation.\n\nChange-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8\n'}]",10,628136,df4ab076125ebdb264e66fa39f91dee5816dc30f,29,7,7,19262,,,0,"Extend testing for reset state operation

Add ""error_deleting"", ""deleting"", ""creating"" statuses resource
for reset state operation.

Change-Id: Icaa6cf9930913a728fcacba7d673f0631cf68ba8
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/36/628136/7 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/admin/test_admin_actions.py'],1,1fb74e2c28350bd8a16bbb2e14614c90ac1900ee,reset_state," cls.states = [""error"", ""available"", ""error_deleting"", ""deleting"", ""creating""] def _reset_resource_available(self, id, type=""shares""): self.shares_v2_client.reset_state(id, s_type=type, status=""available"") self.shares_v2_client.wait_for_share_status(self.sh[""id""], ""available"") self.addCleanup(self._reset_resource_available, self.sh[""id""]) sh_instance = self.shares_v2_client.get_instances_of_share( self.sh[""id""])[0] id = sh_instance[""id""] self.addCleanup(self._reset_resource_available, id, ""share_instances"") def test_reset_snapshot_state(self): sn = self.create_snapshot_wait_for_active(self.sh[""id""]) sn[""id""], s_type=""snapshots"", status=status) self.shares_v2_client.wait_for_snapshot_status(sn[""id""], status)"," cls.states = [""error"", ""available""] cls.sh_instance = ( cls.shares_v2_client.get_instances_of_share(cls.sh[""id""])[0] ) if CONF.share.run_snapshot_tests: cls.sn = cls.create_snapshot_wait_for_active(cls.sh[""id""]) id = self.sh_instance[""id""] def test_reset_snapshot_state_to_error(self): self.sn[""id""], s_type=""snapshots"", status=status) self.shares_v2_client.wait_for_snapshot_status( self.sn[""id""], status)",15,11
openstack%2Ftripleo-heat-templates~master~I803ed2ba9ff52f9a02c550a28d21cc9102568c8e,openstack/tripleo-heat-templates,master,I803ed2ba9ff52f9a02c550a28d21cc9102568c8e,Bind mount /var/lib/iscsi in containers using iSCSI,MERGED,2019-01-03 16:37:29.000000000,2019-01-08 03:44:36.000000000,2019-01-08 03:44:36.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-03 16:37:29.000000000', 'files': ['docker/services/multipathd.yaml', 'docker/services/nova-ironic.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'docker/services/cinder-common.yaml', 'docker/services/iscsid.yaml', 'docker/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/243cb34615a1482ba676ad91afa10b3c76d800d6', 'message': ""Bind mount /var/lib/iscsi in containers using iSCSI\n\nServices that create iSCSI connections need to share the connection info\nthat gets created in /var/lib/iscsi. It's especially important that the\nhost has knowledge of *all* connections so that it can disconnect them\nwhenever the host shuts down or reboots.\n\nCloses-Bug: #1810338\nChange-Id: I803ed2ba9ff52f9a02c550a28d21cc9102568c8e\n""}]",0,628218,243cb34615a1482ba676ad91afa10b3c76d800d6,13,7,1,21129,,,0,"Bind mount /var/lib/iscsi in containers using iSCSI

Services that create iSCSI connections need to share the connection info
that gets created in /var/lib/iscsi. It's especially important that the
host has knowledge of *all* connections so that it can disconnect them
whenever the host shuts down or reboots.

Closes-Bug: #1810338
Change-Id: I803ed2ba9ff52f9a02c550a28d21cc9102568c8e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/628218/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/multipathd.yaml', 'docker/services/nova-ironic.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'docker/services/cinder-common.yaml', 'docker/services/iscsid.yaml', 'docker/services/nova-compute.yaml']",6,243cb34615a1482ba676ad91afa10b3c76d800d6,bug/1810338, - /var/lib/iscsi:/var/lib/iscsi:z,,10,3
openstack%2Ftripleo-heat-templates~master~I6a9123627d754a153ab6cb68a33778a57846aeb7,openstack/tripleo-heat-templates,master,I6a9123627d754a153ab6cb68a33778a57846aeb7,flatten time service configuration,MERGED,2018-12-18 15:42:12.000000000,2019-01-08 03:37:03.000000000,2019-01-08 03:37:02.000000000,"[{'_account_id': 360}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-12-18 15:42:12.000000000', 'files': ['sample-env-generator/standalone.yaml', 'deployment/time/ntp-baremetal-puppet.yaml', 'sample-env-generator/composable-roles.yaml', 'environments/services/ptp.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'deployment/time/timezone-baremetal-puppet.yaml', 'deployment/time/ptp-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cd331e44beefa98f6add073e716f814f6f3a8260', 'message': 'flatten time service configuration\n\nThis change combines the previous puppet and docker files into a single\nfile that performs the docker service installation and configuration.\n\nChange-Id: I6a9123627d754a153ab6cb68a33778a57846aeb7\nRelated-Blueprint: services-yaml-flattening\n'}]",0,625940,cd331e44beefa98f6add073e716f814f6f3a8260,10,5,1,27427,,,0,"flatten time service configuration

This change combines the previous puppet and docker files into a single
file that performs the docker service installation and configuration.

Change-Id: I6a9123627d754a153ab6cb68a33778a57846aeb7
Related-Blueprint: services-yaml-flattening
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/625940/1 && git format-patch -1 --stdout FETCH_HEAD,"['sample-env-generator/standalone.yaml', 'deployment/time/ntp-baremetal-puppet.yaml', 'sample-env-generator/composable-roles.yaml', 'environments/services/ptp.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'deployment/time/timezone-baremetal-puppet.yaml', 'deployment/time/ptp-baremetal-puppet.yaml']",7,cd331e44beefa98f6add073e716f814f6f3a8260,bp/services-yaml-flattening,,,8,8
openstack%2Ftripleo-heat-templates~stable%2Frocky~I1330e54744adef9be159edd8f01aefa3db85a480,openstack/tripleo-heat-templates,stable/rocky,I1330e54744adef9be159edd8f01aefa3db85a480,Put user data in the main stack,MERGED,2018-12-14 13:53:00.000000000,2019-01-08 03:30:54.000000000,2019-01-08 03:30:54.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 7385}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-12-14 13:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/057365e8922ede5e5a31b6dd60174c131b5d75af', 'message': 'Put user data in the main stack\n\nWe create user data per instance, but two are global for all, and the\nlast one per role, so we can move it up the stack.\n\nChange-Id: I1330e54744adef9be159edd8f01aefa3db85a480\n(cherry picked from commit 862f52cce0821878a0ea0ea66160cb9dfa1a2506)\n'}, {'number': 2, 'created': '2018-12-27 10:55:01.000000000', 'files': ['overcloud.j2.yaml', 'puppet/role.role.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b7167b072c042fa5a0539a2e20edfdf1b83d1149', 'message': 'Put user data in the main stack\n\nWe create user data per instance, but two are global for all, and the\nlast one per role, so we can move it up the stack.\n\nChange-Id: I1330e54744adef9be159edd8f01aefa3db85a480\n(cherry picked from commit 862f52cce0821878a0ea0ea66160cb9dfa1a2506)\n'}]",0,625260,b7167b072c042fa5a0539a2e20edfdf1b83d1149,21,7,2,3153,,,0,"Put user data in the main stack

We create user data per instance, but two are global for all, and the
last one per role, so we can move it up the stack.

Change-Id: I1330e54744adef9be159edd8f01aefa3db85a480
(cherry picked from commit 862f52cce0821878a0ea0ea66160cb9dfa1a2506)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/625260/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud.j2.yaml', 'puppet/role.role.j2.yaml']",2,057365e8922ede5e5a31b6dd60174c131b5d75af,global-user-data-stable/rocky, UserData: type: string user_data: {get_param: UserData}," user_data: {get_resource: UserData} # Combine the NodeAdminUserData and NodeUserData mime archives UserData: type: OS::Heat::MultipartMime properties: parts: - config: {get_resource: NodeAdminUserData} type: multipart - config: {get_resource: NodeUserData} type: multipart - config: {get_resource: RoleUserData} type: multipart # Creates the ""heat-admin"" user if configured via the environment # Should return a OS::Heat::MultipartMime reference via OS::stack_id NodeAdminUserData: type: OS::TripleO::NodeAdminUserData # For optional operator additional userdata # Should return a OS::Heat::MultipartMime reference via OS::stack_id NodeUserData: type: OS::TripleO::NodeUserData # For optional operator role-specific userdata # Should return a OS::Heat::MultipartMime reference via OS::stack_id RoleUserData: type: OS::TripleO::{{role.name}}::NodeUserData ",32,28
openstack%2Fzaqar-ui~master~I45b0dc4b8491b4330bbf27e43d8562ce76fac2d5,openstack/zaqar-ui,master,I45b0dc4b8491b4330bbf27e43d8562ce76fac2d5,One more letter d,MERGED,2018-12-21 07:15:21.000000000,2019-01-08 02:49:41.000000000,2019-01-08 02:49:41.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 07:15:21.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/zaqar-ui/commit/f54bf31732981b8780900af7437cf89febe2e7ed', 'message': 'One more letter d\n\nChange-Id: I45b0dc4b8491b4330bbf27e43d8562ce76fac2d5\n'}]",0,626836,f54bf31732981b8780900af7437cf89febe2e7ed,6,2,1,29602,,,0,"One more letter d

Change-Id: I45b0dc4b8491b4330bbf27e43d8562ce76fac2d5
",git fetch https://review.opendev.org/openstack/zaqar-ui refs/changes/36/626836/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,f54bf31732981b8780900af7437cf89febe2e7ed,,# This file is execfile() with the current directory set to its,# This file is execfile()d with the current directory set to its,1,1
openstack%2Fmagnum-ui~master~I645a89cdb0b87108152a429df669a850cf8e07bc,openstack/magnum-ui,master,I645a89cdb0b87108152a429df669a850cf8e07bc,Update the bugs link to storyboard,MERGED,2018-12-30 16:07:13.000000000,2019-01-08 02:46:57.000000000,2019-01-08 02:46:57.000000000,"[{'_account_id': 16352}, {'_account_id': 17130}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 16:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/21c5b4fba85af27cd00bcb04f4a36ede8a3f0987', 'message': 'Update the bugs link to storyboard\n\nChange-Id: I645a89cdb0b87108152a429df669a850cf8e07bc\n'}, {'number': 2, 'created': '2018-12-31 12:27:52.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/b5df885115b4e65db3383fca0fbee9a9ea0e1290', 'message': 'Update the bugs link to storyboard\n\nChange-Id: I645a89cdb0b87108152a429df669a850cf8e07bc\n'}]",1,627833,b5df885115b4e65db3383fca0fbee9a9ea0e1290,11,4,2,21691,,,0,"Update the bugs link to storyboard

Change-Id: I645a89cdb0b87108152a429df669a850cf8e07bc
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/33/627833/2 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,21c5b4fba85af27cd00bcb04f4a36ede8a3f0987,, https://storyboard.openstack.org/#!/project/openstack/magnum-ui, http://bugs.launchpad.net/magnum-ui,1,1
openstack%2Fironic-python-agent~master~I45d8155e476e18c71ca6a368ce0650c7d13cd91c,openstack/ironic-python-agent,master,I45d8155e476e18c71ca6a368ce0650c7d13cd91c,update the tox mini version,MERGED,2018-11-10 08:50:50.000000000,2019-01-08 02:45:38.000000000,2019-01-08 02:45:38.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2018-11-10 08:50:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d8b2549c37ed3ac9246788a08bf9cb4ed32b69da', 'message': 'update the tox mini version\n\nChange-Id: I45d8155e476e18c71ca6a368ce0650c7d13cd91c\n'}]",0,617101,d8b2549c37ed3ac9246788a08bf9cb4ed32b69da,7,3,1,27866,,,0,"update the tox mini version

Change-Id: I45d8155e476e18c71ca6a368ce0650c7d13cd91c
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/01/617101/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d8b2549c37ed3ac9246788a08bf9cb4ed32b69da,,minversion = 2.0,minversion = 1.6,1,1
openstack%2Fnetworking-sfc~master~I3757d64e2ddff6caa7961d1bc0a5eb9d872b42fe,openstack/networking-sfc,master,I3757d64e2ddff6caa7961d1bc0a5eb9d872b42fe,Update Openflow version from 1.1 to 1.3,MERGED,2019-01-03 10:57:00.000000000,2019-01-08 00:47:46.000000000,2019-01-08 00:47:46.000000000,"[{'_account_id': 9396}, {'_account_id': 12021}, {'_account_id': 18955}, {'_account_id': 21883}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 10:57:00.000000000', 'files': ['networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/services/sfc/common/ovs_ext_lib.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/58fcc6ad28cf1d6d5d2bb3ad9969a48d7f3c91a5', 'message': 'Update Openflow version from 1.1 to 1.3\n\nCurrently, networking-sfc can not add NSH related flow when it uses\nOpenflow 1.1. This patch update Openflow version to 1.3 to support\nNSH.\n\nChange-Id: I3757d64e2ddff6caa7961d1bc0a5eb9d872b42fe\n'}]",0,628149,58fcc6ad28cf1d6d5d2bb3ad9969a48d7f3c91a5,7,5,1,26222,,,0,"Update Openflow version from 1.1 to 1.3

Currently, networking-sfc can not add NSH related flow when it uses
Openflow 1.1. This patch update Openflow version to 1.3 to support
NSH.

Change-Id: I3757d64e2ddff6caa7961d1bc0a5eb9d872b42fe
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/49/628149/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/services/sfc/common/ovs_ext_lib.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py']",3,58fcc6ad28cf1d6d5d2bb3ad9969a48d7f3c91a5,," ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"" ""encap(nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(ethernet),"""," ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),"" ""encap(hdr=nsh,prop(class=nsh,type=md_type,val=1)),"" ""encap(hdr=ethernet),""",37,36
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ie79aed5f5665658ea09e000a4847062e9207e25c,openstack/tripleo-heat-templates,stable/rocky,Ie79aed5f5665658ea09e000a4847062e9207e25c,Fix access to /var/lib/haproxy when SELinux is enabled,MERGED,2018-12-14 15:17:54.000000000,2019-01-08 00:28:12.000000000,2019-01-08 00:28:12.000000000,"[{'_account_id': 3153}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-14 15:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ff5d01309495f6fd53c0225c9932e1a405554e1b', 'message': ""Fix access to /var/lib/haproxy when SELinux is enabled\n\nCurrently we don't use relabeling of the folder when SELinux is enabled.\nThis leads to the fact that we can not update the configuration of\nhaproxy during the update, because of missing permissions.\n\nThis commit adds the relabeling for the folder, which allows the\ncontainer with haproxy to write into it.\n\nCloses-Bug: #1807933\n\nChange-Id: Ie79aed5f5665658ea09e000a4847062e9207e25c\n""}, {'number': 2, 'created': '2019-01-03 10:38:08.000000000', 'files': ['docker/services/haproxy.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1132612f7d8363cc4cf67515e9612bcb8d065cc0', 'message': ""Fix access to /var/lib/haproxy when SELinux is enabled\n\nCurrently we don't use relabeling of the folder when SELinux is enabled.\nThis leads to the fact that we can not update the configuration of\nhaproxy during the update, because of missing permissions.\n\nThis commit adds the relabeling for the folder, which allows the\ncontainer with haproxy to write into it.\n\nCloses-Bug: #1807933\n\nChange-Id: Ie79aed5f5665658ea09e000a4847062e9207e25c\n(cherry picked from commit 32f4db83c638af33225f2f2a58e141e535a619da)\n""}]",0,625281,1132612f7d8363cc4cf67515e9612bcb8d065cc0,11,4,2,11391,,,0,"Fix access to /var/lib/haproxy when SELinux is enabled

Currently we don't use relabeling of the folder when SELinux is enabled.
This leads to the fact that we can not update the configuration of
haproxy during the update, because of missing permissions.

This commit adds the relabeling for the folder, which allows the
container with haproxy to write into it.

Closes-Bug: #1807933

Change-Id: Ie79aed5f5665658ea09e000a4847062e9207e25c
(cherry picked from commit 32f4db83c638af33225f2f2a58e141e535a619da)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/625281/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/haproxy.yaml'],1,ff5d01309495f6fd53c0225c9932e1a405554e1b,bug/1807933-stable/rocky," - /var/lib/haproxy:/var/lib/haproxy:rw,z - /var/lib/haproxy:/var/lib/haproxy:rw,z", - /var/lib/haproxy:/var/lib/haproxy:rw - /var/lib/haproxy:/var/lib/haproxy:rw,2,2
openstack%2Foslo.utils~master~I28781acf027b9b34f8274196db5dd4d2a9adc9ba,openstack/oslo.utils,master,I28781acf027b9b34f8274196db5dd4d2a9adc9ba,Support non-dict mappings in mask_dict_password,MERGED,2018-11-28 19:40:40.000000000,2019-01-08 00:08:03.000000000,2019-01-08 00:08:03.000000000,"[{'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 8116}, {'_account_id': 9796}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2018-11-28 19:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/df018bdaaa749fa128c45a78e8e07a20a3dd16ba', 'message': ""Support non-dict mappings in mask_dict_password\n\nmask_dict_password doesn't actually have a dependency on the dict\ntype specifically. It can work on any subclass of collections.Mapping.\nThis changes the isinstance check to reflect that and adds a unit\ntest using a collections.Mapping subclass.\n\nChange-Id: I28781acf027b9b34f8274196db5dd4d2a9adc9ba\nCloses-Bug: 1804528\n""}, {'number': 2, 'created': '2018-12-03 16:44:54.000000000', 'files': ['oslo_utils/tests/test_strutils.py', 'oslo_utils/strutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/ddc436925887b6ece4aba19a36e53ede0b22ae21', 'message': ""Support non-dict mappings in mask_dict_password\n\nmask_dict_password doesn't actually have a dependency on the dict\ntype specifically. It can work on any subclass of collections.Mapping.\nThis changes the isinstance check to reflect that and adds a unit\ntest using a collections.Mapping subclass.\n\nChange-Id: I28781acf027b9b34f8274196db5dd4d2a9adc9ba\nCloses-Bug: 1804528\n""}]",2,620686,ddc436925887b6ece4aba19a36e53ede0b22ae21,18,7,2,6928,,,0,"Support non-dict mappings in mask_dict_password

mask_dict_password doesn't actually have a dependency on the dict
type specifically. It can work on any subclass of collections.Mapping.
This changes the isinstance check to reflect that and adds a unit
test using a collections.Mapping subclass.

Change-Id: I28781acf027b9b34f8274196db5dd4d2a9adc9ba
Closes-Bug: 1804528
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/86/620686/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/tests/test_strutils.py', 'oslo_utils/strutils.py']",2,df018bdaaa749fa128c45a78e8e07a20a3dd16ba,bug/1804528,"import collections if not isinstance(dictionary, collections.Mapping): raise TypeError(""Expected a Mapping, got %s instead."""," if not isinstance(dictionary, dict): raise TypeError(""Expected a dictionary, got %s instead.""",29,2
openstack%2Fgoal-tools~master~Id86c465f66b61c765c4d18c3f99064a361628b08,openstack/goal-tools,master,Id86c465f66b61c765c4d18c3f99064a361628b08,add a couple of queries,MERGED,2019-01-07 23:42:37.000000000,2019-01-08 00:00:58.000000000,2019-01-08 00:00:58.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 23:42:37.000000000', 'files': ['queries/rocky.qry', 'queries/stein-goal-python3-first.qry'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/82b99fc7306ee6850ec33bd9b9817f9371205d0d', 'message': 'add a couple of queries\n\nChange-Id: Id86c465f66b61c765c4d18c3f99064a361628b08\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,629071,82b99fc7306ee6850ec33bd9b9817f9371205d0d,6,2,1,2472,,,0,"add a couple of queries

Change-Id: Id86c465f66b61c765c4d18c3f99064a361628b08
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/71/629071/1 && git format-patch -1 --stdout FETCH_HEAD,"['queries/rocky.qry', 'queries/stein-goal-python3-first.qry']",2,82b99fc7306ee6850ec33bd9b9817f9371205d0d,sql-command,topic:python3-first,,3,0
openstack%2Fgoal-tools~master~I01545ac8e88f40b5b49148571d93fa16463e9624,openstack/goal-tools,master,I01545ac8e88f40b5b49148571d93fa16463e9624,new command to build sql database directly from gerrit,MERGED,2019-01-07 23:03:34.000000000,2019-01-07 23:52:26.000000000,2019-01-07 23:52:26.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 23:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/a85f24ef128e74267e2242d5abd5ba17dfa7412d', 'message': 'new command to build sql database directly from gerrit\n\nRather than downloading the review data in one command and then\nre-processing it to build a sql database in another, just move\ndirectly from gerrit to sqlite.\n\nChange-Id: I01545ac8e88f40b5b49148571d93fa16463e9624\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2019-01-07 23:37:41.000000000', 'files': ['goal_tools/who_helped/sql.py', '.gitignore', 'tools/build_db.sh', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/280cf026107553f5f8d70aa40e0ca87e949435ee', 'message': 'new command to build sql database directly from gerrit\n\nRather than downloading the review data in one command and then\nre-processing it to build a sql database in another, just move\ndirectly from gerrit to sqlite.\n\nChange-Id: I01545ac8e88f40b5b49148571d93fa16463e9624\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,629067,280cf026107553f5f8d70aa40e0ca87e949435ee,8,2,2,2472,,,0,"new command to build sql database directly from gerrit

Rather than downloading the review data in one command and then
re-processing it to build a sql database in another, just move
directly from gerrit to sqlite.

Change-Id: I01545ac8e88f40b5b49148571d93fa16463e9624
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/67/629067/1 && git format-patch -1 --stdout FETCH_HEAD,"['goal_tools/who_helped/sql.py', '.gitignore', 'setup.cfg']",3,a85f24ef128e74267e2242d5abd5ba17dfa7412d,sql-command, database create = goal_tools.who_helped.sql:DBCreate,,124,0
openstack%2Fgoal-tools~master~If759d20d0681f5f6abf7521da2a1e33b52adecb6,openstack/goal-tools,master,If759d20d0681f5f6abf7521da2a1e33b52adecb6,ensure the review id is always a string when building url,MERGED,2019-01-07 23:03:34.000000000,2019-01-07 23:45:40.000000000,2019-01-07 23:45:39.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 23:03:34.000000000', 'files': ['goal_tools/gerrit.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/831abc3fded9ec46d94424e7ca126f2eb289ae8f', 'message': 'ensure the review id is always a string when building url\n\nChange-Id: If759d20d0681f5f6abf7521da2a1e33b52adecb6\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,629066,831abc3fded9ec46d94424e7ca126f2eb289ae8f,6,2,1,2472,,,0,"ensure the review id is always a string when building url

Change-Id: If759d20d0681f5f6abf7521da2a1e33b52adecb6
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/66/629066/1 && git format-patch -1 --stdout FETCH_HEAD,['goal_tools/gerrit.py'],1,831abc3fded9ec46d94424e7ca126f2eb289ae8f,sql-command, return GERRIT_API_URL + str(self._id) + '/', return GERRIT_API_URL + self._id + '/',1,1
openstack%2Fgovernance-uc~master~I4267d28e82f920c9ff3098e6b345734c5f9788ce,openstack/governance-uc,master,I4267d28e82f920c9ff3098e6b345734c5f9788ce,Add document on how to run election,MERGED,2018-12-28 00:33:20.000000000,2019-01-07 23:45:10.000000000,2019-01-07 23:45:10.000000000,"[{'_account_id': 7272}, {'_account_id': 14091}, {'_account_id': 15993}, {'_account_id': 17556}, {'_account_id': 22348}, {'_account_id': 28738}]","[{'number': 1, 'created': '2018-12-28 00:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/1154e4f5ba9d35d8cc2c207093d529e2b797f00f', 'message': 'Add document on how to run election\n\nChange-Id: I4267d28e82f920c9ff3098e6b345734c5f9788ce\nSigned-off-by: Melvin Hillsman <mrhillsman@gmail.com>\n'}, {'number': 2, 'created': '2019-01-07 23:29:08.000000000', 'files': ['reference/running-a-uc-election.rst'], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/0dfb69926da0a0606db474d370be26097fa1b624', 'message': 'Add document on how to run election\n\nChange-Id: I4267d28e82f920c9ff3098e6b345734c5f9788ce\nSigned-off-by: Melvin Hillsman <mrhillsman@gmail.com>\n'}]",0,627578,0dfb69926da0a0606db474d370be26097fa1b624,14,6,2,17556,,,0,"Add document on how to run election

Change-Id: I4267d28e82f920c9ff3098e6b345734c5f9788ce
Signed-off-by: Melvin Hillsman <mrhillsman@gmail.com>
",git fetch https://review.opendev.org/openstack/governance-uc refs/changes/78/627578/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/running-a-uc-election.rst'],1,1154e4f5ba9d35d8cc2c207093d529e2b797f00f,addrunningelectiondoc,"============================= HOWTO - Running UC Election ============================= **User committee elections should be run twice a year, typically in February and August. It is suggested to start the steps within this document at least 60 days before election.** 1. Start by adding a patch to the `governance-uc <https://git.openstack.org/openstack/governance-uc>`_ repository similar to this `patch <https://review.openstack.org/#/c/627575/>`_; **be sure to modify the content like dates and number of seats**. 2. Follow up with an email to the User Committee asking for their action items: - Decision: dates - for nomination period and voting period. - Writing: Posts to Mailing list to announce the election - Selection: Election officials, who don't vote and manage the process in a neutral way (inc setting up the CIVS tools) - Action: pull the updated AUC list and make the voting links for all of them - Writing: Post-election ML and superuser post to announce the results and declare the UC awesome Example resources from February 2017 (copy/paste but remember to update): - https://governance.openstack.org/uc/reference/uc-election-feb2017.html - http://lists.openstack.org/pipermail/openstack-operators/2017-January/012530.html - http://superuser.openstack.org/articles/user-committee-elections/ - https://wiki.openstack.org/wiki/Governance/Foundation/UserCommittee/UC-Election-Feb17 - http://lists.openstack.org/pipermail/openstack-operators/2017-February/012647.html 3. Send email to `openstack-discuss <openstack-discuss@lists.openstack.org>`_ mailing list asking for election officials **Remember to note that election officials will not be able to vote or run for the election and are expected to be neutral in managing the process; including setting up the CIVS tools** Election Officials and Electorate --------------------------------- An early AUC list should be procured and provided to election inspectors to verify the AUC status of candidates. This can be done by downloading the CSV export from https://www.openstack.org/admin/auc/ (requires Foundation staff access). [Alternately. a system could be implemented that places a 'badge' on Foundation member profiles if a member qualifies for AUC.] In addition to the CSV export, the UC may provide lists of manually calculated AUC qualifications under their current criteria and process (eg working groups that do not meet on IRC). *#TODO Reasonable way to collect that is not manual; extra-auc is available but move to SIGs happened after; should revisit.* A final AUC CSV export, with the list of manual additions, should be provided to the election inspectors just before the start of the voting period. The inspectors will then upload it into the voting system, which sends out the voting links. Additional Considerations ------------------------- | **SuperUser Article:** | | The Superuser magazine has published articles around the time of the election such as http://superuser.openstack.org/articles/user-committee-elections/. The editable text is available at https://docs.google.com/document/d/14CkEnrI_YLvkzx14JukfxSQcNSYYg0Xwa-yLMks1oJY/edit. | **Sample eMail Announcement:** | | The announcement mail can follow the template below. Sending to `openstack-discuss <openstack-discuss@lists.openstack.org>`_ list is sufficient even though it has been sent in the past to `user-committee <user-committee@lists.openstack.org>`_, `OpenStack Operators <openstack-operators@lists.openstack.org>`_, and `women-of-openstack@lists.openstack.org <women-of-openstack@lists.openstack.org>`_ mailing lists. | | .. note:: | Hello Everyone, | | The OpenStack User Committee will be holding an election in February, per the (UC) bylaws and charter. | The current UC will serve until the elections in February, and at that point, the current three UC members who still have 6 months to serve get a 6-month seat, and an election is run to determine the other two members. Candidates ranking 1st, and 2nd will get a one-year seat. Voting for the 2018 UC members will be granted to the Active User Contributors (AUC). | Open candidacy for the UC positions will be from January 29th - February 11th, 05:59 UTC. Voting for the User Committee (UC) members will be open on February 12th and will remain open until February 18, 11:59 UTC. | | As a reminder, please see the community code of conduct (http://www.openstack.org/legal/community-code-of-conduct/) | | The details of candidate submission and process are available at here and we look forward to receiving your submissions | Please let me, or anyone from the UC know if you have any questions, comments or concerns. | | Thank you, ",,64,0
openstack%2Fgoal-tools~master~Ib41e49fe1e94af56d2a3fef892b55c4526e4f31d,openstack/goal-tools,master,Ib41e49fe1e94af56d2a3fef892b55c4526e4f31d,move gerrit querying loop somewhere more reusable,MERGED,2019-01-07 23:03:34.000000000,2019-01-07 23:41:34.000000000,2019-01-07 23:41:34.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 23:03:34.000000000', 'files': ['goal_tools/who_helped/changes.py', 'goal_tools/gerrit.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/4e08bbc1d519937e3cdd9c61d5ccff6d304a803c', 'message': 'move gerrit querying loop somewhere more reusable\n\nChange-Id: Ib41e49fe1e94af56d2a3fef892b55c4526e4f31d\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,629065,4e08bbc1d519937e3cdd9c61d5ccff6d304a803c,6,2,1,2472,,,0,"move gerrit querying loop somewhere more reusable

Change-Id: Ib41e49fe1e94af56d2a3fef892b55c4526e4f31d
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/65/629065/1 && git format-patch -1 --stdout FETCH_HEAD,"['goal_tools/who_helped/changes.py', 'goal_tools/gerrit.py']",2,4e08bbc1d519937e3cdd9c61d5ccff6d304a803c,sql-command," def id(self): return self._id @property def raw_change(self): return self._data @property def query(self, query_string): ""Generator for changes matching the query criteria."" batch_size = 200 offset = 0 while True: changes = query_gerrit( 'changes/', params={ 'n': str(batch_size), 'start': offset, 'q': query_string, 'o': QUERY_OPTIONS, }, ) LOG.debug('%d changes', len(changes)) for change in changes: review = Review( change['_number'], change, ) cache_review( review.id, review.raw_change, self._cache, ) yield review if changes and changes[-1].get('_more_changes', False): offset += batch_size else: break",,51,35
openstack%2Ftripleo-quickstart~master~I738e5051f8d92650b6186a114980e043220d2700,openstack/tripleo-quickstart,master,I738e5051f8d92650b6186a114980e043220d2700,Modify fs020 parameters to match fs001 more closely,MERGED,2019-01-02 21:51:22.000000000,2019-01-07 23:06:01.000000000,2019-01-07 23:06:01.000000000,"[{'_account_id': 8367}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22318}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-02 21:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ca34dd49153fe21d1b3624b5e1cbbec02d7bf06a', 'message': 'Modify fs020 parameters to match fs001 more closely\n\nFs020 is failing introspection and other non-tempest\nrelated steps - possible due to the featureset not\nbeing update as frequently as fs001.\nThis review brings fs020 ore in line with fs001\nso that there is a closer comparison between the two.\n\nChange-Id: I738e5051f8d92650b6186a114980e043220d2700\n'}, {'number': 2, 'created': '2019-01-03 14:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/78918f37884831080c9d5fae07fca03ff2d739bf', 'message': 'Modify fs020 parameters to match fs001 more closely\n\nFs020 is failing introspection and other non-tempest\nrelated steps - possible due to the featureset not\nbeing update as frequently as fs001.\nThis review brings fs020 ore in line with fs001\nso that there is a closer comparison between the two.\n\nChange-Id: I738e5051f8d92650b6186a114980e043220d2700\n'}, {'number': 3, 'created': '2019-01-04 13:52:12.000000000', 'files': ['config/general_config/featureset020.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/5748d15456cd00dd9ca16c02e58a4d61cb69d5ca', 'message': 'Modify fs020 parameters to match fs001 more closely\n\nFs020 is failing introspection and other non-tempest\nrelated steps - possible due to the featureset not\nbeing update as frequently as fs001.\nThis review brings fs020 ore in line with fs001\nso that there is a closer comparison between the two.\n\nChange-Id: I738e5051f8d92650b6186a114980e043220d2700\n'}]",0,628052,5748d15456cd00dd9ca16c02e58a4d61cb69d5ca,20,8,3,9976,,,0,"Modify fs020 parameters to match fs001 more closely

Fs020 is failing introspection and other non-tempest
related steps - possible due to the featureset not
being update as frequently as fs001.
This review brings fs020 ore in line with fs001
so that there is a closer comparison between the two.

Change-Id: I738e5051f8d92650b6186a114980e043220d2700
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/52/628052/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset020.yml'],1,ca34dd49153fe21d1b3624b5e1cbbec02d7bf06a,realign-fs020,"# Deploy an non-ha Openstack environment, introspect, andssl_overcloud: truecontainerized_undercloud: >- {% if release not in ['newton','ocata','pike','queens'] -%} true {%- else -%} false {%- endif -%} ctlplane_masquerade: >- {% if release not in ['newton','ocata','pike','queens'] -%} true {%- else -%} false {%- endif -%} undercloud_enable_routed_networks: >- {% if release not in ['newton','ocata','pike'] -%} true {%- else -%} false {%- endif -%} undercloud_clean_nodes: >- {% if release not in ['newton','ocata','pike'] -%} true {%- else -%} false {%- endif -%} undercloud_inspection_extras: false undercloud_custom_env_files: ""{{ working_dir }}/undercloud-parameter-defaults.yaml"" undercloud_cloud_domain: ""localdomain"" undercloud_undercloud_hostname: ""undercloud.{{ undercloud_cloud_domain }}"" undercloud_resource_registry_args: ""OS::TripleO::Undercloud::Net::SoftwareConfig"": ""{{ undercloud_templates_path }}/net-config-undercloud.yaml"" enable_pacemaker: true network_isolation: true network_isolation_type: ""multiple-nics"" network_isolation_args: >- -e {{ overcloud_templates_path }}/ci/environments/network/multiple-nics/network-isolation-absolute.yaml -e {{ overcloud_templates_path }}/ci/environments/network/multiple-nics/network-environment.yaml # This featureset is extremely resource intensive, so we disable telemetry # in order to reduce the overall memory footprint # This is not required in newton telemetry_args: >- {% if release != 'newton' %} -e {{ overcloud_templates_path }}/environments/disable-telemetry.yaml {% endif %}undercloud_ntp_servers: pool.ntp.org {% if release not in ['newton','ocata','pike'] -%}config_download_args: >- {% if release in ['queens'] -%} -e /usr/share/openstack-tripleo-heat-templates/environments/config-download-environment.yaml --config-download --verboseundercloud_container_cli: >- {% if release in ['rocky'] -%} docker {%- else -%} podman {%- endif -%}","# Deploy an non-ha Openstack environment, without SSL, introspect, andssl_overcloud: falseenable_pacemaker: false network_isolation: false {% if release not in ['newton','ocata','pike','queens'] -%} containerized_undercloud: >- {% if release not in ['newton','ocata','pike','queens'] -%} true {%- else -%} false {%- endif -%} undercloud_custom_env_files: ""{{ working_dir }}/undercloud-parameter-defaults.yaml"" undercloud_cloud_domain: ""localdomain"" undercloud_undercloud_hostname: ""undercloud.{{ undercloud_cloud_domain }}"" undercloud_resource_registry_args: ""OS::TripleO::Undercloud::Net::SoftwareConfig"": ""{{ undercloud_templates_path }}/net-config-undercloud.yaml"" ctlplane_masquerade: >- {% if release not in ['newton','ocata','pike','queens'] -%} true {%- else -%} false",62,24
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Ie49b961bb276dff0e5afbf82b450caa57d17f6ff,openstack/tripleo-heat-templates,stable/queens,Ie49b961bb276dff0e5afbf82b450caa57d17f6ff,Add Storage network to IronicConductor role,MERGED,2019-01-02 11:31:45.000000000,2019-01-07 23:05:59.000000000,2019-01-07 23:05:59.000000000,"[{'_account_id': 3153}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-01-02 11:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/29a4d1c9b99194a76d97c817aff2b0741de5369f', 'message': ""Add Storage network to IronicConductor role\n\nWhen Ironic uses the 'direct' deploy interface it requires\naccess to swift. To access swift it needs the storage\nnetwork.\n\nChange-Id: Ie49b961bb276dff0e5afbf82b450caa57d17f6ff\n(cherry picked from commit eaa8f8c2e9597515d75d6f75a52cda0c8d99acc4)\n(cherry picked from commit d5f984231ca80e886931faff723944829f769f5b)\n""}, {'number': 2, 'created': '2019-01-02 11:32:13.000000000', 'files': ['roles/IronicConductor.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/56b150977647334774ce87825c53aed5ef39a688', 'message': ""Add Storage network to IronicConductor role\n\nWhen Ironic uses the 'direct' deploy interface it requires\naccess to swift. To access swift it needs the storage\nnetwork.\n\nChange-Id: Ie49b961bb276dff0e5afbf82b450caa57d17f6ff\n(cherry picked from commit eaa8f8c2e9597515d75d6f75a52cda0c8d99acc4)\n""}]",0,627959,56b150977647334774ce87825c53aed5ef39a688,11,6,2,10239,,,0,"Add Storage network to IronicConductor role

When Ironic uses the 'direct' deploy interface it requires
access to swift. To access swift it needs the storage
network.

Change-Id: Ie49b961bb276dff0e5afbf82b450caa57d17f6ff
(cherry picked from commit eaa8f8c2e9597515d75d6f75a52cda0c8d99acc4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/627959/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/IronicConductor.yaml'],1,29a4d1c9b99194a76d97c817aff2b0741de5369f,ironic-conductor-role-storage-net-stable/rocky-stable/queens, - Storage,,1,0
openstack%2Ftripleo-heat-templates~master~Ib8e12d9e6e82520bea3130bf1945fbda5563c450,openstack/tripleo-heat-templates,master,Ib8e12d9e6e82520bea3130bf1945fbda5563c450,Remove deprecated workflow resource registry entries,MERGED,2019-01-02 17:13:54.000000000,2019-01-07 23:05:57.000000000,2019-01-07 23:05:57.000000000,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 19138}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-01-02 17:13:54.000000000', 'files': ['overcloud-resource-registry-puppet.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f27abb863254869aab84721a40344f769915914', 'message': 'Remove deprecated workflow resource registry entries\n\nThese registry entries were only kept around because of bug #1758014\nand can be removed now.\n\nChange-Id: Ib8e12d9e6e82520bea3130bf1945fbda5563c450\n'}]",0,628009,5f27abb863254869aab84721a40344f769915914,11,9,1,8042,,,0,"Remove deprecated workflow resource registry entries

These registry entries were only kept around because of bug #1758014
and can be removed now.

Change-Id: Ib8e12d9e6e82520bea3130bf1945fbda5563c450
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/09/628009/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-resource-registry-puppet.j2.yaml'],1,5f27abb863254869aab84721a40344f769915914,bug/1758014,," # Deprecated, only defined to allow smooth transition of existing # stacks. Can be removed in S release. OS::TripleO::Tasks::UpdateWorkflow: OS::Heat::None OS::TripleO::Tasks::PackageUpdate: OS::Heat::None ",0,5
openstack%2Ftripleo-heat-templates~master~Ib6c2028df861d350267a0408407775e7d5b24e18,openstack/tripleo-heat-templates,master,Ib6c2028df861d350267a0408407775e7d5b24e18,Fix bind mount for glance-api's service directory,MERGED,2019-01-03 17:31:33.000000000,2019-01-07 23:05:55.000000000,2019-01-07 23:05:55.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 10300}, {'_account_id': 19138}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-01-03 17:31:33.000000000', 'files': ['deployment/glance/glance-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26a86017d2d61833e5cdf0571a64c6a6c7703857', 'message': ""Fix bind mount for glance-api's service directory\n\nThe /var/lib/glance service directory needs 'slave' propagation to handle\nsituations where an NFS mount performed in a host prep task is delayed\nand doesn't finish until after the glance-api container is running. The\n'slave' propagation was inadvertently lost in [1].\n\n[1] I284126db5dcf9dc31ee5ee640b2684643ef3a066\n\nChange-Id: Ib6c2028df861d350267a0408407775e7d5b24e18\n""}]",0,628228,26a86017d2d61833e5cdf0571a64c6a6c7703857,16,8,1,21129,,,0,"Fix bind mount for glance-api's service directory

The /var/lib/glance service directory needs 'slave' propagation to handle
situations where an NFS mount performed in a host prep task is delayed
and doesn't finish until after the glance-api container is running. The
'slave' propagation was inadvertently lost in [1].

[1] I284126db5dcf9dc31ee5ee640b2684643ef3a066

Change-Id: Ib6c2028df861d350267a0408407775e7d5b24e18
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/28/628228/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/glance/glance-api-container-puppet.yaml'],1,26a86017d2d61833e5cdf0571a64c6a6c7703857,glance-mount-propagation," - /var/lib/glance:/var/lib/glance:slave,z", - /var/lib/glance:/var/lib/glance:z,1,1
openstack%2Ftripleo-heat-templates~master~Ia6fbe2fe7392f25cc11276e2a9e17f4e5d6df1f1,openstack/tripleo-heat-templates,master,Ia6fbe2fe7392f25cc11276e2a9e17f4e5d6df1f1,Fix scenario004-standalone - remove cinder/fluentd/horizon/redis,MERGED,2019-01-04 12:12:34.000000000,2019-01-07 23:05:53.000000000,2019-01-07 23:05:53.000000000,"[{'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-01-04 12:12:34.000000000', 'files': ['ci/environments/scenario004-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cf70e57351338ca01929cdeb7aef7029cc86f566', 'message': 'Fix scenario004-standalone - remove cinder/fluentd/horizon/redis\n\nAs tracked in [1] the scenario4 standalone is carrying some\nextra services compared to the multinode it replaces.\n\nThis disables cinder, fluentd, horizon and redis for scenario4\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/task/541\n\nChange-Id: Ia6fbe2fe7392f25cc11276e2a9e17f4e5d6df1f1\n'}]",0,628417,cf70e57351338ca01929cdeb7aef7029cc86f566,9,8,1,8449,,,0,"Fix scenario004-standalone - remove cinder/fluentd/horizon/redis

As tracked in [1] the scenario4 standalone is carrying some
extra services compared to the multinode it replaces.

This disables cinder, fluentd, horizon and redis for scenario4

[1] https://tree.taiga.io/project/tripleo-ci-board/task/541

Change-Id: Ia6fbe2fe7392f25cc11276e2a9e17f4e5d6df1f1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/17/628417/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario004-standalone.yaml'],1,cf70e57351338ca01929cdeb7aef7029cc86f566,fix-scen4, OS::TripleO::Services::CinderApi: OS::Heat::None OS::TripleO::Services::CinderScheduler: OS::Heat::None OS::TripleO::Services::CinderVolume: OS::Heat::None OS::TripleO::Services::Redis: OS::Heat::None OS::TripleO::Services::Horizon: OS::Heat::None, OS::TripleO::Services::Redis: ../../docker/services/pacemaker/database/redis.yaml #Needs to run scenario001 OS::TripleO::Services::Fluentd: ../../docker/services/fluentd.yaml CinderEnableRbdBackend: true CinderBackupBackend: ceph CinderEnableIscsiBackend: false,5,6
openstack%2Ftripleo-common~stable%2Fqueens~Ib806bac815077c2508060719469b5d0f1acc0f99,openstack/tripleo-common,stable/queens,Ib806bac815077c2508060719469b5d0f1acc0f99,Increase size for security hardened images,MERGED,2019-01-04 17:23:51.000000000,2019-01-07 23:05:52.000000000,2019-01-07 23:05:52.000000000,"[{'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-04 17:23:51.000000000', 'files': ['image-yaml/overcloud-hardened-images-uefi.yaml', 'releasenotes/notes/increase-size-security-hardened-images-3fc4df73a48d4a91.yaml', 'image-yaml/overcloud-hardened-images.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d02470c9fa61a691300ce345d43871bb11d8af03', 'message': 'Increase size for security hardened images\n\nWith the move to containers there has been an increase of\ndemand on the /var volume. Increase the global size.\n\nChange-Id: Ib806bac815077c2508060719469b5d0f1acc0f99\n(cherry picked from commit 83c7887ffb361b33cd150098708fe3e06ea5e77b)\n(cherry picked from commit a32cbdee414f9bd20f03fe7eebb3e13cde5ca9e8)\n'}]",0,628638,d02470c9fa61a691300ce345d43871bb11d8af03,7,4,1,21909,,,0,"Increase size for security hardened images

With the move to containers there has been an increase of
demand on the /var volume. Increase the global size.

Change-Id: Ib806bac815077c2508060719469b5d0f1acc0f99
(cherry picked from commit 83c7887ffb361b33cd150098708fe3e06ea5e77b)
(cherry picked from commit a32cbdee414f9bd20f03fe7eebb3e13cde5ca9e8)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/38/628638/1 && git format-patch -1 --stdout FETCH_HEAD,"['image-yaml/overcloud-hardened-images-uefi.yaml', 'releasenotes/notes/increase-size-security-hardened-images-3fc4df73a48d4a91.yaml', 'image-yaml/overcloud-hardened-images.yaml']",3,d02470c9fa61a691300ce345d43871bb11d8af03,, DIB_IMAGE_SIZE: '40', DIB_IMAGE_SIZE: '23',9,2
openstack%2Ftripleo-common~stable%2Frocky~Ic358ed27d63015d297f50c10f553fc1c470ea6a5,openstack/tripleo-common,stable/rocky,Ic358ed27d63015d297f50c10f553fc1c470ea6a5,Additional images for openshift services,MERGED,2019-01-04 14:33:21.000000000,2019-01-07 23:05:51.000000000,2019-01-07 23:05:51.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-04 14:33:21.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py', 'container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/112cc3b5253144f1362ca51e63c386a0abff0a78', 'message': 'Additional images for openshift services\n\nThis commit adds missing images for openshift service catalog and\ntemplate service broker. These two services are enabled by default by\nopenshift-ansible and as a result, tripleo should deploy them in its\ndefault setting too (they were explicitly disabled in tht until now).\n\nChange-Id: Ic358ed27d63015d297f50c10f553fc1c470ea6a5\nPartial-Bug: #1806353\n(cherry picked from commit 9d53ff37713d1192dc1c7c0b3b4f1832c9c7b29d)\n'}]",0,628447,112cc3b5253144f1362ca51e63c386a0abff0a78,7,3,1,13039,,,0,"Additional images for openshift services

This commit adds missing images for openshift service catalog and
template service broker. These two services are enabled by default by
openshift-ansible and as a result, tripleo should deploy them in its
default setting too (they were explicitly disabled in tht until now).

Change-Id: Ic358ed27d63015d297f50c10f553fc1c470ea6a5
Partial-Bug: #1806353
(cherry picked from commit 9d53ff37713d1192dc1c7c0b3b4f1832c9c7b29d)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/47/628447/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py', 'container-images/overcloud_containers.yaml.j2']",4,112cc3b5253144f1362ca51e63c386a0abff0a78,bug/1806353,"- imagename: ""{{openshift_namespace}}/{{openshift_prefix}}-service-catalog:{{openshift_tag}}"" params: - DockerOpenShiftServiceCatalogImage services: - OS::TripleO::Services::OpenShift::Master - imagename: ""{{openshift_namespace}}/{{openshift_prefix}}-template-service-broker:{{openshift_tag}}"" params: - DockerOpenShiftTemplateServiceBrokerImage services: - OS::TripleO::Services::OpenShift::Master - imagename: ""{{openshift_asb_namespace}}/{{openshift_prefix}}-ansible-service-broker:{{openshift_asb_tag}}"" params: - DockerOpenShiftAnsibleServiceBrokerImage services: - OS::TripleO::Services::OpenShift::Infra ",,31,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~I47805608b90d8fda7d8357d3cb55f6372e746da1,openstack/tripleo-heat-templates,stable/rocky,I47805608b90d8fda7d8357d3cb55f6372e746da1,Allow customization of more openshift-ansible vars,MERGED,2019-01-05 12:51:25.000000000,2019-01-07 23:05:50.000000000,2019-01-07 23:05:50.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-05 12:51:25.000000000', 'files': ['extraconfig/services/openshift-master.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4e299d65aea48eb3499dfd59b18c80875c911625', 'message': 'Allow customization of more openshift-ansible vars\n\nThe `openshift_master_cluster_hostname` and\n`openshift_master_cluster_public_hostname` variables are set to IP\naddresses by tripleo, but were wrongly combined with the\nopenshift_global_vars dictionnary in a way that prevented customization\nvia the OpenShiftGlobalVariables heat parameter.\n\nReverse the order of the combine to make customization possible as they\nshould.\n\nChange-Id: I47805608b90d8fda7d8357d3cb55f6372e746da1\nCloses-Bug: #1806736\n(cherry picked from commit 7c4b027a75afbf1491d7f74695be0f72b79e7320)\n'}]",0,628730,4e299d65aea48eb3499dfd59b18c80875c911625,7,3,1,13039,,,0,"Allow customization of more openshift-ansible vars

The `openshift_master_cluster_hostname` and
`openshift_master_cluster_public_hostname` variables are set to IP
addresses by tripleo, but were wrongly combined with the
openshift_global_vars dictionnary in a way that prevented customization
via the OpenShiftGlobalVariables heat parameter.

Reverse the order of the combine to make customization possible as they
should.

Change-Id: I47805608b90d8fda7d8357d3cb55f6372e746da1
Closes-Bug: #1806736
(cherry picked from commit 7c4b027a75afbf1491d7f74695be0f72b79e7320)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/628730/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/services/openshift-master.yaml'],1,4e299d65aea48eb3499dfd59b18c80875c911625,bug/1806736-stable/rocky," openshift_global_vars: ""{{ openshift_master_cluster_vars | combine(openshift_global_vars) }}"""," openshift_global_vars: ""{{ openshift_global_vars | combine(openshift_master_cluster_vars) }}""",1,1
openstack%2Ftripleo-heat-templates~stable%2Frocky~Icc568a551b902e6d9f003250226468ed38a776fc,openstack/tripleo-heat-templates,stable/rocky,Icc568a551b902e6d9f003250226468ed38a776fc,Fix misnaming of service in firewall rule,MERGED,2018-12-17 10:16:11.000000000,2019-01-07 23:05:49.000000000,2019-01-07 23:05:48.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-17 10:16:11.000000000', 'files': ['puppet/services/octavia-health-manager.yaml', 'releasenotes/notes/fix-octavia-health-manager-firewall-rule-cdffe31d580ecf4b.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a74808fafd41c5d12004f50fc336ee47e6575196', 'message': ""Fix misnaming of service in firewall rule\n\nOn Octavia-enabled composable role deployments where the Octavia health\nmanager service doesn't run co-located with the API service, the\nfirewall rule to allow messages in to the o-hm0 interface was not being\ncreated. As a result of that, the load balancers were not going ONLINE.\n\nConflicts:\n    puppet/services/octavia-health-manager.yaml\n\nCloses-Bug: #1808190\nDepends-On: https://review.openstack.org/#/c/624403/\nChange-Id: Icc568a551b902e6d9f003250226468ed38a776fc\n(cherry picked from commit 29da33fae27cd78cf07acbbbbb95914914c782a6)\n""}]",0,625538,a74808fafd41c5d12004f50fc336ee47e6575196,16,5,1,6469,,,0,"Fix misnaming of service in firewall rule

On Octavia-enabled composable role deployments where the Octavia health
manager service doesn't run co-located with the API service, the
firewall rule to allow messages in to the o-hm0 interface was not being
created. As a result of that, the load balancers were not going ONLINE.

Conflicts:
    puppet/services/octavia-health-manager.yaml

Closes-Bug: #1808190
Depends-On: https://review.openstack.org/#/c/624403/
Change-Id: Icc568a551b902e6d9f003250226468ed38a776fc
(cherry picked from commit 29da33fae27cd78cf07acbbbbb95914914c782a6)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/625538/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/octavia-health-manager.yaml', 'releasenotes/notes/fix-octavia-health-manager-firewall-rule-cdffe31d580ecf4b.yaml']",2,a74808fafd41c5d12004f50fc336ee47e6575196,bug/1808190,--- issues: - Fix misnaming of service in firewall rule for Octavia Health Manager service. ,,5,1
openstack%2Fansible-role-tripleo-modify-image~master~Ieab2cd4b303309603ef80bac932810b3a0d89115,openstack/ansible-role-tripleo-modify-image,master,Ieab2cd4b303309603ef80bac932810b3a0d89115,Fix line length for lint,MERGED,2019-01-07 14:19:01.000000000,2019-01-07 22:46:24.000000000,2019-01-07 22:46:24.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 14:19:01.000000000', 'files': ['tasks/modify_image.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/08903c0bab8bb060feebcf7bb606c00502fa8348', 'message': 'Fix line length for lint\n\nCurrently ansible-lint is complaining due to the line being >120 chars.\n\nChange-Id: Ieab2cd4b303309603ef80bac932810b3a0d89115\n'}]",0,628981,08903c0bab8bb060feebcf7bb606c00502fa8348,6,2,1,14985,,,0,"Fix line length for lint

Currently ansible-lint is complaining due to the line being >120 chars.

Change-Id: Ieab2cd4b303309603ef80bac932810b3a0d89115
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-modify-image refs/changes/81/628981/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/modify_image.yml'],1,08903c0bab8bb060feebcf7bb606c00502fa8348,fix-lint, command: | {{ build_commands[container_build_tool] }} \ --tag {{ target_image | default(source_image) }}{{ modified_append_tag }} \ --file {{ dockerfile.path }} --network host ./," command: ""{{ build_commands[container_build_tool] }} --tag {{ target_image | default(source_image) }}{{ modified_append_tag }} --file {{ dockerfile.path }} --network host ./""",4,1
openstack%2Fopenstack-helm-infra~master~I95322e6aa8907fbe47643c2cbc15f8cf4554d447,openstack/openstack-helm-infra,master,I95322e6aa8907fbe47643c2cbc15f8cf4554d447,ceph-osd: validate number of osds,ABANDONED,2018-11-09 23:08:19.000000000,2019-01-07 22:38:44.000000000,,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28372}, {'_account_id': 29053}, {'_account_id': 29268}]","[{'number': 1, 'created': '2018-11-09 23:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/007aaf85e1746aba25f685e1accde10d99e3bbf9', 'message': 'ceph-client: validate number of osds for pg calculation\n\nThis is to validate  number osds in the cluster and user provided osds\nbefore calculating the PGs\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}, {'number': 2, 'created': '2018-11-10 00:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/54df174a3201efa225eaa3006606914726a063ce', 'message': 'ceph-client: validate number of osds for pg calculation\n\nThis is to validate  number osds in the cluster and user provided osds\nbefore calculating the PGs\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}, {'number': 3, 'created': '2018-11-16 14:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/77fdf0e2e322490f0a754ed70302edf48ccf6909', 'message': 'ceph-client: validate number of osds for pg calculation\n\nThis is to validate  number osds in the cluster and user provided osds\nbefore calculating the PGs\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}, {'number': 4, 'created': '2018-11-26 23:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d63c144524121f90abf489eaa86b5b579bda6364', 'message': 'ceph-client: validate number of osds for pg calculation\n\nThis is to validate  number osds in the cluster and user provided osds\nbefore calculating the PGs\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}, {'number': 5, 'created': '2018-12-14 22:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/48db65108147b952c8969cb5722a11b1f9480e4b', 'message': 'ceph-client: validate number of osds for pg calculation\n\nThis is to validate  number osds in the cluster and user provided osds\nbefore calculating the PGs\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}, {'number': 6, 'created': '2018-12-14 23:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1e50953d460bba9eb6061d4d0d34b998a216a5ba', 'message': 'ceph-osd: validate number of osds\n\nThis is to validate  number osds up  in the cluster and target\nnumber of osds\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}, {'number': 7, 'created': '2018-12-14 23:03:28.000000000', 'files': ['ceph-osd/values.yaml', 'ceph-osd/templates/bin/_helm-tests.sh.tpl', 'ceph-osd/templates/pod-helm-tests.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d7c5d43ec0d28cf36f154c93df09e5b68aff6f3e', 'message': 'ceph-osd: validate number of osds\n\nThis is to validate  number osds up  in the cluster and target\nnumber of osds\n\nChange-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447\n'}]",2,617044,d7c5d43ec0d28cf36f154c93df09e5b68aff6f3e,19,6,7,28372,,,0,"ceph-osd: validate number of osds

This is to validate  number osds up  in the cluster and target
number of osds

Change-Id: I95322e6aa8907fbe47643c2cbc15f8cf4554d447
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/44/617044/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-client/templates/bin/pool/_init.sh.tpl'],1,007aaf85e1746aba25f685e1accde10d99e3bbf9,," OSD_IN_CLUSER=$(ceph --cluster ${CLUSTER} -s|grep osd|cut -d' ' -f6) if [ ${OSD_IN_CLUSER} != {{ $targetNumOSD }} ] then echo ""expected number of osds are not yet in the cluster"" exit 1 fi ",,10,0
openstack%2Fkeystone~master~I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e,openstack/keystone,master,I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e,Add section on configuring protected auth paths,MERGED,2019-01-02 13:56:35.000000000,2019-01-07 22:26:42.000000000,2019-01-07 22:26:41.000000000,"[{'_account_id': 5046}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 13:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/814a6b2eadff1ba5a88e9255361b4747fde519e2', 'message': ""Add section on configuring protected auth paths\n\nWithout this change, the federation guide does not do a good job of\nexplaining which URL paths should be protected by a federation-capable\nauth module and why. Instead, the SP-specific guides give code samples\nwith no context, which makes it confusing to understand how to modify\nthe paths in the examples to fit one's own deployment. This change adds\nthat introduction.\n\nPartial-bug: #1793374\n\nChange-Id: I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e\n""}, {'number': 2, 'created': '2019-01-02 22:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/72590757d36c2db903700785dca5108ca80c368f', 'message': ""Add section on configuring protected auth paths\n\nWithout this change, the federation guide does not do a good job of\nexplaining which URL paths should be protected by a federation-capable\nauth module and why. Instead, the SP-specific guides give code samples\nwith no context, which makes it confusing to understand how to modify\nthe paths in the examples to fit one's own deployment. This change adds\nthat introduction.\n\nPartial-bug: #1793374\n\nChange-Id: I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e\n""}, {'number': 3, 'created': '2019-01-04 09:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b9d6ad1f2b34ee0d0dd1696f976f2da8bfb805d3', 'message': ""Add section on configuring protected auth paths\n\nWithout this change, the federation guide does not do a good job of\nexplaining which URL paths should be protected by a federation-capable\nauth module and why. Instead, the SP-specific guides give code samples\nwith no context, which makes it confusing to understand how to modify\nthe paths in the examples to fit one's own deployment. This change adds\nthat introduction.\n\nPartial-bug: #1793374\n\nChange-Id: I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e\n""}, {'number': 4, 'created': '2019-01-07 15:57:06.000000000', 'files': ['doc/source/admin/federation/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/708d3f4d59ceb3df78b3c5d6820c6b150f25dfb6', 'message': ""Add section on configuring protected auth paths\n\nWithout this change, the federation guide does not do a good job of\nexplaining which URL paths should be protected by a federation-capable\nauth module and why. Instead, the SP-specific guides give code samples\nwith no context, which makes it confusing to understand how to modify\nthe paths in the examples to fit one's own deployment. This change adds\nthat introduction.\n\nPartial-bug: #1793374\n\nChange-Id: I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e\n""}]",0,627975,708d3f4d59ceb3df78b3c5d6820c6b150f25dfb6,12,3,4,8482,,,0,"Add section on configuring protected auth paths

Without this change, the federation guide does not do a good job of
explaining which URL paths should be protected by a federation-capable
auth module and why. Instead, the SP-specific guides give code samples
with no context, which makes it confusing to understand how to modify
the paths in the examples to fit one's own deployment. This change adds
that introduction.

Partial-bug: #1793374

Change-Id: I5cf940e0c54e5dd89cd3db810f8b5889a8ddce2e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/75/627975/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/federation/configure_federation.rst'],1,814a6b2eadff1ba5a88e9255361b4747fde519e2,bug/1793374,"Configure protected endpoints ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ There is a minimum of one endpoint that must be protected in the VirtualHost configuration for the keystone service: .. code-block:: apache <Location /v3/OS-FEDERATION/identity_providers/IDENTITYPROVIDER/protocols/PROTOCOL/auth> Require valid-user AuthType [...] ... </Location> This is the endpoint for federated users to request an unscoped token. If configuring WebSSO, you should also protect one or both of the following endpoints: .. code-block:: apache <Location /v3/auth/OS-FEDERATION/websso/PROTOCOL> Require valid-user AuthType [...] ... </Location> <Location /v3/auth/OS-FEDERATION/identity_providers/IDENTITYPROVIDER/protocols/PROTOCOL/websso> Require valid-user AuthType [...] ... </Location> The first example only specifies a protocol, and keystone will use the incoming remote ID to determine the Identity Provider. The second specifies the Identity Provider directly, which must then be supplied to horizon when configuring `horizon for WebSSO`_. The path must exactly match the path that will be used to access the keystone service. For example, if the identity provider you created in `Create an Identity Provider`_ is ``samltest`` and the protocol you created in `Create a Protocol`_ is ``saml2``, then the Locations will be: .. code-block:: apache <Location /v3/OS-FEDERATION/identity_providers/samltest/protocols/saml2/auth> Require valid-user AuthType [...] ... </Location> <Location /v3/auth/OS-FEDERATION/websso/saml2> Require valid-user AuthType [...] ... </Location> <Location /v3/auth/OS-FEDERATION/identity_providers/samltest/protocols/saml2/websso> Require valid-user AuthType [...] ... </Location> However, if you have configured the keystone service to use a virtual path such as ``/identity``, that part of the path should be included: .. code-block:: apache <Location /identity/v3/OS-FEDERATION/identity_providers/samltest/protocols/saml2/auth> Require valid-user AuthType [...] ... </Location> ... .. _horizon for WebSSO: websso.html Configure the auth module ~~~~~~~~~~~~~~~~~~~~~~~~~ ",,77,0
openstack%2Fkeystone~master~Ib09f127f47a0897cc1be03428bfae70f3f18e174,openstack/keystone,master,Ib09f127f47a0897cc1be03428bfae70f3f18e174,Reorganize guide on configuring a keystone SP,MERGED,2019-01-02 13:47:34.000000000,2019-01-07 22:26:39.000000000,2019-01-07 22:26:39.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 13:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/758578e4e61066bd7fe3e4a72b133ea86c973c5e', 'message': 'Reorganize guide on configuring a keystone SP\n\nThe federation guide on configuring keystone as a Service Provider is\ndisjointed and hard to follow. This patch reorganizes it as follows to\nimprove the flow by first moving the instructions on creating an IdP,\nmapping, and protocol in keystone to the beginning, since all other\nsteps in this guide depend on understanding what these objects are and\ndeciding on a name for them, and second by consolidating instructions on\ncreating role assignments into the section on mappings, since these two\nconcepts are informed by one another and splitting them apart makes\nit difficult to mentally connect them. It also cleans up and clarifies\nsome of the wording and pares down unnecessary tangents.\n\nPartial-bug: #1793374\n\nChange-Id: Ib09f127f47a0897cc1be03428bfae70f3f18e174\n'}, {'number': 2, 'created': '2019-01-02 22:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/86bc6ffdca24ab59a387a510f5d95dfc8f5175bf', 'message': 'Reorganize guide on configuring a keystone SP\n\nThe federation guide on configuring keystone as a Service Provider is\ndisjointed and hard to follow. This patch reorganizes it as follows to\nimprove the flow by first moving the instructions on creating an IdP,\nmapping, and protocol in keystone to the beginning, since all other\nsteps in this guide depend on understanding what these objects are and\ndeciding on a name for them, and second by consolidating instructions on\ncreating role assignments into the section on mappings, since these two\nconcepts are informed by one another and splitting them apart makes\nit difficult to mentally connect them. It also cleans up and clarifies\nsome of the wording and pares down unnecessary tangents.\n\nPartial-bug: #1793374\n\nChange-Id: Ib09f127f47a0897cc1be03428bfae70f3f18e174\n'}, {'number': 3, 'created': '2019-01-04 09:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c12557f67c3be1e588810f43bb1e6b51dd2b2d8', 'message': 'Reorganize guide on configuring a keystone SP\n\nThe federation guide on configuring keystone as a Service Provider is\ndisjointed and hard to follow. This patch reorganizes it as follows to\nimprove the flow by first moving the instructions on creating an IdP,\nmapping, and protocol in keystone to the beginning, since all other\nsteps in this guide depend on understanding what these objects are and\ndeciding on a name for them, and second by consolidating instructions on\ncreating role assignments into the section on mappings, since these two\nconcepts are informed by one another and splitting them apart makes\nit difficult to mentally connect them. It also cleans up and clarifies\nsome of the wording and pares down unnecessary tangents.\n\nPartial-bug: #1793374\n\nChange-Id: Ib09f127f47a0897cc1be03428bfae70f3f18e174\n'}, {'number': 4, 'created': '2019-01-07 15:57:06.000000000', 'files': ['doc/source/admin/federation/introduction.rst', 'doc/source/admin/federation/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d7bc6a36deefbe816390f94692fddb86bb2c6eb', 'message': 'Reorganize guide on configuring a keystone SP\n\nThe federation guide on configuring keystone as a Service Provider is\ndisjointed and hard to follow. This patch reorganizes it as follows to\nimprove the flow by first moving the instructions on creating an IdP,\nmapping, and protocol in keystone to the beginning, since all other\nsteps in this guide depend on understanding what these objects are and\ndeciding on a name for them, and second by consolidating instructions on\ncreating role assignments into the section on mappings, since these two\nconcepts are informed by one another and splitting them apart makes\nit difficult to mentally connect them. It also cleans up and clarifies\nsome of the wording and pares down unnecessary tangents.\n\nPartial-bug: #1793374\n\nChange-Id: Ib09f127f47a0897cc1be03428bfae70f3f18e174\n'}]",4,627972,4d7bc6a36deefbe816390f94692fddb86bb2c6eb,15,4,4,8482,,,0,"Reorganize guide on configuring a keystone SP

The federation guide on configuring keystone as a Service Provider is
disjointed and hard to follow. This patch reorganizes it as follows to
improve the flow by first moving the instructions on creating an IdP,
mapping, and protocol in keystone to the beginning, since all other
steps in this guide depend on understanding what these objects are and
deciding on a name for them, and second by consolidating instructions on
creating role assignments into the section on mappings, since these two
concepts are informed by one another and splitting them apart makes
it difficult to mentally connect them. It also cleans up and clarifies
some of the wording and pares down unnecessary tangents.

Partial-bug: #1793374

Change-Id: Ib09f127f47a0897cc1be03428bfae70f3f18e174
",git fetch https://review.opendev.org/openstack/keystone refs/changes/72/627972/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/federation/introduction.rst', 'doc/source/admin/federation/configure_federation.rst']",2,758578e4e61066bd7fe3e4a72b133ea86c973c5e,bug/1793374,".. _sp-prerequisites: Creating federation resources in keystone ----------------------------------------- You need to create three resources via the keystone API to identify the Identity Provider to keystone and align remote user attributes with keystone objects: * `Create an Identity Provider`_ * `Create a Mapping`_ * `Create a Protocol`_ See also the `keystone federation API reference`_. .. _keystone federation API reference: https://developer.openstack.org/api-ref/identity/v3-ext/#os-federation-api Create an Identity Provider ~~~~~~~~~~~~~~~~~~~~~~~~~~~Identity Provider, called the `entity ID` or the `remote ID`. For a SAML Identity Provider, it can found by querying its metadata endpoint: .. code-block:: console $ curl -s https://samltest.id/saml/idp | grep -o 'entityID="".*""' entityID=""https://samltest.id/saml/idp"" For an OpenID Connect IdP, it is the Identity Provider's Issuer Identifier. A remote ID must be globally unique: two identity providers cannot be associated with the same remote ID. The remote ID will usually appear as a URN but but need not be a resolvable URL. The local name, called ``samltest`` in our example, is decided by you and will be used by the mapping and protocol, and later for authentication. .. note:: An identity provider keystone object may have multiple ``remote-ids`` specified, this allows the same *keystone* identity provider resource to be used with multiple external identity providers. For example, an identity provider resource ``university-idp``, may have the following ``remote_ids``: ``['university-x', 'university-y', 'university-z']``. This removes the need to configure N identity providers in keystone. See also the `API reference on identity providers`_. .. _API reference on identity providers: https://developer.openstack.org/api-ref/identity/v3-ext/#identity-providers Create a Mapping ~~~~~~~~~~~~~~~~ Next, create a mapping. A mapping is a set of rules that link the attributes of a remote user to user properties that keystone understands. It is especially useful for granting remote users authorization to keystone resources, either by associating them with a local keystone group and inheriting its role assignments, or dynamically provisioning projects within keystone based on these rules.Mapping objects can be used multiple times by different combinations of Identity Provider and Protocol. As a simple example, create a mapping with a single rule to map all remote users to a local user in a single group in keystone: $ cat > rules.json <<EOF [ { ""local"": [ { ""user"": { ""name"": ""{0}"" }, ""group"": { ""domain"": { ""name"": ""Default"" }, ""name"": ""federated_users"" } } ], ""remote"": [ { ""type"": ""REMOTE_USER"" } ] } ] EOF $ openstack mapping create --rules rules.json samltest_mapping This mapping rule evaluates the ``REMOTE_USER`` variable set by the HTTPD auth module and uses it to fill in the name of the local user in keystone. It also ensures all remote users become effective members of the ``federated_users`` group, thereby inheriting the group's role assignments. In this example, the ``federated_users`` group must exist in the keystone Identity backend and must have a role assignment on some project, domain, or system in order for federated users to have an authorization in keystone. For example, to create the group: $ openstack group create federated_users Create a project these users should be assigned to: .. code-block:: console $ openstack project create federated_project Assign the group a ``member`` role in the project: .. code-block:: console $ openstack role add --group federated_users --project federated_project member Mappings can be quite complex. A detailed guide can be found on the :doc:`mapping_combinations` page. See also the `API reference on mapping rules`_. .. _API reference on mapping rules: https://developer.openstack.org/api-ref/identity/v3-ext/#mappings Create a Protocol ~~~~~~~~~~~~~~~~~ Now create a federation protocol. A federation protocol object links the Identity Provider to a mapping. $ openstack federation protocol create saml2 \ --mapping samltest_mapping --identity-provider samltest As `mentioned in the Prerequisites`_, the name you give the protocol is not arbitrary, it must be a valid auth method. See also the `API reference for federation protocols`_. .. _mentioned in the Prerequisites: sp-prerequisites .. _API reference for federation protocols: https://developer.openstack.org/api-ref/identity/v3-ext/#protocols Configuring an HTTPD auth module -------------------------------- This guide currently only includes examples for the Apache web server, but it possible to use SAML, OpenIDC, and other auth modules in other web servers. See the installation guides for running keystone behind Apache for `SUSE`_, `RedHat`_ or `Ubuntu`_. .. _`SUSE`: ../../install/keystone-install-obs.html#configure-the-apache-http-server .. _`RedHat`: ../../install/keystone-install-rdo.html#configure-the-apache-http-server .. _`Ubuntu`: ../../install/keystone-install-ubuntu.html#configure-the-apache-http-server If your Identity Provider is a SAML IdP, there are two main Apache modules that can be used as a SAML Service Provider: `mod_shib` and `mod_auth_mellon`. For an OpenID Connect Identity Provider, `mod_auth_openidc` is used. You can also use other auth modules such as kerberos, X.509, or others. Check the documentation for the provider you choose for detailed installation and configuration guidance. Depending on the Service Provider module you've chosen, you will need to install the applicable Apache module package and follow additional configuration steps. This guide contains examples for two major federation protocols: * SAML2.0 - see guides for the following implementations: * `Set up mod_shib`_. * `Set up mod_auth_mellon`_. * OpenID Connect: `Set up mod_auth_openidc`_. .. _`Set up mod_shib`: shibboleth.html .. _`Set up mod_auth_openidc`: openidc.html .. _`Set up mod_auth_mellon`: mellon.html Configuring Keystone -------------------- While the Apache module does the majority of the heavy lifting, minor changes are needed to allow keystone to allow and understand federated authentication. Add the Auth Method ~~~~~~~~~~~~~~~~~~~ Add the authentication methods to the ``[auth]`` section in ``keystone.conf``. The auth method here must have the same name as the protocol you created in `Create a Protocol`_. You should also remove ``external`` as an allowable method. .. code-block:: console [auth] methods = password,token,saml2,openid When finished configuring keystone, restart the keystone WSGI process or the web server: .. code-block:: console # systemctl restart apache2`Create an Identity Provider`_ and `Create a Protocol`_ respectively. If you are not the administrator, you must obtain this information from the administrator.","Configure Apache to use a federation capable authentication method ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ There is currently support for two major federation protocols: * SAML - Keystone supports the following implementations: * Shibboleth - see `Setup Shibboleth`_. * Mellon - see `Setup Mellon`_. * OpenID Connect - see `Setup OpenID Connect`_. .. _`Setup Shibboleth`: shibboleth.html .. _`Setup OpenID Connect`: openidc.html .. _`Setup Mellon`: mellon.html Configure keystone and Horizon for Single Sign-On ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * To configure horizon to access a federated keystone, follow the steps outlined at: `Keystone Federation and Horizon`_. .. _`Keystone Federation and Horizon`: websso.html Configure Federation in Keystone -------------------------------- Now that the Identity Provider and keystone are communicating we can start to configure ``federation``. 1. `Configure authentication drivers in keystone.conf`_ 2. `Create keystone groups and assign roles`_ 3. `Add Identity Provider(s), Mapping(s), and Protocol(s)`_ Configure authentication drivers in keystone.conf ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Add the authentication methods to the ``[auth]`` section in ``keystone.conf``. Names should be equal to protocol names added via Identity API v3. Here we use examples ``saml2`` and ``openid``. .. code-block:: ini [auth] methods = external,password,token,saml2,openid Create keystone groups and assign roles ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ As mentioned earlier, no new users will be added to the Identity backend, but the Identity Service requires group-based role assignments to authorize federated users. The federation mapping function will map the user into local Identity Service groups objects, and hence to local role assignments. Thus, it is required to create the necessary Identity Service groups that correspond to the Identity Provider's groups; additionally, these groups should be assigned roles on one or more projects or domains. You may be interested in more information on `group management <https://developer.openstack.org/api-ref/identity/v3/#create-group>`_ and `role assignments <https://developer.openstack.org/api-ref/identity/v3/#assign-role-to-group-on-project>`_, both of which are exposed to the CLI via `python-openstackclient <https://pypi.org/project/python-openstackclient/>`_. For example, create a new domain and project like this: .. code-block:: console $ openstack domain create federated_domain $ openstack project create federated_project --domain federated_domain And a new group like this: .. code-block:: console $ openstack group create federated_users Add the group to the domain and project: .. code-block:: console $ openstack role add --group federated_users --domain federated_domain Member $ openstack role add --group federated_users --project federated_project Member We'll later add a mapping that makes all federated users a part of this group and therefore members of the new domain. Add Identity Provider(s), Mapping(s), and Protocol(s) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ To utilize federation the following must be created in the Identity Service: * `Identity Provider`_ * `Mapping`_ * `Protocol`_ Read more about `federation in keystone <https://developer.openstack.org/api-ref/identity/v3-ext/#os-federation-api>`__. ~~~~~~~~~~~~~~~~~ Identity Provider ~~~~~~~~~~~~~~~~~IdP. For a SAML IdP it can found as the EntityDescriptor entityID in the IdP's provided metadata. If the IdP is a keystone IdP, it is the value set in that keystone's ``[saml]/idp_entity_id`` option. For an OpenID Connect IdP, it is the IdP's Issuer Identifier. It will usually appear as a URI but there is no requirement for it to resolve to anything and may be arbitrarily decided by the administrator of the IdP. The local name, here called 'samltest', is decided by you and will be used by the mapping and protocol, and later for authentication. A keystone identity provider may have multiple `remote_ids` specified, this allows the same *keystone* identity provider resource to be used with multiple external identity providers. For example, an identity provider resource ``university-idp``, may have the following `remote_ids`: ``['university-x', 'university-y', 'university-z']``. This removes the need to configure N identity providers in keystone. .. NOTE:: Remote IDs are globally unique. Two identity providers cannot be associated with the same remote ID. Once authenticated with the external identity provider, keystone will determine which identity provider and mapping to use based on the protocol and the value returned from the `remote_id_attribute` key. For example, if our identity provider is ``google``, the mapping used is ``google_mapping`` and the protocol is ``openid``. The identity provider's remote IDs would be: [``https://accounts.google.com``]. The `remote_id_attribute` value may be set to ``HTTP_OIDC_ISS``, since this value will always be ``https://accounts.google.com``. The motivation for this approach is that there will always be some data sent by the identity provider (in the assertion or claim) that uniquely identifies the identity provider. This removes the requirement for horizon to list all the identity providers that are trusted by keystone. Read more about `identity providers <https://developer.openstack.org/api-ref/identity/v3-ext/#identity-providers>`__. ~~~~~~~ Mapping ~~~~~~~ A mapping is a list of rules. The only Identity API objects that will support mapping are groups and users. Mapping adds a set of rules to map federation protocol attributes to Identity API objects. There are many different ways to setup as well as combine these rules. More information on rules can be found on the :doc:`mapping_combinations` page.Mapping objects can be used multiple times by different combinations of Identity Provider and Protocol. As a simple example, if keystone is your IdP, you can map a few known remote users to the group you already created: $ cat > rules.json <<EOF [ { ""local"": [ { ""user"": { ""name"": ""{0}"" }, ""group"": { ""domain"": { ""name"": ""Default"" }, ""name"": ""federated_users"" } } ], ""remote"": [ { ""type"": ""openstack_user"" }, { ""type"": ""openstack_user"", ""any_one_of"": [ ""demo"", ""alt_demo"" ] } ] } ] EOF $ openstack mapping create --rules rules.json samltest_mapping As another example, if Shibboleth is your IdP, the remote section should use REMOTE_USER as the remote type: $ cat > rules.json <<EOF [ { ""local"": [ { ""user"": { ""name"": ""{0}"" }, ""group"": { ""domain"": { ""name"": ""Default"" }, ""name"": ""federated_users"" } } ], ""remote"": [ { ""type"": ""REMOTE_USER"" } ] } ] EOF $ openstack mapping create --rules rules.json samltest_mapping Read more about `mapping <https://developer.openstack.org/api-ref/identity/v3-ext/#mappings>`__. ~~~~~~~~ Protocol ~~~~~~~~ A protocol contains information that dictates which Mapping rules to use for an incoming request made by an IdP. An IdP may have multiple supported protocols. $ openstack federation protocol create saml2 --mapping samltest_mapping --identity-provider samltest The name you give the protocol is not arbitrary. It must match the method name you gave in the ``[auth]/methods`` config option. When authenticating it will be referred to as the ``protocol_id``. Read more about `federation protocols <https://developer.openstack.org/api-ref/identity/v3-ext/#protocols>`__`Identity Provider`_ and `Protocol`_ respectively. If you are not the administrator, you must obtain this information from the administrator.",180,215
openstack%2Fopenstack-helm-infra~master~I416a283b8ac41f6b360d20aac1be8374c07badcd,openstack/openstack-helm-infra,master,I416a283b8ac41f6b360d20aac1be8374c07badcd,Elasticsearch: Update image for s3 bucket creation,MERGED,2019-01-07 19:53:24.000000000,2019-01-07 22:18:36.000000000,2019-01-07 22:18:36.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-07 19:53:24.000000000', 'files': ['elasticsearch/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/290df6222373982958df6a73caf938b0e740045b', 'message': 'Elasticsearch: Update image for s3 bucket creation\n\nThis updates the Elasticsearch image used for s3 bucket creation\nto use the same ceph daemon image used in the ceph-rgw chart now\nthat the Mimic release is supported\n\nChange-Id: I416a283b8ac41f6b360d20aac1be8374c07badcd\n'}]",0,629039,290df6222373982958df6a73caf938b0e740045b,9,5,1,17591,,,0,"Elasticsearch: Update image for s3 bucket creation

This updates the Elasticsearch image used for s3 bucket creation
to use the same ceph daemon image used in the ceph-rgw chart now
that the Mimic release is supported

Change-Id: I416a283b8ac41f6b360d20aac1be8374c07badcd
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/39/629039/1 && git format-patch -1 --stdout FETCH_HEAD,['elasticsearch/values.yaml'],1,290df6222373982958df6a73caf938b0e740045b,elasticsearch/s3-bucket-image, s3_bucket: docker.io/ceph/daemon:master-0b3eb04-mimic-centos-7-x86_64, s3_bucket: docker.io/ceph/daemon:tag-build-master-luminous-ubuntu-16.04,1,1
openstack%2Fopenstack-helm-infra~master~Ibf1da152f4aa78d425bbd00f514c2787d8ad9c5f,openstack/openstack-helm-infra,master,Ibf1da152f4aa78d425bbd00f514c2787d8ad9c5f,Fluentd: Add security context for pods/containers,MERGED,2019-01-03 20:20:26.000000000,2019-01-07 22:15:19.000000000,2019-01-07 22:15:19.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-01-03 20:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c29760dfc42707003b057ef581a0370f99d65952', 'message': 'Fluentd: Add security context for pod uids\n\nThis adds the security context snippet to the fluentd and\nfluentd exporter templates. This changes the users for these two\npods from root to the nobody user instead\n\nChange-Id: Ibf1da152f4aa78d425bbd00f514c2787d8ad9c5f\n'}, {'number': 2, 'created': '2019-01-03 22:10:58.000000000', 'files': ['fluent-logging/templates/deployment-fluentd.yaml', 'fluent-logging/templates/monitoring/prometheus/exporter-deployment.yaml', 'fluent-logging/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e7232313eaef246a9ec6d05adb783f48a995cbcd', 'message': 'Fluentd: Add security context for pods/containers\n\nThis adds the security context snippet to the fluentd and\nfluentd exporter templates. This changes the users for these two\npods from root to the nobody user instead\n\nThis also adds the container security context to explicitly set\nallowPrivilegeEscalation to false\n\nChange-Id: Ibf1da152f4aa78d425bbd00f514c2787d8ad9c5f\n'}]",0,628291,e7232313eaef246a9ec6d05adb783f48a995cbcd,18,5,2,17591,,,0,"Fluentd: Add security context for pods/containers

This adds the security context snippet to the fluentd and
fluentd exporter templates. This changes the users for these two
pods from root to the nobody user instead

This also adds the container security context to explicitly set
allowPrivilegeEscalation to false

Change-Id: Ibf1da152f4aa78d425bbd00f514c2787d8ad9c5f
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/91/628291/1 && git format-patch -1 --stdout FETCH_HEAD,"['fluent-logging/templates/deployment-fluentd.yaml', 'fluent-logging/templates/monitoring/prometheus/exporter-deployment.yaml', 'fluent-logging/values.yaml']",3,c29760dfc42707003b057ef581a0370f99d65952,fluentd/pod-uid, user: fluentd: uid: 65534 fluentd_exporter: uid: 65534,,7,0
openstack%2Fopenstack-helm-infra~master~I01e8df6e9d4b39859db32526c29b6397df14e21f,openstack/openstack-helm-infra,master,I01e8df6e9d4b39859db32526c29b6397df14e21f,Jobs: Move tenant-ceph check to periodic job,MERGED,2019-01-04 17:40:36.000000000,2019-01-07 22:11:00.000000000,2019-01-07 22:11:00.000000000,"[{'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-01-04 17:40:36.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2716e01c3faeb8d92ed11e489966a7d5bda7d511', 'message': 'Jobs: Move tenant-ceph check to periodic job\n\nThis moves the tenant-ceph job from a check to a periodic job\n\nChange-Id: I01e8df6e9d4b39859db32526c29b6397df14e21f\n'}]",0,628643,2716e01c3faeb8d92ed11e489966a7d5bda7d511,11,4,1,17591,,,0,"Jobs: Move tenant-ceph check to periodic job

This moves the tenant-ceph job from a check to a periodic job

Change-Id: I01e8df6e9d4b39859db32526c29b6397df14e21f
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/43/628643/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,2716e01c3faeb8d92ed11e489966a7d5bda7d511,gate/tenant-ceph, periodic: jobs: - openstack-helm-infra-tenant-ceph, - openstack-helm-infra-tenant-ceph: voting: false,3,2
openstack%2Frequirements~master~I5ed4400905ccd101974976b509737b0de07cf298,openstack/requirements,master,I5ed4400905ccd101974976b509737b0de07cf298,Limit oslo.privsep version to 1.30.1,MERGED,2019-01-07 09:18:02.000000000,2019-01-07 22:09:12.000000000,2019-01-07 22:09:11.000000000,"[{'_account_id': 6928}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 09:18:02.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1e822c793ff9a762d0f25f513da59eb6c78155f3', 'message': 'Limit oslo.privsep version to 1.30.1\n\nNew version 1.31.0 is causing some problems in Neutron repo.\nWith this version neutron-functional job is failing 100% times.\n\nLets lower oslo.privsep version for now to unblock Neutron gate\nuntil this issue will not be fixed.\n\nChange-Id: I5ed4400905ccd101974976b509737b0de07cf298\nRelated-Bug: #1810518\n'}]",0,628916,1e822c793ff9a762d0f25f513da59eb6c78155f3,11,4,1,11975,,,0,"Limit oslo.privsep version to 1.30.1

New version 1.31.0 is causing some problems in Neutron repo.
With this version neutron-functional job is failing 100% times.

Lets lower oslo.privsep version for now to unblock Neutron gate
until this issue will not be fixed.

Change-Id: I5ed4400905ccd101974976b509737b0de07cf298
Related-Bug: #1810518
",git fetch https://review.opendev.org/openstack/requirements refs/changes/16/628916/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,1e822c793ff9a762d0f25f513da59eb6c78155f3,bug/1810518,oslo.privsep===1.30.1,oslo.privsep===1.31.0,2,2
openstack%2Fopenstack-ansible~stable%2Frocky~I3f37969686fd1da88bed49706da5be2a52502f21,openstack/openstack-ansible,stable/rocky,I3f37969686fd1da88bed49706da5be2a52502f21,Update all SHAs for 18.1.3,MERGED,2018-12-23 16:38:32.000000000,2019-01-07 21:39:59.000000000,2019-01-07 21:39:59.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-23 16:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5cc1b3ba86fb454a3cf6a9999e8c0289920f01a1', 'message': 'Update all SHAs for 18.1.3\n\nThis patch:\n- updates all the roles to the latest available stable SHAs\n- copies the release notes from the updated roles into the integrated repo\n- updates all the OpenStack Service SHAs\n\nDepends-On: https://review.openstack.org/#/c/627078/\nChange-Id: I3f37969686fd1da88bed49706da5be2a52502f21\n'}, {'number': 2, 'created': '2019-01-07 09:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/03af13ef716ccbf05bd0ee1165980a93e5eb701a', 'message': 'Update all SHAs for 18.1.3\n\nThis patch:\n- updates all the roles to the latest available stable SHAs\n- copies the release notes from the updated roles into the integrated repo\n- updates all the OpenStack Service SHAs\n\nDepends-On: https://review.openstack.org/#/c/627078/\nChange-Id: I3f37969686fd1da88bed49706da5be2a52502f21\n'}, {'number': 3, 'created': '2019-01-07 11:35:35.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'inventory/group_vars/all/all.yml', 'ansible-role-requirements.yml', 'releasenotes/notes/add-nfs-support-5aacc81dbf3c2270.yaml', 'releasenotes/notes/galera-client-gpg-keys-8b674cee476885d0.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/904836512c84926ac1d706ae2211d182d41ff160', 'message': 'Update all SHAs for 18.1.3\n\nThis patch:\n- updates all the roles to the latest available stable SHAs\n- copies the release notes from the updated roles into the integrated repo\n- updates all the OpenStack Service SHAs\n\nDepends-On: https://review.openstack.org/#/c/627078/\nChange-Id: I3f37969686fd1da88bed49706da5be2a52502f21\n'}]",0,627079,904836512c84926ac1d706ae2211d182d41ff160,14,4,3,17068,,,0,"Update all SHAs for 18.1.3

This patch:
- updates all the roles to the latest available stable SHAs
- copies the release notes from the updated roles into the integrated repo
- updates all the OpenStack Service SHAs

Depends-On: https://review.openstack.org/#/c/627078/
Change-Id: I3f37969686fd1da88bed49706da5be2a52502f21
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/79/627079/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'inventory/group_vars/all/all.yml', 'ansible-role-requirements.yml', 'releasenotes/notes/add-nfs-support-5aacc81dbf3c2270.yaml', 'releasenotes/notes/galera-client-gpg-keys-8b674cee476885d0.yaml']",6,5cc1b3ba86fb454a3cf6a9999e8c0289920f01a1,release_osa,"--- upgrade: - | The data structure for ``galera_client_gpg_keys`` has been changed to be a dict passed directly to the applicable apt_key/rpm_key module. As such any overrides would need to be reviewed to ensure that they do not pass any key/value pairs which would cause the module to fail. - | The default values for ``galera_client_gpg_keys`` have been changed for all supported platforms will use vendored keys. This means that the task execution will no longer reach out to the internet to add the keys, making offline or proxy-based installations easier and more reliable. ",,68,51
openstack%2Fopenstack-ansible~stable%2Frocky~I5a0bfd465d93570b09175b39291cfe7791c91c3e,openstack/openstack-ansible,stable/rocky,I5a0bfd465d93570b09175b39291cfe7791c91c3e,Publish readable journal files in the gate,MERGED,2018-12-18 12:03:34.000000000,2019-01-07 21:39:58.000000000,2019-01-07 21:39:58.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-18 12:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/03f7ec0eb8c8043e919a6a511cc5bda4fbe78912', 'message': 'Publish readable journal files in the gate\n\nThe published journal files seem to be corrupted when compressed and\npublished to gate logs. Find the journal files and create a text file\nfor each that can be readable within a browser. Remove the original\njournal files afterwards to conserve space.\n\nChange-Id: I5a0bfd465d93570b09175b39291cfe7791c91c3e\n(cherry picked from commit 54fb1055e8fb82f40db0ef3320a3b7b250a32d1f)\n'}, {'number': 2, 'created': '2019-01-07 09:05:16.000000000', 'files': ['scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/59ee4a4ed54aa6eb642feabefe92e4e10f487711', 'message': 'Publish readable journal files in the gate\n\nThe published journal files seem to be corrupted when compressed and\npublished to gate logs. Find the journal files and create a text file\nfor each that can be readable within a browser. Remove the original\njournal files afterwards to conserve space.\n\nChange-Id: I5a0bfd465d93570b09175b39291cfe7791c91c3e\n(cherry picked from commit 54fb1055e8fb82f40db0ef3320a3b7b250a32d1f)\n'}]",0,625895,59ee4a4ed54aa6eb642feabefe92e4e10f487711,17,5,2,6816,,,0,"Publish readable journal files in the gate

The published journal files seem to be corrupted when compressed and
published to gate logs. Find the journal files and create a text file
for each that can be readable within a browser. Remove the original
journal files afterwards to conserve space.

Change-Id: I5a0bfd465d93570b09175b39291cfe7791c91c3e
(cherry picked from commit 54fb1055e8fb82f40db0ef3320a3b7b250a32d1f)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/95/625895/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,03f7ec0eb8c8043e919a6a511cc5bda4fbe78912,readable_gate_journals-stable/rocky," JOURNALCTL_CMD=""journalctl --output=short --file"" if [[ $filename =~ \.journal$ ]]; then ${JOURNALCTL_CMD} ${filename} > ${filename}.txt || echo ""WARNING: Could not rename ${filename}""; \ else mv ${filename} ${filename}.txt || echo ""WARNING: Could not rename ${filename}""; \ fi"," mv ${filename} ${filename}.txt || echo ""WARNING: Could not rename ${filename}""; \",6,1
openstack%2Ftripleo-heat-templates~master~I87568372e80bd8bdb17ae6396ffe5805e37359a7,openstack/tripleo-heat-templates,master,I87568372e80bd8bdb17ae6396ffe5805e37359a7,Bind mount docker-puppet.py in RO without SElinux labelling,MERGED,2019-01-04 09:50:33.000000000,2019-01-07 21:25:12.000000000,2019-01-07 21:25:12.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-01-04 09:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7092a863ffa7af1d9be18e91ef90a495cf281488', 'message': ""Bind mount docker-puppet.sh in RO without SElinux labelling\n\ndocker-puppet.sh doesn't need to be bind-mounted in read-write,\nread-only should be enough.\nTherefore, we don't need to relabel the script when running the\ncontainer.\n\nThe background of this patch can be found here:\nhttps://github.com/containers/libpod/issues/1844\n\nThe version of runc that is vendored in libpod contains is a bit old and\ndoesn't the labelling task isn't tied to the threads yet (done by\nhttps://github.com/opencontainers/runc/commit/aa3fee6c80f2817d47e912372267c74a96cde2bd)\n\nWe will request an update of runc in libpod but we also want to avoid\nuseless RW for this bind mount, which is the goal of this patch.\n\nChange-Id: I87568372e80bd8bdb17ae6396ffe5805e37359a7\n""}, {'number': 2, 'created': '2019-01-04 09:53:07.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21145a91b52f3450d2ae730071077c90cdf86c7b', 'message': ""Bind mount docker-puppet.py in RO without SElinux labelling\n\ndocker-puppet.sh doesn't need to be bind-mounted in read-write,\nread-only should be enough.\nTherefore, we don't need to relabel the script when running the\ncontainer.\n\nThe background of this patch can be found here:\nhttps://github.com/containers/libpod/issues/1844\n\nThe version of runc that is vendored in libpod contains is a bit old and\ndoesn't the labelling task isn't tied to the threads yet (done by\nhttps://github.com/opencontainers/runc/commit/aa3fee6c80f2817d47e912372267c74a96cde2bd)\n\nWe will request an update of runc in libpod but we also want to avoid\nuseless RW for this bind mount, which is the goal of this patch.\n\nNote: we also switch /etc/config.pp and /etc/puppet/ to RO, without labelling\nas well.\n\nChange-Id: I87568372e80bd8bdb17ae6396ffe5805e37359a7\n""}]",4,628376,21145a91b52f3450d2ae730071077c90cdf86c7b,14,8,2,3153,,,0,"Bind mount docker-puppet.py in RO without SElinux labelling

docker-puppet.sh doesn't need to be bind-mounted in read-write,
read-only should be enough.
Therefore, we don't need to relabel the script when running the
container.

The background of this patch can be found here:
https://github.com/containers/libpod/issues/1844

The version of runc that is vendored in libpod contains is a bit old and
doesn't the labelling task isn't tied to the threads yet (done by
https://github.com/opencontainers/runc/commit/aa3fee6c80f2817d47e912372267c74a96cde2bd)

We will request an update of runc in libpod but we also want to avoid
useless RW for this bind mount, which is the goal of this patch.

Note: we also switch /etc/config.pp and /etc/puppet/ to RO, without labelling
as well.

Change-Id: I87568372e80bd8bdb17ae6396ffe5805e37359a7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/76/628376/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,7092a863ffa7af1d9be18e91ef90a495cf281488,docker-puppet.sh," '--volume', '%s:%s:r' % (sh_script, sh_script) ]"," '--volume', '%s:%s:rw,z' % (sh_script, sh_script) ]",1,1
openstack%2Fnova~master~I18f749e6089f776fcca386daea0e479b5382a44b,openstack/nova,master,I18f749e6089f776fcca386daea0e479b5382a44b,Run nova-lvm job on nova/privsep/* changes,MERGED,2019-01-03 21:43:29.000000000,2019-01-07 21:15:55.000000000,2019-01-07 21:15:55.000000000,"[{'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-03 21:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2b4af7dc071eab559d09351139bdec74a6fee39', 'message': ""Run nova-lvm job on nova/privsep/* changes\n\nAs seen from bug 1808247, there is something about\nthe [libvirt]/image_type=lvm configuration that\ntickles privsep in ways that our normal integrated\ngate jobs don't, so this adds nova/privsep/* to the\nwhitelist of files to trigger the nova-lvm job.\n\nChange-Id: I18f749e6089f776fcca386daea0e479b5382a44b\nRelated-Bug: #1808247\n""}, {'number': 2, 'created': '2019-01-03 22:21:36.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/f54b43c8b9a30948a270713e9503b54cc1bebc75', 'message': ""Run nova-lvm job on nova/privsep/* changes\n\nAs seen from bug 1808247, there is something about\nthe [libvirt]/image_type=lvm configuration that\ntickles privsep in ways that our normal integrated\ngate jobs don't, so this adds nova/privsep/* to the\nwhitelist of files to trigger the nova-lvm job.\n\nChange-Id: I18f749e6089f776fcca386daea0e479b5382a44b\nRelated-Bug: #1808247\n""}]",0,628306,f54b43c8b9a30948a270713e9503b54cc1bebc75,21,14,2,6873,,,0,"Run nova-lvm job on nova/privsep/* changes

As seen from bug 1808247, there is something about
the [libvirt]/image_type=lvm configuration that
tickles privsep in ways that our normal integrated
gate jobs don't, so this adds nova/privsep/* to the
whitelist of files to trigger the nova-lvm job.

Change-Id: I18f749e6089f776fcca386daea0e479b5382a44b
Related-Bug: #1808247
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/628306/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c2b4af7dc071eab559d09351139bdec74a6fee39,bug/1808247, # that is not in nova/virt/libvirt/* or nova/privsep/* (besides the actual # zuul playbook and tempest rc files so this can be self-testing). irrelevant-files: - ^(?!.zuul.yaml)(?!playbooks/legacy/nova-lvm/)(?!devstack/tempest-dsvm-lvm-rc)(?!nova/virt/libvirt/)(?!nova/privsep/).*$, # that is not in the nova/virt/libvirt/* tree (besides the actual zuul # playbook and tempest rc files so this can be self-testing). irrelevant-files: - ^(?!.zuul.yaml)(?!playbooks/legacy/nova-lvm/)(?!devstack/tempest-dsvm-lvm-rc)(?!nova/virt/libvirt/).*$,3,3
openstack%2Fopenstack-ansible-os_swift~master~I6d037c45aee8b54502a2e3f3add56b23be34109d,openstack/openstack-ansible-os_swift,master,I6d037c45aee8b54502a2e3f3add56b23be34109d,Remove unnecessary package install duplication,MERGED,2018-10-30 19:46:36.000000000,2019-01-07 21:05:51.000000000,2019-01-07 21:05:51.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-10-30 19:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/df4f759a517ceb000bef9e5e3dcea79092a55f30', 'message': 'Remove unnecessary package install duplication\n\nCurrently the devel packages are installed everywhere,\nbut they only need to be where the wheels are built.\n\nAlso, there is already a task to install the packages\nneeded on the target hosts when installing - so we do\nnot need to give the same list to the venv install role\nbecause they will already have been installed.\n\nFinally, we remove the unnecessary installation of the\ncompiling packages because the python venv build role\nalready does it.\n\nDepends-On: https://review.openstack.org/613585\nChange-Id: I6d037c45aee8b54502a2e3f3add56b23be34109d\n'}, {'number': 2, 'created': '2018-11-01 14:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/115ca2bbe55f338597e3ede37b9397b21834df30', 'message': 'Remove unnecessary package install duplication\n\nCurrently the devel packages are installed everywhere,\nbut they only need to be where the wheels are built.\n\nAlso, there is already a task to install the packages\nneeded on the target hosts when installing - so we do\nnot need to give the same list to the venv install role\nbecause they will already have been installed.\n\nWe remove the unnecessary installation of the compiling\npackages because the python venv build role already does\nit.\n\nWe also re-order the package lists alphabetically to\nmake them easier to follow.\n\nDepends-On: https://review.openstack.org/613585\nChange-Id: I6d037c45aee8b54502a2e3f3add56b23be34109d\n'}, {'number': 3, 'created': '2018-11-01 14:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/bd9dc99e6cd0e1b5d8b1eb701265a54880cb8bd8', 'message': ""Remove unnecessary package install duplication\n\nCurrently the devel packages are installed everywhere,\nbut they only need to be where the wheels are built.\n\nAlso, there is already a task to install the packages\nneeded on the target hosts when installing - so we do\nnot need to give the same list to the venv install role\nbecause they will already have been installed.\n\nWe remove the unnecessary installation of the compiling\npackages because the python venv build role already does\nit. We also remove the curl and which packages as they\nappear to be unused. The git package is moved to the\ndevel package list as it's only used there.\n\nWe also re-order the package lists alphabetically to\nmake them easier to follow.\n\nDepends-On: https://review.openstack.org/613585\nChange-Id: I6d037c45aee8b54502a2e3f3add56b23be34109d\n""}, {'number': 4, 'created': '2018-12-04 11:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/817d5b9c9bd9678e4e6ca3e1875b3135883166e6', 'message': ""Remove unnecessary package install duplication\n\nCurrently the devel packages are installed everywhere,\nbut they only need to be where the wheels are built.\n\nAlso, there is already a task to install the packages\nneeded on the target hosts when installing - so we do\nnot need to give the same list to the venv install role\nbecause they will already have been installed.\n\nWe remove the unnecessary installation of the compiling\npackages because the python venv build role already does\nit. We also remove the curl and which packages as they\nappear to be unused. The git package is moved to the\ndevel package list as it's only used there.\n\nWe also re-order the package lists alphabetically to\nmake them easier to follow.\n\nDepends-On: https://review.openstack.org/613585\nChange-Id: I6d037c45aee8b54502a2e3f3add56b23be34109d\n""}, {'number': 5, 'created': '2019-01-03 09:28:21.000000000', 'files': ['vars/source_install.yml', 'vars/redhat-7.yml', 'vars/debian.yml', 'tasks/swift_install_source.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/430932f274b51e58884065bbefc2c572eb77c94d', 'message': ""Remove unnecessary package install duplication\n\nCurrently the devel packages are installed everywhere,\nbut they only need to be where the wheels are built.\n\nAlso, there is already a task to install the packages\nneeded on the target hosts when installing - so we do\nnot need to give the same list to the venv install role\nbecause they will already have been installed.\n\nWe remove the unnecessary installation of the compiling\npackages because the python venv build role already does\nit. We also remove the curl and which packages as they\nappear to be unused. The git package is moved to the\ndevel package list as it's only used there.\n\nWe also re-order the package lists alphabetically to\nmake them easier to follow.\n\nDepends-On: https://review.openstack.org/613585\nChange-Id: I6d037c45aee8b54502a2e3f3add56b23be34109d\n""}]",2,614342,430932f274b51e58884065bbefc2c572eb77c94d,45,6,5,6816,,,0,"Remove unnecessary package install duplication

Currently the devel packages are installed everywhere,
but they only need to be where the wheels are built.

Also, there is already a task to install the packages
needed on the target hosts when installing - so we do
not need to give the same list to the venv install role
because they will already have been installed.

We remove the unnecessary installation of the compiling
packages because the python venv build role already does
it. We also remove the curl and which packages as they
appear to be unused. The git package is moved to the
devel package list as it's only used there.

We also re-order the package lists alphabetically to
make them easier to follow.

Depends-On: https://review.openstack.org/613585
Change-Id: I6d037c45aee8b54502a2e3f3add56b23be34109d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/42/614342/5 && git format-patch -1 --stdout FETCH_HEAD,"['vars/source_install.yml', 'tasks/swift_install_source.yml', 'vars/suse.yml']",3,df4f759a517ceb000bef9e5e3dcea79092a55f30,reduce-unnecessary-package-installs,, - gcc - python-devel,2,4
openstack%2Fcharm-ceph-proxy~master~I06fc6263ba31f7e37b45b1bd0af658bcd602254d,openstack/charm-ceph-proxy,master,I06fc6263ba31f7e37b45b1bd0af658bcd602254d,Remove ch-tests from make sync command,MERGED,2019-01-07 20:32:25.000000000,2019-01-07 20:58:19.000000000,2019-01-07 20:58:19.000000000,"[{'_account_id': 11805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 20:32:25.000000000', 'files': ['Makefile'], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/acd93c43959c3c2e927d130b926447b874f00d76', 'message': 'Remove ch-tests from make sync command\n\nThe tests/charm-helpers contents were removed in the last cycle\nbut the corresponding sync tool was not updated for this charm.\n\nChange-Id: I06fc6263ba31f7e37b45b1bd0af658bcd602254d\n'}]",0,629044,acd93c43959c3c2e927d130b926447b874f00d76,7,2,1,20635,,,0,"Remove ch-tests from make sync command

The tests/charm-helpers contents were removed in the last cycle
but the corresponding sync tool was not updated for this charm.

Change-Id: I06fc6263ba31f7e37b45b1bd0af658bcd602254d
",git fetch https://review.opendev.org/openstack/charm-ceph-proxy refs/changes/44/629044/1 && git format-patch -1 --stdout FETCH_HEAD,['Makefile'],1,acd93c43959c3c2e927d130b926447b874f00d76,update-sync,, $(PYTHON) bin/charm_helpers_sync.py -c charm-helpers-tests.yaml,0,1
openstack%2Fkolla-ansible~stable%2Fqueens~I7670544f4bc41c93ac1d081486502f9ffb8f2286,openstack/kolla-ansible,stable/queens,I7670544f4bc41c93ac1d081486502f9ffb8f2286,Fix ironic inspector dnsmasq listening interface,MERGED,2019-01-07 09:42:48.000000000,2019-01-07 20:49:12.000000000,2019-01-07 20:49:12.000000000,"[{'_account_id': 10068}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 09:42:48.000000000', 'files': ['ansible/roles/ironic/templates/ironic-dnsmasq.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/968368b18dc7a5141fcae6b37cf2cc2c1d70984b', 'message': ""Fix ironic inspector dnsmasq listening interface\n\nThe variable 'ironic_dnsmasq_interface' is used to configure the interface\nused by the ironic inspector dnsmasq service for DHCP on the inspection\nnetwork. It is being used correctly in inspector.conf, but not in the\ndnsmasq configuration file, which uses api_interface. This change modifies\nthe dnsmasq configuration file to also use ironic_dnsmasq_interface.\n\nChange-Id: I7670544f4bc41c93ac1d081486502f9ffb8f2286\nCloses-Bug: #1785574\n(cherry picked from commit ea2cda217ed3d3fbb1a829a82509dbfd79622e8d)\n""}]",0,628920,968368b18dc7a5141fcae6b37cf2cc2c1d70984b,8,4,1,27420,,,0,"Fix ironic inspector dnsmasq listening interface

The variable 'ironic_dnsmasq_interface' is used to configure the interface
used by the ironic inspector dnsmasq service for DHCP on the inspection
network. It is being used correctly in inspector.conf, but not in the
dnsmasq configuration file, which uses api_interface. This change modifies
the dnsmasq configuration file to also use ironic_dnsmasq_interface.

Change-Id: I7670544f4bc41c93ac1d081486502f9ffb8f2286
Closes-Bug: #1785574
(cherry picked from commit ea2cda217ed3d3fbb1a829a82509dbfd79622e8d)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/20/628920/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ironic/templates/ironic-dnsmasq.conf.j2'],1,968368b18dc7a5141fcae6b37cf2cc2c1d70984b,bug/1785574-stable/queens,interface={{ ironic_dnsmasq_interface }},interface={{ api_interface }},1,1
openstack%2Fsahara~master~Ib9e855c11f03239e70306d12e96194549d2dc0f3,openstack/sahara,master,Ib9e855c11f03239e70306d12e96194549d2dc0f3,APIv2 - api-ref documentation for APIv2,MERGED,2018-12-11 11:37:49.000000000,2019-01-07 20:42:06.000000000,2019-01-07 20:42:06.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2018-12-11 11:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6cce80f5c4989b6402bb9f3def1158f5d111d6e5', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 2, 'created': '2018-12-13 11:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a81e9e6ff2df81137810bff8105e4cc3858eb973', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 3, 'created': '2018-12-13 16:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/521c83d9bab565e890ab1b1b44dc34ed01835f15', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 4, 'created': '2018-12-13 17:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4155348e451bbbf6cfade1fcc0621ea81bd4e92f', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 5, 'created': '2018-12-14 12:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8f8f4c4f0af213d0b5648992e04435f38d2bd0f8', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 6, 'created': '2018-12-26 13:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/408ca39d16c1df9620c5119c1a0fd0f749633d27', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 7, 'created': '2018-12-26 14:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c46eb0193f0e3c3e3a73eede49aa20b42ad4e5ed', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 8, 'created': '2019-01-03 11:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7d6f63f48ef1e9572228fc60655a21af402ccfcd', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 9, 'created': '2019-01-03 15:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7b0d69fa8225700889459a237fd60a8efa56f9fe', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 10, 'created': '2019-01-03 18:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9f283d5ec2df013094f561a5af316aaa5bda9f51', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}, {'number': 11, 'created': '2019-01-07 17:59:32.000000000', 'files': ['api-ref/source/v2/samples/jobs/job-update-request.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-show-response.json', 'api-ref/source/v2/samples/image-registry/image-tags-delete-request.json', 'api-ref/source/v2/samples/data-sources/data-sources-list-response.json', 'api-ref/source/v2/samples/job-templates/job-template-update-response.json', 'api-ref/source/v2/samples/cluster-templates/cluster-templates-list-response.json', 'api-ref/source/v2/samples/event-log/cluster-progress-response.json', 'api-ref/source/v2/samples/clusters/cluster-update-request.json', 'api-ref/source/v2/samples/job-binaries/update-response.json', 'api-ref/source/v2/samples/plugins/plugin-version-show-response.json', 'api-ref/source/v2/samples/job-binaries/create-response.json', 'api-ref/source/v2/samples/jobs/cancel-response.json', 'api-ref/source/v2/samples/clusters/multiple-clusters-create-response.json', 'api-ref/source/v2/samples/plugins/plugin-update-response.json', 'api-ref/source/v2/samples/job-types/job-types-list-response.json', 'api-ref/source/v2/samples/plugins/plugin-show-response.json', 'api-ref/source/v2/cluster-templates.inc', 'api-ref/source/v2/samples/node-group-templates/node-group-templates-list-response.json', 'api-ref/source/v2/samples/plugins/plugin-update-request.json', 'api-ref/source/v2/node-group-templates.inc', 'api-ref/source/v2/samples/job-templates/job-template-show-response.json', 'api-ref/source/v2/samples/data-sources/data-source-show-response.json', 'api-ref/source/index.rst', 'api-ref/source/v2/samples/job-templates/job-template-create-response.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-update-response.json', 'api-ref/source/v2/index.rst', 'api-ref/source/v2/samples/jobs/job-request.json', 'lower-constraints.txt', 'api-ref/source/v2/samples/image-registry/image-register-request.json', 'api-ref/source/v2/samples/image-registry/image-tags-delete-response.json', 'api-ref/source/v2/data-sources.inc', 'api-ref/source/v2/job-types.inc', 'api-ref/source/v2/samples/data-sources/data-source-register-hdfs-request.json', 'api-ref/source/v2/samples/clusters/cluster-create-request.json', 'api-ref/source/v2/samples/plugins/plugins-list-response.json', 'api-ref/source/v2/samples/jobs/job-response.json', 'api-ref/source/v2/samples/data-sources/data-source-update-response.json', 'api-ref/source/v2/samples/job-binaries/show-response.json', 'api-ref/source/v2/samples/image-registry/image-show-response.json', 'api-ref/source/v2/samples/clusters/cluster-create-response.json', 'api-ref/source/v2/samples/clusters/cluster-update-response.json', 'api-ref/source/v2/samples/job-templates/job-template-create-request.json', 'api-ref/source/v2/samples/job-templates/job-template-update-request.json', 'api-ref/source/v2/samples/job-binaries/show-data-response', 'api-ref/source/v2/jobs.inc', 'api-ref/source/v2/plugins.inc', 'api-ref/source/v2/samples/cluster-templates/cluster-template-update-response.json', 'api-ref/source/v1.1/index.rst', 'api-ref/source/v2/samples/data-sources/data-source-register-swift-response.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-create-response.json', 'api-ref/source/v2/samples/data-sources/data-source-register-swift-request.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-create-response.json', 'api-ref/source/v2/samples/image-registry/images-list-response.json', 'api-ref/source/v2/samples/data-sources/data-source-update-request.json', 'api-ref/source/v2/samples/job-templates/job-templates-list-response.json', 'api-ref/source/v2/image-registry.inc', 'api-ref/source/v2/clusters.inc', 'api-ref/source/v2/samples/clusters/cluster-scale-response.json', 'api-ref/source/v2/samples/image-registry/image-tags-add-request.json', 'api-ref/source/v2/samples/jobs/job-update-response.json', 'api-ref/source/v2/job-binaries.inc', 'api-ref/source/v2/samples/image-registry/image-register-response.json', 'api-ref/source/v2/event-log.inc', 'api-ref/source/v2/samples/clusters/cluster-show-response.json', 'api-ref/source/v2/samples/jobs/list-response.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-show-response.json', 'api-ref/source/v2/samples/clusters/multiple-clusters-create-request.json', 'api-ref/source/v2/job-templates.inc', 'api-ref/source/v2/samples/clusters/clusters-list-response.json', 'api-ref/source/v2/samples/clusters/cluster-scale-request.json', 'api-ref/source/v2/samples/job-binaries/create-request.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-create-request.json', 'api-ref/source/v2/samples/image-registry/image-tags-add-response.json', 'api-ref/source/v2/parameters.yaml', 'api-ref/source/v2/samples/job-binaries/update-request.json', 'api-ref/source/v2/samples/data-sources/data-source-register-hdfs-response.json', 'api-ref/source/v2/samples/job-binaries/list-response.json', 'doc/requirements.txt', 'api-ref/source/v2/samples/cluster-templates/cluster-template-update-request.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-create-request.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-update-request.json'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0b8002a99d800412268dd9f5796f08aeacb9974c', 'message': 'APIv2 - api-ref documentation for APIv2\n\nWriting api-ref for APIv2.\n\nStory: #2002102\nTask: #19780\n\nChange-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3\n'}]",8,624365,0b8002a99d800412268dd9f5796f08aeacb9974c,44,4,11,8932,,,0,"APIv2 - api-ref documentation for APIv2

Writing api-ref for APIv2.

Story: #2002102
Task: #19780

Change-Id: Ib9e855c11f03239e70306d12e96194549d2dc0f3
",git fetch https://review.opendev.org/openstack/sahara refs/changes/65/624365/9 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v2/samples/jobs/job-update-request.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-show-response.json', 'api-ref/source/v2/samples/image-registry/image-tags-delete-request.json', 'api-ref/source/v2/samples/data-sources/data-sources-list-response.json', 'api-ref/source/v2/samples/job-templates/job-template-update-response.json', 'api-ref/source/v2/samples/cluster-templates/cluster-templates-list-response.json', 'api-ref/source/v2/samples/event-log/cluster-progress-response.json', 'api-ref/source/v2/samples/clusters/cluster-update-request.json', 'api-ref/source/v2/samples/job-binaries/update-response.json', 'api-ref/source/v2/samples/plugins/plugin-version-show-response.json', 'api-ref/source/v2/samples/job-binaries/create-response.json', 'api-ref/source/v2/samples/jobs/cancel-response.json', 'api-ref/source/v2/samples/clusters/multiple-clusters-create-response.json', 'api-ref/source/v1.1/job-executions.inc', 'api-ref/source/v2/samples/plugins/plugin-update-response.json', 'api-ref/source/v2/samples/job-types/job-types-list-response.json', 'api-ref/source/v2/samples/job-templates/job-template-execute-request.json', 'api-ref/source/v2/samples/plugins/plugin-show-response.json', 'api-ref/source/v2/cluster-templates.inc', 'api-ref/source/v2/samples/node-group-templates/node-group-templates-list-response.json', 'api-ref/source/v2/samples/plugins/plugin-update-request.json', 'api-ref/source/v2/node-group-templates.inc', 'api-ref/source/v2/samples/job-templates/job-template-show-response.json', 'api-ref/source/v2/samples/data-sources/data-source-show-response.json', 'api-ref/source/index.rst', 'api-ref/source/v2/samples/job-templates/job-template-create-response.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-update-response.json', 'api-ref/source/v2/index.rst', 'api-ref/source/v2/samples/image-registry/image-register-request.json', 'api-ref/source/v2/samples/image-registry/image-tags-delete-response.json', 'api-ref/source/v2/data-sources.inc', 'api-ref/source/v2/job-types.inc', 'api-ref/source/v2/samples/data-sources/data-source-register-hdfs-request.json', 'api-ref/source/v2/samples/clusters/cluster-create-request.json', 'api-ref/source/v2/samples/plugins/plugins-list-response.json', 'api-ref/source/v2/samples/jobs/job-response.json', 'api-ref/source/v2/samples/data-sources/data-source-update-response.json', 'api-ref/source/v2/samples/job-binaries/show-response.json', 'api-ref/source/v2/samples/image-registry/image-show-response.json', 'api-ref/source/v2/samples/clusters/cluster-create-response.json', 'api-ref/source/v2/samples/clusters/cluster-update-response.json', 'api-ref/source/v2/samples/job-templates/job-template-create-request.json', 'api-ref/source/v2/samples/job-templates/job-template-update-request.json', 'api-ref/source/v2/samples/job-binaries/show-data-response', 'api-ref/source/v2/jobs.inc', 'api-ref/source/v2/plugins.inc', 'api-ref/source/v2/samples/cluster-templates/cluster-template-update-response.json', 'api-ref/source/v1.1/jobs.inc', 'api-ref/source/v2/samples/data-sources/data-source-register-swift-response.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-create-response.json', 'api-ref/source/v2/samples/data-sources/data-source-register-swift-request.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-create-response.json', 'api-ref/source/v2/samples/image-registry/images-list-response.json', 'api-ref/source/v2/samples/data-sources/data-source-update-request.json', 'api-ref/source/v2/samples/job-templates/job-templates-list-response.json', 'api-ref/source/v2/image-registry.inc', 'api-ref/source/v2/clusters.inc', 'api-ref/source/v2/samples/clusters/cluster-scale-response.json', 'api-ref/source/v2/samples/image-registry/image-tags-add-request.json', 'api-ref/source/v2/samples/jobs/job-update-response.json', 'api-ref/source/v2/job-binaries.inc', 'api-ref/source/v2/samples/image-registry/image-register-response.json', 'api-ref/source/v2/event-log.inc', 'api-ref/source/v2/samples/clusters/cluster-show-response.json', 'api-ref/source/v2/samples/jobs/list-response.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-show-response.json', 'api-ref/source/v2/samples/clusters/multiple-clusters-create-request.json', 'api-ref/source/v2/job-templates.inc', 'api-ref/source/v2/samples/clusters/clusters-list-response.json', 'api-ref/source/v2/samples/clusters/cluster-scale-request.json', 'api-ref/source/v2/samples/job-binaries/create-request.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-create-request.json', 'api-ref/source/v2/samples/image-registry/image-tags-add-response.json', 'api-ref/source/v2/parameters.yaml', 'api-ref/source/v2/samples/job-binaries/update-request.json', 'api-ref/source/v2/samples/data-sources/data-source-register-hdfs-response.json', 'api-ref/source/v2/samples/job-templates/job-template-execute-response.json', 'api-ref/source/v2/samples/job-binaries/list-response.json', 'api-ref/source/v2/samples/cluster-templates/cluster-template-update-request.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-create-request.json', 'api-ref/source/v2/samples/node-group-templates/node-group-template-update-request.json']",81,6cce80f5c4989b6402bb9f3def1158f5d111d6e5,api_v2_ref,"{ ""plugin_name"": ""vanilla"", ""hadoop_version"": ""2.7.1"", ""node_processes"": [ ""datanode"" ], ""name"": ""new"", ""floating_ip_pool"": ""033debed-aeb8-488c-b7d0-adb74c61faa5"", ""flavor_id"": ""2"" } ",,6802,5
openstack%2Fpuppet-manila~stable%2Fqueens~I745a170ac4458a3f13efc255fc37540a11b54274,openstack/puppet-manila,stable/queens,I745a170ac4458a3f13efc255fc37540a11b54274,Updating nova and neutron configuration,MERGED,2019-01-07 13:39:16.000000000,2019-01-07 20:31:40.000000000,2019-01-07 20:31:40.000000000,"[{'_account_id': 3153}, {'_account_id': 6413}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27419}]","[{'number': 1, 'created': '2019-01-07 13:39:16.000000000', 'files': ['spec/classes/manila_network_neutron_spec.rb', 'manifests/compute/nova.pp', 'releasenotes/notes/update-nova-neutron-with-keystonev3-3386a497d476d7d8.yaml', 'manifests/network/neutron.pp', 'spec/classes/manila_compute_nova_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/d4eaa2736bcc8e3d2188cf9f457f4a09299c7c13', 'message': 'Updating nova and neutron configuration\n\nSince we stopped support of keystonev2, we need to be able to specify a\ndomain in neutron and nova configuration. Might as well add all the\noptions and remove the deprecated ones.\n\nCo-authored-by: Victoria Martinez de la Cruz <victoria@redhat.com>\nChange-Id: I745a170ac4458a3f13efc255fc37540a11b54274\nCloses-Bug: #1802393\n(cherry picked from commit 5ae8e2882b3e8229ea0007938315f5145e4f5f8a)\n'}]",0,628964,d4eaa2736bcc8e3d2188cf9f457f4a09299c7c13,9,5,1,6413,,,0,"Updating nova and neutron configuration

Since we stopped support of keystonev2, we need to be able to specify a
domain in neutron and nova configuration. Might as well add all the
options and remove the deprecated ones.

Co-authored-by: Victoria Martinez de la Cruz <victoria@redhat.com>
Change-Id: I745a170ac4458a3f13efc255fc37540a11b54274
Closes-Bug: #1802393
(cherry picked from commit 5ae8e2882b3e8229ea0007938315f5145e4f5f8a)
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/64/628964/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/manila_network_neutron_spec.rb', 'manifests/compute/nova.pp', 'releasenotes/notes/update-nova-neutron-with-keystonev3-3386a497d476d7d8.yaml', 'manifests/network/neutron.pp', 'spec/classes/manila_compute_nova_spec.rb']",5,d4eaa2736bcc8e3d2188cf9f457f4a09299c7c13,bug/1802393,"require 'spec_helper' describe 'manila::compute::nova' do shared_examples 'manila::nova' do context 'with default parameters' do it 'configures manila compute nova' do is_expected.to contain_manila_config('nova/insecure').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/auth_url').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/auth_type').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/cafile').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/region_name').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/endpoint_type').with_value('<SERVICE DEFAULT>') # These should be added only when auth_type is 'password' is_expected.not_to contain_manila_config('nova/user_domain_name') is_expected.not_to contain_manila_config('nova/project_domain_name') is_expected.not_to contain_manila_config('nova/project_name') is_expected.not_to contain_manila_config('nova/username') is_expected.not_to contain_manila_config('nova/password') end end context 'with overridden parameters' do let :params do { :insecure => true, :auth_url => 'http://127.0.0.2:5000/', :auth_type => 'password', :cafile => '/etc/ssl/certs/ca.crt', :region_name => 'RegionOne', :endpoint_type => 'publicURL', :username => 'novav1', :password => '123123', } end it 'configures manila nova with overridden parameters' do is_expected.to contain_manila_config('nova/insecure').with_value(true) is_expected.to contain_manila_config('nova/auth_url').with_value('http://127.0.0.2:5000/') is_expected.to contain_manila_config('nova/auth_type').with_value('password') is_expected.to contain_manila_config('nova/cafile').with_value('/etc/ssl/certs/ca.crt') is_expected.to contain_manila_config('nova/user_domain_name').with_value('Default') is_expected.to contain_manila_config('nova/project_domain_name').with_value('Default') is_expected.to contain_manila_config('nova/project_name').with_value('service') is_expected.to contain_manila_config('nova/region_name').with_value('RegionOne') is_expected.to contain_manila_config('nova/endpoint_type').with_value('publicURL') is_expected.to contain_manila_config('nova/username').with_value('novav1') is_expected.to contain_manila_config('nova/password').with_value('123123').with_secret(true) end end context 'with deprecated parameters' do let :params do { :nova_api_insecure => true, :nova_ca_certificates_file => '/foo/ssl/certs/ca.crt', :auth_type => 'password', :nova_admin_tenant_name => 'service2', :nova_admin_username => 'novav2', :nova_admin_password => '321321', } end it 'configures manila compute nova with deprecated parameters' do is_expected.to contain_manila_config('nova/auth_type').with_value('password') is_expected.to contain_manila_config('nova/insecure').with_value(true) is_expected.to contain_manila_config('nova/cafile').with_value('/foo/ssl/certs/ca.crt') is_expected.to contain_manila_config('nova/project_name').with_value('service2') is_expected.to contain_manila_config('nova/username').with_value('novav2') is_expected.to contain_manila_config('nova/password').with_value('321321') end end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts()) end it_behaves_like 'manila::nova' end end end ",,502,124
openstack%2Fpuppet-manila~stable%2Frocky~I745a170ac4458a3f13efc255fc37540a11b54274,openstack/puppet-manila,stable/rocky,I745a170ac4458a3f13efc255fc37540a11b54274,Updating nova and neutron configuration,MERGED,2019-01-07 13:30:26.000000000,2019-01-07 20:31:39.000000000,2019-01-07 20:31:39.000000000,"[{'_account_id': 3153}, {'_account_id': 6413}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27419}]","[{'number': 1, 'created': '2019-01-07 13:30:26.000000000', 'files': ['spec/classes/manila_network_neutron_spec.rb', 'manifests/compute/nova.pp', 'releasenotes/notes/update-nova-neutron-with-keystonev3-3386a497d476d7d8.yaml', 'manifests/network/neutron.pp', 'spec/classes/manila_compute_nova_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/8fb1fa1077f3a39274bcf24eea20197175c74605', 'message': 'Updating nova and neutron configuration\n\nSince we stopped support of keystonev2, we need to be able to specify a\ndomain in neutron and nova configuration. Might as well add all the\noptions and remove the deprecated ones.\n\nCo-authored-by: Victoria Martinez de la Cruz <victoria@redhat.com>\nChange-Id: I745a170ac4458a3f13efc255fc37540a11b54274\nCloses-Bug: #1802393\n(cherry picked from commit 5ae8e2882b3e8229ea0007938315f5145e4f5f8a)\n'}]",0,628963,8fb1fa1077f3a39274bcf24eea20197175c74605,9,5,1,6413,,,0,"Updating nova and neutron configuration

Since we stopped support of keystonev2, we need to be able to specify a
domain in neutron and nova configuration. Might as well add all the
options and remove the deprecated ones.

Co-authored-by: Victoria Martinez de la Cruz <victoria@redhat.com>
Change-Id: I745a170ac4458a3f13efc255fc37540a11b54274
Closes-Bug: #1802393
(cherry picked from commit 5ae8e2882b3e8229ea0007938315f5145e4f5f8a)
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/63/628963/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/manila_network_neutron_spec.rb', 'manifests/compute/nova.pp', 'releasenotes/notes/update-nova-neutron-with-keystonev3-3386a497d476d7d8.yaml', 'manifests/network/neutron.pp', 'spec/classes/manila_compute_nova_spec.rb']",5,8fb1fa1077f3a39274bcf24eea20197175c74605,bug/1802393," shared_examples 'manila::nova' do is_expected.to contain_manila_config('nova/insecure').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/auth_url').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/auth_type').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/cafile').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/region_name').with_value('<SERVICE DEFAULT>') is_expected.to contain_manila_config('nova/endpoint_type').with_value('<SERVICE DEFAULT>') # These should be added only when auth_type is 'password' is_expected.not_to contain_manila_config('nova/user_domain_name') is_expected.not_to contain_manila_config('nova/project_domain_name') is_expected.not_to contain_manila_config('nova/project_name') is_expected.not_to contain_manila_config('nova/username') is_expected.not_to contain_manila_config('nova/password') :insecure => true, :auth_url => 'http://127.0.0.2:5000/', :auth_type => 'password', :cafile => '/etc/ssl/certs/ca.crt', :region_name => 'RegionOne', :endpoint_type => 'publicURL', :username => 'novav1', :password => '123123', it 'configures manila nova with overridden parameters' do is_expected.to contain_manila_config('nova/insecure').with_value(true) is_expected.to contain_manila_config('nova/auth_url').with_value('http://127.0.0.2:5000/') is_expected.to contain_manila_config('nova/auth_type').with_value('password') is_expected.to contain_manila_config('nova/cafile').with_value('/etc/ssl/certs/ca.crt') is_expected.to contain_manila_config('nova/user_domain_name').with_value('Default') is_expected.to contain_manila_config('nova/project_domain_name').with_value('Default') is_expected.to contain_manila_config('nova/project_name').with_value('service') is_expected.to contain_manila_config('nova/region_name').with_value('RegionOne') is_expected.to contain_manila_config('nova/endpoint_type').with_value('publicURL') is_expected.to contain_manila_config('nova/username').with_value('novav1') is_expected.to contain_manila_config('nova/password').with_value('123123').with_secret(true) end end context 'with deprecated parameters' do let :params do { :nova_api_insecure => true, :nova_ca_certificates_file => '/foo/ssl/certs/ca.crt', :auth_type => 'password', :nova_admin_tenant_name => 'service2', :nova_admin_username => 'novav2', :nova_admin_password => '321321', } end it 'configures manila compute nova with deprecated parameters' do is_expected.to contain_manila_config('nova/auth_type').with_value('password') is_expected.to contain_manila_config('nova/insecure').with_value(true) is_expected.to contain_manila_config('nova/cafile').with_value('/foo/ssl/certs/ca.crt') is_expected.to contain_manila_config('nova/project_name').with_value('service2') is_expected.to contain_manila_config('nova/username').with_value('novav2') is_expected.to contain_manila_config('nova/password').with_value('321321') it_behaves_like 'manila::nova'"," shared_examples 'manila-nova' do is_expected.to contain_manila_config('DEFAULT/nova_catalog_info').with_value('compute:nova:publicURL') is_expected.to contain_manila_config('DEFAULT/nova_catalog_admin_info').with_value('compute:nova:adminURL') is_expected.to contain_manila_config('DEFAULT/nova_api_insecure').with_value(false) is_expected.to contain_manila_config('DEFAULT/nova_admin_username').with_value('nova') is_expected.to contain_manila_config('DEFAULT/nova_admin_tenant_name').with_value('service') is_expected.to contain_manila_config('DEFAULT/nova_admin_auth_url').with_value('http://localhost:5000/v2.0') :nova_catalog_info => 'compute:nova:internalURL', :nova_catalog_admin_info => 'compute:nova:publicURL', :nova_ca_certificates_file => '/etc/ca.cert', :nova_api_insecure => true, :nova_admin_username => 'novav1', :nova_admin_password => '123123', :nova_admin_tenant_name => 'services', :nova_admin_auth_url => 'http://localhost:5000/v3', it 'configures manila nova' do is_expected.to contain_manila_config('DEFAULT/nova_catalog_info').with_value('compute:nova:internalURL') is_expected.to contain_manila_config('DEFAULT/nova_catalog_admin_info').with_value('compute:nova:publicURL') is_expected.to contain_manila_config('DEFAULT/nova_ca_certificates_file').with_value('/etc/ca.cert') is_expected.to contain_manila_config('DEFAULT/nova_api_insecure').with_value(true) is_expected.to contain_manila_config('DEFAULT/nova_admin_username').with_value('novav1') is_expected.to contain_manila_config('DEFAULT/nova_admin_tenant_name').with_value('services') is_expected.to contain_manila_config('DEFAULT/nova_admin_password').with_value('123123').with_secret(true) is_expected.to contain_manila_config('DEFAULT/nova_admin_auth_url').with_value('http://localhost:5000/v3') it_behaves_like 'manila-nova'",474,152
openstack%2Fopenstack-ansible~stable%2Frocky~Ice93db0ad2688e163ae9b2566f135ff0e066a285,openstack/openstack-ansible,stable/rocky,Ice93db0ad2688e163ae9b2566f135ff0e066a285,Bump rabbitmq_server SHA to include upgrade fix,MERGED,2019-01-03 00:43:33.000000000,2019-01-07 20:19:22.000000000,2019-01-07 20:19:22.000000000,"[{'_account_id': 290}, {'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-03 00:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/62e068dc2c79a397af10f33a9b81077098ff2f58', 'message': 'Bump rabbitmq_server SHA to include upgrade fix\n\nIncrements rabbitmq_server SHA to include a patch that fixes\nupgrades from Queens.\n\nChange-Id: Ice93db0ad2688e163ae9b2566f135ff0e066a285\n'}, {'number': 2, 'created': '2019-01-07 10:02:54.000000000', 'files': ['ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2b9a3b191cb39be508bbda5a6cd21b747675626f', 'message': 'Bump rabbitmq_server SHA to include upgrade fix\n\nIncrements rabbitmq_server SHA to include a patch that fixes\nupgrades from Queens.\n\nChange-Id: Ice93db0ad2688e163ae9b2566f135ff0e066a285\n'}]",0,628073,2b9a3b191cb39be508bbda5a6cd21b747675626f,17,6,2,290,,,0,"Bump rabbitmq_server SHA to include upgrade fix

Increments rabbitmq_server SHA to include a patch that fixes
upgrades from Queens.

Change-Id: Ice93db0ad2688e163ae9b2566f135ff0e066a285
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/73/628073/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible-role-requirements.yml'],1,62e068dc2c79a397af10f33a9b81077098ff2f58,bump_rabbitmq_sha, version: 3aad60868e6e32e4e035e1d27e256e768d722612, version: deccf93bdda1aa873b956418168368284509c99b,1,1
openstack%2Foctavia-tempest-plugin~master~I6bb7be14379174be9018a74b07356ecd85089f45,openstack/octavia-tempest-plugin,master,I6bb7be14379174be9018a74b07356ecd85089f45,Add traffic tests using an IPv6 VIP,MERGED,2018-10-19 22:45:37.000000000,2019-01-07 20:14:42.000000000,2019-01-07 20:14:42.000000000,"[{'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-19 22:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/71e599ef6608bc5243ddea86d35ae3fdc3c31241', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 2, 'created': '2018-10-22 17:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/0f78dfd321dcee3cab173d6bbaaf1dff68b36e61', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 3, 'created': '2018-11-06 21:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/9edb86aa115bc1d99f56718adee86cb26871d747', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 4, 'created': '2018-11-07 01:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/dd18d834ff92c1e54881a9888a413745d6236a17', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 5, 'created': '2018-11-08 23:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/5facf1410a449ad1ddda17d47d00737c5c41c6f4', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 6, 'created': '2018-12-12 18:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/4189466fc33b586d8db456bfe988bc64f4e20182', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 7, 'created': '2018-12-18 23:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/2a9535952b89602c308e66b37f9a91c2bd69eb0a', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 8, 'created': '2018-12-19 22:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/dd8341fc9fe872a9f26154156513941ccdde7bac', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 9, 'created': '2018-12-25 09:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/67221c354b5ca8ce9ad67dd327457e9481ebf015', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 10, 'created': '2019-01-02 18:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/b7ccb7edf66aa255facba9436deb05c1ac56868c', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}, {'number': 11, 'created': '2019-01-03 00:14:56.000000000', 'files': ['octavia_tempest_plugin/tests/api/v2/test_load_balancer.py', 'octavia_tempest_plugin/tests/scenario/v2/test_ipv6_traffic_ops.py', 'octavia_tempest_plugin/tests/test_base.py', 'octavia_tempest_plugin/tests/scenario/v2/test_load_balancer.py', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/5a16ad3267f382f7afe11a48b7b7de707ed6f00a', 'message': 'Add traffic tests using an IPv6 VIP\n\nAdds a traffic scenario test that has an IPv6 VIP address and mixed\nIPv4/IPv6 members. It tests that connections to the IPv6 VIP are\nevenly balanced across the mixed members.\n\nChange-Id: I6bb7be14379174be9018a74b07356ecd85089f45\nStory: 1627892\nTask: 27532\nDepends-On: https://review.openstack.org/#/c/611460/\n'}]",3,611980,5a16ad3267f382f7afe11a48b7b7de707ed6f00a,41,5,11,11628,,,0,"Add traffic tests using an IPv6 VIP

Adds a traffic scenario test that has an IPv6 VIP address and mixed
IPv4/IPv6 members. It tests that connections to the IPv6 VIP are
evenly balanced across the mixed members.

Change-Id: I6bb7be14379174be9018a74b07356ecd85089f45
Story: 1627892
Task: 27532
Depends-On: https://review.openstack.org/#/c/611460/
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/80/611980/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_tempest_plugin/tests/scenario/v2/test_ipv6_traffic_ops.py', 'octavia_tempest_plugin/tests/test_base.py']",2,71e599ef6608bc5243ddea86d35ae3fdc3c31241,ipv6VIP," # See if ipv6-public-subnet exists and use it if so. pub_ipv6_subnet = cls.os_admin.subnets_client.list_subnets( name='ipv6-public-subnet')['subnets'] if len(pub_ipv6_subnet) == 1: cls.lb_member_vip_ipv6_subnet = pub_ipv6_subnet[0] else: subnet_kwargs = { 'name': data_utils.rand_name(""lb_member_vip_ipv6_subnet""), 'network_id': cls.lb_member_vip_net['id'], 'cidr': CONF.load_balancer.vip_ipv6_subnet_cidr, 'ip_version': 6} result = cls.lb_mem_subnet_client.create_subnet( **subnet_kwargs) cls.lb_member_vip_ipv6_subnet = result['subnet'] cls.addClassResourceCleanup( waiters.wait_for_not_found, cls.lb_mem_subnet_client.delete_subnet, cls.lb_mem_subnet_client.show_subnet, cls.lb_member_vip_ipv6_subnet['id']) if cls.lb_member_vip_subnet or cls.lb_member_vip_ipv6_subnet: if ipaddress.ip_address(vip_address).version == 6: vip_address = '[{}]'.format(vip_address) "," subnet_kwargs = { 'name': data_utils.rand_name(""lb_member_vip_ipv6_subnet""), 'network_id': cls.lb_member_vip_net['id'], 'cidr': CONF.load_balancer.vip_ipv6_subnet_cidr, 'ip_version': 6} result = cls.lb_mem_subnet_client.create_subnet(**subnet_kwargs) cls.lb_member_vip_ipv6_subnet = result['subnet'] cls.addClassResourceCleanup( waiters.wait_for_not_found, cls.lb_mem_subnet_client.delete_subnet, cls.lb_mem_subnet_client.show_subnet, cls.lb_member_vip_ipv6_subnet['id']) if cls.lb_member_vip_subnet:",192,13
openstack%2Fcongress~master~I1d767e652eaf7218437d477abe9a999f2ae7b1aa,openstack/congress,master,I1d767e652eaf7218437d477abe9a999f2ae7b1aa,Improve documentation of policy create API,MERGED,2018-12-10 05:03:12.000000000,2019-01-07 20:12:29.000000000,2019-01-07 20:12:29.000000000,"[{'_account_id': 18591}, {'_account_id': 22348}, {'_account_id': 25553}]","[{'number': 1, 'created': '2018-12-10 05:03:12.000000000', 'files': ['doc/source/user/api.rst'], 'web_link': 'https://opendev.org/openstack/congress/commit/12974b28f0ecd0a1d7adf7986e2f01d3c9857d7a', 'message': 'Improve documentation of policy create API\n\nClarifying the different ways to create a new policy:\n- Without rules\n- With specified rules\n- from policy library\n\nChange-Id: I1d767e652eaf7218437d477abe9a999f2ae7b1aa\n'}]",0,623987,12974b28f0ecd0a1d7adf7986e2f01d3c9857d7a,10,3,1,18591,,,0,"Improve documentation of policy create API

Clarifying the different ways to create a new policy:
- Without rules
- With specified rules
- from policy library

Change-Id: I1d767e652eaf7218437d477abe9a999f2ae7b1aa
",git fetch https://review.opendev.org/openstack/congress refs/changes/87/623987/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/api.rst'],1,12974b28f0ecd0a1d7adf7986e2f01d3c9857d7a,policy-api-doc,"POST .../policies `Create new policy`_ POST .../policies/<policy-id> `Policy action`_ (simulate)Create new policy ----------------- Create new policy with empty rule set ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This operation creates a new policy with an empty rule set, presumably to be populated later with rules. Example: ``POST: .../policies`` with the following request body: :: { ""name"": ""policy_name_1"" } Create new policy from policy library ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This operation activates a policy from the policy library. Specify the the name of the library policy ``library_policy`` parameter. Example: ``POST: .../policies?library_policy=DisallowedServerImages`` with empty request body. Create new policy with rules ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This operation creates a new policy along with the specified policy rules. Example: ``POST: .../policies`` with the following request body: :: { ""name"": ""policy_name_2"", ""rules"": [ {""rule"": ""multiple_ip(port_id) :- port(port_id, ip1), port(port_id, ip2), not equal(ip1, ip2)"", ""comment"": ""ports with multiple IP addresses""}, {""rule"": ""single_id(port_id) :- port(port_id, ip), not multiple_ip(port_id)""} ] } Policy action ------------- You can utilize the simulation API call, which answers hypothetical","POST .../policies/<policy-id> Create new policyYou can also utilize the simulation API call, which answers hypothetical",56,2
openstack%2Fcongress~master~I332a844beaf8dec4450bb1ade6ce7e41cc3d4d91,openstack/congress,master,I332a844beaf8dec4450bb1ade6ce7e41cc3d4d91,Avoid coreference between current state and _last_published_data,MERGED,2018-12-18 01:40:58.000000000,2019-01-07 20:12:27.000000000,2019-01-07 20:12:27.000000000,"[{'_account_id': 18591}, {'_account_id': 22348}, {'_account_id': 25553}]","[{'number': 1, 'created': '2018-12-18 01:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/07ae6e5841eb86d0868fe74d18c425406fa7fea3', 'message': 'Avoid coreference between current state and _last_published_data\n\nPreviously, all data source drivers replace the entire state on each\npoll or push update (doctor). The DSE publish code relied on this\nsituation to optimize performance by skipping a copy when setting\n_last_published_data. The coreference introduced did not matter\nbecause the original state was never edited, only replaced.\n\nBut beginning with the webhook drivers\n(monasca webhook and vitrage), the drivers edit the current state.\nThis a bug was introduced where sometimes an update would not be\npublished to messaging bus because of an incorrect _last_published_data\ndue to coreference.\n\nThis patch fixes the bug. In addition, the _last_published_data\nelements are stored as set rather than list to save the need to\nconvert to set each time a diff is needed. The times when\nconversion back to list is needed to publish on the messaging bus\n(used for snapshot publish only)\nis expected to be far fewer than the times the conversion to set is\nneeded.\n\nA few additionalogging lines are also introbuced for improved\ndebuggability.\n\nChange-Id: I332a844beaf8dec4450bb1ade6ce7e41cc3d4d91\n'}, {'number': 2, 'created': '2018-12-18 01:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/088ac35d4f68be5effc3ba6c745df19d98372d29', 'message': 'Avoid coreference between current state and _last_published_data\n\nPreviously, all data source drivers replace the entire state on each\npoll or push update (doctor). The DSE publish code relied on this\nsituation to optimize performance by skipping a copy when setting\n_last_published_data. The coreference introduced did not matter\nbecause the original state was never edited, only replaced.\n\nBut beginning with the webhook drivers\n(monasca webhook and vitrage), the drivers edit the current state.\nThis a bug was introduced where sometimes an update would not be\npublished to messaging bus because of an incorrect _last_published_data\ndue to coreference.\n\nThis patch fixes the bug. In addition, the _last_published_data\nelements are stored as set rather than list to save the need to\nconvert to set each time a diff is needed. The times when\nconversion back to list is needed to publish on the messaging bus\n(used for snapshot publish only)\nis expected to be far fewer than the times the conversion to set is\nneeded.\n\nA few additionalogging lines are also introbuced for improved\ndebuggability.\n\nChange-Id: I332a844beaf8dec4450bb1ade6ce7e41cc3d4d91\n'}, {'number': 3, 'created': '2018-12-18 20:07:02.000000000', 'files': ['congress/dse2/data_service.py', 'congress/tests/dse2/test_dse2.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/5b9ae410249b96f522cfa545da5cfb296a1fc26b', 'message': 'Avoid coreference between current state and _last_published_data\n\nPreviously, all data source drivers replace the entire state on each\npoll or push update (doctor). The DSE publish code relied on this\nsituation to optimize performance by skipping a copy when setting\n_last_published_data. The coreference introduced did not matter\nbecause the original state was never edited, only replaced.\n\nBut beginning with the webhook drivers\n(monasca webhook and vitrage), the drivers edit the current state.\nThis a bug was introduced where sometimes an update would not be\npublished to messaging bus because of an incorrect _last_published_data\ndue to coreference.\n\nThis patch fixes the bug. In addition, the _last_published_data\nelements are stored as set rather than list to save the need to\nconvert to set each time a diff is needed. The times when\nconversion back to list is needed to publish on the messaging bus\n(used for snapshot publish only)\nis expected to be far fewer than the times the conversion to set is\nneeded.\n\nA few additionalogging lines are also introbuced for improved\ndebuggability.\n\nChange-Id: I332a844beaf8dec4450bb1ade6ce7e41cc3d4d91\n'}]",0,625749,5b9ae410249b96f522cfa545da5cfb296a1fc26b,13,3,3,18591,,,0,"Avoid coreference between current state and _last_published_data

Previously, all data source drivers replace the entire state on each
poll or push update (doctor). The DSE publish code relied on this
situation to optimize performance by skipping a copy when setting
_last_published_data. The coreference introduced did not matter
because the original state was never edited, only replaced.

But beginning with the webhook drivers
(monasca webhook and vitrage), the drivers edit the current state.
This a bug was introduced where sometimes an update would not be
published to messaging bus because of an incorrect _last_published_data
due to coreference.

This patch fixes the bug. In addition, the _last_published_data
elements are stored as set rather than list to save the need to
convert to set each time a diff is needed. The times when
conversion back to list is needed to publish on the messaging bus
(used for snapshot publish only)
is expected to be far fewer than the times the conversion to set is
needed.

A few additionalogging lines are also introbuced for improved
debuggability.

Change-Id: I332a844beaf8dec4450bb1ade6ce7e41cc3d4d91
",git fetch https://review.opendev.org/openstack/congress refs/changes/49/625749/3 && git format-patch -1 --stdout FETCH_HEAD,['congress/dse2/data_service.py'],1,07ae6e5841eb86d0868fe74d18c425406fa7fea3,state-coref," LOG.debug('Publishing table %s', table) LOG.trace('Parameters: table: %s, data: %s, use_snapshot: %s', table, data, use_snapshot) LOG.trace('Last published data %s', self._last_published_data) data = set(data) # make a copy to avoid co-reference LOG.trace('Diff against last published data %s', self._last_published_data[table]) to_add = list(data - self._last_published_data[table]) to_del = list(self._last_published_data[table] - data) to_add = list(data) self._last_published_data[table] = data LOG.debug('Differential data to publish %s', data) self._last_published_data[table] = set(self.get_snapshot(table)) # make a copy to avoid co-reference return (self.sender_seqnums[table], list(self._last_published_data[table]))"," to_add = list( set(data) - set(self._last_published_data[table])) to_del = list( set(self._last_published_data[table]) - set(data)) self._last_published_data[table] = data to_add = copy.copy(data) self._last_published_data[table] = self.get_snapshot(table) return (self.sender_seqnums[table], self._last_published_data[table])",16,8
openstack%2Fpython-tripleoclient~master~I1f3dc05808b8b201c8cab788856bff67e317d9f1,openstack/python-tripleoclient,master,I1f3dc05808b8b201c8cab788856bff67e317d9f1,undercloud_preflight: compare actual IPs without mask,ABANDONED,2018-10-19 19:20:52.000000000,2019-01-07 19:59:15.000000000,,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7385}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-10-19 19:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1229c185211bd386d95e9b74e99cc9343c3970cd', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 2, 'created': '2018-10-20 01:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fc333148be987d2d4ba7f0be96afe821480f18ae', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 3, 'created': '2018-10-20 13:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6a206e6064e8bd67b520959ee81b43acb6b06fbc', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 4, 'created': '2018-10-22 13:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/451ec6e5f59ea27543100e2fbac7a198373b5a7c', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 5, 'created': '2018-10-24 19:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f127a3b9c37ddf08cd3cd894a6395fe807c27e51', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 6, 'created': '2018-10-24 19:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b43101e13f9383e5d196aadcd489642c38f622f4', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 7, 'created': '2018-10-25 14:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/647d1dfa31f12c6fa015a016307e7d32814fbc03', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}, {'number': 8, 'created': '2018-10-26 12:06:59.000000000', 'files': ['tripleoclient/tests/test_utils.py', 'tripleoclient/utils.py', 'tripleoclient/v1/undercloud_preflight.py', 'releasenotes/notes/local_ip_extract-a661e576040bf3a9.yaml'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d7908f3b28aeaaa6743137bd33521c1ea26e53c6', 'message': 'undercloud_preflight: compare actual IPs without mask\n\nIn some validations, we need to compare IPs, but sometimes parameters\nalso contain the mask.\nThis patch adds a function that can extract an IP (v4 or v6) from a\nstring, even if the mask is in the string.\n\nIt allows to have local_ip = 192.168.0.21 in undercloud.conf and\n""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.\n\nNote: in this patch we also use yaml.safe_dump() since unicode is forced\nin utils.\n\nChange-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1\nCloses-Bug: #1798845\n'}]",4,611937,d7908f3b28aeaaa6743137bd33521c1ea26e53c6,33,9,8,3153,,,0,"undercloud_preflight: compare actual IPs without mask

In some validations, we need to compare IPs, but sometimes parameters
also contain the mask.
This patch adds a function that can extract an IP (v4 or v6) from a
string, even if the mask is in the string.

It allows to have local_ip = 192.168.0.21 in undercloud.conf and
""ip_netmask"": ""192.168.0.21/24"" in os-net-config config file.

Note: in this patch we also use yaml.safe_dump() since unicode is forced
in utils.

Change-Id: I1f3dc05808b8b201c8cab788856bff67e317d9f1
Closes-Bug: #1798845
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/37/611937/6 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/test_utils.py', 'tripleoclient/utils.py', 'tripleoclient/v1/undercloud_preflight.py', 'releasenotes/notes/local_ip_extract-a661e576040bf3a9.yaml']",4,1229c185211bd386d95e9b74e99cc9343c3970cd,bug/1798845,"--- fixes: - | - Fixes `bug 1798845 <https://bugs.launchpad.net/tripleo/+bug/1798845>`__ Extract the IP address from local_ip in os-net-config, and compare with undercloud.conf. We want to compare the IP withouth the mask, so it adds a function that extract the IP. It works with IPv4 and IPv6. ",,44,1
openstack%2Ftripleo-common~master~I671f9ee4f934d961946396c87c6a250fb738755a,openstack/tripleo-common,master,I671f9ee4f934d961946396c87c6a250fb738755a,image_uploader: fail if registry isn't reachable,ABANDONED,2018-11-26 17:41:30.000000000,2019-01-07 19:58:26.000000000,,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 9592}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 27427}]","[{'number': 1, 'created': '2018-11-26 17:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cb8786df554cb0f9d235bdcb4d0507433b2f7054', 'message': 'WIP - Handle registry 404 in image_uploader\n\nTODO: release note, unit tests, doc\n\nThis patch handles a special case when we pull containers from an host\nwhich returns 404 to https://host:port and try to test SSL against\nhttps://host.\n\nThis is work in progress, I need to finish this patch.\n\nChange-Id: I671f9ee4f934d961946396c87c6a250fb738755a\nCloses-Bug: #1805184\n'}, {'number': 2, 'created': '2018-11-26 19:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/215c6b54d2f4f9d6c673849c8178d4637e5f2c6a', 'message': 'WIP - Handle registry 404 in image_uploader\n\nTODO: release note, unit tests, doc\n\nThis patch handles a special case when we pull containers from an host\nwhich returns 404 to https://host:port and try to test SSL against\nhttps://host.\n\nThis is work in progress, I need to finish this patch.\n\nChange-Id: I671f9ee4f934d961946396c87c6a250fb738755a\nCloses-Bug: #1805184\n'}, {'number': 3, 'created': '2018-11-27 00:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/404068b794023bd79ab9769d7b7052dc4794e979', 'message': ""image_uploader: fail if registry isn't reachable\n\nChange-Id: I671f9ee4f934d961946396c87c6a250fb738755a\nRelated-Bug: #1805184\n""}, {'number': 4, 'created': '2018-11-27 00:53:29.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3be1349f233e3bc04cca383c73214ee841e4e2b4', 'message': ""image_uploader: fail if registry isn't reachable\n\nWhen testing if the registry is secure or not, fail and stop the\ndeployment if the registry isn't reachable.\n\nIt is better to stop the deployment early in the process rather than\nlater if the registry isn't ready.\n\nNote on unit tests:\n- It mocks the URL that is tested.\n- It removes duplicated tests.\n- It removes the timeout test, as we actually want to fail now.\n\nChange-Id: I671f9ee4f934d961946396c87c6a250fb738755a\nRelated-Bug: #1805184\n""}]",0,620117,3be1349f233e3bc04cca383c73214ee841e4e2b4,11,6,4,3153,,,0,"image_uploader: fail if registry isn't reachable

When testing if the registry is secure or not, fail and stop the
deployment if the registry isn't reachable.

It is better to stop the deployment early in the process rather than
later if the registry isn't ready.

Note on unit tests:
- It mocks the URL that is tested.
- It removes duplicated tests.
- It removes the timeout test, as we actually want to fail now.

Change-Id: I671f9ee4f934d961946396c87c6a250fb738755a
Related-Bug: #1805184
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/17/620117/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,cb8786df554cb0f9d235bdcb4d0507433b2f7054,404," url = 'https://' + registry_host + '/' try: r = requests.get(url) except requests.exceptions.HTTPError: if r.status_code == 404: host = registry_host.split(':')[0] url = requests.head('https://%s/' % host, verify=False).url else: raise ImageUploaderException('Get https://%s/ returned a ' 'non 404 error.' % registry_host) except Exception as e: pass #raise ImageUploaderException('Get https://%s/ returned an ' # 'error: %s' % (registry_host, e)) try: requests.get(url)", try: requests.get('https://%s/' % registry_host),15,1
openstack%2Fopenstack-zuul-jobs~master~I368369d146a422abbf94265036a7d280e47eedc0,openstack/openstack-zuul-jobs,master,I368369d146a422abbf94265036a7d280e47eedc0,Use is instead of | for tests,MERGED,2019-01-07 14:02:03.000000000,2019-01-07 19:44:35.000000000,2019-01-07 19:44:35.000000000,"[{'_account_id': 2}, {'_account_id': 1004}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 14:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/4370953abf8a3f97d5cff2e87573ef8405330352', 'message': 'Use is instead of | for tests\n\nNewer ansible wants us to use is. Also, it reads more nicer.\n\nChange-Id: I368369d146a422abbf94265036a7d280e47eedc0\n'}, {'number': 2, 'created': '2019-01-07 14:10:47.000000000', 'files': ['tests/fetch-output.yaml', 'tests/fetch-zuul-cloner.yaml', 'tests/configure-unbound.yaml', 'tests/ensure-output-dirs.yaml', 'tests/multi-node-bridge.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/c5183d416da1f6765f999e6dc49d7f6cdf2a60c9', 'message': 'Use is instead of | for tests\n\nNewer ansible wants us to use is. Also, it reads more nicer.\n\nChange-Id: I368369d146a422abbf94265036a7d280e47eedc0\n'}]",1,628973,c5183d416da1f6765f999e6dc49d7f6cdf2a60c9,14,5,2,2,,,0,"Use is instead of | for tests

Newer ansible wants us to use is. Also, it reads more nicer.

Change-Id: I368369d146a422abbf94265036a7d280e47eedc0
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/73/628973/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/fetch-output.yaml', 'tests/fetch-zuul-cloner.yaml', 'tests/configure-unbound.yaml', 'tests/ensure-output-dirs.yaml', 'tests/multi-node-bridge.yaml']",5,4370953abf8a3f97d5cff2e87573ef8405330352,zuulv3-output, - not ovs_installed is changed - not ovs_running is changed - not ovs_bridge is changed, - not ovs_installed | changed - not ovs_running | changed - not ovs_bridge | changed,23,23
openstack%2Fopenstack-zuul-jobs~master~I8b9b10983b2bc7bba37a19d2eb0d4107241d168c,openstack/openstack-zuul-jobs,master,I8b9b10983b2bc7bba37a19d2eb0d4107241d168c,Add fetch-output and ensure-output-dirs tests,MERGED,2019-01-05 14:26:22.000000000,2019-01-07 19:43:50.000000000,2019-01-07 19:43:50.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-05 14:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/c2fc5e5eedcb5f1d38b7282d1577d34a403d827b', 'message': 'Add fetch-output and ensure-output-dirs to tests regex\n\nWe should run integration test jobs on fetch-output and ensure-output-dirs.\n\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n'}, {'number': 2, 'created': '2019-01-05 14:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/a8f62b064aacb2991736333a4d8d04325ddfc3ca', 'message': ""Add fetch-output and ensure-output-dirs tests\n\nWe've added two new base-job roles, let's also add integration tests.\n\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n""}, {'number': 3, 'created': '2019-01-05 15:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/45ea7476b71a103574ee249fb6d726107b57505b', 'message': ""Add fetch-output and ensure-output-dirs tests\n\nWe've added two new base-job roles, let's also add integration tests.\n\nDepends-On: https://review.openstack.org/628734\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n""}, {'number': 4, 'created': '2019-01-06 00:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/2b9ea86c07f52bb3adea5440de9f71c9e60e7fd9', 'message': ""Add fetch-output and ensure-output-dirs tests\n\nWe've added two new base-job roles, let's also add integration tests.\n\nDepends-On: https://review.openstack.org/628734\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n""}, {'number': 5, 'created': '2019-01-06 15:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/fa6d6a02b945058822714f8a53c3c73d55887ef2', 'message': ""Add fetch-output and ensure-output-dirs tests\n\nWe've added two new base-job roles, let's also add integration tests.\n\nDepends-On: https://review.openstack.org/628734\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n""}, {'number': 6, 'created': '2019-01-06 16:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/d2385d741d80afceb7b59bfd21c4d31f02ed56aa', 'message': ""Add fetch-output and ensure-output-dirs tests\n\nWe've added two new base-job roles, let's also add integration tests.\n\nDepends-On: https://review.openstack.org/628734\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n""}, {'number': 7, 'created': '2019-01-06 17:10:10.000000000', 'files': ['tests/fetch-output.yaml', 'tests/base.yaml', 'tests/ensure-output-dirs.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/d7eb4df0b0f256df61c7b01298ceac27642b9fc1', 'message': ""Add fetch-output and ensure-output-dirs tests\n\nWe've added two new base-job roles, let's also add integration tests.\n\nDepends-On: https://review.openstack.org/628734\nChange-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c\n""}]",4,628731,d7eb4df0b0f256df61c7b01298ceac27642b9fc1,37,6,7,2,,,0,"Add fetch-output and ensure-output-dirs tests

We've added two new base-job roles, let's also add integration tests.

Depends-On: https://review.openstack.org/628734
Change-Id: I8b9b10983b2bc7bba37a19d2eb0d4107241d168c
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/31/628731/7 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,c2fc5e5eedcb5f1d38b7282d1577d34a403d827b,zuulv3-output, - ^roles/ensure-output-dirs/.* - ^roles/fetch-output/.*,,2,0
openstack%2Ftripleo-heat-templates~master~Ica897c186268461f8f90cca4d417794d9b7dedad,openstack/tripleo-heat-templates,master,Ica897c186268461f8f90cca4d417794d9b7dedad,Ensure we get the correct setype for haproxy log dir,MERGED,2019-01-03 15:03:23.000000000,2019-01-07 19:41:19.000000000,2019-01-07 19:41:19.000000000,"[{'_account_id': 3153}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-01-03 15:03:23.000000000', 'files': ['docker/services/haproxy.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/44b155eca6f8dc3d8aabe66e6e5f7e7987e7be82', 'message': 'Ensure we get the correct setype for haproxy log dir\n\nSince haproxy logs are managed by rsyslog, we want to ensure this\nservice can actually write in the location.\n\nThis means we have to ensure haproxy/* is set to var_log_t, and NOT\nthe usual svirt_sandbox_file_t context.\n\nChange-Id: Ica897c186268461f8f90cca4d417794d9b7dedad\n'}]",0,628200,44b155eca6f8dc3d8aabe66e6e5f7e7987e7be82,16,6,1,28223,,,0,"Ensure we get the correct setype for haproxy log dir

Since haproxy logs are managed by rsyslog, we want to ensure this
service can actually write in the location.

This means we have to ensure haproxy/* is set to var_log_t, and NOT
the usual svirt_sandbox_file_t context.

Change-Id: Ica897c186268461f8f90cca4d417794d9b7dedad
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/00/628200/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/haproxy.yaml'],1,44b155eca6f8dc3d8aabe66e6e5f7e7987e7be82,upgrade/haproxy-selinux, - name: ensure we have haproxy log dir with the correct setype file: path: /var/log/containers/haproxy state: directory setype: var_log_t recurse: yes,,6,0
openstack%2Fopenstack-helm-infra~master~I3723a0c96699b9a517dafa2df08bf8cc916bf117,openstack/openstack-helm-infra,master,I3723a0c96699b9a517dafa2df08bf8cc916bf117,Grafana: Add container security context,MERGED,2019-01-03 22:19:44.000000000,2019-01-07 19:40:22.000000000,2019-01-07 19:40:22.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-01-03 22:19:44.000000000', 'files': ['grafana/templates/deployment.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bf5840fa7a5a8694f43c25c3aa2a3b0b1638e21c', 'message': 'Grafana: Add container security context\n\nThis adds the container security context to grafana, which\nexplicitly sets allowPrivilegeEscalation to false\n\nChange-Id: I3723a0c96699b9a517dafa2df08bf8cc916bf117\n'}]",0,628315,bf5840fa7a5a8694f43c25c3aa2a3b0b1638e21c,11,4,1,17591,,,0,"Grafana: Add container security context

This adds the container security context to grafana, which
explicitly sets allowPrivilegeEscalation to false

Change-Id: I3723a0c96699b9a517dafa2df08bf8cc916bf117
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/15/628315/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/templates/deployment.yaml'],1,bf5840fa7a5a8694f43c25c3aa2a3b0b1638e21c,grafana/container-context, securityContext: allowPrivilegeEscalation: false,,2,0
openstack%2Fopenstack-helm-infra~master~Ie3f105ee8b489f7641b5b7256a2023ae35257343,openstack/openstack-helm-infra,master,Ie3f105ee8b489f7641b5b7256a2023ae35257343,Openstack exporter: Add security context for pod/container,MERGED,2019-01-03 21:50:35.000000000,2019-01-07 19:40:21.000000000,2019-01-07 19:40:20.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-01-03 21:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7dc7a7b7b5f5214bf417fc8dd6a890c369d48236', 'message': ""Openstack exporter: Add security context for pod uid\n\nThis adds a security context to the openstack exporter, which\nchanges the pod's user from root to the nobody user instead\n\nChange-Id: Ie3f105ee8b489f7641b5b7256a2023ae35257343\n""}, {'number': 2, 'created': '2019-01-03 22:17:02.000000000', 'files': ['prometheus-openstack-exporter/values.yaml', 'prometheus-openstack-exporter/templates/deployment.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/236d686a6d06899cb9b32a534bcee9c050445287', 'message': ""Openstack exporter: Add security context for pod/container\n\nThis adds a security context to the openstack exporter, which\nchanges the pod's user from root to the nobody user instead\n\nThis also adds the container security context to explicitly set\nallowPrivilegeEscalation to false\n\nChange-Id: Ie3f105ee8b489f7641b5b7256a2023ae35257343\n""}]",0,628309,236d686a6d06899cb9b32a534bcee9c050445287,12,5,2,17591,,,0,"Openstack exporter: Add security context for pod/container

This adds a security context to the openstack exporter, which
changes the pod's user from root to the nobody user instead

This also adds the container security context to explicitly set
allowPrivilegeEscalation to false

Change-Id: Ie3f105ee8b489f7641b5b7256a2023ae35257343
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/09/628309/1 && git format-patch -1 --stdout FETCH_HEAD,"['prometheus-openstack-exporter/values.yaml', 'prometheus-openstack-exporter/templates/deployment.yaml']",2,7dc7a7b7b5f5214bf417fc8dd6a890c369d48236,openstack-exporter/pod-uid,"{{ dict ""envAll"" $envAll ""application"" ""openstack_exporter"" | include ""helm-toolkit.snippets.kubernetes_pod_security_context"" | indent 6 }}",,4,0
openstack%2Fopenstack-helm-infra~master~Ibafff3b53f9d3c20f5aed30d40ee6470cb515a8a,openstack/openstack-helm-infra,master,Ibafff3b53f9d3c20f5aed30d40ee6470cb515a8a,Remove unused pod-etc-apache volumes,MERGED,2019-01-04 16:32:57.000000000,2019-01-07 19:40:20.000000000,2019-01-07 19:40:19.000000000,"[{'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-01-04 16:32:57.000000000', 'files': ['kibana/templates/deployment.yaml', 'nagios/templates/deployment.yaml', 'elasticsearch/templates/deployment-client.yaml', 'prometheus/templates/statefulset.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/30d2cf00d43427b00f3b930909dae2f80a800972', 'message': 'Remove unused pod-etc-apache volumes\n\nThis removes unused pod-etc-apache volumes from the charts that\nuse an apache sidecar container as a reverse proxy.\n\nChange-Id: Ibafff3b53f9d3c20f5aed30d40ee6470cb515a8a\n'}]",0,628589,30d2cf00d43427b00f3b930909dae2f80a800972,7,3,1,17591,,,0,"Remove unused pod-etc-apache volumes

This removes unused pod-etc-apache volumes from the charts that
use an apache sidecar container as a reverse proxy.

Change-Id: Ibafff3b53f9d3c20f5aed30d40ee6470cb515a8a
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/89/628589/1 && git format-patch -1 --stdout FETCH_HEAD,"['kibana/templates/deployment.yaml', 'nagios/templates/deployment.yaml', 'elasticsearch/templates/deployment-client.yaml', 'prometheus/templates/statefulset.yaml']",4,30d2cf00d43427b00f3b930909dae2f80a800972,apache/unused-volumes,, - name: pod-etc-apache emptyDir: {},0,8
openstack%2Fopenstack-helm-infra~master~I5b6698675fad2562741569de559419a1898523ee,openstack/openstack-helm-infra,master,I5b6698675fad2562741569de559419a1898523ee,Grafana: Add dashboard for coredns,MERGED,2019-01-04 16:50:42.000000000,2019-01-07 19:40:10.000000000,2019-01-07 19:40:10.000000000,"[{'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-01-04 16:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f562007e061d449d5845418dccbe29ceefeb7d1e', 'message': 'Grafana: Add dashboard for coredns\n\nThis adds a Grafana dashboard for coredns metrics\n\nChange-Id: I5b6698675fad2562741569de559419a1898523ee\n'}, {'number': 2, 'created': '2019-01-04 18:00:08.000000000', 'files': ['grafana/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7788a1ebeac6a2615b20f804e0c0609edc021eff', 'message': 'Grafana: Add dashboard for coredns\n\nThis adds a Grafana dashboard for coredns metrics\n\nChange-Id: I5b6698675fad2562741569de559419a1898523ee\n'}]",0,628611,7788a1ebeac6a2615b20f804e0c0609edc021eff,8,3,2,17591,,,0,"Grafana: Add dashboard for coredns

This adds a Grafana dashboard for coredns metrics

Change-Id: I5b6698675fad2562741569de559419a1898523ee
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/11/628611/2 && git format-patch -1 --stdout FETCH_HEAD,['grafana/values.yaml'],1,f562007e061d449d5845418dccbe29ceefeb7d1e,grafana/coredns," coredns: __inputs: - name: prometheus label: Prometheus description: '' type: datasource pluginId: prometheus pluginName: Prometheus __requires: - type: grafana id: grafana name: Grafana version: 4.4.3 - type: panel id: graph name: Graph version: '' - type: datasource id: prometheus name: Prometheus version: 1.0.0 annotations: list: [] editable: true gnetId: 5926 graphTooltip: 0 hideControls: false id: links: [] rows: - collapse: false height: 250px panels: - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 1 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: total yaxis: 2 spaceLength: 10 span: 4 stack: false steppedLine: false targets: - expr: sum(rate(coredns_dns_request_count_total{instance=~""$instance""}[5m])) by (proto) format: time_series intervalFactor: 2 legendFormat: ""{{proto}}"" refId: A step: 60 - expr: sum(rate(coredns_dns_request_count_total{instance=~""$instance""}[5m])) format: time_series intervalFactor: 2 legendFormat: total refId: B step: 60 thresholds: [] timeFrom: timeShift: title: Requests (total) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: pps logBase: 1 max: min: 0 show: true - format: pps logBase: 1 max: min: 0 show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 12 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: total yaxis: 2 - alias: other yaxis: 2 spaceLength: 10 span: 4 stack: false steppedLine: false targets: - expr: sum(rate(coredns_dns_request_type_count_total{instance=~""$instance""}[5m])) by (type) intervalFactor: 2 legendFormat: ""{{type}}"" refId: A step: 60 thresholds: [] timeFrom: timeShift: title: Requests (by qtype) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: pps logBase: 1 max: min: 0 show: true - format: pps logBase: 1 max: min: 0 show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 2 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: total yaxis: 2 spaceLength: 10 span: 4 stack: false steppedLine: false targets: - expr: sum(rate(coredns_dns_request_count_total{instance=~""$instance""}[5m])) by (zone) intervalFactor: 2 legendFormat: ""{{zone}}"" refId: A step: 60 - expr: sum(rate(coredns_dns_request_count_total{instance=~""$instance""}[5m])) intervalFactor: 2 legendFormat: total refId: B step: 60 thresholds: [] timeFrom: timeShift: title: Requests (by zone) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: pps logBase: 1 max: min: 0 show: true - format: pps logBase: 1 max: min: 0 show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 10 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: total yaxis: 2 spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: sum(rate(coredns_dns_request_do_count_total{instance=~""$instance""}[5m])) intervalFactor: 2 legendFormat: DO refId: A step: 40 - expr: sum(rate(coredns_dns_request_count_total{instance=~""$instance""}[5m])) intervalFactor: 2 legendFormat: total refId: B step: 40 thresholds: [] timeFrom: timeShift: title: Requests (DO bit) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: pps logBase: 1 max: min: 0 show: true - format: pps logBase: 1 max: min: show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 9 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: tcp:90 yaxis: 2 - alias: 'tcp:99 ' yaxis: 2 - alias: tcp:50 yaxis: 2 spaceLength: 10 span: 3 stack: false steppedLine: false targets: - expr: histogram_quantile(0.99, sum(rate(coredns_dns_request_size_bytes_bucket{instance=~""$instance"",proto=""udp""}[5m])) by (le,proto)) intervalFactor: 2 legendFormat: ""{{proto}}:99 "" refId: A step: 60 - expr: histogram_quantile(0.90, sum(rate(coredns_dns_request_size_bytes_bucket{instance=~""$instance"",proto=""udp""}[5m])) by (le,proto)) intervalFactor: 2 legendFormat: ""{{proto}}:90"" refId: B step: 60 - expr: histogram_quantile(0.50, sum(rate(coredns_dns_request_size_bytes_bucket{instance=~""$instance"",proto=""udp""}[5m])) by (le,proto)) intervalFactor: 2 legendFormat: ""{{proto}}:50"" refId: C step: 60 thresholds: [] timeFrom: timeShift: title: Requests (size, udp) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: bytes logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: 0 show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 14 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: tcp:90 yaxis: 1 - alias: 'tcp:99 ' yaxis: 1 - alias: tcp:50 yaxis: 1 spaceLength: 10 span: 3 stack: false steppedLine: false targets: - expr: histogram_quantile(0.99, sum(rate(coredns_dns_request_size_bytes_bucket{instance=~""$instance"",proto=""tcp""}[5m])) by (le,proto)) intervalFactor: 2 legendFormat: ""{{proto}}:99 "" refId: A step: 60 - expr: histogram_quantile(0.90, sum(rate(coredns_dns_request_size_bytes_bucket{instance=~""$instance"",proto=""tcp""}[5m])) by (le,proto)) intervalFactor: 2 legendFormat: ""{{proto}}:90"" refId: B step: 60 - expr: histogram_quantile(0.50, sum(rate(coredns_dns_request_size_bytes_bucket{instance=~""$instance"",proto=""tcp""}[5m])) by (le,proto)) intervalFactor: 2 legendFormat: ""{{proto}}:50"" refId: C step: 60 thresholds: [] timeFrom: timeShift: title: Requests (size,tcp) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: bytes logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: 0 show: true repeat: repeatIteration: repeatRowId: showTitle: false title: Row titleSize: h6 - collapse: false height: 250px panels: - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 5 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: [] spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: sum(rate(coredns_dns_response_rcode_count_total{instance=~""$instance""}[5m])) by (rcode) intervalFactor: 2 legendFormat: ""{{rcode}}"" refId: A step: 40 thresholds: [] timeFrom: timeShift: title: Responses (by rcode) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: pps logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 3 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: [] spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: histogram_quantile(0.99, sum(rate(coredns_dns_request_duration_milliseconds_bucket{instance=~""$instance""}[5m])) by (le, job)) intervalFactor: 2 legendFormat: 99% refId: A step: 40 - expr: histogram_quantile(0.90, sum(rate(coredns_dns_request_duration_milliseconds_bucket{instance=~""$instance""}[5m])) by (le)) intervalFactor: 2 legendFormat: 90% refId: B step: 40 - expr: histogram_quantile(0.50, sum(rate(coredns_dns_request_duration_milliseconds_bucket{instance=~""$instance""}[5m])) by (le)) intervalFactor: 2 legendFormat: 50% refId: C step: 40 thresholds: [] timeFrom: timeShift: title: Responses (duration) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: ms logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 8 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: udp:50% yaxis: 1 - alias: tcp:50% yaxis: 2 - alias: tcp:90% yaxis: 2 - alias: tcp:99% yaxis: 2 spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: 'histogram_quantile(0.99, sum(rate(coredns_dns_response_size_bytes_bucket{instance=~""$instance"",proto=""udp""}[5m])) by (le,proto)) ' intervalFactor: 2 legendFormat: ""{{proto}}:99%"" refId: A step: 40 - expr: 'histogram_quantile(0.90, sum(rate(coredns_dns_response_size_bytes_bucket{instance=""$instance"",proto=""udp""}[5m])) by (le,proto)) ' intervalFactor: 2 legendFormat: ""{{proto}}:90%"" refId: B step: 40 - expr: 'histogram_quantile(0.50, sum(rate(coredns_dns_response_size_bytes_bucket{instance=~""$instance"",proto=""udp""}[5m])) by (le,proto)) ' intervalFactor: 2 legendFormat: ""{{proto}}:50%"" metric: '' refId: C step: 40 thresholds: [] timeFrom: timeShift: title: Responses (size, udp) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: bytes logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: 0 show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 13 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: udp:50% yaxis: 1 - alias: tcp:50% yaxis: 1 - alias: tcp:90% yaxis: 1 - alias: tcp:99% yaxis: 1 spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: 'histogram_quantile(0.99, sum(rate(coredns_dns_response_size_bytes_bucket{instance=~""$instance"",proto=""tcp""}[5m])) by (le,proto)) ' intervalFactor: 2 legendFormat: ""{{proto}}:99%"" refId: A step: 40 - expr: 'histogram_quantile(0.90, sum(rate(coredns_dns_response_size_bytes_bucket{instance=~""$instance"",proto=""tcp""}[5m])) by (le,proto)) ' intervalFactor: 2 legendFormat: ""{{proto}}:90%"" refId: B step: 40 - expr: 'histogram_quantile(0.50, sum(rate(coredns_dns_response_size_bytes_bucket{instance=~""$instance"",proto=""tcp""}[5m])) by (le, proto)) ' intervalFactor: 2 legendFormat: ""{{proto}}:50%"" metric: '' refId: C step: 40 thresholds: [] timeFrom: timeShift: title: Responses (size, tcp) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: bytes logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: 0 show: true repeat: repeatIteration: repeatRowId: showTitle: false title: New row titleSize: h6 - collapse: false height: 250px panels: - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 15 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: [] spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: sum(coredns_cache_size{instance=~""$instance""}) by (type) intervalFactor: 2 legendFormat: ""{{type}}"" refId: A step: 40 thresholds: [] timeFrom: timeShift: title: Cache (size) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: short logBase: 1 max: min: 0 show: true - format: short logBase: 1 max: min: 0 show: true - aliasColors: {} bars: false dashLength: 10 dashes: false datasource: prometheus editable: true error: false fill: 1 grid: {} id: 16 legend: avg: false current: false max: false min: false show: true total: false values: false lines: true linewidth: 2 links: [] nullPointMode: connected percentage: false pointradius: 5 points: false renderer: flot seriesOverrides: - alias: misses yaxis: 2 spaceLength: 10 span: 6 stack: false steppedLine: false targets: - expr: sum(rate(coredns_cache_hits_total{instance=~""$instance""}[5m])) by (type) intervalFactor: 2 legendFormat: hits:{{type}} refId: A step: 40 - expr: sum(rate(coredns_cache_misses_total{instance=~""$instance""}[5m])) by (type) intervalFactor: 2 legendFormat: misses refId: B step: 40 thresholds: [] timeFrom: timeShift: title: Cache (hitrate) tooltip: shared: true sort: 0 value_type: cumulative type: graph xaxis: buckets: mode: time name: show: true values: [] yaxes: - format: pps logBase: 1 max: min: 0 show: true - format: pps logBase: 1 max: min: 0 show: true repeat: repeatIteration: repeatRowId: showTitle: false title: New row titleSize: h6 schemaVersion: 14 style: dark tags: - dns - coredns templating: list: - allValue: "".*"" current: {} datasource: prometheus hide: 0 includeAll: true label: Instance multi: false name: instance options: [] query: up{job=""coredns""} refresh: 1 regex: .*instance=""(.*?)"".* sort: 0 tagValuesQuery: '' tags: [] tagsQuery: '' type: query useTags: false time: from: now-3h to: now timepicker: now: true refresh_intervals: - 5s - 10s - 30s - 1m - 5m - 15m - 30m - 1h - 2h - 1d time_options: - 5m - 15m - 1h - 6h - 12h - 24h - 2d - 7d - 30d timezone: utc title: CoreDNS version: 3 description: A dashboard for the CoreDNS DNS server.",,1001,0
openstack%2Fansible-role-tripleo-ovn~master~I9d8f78c1aaffebad9b57d62461210432fcab5205,openstack/ansible-role-tripleo-ovn,master,I9d8f78c1aaffebad9b57d62461210432fcab5205,Update hacking version to latest,MERGED,2019-01-04 16:22:38.000000000,2019-01-07 19:39:53.000000000,2019-01-07 19:39:53.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:38.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-ovn/commit/8dc8d443be12f7eee9abdeb1743959b30c35b26e', 'message': 'Update hacking version to latest\n\nChange-Id: I9d8f78c1aaffebad9b57d62461210432fcab5205\n'}]",0,628574,8dc8d443be12f7eee9abdeb1743959b30c35b26e,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I9d8f78c1aaffebad9b57d62461210432fcab5205
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-ovn refs/changes/74/628574/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,8dc8d443be12f7eee9abdeb1743959b30c35b26e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-panko~master~Ie9a42bc198c4ed891d29e67c7868a47810b21a9c,openstack/ansible-role-tripleo-panko,master,Ie9a42bc198c4ed891d29e67c7868a47810b21a9c,Update hacking version to latest,MERGED,2019-01-04 16:22:39.000000000,2019-01-07 19:39:47.000000000,2019-01-07 19:39:47.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:39.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-panko/commit/906325267c408605f272ec672aca7cea7dbecf08', 'message': 'Update hacking version to latest\n\nChange-Id: Ie9a42bc198c4ed891d29e67c7868a47810b21a9c\n'}]",0,628578,906325267c408605f272ec672aca7cea7dbecf08,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ie9a42bc198c4ed891d29e67c7868a47810b21a9c
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-panko refs/changes/78/628578/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,906325267c408605f272ec672aca7cea7dbecf08,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-ui~master~I495af846bf56bd8c40f61d7bc6beeffeff96b481,openstack/ansible-role-tripleo-ui,master,I495af846bf56bd8c40f61d7bc6beeffeff96b481,Update hacking version to latest,MERGED,2019-01-04 16:22:41.000000000,2019-01-07 19:39:45.000000000,2019-01-07 19:39:45.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:41.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-ui/commit/7e4493a803c6c43addf7b6bd4c6b72ef1b4b70c8', 'message': 'Update hacking version to latest\n\nChange-Id: I495af846bf56bd8c40f61d7bc6beeffeff96b481\n'}]",0,628582,7e4493a803c6c43addf7b6bd4c6b72ef1b4b70c8,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I495af846bf56bd8c40f61d7bc6beeffeff96b481
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-ui refs/changes/82/628582/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7e4493a803c6c43addf7b6bd4c6b72ef1b4b70c8,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-sensu~master~I69685560b0e25291aea91b74839499227ff3d3c1,openstack/ansible-role-tripleo-sensu,master,I69685560b0e25291aea91b74839499227ff3d3c1,Update hacking version to latest,MERGED,2019-01-04 16:22:39.000000000,2019-01-07 19:39:43.000000000,2019-01-07 19:39:43.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:39.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-sensu/commit/e856592d794d1f9d0977809f969f5e01570f9b99', 'message': 'Update hacking version to latest\n\nChange-Id: I69685560b0e25291aea91b74839499227ff3d3c1\n'}]",0,628577,e856592d794d1f9d0977809f969f5e01570f9b99,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I69685560b0e25291aea91b74839499227ff3d3c1
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-sensu refs/changes/77/628577/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e856592d794d1f9d0977809f969f5e01570f9b99,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-octavia~master~Ibc3d2c533ede5efd0bc74192438e0d95e047eaf3,openstack/ansible-role-tripleo-octavia,master,Ibc3d2c533ede5efd0bc74192438e0d95e047eaf3,Update hacking version to latest,MERGED,2019-01-04 16:22:35.000000000,2019-01-07 19:39:23.000000000,2019-01-07 19:39:23.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:35.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-octavia/commit/de9b39a1a8b93c194fb2a8a4aa6d8854f799fece', 'message': 'Update hacking version to latest\n\nChange-Id: Ibc3d2c533ede5efd0bc74192438e0d95e047eaf3\n'}]",0,628573,de9b39a1a8b93c194fb2a8a4aa6d8854f799fece,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ibc3d2c533ede5efd0bc74192438e0d95e047eaf3
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-octavia refs/changes/73/628573/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,de9b39a1a8b93c194fb2a8a4aa6d8854f799fece,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-nova~master~I1bf42dc64bdec86193e04a301db1fc1e83dee0a8,openstack/ansible-role-tripleo-nova,master,I1bf42dc64bdec86193e04a301db1fc1e83dee0a8,Update hacking version to latest,MERGED,2019-01-04 16:22:35.000000000,2019-01-07 19:39:22.000000000,2019-01-07 19:39:22.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:35.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-nova/commit/bd6584beff430e374c372c33b5fdaa0993bec357', 'message': 'Update hacking version to latest\n\nChange-Id: I1bf42dc64bdec86193e04a301db1fc1e83dee0a8\n'}]",0,628572,bd6584beff430e374c372c33b5fdaa0993bec357,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I1bf42dc64bdec86193e04a301db1fc1e83dee0a8
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-nova refs/changes/72/628572/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,bd6584beff430e374c372c33b5fdaa0993bec357,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpanko~master~I9a40fbed6c4cf640d8935dee618a4ebb83c30787,openstack/panko,master,I9a40fbed6c4cf640d8935dee618a4ebb83c30787,Replace tripleo-scenario001-multinode with scenario001-standalone,MERGED,2018-12-13 12:55:52.000000000,2019-01-07 19:38:33.000000000,2019-01-07 19:38:33.000000000,"[{'_account_id': 2813}, {'_account_id': 6924}, {'_account_id': 8175}, {'_account_id': 9592}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-13 12:55:52.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/panko/commit/adb1d52ceb70471d9623499e8dc4706da90a4759', 'message': 'Replace tripleo-scenario001-multinode with scenario001-standalone\n\nThe scenario001-standalone job is added in the depends-on below.\nTracked by tripleo ci squad at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/us/191\nDepends-On: https://review.openstack.org/619508\n\nChange-Id: I9a40fbed6c4cf640d8935dee618a4ebb83c30787\n'}]",0,624981,adb1d52ceb70471d9623499e8dc4706da90a4759,10,5,1,8449,,,0,"Replace tripleo-scenario001-multinode with scenario001-standalone

The scenario001-standalone job is added in the depends-on below.
Tracked by tripleo ci squad at [1]

[1] https://tree.taiga.io/project/tripleo-ci-board/us/191
Depends-On: https://review.openstack.org/619508

Change-Id: I9a40fbed6c4cf640d8935dee618a4ebb83c30787
",git fetch https://review.opendev.org/openstack/panko refs/changes/81/624981/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,adb1d52ceb70471d9623499e8dc4706da90a4759,replace-scen1, - tripleo-ci-centos-7-scenario001-standalone:, - tripleo-ci-centos-7-scenario001-multinode-oooq-container:,1,1
openstack%2Fansible-role-tripleo-haproxy~master~I5a4c1139e88846ede781b2834a4a7356b39775ce,openstack/ansible-role-tripleo-haproxy,master,I5a4c1139e88846ede781b2834a4a7356b39775ce,Update hacking version to latest,MERGED,2019-01-04 16:22:24.000000000,2019-01-07 19:38:20.000000000,2019-01-07 19:38:20.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-haproxy/commit/aee54974eec22d5a6987b5a5ff31aa58925cc45e', 'message': 'Update hacking version to latest\n\nChange-Id: I5a4c1139e88846ede781b2834a4a7356b39775ce\n'}]",0,628560,aee54974eec22d5a6987b5a5ff31aa58925cc45e,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I5a4c1139e88846ede781b2834a4a7356b39775ce
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-haproxy refs/changes/60/628560/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,aee54974eec22d5a6987b5a5ff31aa58925cc45e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-ironic~master~I0ea45643053057aa34ffd7bef3e50ab47ae6a4cd,openstack/ansible-role-tripleo-ironic,master,I0ea45643053057aa34ffd7bef3e50ab47ae6a4cd,Update hacking version to latest,MERGED,2019-01-04 16:22:24.000000000,2019-01-07 19:38:12.000000000,2019-01-07 19:38:12.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-ironic/commit/354004f360aba2dc387bce6f4db7f3bfd7cefac1', 'message': 'Update hacking version to latest\n\nChange-Id: I0ea45643053057aa34ffd7bef3e50ab47ae6a4cd\n'}]",0,628563,354004f360aba2dc387bce6f4db7f3bfd7cefac1,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I0ea45643053057aa34ffd7bef3e50ab47ae6a4cd
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-ironic refs/changes/63/628563/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,354004f360aba2dc387bce6f4db7f3bfd7cefac1,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-memcached~master~I2e1345b2b7181a36a14997a0cdf68daec7295030,openstack/ansible-role-tripleo-memcached,master,I2e1345b2b7181a36a14997a0cdf68daec7295030,Update hacking version to latest,MERGED,2019-01-04 16:22:26.000000000,2019-01-07 19:38:06.000000000,2019-01-07 19:38:06.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:26.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-memcached/commit/4bb116e740d9b4841c35b5c832c3f0d49f14097d', 'message': 'Update hacking version to latest\n\nChange-Id: I2e1345b2b7181a36a14997a0cdf68daec7295030\n'}]",0,628567,4bb116e740d9b4841c35b5c832c3f0d49f14097d,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I2e1345b2b7181a36a14997a0cdf68daec7295030
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-memcached refs/changes/67/628567/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,4bb116e740d9b4841c35b5c832c3f0d49f14097d,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-cookiecutter~master~Ie230915523abc0e9d0357a388e8dfcbfd0be8921,openstack/ansible-role-tripleo-cookiecutter,master,Ie230915523abc0e9d0357a388e8dfcbfd0be8921,Update hacking version to latest,MERGED,2019-01-04 16:22:20.000000000,2019-01-07 19:38:03.000000000,2019-01-07 19:38:03.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:20.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-cookiecutter/commit/ee6522c7eeb7f943446a134c7273433ab7f3e08b', 'message': 'Update hacking version to latest\n\nChange-Id: Ie230915523abc0e9d0357a388e8dfcbfd0be8921\n'}]",0,628556,ee6522c7eeb7f943446a134c7273433ab7f3e08b,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ie230915523abc0e9d0357a388e8dfcbfd0be8921
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-cookiecutter refs/changes/56/628556/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ee6522c7eeb7f943446a134c7273433ab7f3e08b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-heat~master~Ied53babf23bc7895b6194db6cefb46ed459b66fc,openstack/ansible-role-tripleo-heat,master,Ied53babf23bc7895b6194db6cefb46ed459b66fc,Update hacking version to latest,MERGED,2019-01-04 16:22:24.000000000,2019-01-07 19:37:33.000000000,2019-01-07 19:37:33.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-heat/commit/0489fd1c654bf1363f1e8cdc36d3cbfe83da195e', 'message': 'Update hacking version to latest\n\nChange-Id: Ied53babf23bc7895b6194db6cefb46ed459b66fc\n'}]",0,628561,0489fd1c654bf1363f1e8cdc36d3cbfe83da195e,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ied53babf23bc7895b6194db6cefb46ed459b66fc
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-heat refs/changes/61/628561/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0489fd1c654bf1363f1e8cdc36d3cbfe83da195e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-barbican~master~I97468550043ffd9d7e2cbe7fc9839cc57c4b5e17,openstack/ansible-role-tripleo-barbican,master,I97468550043ffd9d7e2cbe7fc9839cc57c4b5e17,Update hacking version to latest,MERGED,2019-01-04 16:22:14.000000000,2019-01-07 19:37:25.000000000,2019-01-07 19:37:25.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:14.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-barbican/commit/cce774fa80d2826f6f34b36c188d1ca2e7bdaf0d', 'message': 'Update hacking version to latest\n\nChange-Id: I97468550043ffd9d7e2cbe7fc9839cc57c4b5e17\n'}]",0,628552,cce774fa80d2826f6f34b36c188d1ca2e7bdaf0d,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I97468550043ffd9d7e2cbe7fc9839cc57c4b5e17
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-barbican refs/changes/52/628552/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,cce774fa80d2826f6f34b36c188d1ca2e7bdaf0d,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-keystone~master~Iafd5a51e502200e40b08d50de40f97678a134500,openstack/ansible-role-tripleo-keystone,master,Iafd5a51e502200e40b08d50de40f97678a134500,Update hacking version to latest,MERGED,2019-01-04 16:22:25.000000000,2019-01-07 19:37:21.000000000,2019-01-07 19:37:21.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:25.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-keystone/commit/568b98dbb1eb33a1b11d9c6183f22a7d25be2f19', 'message': 'Update hacking version to latest\n\nChange-Id: Iafd5a51e502200e40b08d50de40f97678a134500\n'}]",0,628565,568b98dbb1eb33a1b11d9c6183f22a7d25be2f19,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Iafd5a51e502200e40b08d50de40f97678a134500
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-keystone refs/changes/65/628565/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,568b98dbb1eb33a1b11d9c6183f22a7d25be2f19,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-manila~master~Idd0f4974d4e462a42badc29c60bc3deb23b55380,openstack/ansible-role-tripleo-manila,master,Idd0f4974d4e462a42badc29c60bc3deb23b55380,Update hacking version to latest,MERGED,2019-01-04 16:22:26.000000000,2019-01-07 19:36:54.000000000,2019-01-07 19:36:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:26.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-manila/commit/93124e5af7bb35471dcf1110967e8ad62c6b8346', 'message': 'Update hacking version to latest\n\nChange-Id: Idd0f4974d4e462a42badc29c60bc3deb23b55380\n'}]",0,628566,93124e5af7bb35471dcf1110967e8ad62c6b8346,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Idd0f4974d4e462a42badc29c60bc3deb23b55380
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-manila refs/changes/66/628566/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,93124e5af7bb35471dcf1110967e8ad62c6b8346,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-gnocchi~master~I54b9e120da89737a47d52d72a37f64afa0d6c125,openstack/ansible-role-tripleo-gnocchi,master,I54b9e120da89737a47d52d72a37f64afa0d6c125,Update hacking version to latest,MERGED,2019-01-04 16:22:23.000000000,2019-01-07 19:36:51.000000000,2019-01-07 19:36:51.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:23.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-gnocchi/commit/683a324724e6629a9655062fb093a602f88f16f7', 'message': 'Update hacking version to latest\n\nChange-Id: I54b9e120da89737a47d52d72a37f64afa0d6c125\n'}]",0,628558,683a324724e6629a9655062fb093a602f88f16f7,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I54b9e120da89737a47d52d72a37f64afa0d6c125
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-gnocchi refs/changes/58/628558/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,683a324724e6629a9655062fb093a602f88f16f7,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-glance~master~Icf5e42c0d27426b1dff8221376c9595cfd6684d2,openstack/ansible-role-tripleo-glance,master,Icf5e42c0d27426b1dff8221376c9595cfd6684d2,Update hacking version to latest,MERGED,2019-01-04 16:22:24.000000000,2019-01-07 19:36:26.000000000,2019-01-07 19:36:26.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-glance/commit/38c685593c400a527f9265c576d70ad8bbc5782f', 'message': 'Update hacking version to latest\n\nChange-Id: Icf5e42c0d27426b1dff8221376c9595cfd6684d2\n'}]",0,628559,38c685593c400a527f9265c576d70ad8bbc5782f,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Icf5e42c0d27426b1dff8221376c9595cfd6684d2
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-glance refs/changes/59/628559/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,38c685593c400a527f9265c576d70ad8bbc5782f,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fgovernance-uc~master~I8015455364dc0af1bfa3b4af0b7e49cf340c9771,openstack/governance-uc,master,I8015455364dc0af1bfa3b4af0b7e49cf340c9771,Add document for February 2019 UC Election,MERGED,2018-12-27 23:16:58.000000000,2019-01-07 19:36:00.000000000,2019-01-07 19:36:00.000000000,"[{'_account_id': 7272}, {'_account_id': 14091}, {'_account_id': 15993}, {'_account_id': 17556}, {'_account_id': 22348}, {'_account_id': 28738}]","[{'number': 1, 'created': '2018-12-27 23:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/7e94f06f5fc586af94343244adcc8482b6ef463f', 'message': 'Add document for February 2019 UC Election\n\nChange-Id: I8015455364dc0af1bfa3b4af0b7e49cf340c9771\nSigned-off-by: Melvin Hillsman <mrhillsman@gmail.com>\n'}, {'number': 2, 'created': '2018-12-27 23:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/e9c32e19da8a68005ded2ae57962fb9f930baa18', 'message': 'Add document for February 2019 UC Election\n\nChange-Id: I8015455364dc0af1bfa3b4af0b7e49cf340c9771\nSigned-off-by: Melvin Hillsman <mrhillsman@gmail.com>\n'}, {'number': 3, 'created': '2018-12-27 23:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/25f97526fac73e4574060635c9c8a6a82d05d2fd', 'message': 'Add document for February 2019 UC Election\n\nChange-Id: I8015455364dc0af1bfa3b4af0b7e49cf340c9771\nSigned-off-by: Melvin Hillsman <mrhillsman@gmail.com>\n'}, {'number': 4, 'created': '2019-01-04 22:12:31.000000000', 'files': ['doc/source/index.rst', 'reference/uc-election-feb2019.rst'], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/fe8a38200830f6d54a82b0055d642187c14c9015', 'message': 'Add document for February 2019 UC Election\n\nChange-Id: I8015455364dc0af1bfa3b4af0b7e49cf340c9771\nSigned-off-by: Melvin Hillsman <mrhillsman@gmail.com>\n'}]",2,627575,fe8a38200830f6d54a82b0055d642187c14c9015,14,6,4,17556,,,0,"Add document for February 2019 UC Election

Change-Id: I8015455364dc0af1bfa3b4af0b7e49cf340c9771
Signed-off-by: Melvin Hillsman <mrhillsman@gmail.com>
",git fetch https://review.opendev.org/openstack/governance-uc refs/changes/75/627575/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/uc-election-feb2019.rst'],1,7e94f06f5fc586af94343244adcc8482b6ef463f,electionfeb2019,"========================== UC Elections February 2019 ========================== We expect all members of our community to adhere to the highest standards of behavior during User Committee elections. Officials ========= # Example: remove when officials have been identified | First Last - first.last at email dot com Election System =============== Elections will be held using CIVS and a Condorcet algorithm (Schulze/Beatpath/CSSD variant). Any tie will be broken using `Governance/TieBreaking <https://wiki.openstack.org/wiki/Governance/TieBreaking>`_. Timeline ======== | January 21 - February 03, 05:59 UTC: Open candidacy for UC positions | February 04 - February 10, 11:59 UTC: UC elections (voting) Elected Positions ================= Under the rules of the UC charter, we need to elect 2 UC seats for this election. Seats are valid for one-year term. User Committee member - 2 positions. Electorate ========== The electorate for this election are the Foundation individual members that are also Active User Contributors (AUC) over the last six months. The electorate is requested to confirm their email address and (if applicable) IRC handle in their `Foundation Member Profile <https://openstack.org/profile>`_, prior to February 03, 2019 05:59 UTC so that the emailed ballots are mailed to the correct email address. Candidates ========== Any individual member of the foundation who is an Active User Contributor (AUC) can propose their candidacy (except two of the three recently elected members). Self-nomination is common, no third party nomination is required. Nominate by sending an email to the openstack-discuss@lists.openstack.org mailing-list, with the subject: ""UC Candidacy"" by February 03, 05:59 UTC. The email can include a description of the candidate platform. The candidacy is then confirmed by one of the election officials, after verification of the electorate status of the candidate. Result ====== | ... were elected. |\* Full Results: ",,56,0
openstack%2Fansible-role-tripleo-opendaylight~master~I05a3b27f7f8067d0bbecddc80de15f1cc2aa92d5,openstack/ansible-role-tripleo-opendaylight,master,I05a3b27f7f8067d0bbecddc80de15f1cc2aa92d5,Update hacking version to latest,MERGED,2019-01-04 16:22:34.000000000,2019-01-07 19:35:23.000000000,2019-01-07 19:35:23.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:34.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-opendaylight/commit/a5cb4428e724b458be518132d02e2a93f2465b32', 'message': 'Update hacking version to latest\n\nChange-Id: I05a3b27f7f8067d0bbecddc80de15f1cc2aa92d5\n'}]",0,628571,a5cb4428e724b458be518132d02e2a93f2465b32,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I05a3b27f7f8067d0bbecddc80de15f1cc2aa92d5
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-opendaylight refs/changes/71/628571/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,a5cb4428e724b458be518132d02e2a93f2465b32,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-neutron~master~I9ee216a787b5a6ca188416693f29d098ef579cb4,openstack/ansible-role-tripleo-neutron,master,I9ee216a787b5a6ca188416693f29d098ef579cb4,Update hacking version to latest,MERGED,2019-01-04 16:22:32.000000000,2019-01-07 19:35:23.000000000,2019-01-07 19:35:23.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:32.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-neutron/commit/207d03beaa99d9d0e0c625be6a3daa33644b6fe2', 'message': 'Update hacking version to latest\n\nChange-Id: I9ee216a787b5a6ca188416693f29d098ef579cb4\n'}]",0,628570,207d03beaa99d9d0e0c625be6a3daa33644b6fe2,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I9ee216a787b5a6ca188416693f29d098ef579cb4
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-neutron refs/changes/70/628570/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,207d03beaa99d9d0e0c625be6a3daa33644b6fe2,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-tempest~master~I38ac1b6d48200b6185f2745d6032b269642b79b0,openstack/ansible-role-tripleo-tempest,master,I38ac1b6d48200b6185f2745d6032b269642b79b0,Update hacking version to latest,MERGED,2019-01-04 16:22:41.000000000,2019-01-07 19:35:20.000000000,2019-01-07 19:35:20.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:41.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-tempest/commit/ab5491a9010b6301a203a4500733290a41c5a0ed', 'message': 'Update hacking version to latest\n\nChange-Id: I38ac1b6d48200b6185f2745d6032b269642b79b0\n'}]",0,628581,ab5491a9010b6301a203a4500733290a41c5a0ed,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I38ac1b6d48200b6185f2745d6032b269642b79b0
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-tempest refs/changes/81/628581/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ab5491a9010b6301a203a4500733290a41c5a0ed,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-zaqar~master~Ifd697cdc5ba4cc312dbe9bad31a2321b79512989,openstack/ansible-role-tripleo-zaqar,master,Ifd697cdc5ba4cc312dbe9bad31a2321b79512989,Update hacking version to latest,MERGED,2019-01-04 16:22:43.000000000,2019-01-07 19:35:18.000000000,2019-01-07 19:35:18.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:43.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-zaqar/commit/e2a7951290361f962903c9c88eddaf4513cd2b01', 'message': 'Update hacking version to latest\n\nChange-Id: Ifd697cdc5ba4cc312dbe9bad31a2321b79512989\n'}]",0,628587,e2a7951290361f962903c9c88eddaf4513cd2b01,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ifd697cdc5ba4cc312dbe9bad31a2321b79512989
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-zaqar refs/changes/87/628587/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e2a7951290361f962903c9c88eddaf4513cd2b01,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-rabbitmq~master~I0bf233190cb3b1ed0aea3863ab9cb03195508c04,openstack/ansible-role-tripleo-rabbitmq,master,I0bf233190cb3b1ed0aea3863ab9cb03195508c04,Update hacking version to latest,MERGED,2019-01-04 16:22:39.000000000,2019-01-07 19:35:16.000000000,2019-01-07 19:35:16.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:39.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-rabbitmq/commit/81b8df133185ad4d04715576427a960a96defdef', 'message': 'Update hacking version to latest\n\nChange-Id: I0bf233190cb3b1ed0aea3863ab9cb03195508c04\n'}]",0,628575,81b8df133185ad4d04715576427a960a96defdef,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I0bf233190cb3b1ed0aea3863ab9cb03195508c04
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-rabbitmq refs/changes/75/628575/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,81b8df133185ad4d04715576427a960a96defdef,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-swift~master~Idcf35b6a6bf7030c7e9e4e0c1df8aba6c190d0c3,openstack/ansible-role-tripleo-swift,master,Idcf35b6a6bf7030c7e9e4e0c1df8aba6c190d0c3,Update hacking version to latest,MERGED,2019-01-04 16:22:40.000000000,2019-01-07 19:35:02.000000000,2019-01-07 19:35:02.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:40.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-swift/commit/5670e23716de645bfe2fbba47374fbde2b2b3d29', 'message': 'Update hacking version to latest\n\nChange-Id: Idcf35b6a6bf7030c7e9e4e0c1df8aba6c190d0c3\n'}]",0,628579,5670e23716de645bfe2fbba47374fbde2b2b3d29,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Idcf35b6a6bf7030c7e9e4e0c1df8aba6c190d0c3
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-swift refs/changes/79/628579/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,5670e23716de645bfe2fbba47374fbde2b2b3d29,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-rsyslog-sidecar~master~I272347a0f875b528865a928ac3c82e05e8e3158e,openstack/ansible-role-tripleo-rsyslog-sidecar,master,I272347a0f875b528865a928ac3c82e05e8e3158e,Update hacking version to latest,MERGED,2019-01-04 16:22:41.000000000,2019-01-07 19:35:01.000000000,2019-01-07 19:35:01.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:41.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-rsyslog-sidecar/commit/c3511bcc586ec241542b63a93d1e18a3868119d3', 'message': 'Update hacking version to latest\n\nChange-Id: I272347a0f875b528865a928ac3c82e05e8e3158e\n'}]",0,628583,c3511bcc586ec241542b63a93d1e18a3868119d3,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I272347a0f875b528865a928ac3c82e05e8e3158e
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-rsyslog-sidecar refs/changes/83/628583/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c3511bcc586ec241542b63a93d1e18a3868119d3,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-sahara~master~I7cfd3cebb902d662becfff7c8be66cd775321849,openstack/ansible-role-tripleo-sahara,master,I7cfd3cebb902d662becfff7c8be66cd775321849,Update hacking version to latest,MERGED,2019-01-04 16:22:39.000000000,2019-01-07 19:34:58.000000000,2019-01-07 19:34:58.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:39.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-sahara/commit/6e67b8b9a1aba92081478685a7b3000d626c942c', 'message': 'Update hacking version to latest\n\nChange-Id: I7cfd3cebb902d662becfff7c8be66cd775321849\n'}]",0,628576,6e67b8b9a1aba92081478685a7b3000d626c942c,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I7cfd3cebb902d662becfff7c8be66cd775321849
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-sahara refs/changes/76/628576/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,6e67b8b9a1aba92081478685a7b3000d626c942c,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-mistral~master~Ibab97e122fe557145db17f42bf3b42a60347811c,openstack/ansible-role-tripleo-mistral,master,Ibab97e122fe557145db17f42bf3b42a60347811c,Update hacking version to latest,MERGED,2019-01-04 16:22:27.000000000,2019-01-07 19:34:47.000000000,2019-01-07 19:34:47.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:27.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-mistral/commit/2ccd43ec995611dbe4f386959f97f90fb36e3a6a', 'message': 'Update hacking version to latest\n\nChange-Id: Ibab97e122fe557145db17f42bf3b42a60347811c\n'}]",0,628568,2ccd43ec995611dbe4f386959f97f90fb36e3a6a,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ibab97e122fe557145db17f42bf3b42a60347811c
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-mistral refs/changes/68/628568/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,2ccd43ec995611dbe4f386959f97f90fb36e3a6a,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-tacker~master~I2a92f0c34c74cf67498ffd173fccad34223fd5fc,openstack/ansible-role-tripleo-tacker,master,I2a92f0c34c74cf67498ffd173fccad34223fd5fc,Update hacking version to latest,MERGED,2019-01-04 16:22:40.000000000,2019-01-07 19:34:41.000000000,2019-01-07 19:34:41.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:40.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-tacker/commit/44b8cf94b2174846f494bc2e6c73e8f22cfb5e5c', 'message': 'Update hacking version to latest\n\nChange-Id: I2a92f0c34c74cf67498ffd173fccad34223fd5fc\n'}]",0,628580,44b8cf94b2174846f494bc2e6c73e8f22cfb5e5c,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I2a92f0c34c74cf67498ffd173fccad34223fd5fc
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-tacker refs/changes/80/628580/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,44b8cf94b2174846f494bc2e6c73e8f22cfb5e5c,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-horizon~master~Ic4b95fd6bce1fa9c245db18255329af818a75a43,openstack/ansible-role-tripleo-horizon,master,Ic4b95fd6bce1fa9c245db18255329af818a75a43,Update hacking version to latest,MERGED,2019-01-04 16:22:24.000000000,2019-01-07 19:33:56.000000000,2019-01-07 19:33:56.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-horizon/commit/24b95d0138b3ffd00e4ce36a3e455b7ec81bb03d', 'message': 'Update hacking version to latest\n\nChange-Id: Ic4b95fd6bce1fa9c245db18255329af818a75a43\n'}]",0,628562,24b95d0138b3ffd00e4ce36a3e455b7ec81bb03d,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ic4b95fd6bce1fa9c245db18255329af818a75a43
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-horizon refs/changes/62/628562/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,24b95d0138b3ffd00e4ce36a3e455b7ec81bb03d,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-keepalived~master~I49037641609596ac0258c8b3004e26a262d3bcf7,openstack/ansible-role-tripleo-keepalived,master,I49037641609596ac0258c8b3004e26a262d3bcf7,Update hacking version to latest,MERGED,2019-01-04 16:22:25.000000000,2019-01-07 19:33:08.000000000,2019-01-07 19:33:08.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:25.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-keepalived/commit/1f551f37dad5ea01ed66af2015c9bb805608203a', 'message': 'Update hacking version to latest\n\nChange-Id: I49037641609596ac0258c8b3004e26a262d3bcf7\n'}]",0,628564,1f551f37dad5ea01ed66af2015c9bb805608203a,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I49037641609596ac0258c8b3004e26a262d3bcf7
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-keepalived refs/changes/64/628564/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1f551f37dad5ea01ed66af2015c9bb805608203a,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-designate~master~Ib6028e7a9a270d6734ab969fc0fd46585c4e51f1,openstack/ansible-role-tripleo-designate,master,Ib6028e7a9a270d6734ab969fc0fd46585c4e51f1,Update hacking version to latest,MERGED,2019-01-04 16:22:20.000000000,2019-01-07 19:33:07.000000000,2019-01-07 19:33:07.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:20.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-designate/commit/dce60190b7d4b747c7d5f3b38caa7cee05b972f5', 'message': 'Update hacking version to latest\n\nChange-Id: Ib6028e7a9a270d6734ab969fc0fd46585c4e51f1\n'}]",0,628557,dce60190b7d4b747c7d5f3b38caa7cee05b972f5,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Ib6028e7a9a270d6734ab969fc0fd46585c4e51f1
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-designate refs/changes/57/628557/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,dce60190b7d4b747c7d5f3b38caa7cee05b972f5,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-cinder~master~Icb6455f1696d6bd9aa9d9c0db3f1a9bbab048731,openstack/ansible-role-tripleo-cinder,master,Icb6455f1696d6bd9aa9d9c0db3f1a9bbab048731,Update hacking version to latest,MERGED,2019-01-04 16:22:18.000000000,2019-01-07 19:33:07.000000000,2019-01-07 19:33:07.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:18.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-cinder/commit/dc384e641c37dbea7ac6a02a4d772cd9c81c4443', 'message': 'Update hacking version to latest\n\nChange-Id: Icb6455f1696d6bd9aa9d9c0db3f1a9bbab048731\n'}]",0,628554,dc384e641c37dbea7ac6a02a4d772cd9c81c4443,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: Icb6455f1696d6bd9aa9d9c0db3f1a9bbab048731
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-cinder refs/changes/54/628554/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,dc384e641c37dbea7ac6a02a4d772cd9c81c4443,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fansible-role-tripleo-ceilometer~master~I33a66f7c393030ef4b85ba64a6adb1bafc9b98ac,openstack/ansible-role-tripleo-ceilometer,master,I33a66f7c393030ef4b85ba64a6adb1bafc9b98ac,Update hacking version to latest,MERGED,2019-01-04 16:22:17.000000000,2019-01-07 19:33:02.000000000,2019-01-07 19:33:02.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:22:17.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-ceilometer/commit/d6f4fc18fef4c2815111e2bfa042d2cddd7d5227', 'message': 'Update hacking version to latest\n\nChange-Id: I33a66f7c393030ef4b85ba64a6adb1bafc9b98ac\n'}]",0,628553,d6f4fc18fef4c2815111e2bfa042d2cddd7d5227,7,3,1,28614,,,0,"Update hacking version to latest

Change-Id: I33a66f7c393030ef4b85ba64a6adb1bafc9b98ac
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-ceilometer refs/changes/53/628553/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d6f4fc18fef4c2815111e2bfa042d2cddd7d5227,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-resource-classes~master~If8dba8c7aee5e8161ac52dd2eeb0a7b2d82ca933,openstack/os-resource-classes,master,If8dba8c7aee5e8161ac52dd2eeb0a7b2d82ca933,Update author-email in setup.cfg,MERGED,2018-12-13 08:11:27.000000000,2019-01-07 19:07:08.000000000,2019-01-07 19:07:08.000000000,"[{'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2018-12-13 08:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/a85d809caff86a35b339ac2b5a5f1cb81c05b1dd', 'message': 'Update author-email in setup.cfg\n\nThe openstack-dev mailing list has been replaced with\nthe openstack-discuss mailing list (*).\nSo replace the openstack-dev mailing list with\nthe openstack-discuss mailing list in setup.cfg.\n\nIn addition, update the home page URL in setup.cfg.\n\n*: http://lists.openstack.org/pipermail/openstack-dev/2018-September/134911.html\n\nChange-Id: If8dba8c7aee5e8161ac52dd2eeb0a7b2d82ca933\n'}, {'number': 2, 'created': '2018-12-17 01:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/0bcae95cba1ae1def1386f1881cd02aed21318d0', 'message': 'Update author-email in setup.cfg\n\nThe openstack-dev mailing list has been replaced with\nthe openstack-discuss mailing list (*).\nSo replace the openstack-dev mailing list with\nthe openstack-discuss mailing list in setup.cfg.\n\nIn addition, update the home page URL in setup.cfg.\n\n*: http://lists.openstack.org/pipermail/openstack-dev/2018-September/134911.html\n\nChange-Id: If8dba8c7aee5e8161ac52dd2eeb0a7b2d82ca933\n'}, {'number': 3, 'created': '2019-01-07 00:14:34.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/bffafeab58bf48fea7a2b6df8ba0ebb0718af50f', 'message': 'Update author-email in setup.cfg\n\nThe openstack-dev mailing list has been replaced with\nthe openstack-discuss mailing list (*).\nSo replace the openstack-dev mailing list with\nthe openstack-discuss mailing list in setup.cfg.\n\nIn addition, update the home page URL in setup.cfg.\n\n*: http://lists.openstack.org/pipermail/openstack-dev/2018-September/134911.html\n\nChange-Id: If8dba8c7aee5e8161ac52dd2eeb0a7b2d82ca933\n'}]",0,624885,bffafeab58bf48fea7a2b6df8ba0ebb0718af50f,23,7,3,7634,,,0,"Update author-email in setup.cfg

The openstack-dev mailing list has been replaced with
the openstack-discuss mailing list (*).
So replace the openstack-dev mailing list with
the openstack-discuss mailing list in setup.cfg.

In addition, update the home page URL in setup.cfg.

*: http://lists.openstack.org/pipermail/openstack-dev/2018-September/134911.html

Change-Id: If8dba8c7aee5e8161ac52dd2eeb0a7b2d82ca933
",git fetch https://review.opendev.org/openstack/os-resource-classes refs/changes/85/624885/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a85d809caff86a35b339ac2b5a5f1cb81c05b1dd,update_author_email,author-email = openstack-discuss@lists.openstack.org home-page = https://docs.openstack.org/os-resource-classes/latest/,author-email = openstack-dev@lists.openstack.org home-page = http://www.openstack.org/,2,2
openstack%2Fopenstack-ansible-tests~master~Ic1afffaff3a9cad16deb67e9391dec3a51271ff4,openstack/openstack-ansible-tests,master,Ic1afffaff3a9cad16deb67e9391dec3a51271ff4,"Revert ""Set OpenSUSE jobs to non-voting""",MERGED,2018-12-20 15:55:32.000000000,2019-01-07 18:55:49.000000000,2019-01-07 18:55:49.000000000,"[{'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-20 15:55:32.000000000', 'files': ['zuul.d/project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/28acc672566eda5b99e8a35f20c78d2606774c73', 'message': 'Revert ""Set OpenSUSE jobs to non-voting""\n\nThis reverts commit 542047b1dadf34cdd7182f52a4ab12966dc93765.\n\nNow that the jobs are working again, we can set them\nto be voting.\n\nChange-Id: Ic1afffaff3a9cad16deb67e9391dec3a51271ff4\n'}]",0,626602,28acc672566eda5b99e8a35f20c78d2606774c73,12,4,1,6816,,,0,"Revert ""Set OpenSUSE jobs to non-voting""

This reverts commit 542047b1dadf34cdd7182f52a4ab12966dc93765.

Now that the jobs are working again, we can set them
to be voting.

Change-Id: Ic1afffaff3a9cad16deb67e9391dec3a51271ff4
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/02/626602/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project-templates.yaml'],1,28acc672566eda5b99e8a35f20c78d2606774c73,osa-suse-jobs, - openstack-ansible-functional-opensuse-423 - openstack-ansible-functional-opensuse-423, - openstack-ansible-functional-opensuse-423: voting: false,2,2
openstack%2Fos-resource-classes~master~I5360e041b6b81c5686e2700aa89de8514a69dd9a,openstack/os-resource-classes,master,I5360e041b6b81c5686e2700aa89de8514a69dd9a,Don't use upper-constraints when installing package,MERGED,2019-01-04 13:57:49.000000000,2019-01-07 18:55:05.000000000,2019-01-07 18:55:05.000000000,"[{'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 7634}, {'_account_id': 11904}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 13:57:49.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/a9e988bf28cd0cbec15854968a8a5f3d595f479e', 'message': ""Don't use upper-constraints when installing package\n\nWe only want to use upper-constraints when installing dependencies, not\nthe os-resource-classes package itself, otherwise we get:\n\n   Could not satisfy constraints for 'os-resource-classes':\n   installation from path or url cannot be constrained to a version\n\nChange-Id: I5360e041b6b81c5686e2700aa89de8514a69dd9a\nCloses-Bug: #1809401\n""}]",0,628442,a9e988bf28cd0cbec15854968a8a5f3d595f479e,10,6,1,11564,,,0,"Don't use upper-constraints when installing package

We only want to use upper-constraints when installing dependencies, not
the os-resource-classes package itself, otherwise we get:

   Could not satisfy constraints for 'os-resource-classes':
   installation from path or url cannot be constrained to a version

Change-Id: I5360e041b6b81c5686e2700aa89de8514a69dd9a
Closes-Bug: #1809401
",git fetch https://review.opendev.org/openstack/os-resource-classes refs/changes/42/628442/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a9e988bf28cd0cbec15854968a8a5f3d595f479e,bug/1809401,install_command = pip install {opts} {packages}deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/test-requirements.txt,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}deps = -r{toxinidir}/test-requirements.txt,4,2
openstack%2Ftripleo-heat-templates~master~I7d9a951d0c156c83430c1e326bc8edcb52b08537,openstack/tripleo-heat-templates,master,I7d9a951d0c156c83430c1e326bc8edcb52b08537,Add a tag's containing subnet cidr to ctlplane network,MERGED,2018-10-25 22:40:49.000000000,2019-01-07 18:39:51.000000000,2019-01-07 18:39:50.000000000,"[{'_account_id': 8871}, {'_account_id': 10873}, {'_account_id': 11090}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-10-25 22:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1323fd23055f438021012426e1992a3718fec944', 'message': ""Add a tag's contining subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 2, 'created': '2018-10-25 22:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/01867890dd5aa17548714a64ea501e0be3d4094f', 'message': ""Add a tag's contining subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 3, 'created': '2018-10-26 23:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/732ac0322aae4f9efb2b7b6e3f82a5e02fa6e7e7', 'message': ""Add a tag's contining subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 4, 'created': '2018-10-28 02:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/52dc816d9a5e1cb9309a91e80f1745d3109a2f42', 'message': ""Add a tag's contining subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 5, 'created': '2018-10-30 12:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/840ae7fd7658313b8098d28d1cd30bc3f5ced449', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 6, 'created': '2018-11-11 12:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21296c826bc7d5afc0a833b92fa3b432797230db', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 7, 'created': '2018-11-22 21:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a7dfd52101bfc0b1c95333f4589c920f716a0e9c', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 8, 'created': '2018-11-22 22:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/864146c40dfed8245c72aae1d3bed5f1d3596fd6', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 9, 'created': '2018-11-26 16:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e965517d58e48e7245ea60a254c654d989b1b9d', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 10, 'created': '2018-12-02 10:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/77ba13917372777d614fdf5ce3f7a7679cf6dca9', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 11, 'created': '2018-12-02 12:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c2811dec8dedfd68cd8bb2b81565787d44429c79', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 12, 'created': '2018-12-12 01:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f50dead78942d2addce77f07cc9d40d8970f1325', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 13, 'created': '2018-12-18 03:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b0b0df1d33d6f894f157b4472eaa375f39624654', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 14, 'created': '2018-12-30 18:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e136ae147d194869554de0f37d65bbe20e34689', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 15, 'created': '2019-01-02 14:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/00418a9ffada5fc845377b477b5e51d09d396a57', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 16, 'created': '2019-01-02 15:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6b830f869ad5ba6baf0dff3c1330d4d05e3fd98d', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 17, 'created': '2019-01-02 15:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/18b17e11130b0fb5dbc9a6a7c73d4234da967ae5', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}, {'number': 18, 'created': '2019-01-06 17:23:32.000000000', 'files': ['extraconfig/post_deploy/undercloud_ctlplane_network.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/00cecfe2f3268ae12842f69758455968782a3272', 'message': ""Add a tag's containing subnet cidr to ctlplane network\n\nSince the ctlplane network and it's subnets are created\noutside of the overcloud heat templates we cannot in an\neasy way create a list containing the cidr of each of\nthe ctlplane subnets in THT.\n\nPrior to routed networks we only had one subnet and was\nable to create the NetCidrMapValue by reading the cidr\nvalue of one of the ControlVirtualIP resource. When we\nhave multiple subnets on each network we should make\nNetCidrMapValue contain lists of cidrs for each network.\n\nBy setting a tags on the ctlplane network, one\nper subnet, containing each individual subnets cidr the\ntags can be loaded via the ControlVirtualIP resource so\nthat we can have NetCidrMapValue contain all the cidrs\nof the ctlplane network.\n\nChange-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537\nPartial: blueprint tripleo-routed-networks-templates\n""}]",2,613442,00cecfe2f3268ae12842f69758455968782a3272,79,7,18,24245,,,0,"Add a tag's containing subnet cidr to ctlplane network

Since the ctlplane network and it's subnets are created
outside of the overcloud heat templates we cannot in an
easy way create a list containing the cidr of each of
the ctlplane subnets in THT.

Prior to routed networks we only had one subnet and was
able to create the NetCidrMapValue by reading the cidr
value of one of the ControlVirtualIP resource. When we
have multiple subnets on each network we should make
NetCidrMapValue contain lists of cidrs for each network.

By setting a tags on the ctlplane network, one
per subnet, containing each individual subnets cidr the
tags can be loaded via the ControlVirtualIP resource so
that we can have NetCidrMapValue contain all the cidrs
of the ctlplane network.

Change-Id: I7d9a951d0c156c83430c1e326bc8edcb52b08537
Partial: blueprint tripleo-routed-networks-templates
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/613442/16 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/post_deploy/undercloud_ctlplane_network.py'],1,1323fd23055f438021012426e1992a3718fec944,bp/tripleo-routed-networks-templates,"def _set_network_tags(sdk, network, tags): try: sdk.network.set_tags(network, tags=tags) print('INFO: Tags %s added to network %s.' % (tags, network.name)) except Exception: print('ERROR: Setting tags %s on network %s failed.' % (network.name, tags)) raise def _local_neutron_segments_and_subnets(sdk, ctlplane_id, net_cidrs): net_cidrs.append(s['NetworkCidr']) return net_cidrs def _remote_neutron_segments_and_subnets(sdk, ctlplane_id, net_cidrs): net_cidrs.append(s['NetworkCidr']) return net_cidrs net_cidrs = [] net_cidrs = _local_neutron_segments_and_subnets(sdk, network.id, net_cidrs) if CONF['enable_routed_networks']: net_cidrs = _remote_neutron_segments_and_subnets(sdk, network.id, net_cidrs) # Set the cidrs for all ctlplane subnets as tags on the ctlplane network. # These tags are used for the NetCidrMapValue in tripleo-heat-templates. _set_network_tags(sdk, network, net_cidrs)","def _local_neutron_segments_and_subnets(sdk, ctlplane_id): def _remote_neutron_segments_and_subnets(sdk, ctlplane_id): _local_neutron_segments_and_subnets(sdk, network.id) if CONF['enable_routed_networks']: _remote_neutron_segments_and_subnets(sdk, network.id)",23,4
openstack%2Ftripleo-heat-templates~master~I4ec8f35b1dd71c25cfb41cc54105ac743ef67745,openstack/tripleo-heat-templates,master,I4ec8f35b1dd71c25cfb41cc54105ac743ef67745,Remove MongoDB,MERGED,2018-12-28 11:48:33.000000000,2019-01-07 18:39:49.000000000,2019-01-07 18:39:49.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 8871}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-28 11:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c91194a9cf84a91172700acc89799fbefc34bc66', 'message': 'Remove MongoDB\n\nMongoDB support was stopped in Pike, it is not used anywhere now.\nTherefore, in Stein are removing it to clean things up.\n\nChange-Id: I4ec8f35b1dd71c25cfb41cc54105ac743ef67745\n'}, {'number': 2, 'created': '2019-01-04 09:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c2b42ae3d61829289ec30ced9e5c8d48dec2ea67', 'message': 'Remove MongoDB\n\nMongoDB support was stopped in Pike, it is not used anywhere now.\nTherefore, in Stein are removing it to clean things up.\n\nChange-Id: I4ec8f35b1dd71c25cfb41cc54105ac743ef67745\n'}, {'number': 3, 'created': '2019-01-04 15:17:00.000000000', 'files': ['roles/ControllerNovaStandalone.yaml', 'README.rst', 'roles_data.yaml', 'docker/services/database/mongodb.yaml', 'ci/environments/network/multiple-nics-ipv6/network-isolation.yaml', 'environments/lifecycle/ffwd-upgrade-prepare.yaml', 'roles/ControllerAllNovaStandalone.yaml', 'capabilities-map.yaml', 'roles/Controller.yaml', 'releasenotes/notes/mongodb_drop-02daffbfe4975cb9.yaml', 'tools/yaml-validate.py', 'network/service_net_map.j2.yaml', 'environments/lifecycle/upgrade-prepare.yaml', 'roles/ControllerOpenstack.yaml', 'puppet/services/disabled/mongodb-disabled.yaml', 'roles/Standalone.yaml', 'ci/environments/network/multiple-nics-ipv6/network-isolation-absolute.yaml', 'roles/ControllerStorageNfs.yaml', 'environments/network-isolation-v6.j2.yaml', 'puppet/services/database/mongodb-base.yaml', 'deployed-server/deployed-server-roles-data.yaml', 'roles/ControllerNoCeph.yaml', 'ci/environments/scenario006-multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'puppet/services/database/mongodb.yaml', 'environments/mongodb-nojournal.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/be07f991b6341d525a2c91bdfd01d9c8902b917b', 'message': 'Remove MongoDB\n\nMongoDB support was stopped in Pike, it is not used anywhere now.\nTherefore, in Stein are removing it to clean things up.\n\nChange-Id: I4ec8f35b1dd71c25cfb41cc54105ac743ef67745\n'}]",2,627627,be07f991b6341d525a2c91bdfd01d9c8902b917b,29,8,3,3153,,,0,"Remove MongoDB

MongoDB support was stopped in Pike, it is not used anywhere now.
Therefore, in Stein are removing it to clean things up.

Change-Id: I4ec8f35b1dd71c25cfb41cc54105ac743ef67745
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/27/627627/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/ControllerNovaStandalone.yaml', 'README.rst', 'roles_data.yaml', 'docker/services/database/mongodb.yaml', 'ci/environments/network/multiple-nics-ipv6/network-isolation.yaml', 'roles/ControllerAllNovaStandalone.yaml', 'capabilities-map.yaml', 'roles/Controller.yaml', 'releasenotes/notes/mongodb_drop-02daffbfe4975cb9.yaml', 'tools/yaml-validate.py', 'network/service_net_map.j2.yaml', 'roles/ControllerOpenstack.yaml', 'puppet/services/disabled/mongodb-disabled.yaml', 'roles/Standalone.yaml', 'ci/environments/network/multiple-nics-ipv6/network-isolation-absolute.yaml', 'roles/ControllerStorageNfs.yaml', 'environments/network-isolation-v6.j2.yaml', 'environments/services-baremetal/zaqar.yaml', 'puppet/services/database/mongodb-base.yaml', 'deployed-server/deployed-server-roles-data.yaml', 'roles/ControllerNoCeph.yaml', 'ci/environments/scenario006-multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'puppet/services/database/mongodb.yaml', 'environments/mongodb-nojournal.yaml']",25,c91194a9cf84a91172700acc89799fbefc34bc66,tripleo/rm/mongodb,,"# A Heat environment file which can be used to disable journal in MongoDb. # Since, when journaling is enabled, MongoDb will create big journal file # it can take time. In a CI environment for example journaling is not necessary. parameter_defaults: MongoDbNoJournal: true ",6,485
openstack%2Ftripleo-heat-templates~master~Icffcfae290f94f91823d80cc640f4a9bf9eafa5f,openstack/tripleo-heat-templates,master,Icffcfae290f94f91823d80cc640f4a9bf9eafa5f,ironic: enable the ipxe boot interface by default,MERGED,2019-01-04 15:35:52.000000000,2019-01-07 18:39:47.000000000,2019-01-07 18:39:47.000000000,"[{'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-01-04 15:35:52.000000000', 'files': ['deployment/ironic/ironic-conductor-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8865d01da5050ee2fec2d884026f6504d4031682', 'message': 'ironic: enable the ipxe boot interface by default\n\nIronic is separating the pxe and ipxe implementations into separate boot\ninterfaces, deprecating the ipxe part of the pxe interface. This change\nenables the new ipxe interface instead.\n\nStory: #1628069\nChange-Id: Icffcfae290f94f91823d80cc640f4a9bf9eafa5f\n'}]",0,628494,8865d01da5050ee2fec2d884026f6504d4031682,11,6,1,10239,,,0,"ironic: enable the ipxe boot interface by default

Ironic is separating the pxe and ipxe implementations into separate boot
interfaces, deprecating the ipxe part of the pxe interface. This change
enables the new ipxe interface instead.

Story: #1628069
Change-Id: Icffcfae290f94f91823d80cc640f4a9bf9eafa5f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/94/628494/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ironic/ironic-conductor-container-puppet.yaml'],1,8865d01da5050ee2fec2d884026f6504d4031682,ipxe," default: ['ipxe', 'pxe']", default: ['pxe'],1,1
openstack%2Fopenstack-ansible-os_tempest~master~I90b93c088f7bc2df0c8f10e6aff58d66c6645290,openstack/openstack-ansible-os_tempest,master,I90b93c088f7bc2df0c8f10e6aff58d66c6645290,Use tempest_cloud_name for setting cloudname,MERGED,2019-01-04 16:50:25.000000000,2019-01-07 18:36:44.000000000,2019-01-07 18:36:44.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8367}, {'_account_id': 10459}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2019-01-04 16:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/e4fe1d45f5295b150f5d330174e143f5012d6431', 'message': 'Use tempest_cloudrc for setting cloudname\n\nCurrently in tasks/tempest_resources.yml file, we are using\nansible provided openstack cloud modules which needs cloud name\nwhich is harded to default. When os_tempest role is getting used\nwith different deployment tool, cloud name varies. Adding\ntempest_cloudrc var mades it easier to use any cloud name defined\nin clouds.yaml file.\n\nChange-Id: I90b93c088f7bc2df0c8f10e6aff58d66c6645290\n'}, {'number': 2, 'created': '2019-01-07 13:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/7bfa407fc6fb1d89d02820a5b12cc02bb2ee7dc1', 'message': 'Use tempest_cloud_name for setting cloudname\n\nCurrently in tasks/tempest_resources.yml file, we are using\nansible provided openstack cloud modules which needs cloud name\nwhich is harded to default. When os_tempest role is getting used\nwith different deployment tool, cloud name varies. Adding\ntempest_cloud_name var mades it easier to use any cloud name defined\nin clouds.yaml file.\n\nChange-Id: I90b93c088f7bc2df0c8f10e6aff58d66c6645290\n'}, {'number': 3, 'created': '2019-01-07 15:22:33.000000000', 'files': ['tasks/tempest_resources.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/d499a268bd121a87835569df72d6b1224ff9b90d', 'message': 'Use tempest_cloud_name for setting cloudname\n\nCurrently in tasks/tempest_resources.yml file, we are using\nansible provided openstack cloud modules which needs cloud name\nwhich is harded to default. When os_tempest role is getting used\nwith different deployment tool, cloud name varies. Adding\ntempest_cloud_name var mades it easier to use any cloud name defined\nin clouds.yaml file.\n\nChange-Id: I90b93c088f7bc2df0c8f10e6aff58d66c6645290\n'}]",5,628610,d499a268bd121a87835569df72d6b1224ff9b90d,15,8,3,12393,,,0,"Use tempest_cloud_name for setting cloudname

Currently in tasks/tempest_resources.yml file, we are using
ansible provided openstack cloud modules which needs cloud name
which is harded to default. When os_tempest role is getting used
with different deployment tool, cloud name varies. Adding
tempest_cloud_name var mades it easier to use any cloud name defined
in clouds.yaml file.

Change-Id: I90b93c088f7bc2df0c8f10e6aff58d66c6645290
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/10/628610/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/tempest_resources.yml', 'defaults/main.yml']",2,e4fe1d45f5295b150f5d330174e143f5012d6431,tempest_cloudrc,"## Tempest cloudrc name tempest_cloudrc: ""default"" ",,15,12
openstack%2Fopenstack-ansible-os_ironic~master~If68dd6aca6df63816c1ebe6265d388409bf0afb5,openstack/openstack-ansible-os_ironic,master,If68dd6aca6df63816c1ebe6265d388409bf0afb5,DNM testing gate,ABANDONED,2019-01-07 16:46:09.000000000,2019-01-07 18:33:44.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 16:46:09.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/e30248e2f56579794f2292d95eea27cd0639bfdb', 'message': 'DNM testing gate\n\nChange-Id: If68dd6aca6df63816c1ebe6265d388409bf0afb5\n'}]",0,629014,e30248e2f56579794f2292d95eea27cd0639bfdb,4,2,1,14288,,,0,"DNM testing gate

Change-Id: If68dd6aca6df63816c1ebe6265d388409bf0afb5
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/14/629014/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,e30248e2f56579794f2292d95eea27cd0639bfdb,DNM-testing-gate, - DNM-deleteme,,1,0
openstack%2Fansible-hardening~master~I6814764432da1b3480f1acf401d154395d21aaa0,openstack/ansible-hardening,master,I6814764432da1b3480f1acf401d154395d21aaa0,cleanup: allow running specific tags,ABANDONED,2019-01-07 17:56:20.000000000,2019-01-07 18:06:31.000000000,,[{'_account_id': 6816}],"[{'number': 1, 'created': '2019-01-07 17:56:20.000000000', 'files': ['tasks/main.yml', 'tasks/rhel7stig/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/048b405ec79ba4b699f07aee540f18800a33bcdd', 'message': 'cleanup: allow running specific tags\n\nThe previous changes broke the ability to run a specific tag, this\npatch fixes it by switching into task imports instead of includes.\n\nChange-Id: I6814764432da1b3480f1acf401d154395d21aaa0\n'}]",0,629023,048b405ec79ba4b699f07aee540f18800a33bcdd,3,1,1,1004,,,0,"cleanup: allow running specific tags

The previous changes broke the ability to run a specific tag, this
patch fixes it by switching into task imports instead of includes.

Change-Id: I6814764432da1b3480f1acf401d154395d21aaa0
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/23/629023/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/rhel7stig/main.yml']",2,048b405ec79ba4b699f07aee540f18800a33bcdd,,- import_tasks: accounts.yml - import_tasks: aide.yml - import_tasks: auditd.yml - import_tasks: auth.yml - import_tasks: file_perms.yml - import_tasks: graphical.yml - import_tasks: kernel.yml - import_tasks: lsm.yml - import_tasks: misc.yml - import_tasks: sshd.yml,- include_tasks: accounts.yml - include_tasks: aide.yml - include_tasks: auditd.yml - include_tasks: auth.yml - include_tasks: file_perms.yml - include_tasks: graphical.yml - include_tasks: kernel.yml - include_tasks: lsm.yml - include_tasks: misc.yml - include_tasks: sshd.yml,11,11
openstack%2Foslo.messaging~master~I7512ea93ac794d161a4cd9944546d6ca035a12cf,openstack/oslo.messaging,master,I7512ea93ac794d161a4cd9944546d6ca035a12cf,Avoid unnecessary use of items(),MERGED,2018-10-28 16:31:57.000000000,2019-01-07 18:01:34.000000000,2019-01-07 18:01:34.000000000,"[{'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-28 16:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c091b6af2ba2f0ffb9efff2789a4f936b9b6fa98', 'message': ""Avoid unnecessary use of items()\n\nThe key, value pair returned by items() wasn't used here,\nso rewrite the logic to just iterate over the keys, filtered\nby the type.\n\nChange-Id: I7512ea93ac794d161a4cd9944546d6ca035a12cf\n""}, {'number': 2, 'created': '2018-10-30 19:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c296d59d7f11b3bbd9dfdd2eab6679a1206c5cab', 'message': ""Avoid unnecessary use of items()\n\nThe key, value pair returned by items() wasn't used here,\nso rewrite the logic to just iterate over the keys, filtered\nby the type.\n\nChange-Id: I7512ea93ac794d161a4cd9944546d6ca035a12cf\n""}, {'number': 3, 'created': '2019-01-07 14:07:24.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/344ec5e8bb4a3df92e50edeab8d670f79aad5eb4', 'message': ""Avoid unnecessary use of items()\n\nThe key, value pair returned by items() wasn't used here,\nso rewrite the logic to just iterate over the keys, filtered\nby the type.\n\nChange-Id: I7512ea93ac794d161a4cd9944546d6ca035a12cf\n""}]",0,613799,344ec5e8bb4a3df92e50edeab8d670f79aad5eb4,18,4,3,6593,,,0,"Avoid unnecessary use of items()

The key, value pair returned by items() wasn't used here,
so rewrite the logic to just iterate over the keys, filtered
by the type.

Change-Id: I7512ea93ac794d161a4cd9944546d6ca035a12cf
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/99/613799/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,c091b6af2ba2f0ffb9efff2789a4f936b9b6fa98,613799," for consumer in six.filter(lambda c: c.type == 'fanout', self._consumers): LOG.debug('[connection close] Deleting fanout ' 'queue: %s ' % consumer.queue.name) consumer.queue.delete()"," for consumer, tag in self._consumers.items(): if consumer.type == 'fanout': LOG.debug('[connection close] Deleting fanout ' 'queue: %s ' % consumer.queue.name) consumer.queue.delete()",5,5
openstack%2Fkeystone~master~I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f,openstack/keystone,master,I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f,Clean up keystone-to-keystone section,MERGED,2019-01-02 13:16:43.000000000,2019-01-07 17:55:45.000000000,2019-01-07 17:55:45.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 13:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/be994b93abecd3999679d1bcaf086fb5d0dcdb4f', 'message': 'Clean up keystone-to-keystone section\n\nClean up the wording and add clarifications and examples to the guide on\nconfiguring keystone as an IdP.\n\nPartial-bug: #1793374\n\nChange-Id: I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f\n'}, {'number': 2, 'created': '2019-01-02 22:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ddb7083aae8aa2cad0f9f344247cecf20440dbc7', 'message': 'Clean up keystone-to-keystone section\n\nClean up the wording and add clarifications and examples to the guide on\nconfiguring keystone as an IdP.\n\nPartial-bug: #1793374\n\nChange-Id: I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f\n'}, {'number': 3, 'created': '2019-01-04 09:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4cea499f59fe81269a2587e3d4935501acc11f2e', 'message': 'Clean up keystone-to-keystone section\n\nClean up the wording and add clarifications and examples to the guide on\nconfiguring keystone as an IdP.\n\nPartial-bug: #1793374\n\nChange-Id: I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f\n'}, {'number': 4, 'created': '2019-01-07 15:57:06.000000000', 'files': ['doc/source/admin/federation/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d6930e171d200e2c07683bd179a804f220b8317', 'message': 'Clean up keystone-to-keystone section\n\nClean up the wording and add clarifications and examples to the guide on\nconfiguring keystone as an IdP.\n\nPartial-bug: #1793374\n\nChange-Id: I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f\n'}]",3,627968,3d6930e171d200e2c07683bd179a804f220b8317,16,4,4,8482,,,0,"Clean up keystone-to-keystone section

Clean up the wording and add clarifications and examples to the guide on
configuring keystone as an IdP.

Partial-bug: #1793374

Change-Id: I5feee2da6b8b8f15e1de2e2f1ba493f31babb35f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/68/627968/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/federation/configure_federation.rst'],1,be994b93abecd3999679d1bcaf086fb5d0dcdb4f,bug/1793374,"Configuring Metadata -------------------- Since keystone is acting as a SAML Identity Provider, its metadata must be configured in the ``[saml]`` section of ``keystone.conf`` so that it can served by the `metadata API`_. .. _metadata API: https://developer.openstack.org/api-ref/identity/v3-ext/index.html#retrieve-metadata-properties The two parameters that **must** be set in order for keystone to generate metadata are ``idp_entity_id`` and ``idp_sso_endpoint``:``idp_entity_id`` sets the Identity Provider entity ID, which is a string of your choosing that uniquely identifies the Identity Provider to any Service Provider. ``idp_sso_endpoint`` is required to generate valid metadata, but its value is currently not used because keystone as an Identity Provider does not support the SAML2.0 WebSSO auth profile. This may change in the future which is why there is no default value provided and must be set by the operator. For completeness, the following Organization and Contact configuration options should also be updated to reflect your organization and administrator contact details.It is important to take note of the default ``certfile`` and ``keyfile`` options, and adjust them if necessary: .. code-block:: ini certfile=/etc/keystone/ssl/certs/signing_cert.pem keyfile=/etc/keystone/ssl/private/signing_key.pem You must generate a PKI key pair and copy the files to these paths. You can use the ``openssl`` tool to do so. Keystone does not provide a utility for this. Check the ``idp_metadata_path`` setting and adjust it if necessary: .. code-block:: ini idp_metadata_path=/etc/keystone/saml2_idp_metadata.xmlFinally, restart the keystone WSGI service or the web server frontend: # systemctl restart apache2 Creating a Service Provider Resource ------------------------------------ Create a Service Provider resource to represent your Service Provider as an object in keystone: .. code-block:: console $ openstack service provider create keystonesp \ --service-provider-url https://sp.keystone.example.org/Shibboleth.sso/SAML2/ECP --auth-url https://sp.keystone.example.org/v3/OS-FEDERATION/identity_providers/keystoneidp/protocols/saml2/auth The ``--auth-url`` is the `federated auth endpoint`_ for a specific Identity Provider and protocol name, here named ``keystoneidp`` and ``saml2``. The ``--service-provider-url`` is the ``urn:oasis:names:tc:SAML:2.0:bindings:PAOS`` binding for the Assertion Consumer Service of the Service Provider. It can be obtained from the Service Provider metadata: .. code-block:: console $ curl -s https://sp.keystone.example.org/Shibboleth.sso/Metadata | grep urn:oasis:names:tc:SAML:2.0:bindings:PAOS <md:AssertionConsumerService Binding=""urn:oasis:names:tc:SAML:2.0:bindings:PAOS"" Location=""https://sp.keystone.example.org/Shibboleth.sso/SAML2/ECP"" index=""4""/> .. _federated auth endpoint: https://developer.openstack.org/api-ref/identity/v3-ext/index.html#request-an-unscoped-os-federation-token","Configuration Options --------------------- There are certain settings in ``keystone.conf`` that must be setup, prior to attempting to federate multiple keystone deployments. Within ``keystone.conf``, assign values to the ``[saml]`` related fields, for example:``idp_entity_id`` is the unique identifier for the Identity Provider. It usually takes the form of a URI but it does not have to resolve to anything. ``idp_sso_endpoint`` is required to generate valid metadata but its value is not important, though it may be in the future. Note the ``certfile``, ``keyfile``, and ``idp_metadata_path`` settings and adjust them if necessary: .. code-block:: ini certfile=/etc/keystone/ssl/certs/signing_cert.pem keyfile=/etc/keystone/ssl/private/signing_key.pem idp_metadata_path=/etc/keystone/saml2_idp_metadata.xml Though not necessary, the follow Organization configuration options should also be setup. It is recommended that these values be URL safe. As with the Organization options, the Contact options, are not necessary, but it's advisable to set these values too. .. code-block:: ini Generate Metadata ----------------- In order to create a trust between the IdP and SP, metadata must be exchanged. First, if you haven't already generated a PKI key pair, you need to do so and copy those files the locations designated by ``certfile`` and ``keyfile`` options that were assigned in the previous section. Ensure that your apache vhost has SSL enabled and is using that keypair by adding the following to the vhost:: SSLEngine on SSLCertificateFile /etc/keystone/ssl/certs/signing_cert.pem SSLCertificateKeyFile /etc/keystone/ssl/private/signing_key.pem.. NOTE:: The file location should match the value of the configuration option ``idp_metadata_path`` that was assigned in the previous section. Finally, restart apache. Create a Service Provider (SP) ------------------------------ In this example we are creating a new Service Provider with an ID of ``mysp``, a ``sp_url`` of ``https://sp.keystone.example.org/Shibboleth.sso/SAML2/ECP`` and a ``auth_url`` of ``https://sp.keystone.example.org/v3/OS-FEDERATION/identity_providers/samltest/protocols/saml2/auth`` . The ``sp_url`` will be used when creating a SAML assertion for ``mysp`` and signed by the current keystone IdP. The ``auth_url`` is used to retrieve the token for ``mysp`` once the SAML assertion is sent. $ openstack service provider create \ --service-provider-url 'https://sp.keystone.example.org/Shibboleth.sso/SAML2/ECP' \ --auth-url https://sp.keystone.example.org/v3/OS-FEDERATION/identity_providers/samltest/protocols/saml2/auth mysp",61,55
openstack%2Fkeystone~master~Ieec899a1551be69da232196c59b9aeed0e85f5f5,openstack/keystone,master,Ieec899a1551be69da232196c59b9aeed0e85f5f5,Enhance authn sections in federation guide,MERGED,2019-01-02 12:57:34.000000000,2019-01-07 17:55:42.000000000,2019-01-07 17:55:42.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 12:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5a6f27aef07b0862e694f72385b6c97e4c28fb45', 'message': 'Enhance authn sections in federation guide\n\nModernize the examples on using the CLI to authenticate with an external\nIdP or keystone IdP, add tips on how to get needed information, and add\nexamples on authenticating with horizon.\n\nPartial-bug: #1793374\n\nChange-Id: Ieec899a1551be69da232196c59b9aeed0e85f5f5\n'}, {'number': 2, 'created': '2019-01-02 22:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b17a7fb80511eabec0bfc960e1f1ede3a109d1ee', 'message': 'Enhance authn sections in federation guide\n\nModernize the examples on using the CLI to authenticate with an external\nIdP or keystone IdP, add tips on how to get needed information, and add\nexamples on authenticating with horizon.\n\nPartial-bug: #1793374\n\nChange-Id: Ieec899a1551be69da232196c59b9aeed0e85f5f5\n'}, {'number': 3, 'created': '2019-01-04 09:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e8b870fe777a8fdeb649e15784a8f9f92a02a801', 'message': 'Enhance authn sections in federation guide\n\nModernize the examples on using the CLI to authenticate with an external\nIdP or keystone IdP, add tips on how to get needed information, and add\nexamples on authenticating with horizon.\n\nPartial-bug: #1793374\n\nChange-Id: Ieec899a1551be69da232196c59b9aeed0e85f5f5\n'}, {'number': 4, 'created': '2019-01-07 15:57:06.000000000', 'files': ['doc/source/_static/horizon-login-idp.png', 'doc/source/_static/horizon-login-sp.png', 'doc/source/admin/federation/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/fc3dcc8071bd0c83618ad8abe19d8922669fa3d0', 'message': 'Enhance authn sections in federation guide\n\nModernize the examples on using the CLI to authenticate with an external\nIdP or keystone IdP, add tips on how to get needed information, and add\nexamples on authenticating with horizon.\n\nPartial-bug: #1793374\n\nChange-Id: Ieec899a1551be69da232196c59b9aeed0e85f5f5\n'}]",11,627966,fc3dcc8071bd0c83618ad8abe19d8922669fa3d0,20,4,4,8482,,,0,"Enhance authn sections in federation guide

Modernize the examples on using the CLI to authenticate with an external
IdP or keystone IdP, add tips on how to get needed information, and add
examples on authenticating with horizon.

Partial-bug: #1793374

Change-Id: Ieec899a1551be69da232196c59b9aeed0e85f5f5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/66/627966/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/horizon-login-idp.png', 'doc/source/_static/horizon-login-sp.png', 'doc/source/admin/federation/configure_federation.rst']",3,5a6f27aef07b0862e694f72385b6c97e4c28fb45,bug/1793374,"Authenticating -------------- Use the CLI to authenticate with a SAML2.0 Identity Provider ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. FIXME(cmurphy): Include examples for OpenID Connect authentication with the CLI The ``python-openstackclient`` can be used to authenticate a federated user in a SAML Identity Provider to keystone. The SAML Identity Provider must be configured to support ECP. .. note:: The SAML Identity Provider must be configured to support the ECP authentication profile. To use the CLI tool, you must have the name of the Identity Provider resource in keystone, the name of the federation protocol configured in keystone, and the ECP endpoint for the Identity Provider. If you are the cloud administrator, the name of the Identity Provider and protocol was configured in `Identity Provider`_ and `Protocol`_ respectively. If you are not the administrator, you must obtain this information from the administrator. The ECP endpoint for the Identity Provider can be obtained from its metadata without involving an administrator. This endpoint is the ``urn:oasis:names:tc:SAML:2.0:bindings:SOAP`` binding in the metadata document: .. code-block:: console $ curl -s https://samltest.id/saml/idp | grep urn:oasis:names:tc:SAML:2.0:bindings:SOAP <SingleSignOnService Binding=""urn:oasis:names:tc:SAML:2.0:bindings:SOAP"" Location=""https://samltest.id/idp/profile/SAML2/SOAP/ECP""/> ~~~~~~~~~~~~~~~~~~~~~ Find available scopesIf you are a new user and are not aware of what resources you have access to, you can use an unscoped query to list the projects or domains you have been granted a role assignment on: $ export OS_AUTH_TYPE=v3samlpassword $ export OS_IDENTITY_PROVIDER=samltest $ export OS_IDENTITY_PROVIDER_URL=https://samltest.id/idp/profile/SAML2/SOAP/ECP $ export OS_PROTOCOL=saml2 $ export OS_USERNAME=morty $ export OS_PASSWORD=panic $ export OS_AUTH_URL=https://sp.keystone.example.org/v3 $ # ... $ # ... .. warning:: The CLI does not currently support querying access for the `system scope`_ although it is possible to assign federated users a role assignment on it. .. _system scope: ../tokens-overview.html#system-scoped-tokens ~~~~~~~~~~~~~~~~~~If you already know the project, domain or system you wish to scope to, you can directly request a scoped token: export OS_AUTH_TYPE=v3samlpassword export OS_IDENTITY_PROVIDER=samltest export OS_IDENTITY_PROVIDER_URL=https://samltest.id/idp/profile/SAML2/SOAP/ECP export OS_PROTOCOL=saml2 export OS_USERNAME=morty export OS_PASSWORD=panic export OS_AUTH_URL=https://sp.keystone.example.org/v3 export OS_IDENTITY_API_VERSION=3 export OS_PROJECT_NAME=federated_project export OS_PROJECT_DOMAIN_NAME=Default openstack token issue Use horizon to authenticate with an external Identity Provider ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ When horizon is configured to enable WebSSO, a dropdown menu will appear on the login screen before the user has authenticated. Select an authentication method from the menu to be redirected to your Identity Provider for authentication. .. image:: ../../_static/horizon-login-sp.png :height: 400px :alt: Horizon login screen using external authenticationtoken for ``mysp`` once the SAML assertion is sent.Authenticating -------------- Use the CLI to authenticate with Keystone-to-Keystone ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ export OS_USERNAME=demo export OS_PASSWORD=nomoresecret export OS_AUTH_URL=https://idp.keystone.example.org/v3 export OS_IDENTITY_API_VERSION=3 export OS_PROJECT_NAME=federated_project export OS_PROJECT_DOMAIN_NAME=Default export OS_SERVICE_PROVIDER=keystonesp export OS_REMOTE_PROJECT_NAME=federated_project export OS_REMOTE_PROJECT_DOMAIN_NAME=Default openstack token issue Use Horizon to switch clouds ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ No additional configuration is necessary to enable horizon for Keystone to Keystone. Log into the horizon instance for the Identity Provider using your regular local keystone credentials. Once logged in, you will see a Service Provider dropdown menu which you can use to switch your dashboard view to another cloud. .. image:: ../../_static/horizon-login-idp.png :height: 175px :alt: Horizon dropdown menu for switching between keystone providers","Performing federated authentication ----------------------------------- .. NOTE:: Authentication with keystone-to-keystone federation does not follow these steps. See `Testing it all out`_ to authenticate with keystone-to-keystone. 1. Authenticate externally and generate an unscoped token in keystone 2. Determine accessible resources 3. Get a scoped token Get an unscoped tokenUnlike other authentication methods in the Identity Service, the user does not issue an HTTP POST request with authentication data in the request body. To start federated authentication a user must access the dedicated URL with Identity Provider's and Protocol's identifiers stored within a protected URL. The URL has a format of: ``/v3/OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}/auth``. In this instance we follow a standard SAML2 authentication procedure, that is, the user will be redirected to the Identity Provider's authentication webpage and be prompted for credentials. After successfully authenticating the user will be redirected to the Service Provider's endpoint. If using a web browser, a token will be returned in JSON format, with the ID in the X-Subject-Token header. In the returned unscoped token, a list of Identity Service groups the user belongs to will be included. Read more about `getting an unscoped token <https://developer.openstack.org/api-ref/identity/v3-ext/#request-an-unscoped-os-federation-token>`__. ~~~~~~~~~~~~ Example cURL ~~~~~~~~~~~~ Note that the request does not include a body. The following url would be considered protected by ``mod_shib`` and Apache, as such a request made to the URL would be redirected to the Identity Provider, to start the SAML authentication procedure. $ curl -X GET -D - https://sp.keystone.example.org/v3/OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}/auth Determine accessible resources ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ By using the previously returned token, the user can issue requests to the list projects and domains that are accessible. * List projects a federated user can access: ``GET /OS-FEDERATION/projects`` * List domains a federated user can access: ``GET /OS-FEDERATION/domains`` Read more about `listing resources <https://developer.openstack.org/api-ref/identity/v3-ext/#list-projects-a-federated-user-can-access>`__. ~~~~~~~ Example ~~~~~~~ .. code-block:: console $ export OS_TOKEN=<unscoped token> $ export OS_URL=https://sp.keystone.example.org/v3 or .. code-block:: console $ export OS_IDENTITY_API_VERSION=3 $ export OS_TOKEN=<unscoped token> $ export OS_URL=https://sp.keystone.example.org/v3A federated user may request a scoped token, by using the unscoped token. A project or domain may be specified by either ``id`` or ``name``. An ``id`` is sufficient to uniquely identify a project or domain. Read more about `getting a scoped token <https://developer.openstack.org/api-ref/identity/v3-ext/#request-a-scoped-os-federation-token>`__. ~~~~~~~ Example ~~~~~~~ $ export OS_AUTH_TYPE=token $ export OS_IDENTITY_API_VERSION=3 $ export OS_TOKEN=<unscoped token> $ export OS_AUTH_URL=https://sp.keystone.example.org/v3 $ export OS_PROJECT_DOMAIN_NAME=federated_domain $ export OS_PROJECT_NAME=federated_project $ openstack token issuetoken for ``mysp`` once the SAML assertion is sent. The auth_url has the format described in `Get an unscoped token`_.Testing it all out ------------------.. NOTE:: ECP stands for Enhanced Client or Proxy, an extension from the SAML2 protocol used in non-browser interfaces, like in the following example. $ openstack \ --os-service-provider mysp \ --os-remote-project-name federated_project \ --os-remote-project-domain-name federated_domain \ token issue ",103,97
openstack%2Fnova~master~I3799869fd4217d12b92d79e27484043ef5b8dc13,openstack/nova,master,I3799869fd4217d12b92d79e27484043ef5b8dc13,Fix circular import in nova.privsep.utils,MERGED,2019-01-03 21:21:22.000000000,2019-01-07 17:55:37.000000000,2019-01-07 17:55:37.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-03 21:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/faaf75688f56339e6a7a1116e352fc696853caac', 'message': 'Fix circular import in nova.privsep.utils\n\nCommit 26521718bdba3bccbf6270e26b76754c26304658 imported\nnova.utils into nova.privsep.utils which can cause\nan ImportError due to an ArgsAlreadyParseError because of\nnova.utils importing nova.conf which registers config options.\n\nFor some obscure reason, this is only being noticed when using\n[libvirt]/image_type=lvm, so something in the libvirt lvm image\nbackend using privsep is tickling this import error, but regardless\nthe nova.privsep code should avoid importing stuff from the\nrest of nova, so this change simply adds a simple\n""generate_random_string"" utility to nova.privsep.utils to\navoid the import.\n\nChange-Id: I3799869fd4217d12b92d79e27484043ef5b8dc13\nCloses-Bug: #1808247\n'}, {'number': 2, 'created': '2019-01-03 22:21:36.000000000', 'files': ['nova/tests/unit/privsep/test_utils.py', 'nova/privsep/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a371f11835e422c06be038d8ce79f38e8f64ab0d', 'message': 'Fix circular import in nova.privsep.utils\n\nCommit 26521718bdba3bccbf6270e26b76754c26304658 imported\nnova.utils into nova.privsep.utils which can cause\nan ImportError due to an ArgsAlreadyParseError because of\nnova.utils importing nova.conf which registers config options.\n\nFor some obscure reason, this is only being noticed when using\n[libvirt]/image_type=lvm, so something in the libvirt lvm image\nbackend using privsep is tickling this import error, but regardless\nthe nova.privsep code should avoid importing stuff from the\nrest of nova, so this change simply adds a simple\n""generate_random_string"" utility to nova.privsep.utils to\navoid the import.\n\nChange-Id: I3799869fd4217d12b92d79e27484043ef5b8dc13\nCloses-Bug: #1808247\n'}]",5,628302,a371f11835e422c06be038d8ce79f38e8f64ab0d,87,20,2,6873,,,0,"Fix circular import in nova.privsep.utils

Commit 26521718bdba3bccbf6270e26b76754c26304658 imported
nova.utils into nova.privsep.utils which can cause
an ImportError due to an ArgsAlreadyParseError because of
nova.utils importing nova.conf which registers config options.

For some obscure reason, this is only being noticed when using
[libvirt]/image_type=lvm, so something in the libvirt lvm image
backend using privsep is tickling this import error, but regardless
the nova.privsep code should avoid importing stuff from the
rest of nova, so this change simply adds a simple
""generate_random_string"" utility to nova.privsep.utils to
avoid the import.

Change-Id: I3799869fd4217d12b92d79e27484043ef5b8dc13
Closes-Bug: #1808247
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/628302/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/privsep/test_utils.py', 'nova/privsep/utils.py']",2,faaf75688f56339e6a7a1116e352fc696853caac,bug/1808247,"import random import sys# NOTE(mriedem): Avoid importing nova.utils since that can cause a circular # import with the privsep code. In fact, avoid importing anything outside # of nova/privsep/ if possible.def generate_random_string(): """"""Returns a random string using randint(0, maxint)"""""" return str(random.randint(0, sys.maxint)) # Use a random filename to avoid issues with $dirpath being on shared # storage. file_name = ""%s.%s"" % ("".directio.test"", generate_random_string())","from nova import utils as nova_utils file_name = ""%s.%s"" % ("".directio.test"", nova_utils.generate_random_string())",16,6
openstack%2Fkeystone~master~I32daa18880a1e646bff8856799b0d01776f0aa6f,openstack/keystone,master,I32daa18880a1e646bff8856799b0d01776f0aa6f,correct the description on domain re-enable,MERGED,2019-01-04 23:14:57.000000000,2019-01-07 17:35:41.000000000,2019-01-07 17:35:41.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 23:14:57.000000000', 'files': ['api-ref/source/v3/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb30a51811e467ba57ebc55d09485de2e94cd4bf', 'message': 'correct the description on domain re-enable\n\nChange-Id: I32daa18880a1e646bff8856799b0d01776f0aa6f\ncloses-bug: 1810485\n'}]",0,628705,bb30a51811e467ba57ebc55d09485de2e94cd4bf,7,3,1,1916,,,0,"correct the description on domain re-enable

Change-Id: I32daa18880a1e646bff8856799b0d01776f0aa6f
closes-bug: 1810485
",git fetch https://review.opendev.org/openstack/keystone refs/changes/05/628705/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v3/parameters.yaml'],1,bb30a51811e467ba57ebc55d09485de2e94cd4bf,bug/1810485," become invalid. However, if you reenable the domain, these tokens become valid again, providing that they haven't expired."," become no longer valid. If you reenable the domain, these tokens are not re-enabled.",2,2
openstack%2Fironic-tempest-plugin~master~Icf97a9cd5b88d2263551f32c0d3c1e09a712b346,openstack/ironic-tempest-plugin,master,Icf97a9cd5b88d2263551f32c0d3c1e09a712b346,[gate] update the list of the voting jobs,MERGED,2019-01-02 11:17:30.000000000,2019-01-07 17:33:40.000000000,2019-01-07 17:33:40.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-02 11:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/52c36a66b35b88152778a119ebd286a65cb8b26f', 'message': ""[gate] update the list of the voting jobs\n\nMake jobs running with N-3 (currently Pike) and older non-voting\n(and thus remove them from the gate queue). I have a gut feeling\nthat a change that breaks N-3 is very likely to break N-2 (currently\nQueens) as well, so it's enough to have N-2 voting.\n\nMake the discovery and the multinode jobs from all stable branches\nnon-voting.  These jobs cover the tests that get changed very infrequently\n(if ever).  These are also the jobs with the highest random failure rate.\n\nAdd missing API tests, voting for Queens to master, non-voting for Pike.\n\nChange-Id: Icf97a9cd5b88d2263551f32c0d3c1e09a712b346\n""}, {'number': 2, 'created': '2019-01-02 13:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/e2f78416e5f47cb0f686c34848286b3a10d5bdf1', 'message': ""[gate] update the list of the voting jobs\n\nMake jobs running with N-3 (currently Pike) and older non-voting\n(and thus remove them from the gate queue). I have a gut feeling\nthat a change that breaks N-3 is very likely to break N-2 (currently\nQueens) as well, so it's enough to have N-2 voting.\n\nMake the discovery and the multinode jobs from all stable branches\nnon-voting.  These jobs cover the tests that get changed very infrequently\n(if ever).  These are also the jobs with the highest random failure rate.\n\nAdd missing API tests for Rocky (this job did not exist before that).\nUse the updated job name for the multinode job.\n\nChange-Id: Icf97a9cd5b88d2263551f32c0d3c1e09a712b346\n""}, {'number': 3, 'created': '2019-01-02 13:08:28.000000000', 'files': ['zuul.d/stable-jobs.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/6fe29d2aedc3de74dc88250dc1a9a31b10adcc00', 'message': ""[gate] update the list of the voting jobs\n\nMake jobs running with N-3 (currently Pike) and older non-voting\n(and thus remove them from the gate queue). I have a gut feeling\nthat a change that breaks N-3 is very likely to break N-2 (currently\nQueens) as well, so it's enough to have N-2 voting.\n\nMake the discovery and the multinode jobs from all stable branches\nnon-voting.  These jobs cover the tests that get changed very infrequently\n(if ever).  These are also the jobs with the highest random failure rate.\n\nAdd missing API tests for Rocky (this job did not exist before that).\nUse the updated job name for the multinode job.\n\nChange-Id: Icf97a9cd5b88d2263551f32c0d3c1e09a712b346\n""}]",2,627955,6fe29d2aedc3de74dc88250dc1a9a31b10adcc00,14,4,3,10239,,,0,"[gate] update the list of the voting jobs

Make jobs running with N-3 (currently Pike) and older non-voting
(and thus remove them from the gate queue). I have a gut feeling
that a change that breaks N-3 is very likely to break N-2 (currently
Queens) as well, so it's enough to have N-2 voting.

Make the discovery and the multinode jobs from all stable branches
non-voting.  These jobs cover the tests that get changed very infrequently
(if ever).  These are also the jobs with the highest random failure rate.

Add missing API tests for Rocky (this job did not exist before that).
Use the updated job name for the multinode job.

Change-Id: Icf97a9cd5b88d2263551f32c0d3c1e09a712b346
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/55/627955/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/stable-jobs.yaml', 'zuul.d/project.yaml']",2,52c36a66b35b88152778a119ebd286a65cb8b26f,gate," # NOTE(dtantsur): keep N-3 and older non-voting for these jobs. - ironic-dsvm-standalone-pike: voting: false - ironic-tempest-dsvm-functional-python3-rocky - ironic-tempest-dsvm-functional-python3-queens - ironic-tempest-dsvm-functional-python3-pike: voting: false - ironic-tempest-dsvm-ironic-inspector-pike: voting: false # NOTE(dtantsur): these jobs cover rarely changed tests and are quite # unstable, so keep them non-voting on stable branches. - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-rocky: voting: false - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-queens: voting: false - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-pike: voting: false - ironic-inspector-tempest-dsvm-discovery-rocky: voting: false - ironic-inspector-tempest-dsvm-discovery-queens: voting: false - ironic-inspector-tempest-dsvm-discovery-pike: voting: false - ironic-tempest-dsvm-functional-python3-rocky - ironic-tempest-dsvm-functional-python3-queens - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode", - ironic-dsvm-standalone-pike - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-rocky - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-queens - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-pike - ironic-tempest-dsvm-ironic-inspector-pike - ironic-inspector-tempest-dsvm-discovery-rocky - ironic-inspector-tempest-dsvm-discovery-queens - ironic-inspector-tempest-dsvm-discovery-pike - ironic-dsvm-standalone-pike - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-rocky - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-queens - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-pike - ironic-tempest-dsvm-ironic-inspector-pike - ironic-inspector-tempest-dsvm-discovery-rocky - ironic-inspector-tempest-dsvm-discovery-queens - ironic-inspector-tempest-dsvm-discovery-pike,42,18
openstack%2Fironic~stable%2Fpike~I1bb62d55e3e18272fd5da355d63fd2c11a033acd,openstack/ironic,stable/pike,I1bb62d55e3e18272fd5da355d63fd2c11a033acd,Allow disabling instance image cache,MERGED,2019-01-04 16:15:26.000000000,2019-01-07 17:33:37.000000000,2019-01-07 17:33:37.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-01-04 16:15:26.000000000', 'files': ['ironic/conf/pxe.py', 'ironic/drivers/modules/iscsi_deploy.py', 'releasenotes/notes/fix-instance-master-path-config-fa524c907a7888e5.yaml', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d8521c4910f2b30903b97ed0712f8dca82b3a100', 'message': 'Allow disabling instance image cache\n\nWe document that this can be disabled by setting the\ninstance_master_path config  to ""<None>"",\nbut don\'t actually support it in code. oslo.config doesn\'t actually\ntranslate that value to the Python None as we expect.\n\nAllow disabling the cache by setting the config to the empty string, as\nin ""instance_master_path="". This doesn\'t make sense as a directory to\nuse as a cache anyway, so it shouldn\'t break anyone.\n\nConflicts:\n\tironic/drivers/modules/deploy_utils.py\nDue to class InstanceImageCache being in iscsi_deploy.py instead of\ndeploy_utils.py.\n\nChange-Id: I1bb62d55e3e18272fd5da355d63fd2c11a033acd\nStory: 2004279\nTask: 27829\n(cherry picked from commit 0498e2982901a586f19c9c8412c596bad0cf8004)\n'}]",0,628528,d8521c4910f2b30903b97ed0712f8dca82b3a100,11,7,1,6618,,,0,"Allow disabling instance image cache

We document that this can be disabled by setting the
instance_master_path config  to ""<None>"",
but don't actually support it in code. oslo.config doesn't actually
translate that value to the Python None as we expect.

Allow disabling the cache by setting the config to the empty string, as
in ""instance_master_path="". This doesn't make sense as a directory to
use as a cache anyway, so it shouldn't break anyone.

Conflicts:
	ironic/drivers/modules/deploy_utils.py
Due to class InstanceImageCache being in iscsi_deploy.py instead of
deploy_utils.py.

Change-Id: I1bb62d55e3e18272fd5da355d63fd2c11a033acd
Story: 2004279
Task: 27829
(cherry picked from commit 0498e2982901a586f19c9c8412c596bad0cf8004)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/28/628528/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conf/pxe.py', 'ironic/drivers/modules/iscsi_deploy.py', 'releasenotes/notes/fix-instance-master-path-config-fa524c907a7888e5.yaml', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py']",4,d8521c4910f2b30903b97ed0712f8dca82b3a100,story/2004279-stable/pike," class InstanceImageCacheTestCase(db_base.DbTestCase): @mock.patch.object(fileutils, 'ensure_tree') def test_with_master_path(self, mock_ensure_tree): self.config(instance_master_path='/fake/path', group='pxe') self.config(image_cache_size=500, group='pxe') self.config(image_cache_ttl=30, group='pxe') cache = iscsi_deploy.InstanceImageCache() mock_ensure_tree.assert_called_once_with('/fake/path') self.assertEqual(500 * 1024 * 1024, cache._cache_size) self.assertEqual(30 * 60, cache._cache_ttl) @mock.patch.object(fileutils, 'ensure_tree') def test_without_master_path(self, mock_ensure_tree): self.config(instance_master_path='', group='pxe') self.config(image_cache_size=500, group='pxe') self.config(image_cache_ttl=30, group='pxe') cache = iscsi_deploy.InstanceImageCache() mock_ensure_tree.assert_not_called() self.assertEqual(500 * 1024 * 1024, cache._cache_size) self.assertEqual(30 * 60, cache._cache_ttl)",,35,2
openstack%2Fironic~stable%2Fqueens~I1bb62d55e3e18272fd5da355d63fd2c11a033acd,openstack/ironic,stable/queens,I1bb62d55e3e18272fd5da355d63fd2c11a033acd,Allow disabling instance image cache,MERGED,2019-01-04 16:13:15.000000000,2019-01-07 17:33:34.000000000,2019-01-07 17:33:34.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-01-04 16:13:15.000000000', 'files': ['ironic/conf/pxe.py', 'ironic/drivers/modules/iscsi_deploy.py', 'releasenotes/notes/fix-instance-master-path-config-fa524c907a7888e5.yaml', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/56b5d3f0bc8ca25b6601a22508e3e173dc46e853', 'message': 'Allow disabling instance image cache\n\nWe document that this can be disabled by setting the\ninstance_master_path config  to ""<None>"",\nbut don\'t actually support it in code. oslo.config doesn\'t actually\ntranslate that value to the Python None as we expect.\n\nAllow disabling the cache by setting the config to the empty string, as\nin ""instance_master_path="". This doesn\'t make sense as a directory to\nuse as a cache anyway, so it shouldn\'t break anyone.\n\nConflicts:\n\tironic/drivers/modules/deploy_utils.py\nDue to class InstanceImageCache being in iscsi_deploy.py instead of\ndeploy_utils.py.\n\nChange-Id: I1bb62d55e3e18272fd5da355d63fd2c11a033acd\nStory: 2004279\nTask: 27829\n(cherry picked from commit 0498e2982901a586f19c9c8412c596bad0cf8004)\n'}]",0,628527,56b5d3f0bc8ca25b6601a22508e3e173dc46e853,12,7,1,6618,,,0,"Allow disabling instance image cache

We document that this can be disabled by setting the
instance_master_path config  to ""<None>"",
but don't actually support it in code. oslo.config doesn't actually
translate that value to the Python None as we expect.

Allow disabling the cache by setting the config to the empty string, as
in ""instance_master_path="". This doesn't make sense as a directory to
use as a cache anyway, so it shouldn't break anyone.

Conflicts:
	ironic/drivers/modules/deploy_utils.py
Due to class InstanceImageCache being in iscsi_deploy.py instead of
deploy_utils.py.

Change-Id: I1bb62d55e3e18272fd5da355d63fd2c11a033acd
Story: 2004279
Task: 27829
(cherry picked from commit 0498e2982901a586f19c9c8412c596bad0cf8004)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/27/628527/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conf/pxe.py', 'ironic/drivers/modules/iscsi_deploy.py', 'releasenotes/notes/fix-instance-master-path-config-fa524c907a7888e5.yaml', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py']",4,56b5d3f0bc8ca25b6601a22508e3e173dc46e853,story/2004279," class InstanceImageCacheTestCase(db_base.DbTestCase): @mock.patch.object(fileutils, 'ensure_tree') def test_with_master_path(self, mock_ensure_tree): self.config(instance_master_path='/fake/path', group='pxe') self.config(image_cache_size=500, group='pxe') self.config(image_cache_ttl=30, group='pxe') cache = iscsi_deploy.InstanceImageCache() mock_ensure_tree.assert_called_once_with('/fake/path') self.assertEqual(500 * 1024 * 1024, cache._cache_size) self.assertEqual(30 * 60, cache._cache_ttl) @mock.patch.object(fileutils, 'ensure_tree') def test_without_master_path(self, mock_ensure_tree): self.config(instance_master_path='', group='pxe') self.config(image_cache_size=500, group='pxe') self.config(image_cache_ttl=30, group='pxe') cache = iscsi_deploy.InstanceImageCache() mock_ensure_tree.assert_not_called() self.assertEqual(500 * 1024 * 1024, cache._cache_size) self.assertEqual(30 * 60, cache._cache_ttl)",,35,2
openstack%2Fironic~stable%2Frocky~I1bb62d55e3e18272fd5da355d63fd2c11a033acd,openstack/ironic,stable/rocky,I1bb62d55e3e18272fd5da355d63fd2c11a033acd,Allow disabling instance image cache,MERGED,2019-01-03 17:33:41.000000000,2019-01-07 17:33:31.000000000,2019-01-07 17:33:31.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14208}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-01-03 17:33:41.000000000', 'files': ['ironic/conf/pxe.py', 'ironic/drivers/modules/iscsi_deploy.py', 'releasenotes/notes/fix-instance-master-path-config-fa524c907a7888e5.yaml', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef50e5a2eaf15b43c37283d8e7c73f8df3ec7e4a', 'message': 'Allow disabling instance image cache\n\nWe document that this can be disabled by setting the\ninstance_master_path config  to ""<None>"",\nbut don\'t actually support it in code. oslo.config doesn\'t actually\ntranslate that value to the Python None as we expect.\n\nAllow disabling the cache by setting the config to the empty string, as\nin ""instance_master_path="". This doesn\'t make sense as a directory to\nuse as a cache anyway, so it shouldn\'t break anyone.\n\nConflicts:\n\tironic/drivers/modules/deploy_utils.py\nDue to class InstanceImageCache being in iscsi_deploy.py instead of\ndeploy_utils.py.\n\nChange-Id: I1bb62d55e3e18272fd5da355d63fd2c11a033acd\nStory: 2004279\nTask: 27829\n(cherry picked from commit 0498e2982901a586f19c9c8412c596bad0cf8004)\n'}]",0,628229,ef50e5a2eaf15b43c37283d8e7c73f8df3ec7e4a,13,6,1,6618,,,0,"Allow disabling instance image cache

We document that this can be disabled by setting the
instance_master_path config  to ""<None>"",
but don't actually support it in code. oslo.config doesn't actually
translate that value to the Python None as we expect.

Allow disabling the cache by setting the config to the empty string, as
in ""instance_master_path="". This doesn't make sense as a directory to
use as a cache anyway, so it shouldn't break anyone.

Conflicts:
	ironic/drivers/modules/deploy_utils.py
Due to class InstanceImageCache being in iscsi_deploy.py instead of
deploy_utils.py.

Change-Id: I1bb62d55e3e18272fd5da355d63fd2c11a033acd
Story: 2004279
Task: 27829
(cherry picked from commit 0498e2982901a586f19c9c8412c596bad0cf8004)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/628229/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conf/pxe.py', 'ironic/drivers/modules/iscsi_deploy.py', 'releasenotes/notes/fix-instance-master-path-config-fa524c907a7888e5.yaml', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py']",4,ef50e5a2eaf15b43c37283d8e7c73f8df3ec7e4a,story/2004279," class InstanceImageCacheTestCase(db_base.DbTestCase): @mock.patch.object(fileutils, 'ensure_tree') def test_with_master_path(self, mock_ensure_tree): self.config(instance_master_path='/fake/path', group='pxe') self.config(image_cache_size=500, group='pxe') self.config(image_cache_ttl=30, group='pxe') cache = iscsi_deploy.InstanceImageCache() mock_ensure_tree.assert_called_once_with('/fake/path') self.assertEqual(500 * 1024 * 1024, cache._cache_size) self.assertEqual(30 * 60, cache._cache_ttl) @mock.patch.object(fileutils, 'ensure_tree') def test_without_master_path(self, mock_ensure_tree): self.config(instance_master_path='', group='pxe') self.config(image_cache_size=500, group='pxe') self.config(image_cache_ttl=30, group='pxe') cache = iscsi_deploy.InstanceImageCache() mock_ensure_tree.assert_not_called() self.assertEqual(500 * 1024 * 1024, cache._cache_size) self.assertEqual(30 * 60, cache._cache_ttl)",,35,2
openstack%2Foslo.utils~master~I81579e2977bb965a5398a2cb4e3e24f5671e856a,openstack/oslo.utils,master,I81579e2977bb965a5398a2cb4e3e24f5671e856a,Fix race condition in eventletutils Event,MERGED,2018-11-16 08:19:29.000000000,2019-01-07 16:50:33.000000000,2019-01-07 16:50:32.000000000,"[{'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 9257}, {'_account_id': 22348}, {'_account_id': 27954}, {'_account_id': 28522}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-11-16 08:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/2c0e070d4299b67e131e4df6be02de0f1c414785', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 2, 'created': '2018-11-16 09:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/1ee343b6c2d849156ce9c810462c893263cb71ce', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 3, 'created': '2018-11-16 09:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/d01ff324d7a49df4699d6e0eeacb9d1b12c46d73', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 4, 'created': '2018-11-22 14:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/701fb4c11cdb2546a9daf1bf7ff5f76719b089ff', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 5, 'created': '2018-11-26 10:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/e21194d5c54c30f59f1b5f14ee89b2db9628fb08', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 6, 'created': '2018-11-28 21:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/d14e53ec89db8b0a606d78c3c2b08817773deb2f', 'message': 'Fix race condition in eventletutils Event\n\nThe threading-compatible eventlet Event class has a race condition on\nthe wait method. If greenthread A is blocked on the wait, but another\ngreenthread B calls clear() and then set(), B calls self._event.send(),\nbut A is waiting on a different eventlet Event which is no longer used\nby the oslo.service Event...\n\nTo resolve this, when clearing an Event trigger the underlying eventlet\nEvent immediately, then have the wait() method resume waiting on the new\neventlet Event.\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\nCo-Authored-By: Victor Stinner <vstinner@redhat.com>\nCo-Authored-By: Hervé Beraud <hberaud@redhat.com>\nCloses-Bug: #1805706\n'}, {'number': 7, 'created': '2018-11-29 18:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/b6e7f6b85ba979ee3ba76c8a28617826af5458c1', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 8, 'created': '2018-11-30 09:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/9d0fbcae94ac6d99c7e59f6203242dbf066b3a63', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 9, 'created': '2018-11-30 09:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/0cd5c846b32f5b996b8a9071afebf85b2c5460dd', 'message': 'Fixing race condition\n\nis there a race condition on the wait method, a greenthread A is blocked\non the wait, but another greenthread B calls clear() and then set(),\nB calls self._event.send(), but A is waiting on a different eventlet\nEvent which is no longer used by the oslo.service Event...\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\n'}, {'number': 10, 'created': '2018-12-02 23:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/bd8f1d2ceb618f5ddeab20582167b7082ff04d60', 'message': 'Fix race condition in eventletutils Event\n\nThe threading-compatible eventlet Event class has a race condition on\nthe wait method. If greenthread A is blocked on the wait, but another\ngreenthread B calls clear() and then set(), B calls self._event.send(),\nbut A is waiting on a different eventlet Event which is no longer used\nby the oslo.service Event...\n\nTo resolve this, when clearing an Event trigger the underlying eventlet\nEvent immediately, then have the wait() method resume waiting on the new\neventlet Event.\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\nCo-Authored-By: Victor Stinner <vstinner@redhat.com>\nCo-Authored-By: Hervé Beraud <hberaud@redhat.com>\nCloses-Bug: #1805706\n'}, {'number': 11, 'created': '2018-12-05 00:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/2aca971e8aba8abc2bc608ec125f849a61e0a545', 'message': 'Fix race condition in eventletutils Event\n\nThe threading-compatible eventlet Event class has a race condition on\nthe wait method. If greenthread A is blocked on the wait, but another\ngreenthread B calls clear() and then set(), B calls self._event.send(),\nbut A is waiting on a different eventlet Event which is no longer used\nby the oslo.service Event...\n\nTo resolve this, when clearing an Event trigger the underlying eventlet\nEvent immediately, then have the wait() method resume waiting on the new\neventlet Event.\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\nCo-Authored-By: Victor Stinner <vstinner@redhat.com>\nCo-Authored-By: Hervé Beraud <hberaud@redhat.com>\nCloses-Bug: #1805706\n'}, {'number': 12, 'created': '2018-12-05 03:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/76c5160e519c269661b2a9c8ffb3c86251e35665', 'message': 'Fix race condition in eventletutils Event\n\nThe threading-compatible eventlet Event class has a race condition on\nthe wait method. If greenthread A is blocked on the wait, but another\ngreenthread B calls clear() and then set(), B calls self._event.send(),\nbut A is waiting on a different eventlet Event which is no longer used\nby the oslo.service Event...\n\nTo resolve this, when clearing an Event trigger the underlying eventlet\nEvent immediately, then have the wait() method resume waiting on the new\neventlet Event.\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\nCo-Authored-By: Victor Stinner <vstinner@redhat.com>\nCo-Authored-By: Hervé Beraud <hberaud@redhat.com>\nCloses-Bug: #1805706\n'}, {'number': 13, 'created': '2018-12-05 07:08:00.000000000', 'files': ['oslo_utils/tests/test_eventletutils.py', 'test-requirements.txt', 'lower-constraints.txt', 'oslo_utils/eventletutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/cc8b51e1e16f6bdc7d6c0e571e2002e70cde098d', 'message': 'Fix race condition in eventletutils Event\n\nThe threading-compatible eventlet Event class has a race condition on\nthe wait method. If greenthread A is blocked on the wait, but another\ngreenthread B calls clear() and then set(), B calls self._event.send(),\nbut A is waiting on a different eventlet Event which is no longer used\nby the oslo.service Event...\n\nTo resolve this, when clearing an Event trigger the underlying eventlet\nEvent immediately, then have the wait() method resume waiting on the new\neventlet Event.\n\nChange-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a\nCo-Authored-By: Victor Stinner <vstinner@redhat.com>\nCo-Authored-By: Hervé Beraud <hberaud@redhat.com>\nCloses-Bug: #1805706\n'}]",12,618482,cc8b51e1e16f6bdc7d6c0e571e2002e70cde098d,42,8,13,28522,,,0,"Fix race condition in eventletutils Event

The threading-compatible eventlet Event class has a race condition on
the wait method. If greenthread A is blocked on the wait, but another
greenthread B calls clear() and then set(), B calls self._event.send(),
but A is waiting on a different eventlet Event which is no longer used
by the oslo.service Event...

To resolve this, when clearing an Event trigger the underlying eventlet
Event immediately, then have the wait() method resume waiting on the new
eventlet Event.

Change-Id: I81579e2977bb965a5398a2cb4e3e24f5671e856a
Co-Authored-By: Victor Stinner <vstinner@redhat.com>
Co-Authored-By: Hervé Beraud <hberaud@redhat.com>
Closes-Bug: #1805706
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/82/618482/4 && git format-patch -1 --stdout FETCH_HEAD,['oslo_utils/eventletutils.py'],1,2c0e070d4299b67e131e4df6be02de0f1c414785,bug/1805706," try: old_event = self._event old_event.send(True) except AttributeError: # no old event exist # nothing to do and nothing to send pass event = self._event while True: with _eventlet.timeout.Timeout(timeout, False): event.wait() if event is not self._event: continue break"," with _eventlet.timeout.Timeout(timeout, False): self._event.wait()",14,2
openstack%2Fopenstack-chef~master~I6c25a071fa6db1b498adb56500ae5456ecf98781,openstack/openstack-chef,master,I6c25a071fa6db1b498adb56500ae5456ecf98781,Update the example roles and AIO Kitchen scenario,MERGED,2018-12-14 22:33:10.000000000,2019-01-07 16:47:31.000000000,2019-01-07 16:47:30.000000000,"[{'_account_id': 11915}, {'_account_id': 19193}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-14 22:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/028c75c5da292dc174a2dea0b1132fc8ab8d4daf', 'message': 'Update the example roles and AIO Kitchen scenario\n\nThis change:\n- pins poise at known stable releases for Kitchen\n- removes deprecated build toolchain cookbook dependency\n\nChange-Id: I6c25a071fa6db1b498adb56500ae5456ecf98781\n'}, {'number': 2, 'created': '2018-12-14 23:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/37d460cfaa03b31024b700ff88f1a2bb7e3560e3', 'message': 'Update the example roles and AIO Kitchen scenario\n\nThis change:\n- pins poise at known stable releases for Kitchen\n- removes deprecated build toolchain cookbook dependency\n\nDepends-On: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\nDepends-On: Ib8c788f69e9545b2d7121199590e3795f2212c7f\nDepends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c\nChange-Id: I6c25a071fa6db1b498adb56500ae5456ecf98781\n'}, {'number': 3, 'created': '2018-12-14 23:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/8a7f639cfb70298bf6ec4071e0dab35833ecd326', 'message': 'Update the example roles and AIO Kitchen scenario\n\nThis change:\n- pins poise at known stable releases for Kitchen\n- removes deprecated build toolchain cookbook dependency\n\nDepends-On: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\nDepends-On: Ib8c788f69e9545b2d7121199590e3795f2212c7f\nChange-Id: I6c25a071fa6db1b498adb56500ae5456ecf98781\n'}, {'number': 4, 'created': '2018-12-15 01:17:14.000000000', 'files': ['roles/multinode-controller.json', 'roles/multinode-network.json', 'roles/allinone.json', 'roles/multinode-compute.json', '.kitchen.yml'], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/bd5961e8ccc78c1e8d8ecc2583609ec687189a1f', 'message': 'Update the example roles and AIO Kitchen scenario\n\nThis change:\n- pins poise at known stable releases for Kitchen\n- removes deprecated build toolchain cookbook dependency\n\nChange-Id: I6c25a071fa6db1b498adb56500ae5456ecf98781\n'}]",0,625365,bd5961e8ccc78c1e8d8ecc2583609ec687189a1f,14,3,4,14790,,,0,"Update the example roles and AIO Kitchen scenario

This change:
- pins poise at known stable releases for Kitchen
- removes deprecated build toolchain cookbook dependency

Change-Id: I6c25a071fa6db1b498adb56500ae5456ecf98781
",git fetch https://review.opendev.org/openstack/openstack-chef refs/changes/65/625365/2 && git format-patch -1 --stdout FETCH_HEAD,"['roles/multinode-controller.json', 'roles/multinode-network.json', 'roles/allinone.json', '.kitchen.yml', 'roles/multinode-compute.json']",5,028c75c5da292dc174a2dea0b1132fc8ab8d4daf,chef_14_fixes,," ""recipe[build-essential]"",",7,6
openstack%2Fcookbook-openstack-bare-metal~master~Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7,openstack/cookbook-openstack-bare-metal,master,Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7,Convert hyphens to underscores for service names,MERGED,2018-12-11 01:00:01.000000000,2019-01-07 16:36:27.000000000,2019-01-07 16:36:27.000000000,"[{'_account_id': 11915}, {'_account_id': 14790}, {'_account_id': 19193}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-11 01:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/ea2d779f550f72446f49f9766123d3c9540f3679', 'message': 'Convert baremetal service name to bare_metal\n\nIn order to better align with Chef best practices[1], the\nservice name is converted to use underscores instead of\nhyphens.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nDepends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 2, 'created': '2018-12-11 01:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/4ae662d8b5f308d2bf265d62832a734c5d5b28bd', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using underscores for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nDepends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 3, 'created': '2018-12-14 07:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/52a207a9c23a4b7b6f45d3ecaa644d41333ce33a', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using hyphens for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 4, 'created': '2018-12-14 23:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/7217ad5add1e0806cc840644a62f508174c98bd2', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using hyphens for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 5, 'created': '2018-12-14 23:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/f6db3c89e9a0655441c7578c7ef09cd14f99406e', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using hyphens for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nDepends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 6, 'created': '2018-12-15 01:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/547dd7372158e2cc602e2c4988f57f5d5d4f3031', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using hyphens for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nDepends-On: Ib8c788f69e9545b2d7121199590e3795f2212c7f\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 7, 'created': '2018-12-15 01:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/624c681a8f52156e2ab94ea50ec6c501ea1a0919', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using hyphens for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nDepends-On: Ib8c788f69e9545b2d7121199590e3795f2212c7f\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}, {'number': 8, 'created': '2018-12-15 07:56:36.000000000', 'files': ['.gitreview', 'spec/ironic-common_spec.rb', 'templates/default/ironic.conf.erb', 'attributes/conductor_conf.rb', 'attributes/ironic_conf.rb', 'recipes/api.rb', 'recipes/ironic-common.rb', 'recipes/conductor.rb', 'templates/default/rootwrap.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/identity_registration_spec.rb', 'recipes/identity_registration.rb', 'templates/default/wsgi-template.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/68389100a4002df101aae045e357b9b260b8099f', 'message': 'Convert hyphens to underscores for service names\n\nThe Chef Style Guide[1] does not recommend using hyphens for\ncookbook or resource names. To maintain consistency, we should follow\nbest practices.\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n\nDepends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c\nChange-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7\n'}]",0,624256,68389100a4002df101aae045e357b9b260b8099f,21,4,8,14790,,,0,"Convert hyphens to underscores for service names

The Chef Style Guide[1] does not recommend using hyphens for
cookbook or resource names. To maintain consistency, we should follow
best practices.

[1]: https://docs.chef.io/ruby.html#use-of-hyphens

Depends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c
Change-Id: Ib8b6ed53f2d4e97ea5bfc89f5fb8fac42308b3b7
",git fetch https://review.opendev.org/openstack/cookbook-openstack-bare-metal refs/changes/56/624256/8 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'spec/ironic-common_spec.rb', 'templates/default/ironic.conf.erb', 'attributes/conductor_conf.rb', 'attributes/ironic_conf.rb', 'recipes/api.rb', 'recipes/ironic-common.rb', 'recipes/conductor.rb', 'templates/default/rootwrap.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/identity_registration_spec.rb', 'recipes/identity_registration.rb', 'templates/default/wsgi-template.conf.erb']",14,ea2d779f550f72446f49f9766123d3c9540f3679,chef_14_fixes,<%= node['openstack']['bare_metal']['custom_template_banner'] %>,<%= node['openstack']['baremetal']['custom_template_banner'] %>,117,113
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ic0789da4645a4ee186d82ad7d943de78d4d5c443,openstack/tripleo-heat-templates,stable/rocky,Ic0789da4645a4ee186d82ad7d943de78d4d5c443,puppet_config for rabbitmq_bundle needs file_line,MERGED,2018-12-20 15:21:13.000000000,2019-01-07 16:30:55.000000000,2019-01-07 16:30:55.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-20 15:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/69b5a701d1600bb6fa672e9348a2132843cfd89b', 'message': 'puppet_config for rabbitmq_bundle needs file_line\n\nThe main reason for this change is that in a related puppet-tripleo patch\nwe will use the file_line puppet class in order to set some parameters\nto reduce the excessive rabbitmq logging.\n\nBecause this change will be very specific to rabbitmq running in a\ncontainer we also need to make sure that we actually use the\nrabbitmq_bundle puppet manifest to create config files and not the\nmore generic one.\n\nChange-Id: Ic0789da4645a4ee186d82ad7d943de78d4d5c443\nRelated-Bug: #1806451\n(cherry picked from commit 34aa23814ed80be7202ae8d92bdae08ad640f861)\n'}, {'number': 2, 'created': '2019-01-07 07:42:20.000000000', 'files': ['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f750ab67ead3692145c7bf78f77edc96bf0cc97d', 'message': 'puppet_config for rabbitmq_bundle needs file_line\n\nThe main reason for this change is that in a related puppet-tripleo patch\nwe will use the file_line puppet class in order to set some parameters\nto reduce the excessive rabbitmq logging.\n\nBecause this change will be very specific to rabbitmq running in a\ncontainer we also need to make sure that we actually use the\nrabbitmq_bundle puppet manifest to create config files and not the\nmore generic one.\n\nChange-Id: Ic0789da4645a4ee186d82ad7d943de78d4d5c443\nRelated-Bug: #1806451\n(cherry picked from commit 34aa23814ed80be7202ae8d92bdae08ad640f861)\n'}]",0,626595,f750ab67ead3692145c7bf78f77edc96bf0cc97d,11,4,2,20172,,,0,"puppet_config for rabbitmq_bundle needs file_line

The main reason for this change is that in a related puppet-tripleo patch
we will use the file_line puppet class in order to set some parameters
to reduce the excessive rabbitmq logging.

Because this change will be very specific to rabbitmq running in a
container we also need to make sure that we actually use the
rabbitmq_bundle puppet manifest to create config files and not the
more generic one.

Change-Id: Ic0789da4645a4ee186d82ad7d943de78d4d5c443
Related-Bug: #1806451
(cherry picked from commit 34aa23814ed80be7202ae8d92bdae08ad640f861)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/95/626595/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml']",2,69b5a701d1600bb6fa672e9348a2132843cfd89b,bug/1806451," puppet_tags: 'file,file_line' - ""include ::tripleo::profile::pacemaker::rabbitmq_bundle"""," puppet_tags: file - get_attr: [RabbitmqBase, role_data, step_config]",4,4
openstack%2Fopenstack-helm-infra~master~I5ddebb059e3c31c231fdc4c24190a65f23e37785,openstack/openstack-helm-infra,master,I5ddebb059e3c31c231fdc4c24190a65f23e37785,Mariadb: Add security context for mysql exporter pod/container,MERGED,2019-01-03 21:27:31.000000000,2019-01-07 16:30:36.000000000,2019-01-07 16:30:36.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-01-03 21:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/094d5ca48275a604ef3c54fe715e78eda5615d9f', 'message': 'Mariadb: Add security context for mysql exporter uid\n\nThis adds a security context to the mysql prometheus exporter pod,\nwhich changes the user from root to the nobody user (uid 99 here)\ninstead\n\nChange-Id: I5ddebb059e3c31c231fdc4c24190a65f23e37785\n'}, {'number': 2, 'created': '2019-01-03 22:16:06.000000000', 'files': ['mariadb/values.yaml', 'mariadb/templates/monitoring/prometheus/exporter-deployment.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/530e765815837ec56a67fc3024fe5576d08e2a00', 'message': 'Mariadb: Add security context for mysql exporter pod/container\n\nThis adds a security context to the mysql prometheus exporter pod,\nwhich changes the user from root to the nobody user (uid 99 here)\ninstead\n\nThis also adds the container security context to explicitly set\nallowPrivilegeEscalation to false\n\nChange-Id: I5ddebb059e3c31c231fdc4c24190a65f23e37785\n'}]",0,628303,530e765815837ec56a67fc3024fe5576d08e2a00,12,5,2,17591,,,0,"Mariadb: Add security context for mysql exporter pod/container

This adds a security context to the mysql prometheus exporter pod,
which changes the user from root to the nobody user (uid 99 here)
instead

This also adds the container security context to explicitly set
allowPrivilegeEscalation to false

Change-Id: I5ddebb059e3c31c231fdc4c24190a65f23e37785
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/03/628303/2 && git format-patch -1 --stdout FETCH_HEAD,"['mariadb/templates/monitoring/prometheus/exporter-deployment.yaml', 'mariadb/values.yaml']",2,094d5ca48275a604ef3c54fe715e78eda5615d9f,mariadb-exporter/pod-uid, user: mysql_exporter: uid: 99,,4,0
openstack%2Fopenstack-helm-infra~master~I3401c1a67f17cef49a478be98f9ab42691b84d66,openstack/openstack-helm-infra,master,I3401c1a67f17cef49a478be98f9ab42691b84d66,Memcached: Add security context for exporter pod/container,MERGED,2019-01-03 21:03:24.000000000,2019-01-07 16:30:35.000000000,2019-01-07 16:30:35.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-01-03 21:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c6e26ead3682532f1efb297055d79617a4707d80', 'message': 'Memcached: Add security context for exporter pod uid\n\nThis adds the security context to the memcached prometheus\nexporter pod, which changes the default user from root to the\nnobody user instead\n\nChange-Id: I3401c1a67f17cef49a478be98f9ab42691b84d66\n'}, {'number': 2, 'created': '2019-01-03 22:15:12.000000000', 'files': ['memcached/templates/monitoring/prometheus/exporter-deployment.yaml', 'memcached/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/96a3cf2f6ec58434dce2aef2f711fce01b98adaf', 'message': 'Memcached: Add security context for exporter pod/container\n\nThis adds the security context to the memcached prometheus\nexporter pod, which changes the default user from root to the\nnobody user instead\n\nThis also adds the container security context to explicitly set\nallowPrivilegeEscalation to false\n\nChange-Id: I3401c1a67f17cef49a478be98f9ab42691b84d66\n'}]",0,628298,96a3cf2f6ec58434dce2aef2f711fce01b98adaf,9,4,2,17591,,,0,"Memcached: Add security context for exporter pod/container

This adds the security context to the memcached prometheus
exporter pod, which changes the default user from root to the
nobody user instead

This also adds the container security context to explicitly set
allowPrivilegeEscalation to false

Change-Id: I3401c1a67f17cef49a478be98f9ab42691b84d66
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/98/628298/1 && git format-patch -1 --stdout FETCH_HEAD,"['memcached/templates/monitoring/prometheus/exporter-deployment.yaml', 'memcached/values.yaml']",2,c6e26ead3682532f1efb297055d79617a4707d80,memcached-exporter/pod-uid, user: memcached_exporter: uid: 65534,,4,0
openstack%2Fopenstack-helm-infra~master~Ie4423c57e871a03ab4baea346ac777c9f2ca3e2e,openstack/openstack-helm-infra,master,Ie4423c57e871a03ab4baea346ac777c9f2ca3e2e,Alertmanager: Add security context for pod/container,MERGED,2019-01-03 20:52:24.000000000,2019-01-07 16:30:34.000000000,2019-01-07 16:30:34.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-01-03 20:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/400fbdf67ee7fc9478e0d38114676a708faafacd', 'message': 'Alertmanager: Add security context snippet for pod uid\n\nThis adds the security context snipper to the alertmanager pod.\nThis changes the default user from root to the nobody user instead\n\nChange-Id: Ie4423c57e871a03ab4baea346ac777c9f2ca3e2e\n'}, {'number': 2, 'created': '2019-01-03 22:14:05.000000000', 'files': ['prometheus-alertmanager/templates/statefulset.yaml', 'prometheus-alertmanager/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/72e231c5c16f797032e27832d4054dc6390f7dab', 'message': 'Alertmanager: Add security context for pod/container\n\nThis adds the security context snipper to the alertmanager pod.\nThis changes the default user from root to the nobody user instead\n\nThis also adds the container security context to explicitly set\nallowPrivilegeEscalation to false\n\nChange-Id: Ie4423c57e871a03ab4baea346ac777c9f2ca3e2e\n'}]",1,628297,72e231c5c16f797032e27832d4054dc6390f7dab,14,5,2,17591,,,0,"Alertmanager: Add security context for pod/container

This adds the security context snipper to the alertmanager pod.
This changes the default user from root to the nobody user instead

This also adds the container security context to explicitly set
allowPrivilegeEscalation to false

Change-Id: Ie4423c57e871a03ab4baea346ac777c9f2ca3e2e
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/97/628297/2 && git format-patch -1 --stdout FETCH_HEAD,"['prometheus-alertmanager/templates/statefulset.yaml', 'prometheus-alertmanager/values.yaml']",2,400fbdf67ee7fc9478e0d38114676a708faafacd,alertmanager/pod-uid, user: alertmanager: uid: 65534,,4,0
openstack%2Fopenstack-helm-infra~master~If692fccaf4dd362b28fecb4656036289a3a97122,openstack/openstack-helm-infra,master,If692fccaf4dd362b28fecb4656036289a3a97122,Elasticsearch: Add security context for exporter pod/container,MERGED,2019-01-03 20:33:51.000000000,2019-01-07 16:26:08.000000000,2019-01-07 16:26:08.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-01-03 20:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1c1ef9038e94a14f486e17c07f3550fc2a664c3e', 'message': ""Elasticsearch: Add security context for exporter pod uid\n\nThis adds the security context snippet for the elasticsearch\nprometheus exporter pod. This changes the pod's user from root to\nthe nobody user instead\n\nChange-Id: If692fccaf4dd362b28fecb4656036289a3a97122\n""}, {'number': 2, 'created': '2019-01-03 22:12:59.000000000', 'files': ['elasticsearch/values.yaml', 'elasticsearch/templates/monitoring/prometheus/exporter-deployment.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0679ed49bd92d90e0774d3f500e1a3dd3c59ec2f', 'message': ""Elasticsearch: Add security context for exporter pod/container\n\nThis adds the security context snippet for the elasticsearch\nprometheus exporter pod. This changes the pod's user from root to\nthe nobody user instead\n\nThis also adds the container security context to explicitly set\nallowPrivilegeEscalation to false\n\nChange-Id: If692fccaf4dd362b28fecb4656036289a3a97122\n""}]",2,628293,0679ed49bd92d90e0774d3f500e1a3dd3c59ec2f,12,5,2,17591,,,0,"Elasticsearch: Add security context for exporter pod/container

This adds the security context snippet for the elasticsearch
prometheus exporter pod. This changes the pod's user from root to
the nobody user instead

This also adds the container security context to explicitly set
allowPrivilegeEscalation to false

Change-Id: If692fccaf4dd362b28fecb4656036289a3a97122
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/93/628293/1 && git format-patch -1 --stdout FETCH_HEAD,"['elasticsearch/values.yaml', 'elasticsearch/templates/monitoring/prometheus/exporter-deployment.yaml']",2,1c1ef9038e94a14f486e17c07f3550fc2a664c3e,elasticsearch/exporter-pod-uid,"{{ dict ""envAll"" $envAll ""application"" ""elasticsearch_exporter"" | include ""helm-toolkit.snippets.kubernetes_pod_security_context"" | indent 6 }}",,4,0
openstack%2Fopenstack-helm-images~master~Id5bdb959ac57cca75ece62457cb233a5b99e5bd0,openstack/openstack-helm-images,master,Id5bdb959ac57cca75ece62457cb233a5b99e5bd0,Add Ceph Daemon image with Mimic support,MERGED,2019-01-04 20:30:14.000000000,2019-01-07 16:17:13.000000000,2019-01-07 16:17:13.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-04 20:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/94eedb25acc2292d9d992bcaffe1fbbfa6b21d3e', 'message': '[WIP] Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n- Uplift all docker files to support Mimic releases\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 2, 'created': '2019-01-04 20:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/c62d65fdad9427fba04469f1f040e704ca9d0d3e', 'message': '[WIP] Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 3, 'created': '2019-01-05 01:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d299d7d5d295dcf72c1fb6f84bb7a13658bc28b4', 'message': '[WIP] Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 4, 'created': '2019-01-05 01:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/6ee6cb0a467708803fc9dcadd306b2486fd2dbce', 'message': 'Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 5, 'created': '2019-01-05 20:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/c8647eae457ed7afc198f91ba527a863475bde9c', 'message': '[WIP] Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 6, 'created': '2019-01-05 21:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/e1f795cd5c8f40b21b546c0aeb078de074d098d9', 'message': 'Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 7, 'created': '2019-01-06 18:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/9c85c57c3f751bb5bd28fc8b8c91ec5c93eb6289', 'message': 'Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 8, 'created': '2019-01-06 20:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/e395d8d48203c6fed74dbcc74849d2ee083a3ec2', 'message': 'Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 9, 'created': '2019-01-06 20:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/00c11b5106d674acc44d5d4279cf65d45c6f3da6', 'message': 'Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}, {'number': 10, 'created': '2019-01-06 20:41:44.000000000', 'files': ['ceph-daemon/build.sh', 'ceph-daemon/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/dc752322905f5d443a6d1e7d184ef824724aac30', 'message': 'Add Ceph Daemon image with Mimic support\n\n- Add a new dockerfile to create a Ceph docker image\n\nChange-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0\n'}]",2,628677,dc752322905f5d443a6d1e7d184ef824724aac30,27,5,10,29268,,,0,"Add Ceph Daemon image with Mimic support

- Add a new dockerfile to create a Ceph docker image

Change-Id: Id5bdb959ac57cca75ece62457cb233a5b99e5bd0
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/77/628677/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-daemon/build.sh', 'ceph-config-helper/Dockerfile.suse_15', 'ceph-config-helper/Dockerfile.ubuntu_xenial', 'libvirt/Dockerfile.suse_15', 'libvirt/Dockerfile.ubuntu_xenial', 'ceph-daemon/Dockerfile']",6,94eedb25acc2292d9d992bcaffe1fbbfa6b21d3e,ceph_mimic,"FROM docker.io/ubuntu:xenial MAINTAINER mh935s@att.com ARG KUBE_VERSION=v1.12.2 ARG CEPH_RELEASE=mimic ADD https://download.ceph.com/keys/release.asc /etc/apt/ceph-release.asc RUN set -ex ;\ export DEBIAN_FRONTEND=noninteractive ;\ apt-key add /etc/apt/ceph-release.asc ;\ rm -f /etc/apt/ceph-release.asc ;\ echo ""deb http://download.ceph.com/debian-${CEPH_RELEASE}/ xenial main"" | tee /etc/apt/sources.list.d/ceph.list ;\ TMP_DIR=$(mktemp --directory) ;\ cd ${TMP_DIR} ;\ apt-get update ;\ apt-get dist-upgrade -y ;\ apt-get install --no-install-recommends -y \ apt-transport-https \ ca-certificates \ ceph \ ceph-common \ radosgw \ ceph-mds \ ceph-fuse \ rbd-nbd \ rbd-mirror \ rbd-fuse \ s3cmd \ strace \ valgrind \ hexedit \ tcpdump \ iperf \ xfsprogs \ rsync \ curl \ gcc \ gdb \ python \ python-dev \ jq ;\ curl -sSL https://bootstrap.pypa.io/get-pip.py | python ;\ pip --no-cache-dir install --upgrade \ six \ python-openstackclient \ python-swiftclient ;\ curl -sSL https://dl.k8s.io/${KUBE_VERSION}/kubernetes-client-linux-amd64.tar.gz | tar -zxv --strip-components=1 ;\ mv ${TMP_DIR}/client/bin/kubectl /usr/bin/kubectl ;\ chmod +x /usr/bin/kubectl ;\ rm -rf ${TMP_DIR} ;\ apt-get purge -y --auto-remove \ python-dev \ gcc ;\ rm -rf /var/lib/apt/lists/* ",,76,6
openstack%2Fopenstack-ansible-os_nova~master~Ia66fe9a4c5c18f31fa50e06017389489be8c66a4,openstack/openstack-ansible-os_nova,master,Ia66fe9a4c5c18f31fa50e06017389489be8c66a4,Update messaging notification configuration,MERGED,2018-09-20 14:31:22.000000000,2019-01-07 15:57:03.000000000,2018-12-17 21:11:02.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 20523}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-20 14:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/bb6d1a527e3e5772a6f0a790abe33d37ba36c7ef', 'message': 'Update messaging notification configuration\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 2, 'created': '2018-09-21 20:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/27bce47f82ab0c0d1c6a0d0182a6d943e22ef836', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nThis patch conditionally selects the notifier driver. The noop\ndriver will be selected when notification publishing is disabled.\nThe messagingv2 driver is selected when notification publishing is\nenabled.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 3, 'created': '2018-09-24 20:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/903b2ffee9ae916735fe928d2184b4d640aa95d6', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 4, 'created': '2018-10-01 13:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/47770b08d9e0c69e29a4d72a40ab595d3ee29575', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 5, 'created': '2018-10-16 13:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/b03a906cd5831920e2890a7f8d074ff3d58dd4a9', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 6, 'created': '2018-10-22 20:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/f79df2ae245649f5aeb103646efb8981e072cea8', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 7, 'created': '2018-10-30 13:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8bbf3854470f34f73291efb0186d89331a2d677d', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 8, 'created': '2018-11-09 15:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/032896b6055071813d5215fcfa7f30e2b2b9bd26', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 9, 'created': '2018-11-09 21:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/1cc7461a15df4889bebca65277e38ed8b8ae736d', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}, {'number': 10, 'created': '2018-12-04 14:10:01.000000000', 'files': ['tasks/main.yml', 'tasks/nova_db_setup.yml', 'templates/nova.conf.j2', 'vars/ubuntu.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/2448db8064a6ef019f4fa75d700345ca65a905e1', 'message': 'Update messaging notification configuration\n\nThis patch removes the conditional inclusion of the notification\nsection of the service configuration. This ensures that oslo.messaging\nnotifications use the correct transport for deployments that have\nseparate rpc and notify messaging backends. For example, if the\ntransport_url is not provided in the notification section of the\nservice configuration, the transport_url specified in the default\nsection will be used instead.\n\nChange-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4\n'}]",6,604107,2448db8064a6ef019f4fa75d700345ca65a905e1,41,5,10,20523,,,0,"Update messaging notification configuration

This patch removes the conditional inclusion of the notification
section of the service configuration. This ensures that oslo.messaging
notifications use the correct transport for deployments that have
separate rpc and notify messaging backends. For example, if the
transport_url is not provided in the notification section of the
service configuration, the transport_url specified in the default
section will be used instead.

Change-Id: Ia66fe9a4c5c18f31fa50e06017389489be8c66a4
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/07/604107/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'templates/nova.conf.j2']",2,bb6d1a527e3e5772a6f0a790abe33d37ba36c7ef,bp/hybrid-messaging,"{% set notification_topics = ['notifications'] %} {% if nova_designate_enabled %}topics = {{ notification_topics | join(',') }}","{% if nova_ceilometer_enabled or nova_designate_enabled %}{% set notification_topics = [] %} {% if neutron_ceilometer_enabled %} {% set _ = notification_topics.append('notifications') %} {% endif %} {% if neutron_designate_enabled %}notification_topics = {{ notification_topics | join(',') }}{% endif %}",3,9
openstack%2Fcharm-cinder~master~I694976e994966872230c62de0ce45e9c6e818358,openstack/charm-cinder,master,I694976e994966872230c62de0ce45e9c6e818358,Add project infomation into setup.cfg,MERGED,2018-08-01 15:50:39.000000000,2019-01-07 15:54:51.000000000,2019-01-07 15:54:51.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-08-01 15:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/93e54f9568062fd1184707be29b456015d3e08c3', 'message': 'Add project infomation into setup.cfg\n\nChange-Id: I694976e994966872230c62de0ce45e9c6e818358\n'}, {'number': 2, 'created': '2018-08-01 15:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/0a1f9526b882b3b9f649bf5f55180eb72d98efb1', 'message': 'Add project infomation into setup.cfg\n\nChange-Id: I694976e994966872230c62de0ce45e9c6e818358\n'}, {'number': 3, 'created': '2018-11-27 03:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/955e14e363229836e585b11b869a7b1751f27bb0', 'message': 'Add project infomation into setup.cfg\n\nChange-Id: I694976e994966872230c62de0ce45e9c6e818358\n'}, {'number': 4, 'created': '2019-01-07 15:08:52.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/a90c0c6783dc42f9518d687447d26b1ef7bae0df', 'message': 'Add project infomation into setup.cfg\n\nChange-Id: I694976e994966872230c62de0ce45e9c6e818358\n'}]",1,587862,a90c0c6783dc42f9518d687447d26b1ef7bae0df,27,6,4,22165,,,0,"Add project infomation into setup.cfg

Change-Id: I694976e994966872230c62de0ce45e9c6e818358
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/62/587862/3 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,93e54f9568062fd1184707be29b456015d3e08c3,,[metadata] name = charm-cinder summary = Charm module for OpenStack Cinder description-file = README.md author = OpenStack author-email = openstack-dev@lists.openstack.org home-page = https://docs.openstack.org/charm-guide/latest/ classifier = Intended Audience :: Developers Intended Audience :: System Administrators License :: OSI Approved :: Apache Software License Operating System :: POSIX :: Linux ,,14,0
openstack%2Fgovernance~master~I8509a9e9b1c9c2a81ece1e15c615e04c17717c6a,openstack/governance,master,I8509a9e9b1c9c2a81ece1e15c615e04c17717c6a,New Sahara repositories for split plugins,MERGED,2019-01-03 15:55:41.000000000,2019-01-07 15:53:11.000000000,2019-01-07 15:53:11.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 5046}, {'_account_id': 8099}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 15:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/d9717152fdd924d624379e8f5fd056f68705f45b', 'message': 'New Sahara repositories for split plugins\n\nDepends-On: https://review.openstack.org/628209\n\nChange-Id: I8509a9e9b1c9c2a81ece1e15c615e04c17717c6a\n'}, {'number': 2, 'created': '2019-01-03 15:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/39dd6d1a72066a4d1a345efbd836af373517063d', 'message': 'New Sahara repositories for split plugins\n\nDepends-On: https://review.openstack.org/628209\nChange-Id: I8509a9e9b1c9c2a81ece1e15c615e04c17717c6a\n'}, {'number': 3, 'created': '2019-01-03 16:53:23.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/992c6d2f742b8768f233ad3292fd6d28f536b02d', 'message': 'New Sahara repositories for split plugins\n\nDepends-On: https://review.openstack.org/628209\nChange-Id: I8509a9e9b1c9c2a81ece1e15c615e04c17717c6a\n'}]",0,628210,992c6d2f742b8768f233ad3292fd6d28f536b02d,28,10,3,10459,,,0,"New Sahara repositories for split plugins

Depends-On: https://review.openstack.org/628209
Change-Id: I8509a9e9b1c9c2a81ece1e15c615e04c17717c6a
",git fetch https://review.opendev.org/openstack/governance refs/changes/10/628210/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,d9717152fdd924d624379e8f5fd056f68705f45b,project-update, sahara-plugin-ambari: repos: - openstack/sahara-plugin-ambari tags: - tc:approved-release - vulnerability:managed - assert:follows-standard-deprecation - assert:supports-upgrade - stable:follows-policy sahara-plugin-cdh: repos: - openstack/sahara-plugin-cdh tags: - tc:approved-release - vulnerability:managed - assert:follows-standard-deprecation - assert:supports-upgrade - stable:follows-policy sahara-plugin-mapr: repos: - openstack/sahara-plugin-mapr tags: - tc:approved-release - vulnerability:managed - assert:follows-standard-deprecation - assert:supports-upgrade - stable:follows-policy sahara-plugin-spark: repos: - openstack/sahara-plugin-spark tags: - tc:approved-release - vulnerability:managed - assert:follows-standard-deprecation - assert:supports-upgrade - stable:follows-policy sahara-plugin-storm: repos: - openstack/sahara-plugin-storm tags: - tc:approved-release - vulnerability:managed - assert:follows-standard-deprecation - assert:supports-upgrade - stable:follows-policy sahara-plugin-vanilla: repos: - openstack/sahara-plugin-vanilla tags: - tc:approved-release - vulnerability:managed - assert:follows-standard-deprecation - assert:supports-upgrade - stable:follows-policy,,54,0
openstack%2Freleases~master~I4beed6daf2ed4ce6723d633ebdeca3253fa75727,openstack/releases,master,I4beed6daf2ed4ce6723d633ebdeca3253fa75727,Release openstack/placement 0.1.0,MERGED,2019-01-04 11:17:55.000000000,2019-01-07 15:37:08.000000000,2019-01-07 15:37:08.000000000,"[{'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-01-04 11:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/92d569634bc9164f39ea9cf3c44c17f8b33c130f', 'message': ""Release openstack/placement 0.1.0\n\nThis will provide a working release of the placement service,\nincluding all the expected dependencies of this cycle. This is expected\nto be useful for packagers and other testers. The release will not have\ncomplete documentation, but will be a fully working implementation of\nthe service. In fact it ought to work installed from pypi without too\nmuch hassle.\n\nNote that placement is currently a deliverable of the nova team and uses\nnova's launchpad to track bugs. This is expeced to change relatively\nsoon but the switchover has not yet happened.\n\nChange-Id: I4beed6daf2ed4ce6723d633ebdeca3253fa75727\n""}, {'number': 2, 'created': '2019-01-04 11:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0ed054e93be754cf63f6e1a0b8b733e85e11612a', 'message': ""Release openstack/placement 0.1.0\n\nThis will provide a working release of the placement service,\nincluding all the expected dependencies of this cycle. This is expected\nto be useful for packagers and other testers. The release will not have\ncomplete documentation, but will be a fully working implementation of\nthe service. In fact it ought to work installed from pypi without too\nmuch hassle.\n\nNote that placement is currently a deliverable of the nova team and uses\nnova's launchpad to track bugs. This is expeced to change relatively\nsoon but the switchover has not yet happened.\n\nThe depends on is to the zuul settings to add the release-to-pypi job.\n\nDepends-On: https://review.openstack.org/628240\nChange-Id: I4beed6daf2ed4ce6723d633ebdeca3253fa75727\n""}, {'number': 3, 'created': '2019-01-04 12:51:08.000000000', 'files': ['deliverables/stein/placement.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/759867bae064a1f90f3ba5001a147ed70d5e9cc6', 'message': ""Release openstack/placement 0.1.0\n\nThis will provide a working release of the placement service,\nincluding all the expected dependencies of this cycle. This is expected\nto be useful for packagers and other testers. The release will not have\ncomplete documentation, but will be a fully working implementation of\nthe service. In fact it ought to work installed from pypi without too\nmuch hassle.\n\nNote that placement is currently a deliverable of the nova team and uses\nnova's launchpad to track bugs. This is expeced to change relatively\nsoon but the switchover has not yet happened.\n\nThe depends on is to the zuul settings to add the release-to-pypi job.\n\nDepends-On: https://review.openstack.org/628240\nChange-Id: I4beed6daf2ed4ce6723d633ebdeca3253fa75727\n""}]",1,628400,759867bae064a1f90f3ba5001a147ed70d5e9cc6,17,4,3,11564,,,0,"Release openstack/placement 0.1.0

This will provide a working release of the placement service,
including all the expected dependencies of this cycle. This is expected
to be useful for packagers and other testers. The release will not have
complete documentation, but will be a fully working implementation of
the service. In fact it ought to work installed from pypi without too
much hassle.

Note that placement is currently a deliverable of the nova team and uses
nova's launchpad to track bugs. This is expeced to change relatively
soon but the switchover has not yet happened.

The depends on is to the zuul settings to add the release-to-pypi job.

Depends-On: https://review.openstack.org/628240
Change-Id: I4beed6daf2ed4ce6723d633ebdeca3253fa75727
",git fetch https://review.opendev.org/openstack/releases refs/changes/00/628400/3 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/placement.yaml'],1,92d569634bc9164f39ea9cf3c44c17f8b33c130f,cd/release-stub-placement,--- include-pypi-link: yes launchpad: nova release-model: cycle-with-rc team: nova type: service repository-settings: openstack/placement: {} releases: - version: 0.1.0 projects: - repo: openstack/placement hash: 9d42491910e66ecd15767238bb617ed5984283f2 ,,13,0
openstack%2Fpuppet-ceph~master~Ic549d8dc68aab07007935ce38d7fd147b2445937,openstack/puppet-ceph,master,Ic549d8dc68aab07007935ce38d7fd147b2445937,Supply hrefs for table of contents according to context,MERGED,2018-12-05 07:27:04.000000000,2019-01-07 15:27:20.000000000,2019-01-07 15:27:20.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-05 07:27:04.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/096fefedc8e3e4f0e0a8a1a6531de11ab93a505f', 'message': 'Supply hrefs for table of contents according to context\n\nChange-Id: Ic549d8dc68aab07007935ce38d7fd147b2445937\n'}]",0,622860,096fefedc8e3e4f0e0a8a1a6531de11ab93a505f,6,2,1,23317,,,0,"Supply hrefs for table of contents according to context

Change-Id: Ic549d8dc68aab07007935ce38d7fd147b2445937
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/60/622860/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,096fefedc8e3e4f0e0a8a1a6531de11ab93a505f,fix,11. [Repository - Repository for the module](#repository),,1,0
openstack%2Fopenstack-ansible-os_tempest~master~If14bcfe2a7ffbef08786e001d0dee2f9143eea04,openstack/openstack-ansible-os_tempest,master,If14bcfe2a7ffbef08786e001d0dee2f9143eea04,Use tempest_tempestconf_profile for handling named args,MERGED,2018-12-06 11:08:57.000000000,2019-01-07 15:23:23.000000000,2019-01-07 15:23:23.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 24162}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-06 11:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5fd7f753dd2b7325ee1c3cf26a97c6175e50d266', 'message': 'use tempestconf profile to manage tempestconf cli args\n\nhttps://review.openstack.org/#/c/621567/ addes --profile option in\ntempestconf to manage all the cli arguments through it.\ntempest_tempestconf_profile var will do the job.\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 2, 'created': '2018-12-06 11:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/fc27ff43c5e5ed54c46efe68f982d8875e8ccc0b', 'message': '[WIP] use tempestconf profile to manage tempestconf cli args\n\nhttps://review.openstack.org/#/c/621567/ addes --profile option in\ntempestconf to manage all the cli arguments through it.\ntempest_tempestconf_profile var will do the job.\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 3, 'created': '2018-12-10 06:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/f5c7f4bb1155f33d39bbb8e3204f33dece7a0785', 'message': 'Generate tempestconf sample profile for named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\ntempest_tempestconf_profile var will do the job.\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 4, 'created': '2018-12-17 06:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ef71bcab5a09464381f712dd1890d988b4ae8ebf', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 5, 'created': '2018-12-17 11:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/7eb6df41c027b7a0e4170ddce0b58bf89d9deafc', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nDepends-On: https://review.openstack.org/#/c/621567/\nDepends-On: https://review.openstack.org/#/c/625545/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 6, 'created': '2018-12-18 05:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/b67249b4078ca4490e6666feab9495b201966acd', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 7, 'created': '2018-12-18 07:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/3ddc05a4f4b80413263866775c08d384a68be679', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 8, 'created': '2018-12-18 13:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/68196319800ae6616b9be3e21793ca3eee606463', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 9, 'created': '2018-12-19 05:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5aac6191967c0230bb7091e13fdad09126903542', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 10, 'created': '2018-12-19 05:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/1b54ab7ee2b42cd2db4b63e7539096eb1106a916', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 11, 'created': '2018-12-21 10:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/9aa5349f48eb8adab9f8ccd86d5c086088fcc401', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 12, 'created': '2018-12-21 13:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/cc97c8c93c42e61ff60bc07f7e052efc81a4f30a', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/626889/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 13, 'created': '2018-12-24 04:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/11ef1f64b7947eaec6bc6e221caa57de362c01b7', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/626889/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 14, 'created': '2018-12-24 05:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/126b1b7613341907de65681307d9193f894718ab', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 15, 'created': '2018-12-24 05:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/3c2f0a5d1980b566280a86b0268762c09fc4dae7', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 16, 'created': '2018-12-24 12:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/42921b5df3e2d072657f60c39850a0d2d5bdf4eb', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 17, 'created': '2018-12-24 12:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/873429a365fecc930479a7bfbbc0bdded830708b', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 18, 'created': '2018-12-24 12:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/3301dcd8066c32b129a804561ade7d5b2acccad2', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 19, 'created': '2018-12-24 14:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/081c79d58d1e5a791ee192df7bfcbabe8dd6760b', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 20, 'created': '2018-12-24 15:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ae7ad75f0c022889c7c175d680db4a849c14089c', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 21, 'created': '2018-12-25 13:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5970b3f4b49262abbb4aba0a35998887ab99054e', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 22, 'created': '2018-12-25 15:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/c26732ecd1c32bbf04080cb657c82332c099b5c6', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/621567/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 23, 'created': '2018-12-26 05:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/4268b14c8ed8c64e1530d932a2109ba97a2eb5c7', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/626889/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 24, 'created': '2018-12-26 06:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/17cef03744f81e8c44a5cbd72826e9b2c805ee0b', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/626889/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 25, 'created': '2018-12-26 08:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/cd8488aa1383aaf0f7434b13bdd0df20b4149a04', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nAdded python-tempestconf and tempest as required projects for\ntesting tempest/tempestconf related patches in CI\n\nDepends-On: https://review.openstack.org/#/c/626889/\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 26, 'created': '2019-01-02 11:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/a130fa8b4c9529c6ec1fdccc403a168cbb4d16e5', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 27, 'created': '2019-01-03 07:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/e370a50d33bb8fdf57d0fceab143b674ab49995c', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option. generate-profile will geneates\na profile.yaml file will all the named args and an user\ncan overrides the values and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs with in that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 28, 'created': '2019-01-04 08:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/42a1e784689b0c758049d5b139f7c69a22914b18', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option.An user can override the values\nin profile.yaml file and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs within that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 29, 'created': '2019-01-04 08:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/141b8086f753fe79f92e460fb85167291af95b64', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option.An user can override the values\nin profile.yaml file and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs within that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}, {'number': 30, 'created': '2019-01-07 12:26:37.000000000', 'files': ['tasks/tempestconf.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/e1d2177898ef3427adb219805354053cccb84e10', 'message': 'Use tempest_tempestconf_profile for handling named args\n\nhttps://review.openstack.org/#/c/621567/ adds --profile and\n--generate-profile option.An user can override the values\nin profile.yaml file and pass it to discover-tempest-config\nto generate the tempest.conf.\n\nBy using tempest_tempestconf_profile var, we can add the named\nargs within that, then it will be copied to profile.yaml file\nand --profile arg will be used to generate the tempest.conf.\n\nChange-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04\n'}]",22,623187,e1d2177898ef3427adb219805354053cccb84e10,91,10,30,12393,,,0,"Use tempest_tempestconf_profile for handling named args

https://review.openstack.org/#/c/621567/ adds --profile and
--generate-profile option.An user can override the values
in profile.yaml file and pass it to discover-tempest-config
to generate the tempest.conf.

By using tempest_tempestconf_profile var, we can add the named
args within that, then it will be copied to profile.yaml file
and --profile arg will be used to generate the tempest.conf.

Change-Id: If14bcfe2a7ffbef08786e001d0dee2f9143eea04
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/87/623187/10 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/tempestconf.yml', 'defaults/main.yml']",2,5fd7f753dd2b7325ee1c3cf26a97c6175e50d266,tempestconf_profile,tempest_tempestconf_profile: {},,14,1
openstack%2Fkeystone~stable%2Frocky~Ic7d6e089f0c28e026192e83b56b487180bca09e3,openstack/keystone,stable/rocky,Ic7d6e089f0c28e026192e83b56b487180bca09e3,Fix example for getting system scoped token,MERGED,2018-10-20 09:08:01.000000000,2019-01-07 15:20:39.000000000,2019-01-07 15:20:39.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-10-20 09:08:01.000000000', 'files': ['doc/source/admin/token-support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/adcd05cf56de22f405967316390ec66e59522cba', 'message': 'Fix example for getting system scoped token\n\nPreviously, the example for getting a system scoped token read\n`--os-system` which does not work.\n\nChange-Id: Ic7d6e089f0c28e026192e83b56b487180bca09e3\nCloses-Bug: 1797939\nSigned-off-by: Magnus Lööf <magnus.loof@basalt.se>\n(cherry picked from commit 33295032d95d0e85d68ea28a348d12b4e980a723)\n'}]",0,612003,adcd05cf56de22f405967316390ec66e59522cba,9,5,1,25238,,,0,"Fix example for getting system scoped token

Previously, the example for getting a system scoped token read
`--os-system` which does not work.

Change-Id: Ic7d6e089f0c28e026192e83b56b487180bca09e3
Closes-Bug: 1797939
Signed-off-by: Magnus Lööf <magnus.loof@basalt.se>
(cherry picked from commit 33295032d95d0e85d68ea28a348d12b4e980a723)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/612003/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/token-support-matrix.ini'],1,adcd05cf56de22f405967316390ec66e59522cba,bug/1797939, --os-system-scope all token issue, --os-system token issue,1,1
openstack%2Fneutron~master~I699d03de9e26d5784e6bd5e7d4fa219de6209207,openstack/neutron,master,I699d03de9e26d5784e6bd5e7d4fa219de6209207,"Revert ""Remove -u root as mysql is executed with root user""",MERGED,2019-01-07 06:47:11.000000000,2019-01-07 15:20:37.000000000,2019-01-07 15:20:37.000000000,"[{'_account_id': 1131}, {'_account_id': 5689}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-01-07 06:47:11.000000000', 'files': ['doc/source/install/controller-install-obs.rst', 'doc/source/install/controller-install-ubuntu.rst', 'doc/source/install/controller-install-rdo.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc29d4843d5d4a69c2b5e92475a805d218a9c55e', 'message': 'Revert ""Remove -u root as mysql is executed with root user""\n\nThis commit was approved just to keep the consistency with\nother OpenStack projects, but most proposed changes related to it\nhave been rejected so far [1].\nThe main reason is because it is clearer to specify options explicitly\nand we should not assume some configuration.\n\nI totally agree these opinions and see no reason that neutron\ncontineus to use different command line options for mysql.\nConsistency in the installation guide will bring better user experience.\n\n[1] https://review.openstack.org/#/q/file:%255Edoc/source/install/.*+message:mysql\n\nThis reverts commit 59d178c9de6028016053f2a6958372e14ded386a.\n\nRelated-Bug: #1785025\nChange-Id: I699d03de9e26d5784e6bd5e7d4fa219de6209207\n'}]",0,628878,bc29d4843d5d4a69c2b5e92475a805d218a9c55e,11,7,1,841,,,0,"Revert ""Remove -u root as mysql is executed with root user""

This commit was approved just to keep the consistency with
other OpenStack projects, but most proposed changes related to it
have been rejected so far [1].
The main reason is because it is clearer to specify options explicitly
and we should not assume some configuration.

I totally agree these opinions and see no reason that neutron
contineus to use different command line options for mysql.
Consistency in the installation guide will bring better user experience.

[1] https://review.openstack.org/#/q/file:%255Edoc/source/install/.*+message:mysql

This reverts commit 59d178c9de6028016053f2a6958372e14ded386a.

Related-Bug: #1785025
Change-Id: I699d03de9e26d5784e6bd5e7d4fa219de6209207
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/628878/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/controller-install-obs.rst', 'doc/source/install/controller-install-rdo.rst', 'doc/source/install/controller-install-ubuntu.rst']",3,bc29d4843d5d4a69c2b5e92475a805d218a9c55e,bug/1785025, $ mysql -u root -p, # mysql,3,3
openstack%2Fblazar~master~Icbf91320de3bcee27ca29808974d84a9643833a7,openstack/blazar,master,Icbf91320de3bcee27ca29808974d84a9643833a7,update spelling error,ABANDONED,2018-12-25 06:22:08.000000000,2019-01-07 15:17:23.000000000,,"[{'_account_id': 22348}, {'_account_id': 25625}, {'_account_id': 25747}, {'_account_id': 26776}, {'_account_id': 27549}, {'_account_id': 28563}]","[{'number': 1, 'created': '2018-12-25 06:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e0d82f8b0b75775e4dbf93bbe31ccb51955dfe68', 'message': 'fix the spelling mistake word\n\nChange-Id: Icbf91320de3bcee27ca29808974d84a9643833a7\n'}, {'number': 2, 'created': '2018-12-29 00:39:00.000000000', 'files': ['doc/source/specs/rocky/resource-availability.rst'], 'web_link': 'https://opendev.org/openstack/blazar/commit/b834d0e5fb21403fa62c58e116b1aa7623e4e844', 'message': 'update spelling error\n\nChange-Id: Icbf91320de3bcee27ca29808974d84a9643833a7\n'}]",0,627224,b834d0e5fb21403fa62c58e116b1aa7623e4e844,10,6,2,29558,,,0,"update spelling error

Change-Id: Icbf91320de3bcee27ca29808974d84a9643833a7
",git fetch https://review.opendev.org/openstack/blazar refs/changes/24/627224/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/specs/rocky/resource-availability.rst'],1,e0d82f8b0b75775e4dbf93bbe31ccb51955dfe68,,"information. If not, the API doesn't have to add the information.","information. If not, the API doesn't have to add the infomation.",1,1
openstack%2Fopenstack-ansible-galera_client~master~I110f6fa3b6c6341ec4a8bd8cf69ae61bbbb50689,openstack/openstack-ansible-galera_client,master,I110f6fa3b6c6341ec4a8bd8cf69ae61bbbb50689,"Revert ""cleanup: don't update_cache when adding a new repo""",MERGED,2019-01-07 11:28:26.000000000,2019-01-07 15:16:32.000000000,2019-01-07 15:16:31.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-07 11:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/3633bc1a0dd73ea25bcad4f0da4fd7d6d9c75513', 'message': 'Revert ""cleanup: don\'t update_cache when adding a new repo""\n\nThis reverts commit d8e1f4d83ca14d2555d0a6226c0205a323a5e8b2\nbecause the tasks are implemented that way for the following reason.\n\nIf apt_repository fails to update the apt cache after updating the\nconfiguration, retries don\'t register there was a change and so no\nattempt is made to update the cache by the module on the second attempt.\nThis failure can result in a failure to install packages.\n\nThis change adds an apt module task to update the cache if the\napt_repository task registers a change. This means updating the cache\nwill get retried on failure and no longer fail silently.\n\nThis was all explained in the commit message for\nI41de2b9a98977bb89de812a9fbc85a9f99d62942 but no notes were\nadded to the tasks, resulting in the confusion. To prevent this happening\nagain, we add the comments from Id059dbec3466cb1ef3ea567249f52384a8ade515\ninto these tasks.\n\nChange-Id: I110f6fa3b6c6341ec4a8bd8cf69ae61bbbb50689\n'}, {'number': 2, 'created': '2019-01-07 11:30:25.000000000', 'files': ['tasks/galera_client_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/e31b259cb5ad5d566268a9628a9a7eac2e2c2f06', 'message': 'Revert ""cleanup: don\'t update_cache when adding a new repo""\n\nThis reverts commit d8e1f4d83ca14d2555d0a6226c0205a323a5e8b2\nbecause the tasks are implemented that way for the following reason.\n\nIf apt_repository fails to update the apt cache after updating the\nconfiguration, retries don\'t register there was a change and so no\nattempt is made to update the cache by the module on the second attempt.\nThis failure can result in a failure to install packages.\n\nThis change adds an apt module task to update the cache if the\napt_repository task registers a change. This means updating the cache\nwill get retried on failure and no longer fail silently.\n\nThis was all explained in the commit message for\nI41de2b9a98977bb89de812a9fbc85a9f99d62942 but no notes were\nadded to the tasks, resulting in the confusion. To prevent this happening\nagain, we add the comments from Id059dbec3466cb1ef3ea567249f52384a8ade515\ninto these tasks.\n\nChange-Id: I110f6fa3b6c6341ec4a8bd8cf69ae61bbbb50689\n'}]",0,628933,e31b259cb5ad5d566268a9628a9a7eac2e2c2f06,12,5,2,6816,,,0,"Revert ""cleanup: don't update_cache when adding a new repo""

This reverts commit d8e1f4d83ca14d2555d0a6226c0205a323a5e8b2
because the tasks are implemented that way for the following reason.

If apt_repository fails to update the apt cache after updating the
configuration, retries don't register there was a change and so no
attempt is made to update the cache by the module on the second attempt.
This failure can result in a failure to install packages.

This change adds an apt module task to update the cache if the
apt_repository task registers a change. This means updating the cache
will get retried on failure and no longer fail silently.

This was all explained in the commit message for
I41de2b9a98977bb89de812a9fbc85a9f99d62942 but no notes were
added to the tasks, resulting in the confusion. To prevent this happening
again, we add the comments from Id059dbec3466cb1ef3ea567249f52384a8ade515
into these tasks.

Change-Id: I110f6fa3b6c6341ec4a8bd8cf69ae61bbbb50689
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/33/628933/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_client_install_apt.yml'],1,3633bc1a0dd73ea25bcad4f0da4fd7d6d9c75513,osa-speedups, update_cache: no register: add_repo tags: - galera-client-repos - name: Update Apt cache apt: update_cache: yes when: add_repo is changed register: update_apt_cache until: update_apt_cache is success retries: 5 delay: 2,,13,0
openstack%2Fneutron-lib~master~Ib807ec19e02adb2d2199092e2251ddfe4b46441d,openstack/neutron-lib,master,Ib807ec19e02adb2d2199092e2251ddfe4b46441d,"Fix the misspelling of ""interface""",MERGED,2019-01-07 03:06:47.000000000,2019-01-07 15:08:48.000000000,2019-01-07 15:08:48.000000000,"[{'_account_id': 1131}, {'_account_id': 5367}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 03:06:47.000000000', 'files': ['api-ref/source/v2/routers.inc'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/3ef70e81a13b3cd8e2f7ea77d4c8bd4dbbd23c5b', 'message': 'Fix the misspelling of ""interface""\n\nChange-Id: Ib807ec19e02adb2d2199092e2251ddfe4b46441d\n'}]",0,628844,3ef70e81a13b3cd8e2f7ea77d4c8bd4dbbd23c5b,7,3,1,29721,,,0,"Fix the misspelling of ""interface""

Change-Id: Ib807ec19e02adb2d2199092e2251ddfe4b46441d
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/44/628844/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v2/routers.inc'],1,3ef70e81a13b3cd8e2f7ea77d4c8bd4dbbd23c5b,,"To update a router interface, use the add router interface and","To update a router intreface, use the add router interface and",1,1
openstack%2Freleases~master~I145edf20f619ed06a640422f29956e3174c3544d,openstack/releases,master,I145edf20f619ed06a640422f29956e3174c3544d,tripleo-heat-templates 9.2.0,MERGED,2019-01-04 15:24:18.000000000,2019-01-07 15:04:06.000000000,2019-01-07 15:04:06.000000000,"[{'_account_id': 2472}, {'_account_id': 3153}, {'_account_id': 13861}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-01-04 15:24:18.000000000', 'files': ['deliverables/rocky/tripleo-heat-templates.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/eb4ba466945ed0ce4bab241914c580de032db0d9', 'message': 'tripleo-heat-templates 9.2.0\n\nFix recent ansible support\nchange: Ia76fcb87fc98fd93d6f487dd40d407c0bc875ffd\n\nChange-Id: I145edf20f619ed06a640422f29956e3174c3544d\n'}]",0,628456,eb4ba466945ed0ce4bab241914c580de032db0d9,9,6,1,10384,,,0,"tripleo-heat-templates 9.2.0

Fix recent ansible support
change: Ia76fcb87fc98fd93d6f487dd40d407c0bc875ffd

Change-Id: I145edf20f619ed06a640422f29956e3174c3544d
",git fetch https://review.opendev.org/openstack/releases refs/changes/56/628456/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/rocky/tripleo-heat-templates.yaml'],1,eb4ba466945ed0ce4bab241914c580de032db0d9,, - projects: - hash: 682a7722be403086e520920302c202cb896e1cd0 repo: openstack/tripleo-heat-templates version: 9.2.0,,4,0
openstack%2Freleases~master~I5abea3dd06d6a1366dea6102fdac1ad2e2cad459,openstack/releases,master,I5abea3dd06d6a1366dea6102fdac1ad2e2cad459,Release OpenStack-Ansible rocky/18.1.2,MERGED,2018-12-23 16:22:28.000000000,2019-01-07 14:55:13.000000000,2019-01-07 14:55:13.000000000,"[{'_account_id': 1004}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 16:22:28.000000000', 'files': ['deliverables/rocky/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c5e6b0963130adc585ad5f11d2a268e8943a2687', 'message': 'Release OpenStack-Ansible rocky/18.1.2\n\nChange-Id: I5abea3dd06d6a1366dea6102fdac1ad2e2cad459\n'}]",0,627078,c5e6b0963130adc585ad5f11d2a268e8943a2687,9,5,1,17068,,,0,"Release OpenStack-Ansible rocky/18.1.2

Change-Id: I5abea3dd06d6a1366dea6102fdac1ad2e2cad459
",git fetch https://review.opendev.org/openstack/releases refs/changes/78/627078/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/rocky/openstack-ansible.yaml'],1,c5e6b0963130adc585ad5f11d2a268e8943a2687,release_osa, - projects: - hash: 2087cd98f28b35f655ca398d25d2a6c71e38328e repo: openstack/openstack-ansible version: 18.1.2,,4,0
openstack%2Freleases~master~I369b08fa4581915107d67daf9de052268858d8e8,openstack/releases,master,I369b08fa4581915107d67daf9de052268858d8e8,Release OpenStack-Ansible queens/17.1.6,MERGED,2018-12-23 16:43:22.000000000,2019-01-07 14:54:02.000000000,2019-01-07 14:54:02.000000000,"[{'_account_id': 1004}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 16:43:22.000000000', 'files': ['deliverables/queens/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/871c11408caaa40b17b021055bcea570ccb7b11b', 'message': 'Release OpenStack-Ansible queens/17.1.6\n\nChange-Id: I369b08fa4581915107d67daf9de052268858d8e8\n'}]",0,627080,871c11408caaa40b17b021055bcea570ccb7b11b,9,5,1,17068,,,0,"Release OpenStack-Ansible queens/17.1.6

Change-Id: I369b08fa4581915107d67daf9de052268858d8e8
",git fetch https://review.opendev.org/openstack/releases refs/changes/80/627080/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/openstack-ansible.yaml'],1,871c11408caaa40b17b021055bcea570ccb7b11b,release_osa, - projects: - hash: 53e453327073ce477869c618ea7a303f98501531 repo: openstack/openstack-ansible version: 17.1.6,,4,0
openstack%2Fproject-config~master~Ia0da319ac022c6d3bc9387616029d0bca997effb,openstack/project-config,master,Ia0da319ac022c6d3bc9387616029d0bca997effb,Rename base-minimal/post-ssh to base-minimal/post,MERGED,2019-01-07 14:33:10.000000000,2019-01-07 14:50:07.000000000,2019-01-07 14:50:07.000000000,"[{'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 14:33:10.000000000', 'files': ['playbooks/base-minimal/post.yaml', 'playbooks/base-minimal/post-ssh.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ea68aa68f79e93124f7f58a8f4c785c49a4d8bb0', 'message': 'Rename base-minimal/post-ssh to base-minimal/post\n\nThis matches the change already made the job config.\n\nAlso, sync the ignore_errors from base.\n\nChange-Id: Ia0da319ac022c6d3bc9387616029d0bca997effb\n'}]",0,628983,ea68aa68f79e93124f7f58a8f4c785c49a4d8bb0,7,3,1,2,,,0,"Rename base-minimal/post-ssh to base-minimal/post

This matches the change already made the job config.

Also, sync the ignore_errors from base.

Change-Id: Ia0da319ac022c6d3bc9387616029d0bca997effb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/83/628983/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/base-minimal/post.yaml', 'playbooks/base-minimal/post-ssh.yaml']",2,ea68aa68f79e93124f7f58a8f4c785c49a4d8bb0,zuulv3-output,,- hosts: all roles: - remove-build-sshkey ,10,3
openstack%2Fproject-config~master~I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1,openstack/project-config,master,I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1,Add new Sahara repositories for split plugins,MERGED,2019-01-03 15:55:03.000000000,2019-01-07 14:49:54.000000000,2019-01-07 14:49:54.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 15:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/86b52907293bc9b3de7fcfd44b98e47717a945b6', 'message': 'Add new Sahara repositories for split plugins\n\nThe code of each plugin is a filtered subset of the code\ncurrently available in sahara.git.\nMost of the settings are inherited from the existing sahara\nrepositories.\nAlso add their basic jobs (publish to pypi, translations) and\nconfigure the gerritbot notifications.\n\nChange-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1\n'}, {'number': 2, 'created': '2019-01-03 15:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a2db9e8616030849f473890d708a0ac03c7053de', 'message': 'Add new Sahara repositories for split plugins\n\nThe code of each plugin is a filtered subset of the code\ncurrently available in sahara.git.\nMost of the settings are inherited from the existing sahara\nrepositories.\nAlso add their basic jobs (publish to pypi, translations) and\nconfigure the gerritbot notifications.\n\nNeeded-By: https://review.openstack.org/628210\nChange-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1\n'}, {'number': 3, 'created': '2019-01-03 16:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e80ab2a71ad735e6193eb7082f1062527a9b2e98', 'message': 'Add new Sahara repositories for split plugins\n\nThe code of each plugin is a filtered subset of the code\ncurrently available in sahara.git.\nMost of the settings are inherited from the existing sahara\nrepositories.\n\nNeeded-By: https://review.openstack.org/628210\nChange-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1\n'}, {'number': 4, 'created': '2019-01-03 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/313f2416568ba2f6e2cfc353dda1423f36538886', 'message': 'Add new Sahara repositories for split plugins\n\nThe code of each plugin is a filtered subset of the code\ncurrently available in sahara.git.\nMost of the settings are inherited from the existing sahara\nrepositories.\n\nNeeded-By: https://review.openstack.org/628210\nChange-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1\n'}, {'number': 5, 'created': '2019-01-03 18:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eba8538d8715ef02af1b7cf98d837a10e9f1ee59', 'message': 'Add new Sahara repositories for split plugins\n\nThe code of each plugin is a filtered subset of the code\ncurrently available in sahara.git.\nMost of the settings are inherited from the existing sahara\nrepositories (without translations for now, it will be fixed\nlater).\nMake the new repositories known to zuul and\nconfigure the gerritbot notifications.\n\nNeeded-By: https://review.openstack.org/628210\nChange-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1\n'}, {'number': 6, 'created': '2019-01-03 20:20:20.000000000', 'files': ['gerritbot/channels.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/09e2a307f00ea272e6664d3f4cae79effc5609d2', 'message': 'Add new Sahara repositories for split plugins\n\nThe code of each plugin is a filtered subset of the code\ncurrently available in sahara.git.\nMost of the settings are inherited from the existing sahara\nrepositories (without translations for now, it will be fixed\nlater).\nMake the new repositories known to zuul and\nconfigure the gerritbot notifications.\n\nNeeded-By: https://review.openstack.org/628210\nChange-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1\n'}]",18,628209,09e2a307f00ea272e6664d3f4cae79effc5609d2,32,6,6,10459,,,0,"Add new Sahara repositories for split plugins

The code of each plugin is a filtered subset of the code
currently available in sahara.git.
Most of the settings are inherited from the existing sahara
repositories (without translations for now, it will be fixed
later).
Make the new repositories known to zuul and
configure the gerritbot notifications.

Needed-By: https://review.openstack.org/628210
Change-Id: I036788e795bdd6cb9cfbe99a38f8542e6eb1c3a1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/628209/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml']",4,86b52907293bc9b3de7fcfd44b98e47717a945b6,sahara-split, - openstack/sahara-plugin-ambari - openstack/sahara-plugin-cdh - openstack/sahara-plugin-mapr - openstack/sahara-plugin-spark - openstack/sahara-plugin-storm - openstack/sahara-plugin-vanilla,,132,12
openstack%2Frpm-packaging~master~Ica2460af23c4a03d7e20201c590dd93cf7ce7f49,openstack/rpm-packaging,master,Ica2460af23c4a03d7e20201c590dd93cf7ce7f49,os-service-types: Update to 1.4.0,MERGED,2019-01-07 08:56:07.000000000,2019-01-07 14:44:23.000000000,2019-01-07 14:44:23.000000000,"[{'_account_id': 6593}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-07 08:56:07.000000000', 'files': ['openstack/os-service-types/0001-Use-keystoneauth-only-in-applicable-test.patch', 'openstack/os-service-types/os-service-types.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bda3410760cd7dd5abadf5edd4dde53f99f2c78b', 'message': 'os-service-types: Update to 1.4.0\n\nChange-Id: Ica2460af23c4a03d7e20201c590dd93cf7ce7f49\n'}]",0,628912,bda3410760cd7dd5abadf5edd4dde53f99f2c78b,9,5,1,7102,,,0,"os-service-types: Update to 1.4.0

Change-Id: Ica2460af23c4a03d7e20201c590dd93cf7ce7f49
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/12/628912/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/os-service-types/0001-Use-keystoneauth-only-in-applicable-test.patch', 'openstack/os-service-types/os-service-types.spec.j2']",2,bda3410760cd7dd5abadf5edd4dde53f99f2c78b,,{% set upstream_version = upstream_version('1.4.0') %},{% set upstream_version = upstream_version('1.3.0') %}# https://review.openstack.org/599979 Patch0: 0001-Use-keystoneauth-only-in-applicable-test.patch,1,75
openstack%2Fproject-config~master~I7e2f4af868c2f31caed828ffc4417e25710eb26e,openstack/project-config,master,I7e2f4af868c2f31caed828ffc4417e25710eb26e,Add publish-to-pypi template to placement,MERGED,2019-01-03 17:41:59.000000000,2019-01-07 14:44:20.000000000,2019-01-07 14:44:20.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 17:41:59.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/195fbfcbe7dfe2d412d246ff910f8bbc070b726d', 'message': ""Add publish-to-pypi template to placement\n\nWe'd like to make an early release of a working placement from the\nextracted repo so it is time to add the publish-to-pypi template to\nmake that possible.\n\nThe pypi side of things is ready:\nhttps://pypi.org/project/openstack-placement/\n\nChange-Id: I7e2f4af868c2f31caed828ffc4417e25710eb26e\n""}]",0,628240,195fbfcbe7dfe2d412d246ff910f8bbc070b726d,8,4,1,11564,,,0,"Add publish-to-pypi template to placement

We'd like to make an early release of a working placement from the
extracted repo so it is time to add the publish-to-pypi template to
make that possible.

The pypi side of things is ready:
https://pypi.org/project/openstack-placement/

Change-Id: I7e2f4af868c2f31caed828ffc4417e25710eb26e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/628240/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,195fbfcbe7dfe2d412d246ff910f8bbc070b726d,cd/publish-placement, - publish-to-pypi,,1,0
openstack%2Fmonasca-tempest-plugin~master~Iffb4148fd93577809260e1e926f46c8c4cdcdcb9,openstack/monasca-tempest-plugin,master,Iffb4148fd93577809260e1e926f46c8c4cdcdcb9,Mark some basic tests as smoke tests,MERGED,2019-01-04 14:13:59.000000000,2019-01-07 14:44:18.000000000,2019-01-07 14:44:18.000000000,"[{'_account_id': 7052}, {'_account_id': 7102}, {'_account_id': 10311}, {'_account_id': 11809}, {'_account_id': 14123}, {'_account_id': 14273}, {'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 26733}]","[{'number': 1, 'created': '2019-01-04 14:13:59.000000000', 'files': ['monasca_tempest_tests/tests/api/test_dimensions.py', 'monasca_tempest_tests/tests/api/test_metrics.py', 'monasca_tempest_tests/tests/api/test_metrics_names.py', 'monasca_tempest_tests/tests/api/test_alarms.py', 'monasca_tempest_tests/tests/api/test_measurements.py', 'monasca_tempest_tests/tests/api/test_alarm_definitions.py', 'monasca_tempest_tests/tests/log_api/test_single.py'], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/aadc24ea03f9f73c9bb2e943eb734893be5c9290', 'message': 'Mark some basic tests as smoke tests\n\nWhen running tempest with ""tempest run -s"", only tests that are tagged\nas ""smoke"" tests are executed.\nIt\'s useful to also run a couple of monasca tests during a smoke run\nto confirm that at least the basic functions are working.\n\nChange-Id: Iffb4148fd93577809260e1e926f46c8c4cdcdcb9\nStory: #2004700\nTask: # 28721\n'}]",0,628443,aadc24ea03f9f73c9bb2e943eb734893be5c9290,9,12,1,7102,,,0,"Mark some basic tests as smoke tests

When running tempest with ""tempest run -s"", only tests that are tagged
as ""smoke"" tests are executed.
It's useful to also run a couple of monasca tests during a smoke run
to confirm that at least the basic functions are working.

Change-Id: Iffb4148fd93577809260e1e926f46c8c4cdcdcb9
Story: #2004700
Task: # 28721
",git fetch https://review.opendev.org/openstack/monasca-tempest-plugin refs/changes/43/628443/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_tempest_tests/tests/api/test_dimensions.py', 'monasca_tempest_tests/tests/api/test_metrics.py', 'monasca_tempest_tests/tests/api/test_metrics_names.py', 'monasca_tempest_tests/tests/api/test_alarms.py', 'monasca_tempest_tests/tests/api/test_measurements.py', 'monasca_tempest_tests/tests/api/test_alarm_definitions.py', 'monasca_tempest_tests/tests/log_api/test_single.py']",7,aadc24ea03f9f73c9bb2e943eb734893be5c9290,," @decorators.attr(type=[""gate"", ""smoke""])"," @decorators.attr(type=""gate"")",9,9
openstack%2Fgovernance~master~Ib15f7c20b4fc3f85dd90172373175b2b179d492e,openstack/governance,master,Ib15f7c20b4fc3f85dd90172373175b2b179d492e,Technical vision: hide implementation details,MERGED,2019-01-03 13:45:25.000000000,2019-01-07 14:41:00.000000000,2019-01-07 14:41:00.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 5046}, {'_account_id': 8099}, {'_account_id': 11564}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 13:45:25.000000000', 'files': ['reference/technical-vision.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/7e4adc7554c838303e210001481ef322c795c35b', 'message': 'Technical vision: hide implementation details\n\nAs discussed at the Technical Vision session at the OpenStack Forum\nin Berlin, make sure the interoperability guidance in the vision\ncalls out avoiding leakage of backend implementation details and\nconfiguration choices into the end user experience (particularly\nwhen it comes to altering API methods and their behaviors).\n\nChange-Id: Ib15f7c20b4fc3f85dd90172373175b2b179d492e\n'}]",2,628181,7e4adc7554c838303e210001481ef322c795c35b,19,10,1,5263,,,0,"Technical vision: hide implementation details

As discussed at the Technical Vision session at the OpenStack Forum
in Berlin, make sure the interoperability guidance in the vision
calls out avoiding leakage of backend implementation details and
configuration choices into the end user experience (particularly
when it comes to altering API methods and their behaviors).

Change-Id: Ib15f7c20b4fc3f85dd90172373175b2b179d492e
",git fetch https://review.opendev.org/openstack/governance refs/changes/81/628181/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/technical-vision.rst'],1,7e4adc7554c838303e210001481ef322c795c35b,formal-vote,"another. Deployment implementation details like backend driver differences and operators' partitioning_ configuration choices should, as much as possible, not be allowed to leak through to the resource consumer experience; in particular, they should not alter the behaviors of non-administrative API methods.",another.,4,1
openstack%2Fopenstack-zuul-jobs~master~Ib5fe0291fc32ccd970467c4031fef44a7ccd1e45,openstack/openstack-zuul-jobs,master,Ib5fe0291fc32ccd970467c4031fef44a7ccd1e45,Update laravel legacy jobs for PHP 7.x,MERGED,2019-01-07 14:04:10.000000000,2019-01-07 14:40:22.000000000,2019-01-07 14:40:22.000000000,"[{'_account_id': 2}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 22348}, {'_account_id': 24509}]","[{'number': 1, 'created': '2019-01-07 14:04:10.000000000', 'files': ['playbooks/legacy/laravel-openstackid-release-master/run.yaml', 'playbooks/legacy/laravel-openstackid-unittests/run.yaml', 'playbooks/legacy/laravel-openstackid-release-branch/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/590e300fdb73c873428e91263f73c8e6363e547c', 'message': 'Update laravel legacy jobs for PHP 7.x\n\nremoved mcrypt dependency that does not exist anymore\n\nChange-Id: Ib5fe0291fc32ccd970467c4031fef44a7ccd1e45\n'}]",0,628974,590e300fdb73c873428e91263f73c8e6363e547c,7,6,1,9139,,,0,"Update laravel legacy jobs for PHP 7.x

removed mcrypt dependency that does not exist anymore

Change-Id: Ib5fe0291fc32ccd970467c4031fef44a7ccd1e45
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/74/628974/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/laravel-openstackid-release-master/run.yaml', 'playbooks/legacy/laravel-openstackid-unittests/run.yaml', 'playbooks/legacy/laravel-openstackid-release-branch/run.yaml']",3,590e300fdb73c873428e91263f73c8e6363e547c,update/php7_laravel_jobs,, set -e set -x sudo php5enmod mcrypt executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: |,0,27
openstack%2Fnetworking-baremetal~master~I1dc24dc448bb5a38784d34f42ddf8e252dd73481,openstack/networking-baremetal,master,I1dc24dc448bb5a38784d34f42ddf8e252dd73481,[DNM] Tests,ABANDONED,2018-12-12 11:28:54.000000000,2019-01-07 14:39:41.000000000,,"[{'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-12 11:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/eabdcd28c8b135de42945278c127723f283dad63', 'message': '[DNM] Tests\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 2, 'created': '2018-12-18 12:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/6d7c2a411826edd629dcc37c67af0c1e1045a81b', 'message': '[DNM] Tests\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 3, 'created': '2018-12-18 15:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/38fecef3942c4396cdf0deeef810bb79d5187b3b', 'message': '[DNM] Tests\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 4, 'created': '2018-12-18 17:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/a3bb84651e448c318e007ae5105f75db27658471', 'message': '[DNM] Tests\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 5, 'created': '2018-12-19 12:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/f5db0582d4b43d213a1c133cd6ebc320e4d8c543', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 6, 'created': '2018-12-19 12:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/da2a9824b79c566916b7c6c5c1060cc3f1e594f0', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 7, 'created': '2018-12-19 14:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/89135ac50a8c5298e162aca2b0dc5e5e181d63c1', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 8, 'created': '2018-12-19 16:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/c7111894f400008b0fd3ed20785db07a5d03eb2e', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 9, 'created': '2019-01-03 08:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/388b25d0d471a28e498bebc0a0902b882d055ac9', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 10, 'created': '2019-01-03 14:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/04e21e3669dcec74ea1f2eb54ff1482cdd7a6db1', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 11, 'created': '2019-01-04 09:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/a1ef8a1c9691b8ca6aa9f45bf9ccf7c8e4faf431', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 12, 'created': '2019-01-04 10:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/e4d04cbc522a6c2a96f789a5144881f7b312816a', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 13, 'created': '2019-01-04 14:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/77d93236e567244082c4a3b6619f06a71fbbf246', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}, {'number': 14, 'created': '2019-01-05 13:23:36.000000000', 'files': ['zuul.d/networking-baremetal-jobs.yaml', 'zuul.d/project.yaml', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/d0a49c07de9509b2a4105882880114718afd1023', 'message': '[DNM] Tests\n\nDepends-On: https://review.openstack.org/#/c/626169/\n\nChange-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481\n'}]",1,624671,d0a49c07de9509b2a4105882880114718afd1023,29,3,14,15519,,,0,"[DNM] Tests

Depends-On: https://review.openstack.org/#/c/626169/

Change-Id: I1dc24dc448bb5a38784d34f42ddf8e252dd73481
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/71/624671/10 && git format-patch -1 --stdout FETCH_HEAD,['networking_baremetal/__init__.py'],1,eabdcd28c8b135de42945278c127723f283dad63,test_ci, # test,,2,0
openstack%2Freleases~master~I438dba552084b2a78bc60a390415eba105905885,openstack/releases,master,I438dba552084b2a78bc60a390415eba105905885,Release kolla and kolla-ansible stable releases,MERGED,2018-11-28 18:39:40.000000000,2019-01-07 14:36:54.000000000,2019-01-07 14:36:54.000000000,"[{'_account_id': 2472}, {'_account_id': 6873}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 19316}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-28 18:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e44c713b8b6f5af07096dabbf941ffc26074311d', 'message': 'Release kolla and kolla-ansible stable releases\n\nThis change makes a new release for kolla\nand kolla-ansible deliverables\n\nChange-Id: I438dba552084b2a78bc60a390415eba105905885\n'}, {'number': 2, 'created': '2018-12-03 19:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/998474719a87cc0f730394e53544754900da7808', 'message': 'Release kolla and kolla-ansible stable releases\n\nThis change makes a new release for kolla\nand kolla-ansible deliverables\n\nChange-Id: I438dba552084b2a78bc60a390415eba105905885\n'}, {'number': 3, 'created': '2019-01-03 14:17:27.000000000', 'files': ['deliverables/pike/kolla.yaml', 'deliverables/queens/kolla.yaml', 'deliverables/rocky/kolla-ansible.yaml', 'deliverables/pike/kolla-ansible.yaml', 'deliverables/rocky/kolla.yaml', 'deliverables/queens/kolla-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/50157d9588e4e77098b61a3573d794c4ad23c9b6', 'message': 'Release kolla and kolla-ansible stable releases\n\nThis change makes a new release for kolla\nand kolla-ansible deliverables\n\nChange-Id: I438dba552084b2a78bc60a390415eba105905885\n'}]",2,620677,50157d9588e4e77098b61a3573d794c4ad23c9b6,21,6,3,19316,,,0,"Release kolla and kolla-ansible stable releases

This change makes a new release for kolla
and kolla-ansible deliverables

Change-Id: I438dba552084b2a78bc60a390415eba105905885
",git fetch https://review.opendev.org/openstack/releases refs/changes/77/620677/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/pike/kolla.yaml', 'deliverables/queens/kolla.yaml', 'deliverables/rocky/kolla-ansible.yaml', 'deliverables/pike/kolla-ansible.yaml', 'deliverables/rocky/kolla.yaml', 'deliverables/queens/kolla-ansible.yaml']",6,e44c713b8b6f5af07096dabbf941ffc26074311d,kolla-stable-releases, - version: 6.2.0 projects: - repo: openstack/kolla-ansible hash: 70356636ca0193710a5db1b60ffb598ce94cb213,,24,0
openstack%2Freleases~master~Ib2c47ea18d254ab2ed9a13b0fc4f9baaf1c54e60,openstack/releases,master,Ib2c47ea18d254ab2ed9a13b0fc4f9baaf1c54e60,Release OpenStack-Ansible pike/16.0.24,MERGED,2018-12-23 16:53:30.000000000,2019-01-07 14:36:53.000000000,2019-01-07 14:36:53.000000000,"[{'_account_id': 1004}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 16:53:30.000000000', 'files': ['deliverables/pike/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1a06f342c86a93ebd93c7a59180bfe04b669d792', 'message': 'Release OpenStack-Ansible pike/16.0.24\n\nChange-Id: Ib2c47ea18d254ab2ed9a13b0fc4f9baaf1c54e60\n'}]",0,627082,1a06f342c86a93ebd93c7a59180bfe04b669d792,9,5,1,17068,,,0,"Release OpenStack-Ansible pike/16.0.24

Change-Id: Ib2c47ea18d254ab2ed9a13b0fc4f9baaf1c54e60
",git fetch https://review.opendev.org/openstack/releases refs/changes/82/627082/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/openstack-ansible.yaml'],1,1a06f342c86a93ebd93c7a59180bfe04b669d792,release_osa, - projects: - hash: 73ea68040476ada1766ce64d310276d2f6748e9d repo: openstack/openstack-ansible version: 16.0.24,,4,0
openstack%2Fopenstackdocstheme~master~I10f69d1b2cadced4cd155ef9b7f700a2806f44f9,openstack/openstackdocstheme,master,I10f69d1b2cadced4cd155ef9b7f700a2806f44f9,Catch OSError when trying to get the last_update from git,MERGED,2019-01-07 06:28:15.000000000,2019-01-07 14:35:16.000000000,2019-01-07 14:35:16.000000000,"[{'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 06:28:15.000000000', 'files': ['openstackdocstheme/page_context.py'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/1430d84470e4348629429f48de72546ba520c52a', 'message': 'Catch OSError when trying to get the last_update from git\n\nThe ""git"" executable might not be available (eg. in build environments\nwhere the .git dir is anyway no there because tarballs are used). In\nthat case, the current code failed with an\n\nOSError: [Errno 2] No such file or directory\n\nexception. This is now catched and the code works even if ""git"" is not\navailable.\n\nChange-Id: I10f69d1b2cadced4cd155ef9b7f700a2806f44f9\n'}]",0,628869,1430d84470e4348629429f48de72546ba520c52a,7,3,1,7102,,,0,"Catch OSError when trying to get the last_update from git

The ""git"" executable might not be available (eg. in build environments
where the .git dir is anyway no there because tarballs are used). In
that case, the current code failed with an

OSError: [Errno 2] No such file or directory

exception. This is now catched and the code works even if ""git"" is not
available.

Change-Id: I10f69d1b2cadced4cd155ef9b7f700a2806f44f9
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/69/628869/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackdocstheme/page_context.py'],1,1430d84470e4348629429f48de72546ba520c52a,," except (subprocess.CalledProcessError, OSError) as err:", except subprocess.CalledProcessError as err:,1,1
openstack%2Freleases~master~Ifc666d164ab82e6d29cd1cc7c4459267fc70473b,openstack/releases,master,Ifc666d164ab82e6d29cd1cc7c4459267fc70473b,Release kolla milestone2 deliverables,MERGED,2019-01-07 10:54:02.000000000,2019-01-07 14:33:17.000000000,2019-01-07 14:33:17.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-01-07 10:54:02.000000000', 'files': ['deliverables/stein/kolla.yaml', 'deliverables/stein/kolla-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/bd51707f73ce44d9e44b33672ba52b555473e8f3', 'message': 'Release kolla milestone2 deliverables\n\nChange-Id: Ifc666d164ab82e6d29cd1cc7c4459267fc70473b\n'}]",0,628930,bd51707f73ce44d9e44b33672ba52b555473e8f3,7,3,1,19316,,,0,"Release kolla milestone2 deliverables

Change-Id: Ifc666d164ab82e6d29cd1cc7c4459267fc70473b
",git fetch https://review.opendev.org/openstack/releases refs/changes/30/628930/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/stein/kolla.yaml', 'deliverables/stein/kolla-ansible.yaml']",2,bd51707f73ce44d9e44b33672ba52b555473e8f3,kolla-m2,releases: - projects: - hash: d55129d1266d13baec41753b3d07028bb966da6b repo: openstack/kolla-ansible version: 8.0.0.0b1,,10,0
openstack%2Fopenstack-helm-infra~master~I12dd9397850f854984bccbe190227f542eb577c4,openstack/openstack-helm-infra,master,I12dd9397850f854984bccbe190227f542eb577c4,Elasticsearch: Update s3 bucket name for snapshot repositories,ABANDONED,2019-01-04 15:25:34.000000000,2019-01-07 14:30:45.000000000,,"[{'_account_id': 22348}, {'_account_id': 28372}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-04 15:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dc1d333891396230aa75246818f09081be950f65', 'message': 'Elasticsearch: Update s3 bucket name for snapshot repositories\n\nThis changes the s3 bucket name in the Elasticsearch chart to\nfollow domain name constraints by changing the underscore to\na dash instead\n\nChange-Id: I12dd9397850f854984bccbe190227f542eb577c4\n'}, {'number': 2, 'created': '2019-01-04 17:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ab2e078fdf35e8f59ff8e9db9f8e093a58414b1f', 'message': 'Elasticsearch: Update s3 bucket name for snapshot repositories\n\nThis changes the s3 bucket name in the Elasticsearch chart to\nfollow domain name constraints by changing the underscore to\na dash instead\n\nChange-Id: I12dd9397850f854984bccbe190227f542eb577c4\n'}, {'number': 3, 'created': '2019-01-04 17:31:33.000000000', 'files': ['elasticsearch/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/83bbf89b29796e165d85547282aad0e2399b2217', 'message': 'Elasticsearch: Update s3 bucket name for snapshot repositories\n\nThis changes the s3 bucket name in the Elasticsearch chart to\nfollow domain name constraints by removing the underscore\n\nChange-Id: I12dd9397850f854984bccbe190227f542eb577c4\n'}]",0,628457,83bbf89b29796e165d85547282aad0e2399b2217,9,3,3,17591,,,0,"Elasticsearch: Update s3 bucket name for snapshot repositories

This changes the s3 bucket name in the Elasticsearch chart to
follow domain name constraints by removing the underscore

Change-Id: I12dd9397850f854984bccbe190227f542eb577c4
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/57/628457/2 && git format-patch -1 --stdout FETCH_HEAD,['elasticsearch/values.yaml'],1,dc1d333891396230aa75246818f09081be950f65,elasticsearch/bucket-name, bucket: elasticsearch-bucket, bucket: elasticsearch_bucket,1,1
openstack%2Ftripleo-ci~master~Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6,openstack/tripleo-ci,master,Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6,"Render playbooks minimal, move everything to roles",MERGED,2018-10-02 15:15:12.000000000,2019-01-07 14:29:06.000000000,2019-01-04 12:43:11.000000000,"[{'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2018-10-02 15:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4be116a18eade23c76b101def40df6c16437deff', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 2, 'created': '2018-10-03 09:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/997e9741fd08b636dbf74fb97fc6c7b4a1af45c6', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 3, 'created': '2018-10-04 15:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/52fd7835104c058a2dce0f248b41003794b2273c', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 4, 'created': '2018-11-13 15:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0a931df16e96e6e6dc6cc4122b11e6e5208c4645', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 5, 'created': '2018-11-13 16:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1164480c59057137230815cf989f47b6862d0ec9', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 6, 'created': '2018-11-13 17:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1a01b3b032d56675f3e8243539a6e66ca2529f23', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 7, 'created': '2018-11-16 18:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0a087a0153a57e1d3c41c6019ef2147ede6e09dc', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 8, 'created': '2018-11-16 18:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/06e2c03538b6d25cc1caafcc387e6bd91e62506b', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 9, 'created': '2018-11-16 19:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/58fad47d4a1273a3c9bd6dfe9dac3296c8d76551', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 10, 'created': '2018-11-16 19:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/38b56b3a27f45aa060489d7438486e9550a43465', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 11, 'created': '2018-11-16 19:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/08156cffbdef573b8fc5d4b897e3de410a4003d8', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 12, 'created': '2018-11-16 19:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ad480fb93d2ab79ba9572ea4c2af2ce89fc6116e', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 13, 'created': '2018-11-16 19:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d4920d5edb3e414ae489f656110018223f92cfed', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 14, 'created': '2018-11-16 20:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/495c244941f1a1a9e15ce601df132a7405bba10b', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 15, 'created': '2018-11-16 20:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/98720efd34fb0a98efc04388c5260c11552c6ed8', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 16, 'created': '2018-11-19 11:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5c18a42b9250874a7ac5bdc014356026bebb1b5c', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 17, 'created': '2018-11-19 12:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a380cf66fd6e0abf4312ce91bcd6e468a25d35c0', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 18, 'created': '2018-11-23 10:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2a87ab7f61bef10db503081481ff25a1bb2db9cb', 'message': 'Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates roles, and move tasks to be included in the new\nroles, so the playbooks are just minimal, and replicating them is not a\nproblem since the logic is in roles that are included\n\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n'}, {'number': 19, 'created': '2018-11-28 12:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/64136672b6033459a89e5209ffdc18c14db27243', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}, {'number': 20, 'created': '2018-12-12 10:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1290f3d647b9cbb99e8e2a08c029c79096a2323c', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}, {'number': 21, 'created': '2018-12-17 10:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e6c38f5a4c3c006c757ea46dbe1c102c4be18e1e', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}, {'number': 22, 'created': '2018-12-20 12:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0a6c8968625f04c5fdaf42763da8a2df4225f26c', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}, {'number': 23, 'created': '2019-01-02 13:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b1f2e24146abaa841c0575676502668fc3df66cf', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}, {'number': 24, 'created': '2019-01-03 07:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/016f262df6c7a83676eb4fcfe6a6411f4971e325', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}, {'number': 25, 'created': '2019-01-04 06:18:53.000000000', 'files': ['roles/run-test/templates/toci_gate_test.sh.j2', 'roles/common/vars/main.yaml', 'roles/run-test/templates/featureset-override.j2', 'zuul.d/base.yaml', 'playbooks/tripleo-ci/run-v3.yaml', 'roles/common/tasks/main.yml', 'roles/run-test/tasks/main.yaml', 'roles/prepare-node/tasks/main.yaml', 'roles/run-test/templates/common_vars.bash.j2', 'roles/run-test/templates/oooq_common_functions.sh.j2', 'roles/run-test/templates/toci_quickstart.sh.j2', 'playbooks/tripleo-ci/pre.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9206748e9d7d2700e1b0bd8edf6ac5c5d0792de9', 'message': ""Render playbooks minimal, move everything to roles\n\nIn zuul, roles can be easily included cross repos, while playbooks need\nto be replicated and copied.\nThis change creates three roles roles, and move tasks to be included in\nthe new roles, so the playbooks are just minimal, and replicating them\nis not a problem since the logic is in roles that are included\nThe common variables are loaded in the role common, the node preparation\ni moved to the prepare-node role, and it's now called in the pre,yaml\nplaybook in pre-run.\nrun-test role contains the rendering of bash scripts and effective test\nrun\n\nTaiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112\nChange-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6\n""}]",19,607288,9206748e9d7d2700e1b0bd8edf6ac5c5d0792de9,114,13,25,10022,,,0,"Render playbooks minimal, move everything to roles

In zuul, roles can be easily included cross repos, while playbooks need
to be replicated and copied.
This change creates three roles roles, and move tasks to be included in
the new roles, so the playbooks are just minimal, and replicating them
is not a problem since the logic is in roles that are included
The common variables are loaded in the role common, the node preparation
i moved to the prepare-node role, and it's now called in the pre,yaml
playbook in pre-run.
run-test role contains the rendering of bash scripts and effective test
run

Taiga-id: https://tree.taiga.io/project/tripleo-ci-board/task/112
Change-Id: Ie51fcfbee79727d04fca47d26a5ed8ad44ed3bf6
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/88/607288/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/tripleo-ci/run-v3.yaml', 'roles/run-test/tasks/main.yaml', 'roles/prepare-node/tasks/main.yaml', 'zuul.d/base.yaml', 'playbooks/tripleo-ci/pre.yaml']",5,4be116a18eade23c76b101def40df6c16437deff,oooq/move-to-roles,- hosts: all name: Common tasks for nodes preparation tasks: - include_role: name: prepare_node ,,115,117
openstack%2Fopenstack-ansible-lxc_container_create~master~Ica79472568799098ebf83c6cefc585f117975f37,openstack/openstack-ansible-lxc_container_create,master,Ica79472568799098ebf83c6cefc585f117975f37,Enable quota system and set qgroups,MERGED,2018-05-15 03:34:02.000000000,2019-01-07 14:20:53.000000000,2018-05-15 16:02:23.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-05-15 03:34:02.000000000', 'files': ['tasks/lxc_container_create_cow.yml', 'defaults/main.yml', 'tasks/lxc_container_create_machinectl.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/25478e9b4e8eaf7db05bb87356e6e317638fdd66', 'message': 'Enable quota system and set qgroups\n\nThis change implements the machinectl quota system and qgroups when\nthey\'re enabled and available. This change is being implemented to\nresolve an issue where machinectl based containers using a loopback file\nsystem spam DMESG with the following:\n\n* BTRFS error (device loop0): could not find root $INT\n\nWhile various upstream sources say this error is benign[0], it raises\nan inconsistency flag within the host system and is speculatively the\ncause of our inconsistent read-only/Full-FS issues we\'ve seen in the\nintegrated gate. Once the qgroups are properly setup the system will\nremove the inconsistency flag and the message spam will stop.\n\n* BTRFS info (device loop0): qgroup scan completed (inconsistency flag cleared)\n\nTo resolve this issue the quota system is being enabled by default\nwithin the ""lxc_host"" role. This change essentially acknowledges\nthe built-in quota system and when enabled provides for the ability\nto set / define specific quota (qgroup) options as necessary. While\nmany deployers may never use these options or this tooling, the role\nwill now properly set everything up should it ever be needed.\n\n[0] https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1651435\nCloses-Bug: #1753790\nDepends-On: I34a41ac8a9fe4419254284c83f4600efee274c04\nChange-Id: Ica79472568799098ebf83c6cefc585f117975f37\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",4,568430,25478e9b4e8eaf7db05bb87356e6e317638fdd66,11,3,1,7353,,,0,"Enable quota system and set qgroups

This change implements the machinectl quota system and qgroups when
they're enabled and available. This change is being implemented to
resolve an issue where machinectl based containers using a loopback file
system spam DMESG with the following:

* BTRFS error (device loop0): could not find root $INT

While various upstream sources say this error is benign[0], it raises
an inconsistency flag within the host system and is speculatively the
cause of our inconsistent read-only/Full-FS issues we've seen in the
integrated gate. Once the qgroups are properly setup the system will
remove the inconsistency flag and the message spam will stop.

* BTRFS info (device loop0): qgroup scan completed (inconsistency flag cleared)

To resolve this issue the quota system is being enabled by default
within the ""lxc_host"" role. This change essentially acknowledges
the built-in quota system and when enabled provides for the ability
to set / define specific quota (qgroup) options as necessary. While
many deployers may never use these options or this tooling, the role
will now properly set everything up should it ever be needed.

[0] https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1651435
Closes-Bug: #1753790
Depends-On: I34a41ac8a9fe4419254284c83f4600efee274c04
Change-Id: Ica79472568799098ebf83c6cefc585f117975f37
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/30/568430/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/lxc_container_create_cow.yml', 'defaults/main.yml', 'tasks/lxc_container_create_machinectl.yml']",3,25478e9b4e8eaf7db05bb87356e6e317638fdd66,bug/1753790," - name: Set the qgroup limits block: - name: Set the qgroup size|compression limits on machines command: ""btrfs qgroup limit {{ item }} /var/lib/machines/{{ inventory_hostname }}"" changed_when: false with_items: - ""-e {{ lxc_host_machine_qgroup_space_limit }}"" - ""-c {{ lxc_host_machine_qgroup_compression_limit }}"" when: - not lxc_host_machine_quota_disabled rescue: - name: Notice regarding quota system debug: msg: >- There was an error processing the setup of qgroups. Check the system to ensure they're available otherwise disable the quota system by setting `lxc_host_machine_quota_disabled` to true.",,50,0
openstack%2Fshade~master~I654b4408444f804f900951333a6ebc3372d5037e,openstack/shade,master,I654b4408444f804f900951333a6ebc3372d5037e,Split parser creation and parser for inventory,MERGED,2019-01-07 05:08:18.000000000,2019-01-07 14:12:12.000000000,2019-01-07 14:12:12.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 05:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/25ecb2ef1d79243249b6aa98cf1e16490c3080df', 'message': 'Split parser creation and parser for inventory\n\nAccess to the object separate from parsing allows us to use\nargparse-manpage to generate a man page in the Debian package\nautomatically.\n\nChange-Id: I654b4408444f804f900951333a6ebc3372d5037e\n'}, {'number': 2, 'created': '2019-01-07 11:40:38.000000000', 'files': ['shade/cmd/inventory.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/186dac653558477ee7fb64f978da457023074948', 'message': ""Split parser creation and parser for inventory\n\nAccess to the object separate from parsing allows us to use\nargparse-manpage to generate a man page in the Debian package\nautomatically. We also need to set 'prog' explicitly rather\nthan let it be picked up via argv[0] so that when we load\nthe parser via argparse-manpage it produces the right value.\n\nChange-Id: I654b4408444f804f900951333a6ebc3372d5037e\n""}]",0,628859,186dac653558477ee7fb64f978da457023074948,8,2,2,6488,,,0,"Split parser creation and parser for inventory

Access to the object separate from parsing allows us to use
argparse-manpage to generate a man page in the Debian package
automatically. We also need to set 'prog' explicitly rather
than let it be picked up via argv[0] so that when we load
the parser via argparse-manpage it produces the right value.

Change-Id: I654b4408444f804f900951333a6ebc3372d5037e
",git fetch https://review.opendev.org/openstack/shade refs/changes/59/628859/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/cmd/inventory.py'],1,25ecb2ef1d79243249b6aa98cf1e16490c3080df,,def get_parser(): return parser def parse_args(): return get_parser().parse_args(),def parse_args(): return parser.parse_args(),6,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~I675dc4985cdb3a86fac0a8421518ff3d7c784214,openstack/tripleo-heat-templates,stable/rocky,I675dc4985cdb3a86fac0a8421518ff3d7c784214,ceilometer: --skip-metering-database is gone,MERGED,2018-10-24 12:56:46.000000000,2019-01-07 14:09:32.000000000,2019-01-07 14:09:32.000000000,"[{'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 9592}, {'_account_id': 17216}, {'_account_id': 20775}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-24 12:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c4a32d21edb4d4365e4e29efaeebba726e89e215', 'message': 'ceilometer: --skip-metering-database is gone\n\nOption --skip-metering-database is gone since OSP13\n(I6b262dd440a72f25662b64d938ab9e5328709a97).\n\nThis change removes it.\n\nChange-Id: I675dc4985cdb3a86fac0a8421518ff3d7c784214\n'}, {'number': 2, 'created': '2018-11-05 21:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/85096eb44655ede538a796269b76a5d199f0daaf', 'message': 'ceilometer: --skip-metering-database is gone\n\nOption --skip-metering-database is gone since OSP13\n(I6b262dd440a72f25662b64d938ab9e5328709a97).\n\nThis change removes it.\n\nChange-Id: I675dc4985cdb3a86fac0a8421518ff3d7c784214\n(cherry picked from commit 60f6300e9bbd255a8a8f65d7ed5b50cbb5e4e662)\n'}, {'number': 3, 'created': '2018-12-12 13:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/23dbc792e753e89c97c33ae0443196371ebeedd4', 'message': 'ceilometer: --skip-metering-database is gone\n\nOption --skip-metering-database is gone since OSP13\n(I6b262dd440a72f25662b64d938ab9e5328709a97).\n\nThis change removes it.\n\nCloses #1743563\n\nChange-Id: I675dc4985cdb3a86fac0a8421518ff3d7c784214\n(cherry picked from commit 60f6300e9bbd255a8a8f65d7ed5b50cbb5e4e662)\n'}, {'number': 4, 'created': '2018-12-12 13:50:15.000000000', 'files': ['docker/services/ceilometer-agent-central.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/582182f39a298c2841fe5c442e41f83f84da60c5', 'message': 'ceilometer: --skip-metering-database is gone\n\nOption --skip-metering-database is gone since OSP13\n(I6b262dd440a72f25662b64d938ab9e5328709a97).\n\nThis change removes it.\n\nCloses-bug: #1743563\n\nChange-Id: I675dc4985cdb3a86fac0a8421518ff3d7c784214\n(cherry picked from commit 60f6300e9bbd255a8a8f65d7ed5b50cbb5e4e662)\n'}]",0,613009,582182f39a298c2841fe5c442e41f83f84da60c5,26,7,4,2813,,,0,"ceilometer: --skip-metering-database is gone

Option --skip-metering-database is gone since OSP13
(I6b262dd440a72f25662b64d938ab9e5328709a97).

This change removes it.

Closes-bug: #1743563

Change-Id: I675dc4985cdb3a86fac0a8421518ff3d7c784214
(cherry picked from commit 60f6300e9bbd255a8a8f65d7ed5b50cbb5e4e662)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/09/613009/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceilometer-agent-central.yaml'],1,c4a32d21edb4d4365e4e29efaeebba726e89e215,," - ""su ceilometer -s /bin/bash -c 'for n in {1..10}; do /usr/bin/ceilometer-upgrade && exit 0 || sleep 30; done; exit 1'"""," - ""su ceilometer -s /bin/bash -c 'for n in {1..10}; do /usr/bin/ceilometer-upgrade --skip-metering-database && exit 0 || sleep 30; done; exit 1'""",1,1
openstack%2Fopenstack-ansible-os_nova~master~Ica39496623eaba4797067d077cf822548562ca1d,openstack/openstack-ansible-os_nova,master,Ica39496623eaba4797067d077cf822548562ca1d,Update auth_uri option to www_authenticate_uri,ABANDONED,2018-04-16 21:04:27.000000000,2019-01-07 14:05:15.000000000,,"[{'_account_id': 22348}, {'_account_id': 26297}]","[{'number': 1, 'created': '2018-04-16 21:04:27.000000000', 'files': ['templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/764b757286a5d5c82b577e0d07727bcc32ac929b', 'message': 'Update auth_uri option to www_authenticate_uri\n\nOption auth_uri from group keystone_authtoken is deprecated[1].\nUse option www_authenticate_uri from group keystone_authtoken.\n\n[1]https://review.openstack.org/#/c/508522/\n\nChange-Id: Ica39496623eaba4797067d077cf822548562ca1d\n'}]",0,561726,764b757286a5d5c82b577e0d07727bcc32ac929b,4,2,1,17130,,,0,"Update auth_uri option to www_authenticate_uri

Option auth_uri from group keystone_authtoken is deprecated[1].
Use option www_authenticate_uri from group keystone_authtoken.

[1]https://review.openstack.org/#/c/508522/

Change-Id: Ica39496623eaba4797067d077cf822548562ca1d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/26/561726/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/nova.conf.j2'],1,764b757286a5d5c82b577e0d07727bcc32ac929b,auth_uri,www_authenticate_uri = {{ keystone_service_internaluri }},auth_uri = {{ keystone_service_internaluri }},1,1
openstack%2Fpaunch~master~Ie7433bff03d37f2aeffdf7592739768e71ba2366,openstack/paunch,master,Ie7433bff03d37f2aeffdf7592739768e71ba2366,[Core] Change openstack-dev to openstack-discuss.,MERGED,2018-12-05 08:42:24.000000000,2019-01-07 14:02:30.000000000,2019-01-07 14:02:30.000000000,"[{'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 26343}, {'_account_id': 28522}]","[{'number': 1, 'created': '2018-12-05 08:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/bd569cee40b7551e6d1457e23029b78d71904f6f', 'message': '[Core] Change openstack-dev to openstack-discuss.\n\nThe openstack-dev address is replaces by openstack-discuss.\n\nChange-Id: Ie7433bff03d37f2aeffdf7592739768e71ba2366\n'}, {'number': 2, 'created': '2019-01-03 14:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/f85b71a21549446062b18d1b885f603161a1bd9d', 'message': '[Core] Change openstack-dev to openstack-discuss.\n\nThe openstack-dev address is replaces by openstack-discuss.\n\nChange-Id: Ie7433bff03d37f2aeffdf7592739768e71ba2366\n'}, {'number': 3, 'created': '2019-01-07 09:01:19.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/paunch/commit/4e55596f71f980ecaba50a89dd0eb70b7d3927ff', 'message': '[Core] Change openstack-dev to openstack-discuss.\n\nThe openstack-dev address is replaces by openstack-discuss.\n\nChange-Id: Ie7433bff03d37f2aeffdf7592739768e71ba2366\n'}]",1,622894,4e55596f71f980ecaba50a89dd0eb70b7d3927ff,14,7,3,29222,,,0,"[Core] Change openstack-dev to openstack-discuss.

The openstack-dev address is replaces by openstack-discuss.

Change-Id: Ie7433bff03d37f2aeffdf7592739768e71ba2366
",git fetch https://review.opendev.org/openstack/paunch refs/changes/94/622894/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,bd569cee40b7551e6d1457e23029b78d71904f6f,change_mail,uthor-email = openstack-discuss@lists.openstack.orguniversal = 1 ,author-email = openstack-dev@lists.openstack.orguniversal = 1,2,2
openstack%2Ftripleo-heat-templates~master~If30b4647bca210663a22fd653e752d4d57345bdd,openstack/tripleo-heat-templates,master,If30b4647bca210663a22fd653e752d4d57345bdd,Use templating for nova cell database_connection,MERGED,2018-10-17 17:56:43.000000000,2019-01-07 14:02:29.000000000,2019-01-07 14:02:29.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 17823}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-10-17 17:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1671d09dbe16f7685fcf42428d77f1c5c4356023', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 2, 'created': '2018-10-25 09:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/38e3cb65a30e9e7ef7f51fa980bf0e7151e609ee', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 3, 'created': '2018-10-25 14:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eed01762ca71b0ffa36a31f9fbbaa555cb0bd708', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 4, 'created': '2018-12-06 14:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5dc0de0a82813de3f1ea3d856b0b2b97a55cd5d6', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 5, 'created': '2018-12-10 16:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/793cdaaeb346ca7fe764a4960f07d3930e8777b0', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 6, 'created': '2018-12-11 07:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1ed65898ff28b2169e47663ccaceb4aec116bf2b', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 7, 'created': '2018-12-12 10:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/264495fd42fa101a104afcbf1f98421b1b741d4d', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 8, 'created': '2018-12-13 07:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/77a39d0bdbb019dd3ccd32935761e0abce87628b', 'message': 'WIP: use templating for nova cell database_connection\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n'}, {'number': 9, 'created': '2018-12-14 17:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/14ea7e97a07a3cd6f4b2613debb0e97f6fae89eb', 'message': ""Use templating for nova cell database_connection\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated DB urls as part 1.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nRelated-Bug: 1808134\n\nCo-Authored-By: Martin Schuppert <mschuppert@redhat.com>\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n""}, {'number': 10, 'created': '2018-12-15 09:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/760b85c51a512e0db93961be05f56e51c2efd028', 'message': ""Use templating for nova cell database_connection\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated DB urls as part 1.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nRelated-Bug: 1808134\n\nCo-Authored-By: Martin Schuppert <mschuppert@redhat.com>\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n""}, {'number': 11, 'created': '2018-12-18 16:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/753ff7ad469f3626c0564f9a5efc3776227f7020', 'message': ""Use templating for nova cell database_connection\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated DB urls as part 1.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nRelated-Bug: 1808134\n\nCo-Authored-By: Martin Schuppert <mschuppert@redhat.com>\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n""}, {'number': 12, 'created': '2018-12-20 15:30:32.000000000', 'files': ['releasenotes/notes/nova_templated_cells_db_urls-2eb151090c49c51d.yaml', 'roles_data_undercloud.yaml', 'docker/services/nova-api.yaml', 'roles/Undercloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7288062676e9f1153c7982f708952a7f4ba59706', 'message': ""Use templating for nova cell database_connection\n\nNova now allows use of templated urls in the database and mq\nconnections which will allow static configuration elements to be\napplied to the urls read from the database per-node. This should\nbe a simpler and less obscure method of configuring things like\nthe per-node bind_address necessary for director's HA arrangement.\n\nThis patch addresses the templated DB urls as part 1.\n\nNova support added here:\nhttps://review.openstack.org/#/c/578163/\n\nRelated-Bug: 1808134\n\nCo-Authored-By: Martin Schuppert <mschuppert@redhat.com>\n\nChange-Id: If30b4647bca210663a22fd653e752d4d57345bdd\n""}]",11,611404,7288062676e9f1153c7982f708952a7f4ba59706,64,12,12,23811,,,0,"Use templating for nova cell database_connection

Nova now allows use of templated urls in the database and mq
connections which will allow static configuration elements to be
applied to the urls read from the database per-node. This should
be a simpler and less obscure method of configuring things like
the per-node bind_address necessary for director's HA arrangement.

This patch addresses the templated DB urls as part 1.

Nova support added here:
https://review.openstack.org/#/c/578163/

Related-Bug: 1808134

Co-Authored-By: Martin Schuppert <mschuppert@redhat.com>

Change-Id: If30b4647bca210663a22fd653e752d4d57345bdd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/04/611404/4 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/nova-base.yaml', 'docker/services/nova-api.yaml']",2,1671d09dbe16f7685fcf42428d77f1c5c4356023,bug/1808134," content: str_replace: template: | #!/bin/bash DEFID=$(nova-manage cell_v2 list_cells | sed -e '1,3d' -e '$d' | awk -F ' *| *' '$2 == ""default"" {print $4}') if [ ""$DEFID"" ]; then echo ""(cellv2) Updating default cell_v2 cell $DEFID"" su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 update_cell --cell_uuid $DEFID --name=default --database_connection='CELLDB'"" else echo ""(cellv2) Creating default cell_v2 cell"" su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 create_cell --name=default --database_connection='CELLDB'"" fi params: CELLDB: make_url: scheme: {get_param: [EndpointMap, MysqlInternal, protocol]} username: '{username}' password: '{password}' host: {get_param: [EndpointMap, MysqlInternal, host]} path: '/nova?{query}' fragment: '{fragment}' command: str_replace: template: ""/usr/bin/bootstrap_host_exec nova_api su nova -s /bin/bash -c '/usr/bin/nova-manage cell_v2 map_cell0 --database_connection=\'CELL0DB\''"" params: CELL0DB: make_url: scheme: {get_param: [EndpointMap, MysqlInternal, protocol]} username: '{username}' password: '{password}' host: {get_param: [EndpointMap, MysqlInternal, host]} path: '/nova_cell0?{query}' fragment: '{fragment}' template: nova-manage cell_v2 map_cell0 --database_connection='CELL0DB' params: CELL0DB: username: '{username}' password: '{password}' path: '/nova_cell0?{query}' fragment: '{fragment}' shell: str_replace: template: nova-manage cell_v2 create_cell --name='default' --database_connection='CELLDB' params: CELLDB: make_url: scheme: {get_param: [EndpointMap, MysqlInternal, protocol]} username: '{username}' password: '{password}' host: {get_param: [EndpointMap, MysqlInternal, host]} path: '/nova?{query}' fragment: '{fragment}'"," content: | #!/bin/bash DEFID=$(nova-manage cell_v2 list_cells | sed -e '1,3d' -e '$d' | awk -F ' *| *' '$2 == ""default"" {print $4}') if [ ""$DEFID"" ]; then echo ""(cellv2) Updating default cell_v2 cell $DEFID"" su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 update_cell --cell_uuid $DEFID --name=default"" else echo ""(cellv2) Creating default cell_v2 cell"" su nova -s /bin/bash -c ""/usr/bin/nova-manage cell_v2 create_cell --name=default"" fi command: ""/usr/bin/bootstrap_host_exec nova_api su nova -s /bin/bash -c '/usr/bin/nova-manage cell_v2 map_cell0'"" template: nova-manage cell_v2 map_cell0 --database_connection=CELL params: CELL: username: nova password: {get_param: NovaPassword} path: /nova_cell0 # (owalsh) pass the db uri explicitly to avoid https://bugs.launchpad.net/tripleo/+bug/1662344 shell: nova-manage cell_v2 create_cell --name='default' --database_connection=$(hiera nova::database_connection)",99,54
openstack%2Ftripleo-common~master~I967ae5528834382b6ef69cc4dac10c893c907fc8,openstack/tripleo-common,master,I967ae5528834382b6ef69cc4dac10c893c907fc8,Fail multiple executions of config-download of the same plan,MERGED,2018-09-28 13:11:11.000000000,2019-01-07 13:55:42.000000000,2019-01-07 13:55:42.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7385}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-28 13:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6bf5d02a6f428735f4a34368229db58b4dc9ca24', 'message': 'Fail multiple executions of config-download of the same plan\n\nAdd an initial task to the config_download_deploy workflow that queries\nfor existing executions of the same workflow on the same plan. If any\nare found, that means that config-download is already running on the\nexisting plan, so we should fail the additional one that is trying to\nstart.\n\nChange-Id: I967ae5528834382b6ef69cc4dac10c893c907fc8\n'}, {'number': 2, 'created': '2018-11-12 02:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/460458f9969997a3891b439760b0d39c44dec368', 'message': 'Fail multiple executions of config-download of the same plan\n\nAdd an initial task to the config_download_deploy workflow that queries\nfor existing executions of the same workflow on the same plan. If any\nare found, that means that config-download is already running on the\nexisting plan, so we should fail the additional one that is trying to\nstart.\n\nChange-Id: I967ae5528834382b6ef69cc4dac10c893c907fc8\n'}, {'number': 3, 'created': '2019-01-02 15:46:07.000000000', 'files': ['workbooks/deployment.yaml', 'releasenotes/notes/fail-multiple-config-download-executions-bf1f0984cd8af5f0.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/094ce5b250f7b1af54b7f08f2b3b353b05946ee4', 'message': 'Fail multiple executions of config-download of the same plan\n\nAdd an initial task to the config_download_deploy workflow that queries\nfor existing executions of the same workflow on the same plan. If any\nare found, that means that config-download is already running on the\nexisting plan, so we should fail the additional one that is trying to\nstart.\n\nChange-Id: I967ae5528834382b6ef69cc4dac10c893c907fc8\n'}]",0,606065,094ce5b250f7b1af54b7f08f2b3b353b05946ee4,17,6,3,7144,,,0,"Fail multiple executions of config-download of the same plan

Add an initial task to the config_download_deploy workflow that queries
for existing executions of the same workflow on the same plan. If any
are found, that means that config-download is already running on the
existing plan, so we should fail the additional one that is trying to
start.

Change-Id: I967ae5528834382b6ef69cc4dac10c893c907fc8
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/65/606065/2 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/deployment.yaml'],1,6bf5d02a6f428735f4a34368229db58b4dc9ca24,606065," check_for_deploy_in_progress: action: mistral.executions_find input: workflow_name: tripleo.deployment.v1.config_download_deploy state: RUNNING publish: running_config_download_workflows: <% task().result.where($.id != execution().id) %> on-success: - fail_deploy_in_progress: <% $.running_config_download_workflows != [] %> - get_blacklisted_hostnames: <% $.running_config_download_workflows = [] %> fail_deploy_in_progress: workflow: tripleo.messaging.v1.send input: queue_name: <% $.queue_name %> type: <% execution().name %> status: <% $.get('status', 'FAILED') %> execution: <% execution() %> message: Deployment already in progress with execution <% $.running_config_download_workflows[0].id %> plan_name: <% $.plan_name %> on-complete: fail ",,22,0
openstack%2Fproject-config~master~If9649afbabca579ce6d87780d87d52ab57d8172a,openstack/project-config,master,If9649afbabca579ce6d87780d87d52ab57d8172a,"Revert ""Add fetch-output to base job""",ABANDONED,2019-01-07 13:44:13.000000000,2019-01-07 13:51:02.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1004}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 13:44:13.000000000', 'files': ['playbooks/base/post-ssh.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/30145397f8e93627a2fa1aa21fa6978530cc059a', 'message': 'Revert ""Add fetch-output to base job""\n\nThis reverts commit 827559d01197d88db5977316388892e262ffd1c2.\n\nChange-Id: If9649afbabca579ce6d87780d87d52ab57d8172a\n'}]",0,628967,30145397f8e93627a2fa1aa21fa6978530cc059a,5,8,1,13252,,,0,"Revert ""Add fetch-output to base job""

This reverts commit 827559d01197d88db5977316388892e262ffd1c2.

Change-Id: If9649afbabca579ce6d87780d87d52ab57d8172a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/628967/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/base/post-ssh.yaml', 'zuul.d/jobs.yaml']",2,30145397f8e93627a2fa1aa21fa6978530cc059a,zuulv3-output, - playbooks/base-minimal/post-ssh.yaml, - playbooks/base-minimal/post.yaml,1,5
openstack%2Fproject-config~master~Icd1b98e2818519fe7a39668a5fbc036afccc633e,openstack/project-config,master,Icd1b98e2818519fe7a39668a5fbc036afccc633e,fetch-output: switch base to use post.yaml,MERGED,2019-01-07 13:48:51.000000000,2019-01-07 13:50:29.000000000,2019-01-07 13:50:29.000000000,[{'_account_id': 2}],"[{'number': 1, 'created': '2019-01-07 13:48:51.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3469395333b7b7d413f3a8d7ab34aa57da8ab747', 'message': ""fetch-output: switch base to use post.yaml\n\nIt looks like we've missed the base job in switching it to use\npost.yaml instead of post-ssh.yaml\n\nChange-Id: Icd1b98e2818519fe7a39668a5fbc036afccc633e\n""}]",0,628970,3469395333b7b7d413f3a8d7ab34aa57da8ab747,3,1,1,1004,,,0,"fetch-output: switch base to use post.yaml

It looks like we've missed the base job in switching it to use
post.yaml instead of post-ssh.yaml

Change-Id: Icd1b98e2818519fe7a39668a5fbc036afccc633e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/70/628970/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,3469395333b7b7d413f3a8d7ab34aa57da8ab747,, - playbooks/base/post.yaml, - playbooks/base/post-ssh.yaml,1,1
openstack%2Ftripleo-common~master~I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e,openstack/tripleo-common,master,I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e,Fail node cleaning on timeout,MERGED,2018-10-05 13:28:16.000000000,2019-01-07 13:45:18.000000000,2019-01-04 04:31:22.000000000,"[{'_account_id': 1926}, {'_account_id': 6926}, {'_account_id': 10239}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-05 13:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/43e9e76658339405aca02303ac94c9f09c89cfe1', 'message': 'Fail node cleaning on timeout\n\nThe Use of a retry with continue-on causes the task\nwait_for_provision_state to finish in success. We need another\ntask to test the provisioning state and conditionally fail\nbased on that.\n\nCloses-Bug: #1796293\nChange-Id: I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e\n'}, {'number': 2, 'created': '2018-10-05 15:33:36.000000000', 'files': ['workbooks/baremetal.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/70ed6378186dca5735f7ff8f51190de7eb7bf3ca', 'message': 'Fail node cleaning on timeout\n\nThe Use of a retry with continue-on causes the task\nwait_for_provision_state to finish in success. We need another\ntask to test the provisioning state and conditionally fail\nbased on that.\n\nCloses-Bug: #1796293\nChange-Id: I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e\n'}]",0,608260,70ed6378186dca5735f7ff8f51190de7eb7bf3ca,26,6,2,1926,,,0,"Fail node cleaning on timeout

The Use of a retry with continue-on causes the task
wait_for_provision_state to finish in success. We need another
task to test the provisioning state and conditionally fail
based on that.

Closes-Bug: #1796293
Change-Id: I94fe438a05c3d20b927f9fe1bc8cc3ea10d85f1e
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/60/608260/2 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/baremetal.yaml'],1,43e9e76658339405aca02303ac94c9f09c89cfe1,bug/1796293, on-complete: send_message - send_message: <% task().result.provision_state = 'manageable' %> - state_not_reached: <% task().result.provision_state != 'manageable' %> state_not_reached: publish: status: FAILED message: Cleaning of node <% $.node_uuid %> timed out. on-complete: send_message, on-success: send_message,9,1
openstack%2Fproject-config~master~I8eb1ed429a0662feb13eebcde9f8c085a2f156f0,openstack/project-config,master,I8eb1ed429a0662feb13eebcde9f8c085a2f156f0,Add fetch-output to base job,MERGED,2017-10-13 13:36:37.000000000,2019-01-07 13:44:13.000000000,2019-01-07 13:26:57.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-13 13:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a1e06fee620b0b0b28cf093374130b77960ae78a', 'message': 'Add fetch-output to base job\n\nChange-Id: I8eb1ed429a0662feb13eebcde9f8c085a2f156f0\n'}, {'number': 2, 'created': '2018-07-10 20:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bb30d2c667f47e913a047617c37f7cd5dbfaaf4c', 'message': 'Add fetch-output to base job\n\nChange-Id: I8eb1ed429a0662feb13eebcde9f8c085a2f156f0\n'}, {'number': 3, 'created': '2019-01-06 18:07:01.000000000', 'files': ['playbooks/base/post.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/827559d01197d88db5977316388892e262ffd1c2', 'message': 'Add fetch-output to base job\n\nChange-Id: I8eb1ed429a0662feb13eebcde9f8c085a2f156f0\n'}]",0,511851,827559d01197d88db5977316388892e262ffd1c2,15,7,3,2,,,0,"Add fetch-output to base job

Change-Id: I8eb1ed429a0662feb13eebcde9f8c085a2f156f0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/511851/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/base/post-logs.yaml'],1,a1e06fee620b0b0b28cf093374130b77960ae78a,zuulv3-output,- hosts: all roles: - fetch-output ,,4,0
openstack%2Fmanila~stable%2Frocky~Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39,openstack/manila,stable/rocky,Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39,Adjust ssh timeouts,MERGED,2019-01-05 12:37:17.000000000,2019-01-07 13:42:31.000000000,2019-01-07 12:58:18.000000000,"[{'_account_id': 7102}, {'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 24236}, {'_account_id': 25243}, {'_account_id': 26458}]","[{'number': 1, 'created': '2019-01-05 12:37:17.000000000', 'files': ['manila/tests/test_utils.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'devstack/plugin.sh', 'manila/utils.py', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/manila/commit/8919db0186f8da9f2f492d80c8a3700c3d9367d1', 'message': 'Adjust ssh timeouts\n\nGeneric driver jobs are failing because of timeouts when\nestablishing the initial ssh connection from manila-share\nto the service VM.\n\nBump up the default value of the connection timeout for paramiko\nclient and also set the banner timeout since the failure occurred\nduring banner exchange.  Set the two timeouts to the same value\nfor now.  This ensures that the connection timeout is at least as\nlong as the banner timeout and there is no current need in manila\nto control these independently.\n\nThis is more of a workaround than a real fix since a real fix\nwould remove the delay during banner exchange.  I suspect that\nthe real fix will need to be in neutron/ovs though.\n\nChange-Id: Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39\nPartial-bug: #1807216\n(cherry picked from commit 7548706b0928f2c23bf27e10d116ceca585660e4)\n'}]",0,628729,8919db0186f8da9f2f492d80c8a3700c3d9367d1,17,10,1,9003,,,0,"Adjust ssh timeouts

Generic driver jobs are failing because of timeouts when
establishing the initial ssh connection from manila-share
to the service VM.

Bump up the default value of the connection timeout for paramiko
client and also set the banner timeout since the failure occurred
during banner exchange.  Set the two timeouts to the same value
for now.  This ensures that the connection timeout is at least as
long as the banner timeout and there is no current need in manila
to control these independently.

This is more of a workaround than a real fix since a real fix
would remove the delay during banner exchange.  I suspect that
the real fix will need to be in neutron/ovs though.

Change-Id: Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39
Partial-bug: #1807216
(cherry picked from commit 7548706b0928f2c23bf27e10d116ceca585660e4)
",git fetch https://review.opendev.org/openstack/manila refs/changes/29/628729/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_utils.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'devstack/plugin.sh', 'manila/utils.py', 'devstack/settings']",5,8919db0186f8da9f2f492d80c8a3700c3d9367d1,bug/1673662-stable/rocky,# SSH TIMEOUT MANILA_SSH_TIMEOUT=${MANILA_SSH_TIMEOUT:-180} ,,28,7
openstack%2Fmanila~master~Ib3a9bebe362609d7198e053afebc6004f3d94baf,openstack/manila,master,Ib3a9bebe362609d7198e053afebc6004f3d94baf,Improve service instance module debug logging,MERGED,2018-12-30 02:58:07.000000000,2019-01-07 13:42:01.000000000,2019-01-05 00:47:56.000000000,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 18058}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2018-12-30 02:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4e7ae911552cf5fb067324ccd884e44d00f21835', 'message': 'Improve service instance module debug logging\n\nChange-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf\n'}, {'number': 2, 'created': '2018-12-30 17:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c234b5bd8484ba567731494aad1cea8f9ea415ec', 'message': 'Improve service instance module debug logging\n\nChange-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf\n'}, {'number': 3, 'created': '2018-12-31 13:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/eb9d26a4c5860e60b60350a8d07f1665e8314bbf', 'message': 'Improve service instance module debug logging\n\nChange-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf\n'}, {'number': 4, 'created': '2019-01-02 18:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e5a2b3b3b8474b4b509fac032c46c6391e37006b', 'message': 'Improve service instance module debug logging\n\nChange-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf\n'}, {'number': 5, 'created': '2019-01-02 21:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/39251882744de0e661a767c568d5a4c0fc005c25', 'message': 'Improve service instance module debug logging\n\nChange-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf\n'}, {'number': 6, 'created': '2019-01-03 17:06:37.000000000', 'files': ['manila/share/drivers/service_instance.py', 'manila/network/linux/interface.py', 'manila/share/drivers/generic.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/2117632c50a676a1782bdbd731b4d02f36a6f047', 'message': 'Improve service instance module debug logging\n\nChange-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf\n'}]",9,627796,2117632c50a676a1782bdbd731b4d02f36a6f047,114,16,6,9003,,,0,"Improve service instance module debug logging

Change-Id: Ib3a9bebe362609d7198e053afebc6004f3d94baf
",git fetch https://review.opendev.org/openstack/manila refs/changes/96/627796/6 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/service_instance.py', 'manila/network/linux/interface.py', 'manila/share/drivers/generic.py']",3,4e7ae911552cf5fb067324ccd884e44d00f21835,bug/1673662," LOG.debug(""_ssh_exec - server: %s, command: %s, check_exit_code: %s"" % (server, command, check_exit_code))",,10,2
openstack%2Fopenstack-ansible~stable%2Frocky~If1b126db89d053d969136c5f39b753badf7f28ba,openstack/openstack-ansible,stable/rocky,If1b126db89d053d969136c5f39b753badf7f28ba,Update Ansible to 2.5.14,MERGED,2018-12-19 22:53:51.000000000,2019-01-07 13:33:26.000000000,2019-01-07 13:33:25.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-19 22:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d56fab1ba22dace45d2593d132197889fcba0527', 'message': 'Update Ansible to 2.5.14\n\nUpdate to the latest available Ansible 2.5.x release.\nThis includes security fixes for several recent CVEs.\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16837\nhttps://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16859\nhttps://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16876\n\nChange-Id: If1b126db89d053d969136c5f39b753badf7f28ba\n'}, {'number': 2, 'created': '2019-01-07 09:31:50.000000000', 'files': ['scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/07658a2991a1dcf86054e232bdb34854700a2963', 'message': 'Update Ansible to 2.5.14\n\nUpdate to the latest available Ansible 2.5.x release.\nThis includes security fixes for several recent CVEs.\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16837\nhttps://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16859\nhttps://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16876\n\nChange-Id: If1b126db89d053d969136c5f39b753badf7f28ba\n'}]",0,626404,07658a2991a1dcf86054e232bdb34854700a2963,19,4,2,14805,,,0,"Update Ansible to 2.5.14

Update to the latest available Ansible 2.5.x release.
This includes security fixes for several recent CVEs.

https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16837
https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16859
https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2018-16876

Change-Id: If1b126db89d053d969136c5f39b753badf7f28ba
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/04/626404/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/bootstrap-ansible.sh'],1,d56fab1ba22dace45d2593d132197889fcba0527,osa-update-ansible,"export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible==2.5.14""}","export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible==2.5.10""}",1,1
openstack%2Fnova~stable%2Fqueens~I5165b69f956fbf1904112a742698b2739f747e72,openstack/nova,stable/queens,I5165b69f956fbf1904112a742698b2739f747e72,Exclude build request marker from server listing,MERGED,2018-12-20 13:54:47.000000000,2019-01-07 13:05:23.000000000,2019-01-07 04:32:37.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 25113}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-20 13:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fe89a04c94d41484f48dd074fda9a7a3c7ea5fb', 'message': 'Exclude build request marker from server listing\n\nWhen listing ""real"" (already in cell) instances e.g. from\nnova_cell1.instances table, a marker option means ""start after the\ninstance with marker"".\n\nFor VMs:\n\n| uuid | name |\n| 1    | vm1  |\n| 2    | vm2  |\n\n""openstack server list --marker 1"" returns vm2 only.\n\nBut for VMs from nova_api.build_requests table it\'s different.\n\nFor VMs:\n\n| uuid | name |\n| 1    | vm1  |\n| 2    | vm2  |\n\n""openstack server list --marker 1"" returns both vm1 and vm2.\n\nThis patch excludes instance with marker from listing for\ninstances from build_requests table.\n\nCloses-Bug: #1808286\nChange-Id: I5165b69f956fbf1904112a742698b2739f747e72\n'}, {'number': 2, 'created': '2018-12-20 18:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d446ad594a4605dfee8976f249ece25e4ea3481b', 'message': 'Exclude build request marker from server listing\n\nWhen listing ""real"" (already in cell) instances e.g. from\nnova_cell1.instances table, a marker option means ""start after the\ninstance with marker"".\n\nFor VMs:\n\n| uuid | name |\n| 1    | vm1  |\n| 2    | vm2  |\n\n""openstack server list --marker 1"" returns vm2 only.\n\nBut for VMs from nova_api.build_requests table it\'s different.\n\nFor VMs:\n\n| uuid | name |\n| 1    | vm1  |\n| 2    | vm2  |\n\n""openstack server list --marker 1"" returns both vm1 and vm2.\n\nThis patch excludes instance with marker from listing for\ninstances from build_requests table.\n\nCloses-Bug: #1808286\nChange-Id: I5165b69f956fbf1904112a742698b2739f747e72\n(cherry picked from commit 2ef704cba619a149336692311c2614742aa32909)\n'}, {'number': 3, 'created': '2019-01-03 14:27:36.000000000', 'files': ['nova/tests/functional/db/test_build_request.py', 'nova/objects/build_request.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8aadd4ebdfea3f1b46b2e2e62b355e8b40b6261b', 'message': 'Exclude build request marker from server listing\n\nWhen listing ""real"" (already in cell) instances e.g. from\nnova_cell1.instances table, a marker option means ""start after the\ninstance with marker"".\n\nFor VMs:\n\n| uuid | name |\n| 1    | vm1  |\n| 2    | vm2  |\n\n""openstack server list --marker 1"" returns vm2 only.\n\nBut for VMs from nova_api.build_requests table it\'s different.\n\nFor VMs:\n\n| uuid | name |\n| 1    | vm1  |\n| 2    | vm2  |\n\n""openstack server list --marker 1"" returns both vm1 and vm2.\n\nThis patch excludes instance with marker from listing for\ninstances from build_requests table.\n\nCloses-Bug: #1808286\nChange-Id: I5165b69f956fbf1904112a742698b2739f747e72\n(cherry picked from commit 2ef704cba619a149336692311c2614742aa32909)\n(cherry picked from commit 3eb0ba988f4cfca4399c92cd6bb7b4ae8665720c)\n'}]",1,626585,8aadd4ebdfea3f1b46b2e2e62b355e8b40b6261b,34,13,3,21813,,,0,"Exclude build request marker from server listing

When listing ""real"" (already in cell) instances e.g. from
nova_cell1.instances table, a marker option means ""start after the
instance with marker"".

For VMs:

| uuid | name |
| 1    | vm1  |
| 2    | vm2  |

""openstack server list --marker 1"" returns vm2 only.

But for VMs from nova_api.build_requests table it's different.

For VMs:

| uuid | name |
| 1    | vm1  |
| 2    | vm2  |

""openstack server list --marker 1"" returns both vm1 and vm2.

This patch excludes instance with marker from listing for
instances from build_requests table.

Closes-Bug: #1808286
Change-Id: I5165b69f956fbf1904112a742698b2739f747e72
(cherry picked from commit 2ef704cba619a149336692311c2614742aa32909)
(cherry picked from commit 3eb0ba988f4cfca4399c92cd6bb7b4ae8665720c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/626585/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/db/test_build_request.py', 'nova/objects/build_request.py']",2,2fe89a04c94d41484f48dd074fda9a7a3c7ea5fb,bug/1808286," # The marker is the last seen item in the last page, so # we increment the index to the next item immediately # after the marker so the marker is not returned. marker_index = i + 1", marker_index = i,15,9
openstack%2Fnova~master~I8355372da93b93cc1c7f7a1501af0fbd01eee615,openstack/nova,master,I8355372da93b93cc1c7f7a1501af0fbd01eee615,Removing pip-missing-reqs from default tox jobs,MERGED,2018-09-03 18:15:07.000000000,2019-01-07 13:04:24.000000000,2018-09-04 17:22:53.000000000,"[{'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-03 18:15:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/a8253805dffb5598c311c23b854f987a18e69a15', 'message': 'Removing pip-missing-reqs from default tox jobs\n\nChange I1b02384494ae9f440b72b98d9ae5f31d88dc8967 removed the\ntox env entry for pip-missing-reqs but did not remove the job\nfrom the envlist.\n\nThis means that if you run tox with no args it will run that job,\nusing the default venv setup with takes time but runs no tests.\n\nChange-Id: I8355372da93b93cc1c7f7a1501af0fbd01eee615\n'}]",1,599442,a8253805dffb5598c311c23b854f987a18e69a15,14,9,1,11564,,,0,"Removing pip-missing-reqs from default tox jobs

Change I1b02384494ae9f440b72b98d9ae5f31d88dc8967 removed the
tox env entry for pip-missing-reqs but did not remove the job
from the envlist.

This means that if you run tox with no args it will run that job,
using the default venv setup with takes time but runs no tests.

Change-Id: I8355372da93b93cc1c7f7a1501af0fbd01eee615
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/599442/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a8253805dffb5598c311c23b854f987a18e69a15,cd/missing-pip-missing,"envlist = py{27,35},functional,pep8","envlist = py{27,35},functional,pep8,pip-missing-reqs",1,1
openstack%2Fcharm-ceph-mon~stable%2F18.11~I83211dbdec4dea8dca5b27a66e26a4431d2a7b77,openstack/charm-ceph-mon,stable/18.11,I83211dbdec4dea8dca5b27a66e26a4431d2a7b77,Disable object skew warnings,MERGED,2019-01-07 09:19:21.000000000,2019-01-07 13:01:21.000000000,2019-01-07 13:01:20.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 09:19:21.000000000', 'files': ['templates/ceph.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/a0e0db5774c573f50db3c11892b91a91d6eafec9', 'message': 'Disable object skew warnings\n\nCeph will issue a HEALTH_WARN in the event that one pool has a\nlarge number of objects compared to other pools in the cluster:\n\n ""Issue a HEALTH_WARN in cluster log if the average object\n  number of a certain pool is greater than mon pg warn max\n  object skew times the average object number of the whole\n  pool.""\n\nFor OpenStack deployments, Gnocchi and RADOS gateway can generate\na large number of small objects compared to Cinder, Glance and\nNova usage, causing the cluster to go into HEALTH_WARN status.\n\nDisable this check until the skew evaluation also includes the\nsize of the objects as well as the number.\n\nChange-Id: I83211dbdec4dea8dca5b27a66e26a4431d2a7b77\nCloses-Bug: 1804846\n(cherry picked from commit 33f9bae6c7eba61b931191882f0696db909fb84e)\n'}]",0,628917,a0e0db5774c573f50db3c11892b91a91d6eafec9,8,4,1,935,,,0,"Disable object skew warnings

Ceph will issue a HEALTH_WARN in the event that one pool has a
large number of objects compared to other pools in the cluster:

 ""Issue a HEALTH_WARN in cluster log if the average object
  number of a certain pool is greater than mon pg warn max
  object skew times the average object number of the whole
  pool.""

For OpenStack deployments, Gnocchi and RADOS gateway can generate
a large number of small objects compared to Cinder, Glance and
Nova usage, causing the cluster to go into HEALTH_WARN status.

Disable this check until the skew evaluation also includes the
size of the objects as well as the number.

Change-Id: I83211dbdec4dea8dca5b27a66e26a4431d2a7b77
Closes-Bug: 1804846
(cherry picked from commit 33f9bae6c7eba61b931191882f0696db909fb84e)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/17/628917/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/ceph.conf'],1,a0e0db5774c573f50db3c11892b91a91d6eafec9,bug/1804846,# NOTE(jamespage): # Disable object skew warnings as these only use # the number of objects and not their size in the # skew calculation. mon pg warn max object skew = -1 ,,6,0
openstack%2Fmistral~master~I940b0bea7350735bcf78045058fc23568ba2e29a,openstack/mistral,master,I940b0bea7350735bcf78045058fc23568ba2e29a,Amend the spelling error of a word,MERGED,2018-06-06 09:40:22.000000000,2019-01-07 12:35:57.000000000,2019-01-07 12:35:56.000000000,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 22348}, {'_account_id': 25747}, {'_account_id': 27008}, {'_account_id': 27507}]","[{'number': 1, 'created': '2018-06-06 09:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/853bc487194e44f816cf9eb0676fd9105cdba3ba', 'message': 'Amend the spelling error of a word\n\nChange-Id: I940b0bea7350735bcf78045058fc23568ba2e29a\n'}, {'number': 2, 'created': '2018-12-24 04:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e93f75f975c38d84b70ab3232edb6b5bc83ddb35', 'message': 'Amend the spelling error of a word\n\nChange-Id: I940b0bea7350735bcf78045058fc23568ba2e29a\n'}, {'number': 3, 'created': '2019-01-04 11:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/cb311c18cf403b3810ff427009d3896f826cde25', 'message': 'Amend the spelling error of a word\n\nChange-Id: I940b0bea7350735bcf78045058fc23568ba2e29a\n'}, {'number': 4, 'created': '2019-01-04 14:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1e81e1de52dd3c583d370ee120faed3514d0184f', 'message': 'Amend the spelling error of a word\n\nChange-Id: I940b0bea7350735bcf78045058fc23568ba2e29a\n'}, {'number': 5, 'created': '2019-01-07 09:22:02.000000000', 'files': ['mistral/engine/actions.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/7301d8cbcd7d27687b653df6b4dbaca93d7bf396', 'message': 'Amend the spelling error of a word\n\nChange-Id: I940b0bea7350735bcf78045058fc23568ba2e29a\n'}]",0,572714,7301d8cbcd7d27687b653df6b4dbaca93d7bf396,26,6,5,27549,,,0,"Amend the spelling error of a word

Change-Id: I940b0bea7350735bcf78045058fc23568ba2e29a
",git fetch https://review.opendev.org/openstack/mistral refs/changes/14/572714/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/event_engine/default_event_engine.py', 'mistral/engine/actions.py']",2,853bc487194e44f816cf9eb0676fd9105cdba3ba,, # we should propagate that ID down. Otherwise the parent must be the, # we should propogate that ID down. Otherwise the parent must be the,2,2
openstack%2Fmistral~master~I274bb4b2e6ac97c6ed6d85367f96b72f3ecd06c5,openstack/mistral,master,I274bb4b2e6ac97c6ed6d85367f96b72f3ecd06c5,fix typo mistakes,MERGED,2018-12-16 07:56:32.000000000,2019-01-07 12:21:09.000000000,2019-01-07 12:21:09.000000000,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 27549}, {'_account_id': 29558}]","[{'number': 1, 'created': '2018-12-16 07:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/493cdf1c2eafb2a9297d88a5d6dc75c8aa989d73', 'message': 'fix typo mistakes\n\nChange-Id: I274bb4b2e6ac97c6ed6d85367f96b72f3ecd06c5\n'}, {'number': 2, 'created': '2019-01-04 11:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7280cedd178d2a89a065c94d186a4bfbe6f28cf9', 'message': 'fix typo mistakes\n\nChange-Id: I274bb4b2e6ac97c6ed6d85367f96b72f3ecd06c5\n'}, {'number': 3, 'created': '2019-01-07 09:22:56.000000000', 'files': ['mistral/engine/actions.py', 'releasenotes/notes/make_integrity_checker_work_with_batches-56c1cd94200d4c38.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/efca6f2e95829d23effe3747dd07ce0689ba069c', 'message': 'fix typo mistakes\n\nChange-Id: I274bb4b2e6ac97c6ed6d85367f96b72f3ecd06c5\n'}]",0,625418,efca6f2e95829d23effe3747dd07ce0689ba069c,24,6,3,27507,,,0,"fix typo mistakes

Change-Id: I274bb4b2e6ac97c6ed6d85367f96b72f3ecd06c5
",git fetch https://review.opendev.org/openstack/mistral refs/changes/18/625418/3 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/actions.py', 'releasenotes/notes/make_integrity_checker_work_with_batches-56c1cd94200d4c38.yaml']",2,493cdf1c2eafb2a9297d88a5d6dc75c8aa989d73,, Workflow execution integrity checker mechanism was too aggressive in case, Workflow execution integrity checker mechanism was too agressive in case,2,2
openstack%2Fopenstack-zuul-jobs~master~I4bd32afa5da92df5c272b72f2a1f0bce8fbbd1d9,openstack/openstack-zuul-jobs,master,I4bd32afa5da92df5c272b72f2a1f0bce8fbbd1d9,Remove tempest-dsvm-neutron-scenario-linuxbridge job definition,ABANDONED,2019-01-07 12:13:20.000000000,2019-01-07 12:19:47.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-07 12:13:20.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/tempest-dsvm-neutron-scenario-linuxbridge/run.yaml', 'playbooks/legacy/tempest-dsvm-neutron-scenario-linuxbridge/post.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/9dee3aee4f2e55aba9c31f77029545878dd5709a', 'message': 'Remove tempest-dsvm-neutron-scenario-linuxbridge job definition\n\nIt looks in [1] that this job is not used anywhere.\nTempest scenario test are run in neutron-tempest-linuxbridge job which\nis defined in neutron repo already [2].\n\n[1] http://codesearch.openstack.org/?q=tempest-dsvm-neutron-scenario-linuxbridge&i=nope&files=&repos=\n[2] http://git.openstack.org/cgit/openstack/neutron/tree/.zuul.yaml#n182\n\nChange-Id: I4bd32afa5da92df5c272b72f2a1f0bce8fbbd1d9\n'}]",0,628942,9dee3aee4f2e55aba9c31f77029545878dd5709a,3,1,1,11975,,,0,"Remove tempest-dsvm-neutron-scenario-linuxbridge job definition

It looks in [1] that this job is not used anywhere.
Tempest scenario test are run in neutron-tempest-linuxbridge job which
is defined in neutron repo already [2].

[1] http://codesearch.openstack.org/?q=tempest-dsvm-neutron-scenario-linuxbridge&i=nope&files=&repos=
[2] http://git.openstack.org/cgit/openstack/neutron/tree/.zuul.yaml#n182

Change-Id: I4bd32afa5da92df5c272b72f2a1f0bce8fbbd1d9
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/42/628942/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/tempest-dsvm-neutron-scenario-linuxbridge/run.yaml', 'playbooks/legacy/tempest-dsvm-neutron-scenario-linuxbridge/post.yaml']",3,9dee3aee4f2e55aba9c31f77029545878dd5709a,bug/1804844,,- hosts: primary tasks: - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*nose_results.html - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*testr_results.html.gz - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/.testrepository/tmp* - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*testrepository.subunit.gz - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}/tox' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/.tox/*/log/* - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/logs/** - --include=*/ - --exclude=* - --prune-empty-dirs ,0,162
openstack%2Fnetworking-sfc~master~I29f08214895fdf812994a3f1a790497484bf71d7,openstack/networking-sfc,master,I29f08214895fdf812994a3f1a790497484bf71d7,Define default policies in code,MERGED,2018-12-16 13:31:06.000000000,2019-01-07 12:19:31.000000000,2019-01-07 12:19:30.000000000,"[{'_account_id': 841}, {'_account_id': 18955}, {'_account_id': 21883}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-16 13:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/6b3766b79099168d56ab46b4584af55caf1b3b3b', 'message': 'Define default policies in code\n\nnetworking-sfc has no policy.json so far, so all policy definitions\nare newly created.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: I29f08214895fdf812994a3f1a790497484bf71d7\n'}, {'number': 2, 'created': '2018-12-16 16:21:08.000000000', 'files': ['networking_sfc/policies/__init__.py', 'networking_sfc/policies/port_pair_group.py', 'networking_sfc/policies/base.py', 'networking_sfc/policies/port_chain.py', 'networking_sfc/policies/service_graph.py', 'networking_sfc/policies/flow_classifier.py', 'etc/oslo-policy-generator/policy.conf', 'setup.cfg', 'tox.ini', 'networking_sfc/policies/port_pair.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/235e9fe49370bc411266388e988f3a28720c3cd3', 'message': 'Define default policies in code\n\nnetworking-sfc has no policy.json so far, so all policy definitions\nare newly created.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nChange-Id: I29f08214895fdf812994a3f1a790497484bf71d7\n'}]",2,625431,235e9fe49370bc411266388e988f3a28720c3cd3,12,4,2,841,,,0,"Define default policies in code

networking-sfc has no policy.json so far, so all policy definitions
are newly created.

Partially Implements: blueprint neutron-policy-in-code

Change-Id: I29f08214895fdf812994a3f1a790497484bf71d7
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/31/625431/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_sfc/policies/__init__.py', 'networking_sfc/policies/port_pair_group.py', 'networking_sfc/policies/base.py', 'networking_sfc/policies/port_chain.py', 'networking_sfc/policies/service_graph.py', 'networking_sfc/policies/flow_classifier.py', 'etc/oslo-policy-generator/policy.conf', 'setup.cfg', 'tox.ini', 'networking_sfc/policies/port_pair.py']",10,6b3766b79099168d56ab46b4584af55caf1b3b3b,bp/neutron-policy-in-code,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_policy import policy from networking_sfc.policies import base rules = [ policy.DocumentedRuleDefault( 'create_port_pair', base.RULE_ANY, 'Create a port pair', [ { 'method': 'POST', 'path': '/sfc/port_pairs', }, ] ), policy.DocumentedRuleDefault( 'update_port_pair', base.RULE_ADMIN_OR_OWNER, 'Update a port pair', [ { 'method': 'PUT', 'path': '/sfc/port_pairs/{id}', }, ] ), policy.DocumentedRuleDefault( 'delete_port_pair', base.RULE_ADMIN_OR_OWNER, 'Delete a port pair', [ { 'method': 'DELETE', 'path': '/sfc/port_pairs/{id}', }, ] ), policy.DocumentedRuleDefault( 'get_port_pair', base.RULE_ADMIN_OR_OWNER, 'Get port pairs', [ { 'method': 'GET', 'path': '/sfc/port_pairs', }, { 'method': 'GET', 'path': '/sfc/port_pairs/{id}', }, ] ), ] def list_rules(): return rules ",,413,0
openstack%2Ftripleo-ci~master~Iba46f6cbe67efef6aa413a6583d27893257d1a18,openstack/tripleo-ci,master,Iba46f6cbe67efef6aa413a6583d27893257d1a18,DNM: ssbarnea testing change via depends-on,ABANDONED,2018-11-29 12:39:12.000000000,2019-01-07 12:16:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-11-29 12:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1c47f410305a25cf58a3833288e2c536931bed80', 'message': 'DNM: testing adding pip fallback for pypi.org\n\nDepends-On: https://review.openstack.org/620630\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 2, 'created': '2018-12-07 15:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c1096fa1f03a86b24d48777be9180d61a99c897a', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.openstack.org/#/c/623516/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 3, 'created': '2018-12-07 15:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1058760b135acb16da4d21d7201ecc0947ff03a6', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.openstack.org/#/c/623516/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 4, 'created': '2018-12-11 10:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a13e76684e8f69beef203bc81da1f0fe343e98d7', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.openstack.org/#/c/623516/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 5, 'created': '2018-12-17 12:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/77110720283f099d2fc44364600b9912841bd875', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.rdoproject.org/r/#/c/17732/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 6, 'created': '2018-12-17 12:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3482925f6f4c66332dcbc51946f50c68fac18144', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.rdoproject.org/r/#/c/17732/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 7, 'created': '2018-12-17 12:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/774cc819974b2eb57a83da9adc1f62cc8a9bc61b', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.rdoproject.org/r/#/c/17732/\nDepends-On: https://review.openstack.org/625576\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 8, 'created': '2018-12-17 14:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ef0ff068847527998b9dec0e2a0428b1366e8d28', 'message': 'DNM: ssbarnea testing change via depends-on\n\nDepends-On: https://review.rdoproject.org/17732\nDepends-On: https://review.openstack.org/625576\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 9, 'created': '2018-12-17 17:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fd5e15433aae1bbedd33adb850e628a855de4240', 'message': 'DNM: ssbarnea testing change via depends-on\n\nNote: Once tested on rdo we should also test on upstream zool via\nhttps://review.openstack.org/625576\n\nApparently is not possible to combine dependson from multiple gerrit\nservers as they both fail with: \nThis change depends on a change that failed to merge.\n\nDepends-On: https://review.rdoproject.org/17732\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 10, 'created': '2018-12-17 17:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f5f2ea6300681bd8cda0320748f1262a80f6038', 'message': 'DNM: ssbarnea testing change via depends-on\n\nNote: Once tested on rdo we should also test on upstream zool via\nhttps://review.openstack.org/625576\n\nApparently is not possible to combine dependson from multiple gerrit\nservers as they both fail with: \nThis change depends on a change that failed to merge.\n\nDepends-On: https://review.rdoproject.org/r/#/c/17732/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 11, 'created': '2018-12-17 17:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d1f84618c25ef9a1d2ab3d429d0346e60118cc06', 'message': 'DNM: ssbarnea testing change via depends-on\n\nNote: Once tested on rdo we should also test on upstream zool via\nhttps://review.openstack.org/625576\n\nApparently is not possible to combine dependson from multiple gerrit\nservers as they both fail with: \nThis change depends on a change that failed to merge.\n\nDepends-On: https://review.rdoproject.org/r/#/c/17732/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 12, 'created': '2019-01-07 10:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ac2779100a16ed732a7dd46903ff327f2ab9e458', 'message': 'DNM: ssbarnea testing change via depends-on\n\nNote: Once tested on rdo we should also test on upstream zool via\nhttps://review.openstack.org/625576\n\nApparently is not possible to combine dependson from multiple gerrit\nservers as they both fail with: \nThis change depends on a change that failed to merge.\n\nDepends-On: https://review.rdoproject.org/r/#/c/17732/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}, {'number': 13, 'created': '2019-01-07 11:37:32.000000000', 'files': ['DNM.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3ab349fae8d9572006a971630bd028aac363510d', 'message': 'DNM: ssbarnea testing change via depends-on\n\nNote: Once tested on rdo we should also test on upstream zool via\nhttps://review.openstack.org/625576\n\nApparently is not possible to combine dependson from multiple gerrit\nservers as they both fail with: \nThis change depends on a change that failed to merge.\n\nDepends-On: https://review.openstack.org/#/c/625576/\nChange-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18\n'}]",0,620902,3ab349fae8d9572006a971630bd028aac363510d,31,3,13,24162,,,0,"DNM: ssbarnea testing change via depends-on

Note: Once tested on rdo we should also test on upstream zool via
https://review.openstack.org/625576

Apparently is not possible to combine dependson from multiple gerrit
servers as they both fail with: 
This change depends on a change that failed to merge.

Depends-On: https://review.openstack.org/#/c/625576/
Change-Id: Iba46f6cbe67efef6aa413a6583d27893257d1a18
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/02/620902/3 && git format-patch -1 --stdout FETCH_HEAD,['DNM.txt'],1,1c47f410305a25cf58a3833288e2c536931bed80,oooq/ansible.cfg,,,0,0
openstack%2Fopenstack-ansible-os_neutron~master~Ia6295c1fb1ed48fb830007b202470128e706d529,openstack/openstack-ansible-os_neutron,master,Ia6295c1fb1ed48fb830007b202470128e706d529,cleanup: remove unnecessary package installations,MERGED,2018-12-29 23:53:12.000000000,2019-01-07 12:16:24.000000000,2019-01-07 12:16:24.000000000,"[{'_account_id': 7353}, {'_account_id': 21883}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-29 23:53:12.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu.yml', 'vars/main.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/305a2a94164df31690f3ccc1ba6e95ac2eee3311', 'message': 'cleanup: remove unnecessary package installations\n\nWe are installing a lot more packages than needed, we can rely\non implicit dependencies to be pulled in instead of defining\na wide-set things to install.\n\nChange-Id: Ia6295c1fb1ed48fb830007b202470128e706d529\n'}]",0,627791,305a2a94164df31690f3ccc1ba6e95ac2eee3311,12,3,1,1004,,,0,"cleanup: remove unnecessary package installations

We are installing a lot more packages than needed, we can rely
on implicit dependencies to be pulled in instead of defining
a wide-set things to install.

Change-Id: Ia6295c1fb1ed48fb830007b202470128e706d529
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/91/627791/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu.yml', 'vars/main.yml', 'vars/suse.yml']",4,305a2a94164df31690f3ccc1ba6e95ac2eee3311,osa-speedups,, - python-keystoneclient - python-cliff - python-glanceclient - python-neutronclient - python-novaclient,0,24
openstack%2Fcharm-keystone~master~I952c8c64376b1332328c46e27f7f6004bf7c80e4,openstack/charm-keystone,master,I952c8c64376b1332328c46e27f7f6004bf7c80e4,Remove unnecessary update identity relations calls,ABANDONED,2018-07-04 08:14:14.000000000,2019-01-07 12:08:25.000000000,,"[{'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-04 08:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/5f5396f2287b8fbbd2e12473c63f03718ac1eb54', 'message': 'Remove unnecessary update identity relations calls\n\nThe call to update_all_identity_relation_units() from\nleader_init_db_if_ready() when db is already is\ninitialized gets triggered in many situations when\nit is not necessary.\n\nCall after migrate_database and at end of shared-db changed\nis unnecessary as identity-service-changed hooks will run\ndriven by related charms after shared-db relation is complete\nand database is initialized.\n\nChange-Id: I952c8c64376b1332328c46e27f7f6004bf7c80e4\n'}, {'number': 2, 'created': '2018-07-16 13:30:59.000000000', 'files': ['unit_tests/test_keystone_hooks.py', 'hooks/keystone_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/ac275a36ed7eb5b7547db870add9fccdd10d0ceb', 'message': 'Remove unnecessary update identity relations calls\n\nThe call to update_all_identity_relation_units() from\nleader_init_db_if_ready() when db is already is\ninitialized gets triggered in many situations when\nit is not necessary.\n\nCall after migrate_database and at end of shared-db changed\nis unnecessary as identity-service-changed hooks will run\ndriven by related charms after shared-db relation is complete\nand database is initialized.\n\nChange-Id: I952c8c64376b1332328c46e27f7f6004bf7c80e4\n'}]",0,580083,ac275a36ed7eb5b7547db870add9fccdd10d0ceb,14,4,2,13686,,,0,"Remove unnecessary update identity relations calls

The call to update_all_identity_relation_units() from
leader_init_db_if_ready() when db is already is
initialized gets triggered in many situations when
it is not necessary.

Call after migrate_database and at end of shared-db changed
is unnecessary as identity-service-changed hooks will run
driven by related charms after shared-db relation is complete
and database is initialized.

Change-Id: I952c8c64376b1332328c46e27f7f6004bf7c80e4
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/83/580083/2 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_keystone_hooks.py', 'hooks/keystone_hooks.py']",2,5f5396f2287b8fbbd2e12473c63f03718ac1eb54,remove-redundant-calls,, update_all_identity_relation_units(check_db_ready=False) update_all_identity_relation_units(check_db_ready=False) update_all_identity_relation_units(),4,16
openstack%2Fcharm-ceph-mon~master~I67d0d089e6e6576d3e820dd141424b23dc0c9c01,openstack/charm-ceph-mon,master,I67d0d089e6e6576d3e820dd141424b23dc0c9c01,Add benchmark storage cluster action,ABANDONED,2018-04-28 17:59:08.000000000,2019-01-07 12:05:17.000000000,,"[{'_account_id': 935}, {'_account_id': 22348}, {'_account_id': 27053}]","[{'number': 1, 'created': '2018-04-28 17:59:08.000000000', 'files': ['actions/benchmark-cluster', 'actions/benchmark_cluster.py', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/d5078ef7381c203ab7136d0128bd94862d3cfc33', 'message': 'Add benchmark storage cluster action\n\nUse `rados bench` to perform write, sequential read, and random read\nCeph storage cluster benchmarks.  Allow pool, duration, and number of\nthreads to be specified.  For write benchmarks, also allow object size\nto be specified.\n\nUse `rados cleanup` to clean up benchmark data.  By default, do not\nclean up data after a write benchmark is performed.\n\nChange-Id: I67d0d089e6e6576d3e820dd141424b23dc0c9c01\n'}]",0,565042,d5078ef7381c203ab7136d0128bd94862d3cfc33,6,3,1,27053,,,0,"Add benchmark storage cluster action

Use `rados bench` to perform write, sequential read, and random read
Ceph storage cluster benchmarks.  Allow pool, duration, and number of
threads to be specified.  For write benchmarks, also allow object size
to be specified.

Use `rados cleanup` to clean up benchmark data.  By default, do not
clean up data after a write benchmark is performed.

Change-Id: I67d0d089e6e6576d3e820dd141424b23dc0c9c01
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/42/565042/1 && git format-patch -1 --stdout FETCH_HEAD,"['actions/benchmark-cluster', 'actions/benchmark_cluster.py', 'actions.yaml']",3,d5078ef7381c203ab7136d0128bd94862d3cfc33,benchmark,"benchmark-cluster: description: Benchmark a storage cluster using `rados bench`. params: cleanup: type: boolean default: false description: Clean up after a write benchmark. mode: type: string enum: [write, seq, rand] description: | Mode of benchmark to perform. Either write, sequential read (seq), or random read (rand). To run a read benchmark, first run a write benchmark. pool: type: string description: Pool to use for benchmarking. seconds: type: integer default: 10 description: Duration to perform benchmark for, in seconds. size: type: integer default: 4 description: The size of objects used during write benchmarks, in MB. threads: type: integer default: 16 description: The number of concurrent I/O operations. required: [pool] additionalProperties: false",,149,0
openstack%2Fcharm-hacluster~master~If7da5b5241e1a79d4dfde41a8560798045c76768,openstack/charm-hacluster,master,If7da5b5241e1a79d4dfde41a8560798045c76768,Replace juju set with juju config in docs/comments.,ABANDONED,2018-05-03 12:13:08.000000000,2019-01-07 12:04:59.000000000,,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-05-03 12:13:08.000000000', 'files': ['hooks/charmhelpers/contrib/charmsupport/volumes.py', 'tests/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/core/hookenv.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/bd5854093cc4fd30b55287caa5a823ad5bba8511', 'message': 'Replace juju set with juju config in docs/comments.\n\nChange-Id: If7da5b5241e1a79d4dfde41a8560798045c76768\nSigned-off-by: Vern Hart <v-openstack@vern.com>\n'}]",0,566041,bd5854093cc4fd30b55287caa5a823ad5bba8511,9,2,1,11683,,,0,"Replace juju set with juju config in docs/comments.

Change-Id: If7da5b5241e1a79d4dfde41a8560798045c76768
Signed-off-by: Vern Hart <v-openstack@vern.com>
",git fetch https://review.opendev.org/openstack/charm-hacluster refs/changes/41/566041/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/charmsupport/volumes.py', 'tests/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/core/hookenv.py', 'README.md']",4,bd5854093cc4fd30b55287caa5a823ad5bba8511,juju-config," juju config mysql vip=""192.168.21.1"""," juju set mysql vip=""192.168.21.1""",4,4
openstack%2Fcharm-ceph-osd~master~I849c22beab8e246a9e5293590b7d7c1d71da9487,openstack/charm-ceph-osd,master,I849c22beab8e246a9e5293590b7d7c1d71da9487,Add three new actions to the Ceph OSD charm,ABANDONED,2017-12-04 00:55:18.000000000,2019-01-07 12:03:53.000000000,,"[{'_account_id': 12767}, {'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 24099}]","[{'number': 1, 'created': '2017-12-04 00:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/9a9720ae22dfd72df4bbb864dfb9566a6867cead', 'message': 'Add three new actions to the Ceph OSD charm\n\n* list-host-osds - lists mounted OSDs for a given unit\n* disk-for-osd - returns the block device backing a given OSD\n* osd-for-disk - returns the OSD ID (if any) for a given disk\n\nIncluding unit tests for the above four actions.\n\nChange-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487\nCloses-Bug: #1720099\n'}, {'number': 2, 'created': '2017-12-04 04:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/ab3e93fb2b0c807052113d48ef605ccab722896d', 'message': 'Add three new actions to the Ceph OSD charm\n\n* list-host-osds - lists mounted OSDs for a given unit\n* disk-for-osd - returns the block device backing a given OSD\n* osd-for-disk - returns the OSD ID (if any) for a given disk\n\nIncluding unit tests for the above three actions.\n\nChange-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487\nCloses-Bug: #1720099\n'}, {'number': 3, 'created': '2017-12-04 04:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/7cf1418d249dbe6e5201442e9b6af102ae536937', 'message': 'Add three new actions to the Ceph OSD charm\n\n* list-host-osds - lists mounted OSDs for a given unit\n* disk-for-osd - returns the block device backing a given OSD\n* osd-for-disk - returns the OSD ID (if any) for a given disk\n\nIncluding unit tests for the above three actions.\n\nChange-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487\nCloses-Bug: #1720099\n'}, {'number': 4, 'created': '2018-02-20 23:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/6272d9ed7ad4bc548f2638b07267ebc96c8960d5', 'message': 'Add three new actions to the Ceph OSD charm\n\n* list-host-osds - lists mounted OSDs for a given unit\n* disk-for-osd - returns the block device backing a given OSD\n* osd-for-disk - returns the OSD ID (if any) for a given disk\n\nIncluding unit tests for the above three actions.\n\nChange-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487\nCloses-Bug: #1720099\n'}, {'number': 5, 'created': '2018-03-06 08:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/0af2df8e5be1399c52a925bc821ed7fad47c209d', 'message': 'Add three new actions to the Ceph OSD charm\n\n* list-host-osds - lists mounted OSDs for a given unit\n* disk-for-osd - returns the block device backing a given OSD\n* osd-for-disk - returns the OSD ID (if any) for a given disk\n\nIncluding unit tests for the above three actions.\n\nChange-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487\nCloses-Bug: #1720099\n'}, {'number': 6, 'created': '2018-04-05 22:39:44.000000000', 'files': ['actions/list-host-osds', 'actions/ceph_ops.py', 'unit_tests/test_actions_osd.py', 'actions/disk-for-osd', 'actions/osd-for-disk', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/d61cf059e0f656204bd5048aed3f1221060a3db2', 'message': 'Add three new actions to the Ceph OSD charm\n\n* list-host-osds - lists mounted OSDs for a given unit\n* disk-for-osd - returns the block device backing a given OSD\n* osd-for-disk - returns the OSD ID (if any) for a given disk\n\nIncluding unit tests for the above three actions.\n\nChange-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487\nCloses-Bug: #1720099\n'}]",0,525019,d61cf059e0f656204bd5048aed3f1221060a3db2,29,6,6,24099,,,0,"Add three new actions to the Ceph OSD charm

* list-host-osds - lists mounted OSDs for a given unit
* disk-for-osd - returns the block device backing a given OSD
* osd-for-disk - returns the OSD ID (if any) for a given disk

Including unit tests for the above three actions.

Change-Id: I849c22beab8e246a9e5293590b7d7c1d71da9487
Closes-Bug: #1720099
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/19/525019/3 && git format-patch -1 --stdout FETCH_HEAD,"['actions/list-host-osds', 'actions/ceph_ops.py', 'unit_tests/test_actions_osd.py', 'actions/disk-for-osd', 'actions/osd-for-disk', 'actions.yaml']",6,9a9720ae22dfd72df4bbb864dfb9566a6867cead,bug/1720099,"list-host-osds: description: Output a list of OSDs running on a this unit, if it has mounted OSDs disk-for-osd: description: Output the backing disk for an OSD params: osd: type: string description: The OSD number to fetch backing device for required: [osd] osd-for-disk: description: Output the OSD mounted on a given disk params: device: type: string description: The full device path to return an OSD ID for required: [device]",,221,0
openstack%2Fcharm-barbican~master~I8895b24fec847d1b18739dad85db979a13981298,openstack/charm-barbican,master,I8895b24fec847d1b18739dad85db979a13981298,Update auth_uri option to www_authenticate_uri,ABANDONED,2018-04-16 21:53:15.000000000,2019-01-07 12:03:37.000000000,,"[{'_account_id': 935}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 27615}]","[{'number': 1, 'created': '2018-04-16 21:53:15.000000000', 'files': ['src/templates/mitaka/barbican-api-paste.ini'], 'web_link': 'https://opendev.org/openstack/charm-barbican/commit/0c3bc5c2c927c51e35315dc7b8f2d9d9bccad6ed', 'message': 'Update auth_uri option to www_authenticate_uri\n\nOption auth_uri from group keystone_authtoken is deprecated[1].\nUse option www_authenticate_uri from group keystone_authtoken.\n\n[1]https://review.openstack.org/#/c/508522/\n\nChange-Id: I8895b24fec847d1b18739dad85db979a13981298\n'}]",0,561741,0c3bc5c2c927c51e35315dc7b8f2d9d9bccad6ed,8,5,1,17130,,,0,"Update auth_uri option to www_authenticate_uri

Option auth_uri from group keystone_authtoken is deprecated[1].
Use option www_authenticate_uri from group keystone_authtoken.

[1]https://review.openstack.org/#/c/508522/

Change-Id: I8895b24fec847d1b18739dad85db979a13981298
",git fetch https://review.opendev.org/openstack/charm-barbican refs/changes/41/561741/1 && git format-patch -1 --stdout FETCH_HEAD,['src/templates/mitaka/barbican-api-paste.ini'],1,0c3bc5c2c927c51e35315dc7b8f2d9d9bccad6ed,auth_uri,www_authenticate_uri = {{ identity_service.service_protocol}}://{{ identity_service.service_host }}:{{ identity_service.service_port }}/,auth_uri = {{ identity_service.service_protocol}}://{{ identity_service.service_host }}:{{ identity_service.service_port }}/,1,1
openstack%2Fcharm-mistral~master~I04a58b753e9ff66a13b89e9d7b655e8f9a877eb0,openstack/charm-mistral,master,I04a58b753e9ff66a13b89e9d7b655e8f9a877eb0,Drop all qpid related explanations,ABANDONED,2018-05-29 07:09:06.000000000,2019-01-07 12:02:08.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-05-29 07:09:06.000000000', 'files': ['src/templates/mitaka/mistral.conf'], 'web_link': 'https://opendev.org/openstack/charm-mistral/commit/6b9e7cfa51e13078279424101e393b10cd2b609b', 'message': 'Drop all qpid related explanations\n\nQpid was removed in Mitaka from Oslo Messaging, so we\ncan remove all qpid related explanations.\n\nChange-Id: I04a58b753e9ff66a13b89e9d7b655e8f9a877eb0\n'}]",0,570848,6b9e7cfa51e13078279424101e393b10cd2b609b,3,1,1,17130,,,0,"Drop all qpid related explanations

Qpid was removed in Mitaka from Oslo Messaging, so we
can remove all qpid related explanations.

Change-Id: I04a58b753e9ff66a13b89e9d7b655e8f9a877eb0
",git fetch https://review.opendev.org/openstack/charm-mistral refs/changes/48/570848/1 && git format-patch -1 --stdout FETCH_HEAD,['src/templates/mitaka/mistral.conf'],1,6b9e7cfa51e13078279424101e393b10cd2b609b,remove-qpid,"#default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,dogpile.core.dogpile=INFO","#default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,dogpile.core.dogpile=INFO",1,1
openstack%2Fcharm-cinder-ceph~master~Ibe0e8e0d22886c9996ed2a07ae1b04378136356e,openstack/charm-cinder-ceph,master,Ibe0e8e0d22886c9996ed2a07ae1b04378136356e,provide backend_host in per-backend sections,ABANDONED,2018-06-01 15:21:36.000000000,2019-01-07 12:01:42.000000000,,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 24824}]","[{'number': 1, 'created': '2018-06-01 15:21:36.000000000', 'files': ['tests/basic_deployment.py', 'hooks/cinder_contexts.py', 'unit_tests/test_cinder_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/fc1bd9be1c7189328d861b6ad98630d7d85efbc0', 'message': 'provide backend_host in per-backend sections\n\nIn order to support multiple Ceph clusters related to the same Cinder\nglobal host config needs to be overridden via backend_host config.\n\nChange-Id: Ibe0e8e0d22886c9996ed2a07ae1b04378136356e\nCloses-Bug: #1773800\n'}]",0,571762,fc1bd9be1c7189328d861b6ad98630d7d85efbc0,7,5,1,24824,,,0,"provide backend_host in per-backend sections

In order to support multiple Ceph clusters related to the same Cinder
global host config needs to be overridden via backend_host config.

Change-Id: Ibe0e8e0d22886c9996ed2a07ae1b04378136356e
Closes-Bug: #1773800
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/62/571762/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/basic_deployment.py', 'hooks/cinder_contexts.py', 'unit_tests/test_cinder_contexts.py']",3,fc1bd9be1c7189328d861b6ad98630d7d85efbc0,bug/1773800," ('backend_host', service), ('backend_host', service),",,5,0
openstack%2Fcharm-rabbitmq-server~master~I0643596a24d918a7afa1800f145ba3ef79736c14,openstack/charm-rabbitmq-server,master,I0643596a24d918a7afa1800f145ba3ef79736c14,Update config.yaml,ABANDONED,2018-06-07 15:07:13.000000000,2019-01-07 12:00:08.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2018-06-07 15:07:13.000000000', 'files': ['config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/a635e1add54d9fc9765e9f1c319a2be4303cd4d9', 'message': 'Update config.yaml\n\nChange-Id: I0643596a24d918a7afa1800f145ba3ef79736c14\n'}]",0,573290,a635e1add54d9fc9765e9f1c319a2be4303cd4d9,3,1,1,28371,,,0,"Update config.yaml

Change-Id: I0643596a24d918a7afa1800f145ba3ef79736c14
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/90/573290/1 && git format-patch -1 --stdout FETCH_HEAD,['config.yaml'],1,a635e1add54d9fc9765e9f1c319a2be4303cd4d9,," default: ""[['\\*', '\\*', 500, 600]]"""," default: ""[['\\*', '\\*', 100, 200]]""",1,1
openstack%2Fcharm-cinder-ceph~master~I180c6e228e8aeaec9949f300983ee3f9518bebf0,openstack/charm-cinder-ceph,master,I180c6e228e8aeaec9949f300983ee3f9518bebf0,Allows to specify pg_num to be used for ceph pool,ABANDONED,2018-06-22 17:41:24.000000000,2019-01-07 11:59:39.000000000,,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 22348}, {'_account_id': 27052}]","[{'number': 1, 'created': '2018-06-22 17:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/3a4c148a6fc0b6ebe02a2a4c6c06256e5ed326e8', 'message': 'Allows to specify pg_num to be used for ceph pool\n\nIf ceph-pool-pgnum is specified, it will be used directly as pg_num\nin ceph pool create command instead of calculated value.\nIn such case ceph-pool-weight is ignored.\n\nChange-Id: I180c6e228e8aeaec9949f300983ee3f9518bebf0\n'}, {'number': 2, 'created': '2018-06-22 18:19:24.000000000', 'files': ['config.yaml', 'hooks/cinder_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/6d899275e0ac2997368fb84fa5264485bc4034a5', 'message': 'Allows to specify pg_num to be used for ceph pool\n\nIf ceph-pool-pgnum is specified, it will be used directly as pg_num\nin ceph pool create command instead of calculated value.\nIn such case ceph-pool-weight is ignored.\n\nChange-Id: I180c6e228e8aeaec9949f300983ee3f9518bebf0\n'}]",0,577484,6d899275e0ac2997368fb84fa5264485bc4034a5,8,4,2,27052,,,0,"Allows to specify pg_num to be used for ceph pool

If ceph-pool-pgnum is specified, it will be used directly as pg_num
in ceph pool create command instead of calculated value.
In such case ceph-pool-weight is ignored.

Change-Id: I180c6e228e8aeaec9949f300983ee3f9518bebf0
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/84/577484/1 && git format-patch -1 --stdout FETCH_HEAD,"['config.yaml', 'hooks/cinder_hooks.py']",2,3a4c148a6fc0b6ebe02a2a4c6c06256e5ed326e8,allow-pgnum-parameter," pg_num = config('ceph-pool-pgnum') if (pg_num != 0): rq.add_op_create_pool(name=service, replica_count=replicas, pg_num=pg_num, group=""volumes"") else: rq.add_op_create_pool(name=service, replica_count=replicas,"," rq.add_op_create_pool(name=service, replica_count=replicas,",15,1
openstack%2Fkayobe~master~I8951242ba40158c26e85377254d19085d85cf753,openstack/kayobe,master,I8951242ba40158c26e85377254d19085d85cf753,Perform ironic online data migrations prior to seed upgrade,MERGED,2018-12-24 14:39:25.000000000,2019-01-07 11:54:24.000000000,2019-01-07 11:54:24.000000000,"[{'_account_id': 16984}, {'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-24 14:39:25.000000000', 'files': ['ansible/seed-service-upgrade-prep.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/950bcb165f76897f4314cb2b857af9a97a528864', 'message': 'Perform ironic online data migrations prior to seed upgrade\n\nBifrost does not perform ironic online data migrations after upgrading. This\ncan lead to the following error during kayobe seed service upgrade:\n\nThe database is not compatible with this release of ironic (10.1.7). Please run\n""ironic-dbsync online_data_migrations"" using the previous release.\n\nAs a workaround, perform the migrations in kayobe, prior to performing the\nupgrade.\n\nChange-Id: I8951242ba40158c26e85377254d19085d85cf753\nStory: 2004308\nTask: 28657\n'}]",0,627187,950bcb165f76897f4314cb2b857af9a97a528864,7,3,1,14826,,,0,"Perform ironic online data migrations prior to seed upgrade

Bifrost does not perform ironic online data migrations after upgrading. This
can lead to the following error during kayobe seed service upgrade:

The database is not compatible with this release of ironic (10.1.7). Please run
""ironic-dbsync online_data_migrations"" using the previous release.

As a workaround, perform the migrations in kayobe, prior to performing the
upgrade.

Change-Id: I8951242ba40158c26e85377254d19085d85cf753
Story: 2004308
Task: 28657
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/87/627187/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/seed-service-upgrade-prep.yml'],1,950bcb165f76897f4314cb2b857af9a97a528864,story/2004308," # Bifrost does not perform ironic's online data migrations, which can # prevent upgrading the database. If the upgrade fails early on, then the # ironic config file may not exist. On subsequent attempts, this would # cause the migrations to fail, so skip online migrations if ironic.conf # doesn't exist. # TODO: If the ironic config file does exist, we need to check # the return code, since 2 means that the DB is not compatible - name: Perform ironic online data migrations command: > docker exec bifrost_deploy bash -c ' if [[ -f /etc/ironic/ironic.conf ]]; then ironic-dbsync online_data_migrations fi' changed_when: true",,16,0
openstack%2Fcharm-ceph-radosgw~master~I7f4deec0bbd7c22a77021bf2f1bbd7485f564761,openstack/charm-ceph-radosgw,master,I7f4deec0bbd7c22a77021bf2f1bbd7485f564761,Removes broker_req from mon's relation_get to avoid pool creation retrials for every hook called.,ABANDONED,2018-07-12 12:47:50.000000000,2019-01-07 11:53:43.000000000,,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 28510}]","[{'number': 1, 'created': '2018-07-12 12:47:50.000000000', 'files': ['hooks/hooks.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/8c30a5073c53b0d07cbcddf45cf891510e25c83c', 'message': ""Removes broker_req from mon's relation_get to avoid pool creation retrials for every hook called.\n\nChange-Id: I7f4deec0bbd7c22a77021bf2f1bbd7485f564761\nPartial-Bug: #1773910\n""}]",0,582172,8c30a5073c53b0d07cbcddf45cf891510e25c83c,6,4,1,28510,,,0,"Removes broker_req from mon's relation_get to avoid pool creation retrials for every hook called.

Change-Id: I7f4deec0bbd7c22a77021bf2f1bbd7485f564761
Partial-Bug: #1773910
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/72/582172/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/hooks.py', 'test-requirements.txt']",2,8c30a5073c53b0d07cbcddf45cf891510e25c83c,bug/1773910,"charm-tools>=2.0.0;python_version=='2.7'bundletester>=0.6.1,<1.0;python_version=='2.7'","charm-tools>=2.0.0bundletester>=0.6.1,<1.0",28,8
openstack%2Fcharm-neutron-api-genericswitch~master~Iba205b842ba40a59de3edf6c0600b2cc8f95cc11,openstack/charm-neutron-api-genericswitch,master,Iba205b842ba40a59de3edf6c0600b2cc8f95cc11,Introduce support for Queens release (WIP),ABANDONED,2018-07-04 01:03:30.000000000,2019-01-07 11:51:36.000000000,,"[{'_account_id': 7080}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-04 01:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/bfdb1a7e9a1a5690c98e8336fef1d1abaa0cd8e3', 'message': 'Introduce support for Queens release (WIP)\n\nChange-Id: Iba205b842ba40a59de3edf6c0600b2cc8f95cc11\n'}, {'number': 2, 'created': '2018-08-06 23:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/8e3a326db6b652317c0d5b6c3eb32a17f7f12a63', 'message': 'Introduce support for Queens release (WIP)\n\nChange-Id: Iba205b842ba40a59de3edf6c0600b2cc8f95cc11\n'}, {'number': 3, 'created': '2018-08-07 02:19:41.000000000', 'files': ['unit_tests/test_lib_charm_neutron_api_genericswitch.py', 'src/lib/charm/openstack/neutron_api_genericswitch.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/b96d492b15835e61584e75699839de0a879807b0', 'message': 'Introduce support for Queens release (WIP)\n\nChange-Id: Iba205b842ba40a59de3edf6c0600b2cc8f95cc11\n'}]",0,580010,b96d492b15835e61584e75699839de0a879807b0,13,3,3,7080,,,0,"Introduce support for Queens release (WIP)

Change-Id: Iba205b842ba40a59de3edf6c0600b2cc8f95cc11
",git fetch https://review.opendev.org/openstack/charm-neutron-api-genericswitch refs/changes/10/580010/2 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_lib_charm_neutron_api_genericswitch.py', 'src/lib/charm/openstack/neutron_api_genericswitch.py']",2,bfdb1a7e9a1a5690c98e8336fef1d1abaa0cd8e3,, class QueensNeutronAPIGenericSwitchCharm( NewtonNeutronAPIGenericSwitchCharm): release = 'queens',,33,0
openstack%2Fcharm-neutron-api-genericswitch~master~I3996082c19d4ff867ba43e64a155b610ba68af96,openstack/charm-neutron-api-genericswitch,master,I3996082c19d4ff867ba43e64a155b610ba68af96,Correctly upgrade package and refresh config,ABANDONED,2018-01-30 04:02:57.000000000,2019-01-07 11:51:22.000000000,,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-30 04:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/b2aa45a7610100597623aa2b543be531a1332daf', 'message': 'Correctly upgrade package and refresh config\n\nCurrently, when the charm is upgraded, the package and configs are kept at\ntheir old versions, despite users passing new resources.\n\nThis commit ensures the package and configs are modified when calling upgrade-\ncharm.\n\nChange-Id: I3996082c19d4ff867ba43e64a155b610ba68af96\n'}, {'number': 2, 'created': '2018-01-30 04:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/a4fdd9a85c602de3b907a2564ddb38755ed89b8d', 'message': 'Correctly upgrade package and refresh config\n\nCurrently, when the charm is upgraded, the package and configs are kept\nat their old versions, despite users passing new resources.\n\nThis commit ensures the package and configs are modified when calling\nupgrade-charm.\n\nChange-Id: I3996082c19d4ff867ba43e64a155b610ba68af96\n'}, {'number': 3, 'created': '2018-06-27 02:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/9b9de296924747ffb9bc9f79f41798a2a3da1d42', 'message': 'Correctly upgrade package and refresh config\n\nCurrently, when the charm is upgraded, the package and configs are kept\nat their old versions, despite users passing new resources.\n\nThis commit ensures the package and configs are modified when calling\nupgrade-charm.\n\nChange-Id: I3996082c19d4ff867ba43e64a155b610ba68af96\n'}, {'number': 4, 'created': '2018-06-27 02:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/6e0b7501f3410e6d21ffeb9bee00caf10666d83d', 'message': 'Correctly upgrade package and refresh config\n\nCurrently, when the charm is upgraded, the package and configs are kept\nat their old versions, despite users passing new resources.\n\nThis commit ensures the package and configs are modified when calling\nupgrade-charm.\n\nChange-Id: I3996082c19d4ff867ba43e64a155b610ba68af96\n'}, {'number': 5, 'created': '2018-08-06 23:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/6deb779988f28697cde011e13df3c8ef5366e748', 'message': 'Correctly upgrade package and refresh config\n\nCurrently, when the charm is upgraded, the package and configs are kept\nat their old versions, despite users passing new resources.\n\nThis commit ensures the package and configs are modified when calling\nupgrade-charm.\n\nChange-Id: I3996082c19d4ff867ba43e64a155b610ba68af96\n'}, {'number': 6, 'created': '2018-08-07 02:19:41.000000000', 'files': ['src/config.yaml', 'src/tox.ini', 'src/layer.yaml', 'src/lib/charm/openstack/neutron_api_genericswitch.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/2282f08476497f4664cd7ee0f76dbaf27eb37657', 'message': 'Correctly upgrade package and refresh config\n\nCurrently, when the charm is upgraded, the package and configs are kept\nat their old versions, despite users passing new resources.\n\nThis commit ensures the package and configs are modified when calling\nupgrade-charm.\n\nChange-Id: I3996082c19d4ff867ba43e64a155b610ba68af96\n'}]",0,539085,2282f08476497f4664cd7ee0f76dbaf27eb37657,17,4,6,7080,,,0,"Correctly upgrade package and refresh config

Currently, when the charm is upgraded, the package and configs are kept
at their old versions, despite users passing new resources.

This commit ensures the package and configs are modified when calling
upgrade-charm.

Change-Id: I3996082c19d4ff867ba43e64a155b610ba68af96
",git fetch https://review.opendev.org/openstack/charm-neutron-api-genericswitch refs/changes/85/539085/6 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/neutron_api_genericswitch.py'],1,b2aa45a7610100597623aa2b543be531a1332daf,, def upgrade_charm(self): self.install() super().upgrade_charm() ,,4,0
openstack%2Fcharm-neutron-api-genericswitch~master~I460ca063372948877cf55796135dfa64d6e9cece,openstack/charm-neutron-api-genericswitch,master,I460ca063372948877cf55796135dfa64d6e9cece,Remove unused files,ABANDONED,2018-07-04 01:03:30.000000000,2019-01-07 11:51:13.000000000,,"[{'_account_id': 7080}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-04 01:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/82cccf0f5bf28f8589161787201bde0258d4e673', 'message': 'Remove unused files\n\nChange-Id: I460ca063372948877cf55796135dfa64d6e9cece\n'}, {'number': 2, 'created': '2018-08-06 23:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/ac8e69b085f01f378c325133c65e7abfac6ae085', 'message': 'Remove unused files\n\nChange-Id: I460ca063372948877cf55796135dfa64d6e9cece\n'}, {'number': 3, 'created': '2018-08-07 02:19:41.000000000', 'files': ['src/files/qemu-hugefsdir', 'src/templates/ml2_conf.ini'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-genericswitch/commit/1561a1c7074ea4beadfec091e0f76f6db8561fd3', 'message': 'Remove unused files\n\nChange-Id: I460ca063372948877cf55796135dfa64d6e9cece\n'}]",0,580009,1561a1c7074ea4beadfec091e0f76f6db8561fd3,15,3,3,7080,,,0,"Remove unused files

Change-Id: I460ca063372948877cf55796135dfa64d6e9cece
",git fetch https://review.opendev.org/openstack/charm-neutron-api-genericswitch refs/changes/09/580009/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/files/qemu-hugefsdir', 'src/templates/ml2_conf.ini']",2,82cccf0f5bf28f8589161787201bde0258d4e673,,,"############################################################################### # [ WARNING ] # Configuration file maintained by Juju. Local changes may be overwritten. ############################################################################### # [ml2] type_drivers = {{ options.overlay_net_types }},local,flat,vlan tenant_network_types = {{ options.overlay_net_types }} mechanism_drivers = opendaylight [ml2_type_flat] # Provider nets only [ml2_type_vlan] # Provider nets only [ml2_type_gre] tunnel_id_ranges = 1:1000 [ml2_type_vxlan] vni_ranges = 1001:2000 [ml2_odl] username = {{ odl_controller.username }} password = {{ odl_controller.password }} url = http://{{ odl_controller.private_address }}:{{ odl_controller.port }}/controller/nb/v2/neutron [securitygroup] {% if options.security_groups -%} enable_security_group = True {% else -%} enable_security_group = False {% endif -%} ",0,49
openstack%2Fcharm-neutron-api~master~I39f9915301a88920e78ed839d57408fd2909cab0,openstack/charm-neutron-api,master,I39f9915301a88920e78ed839d57408fd2909cab0,Neutron-api checks shared-db before OS migration,ABANDONED,2018-08-08 10:11:57.000000000,2019-01-07 11:50:59.000000000,,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-08 10:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/5a49c3a11a3f1a0c55c2a1003263f9d998649238', 'message': 'Neutron-api checks shared-db before OS migration\n\nMigrating OpenStack versions without correct database set up for neutron-api may cause it to crash.\nTo avoid that, when OpenStack migration is demanded, the charm must wait for a shared-db to be available before moving data with neutron-db-manage command\n\nChange-Id: I39f9915301a88920e78ed839d57408fd2909cab0\nCloses-Bug: #1785839\n'}, {'number': 2, 'created': '2018-08-08 11:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/5d036832b9cd67a5d6410ba57cb6740e5458f4c9', 'message': 'Neutron-api checks shared-db before OS migration\n\nMigrating OpenStack versions without correct database set up for neutron-api may cause it to crash.\nTo avoid that, when OpenStack migration is demanded, the charm must wait for a shared-db to be available before moving data with neutron-db-manage command\n\nChange-Id: I39f9915301a88920e78ed839d57408fd2909cab0\nCloses-Bug: #1785839\n'}, {'number': 3, 'created': '2018-08-08 12:08:40.000000000', 'files': ['hooks/neutron_api_hooks.py', 'hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/ef46fb1b4cd4d06fbce067a5adf14e6a8d8a0bda', 'message': 'Neutron-api checks shared-db before OS migration\n\nMigrating OpenStack versions without correct database set up for\nneutron-api may cause it to crash.\nTo avoid that, when OpenStack migration is demanded, the charm must\nwait for a shared-db to be available before moving data with\nneutron-db-manage command\n\nChange-Id: I39f9915301a88920e78ed839d57408fd2909cab0\nCloses-Bug: #1785839\n'}]",0,589830,ef46fb1b4cd4d06fbce067a5adf14e6a8d8a0bda,10,3,3,28510,,,0,"Neutron-api checks shared-db before OS migration

Migrating OpenStack versions without correct database set up for
neutron-api may cause it to crash.
To avoid that, when OpenStack migration is demanded, the charm must
wait for a shared-db to be available before moving data with
neutron-db-manage command

Change-Id: I39f9915301a88920e78ed839d57408fd2909cab0
Closes-Bug: #1785839
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/30/589830/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/neutron_api_hooks.py', 'hooks/neutron_api_utils.py']",2,5a49c3a11a3f1a0c55c2a1003263f9d998649238,bug/1785839," if is_shared_db_available(): migrate_neutron_database(upgrade=True) else: log(""Database not ready, can't upgrade - deferring to shared-db relation"", level=DEBUG) def is_shared_db_available(use_current_context=False, db_rel=None): """"""Database relations are expected to provide a list of 'allowed' units to confirm that the database is ready for use by those units. If db relation has provided this information and local unit is a member, returns True otherwise False. """""" key = 'allowed_units' db_rels = ['shared-db'] if db_rel: db_rels = [db_rel] if use_current_context: if not any([relation_id() in relation_ids(r) for r in db_rels]): raise Exception(""use_current_context=True but not in one of %s "" ""rel hook contexts (currently in %s)."" % (', '.join(db_rels), relation_id())) allowed_units = relation_get(attribute=key) if allowed_units and local_unit() in allowed_units.split(): return True # We are in shared-db rel but don't yet have permissions log(""%s does not yet have db permissions"" % (local_unit()), level=DEBUG) return False else: for rel in db_rels: for rid in relation_ids(rel): for unit in related_units(rid): allowed_units = relation_get(rid=rid, unit=unit, attribute=key) if allowed_units and local_unit() in allowed_units.split(): return True return False # If neither relation has units then we are probably in sqlite mode so # return False as it is not a shared_db and fails during migration. return False", migrate_neutron_database(upgrade=True) ,62,3
openstack%2Fcharm-cinder~master~Iaf284700bc9ff9d31310c45a675b8db2c84ed904,openstack/charm-cinder,master,Iaf284700bc9ff9d31310c45a675b8db2c84ed904,ensure we only add the policy.json in queens+,ABANDONED,2018-07-30 11:31:39.000000000,2019-01-07 11:50:36.000000000,,"[{'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-30 11:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/d81f43704d3b585c16737b4475a655ba6fca5147', 'message': 'ensure we only add the policy.json in queens+\n\nChange-Id: Iaf284700bc9ff9d31310c45a675b8db2c84ed904\n'}, {'number': 2, 'created': '2018-07-30 11:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/a9bac3213502213b486e50257aab4fe5e89d9ce3', 'message': 'ensure we only add the policy.json in queens+\n\nChange-Id: Iaf284700bc9ff9d31310c45a675b8db2c84ed904\n'}, {'number': 3, 'created': '2018-07-30 15:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/60e69f9243fe344152ed04cfa6f34d9225f71649', 'message': 'ensure we only add the policy.json in queens+\n\nChange-Id: Iaf284700bc9ff9d31310c45a675b8db2c84ed904\n'}, {'number': 4, 'created': '2018-08-14 13:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/020bdf099d21084ad2a67de0e9ccafcd859ebae1', 'message': 'ensure we only add the policy.json in queens+\n\nThis is required because the unnderlyingn template\nfile is onnlny presentned in Queens and greater, leavinng\nprevious releases to throw exceptionsn whenn the template\nis not founnd.\n\nChange-Id: Iaf284700bc9ff9d31310c45a675b8db2c84ed904\n'}, {'number': 5, 'created': '2018-08-14 13:23:53.000000000', 'files': ['unit_tests/test_cinder_utils.py', 'hooks/cinder_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/b4981447853c8c333a84380ac34e4232be525025', 'message': 'ensure we only add the policy.json in queens+\n\nThis is required because the underlying template\nfile is only presented in Queens and greater, leaving\nprevious releases to throw exceptions when the template\nis not found.\n\nChange-Id: Iaf284700bc9ff9d31310c45a675b8db2c84ed904\n'}]",2,587007,b4981447853c8c333a84380ac34e4232be525025,23,5,5,20634,,,0,"ensure we only add the policy.json in queens+

This is required because the underlying template
file is only presented in Queens and greater, leaving
previous releases to throw exceptions when the template
is not found.

Change-Id: Iaf284700bc9ff9d31310c45a675b8db2c84ed904
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/07/587007/5 && git format-patch -1 --stdout FETCH_HEAD,['hooks/cinder_utils.py'],1,d81f43704d3b585c16737b4475a655ba6fca5147,fix-policy-json," cmp_release = CompareOpenStackReleases(release) if cmp_release >= 'queens': configs.register(CINDER_POLICY_JSON, [])"," (CINDER_POLICY_JSON, { 'contexts': [], 'services': ['cinder-api'] }),",4,4
openstack%2Fcharm-ceph-osd~master~Ic4d8617fb7977f5bc29817ce0c543f1a94104964,openstack/charm-ceph-osd,master,Ic4d8617fb7977f5bc29817ce0c543f1a94104964,Activate disk partition to deploy ceph-osd on it,ABANDONED,2017-12-08 12:42:54.000000000,2019-01-07 11:48:18.000000000,,"[{'_account_id': 935}, {'_account_id': 10068}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 27363}]","[{'number': 1, 'created': '2017-12-08 12:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/9fc682afc1843d2a732086b1c13c4b39e4a6d8bf', 'message': 'Activate disk partition to deploy ceph-osd on it\n\nChange-Id: Ic4d8617fb7977f5bc29817ce0c543f1a94104964\nSigned-off-by: KamalaVenaktesh <kamala.v@happiestminds.com>\n'}, {'number': 2, 'created': '2017-12-18 06:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/fe49d5ebc4c5a4bf4de66520ab61fda237c7e45f', 'message': 'Activate disk partition to deploy ceph-osd on it\n\nChange-Id: Ic4d8617fb7977f5bc29817ce0c543f1a94104964\nSigned-off-by: KamalaVenaktesh <kamala.v@happiestminds.com>\n'}, {'number': 3, 'created': '2017-12-18 06:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/bc8491f381ff21abaa35d867113f6ccb056cc35e', 'message': 'Activate disk partition to deploy ceph-osd on it\n\nChange-Id: Ic4d8617fb7977f5bc29817ce0c543f1a94104964\nSigned-off-by: KamalaVenaktesh <kamala.v@happiestminds.com>\n'}, {'number': 4, 'created': '2017-12-18 06:56:55.000000000', 'files': ['lib/ceph/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/49d4ff3b4d1f93d6541a04abb058cd870d4786dc', 'message': 'Activate disk partition to deploy ceph-osd on it\n\nChange-Id: Ic4d8617fb7977f5bc29817ce0c543f1a94104964\nSigned-off-by: KamalaVenaktesh <kamala.v@happiestminds.com>\n'}]",1,526670,49d4ff3b4d1f93d6541a04abb058cd870d4786dc,12,5,4,27363,,,0,"Activate disk partition to deploy ceph-osd on it

Change-Id: Ic4d8617fb7977f5bc29817ce0c543f1a94104964
Signed-off-by: KamalaVenaktesh <kamala.v@happiestminds.com>
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/70/526670/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceph/utils.py'],1,9fc682afc1843d2a732086b1c13c4b39e4a6d8bf,activate_disk_partition," #Command to activate the partitions subprocess.check_call(['ceph-disk', 'activate', dev])",,2,0
openstack%2Fcharm-ceph-osd~master~I5d10cf7b2a9b63951ff034a0f6bf46a21b6ac6f0,openstack/charm-ceph-osd,master,I5d10cf7b2a9b63951ff034a0f6bf46a21b6ac6f0,Do not create OSDs on directories if the directory doesn't exist,ABANDONED,2016-08-18 22:01:04.000000000,2019-01-07 11:48:00.000000000,,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20812}]","[{'number': 1, 'created': '2016-08-18 22:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/656f22f545d4dd881c9a546aa86614c44ed1abe2', 'message': ""Do not create OSDs on directories if the directory doesn't exist\n\nBefore creating an OSD out of a directory, need to ensure that\nthe path exists. If the path doesn't exist, the code will create\nthe directory and it may be on an unintended partition (e.g. the\nsame partition as /).\n\nThis prevents the OSD from being created if the path doesn't\nexist.\n\nChange-Id: I5d10cf7b2a9b63951ff034a0f6bf46a21b6ac6f0\nCloses-Bug: #1590945\n""}, {'number': 2, 'created': '2016-08-18 22:14:56.000000000', 'files': ['lib/ceph/__init__.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/f7a1dfdc58daba558cf186eb147a8f78f90d2d92', 'message': ""Do not create OSDs on directories if the directory doesn't exist\n\nBefore creating an OSD out of a directory, need to ensure that\nthe path exists. If the path doesn't exist, the code will create\nthe directory and it may be on an unintended partition (e.g. the\nsame partition as /).\n\nThis prevents the OSD from being created if the path doesn't\nexist.\n\nChange-Id: I5d10cf7b2a9b63951ff034a0f6bf46a21b6ac6f0\nCloses-Bug: #1590945\n""}]",2,357510,f7a1dfdc58daba558cf186eb147a8f78f90d2d92,13,3,2,8992,,,0,"Do not create OSDs on directories if the directory doesn't exist

Before creating an OSD out of a directory, need to ensure that
the path exists. If the path doesn't exist, the code will create
the directory and it may be on an unintended partition (e.g. the
same partition as /).

This prevents the OSD from being created if the path doesn't
exist.

Change-Id: I5d10cf7b2a9b63951ff034a0f6bf46a21b6ac6f0
Closes-Bug: #1590945
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/10/357510/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceph/__init__.py'],1,656f22f545d4dd881c9a546aa86614c44ed1abe2,bug/1590945," # Don't create the OSD if the path doesn't exist, this may create # a directory on a partition in which it was not intended. if not os.path.exists(path): log('Directory does not exist, bailing for safety reasons.', level=INFO) return ",,7,0
openstack%2Fcharm-specs~master~I73f2baedf34fb5a83d3a736803e7e033fd0d6c97,openstack/charm-specs,master,I73f2baedf34fb5a83d3a736803e7e033fd0d6c97,Switch to single relation between API charm and lb,ABANDONED,2017-09-28 17:46:49.000000000,2019-01-07 11:47:10.000000000,,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2017-09-28 17:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/79c89eb2b94cb9d7fad714bfec23cd69fd01bb21', 'message': 'Switch to single relation between API charm and lb\n\nThe charm spec for OpenStack Endpoint Load Balancer currently\nspecifies three relations between an API charm and the load balancer\n, one for each endpoint type. This merge proposal moves the spec to\nuse a single relation and pushes the logic and updates the interface\nto support sending data about multiple relations.\n\nThe is mp is really a place for discussion and I think it requires\na PTL +2 to land.\n\nChange-Id: I73f2baedf34fb5a83d3a736803e7e033fd0d6c97\n'}, {'number': 2, 'created': '2017-09-28 18:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/ff9f5747d93b65c818e8276716cf165dca8ffed0', 'message': 'Switch to single relation between API charm and lb\n\nThe charm spec for OpenStack Endpoint Load Balancer currently\nspecifies three relations between an API charm and the load balancer\n, one for each endpoint type. This merge proposal moves the spec to\nuse a single relation and pushes the logic and updates the interface\nto support sending data about multiple relations.\n\nThe is mp is really a place for discussion and I think it requires\na PTL +2 to land.\n\nChange-Id: I73f2baedf34fb5a83d3a736803e7e033fd0d6c97\n'}, {'number': 3, 'created': '2017-09-29 17:36:22.000000000', 'files': ['specs/queens/approved/openstack-load-balancer.rst'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/d3c9a196acb7048bc175c96bb5dc71186f707015', 'message': 'Switch to single relation between API charm and lb\n\nThe charm spec for OpenStack Endpoint Load Balancer currently\nspecifies three relations between an API charm and the load balancer\n, one for each endpoint type. This merge proposal moves the spec to\nuse a single relation and pushes the logic and updates the interface\nto support sending data about multiple relations.\n\nThe is mp is really a place for discussion and I think it requires\na PTL +2 to land.\n\nChange-Id: I73f2baedf34fb5a83d3a736803e7e033fd0d6c97\n'}]",6,508256,d3c9a196acb7048bc175c96bb5dc71186f707015,11,5,3,12549,,,0,"Switch to single relation between API charm and lb

The charm spec for OpenStack Endpoint Load Balancer currently
specifies three relations between an API charm and the load balancer
, one for each endpoint type. This merge proposal moves the spec to
use a single relation and pushes the logic and updates the interface
to support sending data about multiple relations.

The is mp is really a place for discussion and I think it requires
a PTL +2 to land.

Change-Id: I73f2baedf34fb5a83d3a736803e7e033fd0d6c97
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/56/508256/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/approved/openstack-load-balancer.rst'],1,79c89eb2b94cb9d7fad714bfec23cd69fd01bb21,feature/ch-lb-single-relaton,"Loadbalancer charm config ------------------------- The new loadbalancer charm will have a 'supported-endtypes' options which lists which endpoints this application will support. To deploy seperate loandbalancers for each endtype mulitple instances of the application can be deployed and then the supported-endtypes set accordingly for each instance. .. code-block:: bash juju deploy openstack-loadbalancer openstack-lb-admin juju deploy openstack-loadbalancer openstack-lb-internal juju deploy openstack-loadbalancer openstack-lb-public juju config openstack-lb-admin supported-endtypes='admin' juju config openstack-lb-internal supported-endtypes='internal' juju config openstack-lb-public supported-endtypes='public' This interface allows the loadbalancer to inform the charm which endpoint types the load balancer supports. Example - loadbalancer (providing admin and internal endpoints): .. code-block:: yaml endpoint-types: admin,internal The backend charm hosting API endpoints can now inform the OpenStack loadbalancer which services it is hosting for each of the endpoints that the loadbalancer supports. For each endpoint the API charm provides the IP address and port frontend API requests should be sent to on the backend unit. It also allows the backend charm to inform the loadbalancer which frontend port should be used for each service. - admin: - service-type: network - frontend-port: 9696 - backend-port: 9689 - backend-ip: 10.10.10.1 - check-type: http - internal: - service-type: network - frontend-port: 9696 - backend-port: 9689 - backend-ip: 10.10.10.1 - check-type: http - admin: - service-type: nova frontend-port: 8774 backend-port: 8764 backend-ip: 10.10.10.2 check-type: http - service-type: nova-placement frontend-port: 8778 backend-port: 8768 backend-ip: 10.10.10.2 check-type: http - internal: - service-type: nova frontend-port: 8774 backend-port: 8764 backend-ip: 10.10.10.2 check-type: http - service-type: nova-placement frontend-port: 8778 backend-port: 8768 backend-ip: 10.10.10.2 check-type: http - admin: - service-type: nova frontend-ip: 98.34.12.1 frontend-port: 8774 - service-type: nova-placement frontend-ip: 98.34.12.1 frontend-port: 8778 - internal: - service-type: nova frontend-ip: 98.34.12.1 frontend-port: 8774 - service-type: nova-placement frontend-ip: 98.34.12.1 frontend-port: 8778charm would provide a single instances of this interface type: backend: The API charm can be related to multiple loadbalancers which support different endpoint types: .. code-block:: bash juju add-relation neutron-api openstack-lb-admin juju add-relation neutron-api openstack-lb-public juju add-relation neutron-api openstack-lb-internal ",This interface allows a backend charm hosting API endpoints to inform the OpenStack loadbalancer which services it's hosting and on which IP address and port frontend API requests should be sent to on the backend unit. It also allows the backend charm to inform the loadbalancer which frontend port should be used for each service. - service-type: network frontend-port: 9696 backend-port: 9689 backend-ip: 10.10.10.1 check-type: http - service-type: nova frontend-port: 8774 backend-port: 8764 backend-ip: 10.10.10.2 check-type: http - service-type: nova-placement frontend-port: 8778 backend-port: 8768 backend-ip: 10.10.10.2 check-type: http - service-type: nova frontend-ip: 98.34.12.1 frontend-port: 8774 - service-type: nova-placement frontend-ip: 98.34.12.1 frontend-port: 8778charm would provide three instances of this interface type: public-backend: admin-backend: interface: openstack-api-endpoints internal-backend: interface: openstack-api-endpoints,93,32
openstack%2Fcharm-neutron-openvswitch~master~I7658e25611bc32d55d4ad70fee11222d185344ca,openstack/charm-neutron-openvswitch,master,I7658e25611bc32d55d4ad70fee11222d185344ca,Adding netflow support,ABANDONED,2018-01-17 08:33:18.000000000,2019-01-07 11:46:24.000000000,,"[{'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-17 08:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/45ab088da1df4b39f017eb6ba1be37f83b159718', 'message': ""Ran tox unit tests.  It is failing only because I don't have a valid ovs-bridge on this system\nI have tested this on an active cloud with juju 2.3.1 and it function as expected.\n\nChange-Id: I7658e25611bc32d55d4ad70fee11222d185344ca\n""}, {'number': 2, 'created': '2018-01-17 10:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/9225b75f1ff27068885ad5480c7aaa0d38184e54', 'message': 'Adding netflow support for br-int\nAsk for the netflow target and then apply the netflow target to the\nappropriate bridge (br-int for all traffic).\n\nChange-Id: I7658e25611bc32d55d4ad70fee11222d185344ca\n'}, {'number': 3, 'created': '2018-01-17 12:37:46.000000000', 'files': ['hooks/neutron_ovs_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/bf474fe945463646c092edb0dfe87820b45343f7', 'message': ""Adding netflow support\n\nAsk for the netflow target and then apply the netflow target to all\nbridges listed in 'data-port' (if any) as well as br-int\n\nChange-Id: I7658e25611bc32d55d4ad70fee11222d185344ca\n""}]",1,534678,bf474fe945463646c092edb0dfe87820b45343f7,8,2,3,27676,,,0,"Adding netflow support

Ask for the netflow target and then apply the netflow target to all
bridges listed in 'data-port' (if any) as well as br-int

Change-Id: I7658e25611bc32d55d4ad70fee11222d185344ca
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/78/534678/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/neutron_ovs_utils.py'],1,45ab088da1df4b39f017eb6ba1be37f83b159718,enable-netflow,,,3,0
openstack%2Fcharm-gnocchi~master~I120a1c58f27ce0a794c560f20b03d8e54fd06766,openstack/charm-gnocchi,master,I120a1c58f27ce0a794c560f20b03d8e54fd06766,"modify spell to easy read change ""gnocchi"" word spell",ABANDONED,2018-01-22 02:21:49.000000000,2019-01-07 11:46:06.000000000,,"[{'_account_id': 21690}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-22 02:21:49.000000000', 'files': ['src/lib/charm/openstack/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/77ef53c06ad76d9271d0082bd127c854c09fac97', 'message': 'modify spell to easy read\nchange ""gnocchi"" word spell\n\nChange-Id: I120a1c58f27ce0a794c560f20b03d8e54fd06766\n'}]",0,536188,77ef53c06ad76d9271d0082bd127c854c09fac97,4,2,1,27382,,,0,"modify spell to easy read
change ""gnocchi"" word spell

Change-Id: I120a1c58f27ce0a794c560f20b03d8e54fd06766
",git fetch https://review.opendev.org/openstack/charm-gnocchi refs/changes/88/536188/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/gnocchi.py'],1,77ef53c06ad76d9271d0082bd127c854c09fac97,easy_read,class GnocchiCharmBase(charms_openstack.charm.HAOpenStackCharm):class GnocchiCharm(GnocchiCharmBase):,class GnochiCharmBase(charms_openstack.charm.HAOpenStackCharm):class GnocchiCharm(GnochiCharmBase):,2,2
openstack%2Fcharm-rabbitmq-server~master~I75cf162e141342de2bd9d2d59b5410d56413cf6d,openstack/charm-rabbitmq-server,master,I75cf162e141342de2bd9d2d59b5410d56413cf6d,Added NRPE monitoring for cluster partition state,ABANDONED,2018-01-26 18:19:21.000000000,2019-01-07 11:45:23.000000000,,"[{'_account_id': 10068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-26 18:19:21.000000000', 'files': ['scripts/check_rabbitmq_cluster.py', 'scripts/rabbitmq_cluster_state.sh', 'hooks/rabbitmq_server_relations.py'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/54832f366c6ba4b368d37368d87cfc7383d23d5d', 'message': 'Added NRPE monitoring for cluster partition state\n\nThe current RabbitMQ charm does not have built-in monitoring for\nthe RabbitMQ cluster partition state.\n\nThis feature was requested by our operations team, but also in\nhttps://bugs.launchpad.net/charm-rabbitmq-server/+bug/1548679\n\nThe implementation in this merge request is very similar to the\nexisting queue length monitoring. The cluster state is retrieved by\nrunning plain rabbitmqctl from cron as root, output is saved into a\ndata file that is checked by the nrpe plugin script.\n\nAnother option could be to use the Management API, but in our\nenvironment it is not enabled.\n\nChange-Id: I75cf162e141342de2bd9d2d59b5410d56413cf6d\nCloses-Bug: 1548679\n'}]",0,538319,54832f366c6ba4b368d37368d87cfc7383d23d5d,4,2,1,27734,,,0,"Added NRPE monitoring for cluster partition state

The current RabbitMQ charm does not have built-in monitoring for
the RabbitMQ cluster partition state.

This feature was requested by our operations team, but also in
https://bugs.launchpad.net/charm-rabbitmq-server/+bug/1548679

The implementation in this merge request is very similar to the
existing queue length monitoring. The cluster state is retrieved by
running plain rabbitmqctl from cron as root, output is saved into a
data file that is checked by the nrpe plugin script.

Another option could be to use the Management API, but in our
environment it is not enabled.

Change-Id: I75cf162e141342de2bd9d2d59b5410d56413cf6d
Closes-Bug: 1548679
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/19/538319/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/check_rabbitmq_cluster.py', 'scripts/rabbitmq_cluster_state.sh', 'hooks/rabbitmq_server_relations.py']",3,54832f366c6ba4b368d37368d87cfc7383d23d5d,bug/1548679,"CLUSTATE_CRONFILE = '/etc/cron.d/rabbitmq-cluster-state' CLUSTATE_DATAFILE = os.path.join(RABBIT_DIR, 'data', '{}_cluster_state.dat' ''.format(rabbit.get_unit_hostname())) rsync(os.path.join(os.getenv('CHARM_DIR'), 'scripts', 'check_rabbitmq_cluster.py'), os.path.join(NAGIOS_PLUGINS, 'check_rabbitmq_cluster.py')) script = os.path.join(SCRIPTS_DIR, 'rabbitmq_cluster_state.sh') cronjob = CRONJOB_CMD.format(schedule=config('stats_cron_schedule'), timeout=config('cron-timeout'), command=script) rsync(os.path.join(charm_dir(), 'scripts', 'rabbitmq_cluster_state.sh'), script) write_file(CLUSTATE_CRONFILE, cronjob) else: if os.path.isfile(STATS_CRONFILE): os.remove(STATS_CRONFILE) if os.path.isfile(CLUSTATE_CRONFILE): os.remove(CLUSTATE_CRONFILE) if config('stats_cron_schedule'): nrpe_compat.add_check( shortname=rabbit.RABBIT_USER + '_cluster', description='Check RabbitMQ cluster state', check_cmd='{}/check_rabbitmq_cluster.py {}'.format( NAGIOS_PLUGINS, CLUSTATE_DATAFILE) )", elif os.path.isfile(STATS_CRONFILE): os.remove(STATS_CRONFILE),87,2
openstack%2Fcharm-ceph-osd~master~I2450a427520b6713abc457374421c94bb7f16078,openstack/charm-ceph-osd,master,I2450a427520b6713abc457374421c94bb7f16078,"Add osd-shared, create osd on mounted devices",ABANDONED,2018-01-16 02:04:53.000000000,2019-01-07 11:44:55.000000000,,"[{'_account_id': 20634}, {'_account_id': 22348}, {'_account_id': 24904}]","[{'number': 1, 'created': '2018-01-16 02:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/4717e2f1cc2d382ddc10561356684f734ecd8868', 'message': ""Add osd-shared, create osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions. No changes are made to hooks, the utils library is\nupdated to handle partitions where it previously bailed.\n* Build ceph-disk flags in function to re-use current logic in\nosdize_dev\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done via charmhelpers instead of using the ceph-disk option\n\nCloses-Bug: #1743278\nCloses-Bug: #1743280\nCloses-Bug: #1743282\n\nChange-Id: I2450a427520b6713abc457374421c94bb7f16078\n""}, {'number': 2, 'created': '2018-01-16 14:36:49.000000000', 'files': ['config.yaml', 'lib/ceph/utils.py', 'files/ceph/setup_osd.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/9eeb960ad2d37acc035ea2aeb9b9624f70dbeb16', 'message': ""Add osd-shared, create osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions. No changes are made to hooks, the utils library is\nupdated to handle partitions where it previously bailed.\n* Build ceph-disk flags in function to re-use current logic in\nosdize_dev\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done via charmhelpers instead of using the ceph-disk option\n\nCloses-Bug: #1743278\nCloses-Bug: #1743280\nCloses-Bug: #1743282\n\nChange-Id: I2450a427520b6713abc457374421c94bb7f16078\n""}]",0,533838,9eeb960ad2d37acc035ea2aeb9b9624f70dbeb16,7,3,2,24904,,,0,"Add osd-shared, create osd on mounted devices

Addes logic to create and activate partitions on devices that have
mounted partitions. No changes are made to hooks, the utils library is
updated to handle partitions where it previously bailed.
* Build ceph-disk flags in function to re-use current logic in
osdize_dev
* Shared osd's implement all options/logic of the osdize_dev
 * Checks for in use
 * Handles the format osd option
 * Works with dmcrypt
 * Will not format/zap non-ceph partitions

This includes two drive-by fixes for bugs which it didn't make since to
break out. Both changes are in code which was altered in this
patch and not closing them would require implementing the bug to avoid
closing it.
* Partitions are wiped before zapping
* Zap is done via charmhelpers instead of using the ceph-disk option

Closes-Bug: #1743278
Closes-Bug: #1743280
Closes-Bug: #1743282

Change-Id: I2450a427520b6713abc457374421c94bb7f16078
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/38/533838/2 && git format-patch -1 --stdout FETCH_HEAD,"['config.yaml', 'lib/ceph/utils.py', 'files/ceph/setup_osd.py']",3,4717e2f1cc2d382ddc10561356684f734ecd8868,bug/1743278,"#!/usr/bin/env python2 from __future__ import print_function import sys import copy from ceph_disk import main as ceph_disk def setup_data(args, factory): # Setup data partition factory.data.set_variables() factory.data.device = ceph_disk.Device.factory(args.data, args) partition_num = factory.data.device.create_partition(uuid=args.osd_uuid, name='data', size=factory.data.get_space_size()) factory.data.partition = factory.data.device.get_partition(partition_num) def create_partitions(argv): args = ceph_disk.parse_args(argv) ceph_disk.setup_logging(args.verbose, args.log_stdout) ceph_disk.setup_statedir(args.statedir) ceph_disk.setup_sysconfdir(args.sysconfdir) factory = ceph_disk.Prepare(args).factory(args) if args.dmcrypt: # Setup lockbox partition lockbox = ceph_disk.Lockbox(args) device_args = copy.copy(args) device_args.dmcrypt = False lockbox.device = ceph_disk.Device.factory(args.lockbox, device_args) partition_num = lockbox.device.create_partition(uuid=args.lockbox_uuid, name='lockbox', size=10) lockbox.partition = lockbox.device.get_partition(partition_num) factory.lockbox = lockbox factory.lockbox.populate() # Bluestore if args.bluestore: setup_data(args, factory) populate_list = [] # Setup block if args.block == args.data: args.data = 'dummy' factory.block.prepare() args.data = args.block else: factory.block.prepare() populate_list.append(factory.block) # Setup block.db if getattr(args, 'block.db'): if getattr(args, 'block.db') == args.data: args.data = 'dummy' factory.blockdb.prepare() args.data = getattr(args, 'block.db') else: factory.blockdb.prepare() populate_list.append(factory.blockdb) # Setup block.wal if getattr(args, 'block.wal'): if getattr(args, 'block.wal') == args.data: args.data = 'dummy' factory.blockwal.prepare() args.data = getattr(args, 'block.wal') else: factory.blockwal.prepare() populate_list.append(factory.blockwal) # Populate factory.data.populate_data_path_device(*populate_list) # Filestore else: # Setup journal if args.journal == args.data: args.data = 'dummy' factory.journal.prepare() args.data = args.journal else: factory.journal.prepare() setup_data(args, factory) # Populate data factory.data.populate_data_path_device(factory.journal) if __name__ == '__main__': argv = sys.argv[1:] create_partitions(argv) ",,252,45
openstack%2Fcharm-guide~master~I76c43dd231d1b0d7a7fbd0eed0500287c93cab75,openstack/charm-guide,master,I76c43dd231d1b0d7a7fbd0eed0500287c93cab75,add reactive charm testing instructions,ABANDONED,2018-02-05 07:49:09.000000000,2019-01-07 11:44:45.000000000,,"[{'_account_id': 935}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-02-05 07:49:09.000000000', 'files': ['doc/source/testing.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/10623054e4b252aa399510b7fe9fad4b9c407033', 'message': 'add reactive charm testing instructions\n\nCurrently the guide does not mention how to run functional tests for\nreactive charms. It only takes one deployment and looking at a log to\nfigure out what is wrong with running tox -e func27 from an unbuilt\nreactive charm directory, however, it is good to have this mentioned in\nthe guide for unexperienced charm developers.\n\nChange-Id: I76c43dd231d1b0d7a7fbd0eed0500287c93cab75\n'}]",1,540748,10623054e4b252aa399510b7fe9fad4b9c407033,4,3,1,24824,,,0,"add reactive charm testing instructions

Currently the guide does not mention how to run functional tests for
reactive charms. It only takes one deployment and looking at a log to
figure out what is wrong with running tox -e func27 from an unbuilt
reactive charm directory, however, it is good to have this mentioned in
the guide for unexperienced charm developers.

Change-Id: I76c43dd231d1b0d7a7fbd0eed0500287c93cab75
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/48/540748/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/testing.rst'],1,10623054e4b252aa399510b7fe9fad4b9c407033,,"Reactive OpenStack Charms ~~~~~~ In order to test a reactive charm you need to build it, therefore, running .. code:: bash tox -e func27 in an unbuilt charm directory is not the right way. This is at least due to the fact that hook files will not be generated and the actual charm code will not be executed. The right way to do it for reactive charms is: .. code:: bash tox -e build cd build/builds/<charm-name-as-in-metadata-yaml> tox -e func27",,20,0
openstack%2Fcharm-keystone~master~I4b82ce2411500e41531a5104bd6853dda62fa3d6,openstack/charm-keystone,master,I4b82ce2411500e41531a5104bd6853dda62fa3d6,add support for policy drop-ins via charm config,ABANDONED,2018-01-07 18:39:38.000000000,2019-01-07 11:44:22.000000000,,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 24824}]","[{'number': 1, 'created': '2018-01-07 18:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/3dc4cb992d13db8f3132cdb5147b1ff096c76294', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n\nDepends on this charm-helpers change:\nhttps://github.com/juju/charm-helpers/pull/84\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 2, 'created': '2018-01-08 21:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/a2c9ee8c998df7ee62a3eabb9fa7d964325d01b9', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nDepends on the following charm-helpers changes for rendering templates\nfrom a string and creating a policy_dir:\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 3, 'created': '2018-01-22 20:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/bddbb614d9dc29b8c4d2b57725676c21f4968ec7', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nDepends on the following charm-helpers changes for rendering templates\nfrom a string and creating a policy_dir:\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 4, 'created': '2018-01-22 20:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/fd966afb41efb407f3e34370cf7f692900a3217a', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nPulls in charm-helpers changes needed for rendering templates from\nstrings and EnsureDirContext to make sure a dir exists before a config\nis rendered.\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 5, 'created': '2018-01-23 22:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/df1288efb3af348e4ccc90765962fa49920b526c', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nPulls in charm-helpers changes needed for rendering templates from\nstrings and EnsureDirContext to make sure a dir exists before a config\nis rendered.\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 6, 'created': '2018-01-24 14:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/4dfe614fbe2654acac105ca4406abf0b8411c4a4', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nPulls in charm-helpers changes needed for rendering templates from\nstrings and EnsureDirContext to make sure a dir exists before a config\nis rendered.\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 7, 'created': '2018-01-28 16:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/8cd4ff79ce326a2e563b47be4279c04541991912', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nPulls in charm-helpers changes needed for rendering templates from\nstrings and EnsureDirContext to make sure a dir exists before a config\nis rendered.\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nNOTE: oslo.policy versions older than 1.25.0 do not handle empty drop-in\nfiles properly, therefore, to clear policy customizations an empty dict\nshould be used as a content instead of an empty string for this option.\nLikewise, an empty dict is used as a default value for this config\noption.\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}, {'number': 8, 'created': '2018-01-29 16:49:59.000000000', 'files': ['charmhelpers/core/hookenv.py', 'hooks/keystone_utils.py', 'config.yaml', 'hooks/keystone_hooks.py', 'tests/charmhelpers/core/hookenv.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_keystone_contexts.py', 'unit_tests/test_keystone_utils.py', 'unit_tests/test_actions.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/templating.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/0c683cfb86167fc0940f5288c30136a5a25c3a33', 'message': ""add support for policy drop-ins via charm config\n\n* oslo.policy allows usage of policy_dirs option (policy.d directory\nunder config_dir of a service by default);\n* by default policy files (yaml or json) are processed and changes from\nthem override changes in a default policy_file (policy.json);\n* policy can potentially come from a subordinate charm, therefore, a\nservice-specific file name is used for a policy drop-in file;\n* file extensions are not used as file contents are interpreted in\noslo.policy regardless of an extension used and any format can be used\nin a config option (doesn't depend on policy.json being json)\n* extra-policy config option can accept a jinja2 template and it is\npossible to use variables available in the keystone context to have an\nability to reference admin_role, admin_domain_id, service_tenant_id etc.\n\nPulls in charm-helpers changes needed for rendering templates from\nstrings and EnsureDirContext to make sure a dir exists before a config\nis rendered.\nhttps://github.com/juju/charm-helpers/pull/87 (from_string rendering)\nhttps://github.com/juju/charm-helpers/pull/88 (policy dir)\n\nNOTE: oslo.policy versions older than 1.25.0 do not handle empty drop-in\nfiles properly, therefore, to clear policy customizations an empty dict\nshould be used as a content instead of an empty string for this option.\nLikewise, an empty dict is used as a default value for this config\noption.\n\nChange-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6\nCloses-Bug: #1741723\n""}]",0,531614,0c683cfb86167fc0940f5288c30136a5a25c3a33,25,6,8,24824,,,0,"add support for policy drop-ins via charm config

* oslo.policy allows usage of policy_dirs option (policy.d directory
under config_dir of a service by default);
* by default policy files (yaml or json) are processed and changes from
them override changes in a default policy_file (policy.json);
* policy can potentially come from a subordinate charm, therefore, a
service-specific file name is used for a policy drop-in file;
* file extensions are not used as file contents are interpreted in
oslo.policy regardless of an extension used and any format can be used
in a config option (doesn't depend on policy.json being json)
* extra-policy config option can accept a jinja2 template and it is
possible to use variables available in the keystone context to have an
ability to reference admin_role, admin_domain_id, service_tenant_id etc.

Pulls in charm-helpers changes needed for rendering templates from
strings and EnsureDirContext to make sure a dir exists before a config
is rendered.
https://github.com/juju/charm-helpers/pull/87 (from_string rendering)
https://github.com/juju/charm-helpers/pull/88 (policy dir)

NOTE: oslo.policy versions older than 1.25.0 do not handle empty drop-in
files properly, therefore, to clear policy customizations an empty dict
should be used as a content instead of an empty string for this option.
Likewise, an empty dict is used as a default value for this config
option.

Change-Id: I4b82ce2411500e41531a5104bd6853dda62fa3d6
Closes-Bug: #1741723
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/14/531614/8 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/keystone_utils.py', 'config.yaml']",2,3dc4cb992d13db8f3132cdb5147b1ff096c76294,fe-extra-policy," extra-policy: type: string default: ""{}"" description: | JSON or YAML policy to be used in a drop-in policy file directory. oslo.policy uses a default policy.d directory under a config directory of a service which is searched for additional files to augment a default policy file supplied by a charm. Regardless of the original policy file format, this file can contain YAML or JSON-formatted policy. Old policy is not discarded so if default rules need to be overwritten this should be done explicitly in this config option.",,24,0
openstack%2Fcharm-neutron-openvswitch~master~Ic34d9384f007e4b57a9e2d208b91c3d40932c377,openstack/charm-neutron-openvswitch,master,Ic34d9384f007e4b57a9e2d208b91c3d40932c377,Expose ovs-vsctl-timeout,ABANDONED,2018-01-03 08:46:51.000000000,2019-01-07 11:43:08.000000000,,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-03 08:46:51.000000000', 'files': ['unit_tests/test_neutron_ovs_context.py', 'templates/mitaka/openvswitch_agent.ini', 'hooks/neutron_ovs_context.py', 'tests/basic_deployment.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/91fdc1248ff19fd715522c99a81db3e47767e53f', 'message': 'Expose ovs-vsctl-timeout\n\nExpose a new config option ovs-vsctl-timeout which specifies the\ntimeout in seconds for ovs-vsctl commands.\n\nChange-Id: Ic34d9384f007e4b57a9e2d208b91c3d40932c377\nCloses-Bug: #1738123\n'}]",1,530867,91fdc1248ff19fd715522c99a81db3e47767e53f,7,4,1,12549,,,0,"Expose ovs-vsctl-timeout

Expose a new config option ovs-vsctl-timeout which specifies the
timeout in seconds for ovs-vsctl commands.

Change-Id: Ic34d9384f007e4b57a9e2d208b91c3d40932c377
Closes-Bug: #1738123
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/67/530867/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_neutron_ovs_context.py', 'templates/mitaka/openvswitch_agent.ini', 'hooks/neutron_ovs_context.py', 'tests/basic_deployment.py', 'config.yaml']",5,91fdc1248ff19fd715522c99a81db3e47767e53f,bug/1738123, ovs-vsctl-timeout: type: int default: 10 description: | Timeout in seconds for ovs-vsctl commands.,,39,0
openstack%2Fmonasca-analytics~master~Ia37563c5b213d96f82f3361f33df135fcf5ad41c,openstack/monasca-analytics,master,Ia37563c5b213d96f82f3361f33df135fcf5ad41c,Update devstack plugin,MERGED,2018-11-09 14:16:27.000000000,2019-01-07 11:43:03.000000000,2019-01-07 11:43:03.000000000,"[{'_account_id': 12193}, {'_account_id': 14162}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-09 14:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/69d74f88dcdc5d50062b2cca951ef22e3582d119', 'message': 'Update devstack pulgin\n\nCurrently, monasca-analytics service runs automatically\nafter devstack/stack.sh.\nBut, that service continues to run ""Alert Fatigue Management"" example\nusing Markov Chain recipe, and it is not expected behavior.\n\nThis patch remove unnecessary code and files.\n\nChange-Id: Ia37563c5b213d96f82f3361f33df135fcf5ad41c\n'}, {'number': 2, 'created': '2018-12-12 12:03:20.000000000', 'files': ['devstack/files/monasca-analytics/logging.json', 'devstack/files/maven/settings.xml', 'devstack/plugin.sh', 'devstack/files/monasca-analytics/markov_source_config.json', 'devstack/files/monasca-analytics/monasca_analytics_init.conf', 'devstack/files/monasca-analytics/monasca-analytics.service', 'devstack/files/monasca-analytics/start-monasca-analytics.sh'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/8707a01ab10f6ad72c0ee96c3f0a2b15f481e5e7', 'message': 'Update devstack plugin\n\n* Current\n  After devstack/stack.sh is completed, the monasca-analytics service \n  starts automatically. This service runs ""Alert Fatigue Management"" \n  example using Markov chain recipe.\n\n* Issue\n  This example keep running until kill the process. Therefore, user can\n  not manually run the new example process after creating devstack env.\n\n* Solve\n  Do not automatically start ""Alert Fatigue Management"" example. And,\n  remove the monasca-analytics service which is no longer necessary.\n\n\nChange-Id: Ia37563c5b213d96f82f3361f33df135fcf5ad41c\n'}]",1,616949,8707a01ab10f6ad72c0ee96c3f0a2b15f481e5e7,12,3,2,14162,,,0,"Update devstack plugin

* Current
  After devstack/stack.sh is completed, the monasca-analytics service 
  starts automatically. This service runs ""Alert Fatigue Management"" 
  example using Markov chain recipe.

* Issue
  This example keep running until kill the process. Therefore, user can
  not manually run the new example process after creating devstack env.

* Solve
  Do not automatically start ""Alert Fatigue Management"" example. And,
  remove the monasca-analytics service which is no longer necessary.


Change-Id: Ia37563c5b213d96f82f3361f33df135fcf5ad41c
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/49/616949/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/files/monasca-analytics/logging.json', 'devstack/files/maven/settings.xml', 'devstack/plugin.sh', 'devstack/files/monasca-analytics/markov_source_config.json', 'devstack/files/monasca-analytics/monasca-analytics.service', 'devstack/files/monasca-analytics/monasca_analytics_init.conf', 'devstack/files/monasca-analytics/start-monasca-analytics.sh']",7,69d74f88dcdc5d50062b2cca951ef22e3582d119,devstack/plugin,,"#!/usr/bin/env bash # # Copyright 2016 FUJITSU LIMITED # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # start-stop-daemon -c monasca-analytics:monasca-analytics -m\ --pidfile /var/run/monasca/analytics/analytics.pid \ --start --exec python /opt/stack/monasca-analytics/run.py -p /opt/spark/spark-1.6.1/ -c /etc/monasca/analytics/markov_source_config.json -l /etc/monasca/analytics/logging.json ",2,257
openstack%2Fcharm-neutron-gateway~master~I50f29fe932e39b1d35a3ccbfd82aee167d019b27,openstack/charm-neutron-gateway,master,I50f29fe932e39b1d35a3ccbfd82aee167d019b27,Expose ovs-vsctl-timeout,ABANDONED,2018-01-02 21:19:31.000000000,2019-01-07 11:42:18.000000000,,"[{'_account_id': 935}, {'_account_id': 8992}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-02 21:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/fd0ccd5a8a7615087b7151ebc2b96bb1a87390d7', 'message': 'Expose ovs-vsctl-timeout\n\nExpose a new config option ovs-vsctl-timeout which specifies the\ntimeout in seconds for ovs-vsctl commands.\n\nCloses-Bug: #1738123\nChange-Id: I50f29fe932e39b1d35a3ccbfd82aee167d019b27\n'}, {'number': 2, 'created': '2018-01-02 21:25:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/a0e7857e65f8c90cdb6377b11ecb76dfe02cd8e4', 'message': 'Expose ovs-vsctl-timeout\n\nExpose a new config option ovs-vsctl-timeout which specifies the\ntimeout in seconds for ovs-vsctl commands.\n\nCloses-Bug: #1738123\nChange-Id: I50f29fe932e39b1d35a3ccbfd82aee167d019b27\n'}, {'number': 3, 'created': '2018-01-03 08:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/7895e9137e4f6aa796df459a04703cb0c742a4c4', 'message': 'Expose ovs-vsctl-timeout\n\nExpose a new config option ovs-vsctl-timeout which specifies the\ntimeout in seconds for ovs-vsctl commands.\n\nCloses-Bug: #1738123\nChange-Id: I50f29fe932e39b1d35a3ccbfd82aee167d019b27\n'}, {'number': 4, 'created': '2018-01-03 15:50:47.000000000', 'files': ['hooks/neutron_contexts.py', 'unit_tests/test_neutron_contexts.py', 'templates/mitaka/openvswitch_agent.ini', 'tests/basic_deployment.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/6cffe3f22303ed657a567a7362a0a3948405927d', 'message': 'Expose ovs-vsctl-timeout\n\nExpose a new config option ovs-vsctl-timeout which specifies the\ntimeout in seconds for ovs-vsctl commands.\n\nCloses-Bug: #1738123\nChange-Id: I50f29fe932e39b1d35a3ccbfd82aee167d019b27\n'}]",2,530801,6cffe3f22303ed657a567a7362a0a3948405927d,20,5,4,12549,,,0,"Expose ovs-vsctl-timeout

Expose a new config option ovs-vsctl-timeout which specifies the
timeout in seconds for ovs-vsctl commands.

Closes-Bug: #1738123
Change-Id: I50f29fe932e39b1d35a3ccbfd82aee167d019b27
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/01/530801/4 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/neutron_contexts.py', 'templates/mitaka/openvswitch_agent.ini', 'unit_tests/test_neutron_contexts.py', 'tests/basic_deployment.py', 'config.yaml']",5,fd0ccd5a8a7615087b7151ebc2b96bb1a87390d7,bug/1738123, ovs-vsctl-timeout: type: int default: description: | Timeout in seconds for ovs-vsctl commands.,,38,0
openstack%2Fcharm-rabbitmq-server~master~I737d4d2736e12eff37d9be111ed62b27f3f83c2b,openstack/charm-rabbitmq-server,master,I737d4d2736e12eff37d9be111ed62b27f3f83c2b,new action check-queues added to display non-zero queues,ABANDONED,2018-02-19 12:42:40.000000000,2019-01-07 11:41:22.000000000,,"[{'_account_id': 10068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-02-19 12:42:40.000000000', 'files': ['actions/check-queues', 'actions/actions.py', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/edd9883725e00c3337b3130b9720276e2b2b19a3', 'message': 'new action check-queues added to display non-zero queues\n\n - check-queues will list all the non-zero queues for a given\n   vhost (default=openstack).\n\nChange-Id: I737d4d2736e12eff37d9be111ed62b27f3f83c2b\n'}]",0,545822,edd9883725e00c3337b3130b9720276e2b2b19a3,4,2,1,27853,,,0,"new action check-queues added to display non-zero queues

 - check-queues will list all the non-zero queues for a given
   vhost (default=openstack).

Change-Id: I737d4d2736e12eff37d9be111ed62b27f3f83c2b
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/22/545822/1 && git format-patch -1 --stdout FETCH_HEAD,"['actions/check-queues', 'actions/actions.py', 'actions.yaml']",3,edd9883725e00c3337b3130b9720276e2b2b19a3,rmq-check-queues, description: Show the current cluster status. check-queues: description: List non-zero message queues. params: vhost: type: string description: The virtual host name (eg. openstack). , description: Show the current cluster status.,31,2
openstack%2Fcharm-ceilometer~master~Ie94ef210d4fd7ae9faf752fab72487b7ebeb4b67,openstack/charm-ceilometer,master,Ie94ef210d4fd7ae9faf752fab72487b7ebeb4b67,Fix auth_url to point at admin endpoint,ABANDONED,2018-02-26 14:04:17.000000000,2019-01-07 11:39:46.000000000,,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-02-26 14:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/2a4396923fff0f73ed2054686bf0aa3e0ce1839d', 'message': 'Fix auth_url to point at admin endpoint\n\nFix the auth_url in the service_credentials to the keystone admin\nendpoint. This makes is consistent with auth_url in the\nkeystone_authtoken section.\n\nChange-Id: Ie94ef210d4fd7ae9faf752fab72487b7ebeb4b67\n'}, {'number': 2, 'created': '2018-02-27 10:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/aa363bcb8eb508801a0e5576d07abad6d3cc4ef2', 'message': 'Fix auth_url to point at admin endpoint\n\nFix the auth_url in the service_credentials to the keystone admin\nendpoint. This makes is consistent with auth_url in the\nkeystone_authtoken section.\n\nChange-Id: Ie94ef210d4fd7ae9faf752fab72487b7ebeb4b67\n'}, {'number': 3, 'created': '2018-02-28 10:46:55.000000000', 'files': ['templates/kilo/ceilometer.conf', 'templates/mitaka/ceilometer.conf', 'tests/basic_deployment.py', 'templates/ocata/ceilometer.conf', 'templates/icehouse/ceilometer.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/df4b53943d701b4389ed7c66512b04bb1bbcb145', 'message': 'Fix auth_url to point at admin endpoint\n\nFix the auth_url in the service_credentials to the keystone admin\nendpoint. This makes is consistent with auth_url in the\nkeystone_authtoken section.\n\nChange-Id: Ie94ef210d4fd7ae9faf752fab72487b7ebeb4b67\n'}]",0,548031,df4b53943d701b4389ed7c66512b04bb1bbcb145,16,3,3,12549,,,0,"Fix auth_url to point at admin endpoint

Fix the auth_url in the service_credentials to the keystone admin
endpoint. This makes is consistent with auth_url in the
keystone_authtoken section.

Change-Id: Ie94ef210d4fd7ae9faf752fab72487b7ebeb4b67
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/31/548031/3 && git format-patch -1 --stdout FETCH_HEAD,"['templates/kilo/ceilometer.conf', 'templates/mitaka/ceilometer.conf', 'tests/basic_deployment.py', 'templates/ocata/ceilometer.conf', 'templates/icehouse/ceilometer.conf']",5,2a4396923fff0f73ed2054686bf0aa3e0ce1839d,bug/1751785,os_auth_url = {{ auth_protocol }}://{{ auth_host }}:{{ auth_port }}/v2.0,os_auth_url = {{ service_protocol }}://{{ service_host }}:{{ service_port }}/v2.0,8,5
openstack%2Fcharms.openstack~master~I9e5233a135ce62c6559e9462b2210237bd13e77d,openstack/charms.openstack,master,I9e5233a135ce62c6559e9462b2210237bd13e77d,Restart designate-pool-manager service on changes,ABANDONED,2018-03-07 10:34:24.000000000,2019-01-07 11:39:17.000000000,,"[{'_account_id': 12549}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-03-07 10:34:24.000000000', 'files': ['charms_openstack/charm/core.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/589f84163064117894eb827db042bdedc977b2eb', 'message': 'Restart designate-pool-manager service on changes\n\nThis patchset implements the logic to restart the\ndesignate-pool-manager service when making changes\nto ""/etc/designate/pools.yaml"" file.\n\nChange-Id: I9e5233a135ce62c6559e9462b2210237bd13e77d\nCloses-Bug: 1752895\nDepens-On: I859bd79c3de61147a9648f0b51120c850d8f3d9b\n'}]",0,550428,589f84163064117894eb827db042bdedc977b2eb,4,2,1,24504,,,0,"Restart designate-pool-manager service on changes

This patchset implements the logic to restart the
designate-pool-manager service when making changes
to ""/etc/designate/pools.yaml"" file.

Change-Id: I9e5233a135ce62c6559e9462b2210237bd13e77d
Closes-Bug: 1752895
Depens-On: I859bd79c3de61147a9648f0b51120c850d8f3d9b
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/28/550428/1 && git format-patch -1 --stdout FETCH_HEAD,['charms_openstack/charm/core.py'],1,589f84163064117894eb827db042bdedc977b2eb,bug/1752895, if service_name == 'designate-pool-manager': subprocess.check_call(self.designate_pool_update_cmd),,2,0
openstack%2Fcharm-designate~master~I859bd79c3de61147a9648f0b51120c850d8f3d9b,openstack/charm-designate,master,I859bd79c3de61147a9648f0b51120c850d8f3d9b,Restart designate-pool-manager service on changes,ABANDONED,2018-03-07 10:32:34.000000000,2019-01-07 11:39:08.000000000,,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-03-07 10:32:34.000000000', 'files': ['src/lib/charm/openstack/designate.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/33d897e59d02dbc4b104f4f8a72f8d8c80b0ec4d', 'message': 'Restart designate-pool-manager service on changes\n\nThis patchset implements the logic to restart the\ndesignate-pool-manager service when making changes\nto ""/etc/designate/pools.yaml"" file.\n\nChange-Id: I859bd79c3de61147a9648f0b51120c850d8f3d9b\nPartial-Bug: 1752895\n'}]",0,550426,33d897e59d02dbc4b104f4f8a72f8d8c80b0ec4d,5,3,1,24504,,,0,"Restart designate-pool-manager service on changes

This patchset implements the logic to restart the
designate-pool-manager service when making changes
to ""/etc/designate/pools.yaml"" file.

Change-Id: I859bd79c3de61147a9648f0b51120c850d8f3d9b
Partial-Bug: 1752895
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/26/550426/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/designate.py'],1,33d897e59d02dbc4b104f4f8a72f8d8c80b0ec4d,bug/1752895," '/etc/designate/pools.yaml': ['designate-pool-manager'], designate_pool_update_cmd = ['designate-manage', 'pool', 'update']"," '/etc/designate/pools.yaml': [''],",2,1
openstack%2Fcharm-cinder-ceph~master~I4763da7a27baec3bffcef5a5916431e70f532f99,openstack/charm-cinder-ceph,master,I4763da7a27baec3bffcef5a5916431e70f532f99,Require ceph-access relation for >= Ocata,ABANDONED,2017-10-30 11:48:54.000000000,2019-01-07 11:38:59.000000000,,"[{'_account_id': 935}, {'_account_id': 6737}, {'_account_id': 10068}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 27156}]","[{'number': 1, 'created': '2017-10-30 11:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/ad84d22c627ba43104cc51ccb456e7d3a2bef69a', 'message': 'Closes-Bug: 1728570 added required nova-compute relation to the docs to prevent problems during volume attachment\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}, {'number': 2, 'created': '2017-10-30 12:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/315156cf4c1c34270666d5cd59877185a5fb267b', 'message': 'added nova-compute relation to the cinder-ceph charm docs\n\ncinder-ceph charm requires a ceph-access relation to nova-compute charm to prevent ""Secret not found: rbd no secret matches uuid $uuid"" errors while attaching a volume to a virtual machine.\n\nCloses-Bug: #1728570\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}, {'number': 3, 'created': '2017-10-30 12:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/9b3fccc857655a84f15a1229480d2813b2120325', 'message': 'added nova-compute relation to the cinder-ceph charm docs\n\ncinder-ceph charm requires a ceph-access relation to nova-compute charm to\nprevent ""Secret not found: rbd no secret matches uuid $uuid"" errors\nwhile attaching a volume to a virtual machine.\n\nCloses-Bug: #1728570\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}, {'number': 4, 'created': '2017-10-30 14:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/ea475db93a2af840b20b35b54fd924e95ee89efb', 'message': 'added information about ceph-access relation\n\ncinder-ceph charm requires a ceph-access relation to nova-compute charm to\nprevent ""Secret not found: rbd no secret matches uuid $uuid"" errors\nwhile attaching a volume to a virtual machine >= Openstack Ocata.\nThis commit basically explains in the cinder-charm README.md file\nwhat is ceph-access relation and what is it used for\nwith a reference of the related LP bug.\n\nCloses-Bug: #1728570\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}, {'number': 5, 'created': '2017-10-30 14:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/47c8e841cc9fe4daf6dad680d36b539b73d806d5', 'message': 'added information about ceph-access relation\n\ncinder-ceph charm requires a ceph-access relation to nova-compute charm to\nprevent ""Secret not found: rbd no secret matches uuid $uuid"" errors\nwhile attaching a volume to a virtual machine >= Openstack Ocata.\nThis commit basically explains in the cinder-charm README.md file\nwhat is ceph-access relation and what is it used for\nwith a reference of the related LP bug.\n\nCloses-Bug: #1728570\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}, {'number': 6, 'created': '2017-11-21 15:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/166e5a8ca1242ce8499deb3ae8ad21cceb742f2d', 'message': 'added information about ceph-access relation\n\ncinder-ceph charm requires a ceph-access relation to nova-compute charm to\nprevent ""Secret not found: rbd no secret matches uuid $uuid"" errors\nwhile attaching a volume to a virtual machine >= Openstack Ocata.\nThis commit basically explains in the cinder-charm README.md file\nwhat is ceph-access relation and what is it used for\nwith a reference of the related LP bug.\n\nPartial-Bug: #1728570\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}, {'number': 7, 'created': '2017-11-22 17:52:34.000000000', 'files': ['unit_tests/test_cinder_utils.py', 'hooks/cinder_hooks.py', 'hooks/cinder_utils.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/47386a172b297979a08594136c275d507859e4b9', 'message': 'Require ceph-access relation for >= Ocata\n\nSince Ocata the ceph-access interface must be used by\nnova-compute in order to be able to attach Ceph volumes\nto instances. This commit updates the README file\nto include this requirement and also updates the code\nto notify users if the interface is not in use for Ocata\nand above.\n\nPartial-Bug: #1728570\n\nChange-Id: I4763da7a27baec3bffcef5a5916431e70f532f99\n'}]",1,516258,47386a172b297979a08594136c275d507859e4b9,29,7,7,27156,,,0,"Require ceph-access relation for >= Ocata

Since Ocata the ceph-access interface must be used by
nova-compute in order to be able to attach Ceph volumes
to instances. This commit updates the README file
to include this requirement and also updates the code
to notify users if the interface is not in use for Ocata
and above.

Partial-Bug: #1728570

Change-Id: I4763da7a27baec3bffcef5a5916431e70f532f99
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/58/516258/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,ad84d22c627ba43104cc51ccb456e7d3a2bef69a,bug/1728570, juju deploy nova-compute juju add-relation cinder-ceph nova-compute,,2,0
openstack%2Fcharms.ceph~master~Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b,openstack/charms.ceph,master,Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b,Allow create of osd on mounted devices,ABANDONED,2018-01-28 16:26:49.000000000,2019-01-07 11:38:47.000000000,,"[{'_account_id': 20634}, {'_account_id': 22348}, {'_account_id': 24904}, {'_account_id': 26297}]","[{'number': 1, 'created': '2018-01-28 16:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/cff4c57ab950aac9bfd0b5a7eeebbc1ed12cf14b', 'message': ""Allow create of osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions.\n* Build ceph-disk flags in function to re-use current logic from\nosdize_dev in osdize_part\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n * Will not format/zap mounted ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done via charmhelpers instead of using the ceph-disk option\n\nAll bugs require syncing to relevant charms to actually close\nPartial-Bug: #1743278\nPartial-Bug: #1743280\nPartial-Bug: #1743282\n\nChange-Id: Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b\n""}, {'number': 2, 'created': '2018-02-18 13:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/d422ef892b5619f9defb778a4d68bc293c62cf00', 'message': ""Allow create of osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions.\n* Build ceph-disk flags in function to re-use current logic from\nosdize_dev in osdize_part\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n * Will not format/zap mounted ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done via charmhelpers instead of using the ceph-disk option\n\nAll bugs require syncing to relevant charms to actually close\nPartial-Bug: #1743278\nPartial-Bug: #1743280\nPartial-Bug: #1743282\n\nChange-Id: Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b\n""}, {'number': 3, 'created': '2018-03-22 18:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/264a00646a9c2db8d9b75f5d3420c454b27a6c12', 'message': ""Allow create of osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions.\n* Build ceph-disk flags in function to re-use current logic from\nosdize_dev in osdize_part\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n * Will not format/zap mounted ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done as an independent call to ceph-disk\n\nAll bugs require syncing to relevant charms to actually close\nPartial-Bug: #1743278\nPartial-Bug: #1743280\nPartial-Bug: #1743282\n\nChange-Id: Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b\n""}, {'number': 4, 'created': '2018-03-22 18:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/ccf5121874f967f17f6ea58c4a8c150cfe39992f', 'message': ""Allow create of osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions.\n* Build ceph-disk flags in function to re-use current logic from\nosdize_dev in osdize_part\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n * Will not format/zap mounted ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done as an independent call to ceph-disk\n\nAll bugs require syncing to relevant charms to actually close\nPartial-Bug: #1743278\nPartial-Bug: #1743280\nPartial-Bug: #1743282\n\nChange-Id: Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b\n""}, {'number': 5, 'created': '2018-03-22 18:42:15.000000000', 'files': ['unit_tests/test_utils.py', 'ceph/utils.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/d7b531cf4d0566c1d54d47acfe7737a9c852adeb', 'message': ""Allow create of osd on mounted devices\n\nAddes logic to create and activate partitions on devices that have\nmounted partitions.\n* Build ceph-disk flags in function to re-use current logic from\nosdize_dev in osdize_part\n* Shared osd's implement all options/logic of the osdize_dev\n * Checks for in use\n * Handles the format osd option\n * Works with dmcrypt\n * Will not format/zap non-ceph partitions\n * Will not format/zap mounted ceph partitions\n\nThis includes two drive-by fixes for bugs which it didn't make since to\nbreak out. Both changes are in code which was altered in this\npatch and not closing them would require implementing the bug to avoid\nclosing it.\n* Partitions are wiped before zapping\n* Zap is done as an independent call to ceph-disk\n\nAll bugs require syncing to relevant charms to actually close\nPartial-Bug: #1743278\nPartial-Bug: #1743280\nPartial-Bug: #1743282\n\nChange-Id: Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b\n""}]",1,538622,d7b531cf4d0566c1d54d47acfe7737a9c852adeb,17,4,5,24904,,,0,"Allow create of osd on mounted devices

Addes logic to create and activate partitions on devices that have
mounted partitions.
* Build ceph-disk flags in function to re-use current logic from
osdize_dev in osdize_part
* Shared osd's implement all options/logic of the osdize_dev
 * Checks for in use
 * Handles the format osd option
 * Works with dmcrypt
 * Will not format/zap non-ceph partitions
 * Will not format/zap mounted ceph partitions

This includes two drive-by fixes for bugs which it didn't make since to
break out. Both changes are in code which was altered in this
patch and not closing them would require implementing the bug to avoid
closing it.
* Partitions are wiped before zapping
* Zap is done as an independent call to ceph-disk

All bugs require syncing to relevant charms to actually close
Partial-Bug: #1743278
Partial-Bug: #1743280
Partial-Bug: #1743282

Change-Id: Id3c8403dfbf710e054ca5e4d965fe6f9b8f9c72b
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/22/538622/2 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_utils.py', 'ceph/utils.py']",2,cff4c57ab950aac9bfd0b5a7eeebbc1ed12cf14b,bug/1743278," '45B0969E-9B03-4F30-B4C6-B4B80CEFF106', # journal 'CAFECAFE-9B03-4F30-B4C6-B4B80CEFF106', # block '4FBD7E29-9D25-41B8-AFD0-062C0CEFF05D', # osd (data) '89C57F98-2FE5-4DC0-89C1-F3AD0CEFF2BE', # osd (data) in creation 'FB3AABF9-D25F-47CC-BF5E-721D1816496B', # lockbox '45b0969e-9b03-4f30-b4c6-35865ceff106', # encrypted luks journal 'CAFECAFE-9B03-4F30-B4C6-35865CEFF106', # encrypted luks block '4FBD7E29-9D25-41B8-AFD0-35865CEFF05D', # encrypted luks osd (data) '45B0969E-9B03-4F30-B4C6-5EC00CEFF106', # encrypted plain journal 'CAFECAFE-9B03-4F30-B4C6-5EC00CEFF106', # encrypted plain block '4FBD7E29-9D25-41B8-AFD0-5EC00CEFF05D', # encrypted plain osd data '89C57F98-2FE5-4DC0-89C1-5EC00CEFF2BE', # encrypted osd (data) in creationdef get_osd_partitions(dev): partitions = get_partition_list(dev) osd_partitions = [] for partition in partitions: try: info = str(subprocess .check_output(['sgdisk', '-i', partition.number, dev]) .decode('UTF-8')) info = info.split(""\n"") # IGNORE:E1103 for line in info: for ptype in CEPH_PARTITIONS: sig = 'Partition GUID code: {}'.format(ptype) if line.startswith(sig): osd_partitions.append(partition) continue except subprocess.CalledProcessError as e: log(""sgdisk inspection of partition {} on {} failed with "" ""error: {}. Skipping"".format(partition.minor, dev, e), level=ERROR) return osd_partitions def build_disk_cmd(osd_format=False, reformat_osd=False, encrypt=False, bluestore=False): return cmd def osdize(dev, osd_format, osd_journal, reformat_osd=False, ignore_errors=False, encrypt=False, bluestore=False): if dev.startswith('/dev'): if is_device_mounted(dev) and config('osd-shared'): osdize_part(dev, osd_format, osd_journal, ignore_errors, encrypt, bluestore) else: osdize_dev(dev, osd_format, osd_journal, reformat_osd, ignore_errors, encrypt, bluestore) else: osdize_dir(dev, encrypt, bluestore) def osdize_dev(dev, osd_format, osd_journal, reformat_osd=False, ignore_errors=False, encrypt=False, bluestore=False): if not os.path.exists(dev): log('Path {} does not exist - bailing'.format(dev)) return if not is_block_device(dev): log('Path {} is not a block device - bailing'.format(dev)) return if is_osd_disk(dev) and not reformat_osd: log('Looks like {} is already an' ' OSD data or journal, skipping.'.format(dev)) return if is_device_mounted(dev): log('Looks like {} is in use, skipping.'.format(dev)) return status_set('maintenance', 'Initializing device {}'.format(dev)) # Note(chrissanders): skip the --zap-disk command in ceph disk # and run manual clear to support dmcrypt bluestore in 12.2.1 cmd = build_disk_cmd(osd_format=osd_format, reformat_osd=False, encrypt=encrypt, bluestore=bluestore) if reformat_osd: # NOTE(chrissanders): wipe partitions or lockbox fails to recreate for partition in get_partition_list(dev): subprocess.check_call('wipefs -a {}'.format(dev+partition.number), shell=True) zap_disk(dev) cmd.append(dev) if osd_journal: least_used = find_least_used_utility_device(osd_journal) cmd.append(least_used)def osdize_part(dev, osd_format, osd_journal, ignore_errors=False, encrypt=False, bluestore=False): """"""Setup partitions if missing and ask ceph-disk to prepare them. :param dev: str. Path to a block device. ex: /dev/sda :param osd_format: str. Filesystem to use on Filestore partitions. :param osd_journal: str. Set of osd_journals to use instead of partition. :param ignore_errors: bool. If true subprocess commands log error instead of warning :param encrypt: bool. Should the OSD partition be encrypted at rest :param bluestore: bool. Should the OSD use bluestore backing :returns: None """""" status_set('maintenance', 'Checking shared device {}'.format(dev)) if is_osd_disk(dev): if not osd_format: log('Disk is already an osd, skipping {}'.format(dev)) return osd_partitions = get_osd_partitions(dev) for partition in osd_partitions: if filesystem_mounted(dev+partition.number): log('Skipping osd, partition in use:' '{}'.format(dev+partition.number)) return for partition in osd_partitions: log('Clearing partition: {}'.format(partition)) cmds = ['wipefs -a {}'.format(dev+partition.number), 'sgdisk -d {} {}'.format(partition.number, dev), 'partprobe {}'.format(dev) ] for cmd in cmds: try: subprocess.check_call(cmd, shell=True) except subprocess.CalledProcessError: if ignore_errors: log('Unable to initialize device: {}'.format(dev), WARNING) return else: log('Unable to initialize device: {}'.format(dev), ERROR) raise status_set('maintenance', 'Seting up shared device {}'.format(dev)) log('Creating ceph partitions on: {}'.format(dev), DEBUG) disk_cmd = build_disk_cmd(osd_format=osd_format, reformat_osd=False, encrypt=encrypt, bluestore=bluestore) log('ceph-disk cmd: {}'.format(disk_cmd), DEBUG) cmd = [hookenv.charm_dir() + '/files/ceph/setup_osd.py'] argv = disk_cmd[1:] argv.append(dev) cmd.extend(argv) try: subprocess.check_call(cmd) except subprocess.CalledProcessError: if ignore_errors: log('Unable to initialize device: {}'.format(dev), WARNING) else: log('Unable to initialize device: {}'.format(dev), ERROR) raise "," '89C57F98-2FE5-4DC0-89C1-5EC00CEFF2BE', # ceph encrypted disk in creation '45B0969E-9B03-4F30-B4C6-5EC00CEFF106', # ceph encrypted journal '4FBD7E29-9D25-41B8-AFD0-5EC00CEFF05D', # ceph encrypted osd data '4FBD7E29-9D25-41B8-AFD0-062C0CEFF05D', # ceph osd data '45B0969E-9B03-4F30-B4C6-B4B80CEFF106', # ceph osd journal '89C57F98-2FE5-4DC0-89C1-F3AD0CEFF2BE', # ceph disk in creationdef osdize(dev, osd_format, osd_journal, reformat_osd=False, ignore_errors=False, encrypt=False, bluestore=False): if dev.startswith('/dev'): osdize_dev(dev, osd_format, osd_journal, reformat_osd, ignore_errors, encrypt, bluestore) else: osdize_dir(dev, encrypt, bluestore) def osdize_dev(dev, osd_format, osd_journal, reformat_osd=False, ignore_errors=False, encrypt=False, bluestore=False): if not os.path.exists(dev): log('Path {} does not exist - bailing'.format(dev)) return if not is_block_device(dev): log('Path {} is not a block device - bailing'.format(dev)) return if is_osd_disk(dev) and not reformat_osd: log('Looks like {} is already an' ' OSD data or journal, skipping.'.format(dev)) return if is_device_mounted(dev): log('Looks like {} is in use, skipping.'.format(dev)) return status_set('maintenance', 'Initializing device {}'.format(dev)) cmd.append(dev) if osd_journal: least_used = find_least_used_utility_device(osd_journal) cmd.append(least_used) else: # Just provide the device - no other options # for older versions of ceph cmd.append(dev) if reformat_osd: zap_disk(dev)",183,47
openstack%2Fcharm-ceph-mon~master~I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4,openstack/charm-ceph-mon,master,I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4,Add get-status action to the ceph-mon charm,ABANDONED,2018-02-15 10:45:53.000000000,2019-01-07 11:38:28.000000000,,"[{'_account_id': 12767}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-02-15 10:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/aecb60cfcd0e576985b89dff16c582ca0c5b7903', 'message': 'Add get-status action to the ceph-mon charm\n\n* get-status - outputs ceph -s output\n\nIncluding unit test for the above action.\n\nCloses-Bug: #1749661\n\nChange-Id: I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4\nSigned-off-by: Craige McWhirter <craige@mcwhirter.io>\n'}, {'number': 2, 'created': '2018-02-15 22:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/367fc893a56893ef963f3fe4fc9d00b30340658a', 'message': 'Add get-status action to the ceph-mon charm\n\n* get-status - outputs ceph -s output\n\nIncluding unit test for the above action.\n\nCloses-Bug: #1749661\n\nChange-Id: I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4\nSigned-off-by: Craige McWhirter <craige@mcwhirter.io>\n'}, {'number': 3, 'created': '2018-03-27 01:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/75da5b5ee5eaf5b94e8d8d97c2e728802f2978bc', 'message': 'Add get-status action to the ceph-mon charm\n\n* get-status - outputs ceph -s output\n\nIncluding unit test for the above action.\n\nCloses-Bug: #1749661\n\nChange-Id: I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4\nSigned-off-by: Craige McWhirter <craige@mcwhirter.io>\n'}, {'number': 4, 'created': '2018-03-27 23:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/f516f481be8c27551f025724a2cd9346e6701a17', 'message': 'Add get-status action to the ceph-mon charm\n\n* get-status - outputs ceph -s output\n\nIncluding unit test for the above action.\n\nCloses-Bug: #1749661\n\nChange-Id: I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4\nSigned-off-by: Craige McWhirter <craige@mcwhirter.io>\n'}, {'number': 5, 'created': '2018-04-04 05:39:45.000000000', 'files': ['actions/get-status', 'actions/ceph_ops.py', 'tests/basic_deployment.py', 'unit_tests/test_actions_mon.py', 'actions/get-status.py', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/9d8b5f3a217e5d5be14dc57cf2300c9a2e776804', 'message': 'Add get-status action to the ceph-mon charm\n\n* get-status - outputs ceph -s output\n\nIncluding unit test for the above action.\n\nCloses-Bug: #1749661\n\nChange-Id: I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4\nSigned-off-by: Craige McWhirter <craige@mcwhirter.io>\n'}]",0,544851,9d8b5f3a217e5d5be14dc57cf2300c9a2e776804,27,6,5,12767,,,0,"Add get-status action to the ceph-mon charm

* get-status - outputs ceph -s output

Including unit test for the above action.

Closes-Bug: #1749661

Change-Id: I3ce8bb1157c50e3fcf3f07028a045a5f6a0cbcd4
Signed-off-by: Craige McWhirter <craige@mcwhirter.io>
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/51/544851/4 && git format-patch -1 --stdout FETCH_HEAD,"['actions/get-status', 'actions/ceph_ops.py', 'unit_tests/test_actions_mon.py', 'actions.yaml']",4,aecb60cfcd0e576985b89dff16c582ca0c5b7903,bug/1749661,get-status: description: Output the current cluster status,,27,0
openstack%2Fcharm-hacluster~master~Icbba065707b0a6e5b7a03aa60b180e13ff6508d4,openstack/charm-hacluster,master,Icbba065707b0a6e5b7a03aa60b180e13ff6508d4,Add actions and tests for health and VIP status,ABANDONED,2017-09-05 02:10:07.000000000,2019-01-07 11:36:34.000000000,,"[{'_account_id': 3}, {'_account_id': 12549}, {'_account_id': 12767}, {'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 21704}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-05 02:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/db83e47abefbb754dc89c54e874f4546b8e08d35', 'message': 'Add actions for health status and listing the hosting node for the VIP\n\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 2, 'created': '2017-09-18 02:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/95e332d99ec3e34fe8a226d683a90e85ef223c4f', 'message': 'Add actions for health status and listing the hosting node for the VIP\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 3, 'created': '2017-11-06 05:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/58e81327e12b6520081ce5d09a6839a0e2611655', 'message': 'Add actions and tests for health and VIP status\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 4, 'created': '2017-11-21 00:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/f8a7fe54248390692657c46de476099ca32e3b31', 'message': 'Add actions and tests for health and VIP status\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 5, 'created': '2017-11-27 02:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/a0fc24d920f0c0cbc85a2bbd093923af37f69d52', 'message': 'Add actions and tests for health and VIP status\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 6, 'created': '2017-11-27 03:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/a9beccf8e5906041c9496c43b31f944d35ae4365', 'message': 'Add actions and tests for health and VIP status\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 7, 'created': '2017-12-29 07:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/aff272b7f77bc3c615c7169633c9c19bead352ba', 'message': 'Add actions and tests for health and VIP status\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}, {'number': 8, 'created': '2018-04-05 22:33:54.000000000', 'files': ['actions/actions.py', 'actions/list-vip-host', 'tests/basic_deployment.py', 'unit_tests/test_actions.py', 'actions/health-status', 'unit_tests/__init__.py', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/7a96151138362de13ffaf6b1e9350ec0e4ad6ef9', 'message': 'Add actions and tests for health and VIP status\n\nCloses-Bug: 1717831\nChange-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4\n'}]",6,500655,7a96151138362de13ffaf6b1e9350ec0e4ad6ef9,46,10,8,21704,,,0,"Add actions and tests for health and VIP status

Closes-Bug: 1717831
Change-Id: Icbba065707b0a6e5b7a03aa60b180e13ff6508d4
",git fetch https://review.opendev.org/openstack/charm-hacluster refs/changes/55/500655/8 && git format-patch -1 --stdout FETCH_HEAD,"['actions/actions.py', 'actions/list-vip-host', 'actions/health-status', 'actions.yaml']",4,db83e47abefbb754dc89c54e874f4546b8e08d35,bug/1717831,list-vip-host: description: Show which unit hosts the VIP health-status: description: Show health status of the cluster,,45,2
openstack%2Fkolla-ansible~master~Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e,openstack/kolla-ansible,master,Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e,Add Kolla Ceph filestore CI jobs,MERGED,2018-11-23 07:52:46.000000000,2019-01-07 11:35:54.000000000,2019-01-07 11:35:54.000000000,"[{'_account_id': 2276}, {'_account_id': 7488}, {'_account_id': 11797}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 24072}, {'_account_id': 24574}, {'_account_id': 27336}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-11-23 07:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/21030832bd7e0715c8d1c23709c72e3f12f5c893', 'message': '[wip] Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type usd by Kolla Ceph.\nThe patch add new Kolla Ceph CI test for filestore.\n\nThe patch is experimental now, and will be updated according to the\ntest result.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 2, 'created': '2018-11-28 06:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fc9e02848f670c4b9aa81539b49482a4f81c7ea0', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch replaces one\nbluestore job with filestore job, and make CI jobs covery both\nCeph store type.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 3, 'created': '2018-12-03 07:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/503d546fdd9afd0c9088ec08e7290f160674b868', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansibel CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 4, 'created': '2018-12-03 10:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/70b06a9a0aefc8baf2436becacc419d37de9aaf1', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 5, 'created': '2018-12-12 01:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/db2bef261565031b20b744d84fa8321915d06fe4', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 6, 'created': '2018-12-14 00:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5f761cbbba121fb79da98478395da8a9929bfa38', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 7, 'created': '2018-12-14 04:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ac1ac7f343263df6a9f1b47352cbf327c576e0ef', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 8, 'created': '2018-12-21 07:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/19547df63c1b2cf8915265c1a1dc9121ec1743cb', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 9, 'created': '2018-12-25 07:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d10f7b5053ac360df6ec516b06fee229175589a4', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 10, 'created': '2018-12-27 09:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ac30833e3d406089cfcc28d986b995d6d7b3d47b', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 11, 'created': '2018-12-27 09:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/26905c08e12519489df96944c27d9f962376b8d8', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 12, 'created': '2018-12-28 00:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/43451a0086f8b9ddc84a1e50f8b226d0ba425046', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 13, 'created': '2018-12-28 02:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/606802179de303f5ec23a0fcc0b267caeda5e67c', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}, {'number': 14, 'created': '2019-01-01 05:32:33.000000000', 'files': ['tests/run.yml', 'tests/setup_ceph_disks.sh', 'tests/templates/inventory.j2', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6786bc5b7766b9eaf9736c6ee3f832ef6b84cfd6', 'message': 'Add Kolla Ceph filestore CI jobs\n\nSince Rocky bluestore is the default store type used by Kolla Ceph.\nFilestore is still used by the customers. The patch allows deploy\nboth Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI\njobs.\n\nChange-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e\nSigned-off-by: tone.zhang <tone.zhang@arm.com>\n'}]",13,619671,6786bc5b7766b9eaf9736c6ee3f832ef6b84cfd6,76,12,14,24574,,,0,"Add Kolla Ceph filestore CI jobs

Since Rocky bluestore is the default store type used by Kolla Ceph.
Filestore is still used by the customers. The patch allows deploy
both Ceph bluestore OSD and Ceph filestore OSD in Kolla-ansible CI
jobs.

Change-Id: Iaa7c1b2ff35eb649c3a6d9f7266463d8961cdc9e
Signed-off-by: tone.zhang <tone.zhang@arm.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/71/619671/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/setup_ceph_filestore_disks.sh', 'tests/run.yml', 'tests/templates/globals-default.j2', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml']",5,21030832bd7e0715c8d1c23709c72e3f12f5c893,ceph-ci, name: kolla-ansible-ubuntu-source-ceph-filestore parent: kolla-ansible-base nodeset: kolla-ansible-xenial-multi voting: false vars: base_distro: ubuntu install_type: source scenario: ceph-filestore - job: name: kolla-ansible-centos-source-ceph-filestore parent: kolla-ansible-base nodeset: kolla-ansible-centos-multi voting: false vars: base_distro: centos install_type: source scenario: ceph-filestore - job: name: kolla-ansible-oraclelinux-source-ceph-filestore parent: kolla-ansible-base nodeset: kolla-ansible-centos-multi voting: false vars: base_distro: oraclelinux install_type: source scenario: ceph-filstore - job:,,61,1
openstack%2Fcharm-ceph-osd~master~Idf59964ad5e5587f050ba6f9c5ab562e1ca213ba,openstack/charm-ceph-osd,master,Idf59964ad5e5587f050ba6f9c5ab562e1ca213ba,Add show-bcache-devices to ceph osd charm,ABANDONED,2018-04-23 09:25:50.000000000,2019-01-07 11:29:43.000000000,,"[{'_account_id': 22348}, {'_account_id': 24297}]","[{'number': 1, 'created': '2018-04-23 09:25:50.000000000', 'files': ['actions/show-bcache-devices', 'tests/basic_deployment.py', 'actions/show_bcache_devices.py', 'unit_tests/test_actions_osd.py', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/071f13bd92cd023481fe6e657aa177f0fb45bf07', 'message': 'Add show-bcache-devices to ceph osd charm\n\nShow-bcache-devices action lists all the configured bcache disks\non the unit along with the state of all the backing disks\n\nChange-Id: Idf59964ad5e5587f050ba6f9c5ab562e1ca213ba\n'}]",1,563543,071f13bd92cd023481fe6e657aa177f0fb45bf07,4,2,1,27146,,,0,"Add show-bcache-devices to ceph osd charm

Show-bcache-devices action lists all the configured bcache disks
on the unit along with the state of all the backing disks

Change-Id: Idf59964ad5e5587f050ba6f9c5ab562e1ca213ba
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/43/563543/1 && git format-patch -1 --stdout FETCH_HEAD,"['actions/show-bcache-devices', 'tests/basic_deployment.py', 'actions/show_bcache_devices.py', 'unit_tests/test_actions_osd.py', 'actions.yaml']",5,071f13bd92cd023481fe6e657aa177f0fb45bf07,action-show-bcache-devices,show-bcache-devices: description: Shows the bcache caching & backing devices as well as their status,,105,0
openstack%2Fopenstack-ansible-galera_client~master~I1c32655eddee6c37d7433e6aca8be851344e93e4,openstack/openstack-ansible-galera_client,master,I1c32655eddee6c37d7433e6aca8be851344e93e4,cleanup: don't update_cache when adding a new repo,MERGED,2018-12-29 22:48:14.000000000,2019-01-07 11:28:26.000000000,2019-01-03 09:20:26.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-29 22:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/9a5c64f6556f23991a24f3ceff238cebaac030ea', 'message': 'cleanup: update_cache when adding a new repo\n\nThere is no need to add an extra task after that watches for\nchanges inside `apt_repository`.  We can simply do the update_cache\nthere anyways.\n\nChange-Id: I1c32655eddee6c37d7433e6aca8be851344e93e4\n'}, {'number': 2, 'created': '2018-12-29 22:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/6ad699ffecb59d24a7c36a9ae05052126628707f', 'message': 'cleanup: update_cache when adding a new repo\n\nThere is no need to add an extra task after that watches for\nchanges inside `apt_repository`.  We can simply do the update_cache\nthere anyways.\n\nChange-Id: I1c32655eddee6c37d7433e6aca8be851344e93e4\n'}, {'number': 3, 'created': '2018-12-29 22:49:36.000000000', 'files': ['tasks/galera_client_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/d8e1f4d83ca14d2555d0a6226c0205a323a5e8b2', 'message': ""cleanup: don't update_cache when adding a new repo\n\nWe don't need to update_cache when we add a new repo because\nwe already do it when we install the package in the follow up task.\n\nChange-Id: I1c32655eddee6c37d7433e6aca8be851344e93e4\n""}]",0,627787,d8e1f4d83ca14d2555d0a6226c0205a323a5e8b2,10,3,3,1004,,,0,"cleanup: don't update_cache when adding a new repo

We don't need to update_cache when we add a new repo because
we already do it when we install the package in the follow up task.

Change-Id: I1c32655eddee6c37d7433e6aca8be851344e93e4
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/87/627787/3 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_client_install_apt.yml'],1,9a5c64f6556f23991a24f3ceff238cebaac030ea,osa-speedups," update_cache: ""{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}""", update_cache: no - name: Update Apt cache apt: update_cache: yes when: add_repo is changed register: update_apt_cache until: update_apt_cache is success retries: 5 delay: 2 tags: - galera-client-repos,1,12
openstack%2Fcharm-neutron-api~master~I8647b4c115667a51505943bd700cc355d357159f,openstack/charm-neutron-api,master,I8647b4c115667a51505943bd700cc355d357159f,change spelling error,ABANDONED,2017-07-26 06:14:31.000000000,2019-01-07 11:28:25.000000000,,"[{'_account_id': 3}, {'_account_id': 8992}, {'_account_id': 10068}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-07-26 06:14:31.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templating.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/a6854137f4004a47c3cce69379d388dfcea56fbd', 'message': 'change spelling error\n\nChange-Id: I8647b4c115667a51505943bd700cc355d357159f\n'}]",0,487287,a6854137f4004a47c3cce69379d388dfcea56fbd,6,4,1,26486,,,0,"change spelling error

Change-Id: I8647b4c115667a51505943bd700cc355d357159f
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/87/487287/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/contrib/openstack/templating.py'],1,a6854137f4004a47c3cce69379d388dfcea56fbd,, # the bottom contains templates_dir and possibly a common templates dir, # the bottom contains tempaltes_dir and possibly a common templates dir,1,1
openstack%2Fcharm-nova-compute~master~I25c16b346a5eb7047a8efb24171d8a0365967262,openstack/charm-nova-compute,master,I25c16b346a5eb7047a8efb24171d8a0365967262,Improve Python 3 compatibility,ABANDONED,2017-06-29 14:22:35.000000000,2019-01-07 11:28:15.000000000,,"[{'_account_id': 3}, {'_account_id': 8992}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-06-29 14:22:35.000000000', 'files': ['templates/ocata/nova.conf', 'templates/liberty/nova.conf', 'templates/juno/nova.conf', 'templates/kilo/nova.conf', 'templates/icehouse/nova.conf', 'hooks/charmhelpers/contrib/openstack/templates/ceph.conf', 'templates/mitaka/nova.conf'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/5af11f62c69c5481a8ab324f8442fd70bc5f45ad', 'message': 'Improve Python 3 compatibility\n\nUse dict.items() instead of dict.iteritems() for python 3 compatibility\n\nChange-Id: I25c16b346a5eb7047a8efb24171d8a0365967262\n'}]",1,478946,5af11f62c69c5481a8ab324f8442fd70bc5f45ad,5,3,1,26295,,,0,"Improve Python 3 compatibility

Use dict.items() instead of dict.iteritems() for python 3 compatibility

Change-Id: I25c16b346a5eb7047a8efb24171d8a0365967262
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/46/478946/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/ocata/nova.conf', 'templates/liberty/nova.conf', 'templates/juno/nova.conf', 'templates/kilo/nova.conf', 'templates/icehouse/nova.conf', 'hooks/charmhelpers/contrib/openstack/templates/ceph.conf', 'templates/mitaka/nova.conf']",7,5af11f62c69c5481a8ab324f8442fd70bc5f45ad,python3compatibility,"{% for key, value in network_manager_config.items() -%}{% for key, value in user_config_flags.items() -%}","{% for key, value in network_manager_config.iteritems() -%}{% for key, value in user_config_flags.iteritems() -%}",14,14
openstack%2Fcharm-neutron-api~master~I96c800bf955ad8f52f570b3b6d6fe7a1d521d79a,openstack/charm-neutron-api,master,I96c800bf955ad8f52f570b3b6d6fe7a1d521d79a,Adding auth_version=3 parameter if api_version=3,ABANDONED,2017-07-13 12:16:38.000000000,2019-01-07 11:28:01.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 8992}, {'_account_id': 10068}, {'_account_id': 13686}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-07-13 12:16:38.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/93ec64ab62396cf9607bbb37c9ec2351be30362b', 'message': 'Adding auth_version=3 parameter if api_version=3\n\nWhen the cloud is deployed or upgraded with keystone parameter preferred-api-version=3, auth_version=3 parameter should also be set in [keystone_authtoken] section of neutron conf. This is also a requirement for Cisco ACI integration i.e. for cisco group-based-policy plugin to send v3 requests to keystone.\n\nChange-Id: I96c800bf955ad8f52f570b3b6d6fe7a1d521d79a\nCloses-Bug: #1702278\n'}]",3,483323,93ec64ab62396cf9607bbb37c9ec2351be30362b,9,6,1,26403,,,0,"Adding auth_version=3 parameter if api_version=3

When the cloud is deployed or upgraded with keystone parameter preferred-api-version=3, auth_version=3 parameter should also be set in [keystone_authtoken] section of neutron conf. This is also a requirement for Cisco ACI integration i.e. for cisco group-based-policy plugin to send v3 requests to keystone.

Change-Id: I96c800bf955ad8f52f570b3b6d6fe7a1d521d79a
Closes-Bug: #1702278
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/23/483323/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka'],1,93ec64ab62396cf9607bbb37c9ec2351be30362b,bug/1702278,auth_version = 3,,1,0
openstack%2Fcharm-openstack-dashboard~master~I1afdf51b3988f4d2b6781dc67e20637457ad5c14,openstack/charm-openstack-dashboard,master,I1afdf51b3988f4d2b6781dc67e20637457ad5c14,Install Murano-dashboard package as part of openstack-dashboard charm,ABANDONED,2016-11-12 07:24:34.000000000,2019-01-07 11:27:48.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20807}, {'_account_id': 22233}]","[{'number': 1, 'created': '2016-11-12 07:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/342f8c52441f5f7a2501669855d6754e19cf6b9d', 'message': 'Install Murano-dashboard package as part of openstack-dashboard charm\n\nChange-Id: I1afdf51b3988f4d2b6781dc67e20637457ad5c14\n'}, {'number': 2, 'created': '2016-11-12 07:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/7e8760a68647bad9e72f609194bd2fd0dd2c5567', 'message': 'Install Murano-dashboard package as part of openstack-dashboard charm\n\ncloses-bug:1641107\n\nChange-Id: I1afdf51b3988f4d2b6781dc67e20637457ad5c14\n'}, {'number': 3, 'created': '2016-11-13 06:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/6e1f335cc4fe15c326972260b80700ec7828335f', 'message': 'Install Murano-dashboard package as part of openstack-dashboard charm\n\ncloses-bug:1641107\n\nChange-Id: I1afdf51b3988f4d2b6781dc67e20637457ad5c14\n'}, {'number': 4, 'created': '2017-04-06 07:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/469b27b14e0877522458f3634a47517531812197', 'message': 'Install Murano-dashboard package as part of openstack-dashboard charm\n\ncloses-bug:1641107\n\nChange-Id: I1afdf51b3988f4d2b6781dc67e20637457ad5c14\n'}, {'number': 5, 'created': '2017-08-21 22:27:44.000000000', 'files': ['hooks/horizon_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/26e1e192ad2732b685a5a6f6de60d2bc38d821d3', 'message': 'Install Murano-dashboard package as part of openstack-dashboard charm\n\ncloses-bug:1641107\n\nChange-Id: I1afdf51b3988f4d2b6781dc67e20637457ad5c14\n'}]",1,396839,26e1e192ad2732b685a5a6f6de60d2bc38d821d3,33,7,5,22233,,,0,"Install Murano-dashboard package as part of openstack-dashboard charm

closes-bug:1641107

Change-Id: I1afdf51b3988f4d2b6781dc67e20637457ad5c14
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/39/396839/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/horizon_utils.py'],1,342f8c52441f5f7a2501669855d6754e19cf6b9d,bug/1641107," 'python-murano-dashboard',",,1,0
openstack%2Fcharm-keystone~master~I05888870bc9c8579d5c04c79d200ea57a77e711b,openstack/charm-keystone,master,I05888870bc9c8579d5c04c79d200ea57a77e711b,Silence several deprecation warnings that should be removed in N.,ABANDONED,2017-04-21 13:25:19.000000000,2019-01-07 11:27:30.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-04-21 13:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/af6a849b10fc8346ff4560c8009bc5a321752129', 'message': 'Silence several deprecation warnings that shoulb be remobed in N.\n\nChange-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b\nSigned-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>\n'}, {'number': 2, 'created': '2017-04-21 14:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/444639d2293f5ae420093c8c8da35c99ba8568b6', 'message': 'Silence several deprecation warnings that should be removed in N.\n\nChange-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b\nSigned-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>\n'}, {'number': 3, 'created': '2017-04-24 11:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/9b9babd889fef90e4b056b65d2dba80f036b0bbc', 'message': 'Silence several deprecation warnings that should be removed in N.\n\nChange-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b\nSigned-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>\n'}, {'number': 4, 'created': '2017-04-27 13:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/dc11a0bd08fdb4511d708782fe717901973c32cf', 'message': 'Silence several deprecation warnings that should be removed in N.\n\nChange-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b\nSigned-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>\n'}, {'number': 5, 'created': '2017-04-27 14:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/5398e249d77bd4da247b5122106c6a356b346bb6', 'message': 'Silence several deprecation warnings that should be removed in N.\n\nChange-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b\nSigned-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>\n'}, {'number': 6, 'created': '2017-08-21 22:43:50.000000000', 'files': ['templates/newton/keystone.conf'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/28bee682bc3c1f1f00430a17a1c4c6c0fd9bce10', 'message': 'Silence several deprecation warnings that should be removed in N.\n\nChange-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b\nSigned-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>\n'}]",0,458842,28bee682bc3c1f1f00430a17a1c4c6c0fd9bce10,18,4,6,25817,,,0,"Silence several deprecation warnings that should be removed in N.

Change-Id: I05888870bc9c8579d5c04c79d200ea57a77e711b
Signed-off-by: José Pekkarinen <jose.pekkarinen@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/42/458842/4 && git format-patch -1 --stdout FETCH_HEAD,['templates/newton/keystone.conf'],1,af6a849b10fc8346ff4560c8009bc5a321752129,,"# newton ############################################################################### # [ WARNING ] # Configuration file maintained by Juju. Local changes may be overwritten. ############################################################################### [DEFAULT] admin_token = {{ token }} use_syslog = {{ use_syslog }} log_config_append = /etc/keystone/logging.conf debug = {{ debug }} public_endpoint = {{ public_endpoint }} admin_endpoint = {{ admin_endpoint }} [database] {% if database_host -%} connection = {{ database_type }}://{{ database_user }}:{{ database_password }}@{{ database_host }}/{{ database }}{% if database_ssl_ca %}?ssl_ca={{ database_ssl_ca }}{% if database_ssl_cert %}&ssl_cert={{ database_ssl_cert }}&ssl_key={{ database_ssl_key }}{% endif %}{% endif %} {% else -%} connection = sqlite:////var/lib/keystone/keystone.db {% endif -%} idle_timeout = 200 [identity] driver = {{ identity_backend }} {% if default_domain_id -%} default_domain_id = {{ default_domain_id }} {% endif -%} {% if api_version == 3 -%} domain_specific_drivers_enabled = True domain_config_dir = /etc/keystone/domains {% endif -%} [credential] driver = sql [trust] driver = sql [os_inherit] [catalog] driver = sql [endpoint_filter] [token] driver = sql {% if token_provider == 'pki' -%} provider = keystone.token.providers.pki.Provider {% elif token_provider == 'pkiz' -%} provider = keystone.token.providers.pkiz.Provider {% endif -%} expiration = {{ token_expiration }} {% include ""parts/section-signing"" %} [cache] [policy] driver = sql [assignment] driver = {{ assignment_backend }} [oauth1] [auth] methods = external,password,token,oauth1 [paste_deploy] config_file = /etc/keystone/keystone-paste.ini [extra_headers] Distribution = Ubuntu [ldap] {% if identity_backend == 'ldap' -%} url = {{ ldap_server }} user = {{ ldap_user }} password = {{ ldap_password }} suffix = {{ ldap_suffix }} {% if ldap_config_flags -%} {% for key, value in ldap_config_flags.iteritems() -%} {{ key }} = {{ value }} {% endfor -%} {% endif -%} {% if ldap_readonly -%} user_allow_create = False user_allow_update = False user_allow_delete = False tenant_allow_create = False tenant_allow_update = False tenant_allow_delete = False role_allow_create = False role_allow_update = False role_allow_delete = False group_allow_create = False group_allow_update = False group_allow_delete = False {% endif -%} {% endif -%} {% if api_version == 3 -%} [resource] admin_project_domain_name = {{ admin_domain_name }} admin_project_name = admin {% endif -%} ",,112,0
openstack%2Fcharm-neutron-gateway~master~Id5f9ef64431b08b53d38c035c3405a9f1a6d5f0e,openstack/charm-neutron-gateway,master,Id5f9ef64431b08b53d38c035c3405a9f1a6d5f0e,this charm should be looking for *.init.in.template files,ABANDONED,2017-09-08 13:27:39.000000000,2019-01-07 11:27:14.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 8992}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-09-08 13:27:39.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/108e26abcfcd620c1823b8b5c206e4574796831c', 'message': 'this charm should be looking for *.init.in.template files\n\nChange-Id: Id5f9ef64431b08b53d38c035c3405a9f1a6d5f0e\nSigned-off-by: Szilard Cserey <szilard.cserey@canonical.com>\n'}]",1,502060,108e26abcfcd620c1823b8b5c206e4574796831c,6,4,1,19726,,,0,"this charm should be looking for *.init.in.template files

Change-Id: Id5f9ef64431b08b53d38c035c3405a9f1a6d5f0e
Signed-off-by: Szilard Cserey <szilard.cserey@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/60/502060/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/contrib/openstack/utils.py'],1,108e26abcfcd620c1823b8b5c206e4574796831c,," if f.endswith("".init.in.template""): init_file = f[:-17] if f.endswith("".init.in.template""): init_file = f[:-17]"," if f.endswith("".init.in""): init_file = f[:-8] if f.endswith("".init.in""): init_file = f[:-8]",4,4
openstack%2Fcharm-swift-proxy~master~I0b782992d3dd61227780892973ff447004dd098f,openstack/charm-swift-proxy,master,I0b782992d3dd61227780892973ff447004dd098f,Add update-replicas action,ABANDONED,2017-09-01 05:58:00.000000000,2019-01-07 11:26:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6737}, {'_account_id': 13686}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-09-01 05:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/da73f2ace3d53b676c7b12a2629383b59e692c8a', 'message': ""Add update-replicas action\n\nChange-Id: I0b782992d3dd61227780892973ff447004dd098f\nImplements: blueprint Make ring's replica count adjustable\n""}, {'number': 2, 'created': '2017-09-01 06:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/722b1400a467d823446f42f1e008cf18facea32e', 'message': 'Add update-replicas action\n\nChange-Id: I0b782992d3dd61227780892973ff447004dd098f\nImplements: blueprint adjustable-replica-count\n'}, {'number': 3, 'created': '2017-09-07 22:11:40.000000000', 'files': ['actions/actions.py', 'lib/swift_utils.py', 'actions/update-replicas', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/70ba9141f201344c6fcf457bc40ec2f4edba1d88', 'message': ""Add update-replicas action\n\nChange-Id: I0b782992d3dd61227780892973ff447004dd098f\nImplements: blueprint Make ring's replica count adjustable\n""}]",4,499901,70ba9141f201344c6fcf457bc40ec2f4edba1d88,13,5,3,25011,,,0,"Add update-replicas action

Change-Id: I0b782992d3dd61227780892973ff447004dd098f
Implements: blueprint Make ring's replica count adjustable
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/01/499901/1 && git format-patch -1 --stdout FETCH_HEAD,"['actions/actions.py', 'lib/swift_utils.py', 'actions/update-replicas', 'actions.yaml']",4,da73f2ace3d53b676c7b12a2629383b59e692c8a,bp/Make,"update-replicas: description: | Update object, account, and container server replica count Useful when needing to slowly weight up or down between replica settings Implements 'Make ring's replica count adjustable' blueprint in charm https://blueprints.launchpad.net/swift/+spec/adjustable-replica-counts This action will trigger a rebalance and synchronization of the builder and ring files params: replicas: type: number description: | Number of replicas (floating point replicas can be used to gradually reweight replica changes to reduce replication i/o overhead) Example - 3.0 server: type: string description: | One of ""account"", ""container"", or ""object"". ""all"" can be specified to make the change to all 3 builder/ring settings required: - replicas - server",,123,3
openstack%2Fcharm-specs~master~I2b4735a949d7d228933d6340be17bd3ede98566d,openstack/charm-specs,master,I2b4735a949d7d228933d6340be17bd3ede98566d,Specify the differnet modes the lb can run in,ABANDONED,2017-09-28 18:38:25.000000000,2019-01-07 11:26:48.000000000,,"[{'_account_id': 20635}, {'_account_id': 20805}, {'_account_id': 26040}]","[{'number': 1, 'created': '2017-09-28 18:38:25.000000000', 'files': ['specs/queens/approved/openstack-load-balancer.rst'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/afef59428825c6c5336723468fb6cd05c54b3e9d', 'message': 'Specify the differnet modes the lb can run in\n\nDetail the three main configurations (DNS HA, VIP and external load\nbalancer) that the charm do.\n\nChange-Id: I2b4735a949d7d228933d6340be17bd3ede98566d\n'}]",0,508268,afef59428825c6c5336723468fb6cd05c54b3e9d,5,3,1,12549,,,0,"Specify the differnet modes the lb can run in

Detail the three main configurations (DNS HA, VIP and external load
balancer) that the charm do.

Change-Id: I2b4735a949d7d228933d6340be17bd3ede98566d
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/68/508268/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/approved/openstack-load-balancer.rst'],1,afef59428825c6c5336723468fb6cd05c54b3e9d,osbalancer/deployment-types,"OpenStack Loadbalancer: DNS HA Support -------------------------------------- The loadbalancer charm will support DNS HA. This will allow the loadbalancer units to be spread across different subnets within each network space. The loadbalancer will expose a config option for each space, these can be set to a single dns-entry or a distinct one per endpoint type. .. code-block:: yaml os-public-hostname: type: string default: os-internal-hostname: type: string default: os-admin-hostname: type: string default: dns-ha: type: boolean default: False OpenStack Loadbalancer: External VIP manager -------------------------------------------- The loadbalancer charm will support a vip being managed by an external device (eg F5). In this case the charm is not responsible for managing the vip but does need to expose that vip down to the API charms: .. code-block:: yaml os-public-address: type: string default: os-internal-address: type: string default: os-admin-address: type: string default: vip-ha: type: boolean default: False OpenStack Loadbalancer: VIP --------------------------- The loadbalancer charm will support floating a vip accross all the units in the application. This deployment is restricted to all the units being on the same subnet. .. code-block:: yaml os-public-address: type: string default: os-internal-address: type: string default: os-admin-address: type: string default: vip-ha: type: boolean default: True ",,67,0
openstack%2Fcharm-specs~master~Ia6e2a7dba2f7fe270badd3fdb4984399f2049bba,openstack/charm-specs,master,Ia6e2a7dba2f7fe270badd3fdb4984399f2049bba,Charm lb spec should allow lb to server mulit eps,ABANDONED,2017-09-28 16:15:03.000000000,2019-01-07 11:26:08.000000000,,"[{'_account_id': 20635}, {'_account_id': 20805}]","[{'number': 1, 'created': '2017-09-28 16:15:03.000000000', 'files': ['specs/queens/approved/openstack-load-balancer.rst'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/05745c9e2427c985063bd3122896f74d85a544c6', 'message': 'Charm lb spec should allow lb to server mulit eps\n\nThe charm load balancer spec currently stipulates that a single\nload-balancer application should only manage a single endpoint type.\nThis restriction seems artificial so this patch removes it.\n\nChange-Id: Ia6e2a7dba2f7fe270badd3fdb4984399f2049bba\n'}]",0,508216,05745c9e2427c985063bd3122896f74d85a544c6,4,2,1,12549,,,0,"Charm lb spec should allow lb to server mulit eps

The charm load balancer spec currently stipulates that a single
load-balancer application should only manage a single endpoint type.
This restriction seems artificial so this patch removes it.

Change-Id: Ia6e2a7dba2f7fe270badd3fdb4984399f2049bba
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/16/508216/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/approved/openstack-load-balancer.rst'],1,05745c9e2427c985063bd3122896f74d85a544c6,feature/charm-lb-multi-ep,"A single instance of the OpenStack Loadbalancer application will service one or more of the OpenStack API endpoint types (public, admin or internal). The charm will use the network space binding of the frontend interface to determine which IP or VIP (if deployed in HA configuration) should be used by the backend API service for registration into the Cloud endpoint catalog.","A single instance of the OpenStack Loadbalancer application will only service a single type of OpenStack API endpoint (public, admin or internal). The charm will use the network space binding of the frontend interface to determine which IP or VIP (if deployed in HA configuration) should be used by the backend API service for registration into the Cloud endpoint catalog.",5,5
openstack%2Fcharm-odl-controller~master~I9002f6fd53c648d8402fbf19db400868dcd31fb5,openstack/charm-odl-controller,master,I9002f6fd53c648d8402fbf19db400868dcd31fb5,Enable xenial-pike amulet test,ABANDONED,2017-11-15 22:15:37.000000000,2019-01-07 11:24:20.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 22799}]","[{'number': 1, 'created': '2017-11-15 22:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-odl-controller/commit/25df719ba10316114c75d2503f7990f62a145e75', 'message': 'Enable xenial-pike amulet test\n\nEnable artful-pike amulet test\nMake default func27-smoke xenial-pike\nCharm-helpers sync\n\nChange-Id: I9002f6fd53c648d8402fbf19db400868dcd31fb5\n'}, {'number': 2, 'created': '2017-11-16 02:46:59.000000000', 'files': ['tests/gate-basic-xenial-pike', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'tests/charmhelpers/core/hookenv.py', 'tests/charmhelpers/core/strutils.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/templating.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/templates/section-oslo-cache', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/network/ip.py', 'hooks/charmhelpers/contrib/openstack/files/check_haproxy.sh', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/alternatives.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py', 'hooks/charmhelpers/contrib/openstack/templates/ceph.conf', 'hooks/charmhelpers/core/unitdata.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/storage/linux/utils.py', 'hooks/charmhelpers/fetch/snap.py', 'tests/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/openstack/neutron.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'tests/gate-basic-artful-pike', 'hooks/charmhelpers/contrib/openstack/utils.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'tests/charmhelpers/core/unitdata.py', 'hooks/charmhelpers/core/strutils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-odl-controller/commit/0b37697417f4cd191cde6e8db7ffa610cb5a4eac', 'message': 'Enable xenial-pike amulet test\n\nMake default func27-smoke xenial-pike\nCharm-helpers sync\n\nChange-Id: I9002f6fd53c648d8402fbf19db400868dcd31fb5\n'}]",0,520221,0b37697417f4cd191cde6e8db7ffa610cb5a4eac,11,3,2,22799,,,0,"Enable xenial-pike amulet test

Make default func27-smoke xenial-pike
Charm-helpers sync

Change-Id: I9002f6fd53c648d8402fbf19db400868dcd31fb5
",git fetch https://review.opendev.org/openstack/charm-odl-controller refs/changes/21/520221/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/gate-basic-xenial-pike', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'tests/charmhelpers/core/hookenv.py', 'tests/charmhelpers/core/strutils.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/templating.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/templates/section-oslo-cache', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/network/ip.py', 'hooks/charmhelpers/contrib/openstack/files/check_haproxy.sh', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/alternatives.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py', 'hooks/charmhelpers/contrib/openstack/templates/ceph.conf', 'hooks/charmhelpers/core/unitdata.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/storage/linux/utils.py', 'hooks/charmhelpers/fetch/snap.py', 'tests/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/openstack/neutron.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'tests/gate-basic-artful-pike', 'hooks/charmhelpers/contrib/openstack/utils.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'tests/charmhelpers/core/unitdata.py', 'hooks/charmhelpers/core/strutils.py', 'tox.ini']",31,25df719ba10316114c75d2503f7990f62a145e75,update-amulet-defs, bundletester -vl DEBUG -r json -o func-results.json gate-basic-xenial-pike --no-destroy, bundletester -vl DEBUG -r json -o func-results.json gate-basic-xenial-mitaka --no-destroy,619,176
openstack%2Fcharm-nova-compute-proxy~master~Id807da7077ee9159492d080b75244b7b84d8e644,openstack/charm-nova-compute-proxy,master,Id807da7077ee9159492d080b75244b7b84d8e644,Enable xenial-pike amulet test,ABANDONED,2017-11-15 22:09:57.000000000,2019-01-07 11:24:12.000000000,,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 22799}]","[{'number': 1, 'created': '2017-11-15 22:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-proxy/commit/b2ed11e8ab5b40eb3d245bdd9fca8abb49bcd3aa', 'message': 'Enable xenial-pike amulet test\n\nEnable artful-pike amulet test\nMake default func27-smoke xenial-pike\nCharm-helpers sync\n\nChange-Id: Id807da7077ee9159492d080b75244b7b84d8e644\n'}, {'number': 2, 'created': '2017-11-15 22:12:55.000000000', 'files': ['hooks/charmhelpers/contrib/hahelpers/cluster.py', 'tests/gate-basic-xenial-pike', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'tests/gate-basic-trusty-mitaka', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/templating.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/templates/section-oslo-cache', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/network/ip.py', 'hooks/charmhelpers/contrib/openstack/files/check_haproxy.sh', 'hooks/charmhelpers/contrib/openstack/alternatives.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py', 'hooks/charmhelpers/contrib/openstack/templates/ceph.conf', 'hooks/charmhelpers/core/unitdata.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/storage/linux/utils.py', 'hooks/charmhelpers/fetch/snap.py', 'hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/charmhelpers/contrib/openstack/neutron.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'tests/gate-basic-artful-pike', 'bin/charm_helpers_sync.py', 'hooks/charmhelpers/contrib/hardening/audits/apache.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/core/strutils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-proxy/commit/58b286819a3da9a0719bf84142c5267f7a126cdb', 'message': 'Enable xenial-pike amulet test\n\nEnable artful-pike amulet test\nMake default func27-smoke xenial-pike\nCharm-helpers sync\n\nChange-Id: Id807da7077ee9159492d080b75244b7b84d8e644\n'}]",0,520220,58b286819a3da9a0719bf84142c5267f7a126cdb,9,4,2,22799,,,0,"Enable xenial-pike amulet test

Enable artful-pike amulet test
Make default func27-smoke xenial-pike
Charm-helpers sync

Change-Id: Id807da7077ee9159492d080b75244b7b84d8e644
",git fetch https://review.opendev.org/openstack/charm-nova-compute-proxy refs/changes/20/520220/2 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/hahelpers/cluster.py', 'tests/gate-basic-xenial-pike', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/templating.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/templates/section-oslo-cache', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/network/ip.py', 'hooks/charmhelpers/contrib/openstack/files/check_haproxy.sh', 'hooks/charmhelpers/contrib/openstack/alternatives.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py', 'hooks/charmhelpers/contrib/openstack/templates/ceph.conf', 'hooks/charmhelpers/core/unitdata.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/storage/linux/utils.py', 'tests/gate-basic-trusty-liberty', 'hooks/charmhelpers/fetch/snap.py', 'hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/charmhelpers/contrib/openstack/neutron.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'tests/gate-basic-artful-pike', 'bin/charm_helpers_sync.py', 'hooks/charmhelpers/contrib/hardening/audits/apache.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/core/strutils.py', 'tox.ini']",30,b2ed11e8ab5b40eb3d245bdd9fca8abb49bcd3aa,update-amulet-defs, bundletester -vl DEBUG -r json -o func-results.json gate-basic-xenial-pike --no-destroy, bundletester -vl DEBUG -r json -o func-results.json gate-basic-xenial-mitaka --no-destroy,451,205
openstack%2Fcharm-openvswitch-odl~master~Iab971417e080ba503e17df15bac9fdf4b2e9e318,openstack/charm-openvswitch-odl,master,Iab971417e080ba503e17df15bac9fdf4b2e9e318,Enable xenial-pike amulet test,ABANDONED,2017-11-19 20:49:32.000000000,2019-01-07 11:24:00.000000000,,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 22799}]","[{'number': 1, 'created': '2017-11-19 20:49:32.000000000', 'files': ['src/tox.ini', 'src/tests/gate-basic-xenial-pike'], 'web_link': 'https://opendev.org/openstack/charm-openvswitch-odl/commit/fa023d6a619717e6754e3235d2bdc0dacca93b4c', 'message': 'Enable xenial-pike amulet test\n\nMake default func27-smoke xenial-pike\n\nChange-Id: Iab971417e080ba503e17df15bac9fdf4b2e9e318\n'}]",0,521383,fa023d6a619717e6754e3235d2bdc0dacca93b4c,6,4,1,22799,,,0,"Enable xenial-pike amulet test

Make default func27-smoke xenial-pike

Change-Id: Iab971417e080ba503e17df15bac9fdf4b2e9e318
",git fetch https://review.opendev.org/openstack/charm-openvswitch-odl refs/changes/83/521383/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tox.ini', 'src/tests/gate-basic-xenial-pike']",2,fa023d6a619717e6754e3235d2bdc0dacca93b4c,update-amulet-defs,,,1,1
openstack%2Fcharm-ceilometer~master~Id7d8609eec916685ca327ace4b3cdfa5b06f5f60,openstack/charm-ceilometer,master,Id7d8609eec916685ca327ace4b3cdfa5b06f5f60,Enable xenial-pike amulet test,ABANDONED,2017-11-20 22:55:03.000000000,2019-01-07 11:23:47.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 22799}]","[{'number': 1, 'created': '2017-11-20 22:55:03.000000000', 'files': ['tests/gate-basic-xenial-pike', 'charmhelpers/core/hookenv.py', 'charmhelpers/fetch/snap.py', 'tests/charmhelpers/core/hookenv.py', 'tests/charmhelpers/core/strutils.py', 'charmhelpers/contrib/openstack/templates/ceph.conf', 'charmhelpers/core/strutils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/core/unitdata.py', 'charmhelpers/contrib/hardening/audits/apache.py', 'charmhelpers/contrib/openstack/context.py', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/neutron.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/storage/linux/lvm.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'tests/charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/files/check_haproxy.sh', 'charmhelpers/contrib/storage/linux/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/alternatives.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/openstack/templating.py', 'tests/charmhelpers/core/unitdata.py', 'tox.ini', 'charmhelpers/contrib/openstack/templates/section-oslo-cache'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/f623e1532e6d53a12696e0da57bc4a86a0c9b423', 'message': 'Enable xenial-pike amulet test\n\nMake default func27-smoke xenial-pike\nCharm-helpers sync\n\nChange-Id: Id7d8609eec916685ca327ace4b3cdfa5b06f5f60\n'}]",0,521668,f623e1532e6d53a12696e0da57bc4a86a0c9b423,8,3,1,22799,,,0,"Enable xenial-pike amulet test

Make default func27-smoke xenial-pike
Charm-helpers sync

Change-Id: Id7d8609eec916685ca327ace4b3cdfa5b06f5f60
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/68/521668/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/gate-basic-xenial-pike', 'charmhelpers/core/hookenv.py', 'charmhelpers/fetch/snap.py', 'tests/charmhelpers/core/hookenv.py', 'tests/charmhelpers/core/strutils.py', 'charmhelpers/contrib/openstack/templates/ceph.conf', 'charmhelpers/core/strutils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/core/unitdata.py', 'charmhelpers/contrib/hardening/audits/apache.py', 'charmhelpers/contrib/openstack/context.py', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/neutron.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/storage/linux/lvm.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'tests/charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/files/check_haproxy.sh', 'charmhelpers/contrib/storage/linux/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/alternatives.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/openstack/templating.py', 'tests/charmhelpers/core/unitdata.py', 'tox.ini', 'charmhelpers/contrib/openstack/templates/section-oslo-cache']",33,f623e1532e6d53a12696e0da57bc4a86a0c9b423,update-amulet-defs,[cache] {% if memcache_url %} enabled = true backend = oslo_cache.memcache_pool memcache_servers = {{ memcache_url }} {% endif %} ,,677,184
openstack%2Fcharm-designate~master~I08df9dbc185877ca82e6bf539b9f56391ead2f35,openstack/charm-designate,master,I08df9dbc185877ca82e6bf539b9f56391ead2f35,Partial-Bug: 1704769,ABANDONED,2017-08-29 13:11:27.000000000,2019-01-07 11:23:13.000000000,,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 20870}]","[{'number': 1, 'created': '2017-08-29 13:11:27.000000000', 'files': ['src/README.md', 'src/config.yaml', 'unit_tests/test_designate_handlers.py', 'src/lib/charm/openstack/designate.py', 'src/reactive/designate_handlers.py', 'src/metadata.yaml', 'src/layer.yaml'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/8a97c048f40c3de370831d898e39a95dcca9b18f', 'message': 'Partial-Bug: 1704769\n\nI have implemented a new relation (""external-dns"") which uses a new interface\n(""endpoint"") between ""designate"" and ""neutron-api"" charms.\n\nOnce the relation is established, the ""designate"" charm exposes its internal\nAPI endpoint through relation data. The ""neutron-api"" charm consumes these\ndata and updates Neutron configuration files as described here:\n\nhttps://docs.openstack.org/mitaka/networking-guide/config-dns-int.html\n\nChange-Id: I08df9dbc185877ca82e6bf539b9f56391ead2f35\n'}]",0,498806,8a97c048f40c3de370831d898e39a95dcca9b18f,9,3,1,24504,,,0,"Partial-Bug: 1704769

I have implemented a new relation (""external-dns"") which uses a new interface
(""endpoint"") between ""designate"" and ""neutron-api"" charms.

Once the relation is established, the ""designate"" charm exposes its internal
API endpoint through relation data. The ""neutron-api"" charm consumes these
data and updates Neutron configuration files as described here:

https://docs.openstack.org/mitaka/networking-guide/config-dns-int.html

Change-Id: I08df9dbc185877ca82e6bf539b9f56391ead2f35
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/06/498806/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/README.md', 'src/config.yaml', 'src/lib/charm/openstack/designate.py', 'unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py', 'src/metadata.yaml', 'src/layer.yaml']",7,8a97c048f40c3de370831d898e39a95dcca9b18f,bug/1704769,"includes: ['layer:openstack-api', 'interface:bind-rndc', 'interface:hacluster', 'interface:openstack-ha', 'interface:endpoint']","includes: ['layer:openstack-api', 'interface:bind-rndc', 'interface:hacluster', 'interface:openstack-ha']",50,10
openstack%2Fcharm-keystone~master~I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae,openstack/charm-keystone,master,I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae,"Related-Bug: 1671506 Configure federated authentication, SAML2 and OIDC",ABANDONED,2017-03-10 13:39:39.000000000,2019-01-07 11:23:02.000000000,,"[{'_account_id': 935}, {'_account_id': 10068}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-03-10 13:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/26fa47e50b7b2d6b13d4cbb28b4edcd4bbaa54ad', 'message': 'Related-Bug: 1671506\n\n2017-03-10:  FG;  Initial set of changes needed to support Federated authentication and OIDC in Keystone.\n\nChange-Id: I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae\n'}, {'number': 2, 'created': '2017-03-10 14:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b8d958219076ffa89cc37bdb2a2333a3eee79b0d', 'message': 'Related-Bug: 1671506\n\n2017-03-10:  FG;  First set of changes to keystone.conf and wsgi-openstack-api\n        (which will eventually be dealt with in charm-helpers).\n\nChange-Id: I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae\nSigned-off-by: Fulvio Galeazzi <fulvio.galeazzi@gmail.com>\n'}, {'number': 3, 'created': '2017-07-06 15:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/bedb3e915996bb9043063ef912bd9ff1947b5171', 'message': 'Related-Bug: 1671506\n\nConfigure federated authentication, SAML2 and OIDC\n\nThis work extends Keystone functionality by configuring federated\nauthentication leveraging SAML2 Identity Providers and the Google\nOpenID Connect Provider.\nSAML2 authentication is in widespread use in the world of Research\nand Education Networks, with national federations in Europe being\ninterconnected by eduGAIN (edugain.org).\n\n2017-05-19:  FG;  Completed changes to configure (config.yaml,\n\t     keystone.conf, keystone_context.py, keystone_utils.py,\n\t     wsgi-openstack-api.conf and templates) and activate (handful\n\t     of REST calls in keystone_hooks.py config_postupgrade)\n\t     support for federated authentication.\n\n\t     SAML2 and OIDC parts can be independently configured via\n\t     enable-saml2 and enable-oidc config.yaml switches, which are\n\t     both by default set to false, so should not break anything.\n\n\t     This charms implements what is in production at GARR\n\t     cloud, described at:\n\t     \t  https://cloud.garr.it/support/kb/cloud/federated_auth/\n\t     and corresponds to: cs:~garrcsd/keystone-fed-14\n\n \t     Since this work started, keystone HEAD has moved forward:\n\t     will tackle this at next commit.\n\n2017-03-10:  FG;  First set of changes to keystone.conf and wsgi-openstack-api\n        (which will eventually be dealt with in charm-helpers).\n\nChange-Id: I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae\nSigned-off-by: Fulvio Galeazzi <fulvio.galeazzi@gmail.com>\n'}, {'number': 4, 'created': '2017-09-13 15:29:30.000000000', 'files': ['templates/mitaka/saml2_mapping.json', 'templates/mitaka/shibboleth2.xml', 'hooks/keystone_utils.py', 'config.yaml', 'hooks/keystone_hooks.py', 'templates/mitaka/oidc_mapping.json', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf', 'templates/mitaka/attribute-map.xml', 'README.md', 'templates/mitaka/attribute-policy.xml', 'templates/mitaka/keystone.conf', 'hooks/keystone_context.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/44669be1df1d5faeac2f0001fd10da23fbb949ca', 'message': 'Related-Bug: 1671506 Configure federated authentication, SAML2 and OIDC\n\nThis work extends Keystone functionality by configuring federated\nauthentication leveraging SAML2 Identity Providers and the Google\nOpenID Connect Provider.\nSAML2 authentication is in widespread use in the world of Research and\nEducation Networks, with national federations in Europe being\ninterconnected by eduGAIN (edugain.org).\n\nCompleted changes to configure (config.yaml, keystone.conf,\nkeystone_context.py, keystone_utils.py, wsgi-openstack-api.conf and\ntemplates) and activate (handful of REST calls in keystone_hooks.py config_postupgrade) support for federated authentication.\n\nSAML2 and OIDC parts can be independently configured via enable-saml2\nand enable-oidc config.yaml switches, which are both by default set to\nfalse, so should not break anything.\n\nThis charms implements what is in production at GARR cloud, described\nat: https://cloud.garr.it/support/kb/cloud/federated_auth/ and\ncorresponds to: cs:~csd-garr/keystone-fed-4\n\nChange-Id: I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae\nSigned-off-by: Fulvio Galeazzi <fulvio.galeazzi@gmail.com>\n'}]",8,444299,44669be1df1d5faeac2f0001fd10da23fbb949ca,18,3,4,25409,,,0,"Related-Bug: 1671506 Configure federated authentication, SAML2 and OIDC

This work extends Keystone functionality by configuring federated
authentication leveraging SAML2 Identity Providers and the Google
OpenID Connect Provider.
SAML2 authentication is in widespread use in the world of Research and
Education Networks, with national federations in Europe being
interconnected by eduGAIN (edugain.org).

Completed changes to configure (config.yaml, keystone.conf,
keystone_context.py, keystone_utils.py, wsgi-openstack-api.conf and
templates) and activate (handful of REST calls in keystone_hooks.py config_postupgrade) support for federated authentication.

SAML2 and OIDC parts can be independently configured via enable-saml2
and enable-oidc config.yaml switches, which are both by default set to
false, so should not break anything.

This charms implements what is in production at GARR cloud, described
at: https://cloud.garr.it/support/kb/cloud/federated_auth/ and
corresponds to: cs:~csd-garr/keystone-fed-4

Change-Id: I6bf80e3b23e8219ba6f8b293fb048c97bd75c8ae
Signed-off-by: Fulvio Galeazzi <fulvio.galeazzi@gmail.com>
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/99/444299/4 && git format-patch -1 --stdout FETCH_HEAD,['config.yaml'],1,26fa47e50b7b2d6b13d4cbb28b4edcd4bbaa54ad,bug/1671506," # Federation settings # SAML federation settings enable-saml2: type: boolean default: False description: | Enable support for SAML federations. If this is set, then all following saml2- settings are considered. saml2-metadata-url: type: string default: None description: URL at which federation metadata is kept. saml2-metadata-signer-url: type: string default: None description: URL of the certificate used to sign metadata. saml2-discovery-url: type: string default: None description: URL of the WhereAreYouFrom service shibsp-application-id: type: string default: None description: ID of the federation (e.g., idem-fed) # OIDC settings enable-oidc: type: boolean default: False description: | Enable support for OIDC authentication. If this is set, then all following oidc- settings are considered. oidc-provider-metadata-url: type: string default: None description: URL of the OIDC provider metadata. oidc-client-id: type: string default: None description: OIDC client ID. oidc-client-secret: type: string default: None description: OIDC client secret. oidc-crypto-passphrase: type: string default: None description: OIDC crypto passphrase. oidc-redirect-uri: type: string default: None description: OIDC redirect URI. oidc-op-id: type: string default: None description: ID of the OIDC entity (e.g., google).",,55,0
openstack%2Fcharm-openstack-dashboard~master~I558dc686715e787ae5d95678e1e015355d4f106d,openstack/charm-openstack-dashboard,master,I558dc686715e787ae5d95678e1e015355d4f106d,[stormmore] Add config option for exposing HAProxy stats interface,ABANDONED,2017-08-11 14:43:39.000000000,2019-01-07 11:22:42.000000000,,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20870}]","[{'number': 1, 'created': '2017-08-11 14:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/fdda49405b98fa1f306cf05f8424adf65235b6fc', 'message': '[stormmore] Add config option for exposing HAProxy stats interface\n\nAdded expose-haproxy-stats as a configuration option to the charm\n\nBug:\nChange-Id: I558dc686715e787ae5d95678e1e015355d4f106d\n'}, {'number': 2, 'created': '2017-08-11 14:46:54.000000000', 'files': ['hooks/horizon_contexts.py', 'templates/haproxy.cfg', 'unit_tests/test_horizon_contexts.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/385227e5f1af016697673843d902e1dde86e9e78', 'message': '[stormmore] Add config option for exposing HAProxy stats interface\n\nAdded expose-haproxy-stats as a configuration option to the charm\n\nBug: Issue 1710208\nChange-Id: I558dc686715e787ae5d95678e1e015355d4f106d\n'}]",4,493029,385227e5f1af016697673843d902e1dde86e9e78,9,3,2,26625,,,0,"[stormmore] Add config option for exposing HAProxy stats interface

Added expose-haproxy-stats as a configuration option to the charm

Bug: Issue 1710208
Change-Id: I558dc686715e787ae5d95678e1e015355d4f106d
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/29/493029/2 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'templates/haproxy.cfg', 'unit_tests/test_horizon_contexts.py', 'config.yaml']",4,fdda49405b98fa1f306cf05f8424adf65235b6fc,haproxy_fix," expose-haproxy-stats: default: False type: boolean description: If True, exposes the HAProxy stats interface globally.",,26,4
openstack%2Fcharm-neutron-api~master~Ic917e2937719998c934d1f9c85637df61e4699fb,openstack/charm-neutron-api,master,Ic917e2937719998c934d1f9c85637df61e4699fb,Partial-Bug: 1704769,ABANDONED,2017-08-29 13:11:57.000000000,2019-01-07 11:22:28.000000000,,"[{'_account_id': 935}, {'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20870}]","[{'number': 1, 'created': '2017-08-29 13:11:57.000000000', 'files': ['hooks/external-dns-relation-changed', 'templates/parts/section-designate', 'hooks/neutron_api_hooks.py', 'hooks/neutron_api_utils.py', 'templates/mitaka/neutron.conf', 'hooks/external-dns-relation-joined', 'README.md', 'hooks/external-dns-relation-departed', 'hooks/neutron_api_context.py', 'hooks/external-dns-relation-broken', 'unit_tests/test_neutron_api_context.py', 'metadata.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/ae6b81d3576e1ab3a6ac1e041279b3f9a694ae8f', 'message': 'Partial-Bug: 1704769\n\nI have implemented a new relation (""external-dns"") which uses a new interface\n(""endpoint"") between ""designate"" and ""neutron-api"" charms.\n\nOnce the relation is established, the ""designate"" charm exposes its internal\nAPI endpoint through relation data. The ""neutron-api"" charm consumes these\ndata and updates Neutron configuration files as described here:\n\nhttps://docs.openstack.org/mitaka/networking-guide/config-dns-int.html\n\nChange-Id: Ic917e2937719998c934d1f9c85637df61e4699fb\n'}]",7,498808,ae6b81d3576e1ab3a6ac1e041279b3f9a694ae8f,9,4,1,24504,,,0,"Partial-Bug: 1704769

I have implemented a new relation (""external-dns"") which uses a new interface
(""endpoint"") between ""designate"" and ""neutron-api"" charms.

Once the relation is established, the ""designate"" charm exposes its internal
API endpoint through relation data. The ""neutron-api"" charm consumes these
data and updates Neutron configuration files as described here:

https://docs.openstack.org/mitaka/networking-guide/config-dns-int.html

Change-Id: Ic917e2937719998c934d1f9c85637df61e4699fb
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/08/498808/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/external-dns-relation-changed', 'templates/parts/section-designate', 'hooks/neutron_api_hooks.py', 'hooks/neutron_api_utils.py', 'templates/mitaka/neutron.conf', 'hooks/external-dns-relation-joined', 'README.md', 'hooks/external-dns-relation-departed', 'hooks/neutron_api_context.py', 'hooks/external-dns-relation-broken', 'unit_tests/test_neutron_api_context.py', 'metadata.yaml']",12,ae6b81d3576e1ab3a6ac1e041279b3f9a694ae8f,bug/1704769, external-dns: interface: endpoint,,94,8
openstack%2Fcharm-keystone~master~I982aa4f410bbcf24ab33dcc049ba07d5c0eceb75,openstack/charm-keystone,master,I982aa4f410bbcf24ab33dcc049ba07d5c0eceb75,Adds support for overriding policy.json in ocata,ABANDONED,2017-07-21 08:23:11.000000000,2019-01-07 11:22:15.000000000,,"[{'_account_id': 10068}, {'_account_id': 13686}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-07-21 08:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b651abdbbd1802198b0ed671fac44be2db933f10', 'message': 'Adds support for overriding policy.json in ocata\n\nIn OpenStack deployments using external RBAC more fine-grained\ncontrol of policy can be desireable. This PR adds a config option\nto pass a base64 encoded string representing a custom policy.json\ninto the charm in ocata and higher. If this config option is\npresent the string is decoded and passed into the existing template\nas a total override of its contents. This obviously allows users\nto shoot themselves in the foot, but unsetting the config option\nwill revert the policy to its original state following a\nconfig-changed hook.\n\nChange-Id: I982aa4f410bbcf24ab33dcc049ba07d5c0eceb75\n'}, {'number': 2, 'created': '2017-07-21 12:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/8a7c5e25c4c047eafa2e417ea6a6fb1b1332aea8', 'message': 'Adds support for overriding policy.json in ocata\n\nIn OpenStack deployments using external RBAC more fine-grained\ncontrol of policy can be desireable. This PR adds a config option\nto pass a base64 encoded string representing a custom policy.json\ntemplate into the charm. If this config option is present the\nstring is decoded and rendered out to a location on disk.\nIn conjunction with a change to how\ncharmhelpers.contrib.openstack.templating.py operates allows the\ndecoded template to be selected. This obviously allows users\nto shoot themselves in the foot, but unsetting the config option\nwill revert the policy to its original state following a\nconfig-changed hook.\n\nChange-Id: I982aa4f410bbcf24ab33dcc049ba07d5c0eceb75\n'}, {'number': 3, 'created': '2017-09-06 14:14:17.000000000', 'files': ['config.yaml', 'hooks/keystone_hooks.py', 'hooks/keystone_context.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/f785b23b8b17ddff0ebfa00d284a005a9f49a3cc', 'message': 'Adds support for overriding policy.json in ocata\n\nIn OpenStack deployments using external RBAC more fine-grained\ncontrol of policy can be desireable. This PR adds a config option\nto pass a base64 encoded string representing a custom policy.json\ntemplate into the charm. If this config option is present the\nstring is decoded and rendered out to a location on disk.\nIn conjunction with a change to how\ncharmhelpers.contrib.openstack.templating.py operates allows the\ndecoded template to be selected. This obviously allows users\nto shoot themselves in the foot, but unsetting the config option\nwill revert the policy to its original state following a\nconfig-changed hook.\n\nChange-Id: I982aa4f410bbcf24ab33dcc049ba07d5c0eceb75\n'}]",0,486041,f785b23b8b17ddff0ebfa00d284a005a9f49a3cc,15,3,3,26460,,,0,"Adds support for overriding policy.json in ocata

In OpenStack deployments using external RBAC more fine-grained
control of policy can be desireable. This PR adds a config option
to pass a base64 encoded string representing a custom policy.json
template into the charm. If this config option is present the
string is decoded and rendered out to a location on disk.
In conjunction with a change to how
charmhelpers.contrib.openstack.templating.py operates allows the
decoded template to be selected. This obviously allows users
to shoot themselves in the foot, but unsetting the config option
will revert the policy to its original state following a
config-changed hook.

Change-Id: I982aa4f410bbcf24ab33dcc049ba07d5c0eceb75
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/41/486041/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/ocata/policy.json', 'config.yaml', 'hooks/keystone_context.py']",3,b651abdbbd1802198b0ed671fac44be2db933f10,policy.json-override," import binascii ERROR, if config('policy-override'): ctxt['policy_override'] = True try: ctxt['custom_policy'] = b64decode(config('policy-override')) except binascii.Error as e: log('Could not decode policy.json override', level=ERROR) raise e ",,20,2
openstack%2Fcharm-interface-service-control~master~I1eca0a509601de536c5c5f5879f8dc6fd8b4e6d7,openstack/charm-interface-service-control,master,I1eca0a509601de536c5c5f5879f8dc6fd8b4e6d7,Replaced uuid.uuid4 with uuidutils.generate_uuid,ABANDONED,2017-06-28 04:33:21.000000000,2019-01-07 11:21:58.000000000,,"[{'_account_id': 17130}, {'_account_id': 20648}, {'_account_id': 25903}]","[{'number': 1, 'created': '2017-06-28 04:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-interface-service-control/commit/e6741f85b194567e9f57c886f92176b1595f24a1', 'message': 'Replaced uuid.uuid4 with uuidutils.generate_uuid()\n\nChange-Id: I1eca0a509601de536c5c5f5879f8dc6fd8b4e6d7\n'}, {'number': 2, 'created': '2017-06-28 04:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-interface-service-control/commit/cb5676714aa794907934d1f0a68f1d94c5d721f2', 'message': 'Replaced uuid.uuid4 with uuidutils.generate_uuid()\n\nOpenstack common has a wrapper for generating uuids.We should\nuse that function when generating uuids for consistency.\n\nChange-Id: I1eca0a509601de536c5c5f5879f8dc6fd8b4e6d7\n'}, {'number': 3, 'created': '2017-06-30 12:37:37.000000000', 'files': ['requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-service-control/commit/090244f03895e3f30a2d0e0be5d629aa3909344d', 'message': 'Replaced uuid.uuid4 with uuidutils.generate_uuid\n\nOpenstack common has a wrapper for generating uuids.We should\nuse that function when generating uuids for consistency.\n\nChange-Id: I1eca0a509601de536c5c5f5879f8dc6fd8b4e6d7\n'}]",0,478376,090244f03895e3f30a2d0e0be5d629aa3909344d,12,3,3,25005,,,0,"Replaced uuid.uuid4 with uuidutils.generate_uuid

Openstack common has a wrapper for generating uuids.We should
use that function when generating uuids for consistency.

Change-Id: I1eca0a509601de536c5c5f5879f8dc6fd8b4e6d7
",git fetch https://review.opendev.org/openstack/charm-interface-service-control refs/changes/76/478376/1 && git format-patch -1 --stdout FETCH_HEAD,['requires.py'],1,e6741f85b194567e9f57c886f92176b1595f24a1,uuid,"from oslo_utils import uuidutils key: uuidutils.generate_uuid(),","import uuid key: str(uuid.uuid4()),",3,3
openstack%2Fcharm-ceph-osd~master~I9f2dfd4c2ceda0e6e486792a39cbcdcd67d4a8dd,openstack/charm-ceph-osd,master,I9f2dfd4c2ceda0e6e486792a39cbcdcd67d4a8dd,Add support of an optional journal zapping config.,ABANDONED,2016-10-26 22:40:50.000000000,2019-01-07 11:21:27.000000000,,"[{'_account_id': 10068}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20812}, {'_account_id': 23310}]","[{'number': 1, 'created': '2016-10-26 22:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/ad05f2efb5fd6ca483f4cda524bf27b648fad200', 'message': 'Add new config to the charm that make zapping journals optional.\nconfig: ""zap-journals""\ntype: boolean\nCloses-Bug: #1637003\n\nChange-Id: I9f2dfd4c2ceda0e6e486792a39cbcdcd67d4a8dd\n'}, {'number': 2, 'created': '2016-10-26 23:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/a9ed7b88db54f0b873a829a596dc8b8f0eb90121', 'message': 'Add support of an optional journal zapping.\n\nA new boolean config option ""zap-journals"" to be able to activate or\ndesactivate journal zapping when deploying ceph-osd charm. The default\nvalue for this option is ""True"".\nProblem: To migrate an existing node into a Juju managed Ceph cluster,\nthe journal always gets zapped if it is on an external disk. This will\ncause the loss of the OSD.\n\nCloses-Bug: #1637003\n\nChange-Id: I9f2dfd4c2ceda0e6e486792a39cbcdcd67d4a8dd\n'}, {'number': 3, 'created': '2016-10-26 23:19:53.000000000', 'files': ['hooks/ceph_hooks.py', 'unit_tests/test_ceph_hooks.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/1063fe1ebdb33a7fa248697a4281c828ffbf6b11', 'message': 'Add support of an optional journal zapping config.\n\nAdd a new boolean config option ""zap-journals"" to be able to activate or\ndesactivate journal zapping when deploying ceph-osd charm. The default\nvalue for this option is ""True"".\nProblem: To migrate an existing node into a Juju managed Ceph cluster,\nthe journal always gets zapped if it is on an external disk. This will\ncause the loss of the OSD.\n\nCloses-Bug: #1637003\n\nChange-Id: I9f2dfd4c2ceda0e6e486792a39cbcdcd67d4a8dd\n'}]",0,390985,1063fe1ebdb33a7fa248697a4281c828ffbf6b11,21,6,3,23969,,,0,"Add support of an optional journal zapping config.

Add a new boolean config option ""zap-journals"" to be able to activate or
desactivate journal zapping when deploying ceph-osd charm. The default
value for this option is ""True"".
Problem: To migrate an existing node into a Juju managed Ceph cluster,
the journal always gets zapped if it is on an external disk. This will
cause the loss of the OSD.

Closes-Bug: #1637003

Change-Id: I9f2dfd4c2ceda0e6e486792a39cbcdcd67d4a8dd
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/85/390985/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/ceph_hooks.py', 'unit_tests/test_ceph_hooks.py', 'config.yaml']",3,ad05f2efb5fd6ca483f4cda524bf27b648fad200,bug/1637003, zap-journals: type: boolean default: True description: | By default the charm will zap (delete the partition table) of all disks. This option is added to prevent this behaviour for specific use cases.,,49,2
openstack%2Fcharm-neutron-api~master~Icbc0dfea9ebc06c05616e2d1c6a85f93af4e4428,openstack/charm-neutron-api,master,Icbc0dfea9ebc06c05616e2d1c6a85f93af4e4428,Allow using a newer etcd package than in the Ubuntu archive,ABANDONED,2016-10-05 16:51:02.000000000,2019-01-07 11:20:53.000000000,,"[{'_account_id': 935}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-10-05 16:51:02.000000000', 'files': ['hooks/neutron_api_hooks.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/b3a9dec28000469149cd98fd39fd54aa84a1ec44', 'message': 'Allow using a newer etcd package than in the Ubuntu archive\n\nThis is motivated by the problem reported at\nhttps://bugs.launchpad.net/ubuntu/+source/etcd/+bug/1620897.  The\ncurrent etcd in Xenial has a serious problem with its proxy function,\nand I need a way for a current customer deployment to be able to use a\nnewer (and fixed!) etcd package, until that problem is fixed in the\nXenial archive.\n\nChange-Id: Icbc0dfea9ebc06c05616e2d1c6a85f93af4e4428\n'}]",1,382566,b3a9dec28000469149cd98fd39fd54aa84a1ec44,9,3,1,13734,,,0,"Allow using a newer etcd package than in the Ubuntu archive

This is motivated by the problem reported at
https://bugs.launchpad.net/ubuntu/+source/etcd/+bug/1620897.  The
current etcd in Xenial has a serious problem with its proxy function,
and I need a way for a current customer deployment to be able to use a
newer (and fixed!) etcd package, until that problem is fixed in the
Xenial archive.

Change-Id: Icbc0dfea9ebc06c05616e2d1c6a85f93af4e4428
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/66/382566/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/neutron_api_hooks.py', 'config.yaml']",2,b3a9dec28000469149cd98fd39fd54aa84a1ec44,alternate-etcd," etcd-package-url: default: type: string description: | URL for an etcd package to install. If this URL has a newer package version than the current package in the Ubuntu archive, it will replace the Ubuntu archive package. Example: http://launchpadlibrarian.net/274096873/etcd_2.3.7+dfsg-4_amd64.deb",,21,0
openstack%2Fkayobe~stable%2Fqueens~Ia3eb39cf81cb3618fd94c4456bd576b52098c946,openstack/kayobe,stable/queens,Ia3eb39cf81cb3618fd94c4456bd576b52098c946,Test upgrading seed services in CI,MERGED,2018-12-20 19:48:01.000000000,2019-01-07 11:17:45.000000000,2019-01-07 11:17:45.000000000,"[{'_account_id': 14826}, {'_account_id': 16984}, {'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-20 19:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/afb1937d86fbbc916ed478bb99754d59237c2ebb', 'message': 'Test upgrading seed services in CI\n\nAdds the kayobe-seed-upgrade-centos job, which performs an upgrade of\nthe seed services from the previous release to the current release.\n\nChange-Id: Ia3eb39cf81cb3618fd94c4456bd576b52098c946\nStory: 2004308\nTask: 27873\n(cherry picked from commit 390af7a06b321368776f8a5d005f27ad0928d37e)\n'}, {'number': 2, 'created': '2018-12-21 09:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/18199164d3c2f2badbcb43941d64deb372062e28', 'message': 'Test upgrading seed services in CI\n\nAdds the kayobe-seed-upgrade-centos job, which performs an upgrade of\nthe seed services from the previous release to the current release.\n\nChange-Id: Ia3eb39cf81cb3618fd94c4456bd576b52098c946\nStory: 2004308\nTask: 27873\n(cherry picked from commit 390af7a06b321368776f8a5d005f27ad0928d37e)\n'}, {'number': 3, 'created': '2019-01-04 13:41:37.000000000', 'files': ['playbooks/kayobe-seed-upgrade-base/bifrost-overrides.yml.j2', 'playbooks/kayobe-seed-upgrade-base/run.yml', 'doc/source/development/automated.rst', 'playbooks/kayobe-seed-upgrade-base/pre.yml', 'dev/functions', 'dev/seed-upgrade.sh', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml', 'playbooks/kayobe-seed-upgrade-base/overrides.yml.j2', 'playbooks/kayobe-seed-upgrade-base/post.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/68d0d5c2110311bee4c4974313d19e685a0625ea', 'message': 'Test upgrading seed services in CI\n\nAdds the kayobe-seed-upgrade-centos job, which performs an upgrade of\nthe seed services from the previous release to the current release.\n\nChange-Id: Ia3eb39cf81cb3618fd94c4456bd576b52098c946\nStory: 2004308\nTask: 27873\n(cherry picked from commit 390af7a06b321368776f8a5d005f27ad0928d37e)\n'}]",0,626670,68d0d5c2110311bee4c4974313d19e685a0625ea,13,4,3,14826,,,0,"Test upgrading seed services in CI

Adds the kayobe-seed-upgrade-centos job, which performs an upgrade of
the seed services from the previous release to the current release.

Change-Id: Ia3eb39cf81cb3618fd94c4456bd576b52098c946
Story: 2004308
Task: 27873
(cherry picked from commit 390af7a06b321368776f8a5d005f27ad0928d37e)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/70/626670/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/kayobe-seed-upgrade-base/bifrost-overrides.yml.j2', 'playbooks/kayobe-seed-upgrade-base/run.yml', 'doc/source/development/automated.rst', 'playbooks/kayobe-seed-upgrade-base/pre.yml', 'dev/functions', 'dev/seed-upgrade.sh', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml', 'playbooks/kayobe-seed-upgrade-base/overrides.yml.j2', 'playbooks/kayobe-seed-upgrade-base/post.yml']",10,afb1937d86fbbc916ed478bb99754d59237c2ebb,story/2004308-stable/queens,"--- - hosts: all roles: - role: kayobe-diagnostics kayobe_diagnostics_phase: ""post"" kayobe_diagnostics_log_dir: ""/tmp/logs"" kayobe_diagnostics_config_dir: ""{{ ansible_env.PWD ~ '/' ~ zuul.projects['git.openstack.org/openstack/kayobe-config-dev'].src_dir }}"" kayobe_diagnostics_previous_config_dir: ""{{ ansible_env.PWD ~ '/previous/kayobe-config' }}"" kayobe_diagnostics_executor_log_dir: ""{{ zuul.executor.log_root }}/{{ inventory_hostname }}"" ",,329,29
openstack%2Fcharm-cloudkitty~master~I879bf7a4b35317d349259c972f3876e967cc5f06,openstack/charm-cloudkitty,master,I879bf7a4b35317d349259c972f3876e967cc5f06,Initialize repository,ABANDONED,2016-12-14 14:24:42.000000000,2019-01-07 11:15:52.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 2376}, {'_account_id': 20648}, {'_account_id': 23060}]","[{'number': 1, 'created': '2016-12-14 14:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/e6b42932a45ad0b564bba077b8b3545f21a216bb', 'message': '[WIP] Initialize repository\n\nThis adds the source files for the CloudKitty charm.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 2, 'created': '2016-12-15 16:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/3b890c9ec5806061fd846b6196a69c5c8416c55a', 'message': '[WIP] Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as unit tests.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 3, 'created': '2016-12-15 16:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/bcf91d3ce2c8bf5aac1a5c41ffa1c460556c02e9', 'message': '[WIP] Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as unit tests.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 4, 'created': '2016-12-15 16:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/9bb2b5eca447ffc29b16c68beda8e3b28dca1572', 'message': '[WIP] Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 5, 'created': '2016-12-16 10:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/d90ac4a069ad66db6365fc25967ed31243283f53', 'message': '[WIP] Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 6, 'created': '2017-01-30 14:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/f9b1a30495f7ec24ce302c427a56d533315c848e', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 7, 'created': '2017-01-30 14:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/2be3197a814c12f61347e005315f1d9dbb16034c', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 8, 'created': '2017-01-30 14:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/67829262049765b3e2c5e2847235ee37f8168f6a', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 9, 'created': '2017-01-30 15:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/d6037ed1c87f5905c106bb691fddae21cd9b2815', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 10, 'created': '2017-01-30 16:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/f8ade2be550c356411a498f8ca53ac392f0a5d4f', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 11, 'created': '2017-01-30 16:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/7fb0d4033f47f6d3296cf2978f08c3e86ea30301', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 12, 'created': '2017-02-02 17:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/ff92d23263bb5d5d3f7a2a7584f0bd967f1ac19d', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 13, 'created': '2017-02-02 18:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/bce49131bf8d858b28518265139fbe039dc0c725', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 14, 'created': '2017-02-02 19:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/740220b6885110492cba783d0bf5d97805ef77fb', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 15, 'created': '2017-02-06 15:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/301c5bd8f3af54d1bd3df8b14a813f6c8cfa90a8', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 16, 'created': '2017-02-06 15:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/bc507c009a62da9aba972703dc0162162ca285f0', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}, {'number': 17, 'created': '2017-02-06 16:36:29.000000000', 'files': ['copyright', '.gitignore', 'test-requirements.txt', 'src/tox.ini', 'src/metadata.yaml', 'src/test-requirements.txt', 'src/layer.yaml', 'unit_tests/test_lib_charm_openstack_cloudkitty.py', 'requirements.txt', 'src/lib/charm/openstack/cloudkitty.py', 'src/reactive/cloudkitty_handlers.py', 'src/templates/newton/cloudkitty.conf', 'src/templates/parts/section-ks-auth', 'src/lib/charm/openstack/__init__.py', 'unit_tests/__init__.py', 'src/tests/gate-basic-xenial-newton', 'src/tests/tests.yaml', 'README.md', 'src/README.md', 'src/copyright', 'src/icon.svg', 'src/tests/basic_deployment.py', '.testr.conf', 'unit_tests/test_cloudkitty_handlers.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-cloudkitty/commit/b4a5b8d24b029931c16e73902da8119cac65a56c', 'message': 'Initialize repository\n\nThis adds the source files for the CloudKitty charm as well as\nunit tests and a single amulet test.\n\nChange-Id: I879bf7a4b35317d349259c972f3876e967cc5f06\n'}]",2,410779,b4a5b8d24b029931c16e73902da8119cac65a56c,56,5,17,23060,,,0,"Initialize repository

This adds the source files for the CloudKitty charm as well as
unit tests and a single amulet test.

Change-Id: I879bf7a4b35317d349259c972f3876e967cc5f06
",git fetch https://review.opendev.org/openstack/charm-cloudkitty refs/changes/79/410779/17 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/__init__.py', 'copyright', 'src/metadata.yaml', 'README.md', 'src/layer.yaml', 'src/README.md', 'src/config.yaml', 'src/lib/charm/openstack/cloudkitty.py', 'src/copyright', 'src/icon.svg', 'src/reactive/cloudkitty_handlers.py', 'src/templates/newton/cloudkitty.conf', 'src/templates/parts/section-ks-auth']",13,e6b42932a45ad0b564bba077b8b3545f21a216bb,initial-commit,{% if identity_service.auth_host -%} auth_uri = {{ identity_service.service_protocol }}://{{ identity_service.service_host }}:{{ identity_service.service_port }} auth_url = {{ identity_service.auth_protocol }}://{{ identity_service.auth_host }}:{{ identity_service.auth_port }} auth_type = password project_domain_name = default user_domain_name = default project_name = services username = {{ identity_service.service_username }} password = {{ identity_service.service_password }} {% if identity_service.signing_dir -%} signing_dir = {{ identity_service.signing_dir }} {% endif -%} {% endif -%} ,,725,0
openstack%2Fcharm-murano~master~I65903fd872c742cdd03383a043bba19bc5219cf5,openstack/charm-murano,master,I65903fd872c742cdd03383a043bba19bc5219cf5,Cleanup config.yaml.,ABANDONED,2017-06-30 05:05:56.000000000,2019-01-07 11:15:18.000000000,,"[{'_account_id': 3}, {'_account_id': 15168}, {'_account_id': 20648}, {'_account_id': 25254}, {'_account_id': 26295}]","[{'number': 1, 'created': '2017-06-30 05:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-murano/commit/63a2a72386a97c71bbab90748024eb85ccdd2ded', 'message': 'Cleanup config.yaml.\n\nChange-Id: I65903fd872c742cdd03383a043bba19bc5219cf5\n'}, {'number': 2, 'created': '2017-06-30 07:22:48.000000000', 'files': ['src/config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-murano/commit/ea412bac7a346adceaeefad58b74a7ee598a47e0', 'message': 'Cleanup config.yaml.\n\nChange-Id: I65903fd872c742cdd03383a043bba19bc5219cf5\n'}]",0,479146,ea412bac7a346adceaeefad58b74a7ee598a47e0,10,5,2,26295,,,0,"Cleanup config.yaml.

Change-Id: I65903fd872c742cdd03383a043bba19bc5219cf5
",git fetch https://review.opendev.org/openstack/charm-murano refs/changes/46/479146/2 && git format-patch -1 --stdout FETCH_HEAD,['src/config.yaml'],1,63a2a72386a97c71bbab90748024eb85ccdd2ded,cleanup, default: murano rabbit-vhost: default: openstack database-user: default: murano database: type: string debug: type: string verbose: default: False region: type: string ext-network: default: ext_net router: default: default_router default_dns: default: 8.8.8.8, default: murano rabbit-vhost: default: openstack database-user: default: murano database: type: string debug: type: boolean verbose: default: False region: type: string ext-network: default: ext_net router: default: default_router default_dns: default: 8.8.8.8,19,10
openstack%2Fcharm-rabbitmq-server~master~I7f26e1ec8fd33812edbe368fd8a81b21cad37667,openstack/charm-rabbitmq-server,master,I7f26e1ec8fd33812edbe368fd8a81b21cad37667,[WIP] Update cluster name on removal of leader unit,ABANDONED,2017-07-12 10:13:17.000000000,2019-01-07 11:13:44.000000000,,"[{'_account_id': 3}, {'_account_id': 13686}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-07-12 10:13:17.000000000', 'files': ['tests/basic_deployment.py'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/b14d505f6ca8ecdbdd3e0829555ecef12630e4b4', 'message': '[WIP] Update cluster name on removal of leader unit\n\nAdd functional tests verifying adding new units to cluster\nafter removal of regular member unit and leader unit.\n\nChange-Id: I7f26e1ec8fd33812edbe368fd8a81b21cad37667\nCloses-Bug: #1703779\nRelated-Bug: #1701061\n'}]",0,482887,b14d505f6ca8ecdbdd3e0829555ecef12630e4b4,5,3,1,13686,,,0,"[WIP] Update cluster name on removal of leader unit

Add functional tests verifying adding new units to cluster
after removal of regular member unit and leader unit.

Change-Id: I7f26e1ec8fd33812edbe368fd8a81b21cad37667
Closes-Bug: #1703779
Related-Bug: #1701061
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/87/482887/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/basic_deployment.py'],1,b14d505f6ca8ecdbdd3e0829555ecef12630e4b4,bug/1703779," """"""Local helper to get rabbitmq-server sentries."""""" return self.d.sentry['rabbitmq-server'] def _check_unit_rmq_cluster_nodes(self, sentry, unit_node_names=None): """"""Local helper function for checking rmq node registration."""""" if not unit_node_names: sentry_units = self._get_rmq_sentry_units() unit_host_names = u.get_unit_hostnames(sentry_units) unit_node_names = [] for unit in unit_host_names: unit_node_names.append('rabbit@{}' ''.format(unit_host_names[unit])) def _remove_unit(self, remove_leader=False): """"""Local helper function specific to removing rabbitmq-server units for this series of tests."""""" remove_unit_sentry = None for sentry in self._get_rmq_sentry_units(): (output, code) = sentry.run('is-leader') u.log.debug( 'unit {} is-leader: {} ({})' ''.format(sentry.info['unit_name'], output, code) ) if code: amulet.raise_status(amulet.FAIL, msg='Unable to determine ' 'leader unit') if remove_leader and output != ""True"": u.log.debug('Skipping removal of non-leader unit {}' ''.format(sentry.info['unit_name'])) continue elif not remove_leader and output == ""True"": u.log.debug('Skipping removal of leader unit {}' ''.format(sentry.info['unit_name'])) continue remove_unit_sentry = sentry break self.d.remove_unit(remove_unit_sentry.info['unit_name']) for sentry in self._get_rmq_sentry_units(): e = self._check_unit_rmq_cluster_nodes(sentry) e = self._check_unit_rmq_cluster_nodes(sentry) def _add_unit(self): """"""Local helper function specific to adding rabbitmq-server units for this series of tests."""""" self.d.add_unit('rabbitmq-server') configs = {'rabbitmq-server': {'min-cluster-size': '3'}} super(RmqBasicDeployment, self)._configure_services(configs) self.d.sentry.wait(timeout=900) u.rmq_wait_for_cluster(self) errors = [] for sentry in self._get_rmq_sentry_units(): e = self._check_unit_rmq_cluster_nodes(sentry) if e: # NOTE: cluster status may not have been updated yet so wait a # little and try one more time. Need to find a better way to do # this. time.sleep(10) e = self._check_unit_rmq_cluster_nodes(sentry) if e: errors.append(e) if errors: amulet.raise_status(amulet.FAIL, msg=errors) def test_901_remove_unit(self): """"""Test if a unit correctly cleans up by removing itself from the RabbitMQ cluster on removal."""""" u.log.debug('Checking that units correctly clean up after themselves ' 'on unit removal...') self._remove_unit() u.log.debug('OK') def test_902_add_unit_after_removal(self): """"""Test if adding a new rabbitmq-server unit succeeds after previous unit removal."""""" u.log.debug('Checking that units can be added after previous unit ' 'removal...') self._add_unit() u.log.debug('OK') def test_903_remove_leader_unit(self): """"""Test if charm correctly handles removal of the leader unit."""""" u.log.debug('Checking that units correctly clean up after themselves ' 'on leader unit removal...') self._remove_unit(remove_leader=True) u.log.debug('OK') def test_904_add_unit_after_remove_leader_unit(self): """"""Test if adding a new rabbitmq-server unit succeeds after previous removal of leader unit."""""" u.log.debug('Checking that units can be added after previous leader ' 'unit removal...') self._add_unit() # the cached sentry pointers may be out of date after the add/remove # tests, update before running this test. self.rmq0_sentry = self._get_rmq_sentry_units()[0] "," """"""Local helper specific to this 3-node rmq series of tests."""""" return [self.rmq0_sentry, self.rmq1_sentry, self.rmq2_sentry] def check_unit_rmq_cluster_nodes(self, sentry, unit_node_names): def test_901_remove_unit(self): """"""Test if a unit correctly cleans up by removing itself from the RabbitMQ cluster on removal"""""" u.log.debug('Checking that units correctly clean up after themselves ' 'on unit removal...') self.d.remove_unit(self.rmq2_sentry.info['unit_name']) sentry_units = self._get_rmq_sentry_units()[:-1] unit_host_names = u.get_unit_hostnames(sentry_units) unit_node_names = [] for unit in unit_host_names: unit_node_names.append('rabbit@{}'.format(unit_host_names[unit])) for sentry in sentry_units: e = self.check_unit_rmq_cluster_nodes(sentry, unit_node_names) e = self.check_unit_rmq_cluster_nodes(sentry, unit_node_names)",101,20
openstack%2Fsolum~master~I2d1941ac446135ea6d9391b9ffaa4056dd4cec97,openstack/solum,master,I2d1941ac446135ea6d9391b9ffaa4056dd4cec97,Update the devstack client settings,MERGED,2019-01-07 08:23:55.000000000,2019-01-07 11:08:43.000000000,2019-01-07 11:08:43.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 08:23:55.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/solum/commit/c12263538212409d40f9fa2cd095ea2cbeb1552a', 'message': 'Update the devstack client settings\n\nChange-Id: I2d1941ac446135ea6d9391b9ffaa4056dd4cec97\n'}]",0,628911,c12263538212409d40f9fa2cd095ea2cbeb1552a,6,2,1,14107,,,0,"Update the devstack client settings

Change-Id: I2d1941ac446135ea6d9391b9ffaa4056dd4cec97
",git fetch https://review.opendev.org/openstack/solum refs/changes/11/628911/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,c12263538212409d40f9fa2cd095ea2cbeb1552a,,"GITREPO[""python-solumclient""]=${SOLUMCLIENT_REPO:-${GIT_BASE}/openstack/python-solumclient.git} GITBRANCH[""python-solumclient""]=${SOLUMCLIENT_BRANCH:-master}GITDIR[""python-solumclient""]=$DEST/python-solumclient",SOLUMCLIENT_REPO=${SOLUMCLIENT_REPO:-${GIT_BASE}/openstack/python-solumclient.git} SOLUMCLIENT_BRANCH=${SOLUMCLIENT_BRANCH:-master}SOLUMCLIENT_DIR=$DEST/python-solumclient,3,3
openstack%2Fopenstack-ansible~stable%2Frocky~Idcefc03dafd35cd0fadfaa5007339fd4aa21bb4d,openstack/openstack-ansible,stable/rocky,Idcefc03dafd35cd0fadfaa5007339fd4aa21bb4d,Update horizon role SHA,MERGED,2018-12-30 22:19:46.000000000,2019-01-07 10:55:13.000000000,2019-01-07 10:55:13.000000000,"[{'_account_id': 290}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 22:19:46.000000000', 'files': ['ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/259a84f01c83de19fd6361ef378ba5f7bcdb23f9', 'message': 'Update horizon role SHA\n\nPull in fix for suse package openstack-horizon-plugin-neutron-vpnaas-ui\nbeing renamed to python-neutron-vpnaas-dashboard\n\nChange-Id: Idcefc03dafd35cd0fadfaa5007339fd4aa21bb4d\n'}]",0,627851,259a84f01c83de19fd6361ef378ba5f7bcdb23f9,8,4,1,25023,,,0,"Update horizon role SHA

Pull in fix for suse package openstack-horizon-plugin-neutron-vpnaas-ui
being renamed to python-neutron-vpnaas-dashboard

Change-Id: Idcefc03dafd35cd0fadfaa5007339fd4aa21bb4d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/51/627851/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible-role-requirements.yml'],1,259a84f01c83de19fd6361ef378ba5f7bcdb23f9,, version: b6eb4f1caf5b59fff84ee204f1c59ad0a3f54b42, version: b088034eeaa73ac781fe271588ba03871c88118e,1,1
openstack%2Fopenstack-ansible-os_tempest~master~I7744270e7371260dcc4db146736710fb050f3502,openstack/openstack-ansible-os_tempest,master,I7744270e7371260dcc4db146736710fb050f3502,Added support for installing python-tempestconf from git,MERGED,2018-12-18 12:56:08.000000000,2019-01-07 10:47:58.000000000,2019-01-07 10:47:58.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-12-18 12:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5fd768c07526385f92564625bf0a9f7688c73381', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 2, 'created': '2018-12-18 12:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/eb7442c7a94a72754bee09126f473ff469914ee8', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 3, 'created': '2018-12-18 14:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/67d74ff5dfd03262cc1535b8f479222d2afa50c5', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 4, 'created': '2018-12-19 05:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/c61e63ee66213475f2722ce3033f1ed77561cf0f', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nDepends-On: https://review.openstack.org/#/c/626092/\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 5, 'created': '2018-12-21 10:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5c33e46a7e7a44c5387b30f0c36fec028625aac2', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nDepends-On: https://review.openstack.org/#/c/626092/\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 6, 'created': '2018-12-21 13:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/aee7284d27a148ea569a4e398dbfb5dd635ca657', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nDepends-On: https://review.openstack.org/#/c/626092/\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 7, 'created': '2018-12-21 13:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/bb227fa20f6033770f3cf3ff0d1da26f21c90b46', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 8, 'created': '2018-12-24 12:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/3a0d27488868324ac4a373efe6fd0c8e51576ac5', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 9, 'created': '2019-01-03 10:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/daef2442c80ef66958f19aece0ed6561853b07f0', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}, {'number': 10, 'created': '2019-01-04 08:28:06.000000000', 'files': ['tests/os_tempest-overrides.yml', 'tasks/tempestconf.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/cf900666084af9d1a45de5968002d9499d23237c', 'message': 'Added support for installing python-tempestconf from git\n\nIn CI jobs, currently python-tempestconf is getting from pip,\nwhich makes it hard to test dependent changes of the project.\nBy adding this support, one can test the python-tempestconf\nchanges in the review itself.\n\nSetting tempest_developer_mode to true will exercise the same.\n\nChange-Id: I7744270e7371260dcc4db146736710fb050f3502\n'}]",10,625904,cf900666084af9d1a45de5968002d9499d23237c,41,8,10,12393,,,0,"Added support for installing python-tempestconf from git

In CI jobs, currently python-tempestconf is getting from pip,
which makes it hard to test dependent changes of the project.
By adding this support, one can test the python-tempestconf
changes in the review itself.

Setting tempest_developer_mode to true will exercise the same.

Change-Id: I7744270e7371260dcc4db146736710fb050f3502
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/04/625904/5 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/tempestconf.yml', 'defaults/main.yml']",2,5fd768c07526385f92564625bf0a9f7688c73381,tempestconf_git," # We comment `tempestconf_git_repo` so that the repo_build role does not attempt to # build the wheel from this repo/branch. Instead, we want tempest to get built # from the stable release defined in global requirements. #tempestconf_git_repo: https://git.openstack.org/openstack/python-tempestconf tempestconf_git_install_branch: master tempestconf_developer_mode: False tempestconf_developer_constraints: - ""git+{{ tempestconf_git_repo }}@{{ tempestconf_git_install_branch }}#egg=python_tempestconf""",,24,0
openstack%2Fpuppet-tripleo~master~I82dca36b3c9ebf4243d270ac91ffbf6ad56d6ca6,openstack/puppet-tripleo,master,I82dca36b3c9ebf4243d270ac91ffbf6ad56d6ca6,Prevent systemd unit files to be created to restart services,MERGED,2018-12-23 20:36:32.000000000,2019-01-07 10:46:26.000000000,2019-01-07 10:46:25.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-23 20:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/10004271055e742e2ceb876c7b6b08084261ddef', 'message': ""Prevent systemd unit files to be created to restart services\n\nThis patch removes the code that create/modify Systemd unit files so the\nservices restart. We did it after Newton when we switched the services\nto be managed under Systemd to automatically restart.\n\nWith containers, we don't want / need that anymore.\nIn Pike, Queens and Rocky, containers are restarted by the Docker\nEngine.\nIn Stein, containers are restarted by Systemd (which restart podman\ncontainers) but the unit files are now managed by Paunch.\n\nTo avoid weird behaviors, let's clean this up.\n\nChange-Id: I82dca36b3c9ebf4243d270ac91ffbf6ad56d6ca6\n""}, {'number': 2, 'created': '2019-01-04 12:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e15281266410479da0e1863ca63913b200decebb', 'message': ""Prevent systemd unit files to be created to restart services\n\nThis patch removes the code that create/modify Systemd unit files so the\nservices restart. We did it after Newton when we switched the services\nto be managed under Systemd to automatically restart.\n\nWith containers, we don't want / need that anymore.\nIn Pike, Queens and Rocky, containers are restarted by the Docker\nEngine.\nIn Stein, containers are restarted by Systemd (which restart podman\ncontainers) but the unit files are now managed by Paunch.\n\nTo avoid weird behaviors, let's clean this up.\n\nChange-Id: I82dca36b3c9ebf4243d270ac91ffbf6ad56d6ca6\n""}, {'number': 3, 'created': '2019-01-06 09:39:00.000000000', 'files': ['manifests/profile/base/memcached.pp', 'manifests/profile/base/apache.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b69a1834ac73f1c7f5efc7308bb0972ff363a27e', 'message': ""Prevent systemd unit files to be created to restart services\n\nThis patch removes the code that create/modify Systemd unit files so the\nservices restart. We did it after Newton when we switched the services\nto be managed under Systemd to automatically restart.\n\nWith containers, we don't want / need that anymore.\nIn Pike, Queens and Rocky, containers are restarted by the Docker\nEngine.\nIn Stein, containers are restarted by Systemd (which restart podman\ncontainers) but the unit files are now managed by Paunch.\n\nTo avoid weird behaviors, let's clean this up.\n\nChange-Id: I82dca36b3c9ebf4243d270ac91ffbf6ad56d6ca6\n""}]",0,627085,b69a1834ac73f1c7f5efc7308bb0972ff363a27e,26,5,3,3153,,,0,"Prevent systemd unit files to be created to restart services

This patch removes the code that create/modify Systemd unit files so the
services restart. We did it after Newton when we switched the services
to be managed under Systemd to automatically restart.

With containers, we don't want / need that anymore.
In Pike, Queens and Rocky, containers are restarted by the Docker
Engine.
In Stein, containers are restarted by Systemd (which restart podman
containers) but the unit files are now managed by Paunch.

To avoid weird behaviors, let's clean this up.

Change-Id: I82dca36b3c9ebf4243d270ac91ffbf6ad56d6ca6
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/85/627085/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/memcached.pp', 'manifests/profile/base/apache.pp', 'manifests/profile/base/database/mongodb.pp']",3,10004271055e742e2ceb876c7b6b08084261ddef,memcached,," # Automatic restart ::systemd::dropin_file { 'mongod.conf': unit => 'mongod.service', content => ""[Service]\nRestart=always\n"", }",0,17
openstack%2Ftripleo-heat-templates~master~I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e,openstack/tripleo-heat-templates,master,I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e,Prevent service bootstrap node facts from colliding with each other,MERGED,2019-01-03 12:59:18.000000000,2019-01-07 10:40:28.000000000,2019-01-07 10:40:28.000000000,"[{'_account_id': 8042}, {'_account_id': 8871}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-01-03 12:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/740b7dfe4131cfbb1d24243adef35c35a98e6beb', 'message': 'Prevent service bootstrap node facts from colliding with each other\n\nMany services currently set an `is_bootstrap_node` fact, meaning they\noverride each other\'s results when the fact is being set. As long as\nthe fact doesn\'t belong into a particular step but it\'s executed on\nevery step, nothing bad happens, as the correct is_bootstrap_node\nsetting directly precedes any service upgrade tasks. However, we\nintend to put the fact setting into step 0 in change\nIb04b051e8f4275e06be0cafa81e2111c9cced9b7 and at that point the name\ncollision would break upgrades (only one service would ""win"" in\nsetting the is_bootstrap_node fact).\n\nThis patch changes the is_bootstrap_node facts in upgrade_tasks to use\nper-service naming.\n\nNote that fast_forward_upgrade_tasks use their own is_boostrap_node\nlogic provided by the FFU framework itself, so there we keep the\nis_boostrap_node fact. It\'s not guaranteed that this is the correct\nbehavior for all circumstances, but if we want to change how the FFU\nframework approaches bootstrap logic, we should do so in a separate\npatch.\n\nChange-Id: I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e\nCloses-Bug: #1810408\n'}, {'number': 2, 'created': '2019-01-03 13:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b14f1cd38089a138a9fe71a5fd6e439c95ef35d', 'message': 'Prevent service bootstrap node facts from colliding with each other\n\nMany services currently set an `is_bootstrap_node` fact, meaning they\noverride each other\'s results when the fact is being set. As long as\nthe fact doesn\'t belong into a particular step but it\'s executed on\nevery step, nothing bad happens, as the correct is_bootstrap_node\nsetting directly precedes any service upgrade tasks. However, we\nintend to put the fact setting into step 0 in change\nIb04b051e8f4275e06be0cafa81e2111c9cced9b7 and at that point the name\ncollision would break upgrades (only one service would ""win"" in\nsetting the is_bootstrap_node fact).\n\nThis patch changes the is_bootstrap_node facts in upgrade_tasks to use\nper-service naming.\n\nNote that fast_forward_upgrade_tasks use their own is_boostrap_node\nlogic. We\'ve uncovered some weirdness there while looking into the\nis_boostrap_node issue, but the fix is not a low hanging fruit and\nlikely we\'ll be completely redoing the FFU tasks for Q->T\nupgrade. So the FFU tasks are left alone for now.\n\nChange-Id: I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e\nCloses-Bug: #1810408\n'}, {'number': 3, 'created': '2019-01-03 13:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9fab185b3f5ae61249e8fe8d90a1a06e6cf04303', 'message': 'Prevent service bootstrap node facts from colliding with each other\n\nMany services currently set an `is_bootstrap_node` fact, meaning they\noverride each other\'s results when the fact is being set. As long as\nthe fact doesn\'t belong into a particular step but it\'s executed on\nevery step, nothing bad happens, as the correct is_bootstrap_node\nsetting directly precedes any service upgrade tasks. However, we\nintend to put the fact setting into step 0 in change\nIb04b051e8f4275e06be0cafa81e2111c9cced9b7 and at that point the name\ncollision would break upgrades (only one service would ""win"" in\nsetting the is_bootstrap_node fact).\n\nThis patch changes the is_bootstrap_node facts in upgrade_tasks to use\nper-service naming.\n\nNote that fast_forward_upgrade_tasks use their own is_boostrap_node\nlogic. We\'ve uncovered some weirdness there while looking into the\nis_boostrap_node issue, but the fix is not a low hanging fruit and\nlikely we\'ll be completely redoing the FFU tasks for Q->T\nupgrade. So the FFU tasks are left alone for now.\n\nChange-Id: I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e\nCloses-Bug: #1810408\n'}, {'number': 4, 'created': '2019-01-03 15:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d3a83643825c0b0a28009869ae41bcd841a831c1', 'message': 'Prevent service bootstrap node facts from colliding with each other\n\nMany services currently set an `is_bootstrap_node` fact, meaning they\noverride each other\'s results when the fact is being set. As long as\nthe fact doesn\'t belong into a particular step but it\'s executed on\nevery step, nothing bad happens, as the correct is_bootstrap_node\nsetting directly precedes any service upgrade tasks. However, we\nintend to put the fact setting into step 0 in change\nIb04b051e8f4275e06be0cafa81e2111c9cced9b7 and at that point the name\ncollision would break upgrades (only one service would ""win"" in\nsetting the is_bootstrap_node fact).\n\nThis patch changes the is_bootstrap_node facts in upgrade_tasks to use\nper-service naming.\n\nNote that fast_forward_upgrade_tasks use their own is_boostrap_node\nlogic. We\'ve uncovered some weirdness there while looking into the\nis_boostrap_node issue, but the fix is not a low hanging fruit and\nlikely we\'ll be completely redoing the FFU tasks for Q->T\nupgrade. So the FFU tasks are left alone for now.\n\nChange-Id: I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e\nCloses-Bug: #1810408\n'}, {'number': 5, 'created': '2019-01-03 16:27:35.000000000', 'files': ['docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/haproxy.yaml', 'deployment/ironic/ironic-api-container-puppet.yaml', 'docker/services/nova-api.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/notify-rabbitmq.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml', 'puppet/services/gnocchi-api.yaml', 'puppet/services/haproxy-public-tls-inject.yaml', 'docker/services/cinder-api.yaml', 'puppet/services/nova-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/54fb81ecd94965e6b518060a4760c6aeb3987efe', 'message': 'Prevent service bootstrap node facts from colliding with each other\n\nMany services currently set an `is_bootstrap_node` fact, meaning they\noverride each other\'s results when the fact is being set. As long as\nthe fact doesn\'t belong into a particular step but it\'s executed on\nevery step, nothing bad happens, as the correct is_bootstrap_node\nsetting directly precedes any service upgrade tasks. However, we\nintend to put the fact setting into step 0 in change\nIb04b051e8f4275e06be0cafa81e2111c9cced9b7 and at that point the name\ncollision would break upgrades (only one service would ""win"" in\nsetting the is_bootstrap_node fact).\n\nThis patch changes the is_bootstrap_node facts in upgrade_tasks to use\nper-service naming.\n\nNote that fast_forward_upgrade_tasks use their own is_boostrap_node\nlogic. We\'ve uncovered some weirdness there while looking into the\nis_boostrap_node issue, but the fix is not a low hanging fruit and\nlikely we\'ll be completely redoing the FFU tasks for Q->T\nupgrade. So the FFU tasks are left alone for now.\n\nChange-Id: I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e\nCloses-Bug: #1810408\n'}]",5,628171,54fb81ecd94965e6b518060a4760c6aeb3987efe,34,10,5,8042,,,0,"Prevent service bootstrap node facts from colliding with each other

Many services currently set an `is_bootstrap_node` fact, meaning they
override each other's results when the fact is being set. As long as
the fact doesn't belong into a particular step but it's executed on
every step, nothing bad happens, as the correct is_bootstrap_node
setting directly precedes any service upgrade tasks. However, we
intend to put the fact setting into step 0 in change
Ib04b051e8f4275e06be0cafa81e2111c9cced9b7 and at that point the name
collision would break upgrades (only one service would ""win"" in
setting the is_bootstrap_node fact).

This patch changes the is_bootstrap_node facts in upgrade_tasks to use
per-service naming.

Note that fast_forward_upgrade_tasks use their own is_boostrap_node
logic. We've uncovered some weirdness there while looking into the
is_boostrap_node issue, but the fix is not a low hanging fruit and
likely we'll be completely redoing the FFU tasks for Q->T
upgrade. So the FFU tasks are left alone for now.

Change-Id: I9c585d3cb282b7e4eb0bacb3cf6909e04a9a495e
Closes-Bug: #1810408
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/71/628171/4 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/nova-api.yaml', 'puppet/services/tripleo-packages.yaml', 'docker/services/ironic-api.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/notify-rabbitmq.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml', 'puppet/services/gnocchi-api.yaml', 'puppet/services/haproxy-public-tls-inject.yaml', 'docker/services/cinder-api.yaml', 'puppet/services/nova-api.yaml']",17,740b7dfe4131cfbb1d24243adef35c35a98e6beb,bug/1810408, - name: set nova_api_bootstrap_node fact set_fact: nova_api_bootstrap_node={{nova_api_short_bootstrap_node_name|lower == ansible_hostname|lower}} - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool - nova_api_bootstrap_node|bool, - name: set is_bootstrap_node fact set_fact: is_bootstrap_node={{nova_api_short_bootstrap_node_name|lower == ansible_hostname|lower}} - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool - is_bootstrap_node|bool,71,73
openstack%2Fptgbot~master~I7d82b38cba495e5837ba54fbe7a9b7e9c8e14259,openstack/ptgbot,master,I7d82b38cba495e5837ba54fbe7a9b7e9c8e14259,Generate PTGbot index page dynamically,MERGED,2018-12-21 14:35:40.000000000,2019-01-07 10:37:31.000000000,2019-01-07 10:37:31.000000000,"[{'_account_id': 308}, {'_account_id': 7069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 14:35:40.000000000', 'files': ['html/index.html', 'html/index.js', 'ptgbot/db.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/cb0e38cd1209e5be201637953d56b48fdb1383cf', 'message': 'Generate PTGbot index page dynamically\n\nCurrent system (where the index page is specified in the\npuppet-ptgbot module) requires that (some) links on the page\nare updated in puppet-ptgbot at the start of every event.\n\nThat page should be dynamically generated from JSON data.\nThat way the list of links can be provided in the JSON database\nand dynamically imported and updated using the ~fetchdb command.\n\nChange-Id: I7d82b38cba495e5837ba54fbe7a9b7e9c8e14259\n'}]",0,626907,cb0e38cd1209e5be201637953d56b48fdb1383cf,7,3,1,308,,,0,"Generate PTGbot index page dynamically

Current system (where the index page is specified in the
puppet-ptgbot module) requires that (some) links on the page
are updated in puppet-ptgbot at the start of every event.

That page should be dynamically generated from JSON data.
That way the list of links can be provided in the JSON database
and dynamically imported and updated using the ~fetchdb command.

Change-Id: I7d82b38cba495e5837ba54fbe7a9b7e9c8e14259
",git fetch https://review.opendev.org/openstack/ptgbot refs/changes/07/626907/1 && git format-patch -1 --stdout FETCH_HEAD,"['html/index.html', 'html/index.js', 'ptgbot/db.py', 'README.rst']",4,cb0e38cd1209e5be201637953d56b48fdb1383cf,configurable-index, ~fetchdb http://paste.openstack.org/raw/737820/, ~fetchdb http://paste.openstack.org/raw/736003/,43,2
openstack%2Fptgbot~master~I6353185daa4a494d81ce519a2498639a4f973212,openstack/ptgbot,master,I6353185daa4a494d81ce519a2498639a4f973212,Pin irc module to 15.1.1 to avoid import error,MERGED,2018-12-21 14:35:40.000000000,2019-01-07 10:36:47.000000000,2019-01-07 10:36:47.000000000,"[{'_account_id': 308}, {'_account_id': 7069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 14:35:40.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/052b575a4f6e9dddb78e6be6006674828de01225', 'message': 'Pin irc module to 15.1.1 to avoid import error\n\nib3 triggers an irc.buffer import failure when used with\nirc>=16. The fix is in[1], but was not released yet. In\nthe meantime, pin irc module to 15.1.1 to work around the\nissue.\n\n[1] https://github.com/bd808/python-ib3/commit/92da70155e5378478802cb38baaa2a00187201d6\n\nChange-Id: I6353185daa4a494d81ce519a2498639a4f973212\n'}]",0,626906,052b575a4f6e9dddb78e6be6006674828de01225,7,3,1,308,,,0,"Pin irc module to 15.1.1 to avoid import error

ib3 triggers an irc.buffer import failure when used with
irc>=16. The fix is in[1], but was not released yet. In
the meantime, pin irc module to 15.1.1 to work around the
issue.

[1] https://github.com/bd808/python-ib3/commit/92da70155e5378478802cb38baaa2a00187201d6

Change-Id: I6353185daa4a494d81ce519a2498639a4f973212
",git fetch https://review.opendev.org/openstack/ptgbot refs/changes/06/626906/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,052b575a4f6e9dddb78e6be6006674828de01225,configurable-index,# Pin irc module to 15.1.1 until ib3 releases https://github.com/bd808/python-ib3/commit/92da70155e5378478802cb38baaa2a00187201d6 irc==15.1.1,irc,2,1
openstack%2Fneutron~master~If7292c33dd0716a0a412bf60658123d2e688dfdb,openstack/neutron,master,If7292c33dd0716a0a412bf60658123d2e688dfdb,Implement IpAddrCommand.get_devices_with_ip using pyroute2,MERGED,2018-11-15 19:04:42.000000000,2019-01-07 10:30:15.000000000,2018-12-18 23:37:37.000000000,"[{'_account_id': 1131}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2018-11-15 19:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aea0c251d5e980f08f3a586131be560fff5d76da', 'message': '[WIP] Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 2, 'created': '2018-11-22 11:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5fb6ab83381b68db90f7a065c3e9f4abc5b96b63', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 3, 'created': '2018-11-22 17:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33996dbd2757be68b0ab5bb2399e59ec5d05bbb0', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 4, 'created': '2018-11-22 19:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a3608486bb3f777f9795d5d924afa94012d714a6', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 5, 'created': '2018-11-22 19:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/89fa60c3934173519eb7627ff5677db642a3c413', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 6, 'created': '2018-11-22 19:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/34b84dc8a51a1411ec3723cc55d1ad0361481288', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 7, 'created': '2018-11-22 21:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbd54e6804bf23195faad54d5b03ede82a2a2e38', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 8, 'created': '2018-11-23 10:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad663e1b4506b980e9f9353c66ceeee722e13073', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 9, 'created': '2018-11-23 14:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b172584622e234e382b6e0ab6f06b3215a597bec', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 10, 'created': '2018-11-26 10:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc586125e05c512c80794bcf913fa2939315de18', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 11, 'created': '2018-11-27 09:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fd4b68e56bcfb6d040e82f30028f7e47cafde4d', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 12, 'created': '2018-12-01 18:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed94e43b55c803859d4387c31a23edea22073f96', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 13, 'created': '2018-12-04 18:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a866dae9d23ef90c3d741af45c8fa52321f165c', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 14, 'created': '2018-12-06 10:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af67f8eaf0de7677fd03e6c9fca2d0598f0559f6', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 15, 'created': '2018-12-06 11:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/401c96f3cb98c1d9a0c33e579503da78c8636546', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 16, 'created': '2018-12-06 15:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9ba878df286ac80d0acdb14badfe42763844cb8', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 17, 'created': '2018-12-07 19:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1102b4b3bb7327517f76f7768e4de985743cd789', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 18, 'created': '2018-12-17 09:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c958cc241ad4d7556bce6a1182ee094f163c523', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}, {'number': 19, 'created': '2018-12-17 13:11:51.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/tests/functional/privileged/agent/linux/test_ip_lib.py', 'neutron/common/utils.py', 'neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/privileged/agent/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/05a54e800430bcfc81e36e1dad89fa47f3e8a6f0', 'message': 'Implement IpAddrCommand.get_devices_with_ip using pyroute2\n\nRelated-Bug: #1492714\n\nChange-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb\n'}]",14,618273,05a54e800430bcfc81e36e1dad89fa47f3e8a6f0,141,11,19,16688,,,0,"Implement IpAddrCommand.get_devices_with_ip using pyroute2

Related-Bug: #1492714

Change-Id: If7292c33dd0716a0a412bf60658123d2e688dfdb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/618273/14 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ip_lib.py', 'neutron/tests/functional/privileged/agent/linux/test_ip_lib.py', 'neutron/privileged/agent/linux/ip_lib.py']",3,aea0c251d5e980f08f3a586131be560fff5d76da,bug/1492714,"def get_link_devices(namespace, **kwargs): """"""List interfaces in a namespace :return: (list) interfaces in a namespace return ip.get_links(**kwargs) except OSError as e: if e.errno == errno.ENOENT: raise NetworkNamespaceNotFound(netns_name=namespace) raise def get_device_names(namespace, **kwargs): """"""List interface names in a namespace :return: a list of strings with the names of the interfaces in a namespace """""" return [link.get_attr('IFLA_IFNAME') for link in get_link_devices(namespace, **kwargs)] @privileged.default.entrypoint def get_ip_addresses(namespace, **kwargs): """"""List of IP addresses in a namespace :return: (tuple) IP addresses in a namespace """""" try: with _get_iproute(namespace) as ip: return ip.get_addr(**kwargs)","def get_devices(namespace, **kwargs): """"""List all interfaces in a namespace :return: a list of strings with the names of the interfaces in a namespace return [link.get_attr('IFLA_IFNAME') for link in ip.get_links(**kwargs)]",78,8
openstack%2Fironic~master~I96fa83b81372333e626cca0e64fefcd0aeabe031,openstack/ironic,master,I96fa83b81372333e626cca0e64fefcd0aeabe031,Allow missing ``local_gb`` property,MERGED,2019-01-03 03:43:20.000000000,2019-01-07 10:28:11.000000000,2019-01-07 10:28:11.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 16635}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 26340}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-01-03 03:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9395eb46a647eb747273fa691f94d5746911c12e', 'message': ""Allow non-deterministic ``local_gb`` property\n\nFailure to detect ``local_gb`` makes the Redfish inspection fail.\nBut ideally it shouldn't fail, for instance the node can be a\ndisk-less node.\n\nAllow Redfish inspect operation now to ignore missing ``local_gb``\nproperty and sets it to '0' in such scenario.\n\nChange-Id: I96fa83b81372333e626cca0e64fefcd0aeabe031\nStory: 2004622\nTask: 28542\n""}, {'number': 2, 'created': '2019-01-04 06:01:24.000000000', 'files': ['doc/source/admin/drivers/redfish.rst', 'ironic/tests/unit/drivers/modules/redfish/test_inspect.py', 'ironic/drivers/modules/redfish/inspect.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b8e720e51fc9d9ecff31ceb9c58c63c985754e1b', 'message': ""Allow missing ``local_gb`` property\n\nFailure to detect ``local_gb`` fails the Redfish inspection.\nBut ideally it shouldn't fail, for instance the node can be a\ndisk-less node.\n\nAllow Redfish inspect operation now to ignore missing ``local_gb``\nproperty and set it to 0 in such cases.\n\nChange-Id: I96fa83b81372333e626cca0e64fefcd0aeabe031\nStory: 2004622\nTask: 28542\n""}]",27,628096,b8e720e51fc9d9ecff31ceb9c58c63c985754e1b,21,11,2,16635,,,0,"Allow missing ``local_gb`` property

Failure to detect ``local_gb`` fails the Redfish inspection.
But ideally it shouldn't fail, for instance the node can be a
disk-less node.

Allow Redfish inspect operation now to ignore missing ``local_gb``
property and set it to 0 in such cases.

Change-Id: I96fa83b81372333e626cca0e64fefcd0aeabe031
Story: 2004622
Task: 28542
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/628096/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/drivers/redfish.rst', 'ironic/tests/unit/drivers/modules/redfish/test_inspect.py', 'ironic/drivers/modules/redfish/inspect.py']",3,9395eb46a647eb747273fa691f94d5746911c12e,allow-no-local_gb," try: if storage_size == 0: LOG.debug(""Attempting to get storage disk information for "" ""node %(node)s"", {'node': task.node.uuid}) if system.storage and system.storage.drives_sizes_bytes: storage_size = [ size for size in system.storage.drives_sizes_bytes if size >= 4 * units.Gi ] or [0] storage_size = storage_size[0] except sushy.exceptions.SushyError as ex: LOG.debug(""No storage disk information discovered "" ""for node %(node)s: %(err)s"", {'node': task.node.uuid, 'err': ex}) ""for node %(node)s. Assuming this is a disk-less node"", {'node': task.node.uuid}) inspected_properties['local_gb'] = '0'"," ""for node %(node)s"", {'node': task.node.uuid})",31,15
openstack%2Fpython-cloudkittyclient~master~Ib089bdbc75d5a5008081ba0749eb944fa839f095,openstack/python-cloudkittyclient,master,Ib089bdbc75d5a5008081ba0749eb944fa839f095,Update the bugs link to storyboard,MERGED,2018-12-30 16:07:14.000000000,2019-01-07 10:27:51.000000000,2019-01-07 10:27:51.000000000,"[{'_account_id': 7923}, {'_account_id': 12015}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23060}]","[{'number': 1, 'created': '2018-12-30 16:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/4843b4beb9e2b3cc4d988d682db4a0edc2597265', 'message': 'Update the bugs link to storyboard\n\nChange-Id: Ib089bdbc75d5a5008081ba0749eb944fa839f095\n'}, {'number': 2, 'created': '2018-12-31 12:28:28.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/dd1a421b7c83f87625e623b80fd5dcae10e6b2eb', 'message': 'Update the bugs link to storyboard\n\nChange-Id: Ib089bdbc75d5a5008081ba0749eb944fa839f095\n'}]",1,627836,dd1a421b7c83f87625e623b80fd5dcae10e6b2eb,12,5,2,21691,,,0,"Update the bugs link to storyboard

Change-Id: Ib089bdbc75d5a5008081ba0749eb944fa839f095
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/36/627836/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,4843b4beb9e2b3cc4d988d682db4a0edc2597265,, https://storyboard.openstack.org/#!/project/openstack/python-cloudkittyclient, https://bugs.launchpad.net/cloudkitty,1,1
openstack%2Fcloudkitty-dashboard~master~I02738e95a04bfb497c3bcc99fc7d4765bf23a67d,openstack/cloudkitty-dashboard,master,I02738e95a04bfb497c3bcc99fc7d4765bf23a67d,Add missing JS source,MERGED,2018-08-29 10:16:55.000000000,2019-01-07 10:26:51.000000000,2019-01-07 10:26:51.000000000,"[{'_account_id': 7923}, {'_account_id': 12015}, {'_account_id': 22348}, {'_account_id': 23060}]","[{'number': 1, 'created': '2018-08-29 10:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/d4010be362bef5e4b67617573053bbe67ddaea29', 'message': ""Add missing JS source\n\ncloudkitty-dashboard, so far, doesn't have sourcefull versions of JS files.\nThis makes the whole package non-free.\n\nThis is also quite dangerous, because there's no way to track version\nof included javascript, leading to potential security hole disaster.\n\nFirst step is to re-add the source file. Next step will probably be to\nuse XStatic packages.\n\nChange-Id: I02738e95a04bfb497c3bcc99fc7d4765bf23a67d\n""}, {'number': 2, 'created': '2018-08-29 13:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/82cfe2d1378fdd6198ee12c217dabfade68e3fa5', 'message': ""Add missing JS source\n\ncloudkitty-dashboard, so far, doesn't have sourcefull versions of JS files.\nThis makes the whole package non-free.\n\nThis is also quite dangerous, because there's no way to track version\nof included javascript, leading to potential security hole disaster.\n\nFirst step is to re-add the source file. Next step will probably be to\nuse XStatic packages.\n\nThis patch partially addresses:\nhttps://storyboard.openstack.org/#!/story/2003578\n\nbut cannot claim to actually fix it. The proper fix would be XStatic.\n\nChange-Id: I02738e95a04bfb497c3bcc99fc7d4765bf23a67d\n""}, {'number': 3, 'created': '2018-11-15 13:01:38.000000000', 'files': ['cloudkittydashboard/static/cloudkitty/js/rickshaw.js', 'cloudkittydashboard/static/cloudkitty/js/d3pie.js', 'cloudkittydashboard/static/cloudkitty/js/d3.js'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/1fde6e4f644955cfc53ac59cd2898e8af191093a', 'message': ""Add missing JS source\n\ncloudkitty-dashboard, so far, doesn't have sourcefull versions of JS files.\nThis makes the whole package non-free.\n\nThis is also quite dangerous, because there's no way to track version\nof included javascript, leading to potential security hole disaster.\n\nFirst step is to re-add the source file. Next step will probably be to\nuse XStatic packages.\n\nThis patch partially addresses:\nhttps://storyboard.openstack.org/#!/story/2003578\n\nbut cannot claim to actually fix it. The proper fix would be XStatic.\n\nStory: 2003578\nTask: 24924\nChange-Id: I02738e95a04bfb497c3bcc99fc7d4765bf23a67d\n""}]",0,597438,1fde6e4f644955cfc53ac59cd2898e8af191093a,15,4,3,6476,,,0,"Add missing JS source

cloudkitty-dashboard, so far, doesn't have sourcefull versions of JS files.
This makes the whole package non-free.

This is also quite dangerous, because there's no way to track version
of included javascript, leading to potential security hole disaster.

First step is to re-add the source file. Next step will probably be to
use XStatic packages.

This patch partially addresses:
https://storyboard.openstack.org/#!/story/2003578

but cannot claim to actually fix it. The proper fix would be XStatic.

Story: 2003578
Task: 24924
Change-Id: I02738e95a04bfb497c3bcc99fc7d4765bf23a67d
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/38/597438/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkittydashboard/static/cloudkitty/js/rickshaw.js', 'cloudkittydashboard/static/cloudkitty/js/d3pie.js', 'cloudkittydashboard/static/cloudkitty/js/d3.js']",3,d4010be362bef5e4b67617573053bbe67ddaea29,js-source,"!function() { var d3 = { version: ""3.4.4"" }; if (!Date.now) Date.now = function() { return +new Date(); }; var d3_arraySlice = [].slice, d3_array = function(list) { return d3_arraySlice.call(list); }; var d3_document = document, d3_documentElement = d3_document.documentElement, d3_window = window; try { d3_array(d3_documentElement.childNodes)[0].nodeType; } catch (e) { d3_array = function(list) { var i = list.length, array = new Array(i); while (i--) array[i] = list[i]; return array; }; } try { d3_document.createElement(""div"").style.setProperty(""opacity"", 0, """"); } catch (error) { var d3_element_prototype = d3_window.Element.prototype, d3_element_setAttribute = d3_element_prototype.setAttribute, d3_element_setAttributeNS = d3_element_prototype.setAttributeNS, d3_style_prototype = d3_window.CSSStyleDeclaration.prototype, d3_style_setProperty = d3_style_prototype.setProperty; d3_element_prototype.setAttribute = function(name, value) { d3_element_setAttribute.call(this, name, value + """"); }; d3_element_prototype.setAttributeNS = function(space, local, value) { d3_element_setAttributeNS.call(this, space, local, value + """"); }; d3_style_prototype.setProperty = function(name, value, priority) { d3_style_setProperty.call(this, name, value + """", priority); }; } d3.ascending = d3_ascending; function d3_ascending(a, b) { return a < b ? -1 : a > b ? 1 : a >= b ? 0 : NaN; } d3.descending = function(a, b) { return b < a ? -1 : b > a ? 1 : b >= a ? 0 : NaN; }; d3.min = function(array, f) { var i = -1, n = array.length, a, b; if (arguments.length === 1) { while (++i < n && !((a = array[i]) != null && a <= a)) a = undefined; while (++i < n) if ((b = array[i]) != null && a > b) a = b; } else { while (++i < n && !((a = f.call(array, array[i], i)) != null && a <= a)) a = undefined; while (++i < n) if ((b = f.call(array, array[i], i)) != null && a > b) a = b; } return a; }; d3.max = function(array, f) { var i = -1, n = array.length, a, b; if (arguments.length === 1) { while (++i < n && !((a = array[i]) != null && a <= a)) a = undefined; while (++i < n) if ((b = array[i]) != null && b > a) a = b; } else { while (++i < n && !((a = f.call(array, array[i], i)) != null && a <= a)) a = undefined; while (++i < n) if ((b = f.call(array, array[i], i)) != null && b > a) a = b; } return a; }; d3.extent = function(array, f) { var i = -1, n = array.length, a, b, c; if (arguments.length === 1) { while (++i < n && !((a = c = array[i]) != null && a <= a)) a = c = undefined; while (++i < n) if ((b = array[i]) != null) { if (a > b) a = b; if (c < b) c = b; } } else { while (++i < n && !((a = c = f.call(array, array[i], i)) != null && a <= a)) a = undefined; while (++i < n) if ((b = f.call(array, array[i], i)) != null) { if (a > b) a = b; if (c < b) c = b; } } return [ a, c ]; }; d3.sum = function(array, f) { var s = 0, n = array.length, a, i = -1; if (arguments.length === 1) { while (++i < n) if (!isNaN(a = +array[i])) s += a; } else { while (++i < n) if (!isNaN(a = +f.call(array, array[i], i))) s += a; } return s; }; function d3_number(x) { return x != null && !isNaN(x); } d3.mean = function(array, f) { var n = array.length, a, m = 0, i = -1, j = 0; if (arguments.length === 1) { while (++i < n) if (d3_number(a = array[i])) m += (a - m) / ++j; } else { while (++i < n) if (d3_number(a = f.call(array, array[i], i))) m += (a - m) / ++j; } return j ? m : undefined; }; d3.quantile = function(values, p) { var H = (values.length - 1) * p + 1, h = Math.floor(H), v = +values[h - 1], e = H - h; return e ? v + e * (values[h] - v) : v; }; d3.median = function(array, f) { if (arguments.length > 1) array = array.map(f); array = array.filter(d3_number); return array.length ? d3.quantile(array.sort(d3_ascending), .5) : undefined; }; function d3_bisector(compare) { return { left: function(a, x, lo, hi) { if (arguments.length < 3) lo = 0; if (arguments.length < 4) hi = a.length; while (lo < hi) { var mid = lo + hi >>> 1; if (compare(a[mid], x) < 0) lo = mid + 1; else hi = mid; } return lo; }, right: function(a, x, lo, hi) { if (arguments.length < 3) lo = 0; if (arguments.length < 4) hi = a.length; while (lo < hi) { var mid = lo + hi >>> 1; if (compare(a[mid], x) > 0) hi = mid; else lo = mid + 1; } return lo; } }; } var d3_bisect = d3_bisector(d3_ascending); d3.bisectLeft = d3_bisect.left; d3.bisect = d3.bisectRight = d3_bisect.right; d3.bisector = function(f) { return d3_bisector(f.length === 1 ? function(d, x) { return d3_ascending(f(d), x); } : f); }; d3.shuffle = function(array) { var m = array.length, t, i; while (m) { i = Math.random() * m-- | 0; t = array[m], array[m] = array[i], array[i] = t; } return array; }; d3.permute = function(array, indexes) { var i = indexes.length, permutes = new Array(i); while (i--) permutes[i] = array[indexes[i]]; return permutes; }; d3.pairs = function(array) { var i = 0, n = array.length - 1, p0, p1 = array[0], pairs = new Array(n < 0 ? 0 : n); while (i < n) pairs[i] = [ p0 = p1, p1 = array[++i] ]; return pairs; }; d3.zip = function() { if (!(n = arguments.length)) return []; for (var i = -1, m = d3.min(arguments, d3_zipLength), zips = new Array(m); ++i < m; ) { for (var j = -1, n, zip = zips[i] = new Array(n); ++j < n; ) { zip[j] = arguments[j][i]; } } return zips; }; function d3_zipLength(d) { return d.length; } d3.transpose = function(matrix) { return d3.zip.apply(d3, matrix); }; d3.keys = function(map) { var keys = []; for (var key in map) keys.push(key); return keys; }; d3.values = function(map) { var values = []; for (var key in map) values.push(map[key]); return values; }; d3.entries = function(map) { var entries = []; for (var key in map) entries.push({ key: key, value: map[key] }); return entries; }; d3.merge = function(arrays) { var n = arrays.length, m, i = -1, j = 0, merged, array; while (++i < n) j += arrays[i].length; merged = new Array(j); while (--n >= 0) { array = arrays[n]; m = array.length; while (--m >= 0) { merged[--j] = array[m]; } } return merged; }; var abs = Math.abs; d3.range = function(start, stop, step) { if (arguments.length < 3) { step = 1; if (arguments.length < 2) { stop = start; start = 0; } } if ((stop - start) / step === Infinity) throw new Error(""infinite range""); var range = [], k = d3_range_integerScale(abs(step)), i = -1, j; start *= k, stop *= k, step *= k; if (step < 0) while ((j = start + step * ++i) > stop) range.push(j / k); else while ((j = start + step * ++i) < stop) range.push(j / k); return range; }; function d3_range_integerScale(x) { var k = 1; while (x * k % 1) k *= 10; return k; } function d3_class(ctor, properties) { try { for (var key in properties) { Object.defineProperty(ctor.prototype, key, { value: properties[key], enumerable: false }); } } catch (e) { ctor.prototype = properties; } } d3.map = function(object) { var map = new d3_Map(); if (object instanceof d3_Map) object.forEach(function(key, value) { map.set(key, value); }); else for (var key in object) map.set(key, object[key]); return map; }; function d3_Map() {} d3_class(d3_Map, { has: d3_map_has, get: function(key) { return this[d3_map_prefix + key]; }, set: function(key, value) { return this[d3_map_prefix + key] = value; }, remove: d3_map_remove, keys: d3_map_keys, values: function() { var values = []; this.forEach(function(key, value) { values.push(value); }); return values; }, entries: function() { var entries = []; this.forEach(function(key, value) { entries.push({ key: key, value: value }); }); return entries; }, size: d3_map_size, empty: d3_map_empty, forEach: function(f) { for (var key in this) if (key.charCodeAt(0) === d3_map_prefixCode) f.call(this, key.substring(1), this[key]); } }); var d3_map_prefix = ""\x00"", d3_map_prefixCode = d3_map_prefix.charCodeAt(0); function d3_map_has(key) { return d3_map_prefix + key in this; } function d3_map_remove(key) { key = d3_map_prefix + key; return key in this && delete this[key]; } function d3_map_keys() { var keys = []; this.forEach(function(key) { keys.push(key); }); return keys; } function d3_map_size() { var size = 0; for (var key in this) if (key.charCodeAt(0) === d3_map_prefixCode) ++size; return size; } function d3_map_empty() { for (var key in this) if (key.charCodeAt(0) === d3_map_prefixCode) return false; return true; } d3.nest = function() { var nest = {}, keys = [], sortKeys = [], sortValues, rollup; function map(mapType, array, depth) { if (depth >= keys.length) return rollup ? rollup.call(nest, array) : sortValues ? array.sort(sortValues) : array; var i = -1, n = array.length, key = keys[depth++], keyValue, object, setter, valuesByKey = new d3_Map(), values; while (++i < n) { if (values = valuesByKey.get(keyValue = key(object = array[i]))) { values.push(object); } else { valuesByKey.set(keyValue, [ object ]); } } if (mapType) { object = mapType(); setter = function(keyValue, values) { object.set(keyValue, map(mapType, values, depth)); }; } else { object = {}; setter = function(keyValue, values) { object[keyValue] = map(mapType, values, depth); }; } valuesByKey.forEach(setter); return object; } function entries(map, depth) { if (depth >= keys.length) return map; var array = [], sortKey = sortKeys[depth++]; map.forEach(function(key, keyMap) { array.push({ key: key, values: entries(keyMap, depth) }); }); return sortKey ? array.sort(function(a, b) { return sortKey(a.key, b.key); }) : array; } nest.map = function(array, mapType) { return map(mapType, array, 0); }; nest.entries = function(array) { return entries(map(d3.map, array, 0), 0); }; nest.key = function(d) { keys.push(d); return nest; }; nest.sortKeys = function(order) { sortKeys[keys.length - 1] = order; return nest; }; nest.sortValues = function(order) { sortValues = order; return nest; }; nest.rollup = function(f) { rollup = f; return nest; }; return nest; }; d3.set = function(array) { var set = new d3_Set(); if (array) for (var i = 0, n = array.length; i < n; ++i) set.add(array[i]); return set; }; function d3_Set() {} d3_class(d3_Set, { has: d3_map_has, add: function(value) { this[d3_map_prefix + value] = true; return value; }, remove: function(value) { value = d3_map_prefix + value; return value in this && delete this[value]; }, values: d3_map_keys, size: d3_map_size, empty: d3_map_empty, forEach: function(f) { for (var value in this) if (value.charCodeAt(0) === d3_map_prefixCode) f.call(this, value.substring(1)); } }); d3.behavior = {}; d3.rebind = function(target, source) { var i = 1, n = arguments.length, method; while (++i < n) target[method = arguments[i]] = d3_rebind(target, source, source[method]); return target; }; function d3_rebind(target, source, method) { return function() { var value = method.apply(source, arguments); return value === source ? target : value; }; } function d3_vendorSymbol(object, name) { if (name in object) return name; name = name.charAt(0).toUpperCase() + name.substring(1); for (var i = 0, n = d3_vendorPrefixes.length; i < n; ++i) { var prefixName = d3_vendorPrefixes[i] + name; if (prefixName in object) return prefixName; } } var d3_vendorPrefixes = [ ""webkit"", ""ms"", ""moz"", ""Moz"", ""o"", ""O"" ]; function d3_noop() {} d3.dispatch = function() { var dispatch = new d3_dispatch(), i = -1, n = arguments.length; while (++i < n) dispatch[arguments[i]] = d3_dispatch_event(dispatch); return dispatch; }; function d3_dispatch() {} d3_dispatch.prototype.on = function(type, listener) { var i = type.indexOf("".""), name = """"; if (i >= 0) { name = type.substring(i + 1); type = type.substring(0, i); } if (type) return arguments.length < 2 ? this[type].on(name) : this[type].on(name, listener); if (arguments.length === 2) { if (listener == null) for (type in this) { if (this.hasOwnProperty(type)) this[type].on(name, null); } return this; } }; function d3_dispatch_event(dispatch) { var listeners = [], listenerByName = new d3_Map(); function event() { var z = listeners, i = -1, n = z.length, l; while (++i < n) if (l = z[i].on) l.apply(this, arguments); return dispatch; } event.on = function(name, listener) { var l = listenerByName.get(name), i; if (arguments.length < 2) return l && l.on; if (l) { l.on = null; listeners = listeners.slice(0, i = listeners.indexOf(l)).concat(listeners.slice(i + 1)); listenerByName.remove(name); } if (listener) listeners.push(listenerByName.set(name, { on: listener })); return dispatch; }; return event; } d3.event = null; function d3_eventPreventDefault() { d3.event.preventDefault(); } function d3_eventSource() { var e = d3.event, s; while (s = e.sourceEvent) e = s; return e; } function d3_eventDispatch(target) { var dispatch = new d3_dispatch(), i = 0, n = arguments.length; while (++i < n) dispatch[arguments[i]] = d3_dispatch_event(dispatch); dispatch.of = function(thiz, argumentz) { return function(e1) { try { var e0 = e1.sourceEvent = d3.event; e1.target = target; d3.event = e1; dispatch[e1.type].apply(thiz, argumentz); } finally { d3.event = e0; } }; }; return dispatch; } d3.requote = function(s) { return s.replace(d3_requote_re, ""\\$&""); }; var d3_requote_re = /[\\\^\$\*\+\?\|\[\]\(\)\.\{\}]/g; var d3_subclass = {}.__proto__ ? function(object, prototype) { object.__proto__ = prototype; } : function(object, prototype) { for (var property in prototype) object[property] = prototype[property]; }; function d3_selection(groups) { d3_subclass(groups, d3_selectionPrototype); return groups; } var d3_select = function(s, n) { return n.querySelector(s); }, d3_selectAll = function(s, n) { return n.querySelectorAll(s); }, d3_selectMatcher = d3_documentElement[d3_vendorSymbol(d3_documentElement, ""matchesSelector"")], d3_selectMatches = function(n, s) { return d3_selectMatcher.call(n, s); }; if (typeof Sizzle === ""function"") { d3_select = function(s, n) { return Sizzle(s, n)[0] || null; }; d3_selectAll = Sizzle; d3_selectMatches = Sizzle.matchesSelector; } d3.selection = function() { return d3_selectionRoot; }; var d3_selectionPrototype = d3.selection.prototype = []; d3_selectionPrototype.select = function(selector) { var subgroups = [], subgroup, subnode, group, node; selector = d3_selection_selector(selector); for (var j = -1, m = this.length; ++j < m; ) { subgroups.push(subgroup = []); subgroup.parentNode = (group = this[j]).parentNode; for (var i = -1, n = group.length; ++i < n; ) { if (node = group[i]) { subgroup.push(subnode = selector.call(node, node.__data__, i, j)); if (subnode && ""__data__"" in node) subnode.__data__ = node.__data__; } else { subgroup.push(null); } } } return d3_selection(subgroups); }; function d3_selection_selector(selector) { return typeof selector === ""function"" ? selector : function() { return d3_select(selector, this); }; } d3_selectionPrototype.selectAll = function(selector) { var subgroups = [], subgroup, node; selector = d3_selection_selectorAll(selector); for (var j = -1, m = this.length; ++j < m; ) { for (var group = this[j], i = -1, n = group.length; ++i < n; ) { if (node = group[i]) { subgroups.push(subgroup = d3_array(selector.call(node, node.__data__, i, j))); subgroup.parentNode = node; } } } return d3_selection(subgroups); }; function d3_selection_selectorAll(selector) { return typeof selector === ""function"" ? selector : function() { return d3_selectAll(selector, this); }; } var d3_nsPrefix = { svg: ""http://www.w3.org/2000/svg"", xhtml: ""http://www.w3.org/1999/xhtml"", xlink: ""http://www.w3.org/1999/xlink"", xml: ""http://www.w3.org/XML/1998/namespace"", xmlns: ""http://www.w3.org/2000/xmlns/"" }; d3.ns = { prefix: d3_nsPrefix, qualify: function(name) { var i = name.indexOf("":""), prefix = name; if (i >= 0) { prefix = name.substring(0, i); name = name.substring(i + 1); } return d3_nsPrefix.hasOwnProperty(prefix) ? { space: d3_nsPrefix[prefix], local: name } : name; } }; d3_selectionPrototype.attr = function(name, value) { if (arguments.length < 2) { if (typeof name === ""string"") { var node = this.node(); name = d3.ns.qualify(name); return name.local ? node.getAttributeNS(name.space, name.local) : node.getAttribute(name); } for (value in name) this.each(d3_selection_attr(value, name[value])); return this; } return this.each(d3_selection_attr(name, value)); }; function d3_selection_attr(name, value) { name = d3.ns.qualify(name); function attrNull() { this.removeAttribute(name); } function attrNullNS() { this.removeAttributeNS(name.space, name.local); } function attrConstant() { this.setAttribute(name, value); } function attrConstantNS() { this.setAttributeNS(name.space, name.local, value); } function attrFunction() { var x = value.apply(this, arguments); if (x == null) this.removeAttribute(name); else this.setAttribute(name, x); } function attrFunctionNS() { var x = value.apply(this, arguments); if (x == null) this.removeAttributeNS(name.space, name.local); else this.setAttributeNS(name.space, name.local, x); } return value == null ? name.local ? attrNullNS : attrNull : typeof value === ""function"" ? name.local ? attrFunctionNS : attrFunction : name.local ? attrConstantNS : attrConstant; } function d3_collapse(s) { return s.trim().replace(/\s+/g, "" ""); } d3_selectionPrototype.classed = function(name, value) { if (arguments.length < 2) { if (typeof name === ""string"") { var node = this.node(), n = (name = d3_selection_classes(name)).length, i = -1; if (value = node.classList) { while (++i < n) if (!value.contains(name[i])) return false; } else { value = node.getAttribute(""class""); while (++i < n) if (!d3_selection_classedRe(name[i]).test(value)) return false; } return true; } for (value in name) this.each(d3_selection_classed(value, name[value])); return this; } return this.each(d3_selection_classed(name, value)); }; function d3_selection_classedRe(name) { return new RegExp(""(?:^|\\s+)"" + d3.requote(name) + ""(?:\\s+|$)"", ""g""); } function d3_selection_classes(name) { return name.trim().split(/^|\s+/); } function d3_selection_classed(name, value) { name = d3_selection_classes(name).map(d3_selection_classedName); var n = name.length; function classedConstant() { var i = -1; while (++i < n) name[i](this, value); } function classedFunction() { var i = -1, x = value.apply(this, arguments); while (++i < n) name[i](this, x); } return typeof value === ""function"" ? classedFunction : classedConstant; } function d3_selection_classedName(name) { var re = d3_selection_classedRe(name); return function(node, value) { if (c = node.classList) return value ? c.add(name) : c.remove(name); var c = node.getAttribute(""class"") || """"; if (value) { re.lastIndex = 0; if (!re.test(c)) node.setAttribute(""class"", d3_collapse(c + "" "" + name)); } else { node.setAttribute(""class"", d3_collapse(c.replace(re, "" ""))); } }; } d3_selectionPrototype.style = function(name, value, priority) { var n = arguments.length; if (n < 3) { if (typeof name !== ""string"") { if (n < 2) value = """"; for (priority in name) this.each(d3_selection_style(priority, name[priority], value)); return this; } if (n < 2) return d3_window.getComputedStyle(this.node(), null).getPropertyValue(name); priority = """"; } return this.each(d3_selection_style(name, value, priority)); }; function d3_selection_style(name, value, priority) { function styleNull() { this.style.removeProperty(name); } function styleConstant() { this.style.setProperty(name, value, priority); } function styleFunction() { var x = value.apply(this, arguments); if (x == null) this.style.removeProperty(name); else this.style.setProperty(name, x, priority); } return value == null ? styleNull : typeof value === ""function"" ? styleFunction : styleConstant; } d3_selectionPrototype.property = function(name, value) { if (arguments.length < 2) { if (typeof name === ""string"") return this.node()[name]; for (value in name) this.each(d3_selection_property(value, name[value])); return this; } return this.each(d3_selection_property(name, value)); }; function d3_selection_property(name, value) { function propertyNull() { delete this[name]; } function propertyConstant() { this[name] = value; } function propertyFunction() { var x = value.apply(this, arguments); if (x == null) delete this[name]; else this[name] = x; } return value == null ? propertyNull : typeof value === ""function"" ? propertyFunction : propertyConstant; } d3_selectionPrototype.text = function(value) { return arguments.length ? this.each(typeof value === ""function"" ? function() { var v = value.apply(this, arguments); this.textContent = v == null ? """" : v; } : value == null ? function() { this.textContent = """"; } : function() { this.textContent = value; }) : this.node().textContent; }; d3_selectionPrototype.html = function(value) { return arguments.length ? this.each(typeof value === ""function"" ? function() { var v = value.apply(this, arguments); this.innerHTML = v == null ? """" : v; } : value == null ? function() { this.innerHTML = """"; } : function() { this.innerHTML = value; }) : this.node().innerHTML; }; d3_selectionPrototype.append = function(name) { name = d3_selection_creator(name); return this.select(function() { return this.appendChild(name.apply(this, arguments)); }); }; function d3_selection_creator(name) { return typeof name === ""function"" ? name : (name = d3.ns.qualify(name)).local ? function() { return this.ownerDocument.createElementNS(name.space, name.local); } : function() { return this.ownerDocument.createElementNS(this.namespaceURI, name); }; } d3_selectionPrototype.insert = function(name, before) { name = d3_selection_creator(name); before = d3_selection_selector(before); return this.select(function() { return this.insertBefore(name.apply(this, arguments), before.apply(this, arguments) || null); }); }; d3_selectionPrototype.remove = function() { return this.each(function() { var parent = this.parentNode; if (parent) parent.removeChild(this); }); }; d3_selectionPrototype.data = function(value, key) { var i = -1, n = this.length, group, node; if (!arguments.length) { value = new Array(n = (group = this[0]).length); while (++i < n) { if (node = group[i]) { value[i] = node.__data__; } } return value; } function bind(group, groupData) { var i, n = group.length, m = groupData.length, n0 = Math.min(n, m), updateNodes = new Array(m), enterNodes = new Array(m), exitNodes = new Array(n), node, nodeData; if (key) { var nodeByKeyValue = new d3_Map(), dataByKeyValue = new d3_Map(), keyValues = [], keyValue; for (i = -1; ++i < n; ) { keyValue = key.call(node = group[i], node.__data__, i); if (nodeByKeyValue.has(keyValue)) { exitNodes[i] = node; } else { nodeByKeyValue.set(keyValue, node); } keyValues.push(keyValue); } for (i = -1; ++i < m; ) { keyValue = key.call(groupData, nodeData = groupData[i], i); if (node = nodeByKeyValue.get(keyValue)) { updateNodes[i] = node; node.__data__ = nodeData; } else if (!dataByKeyValue.has(keyValue)) { enterNodes[i] = d3_selection_dataNode(nodeData); } dataByKeyValue.set(keyValue, nodeData); nodeByKeyValue.remove(keyValue); } for (i = -1; ++i < n; ) { if (nodeByKeyValue.has(keyValues[i])) { exitNodes[i] = group[i]; } } } else { for (i = -1; ++i < n0; ) { node = group[i]; nodeData = groupData[i]; if (node) { node.__data__ = nodeData; updateNodes[i] = node; } else { enterNodes[i] = d3_selection_dataNode(nodeData); } } for (;i < m; ++i) { enterNodes[i] = d3_selection_dataNode(groupData[i]); } for (;i < n; ++i) { exitNodes[i] = group[i]; } } enterNodes.update = updateNodes; enterNodes.parentNode = updateNodes.parentNode = exitNodes.parentNode = group.parentNode; enter.push(enterNodes); update.push(updateNodes); exit.push(exitNodes); } var enter = d3_selection_enter([]), update = d3_selection([]), exit = d3_selection([]); if (typeof value === ""function"") { while (++i < n) { bind(group = this[i], value.call(group, group.parentNode.__data__, i)); } } else { while (++i < n) { bind(group = this[i], value); } } update.enter = function() { return enter; }; update.exit = function() { return exit; }; return update; }; function d3_selection_dataNode(data) { return { __data__: data }; } d3_selectionPrototype.datum = function(value) { return arguments.length ? this.property(""__data__"", value) : this.property(""__data__""); }; d3_selectionPrototype.filter = function(filter) { var subgroups = [], subgroup, group, node; if (typeof filter !== ""function"") filter = d3_selection_filter(filter); for (var j = 0, m = this.length; j < m; j++) { subgroups.push(subgroup = []); subgroup.parentNode = (group = this[j]).parentNode; for (var i = 0, n = group.length; i < n; i++) { if ((node = group[i]) && filter.call(node, node.__data__, i, j)) { subgroup.push(node); } } } return d3_selection(subgroups); }; function d3_selection_filter(selector) { return function() { return d3_selectMatches(this, selector); }; } d3_selectionPrototype.order = function() { for (var j = -1, m = this.length; ++j < m; ) { for (var group = this[j], i = group.length - 1, next = group[i], node; --i >= 0; ) { if (node = group[i]) { if (next && next !== node.nextSibling) next.parentNode.insertBefore(node, next); next = node; } } } return this; }; d3_selectionPrototype.sort = function(comparator) { comparator = d3_selection_sortComparator.apply(this, arguments); for (var j = -1, m = this.length; ++j < m; ) this[j].sort(comparator); return this.order(); }; function d3_selection_sortComparator(comparator) { if (!arguments.length) comparator = d3_ascending; return function(a, b) { return a && b ? comparator(a.__data__, b.__data__) : !a - !b; }; } d3_selectionPrototype.each = function(callback) { return d3_selection_each(this, function(node, i, j) { callback.call(node, node.__data__, i, j); }); }; function d3_selection_each(groups, callback) { for (var j = 0, m = groups.length; j < m; j++) { for (var group = groups[j], i = 0, n = group.length, node; i < n; i++) { if (node = group[i]) callback(node, i, j); } } return groups; } d3_selectionPrototype.call = function(callback) { var args = d3_array(arguments); callback.apply(args[0] = this, args); return this; }; d3_selectionPrototype.empty = function() { return !this.node(); }; d3_selectionPrototype.node = function() { for (var j = 0, m = this.length; j < m; j++) { for (var group = this[j], i = 0, n = group.length; i < n; i++) { var node = group[i]; if (node) return node; } } return null; }; d3_selectionPrototype.size = function() { var n = 0; this.each(function() { ++n; }); return n; }; function d3_selection_enter(selection) { d3_subclass(selection, d3_selection_enterPrototype); return selection; } var d3_selection_enterPrototype = []; d3.selection.enter = d3_selection_enter; d3.selection.enter.prototype = d3_selection_enterPrototype; d3_selection_enterPrototype.append = d3_selectionPrototype.append; d3_selection_enterPrototype.empty = d3_selectionPrototype.empty; d3_selection_enterPrototype.node = d3_selectionPrototype.node; d3_selection_enterPrototype.call = d3_selectionPrototype.call; d3_selection_enterPrototype.size = d3_selectionPrototype.size; d3_selection_enterPrototype.select = function(selector) { var subgroups = [], subgroup, subnode, upgroup, group, node; for (var j = -1, m = this.length; ++j < m; ) { upgroup = (group = this[j]).update; subgroups.push(subgroup = []); subgroup.parentNode = group.parentNode; for (var i = -1, n = group.length; ++i < n; ) { if (node = group[i]) { subgroup.push(upgroup[i] = subnode = selector.call(group.parentNode, node.__data__, i, j)); subnode.__data__ = node.__data__; } else { subgroup.push(null); } } } return d3_selection(subgroups); }; d3_selection_enterPrototype.insert = function(name, before) { if (arguments.length < 2) before = d3_selection_enterInsertBefore(this); return d3_selectionPrototype.insert.call(this, name, before); }; function d3_selection_enterInsertBefore(enter) { var i0, j0; return function(d, i, j) { var group = enter[j].update, n = group.length, node; if (j != j0) j0 = j, i0 = 0; if (i >= i0) i0 = i + 1; while (!(node = group[i0]) && ++i0 < n) ; return node; }; } d3_selectionPrototype.transition = function() { var id = d3_transitionInheritId || ++d3_transitionId, subgroups = [], subgroup, node, transition = d3_transitionInherit || { time: Date.now(), ease: d3_ease_cubicInOut, delay: 0, duration: 250 }; for (var j = -1, m = this.length; ++j < m; ) { subgroups.push(subgroup = []); for (var group = this[j], i = -1, n = group.length; ++i < n; ) { if (node = group[i]) d3_transitionNode(node, i, id, transition); subgroup.push(node); } } return d3_transition(subgroups, id); }; d3_selectionPrototype.interrupt = function() { return this.each(d3_selection_interrupt); }; function d3_selection_interrupt() { var lock = this.__transition__; if (lock) ++lock.active; } d3.select = function(node) { var group = [ typeof node === ""string"" ? d3_select(node, d3_document) : node ]; group.parentNode = d3_documentElement; return d3_selection([ group ]); }; d3.selectAll = function(nodes) { var group = d3_array(typeof nodes === ""string"" ? d3_selectAll(nodes, d3_document) : nodes); group.parentNode = d3_documentElement; return d3_selection([ group ]); }; var d3_selectionRoot = d3.select(d3_documentElement); d3_selectionPrototype.on = function(type, listener, capture) { var n = arguments.length; if (n < 3) { if (typeof type !== ""string"") { if (n < 2) listener = false; for (capture in type) this.each(d3_selection_on(capture, type[capture], listener)); return this; } if (n < 2) return (n = this.node()[""__on"" + type]) && n._; capture = false; } return this.each(d3_selection_on(type, listener, capture)); }; function d3_selection_on(type, listener, capture) { var name = ""__on"" + type, i = type.indexOf("".""), wrap = d3_selection_onListener; if (i > 0) type = type.substring(0, i); var filter = d3_selection_onFilters.get(type); if (filter) type = filter, wrap = d3_selection_onFilter; function onRemove() { var l = this[name]; if (l) { this.removeEventListener(type, l, l.$); delete this[name]; } } function onAdd() { var l = wrap(listener, d3_array(arguments)); onRemove.call(this); this.addEventListener(type, this[name] = l, l.$ = capture); l._ = listener; } function removeAll() { var re = new RegExp(""^__on([^.]+)"" + d3.requote(type) + ""$""), match; for (var name in this) { if (match = name.match(re)) { var l = this[name]; this.removeEventListener(match[1], l, l.$); delete this[name]; } } } return i ? listener ? onAdd : onRemove : listener ? d3_noop : removeAll; } var d3_selection_onFilters = d3.map({ mouseenter: ""mouseover"", mouseleave: ""mouseout"" }); d3_selection_onFilters.forEach(function(k) { if (""on"" + k in d3_document) d3_selection_onFilters.remove(k); }); function d3_selection_onListener(listener, argumentz) { return function(e) { var o = d3.event; d3.event = e; argumentz[0] = this.__data__; try { listener.apply(this, argumentz); } finally { d3.event = o; } }; } function d3_selection_onFilter(listener, argumentz) { var l = d3_selection_onListener(listener, argumentz); return function(e) { var target = this, related = e.relatedTarget; if (!related || related !== target && !(related.compareDocumentPosition(target) & 8)) { l.call(target, e); } }; } var d3_event_dragSelect = ""onselectstart"" in d3_document ? null : d3_vendorSymbol(d3_documentElement.style, ""userSelect""), d3_event_dragId = 0; function d3_event_dragSuppress() { var name = "".dragsuppress-"" + ++d3_event_dragId, click = ""click"" + name, w = d3.select(d3_window).on(""touchmove"" + name, d3_eventPreventDefault).on(""dragstart"" + name, d3_eventPreventDefault).on(""selectstart"" + name, d3_eventPreventDefault); if (d3_event_dragSelect) { var style = d3_documentElement.style, select = style[d3_event_dragSelect]; style[d3_event_dragSelect] = ""none""; } return function(suppressClick) { w.on(name, null); if (d3_event_dragSelect) style[d3_event_dragSelect] = select; if (suppressClick) { function off() { w.on(click, null); } w.on(click, function() { d3_eventPreventDefault(); off(); }, true); setTimeout(off, 0); } }; } d3.mouse = function(container) { return d3_mousePoint(container, d3_eventSource()); }; function d3_mousePoint(container, e) { if (e.changedTouches) e = e.changedTouches[0]; var svg = container.ownerSVGElement || container; if (svg.createSVGPoint) { var point = svg.createSVGPoint(); point.x = e.clientX, point.y = e.clientY; point = point.matrixTransform(container.getScreenCTM().inverse()); return [ point.x, point.y ]; } var rect = container.getBoundingClientRect(); return [ e.clientX - rect.left - container.clientLeft, e.clientY - rect.top - container.clientTop ]; } d3.touches = function(container, touches) { if (arguments.length < 2) touches = d3_eventSource().touches; return touches ? d3_array(touches).map(function(touch) { var point = d3_mousePoint(container, touch); point.identifier = touch.identifier; return point; }) : []; }; d3.behavior.drag = function() { var event = d3_eventDispatch(drag, ""drag"", ""dragstart"", ""dragend""), origin = null, mousedown = dragstart(d3_noop, d3.mouse, d3_behavior_dragMouseSubject, ""mousemove"", ""mouseup""), touchstart = dragstart(d3_behavior_dragTouchId, d3.touch, d3_behavior_dragTouchSubject, ""touchmove"", ""touchend""); function drag() { this.on(""mousedown.drag"", mousedown).on(""touchstart.drag"", touchstart); } function dragstart(id, position, subject, move, end) { return function() { var that = this, target = d3.event.target, parent = that.parentNode, dispatch = event.of(that, arguments), dragged = 0, dragId = id(), dragName = "".drag"" + (dragId == null ? """" : ""-"" + dragId), dragOffset, dragSubject = d3.select(subject()).on(move + dragName, moved).on(end + dragName, ended), dragRestore = d3_event_dragSuppress(), position0 = position(parent, dragId); if (origin) { dragOffset = origin.apply(that, arguments); dragOffset = [ dragOffset.x - position0[0], dragOffset.y - position0[1] ]; } else { dragOffset = [ 0, 0 ]; } dispatch({ type: ""dragstart"" }); function moved() { var position1 = position(parent, dragId), dx, dy; if (!position1) return; dx = position1[0] - position0[0]; dy = position1[1] - position0[1]; dragged |= dx | dy; position0 = position1; dispatch({ type: ""drag"", x: position1[0] + dragOffset[0], y: position1[1] + dragOffset[1], dx: dx, dy: dy }); } function ended() { if (!position(parent, dragId)) return; dragSubject.on(move + dragName, null).on(end + dragName, null); dragRestore(dragged && d3.event.target === target); dispatch({ type: ""dragend"" }); } }; } drag.origin = function(x) { if (!arguments.length) return origin; origin = x; return drag; }; return d3.rebind(drag, event, ""on""); }; function d3_behavior_dragTouchId() { return d3.event.changedTouches[0].identifier; } function d3_behavior_dragTouchSubject() { return d3.event.target; } function d3_behavior_dragMouseSubject() { return d3_window; } var π = Math.PI, τ = 2 * π, halfπ = π / 2, ε = 1e-6, ε2 = ε * ε, d3_radians = π / 180, d3_degrees = 180 / π; function d3_sgn(x) { return x > 0 ? 1 : x < 0 ? -1 : 0; } function d3_cross2d(a, b, c) { return (b[0] - a[0]) * (c[1] - a[1]) - (b[1] - a[1]) * (c[0] - a[0]); } function d3_acos(x) { return x > 1 ? 0 : x < -1 ? π : Math.acos(x); } function d3_asin(x) { return x > 1 ? halfπ : x < -1 ? -halfπ : Math.asin(x); } function d3_sinh(x) { return ((x = Math.exp(x)) - 1 / x) / 2; } function d3_cosh(x) { return ((x = Math.exp(x)) + 1 / x) / 2; } function d3_tanh(x) { return ((x = Math.exp(2 * x)) - 1) / (x + 1); } function d3_haversin(x) { return (x = Math.sin(x / 2)) * x; } var ρ = Math.SQRT2, ρ2 = 2, ρ4 = 4; d3.interpolateZoom = function(p0, p1) { var ux0 = p0[0], uy0 = p0[1], w0 = p0[2], ux1 = p1[0], uy1 = p1[1], w1 = p1[2]; var dx = ux1 - ux0, dy = uy1 - uy0, d2 = dx * dx + dy * dy, d1 = Math.sqrt(d2), b0 = (w1 * w1 - w0 * w0 + ρ4 * d2) / (2 * w0 * ρ2 * d1), b1 = (w1 * w1 - w0 * w0 - ρ4 * d2) / (2 * w1 * ρ2 * d1), r0 = Math.log(Math.sqrt(b0 * b0 + 1) - b0), r1 = Math.log(Math.sqrt(b1 * b1 + 1) - b1), dr = r1 - r0, S = (dr || Math.log(w1 / w0)) / ρ; function interpolate(t) { var s = t * S; if (dr) { var coshr0 = d3_cosh(r0), u = w0 / (ρ2 * d1) * (coshr0 * d3_tanh(ρ * s + r0) - d3_sinh(r0)); return [ ux0 + u * dx, uy0 + u * dy, w0 * coshr0 / d3_cosh(ρ * s + r0) ]; } return [ ux0 + t * dx, uy0 + t * dy, w0 * Math.exp(ρ * s) ]; } interpolate.duration = S * 1e3; return interpolate; }; d3.behavior.zoom = function() { var view = { x: 0, y: 0, k: 1 }, translate0, center, size = [ 960, 500 ], scaleExtent = d3_behavior_zoomInfinity, mousedown = ""mousedown.zoom"", mousemove = ""mousemove.zoom"", mouseup = ""mouseup.zoom"", mousewheelTimer, touchstart = ""touchstart.zoom"", touchtime, event = d3_eventDispatch(zoom, ""zoomstart"", ""zoom"", ""zoomend""), x0, x1, y0, y1; function zoom(g) { g.on(mousedown, mousedowned).on(d3_behavior_zoomWheel + "".zoom"", mousewheeled).on(mousemove, mousewheelreset).on(""dblclick.zoom"", dblclicked).on(touchstart, touchstarted); } zoom.event = function(g) { g.each(function() { var dispatch = event.of(this, arguments), view1 = view; if (d3_transitionInheritId) { d3.select(this).transition().each(""start.zoom"", function() { view = this.__chart__ || { x: 0, y: 0, k: 1 }; zoomstarted(dispatch); }).tween(""zoom:zoom"", function() { var dx = size[0], dy = size[1], cx = dx / 2, cy = dy / 2, i = d3.interpolateZoom([ (cx - view.x) / view.k, (cy - view.y) / view.k, dx / view.k ], [ (cx - view1.x) / view1.k, (cy - view1.y) / view1.k, dx / view1.k ]); return function(t) { var l = i(t), k = dx / l[2]; this.__chart__ = view = { x: cx - l[0] * k, y: cy - l[1] * k, k: k }; zoomed(dispatch); }; }).each(""end.zoom"", function() { zoomended(dispatch); }); } else { this.__chart__ = view; zoomstarted(dispatch); zoomed(dispatch); zoomended(dispatch); } }); }; zoom.translate = function(_) { if (!arguments.length) return [ view.x, view.y ]; view = { x: +_[0], y: +_[1], k: view.k }; rescale(); return zoom; }; zoom.scale = function(_) { if (!arguments.length) return view.k; view = { x: view.x, y: view.y, k: +_ }; rescale(); return zoom; }; zoom.scaleExtent = function(_) { if (!arguments.length) return scaleExtent; scaleExtent = _ == null ? d3_behavior_zoomInfinity : [ +_[0], +_[1] ]; return zoom; }; zoom.center = function(_) { if (!arguments.length) return center; center = _ && [ +_[0], +_[1] ]; return zoom; }; zoom.size = function(_) { if (!arguments.length) return size; size = _ && [ +_[0], +_[1] ]; return zoom; }; zoom.x = function(z) { if (!arguments.length) return x1; x1 = z; x0 = z.copy(); view = { x: 0, y: 0, k: 1 }; return zoom; }; zoom.y = function(z) { if (!arguments.length) return y1; y1 = z; y0 = z.copy(); view = { x: 0, y: 0, k: 1 }; return zoom; }; function location(p) { return [ (p[0] - view.x) / view.k, (p[1] - view.y) / view.k ]; } function point(l) { return [ l[0] * view.k + view.x, l[1] * view.k + view.y ]; } function scaleTo(s) { view.k = Math.max(scaleExtent[0], Math.min(scaleExtent[1], s)); } function translateTo(p, l) { l = point(l); view.x += p[0] - l[0]; view.y += p[1] - l[1]; } function rescale() { if (x1) x1.domain(x0.range().map(function(x) { return (x - view.x) / view.k; }).map(x0.invert)); if (y1) y1.domain(y0.range().map(function(y) { return (y - view.y) / view.k; }).map(y0.invert)); } function zoomstarted(dispatch) { dispatch({ type: ""zoomstart"" }); } function zoomed(dispatch) { rescale(); dispatch({ type: ""zoom"", scale: view.k, translate: [ view.x, view.y ] }); } function zoomended(dispatch) { dispatch({ type: ""zoomend"" }); } function mousedowned() { var that = this, target = d3.event.target, dispatch = event.of(that, arguments), dragged = 0, subject = d3.select(d3_window).on(mousemove, moved).on(mouseup, ended), location0 = location(d3.mouse(that)), dragRestore = d3_event_dragSuppress(); d3_selection_interrupt.call(that); zoomstarted(dispatch); function moved() { dragged = 1; translateTo(d3.mouse(that), location0); zoomed(dispatch); } function ended() { subject.on(mousemove, d3_window === that ? mousewheelreset : null).on(mouseup, null); dragRestore(dragged && d3.event.target === target); zoomended(dispatch); } } function touchstarted() { var that = this, dispatch = event.of(that, arguments), locations0 = {}, distance0 = 0, scale0, zoomName = "".zoom-"" + d3.event.changedTouches[0].identifier, touchmove = ""touchmove"" + zoomName, touchend = ""touchend"" + zoomName, target = d3.select(d3.event.target).on(touchmove, moved).on(touchend, ended), subject = d3.select(that).on(mousedown, null).on(touchstart, started), dragRestore = d3_event_dragSuppress(); d3_selection_interrupt.call(that); started(); zoomstarted(dispatch); function relocate() { var touches = d3.touches(that); scale0 = view.k; touches.forEach(function(t) { if (t.identifier in locations0) locations0[t.identifier] = location(t); }); return touches; } function started() { var changed = d3.event.changedTouches; for (var i = 0, n = changed.length; i < n; ++i) { locations0[changed[i].identifier] = null; } var touches = relocate(), now = Date.now(); if (touches.length === 1) { if (now - touchtime < 500) { var p = touches[0], l = locations0[p.identifier]; scaleTo(view.k * 2); translateTo(p, l); d3_eventPreventDefault(); zoomed(dispatch); } touchtime = now; } else if (touches.length > 1) { var p = touches[0], q = touches[1], dx = p[0] - q[0], dy = p[1] - q[1]; distance0 = dx * dx + dy * dy; } } function moved() { var touches = d3.touches(that), p0, l0, p1, l1; for (var i = 0, n = touches.length; i < n; ++i, l1 = null) { p1 = touches[i]; if (l1 = locations0[p1.identifier]) { if (l0) break; p0 = p1, l0 = l1; } } if (l1) { var distance1 = (distance1 = p1[0] - p0[0]) * distance1 + (distance1 = p1[1] - p0[1]) * distance1, scale1 = distance0 && Math.sqrt(distance1 / distance0); p0 = [ (p0[0] + p1[0]) / 2, (p0[1] + p1[1]) / 2 ]; l0 = [ (l0[0] + l1[0]) / 2, (l0[1] + l1[1]) / 2 ]; scaleTo(scale1 * scale0); } touchtime = null; translateTo(p0, l0); zoomed(dispatch); } function ended() { if (d3.event.touches.length) { var changed = d3.event.changedTouches; for (var i = 0, n = changed.length; i < n; ++i) { delete locations0[changed[i].identifier]; } for (var identifier in locations0) { return void relocate(); } } target.on(zoomName, null); subject.on(mousedown, mousedowned).on(touchstart, touchstarted); dragRestore(); zoomended(dispatch); } } function mousewheeled() { var dispatch = event.of(this, arguments); if (mousewheelTimer) clearTimeout(mousewheelTimer); else d3_selection_interrupt.call(this), zoomstarted(dispatch); mousewheelTimer = setTimeout(function() { mousewheelTimer = null; zoomended(dispatch); }, 50); d3_eventPreventDefault(); var point = center || d3.mouse(this); if (!translate0) translate0 = location(point); scaleTo(Math.pow(2, d3_behavior_zoomDelta() * .002) * view.k); translateTo(point, translate0); zoomed(dispatch); } function mousewheelreset() { translate0 = null; } function dblclicked() { var dispatch = event.of(this, arguments), p = d3.mouse(this), l = location(p), k = Math.log(view.k) / Math.LN2; zoomstarted(dispatch); scaleTo(Math.pow(2, d3.event.shiftKey ? Math.ceil(k) - 1 : Math.floor(k) + 1)); translateTo(p, l); zoomed(dispatch); zoomended(dispatch); } return d3.rebind(zoom, event, ""on""); }; var d3_behavior_zoomInfinity = [ 0, Infinity ]; var d3_behavior_zoomDelta, d3_behavior_zoomWheel = ""onwheel"" in d3_document ? (d3_behavior_zoomDelta = function() { return -d3.event.deltaY * (d3.event.deltaMode ? 120 : 1); }, ""wheel"") : ""onmousewheel"" in d3_document ? (d3_behavior_zoomDelta = function() { return d3.event.wheelDelta; }, ""mousewheel"") : (d3_behavior_zoomDelta = function() { return -d3.event.detail; }, ""MozMousePixelScroll""); function d3_Color() {} d3_Color.prototype.toString = function() { return this.rgb() + """"; }; d3.hsl = function(h, s, l) { return arguments.length === 1 ? h instanceof d3_Hsl ? d3_hsl(h.h, h.s, h.l) : d3_rgb_parse("""" + h, d3_rgb_hsl, d3_hsl) : d3_hsl(+h, +s, +l); }; function d3_hsl(h, s, l) { return new d3_Hsl(h, s, l); } function d3_Hsl(h, s, l) { this.h = h; this.s = s; this.l = l; } var d3_hslPrototype = d3_Hsl.prototype = new d3_Color(); d3_hslPrototype.brighter = function(k) { k = Math.pow(.7, arguments.length ? k : 1); return d3_hsl(this.h, this.s, this.l / k); }; d3_hslPrototype.darker = function(k) { k = Math.pow(.7, arguments.length ? k : 1); return d3_hsl(this.h, this.s, k * this.l); }; d3_hslPrototype.rgb = function() { return d3_hsl_rgb(this.h, this.s, this.l); }; function d3_hsl_rgb(h, s, l) { var m1, m2; h = isNaN(h) ? 0 : (h %= 360) < 0 ? h + 360 : h; s = isNaN(s) ? 0 : s < 0 ? 0 : s > 1 ? 1 : s; l = l < 0 ? 0 : l > 1 ? 1 : l; m2 = l <= .5 ? l * (1 + s) : l + s - l * s; m1 = 2 * l - m2; function v(h) { if (h > 360) h -= 360; else if (h < 0) h += 360; if (h < 60) return m1 + (m2 - m1) * h / 60; if (h < 180) return m2; if (h < 240) return m1 + (m2 - m1) * (240 - h) / 60; return m1; } function vv(h) { return Math.round(v(h) * 255); } return d3_rgb(vv(h + 120), vv(h), vv(h - 120)); } d3.hcl = function(h, c, l) { return arguments.length === 1 ? h instanceof d3_Hcl ? d3_hcl(h.h, h.c, h.l) : h instanceof d3_Lab ? d3_lab_hcl(h.l, h.a, h.b) : d3_lab_hcl((h = d3_rgb_lab((h = d3.rgb(h)).r, h.g, h.b)).l, h.a, h.b) : d3_hcl(+h, +c, +l); }; function d3_hcl(h, c, l) { return new d3_Hcl(h, c, l); } function d3_Hcl(h, c, l) { this.h = h; this.c = c; this.l = l; } var d3_hclPrototype = d3_Hcl.prototype = new d3_Color(); d3_hclPrototype.brighter = function(k) { return d3_hcl(this.h, this.c, Math.min(100, this.l + d3_lab_K * (arguments.length ? k : 1))); }; d3_hclPrototype.darker = function(k) { return d3_hcl(this.h, this.c, Math.max(0, this.l - d3_lab_K * (arguments.length ? k : 1))); }; d3_hclPrototype.rgb = function() { return d3_hcl_lab(this.h, this.c, this.l).rgb(); }; function d3_hcl_lab(h, c, l) { if (isNaN(h)) h = 0; if (isNaN(c)) c = 0; return d3_lab(l, Math.cos(h *= d3_radians) * c, Math.sin(h) * c); } d3.lab = function(l, a, b) { return arguments.length === 1 ? l instanceof d3_Lab ? d3_lab(l.l, l.a, l.b) : l instanceof d3_Hcl ? d3_hcl_lab(l.l, l.c, l.h) : d3_rgb_lab((l = d3.rgb(l)).r, l.g, l.b) : d3_lab(+l, +a, +b); }; function d3_lab(l, a, b) { return new d3_Lab(l, a, b); } function d3_Lab(l, a, b) { this.l = l; this.a = a; this.b = b; } var d3_lab_K = 18; var d3_lab_X = .95047, d3_lab_Y = 1, d3_lab_Z = 1.08883; var d3_labPrototype = d3_Lab.prototype = new d3_Color(); d3_labPrototype.brighter = function(k) { return d3_lab(Math.min(100, this.l + d3_lab_K * (arguments.length ? k : 1)), this.a, this.b); }; d3_labPrototype.darker = function(k) { return d3_lab(Math.max(0, this.l - d3_lab_K * (arguments.length ? k : 1)), this.a, this.b); }; d3_labPrototype.rgb = function() { return d3_lab_rgb(this.l, this.a, this.b); }; function d3_lab_rgb(l, a, b) { var y = (l + 16) / 116, x = y + a / 500, z = y - b / 200; x = d3_lab_xyz(x) * d3_lab_X; y = d3_lab_xyz(y) * d3_lab_Y; z = d3_lab_xyz(z) * d3_lab_Z; return d3_rgb(d3_xyz_rgb(3.2404542 * x - 1.5371385 * y - .4985314 * z), d3_xyz_rgb(-.969266 * x + 1.8760108 * y + .041556 * z), d3_xyz_rgb(.0556434 * x - .2040259 * y + 1.0572252 * z)); } function d3_lab_hcl(l, a, b) { return l > 0 ? d3_hcl(Math.atan2(b, a) * d3_degrees, Math.sqrt(a * a + b * b), l) : d3_hcl(NaN, NaN, l); } function d3_lab_xyz(x) { return x > .206893034 ? x * x * x : (x - 4 / 29) / 7.787037; } function d3_xyz_lab(x) { return x > .008856 ? Math.pow(x, 1 / 3) : 7.787037 * x + 4 / 29; } function d3_xyz_rgb(r) { return Math.round(255 * (r <= .00304 ? 12.92 * r : 1.055 * Math.pow(r, 1 / 2.4) - .055)); } d3.rgb = function(r, g, b) { return arguments.length === 1 ? r instanceof d3_Rgb ? d3_rgb(r.r, r.g, r.b) : d3_rgb_parse("""" + r, d3_rgb, d3_hsl_rgb) : d3_rgb(~~r, ~~g, ~~b); }; function d3_rgbNumber(value) { return d3_rgb(value >> 16, value >> 8 & 255, value & 255); } function d3_rgbString(value) { return d3_rgbNumber(value) + """"; } function d3_rgb(r, g, b) { return new d3_Rgb(r, g, b); } function d3_Rgb(r, g, b) { this.r = r; this.g = g; this.b = b; } var d3_rgbPrototype = d3_Rgb.prototype = new d3_Color(); d3_rgbPrototype.brighter = function(k) { k = Math.pow(.7, arguments.length ? k : 1); var r = this.r, g = this.g, b = this.b, i = 30; if (!r && !g && !b) return d3_rgb(i, i, i); if (r && r < i) r = i; if (g && g < i) g = i; if (b && b < i) b = i; return d3_rgb(Math.min(255, ~~(r / k)), Math.min(255, ~~(g / k)), Math.min(255, ~~(b / k))); }; d3_rgbPrototype.darker = function(k) { k = Math.pow(.7, arguments.length ? k : 1); return d3_rgb(~~(k * this.r), ~~(k * this.g), ~~(k * this.b)); }; d3_rgbPrototype.hsl = function() { return d3_rgb_hsl(this.r, this.g, this.b); }; d3_rgbPrototype.toString = function() { return ""#"" + d3_rgb_hex(this.r) + d3_rgb_hex(this.g) + d3_rgb_hex(this.b); }; function d3_rgb_hex(v) { return v < 16 ? ""0"" + Math.max(0, v).toString(16) : Math.min(255, v).toString(16); } function d3_rgb_parse(format, rgb, hsl) { var r = 0, g = 0, b = 0, m1, m2, color; m1 = /([a-z]+)\((.*)\)/i.exec(format); if (m1) { m2 = m1[2].split("",""); switch (m1[1]) { case ""hsl"": { return hsl(parseFloat(m2[0]), parseFloat(m2[1]) / 100, parseFloat(m2[2]) / 100); } case ""rgb"": { return rgb(d3_rgb_parseNumber(m2[0]), d3_rgb_parseNumber(m2[1]), d3_rgb_parseNumber(m2[2])); } } } if (color = d3_rgb_names.get(format)) return rgb(color.r, color.g, color.b); if (format != null && format.charAt(0) === ""#"" && !isNaN(color = parseInt(format.substring(1), 16))) { if (format.length === 4) { r = (color & 3840) >> 4; r = r >> 4 | r; g = color & 240; g = g >> 4 | g; b = color & 15; b = b << 4 | b; } else if (format.length === 7) { r = (color & 16711680) >> 16; g = (color & 65280) >> 8; b = color & 255; } } return rgb(r, g, b); } function d3_rgb_hsl(r, g, b) { var min = Math.min(r /= 255, g /= 255, b /= 255), max = Math.max(r, g, b), d = max - min, h, s, l = (max + min) / 2; if (d) { s = l < .5 ? d / (max + min) : d / (2 - max - min); if (r == max) h = (g - b) / d + (g < b ? 6 : 0); else if (g == max) h = (b - r) / d + 2; else h = (r - g) / d + 4; h *= 60; } else { h = NaN; s = l > 0 && l < 1 ? 0 : h; } return d3_hsl(h, s, l); } function d3_rgb_lab(r, g, b) { r = d3_rgb_xyz(r); g = d3_rgb_xyz(g); b = d3_rgb_xyz(b); var x = d3_xyz_lab((.4124564 * r + .3575761 * g + .1804375 * b) / d3_lab_X), y = d3_xyz_lab((.2126729 * r + .7151522 * g + .072175 * b) / d3_lab_Y), z = d3_xyz_lab((.0193339 * r + .119192 * g + .9503041 * b) / d3_lab_Z); return d3_lab(116 * y - 16, 500 * (x - y), 200 * (y - z)); } function d3_rgb_xyz(r) { return (r /= 255) <= .04045 ? r / 12.92 : Math.pow((r + .055) / 1.055, 2.4); } function d3_rgb_parseNumber(c) { var f = parseFloat(c); return c.charAt(c.length - 1) === ""%"" ? Math.round(f * 2.55) : f; } var d3_rgb_names = d3.map({ aliceblue: 15792383, antiquewhite: 16444375, aqua: 65535, aquamarine: 8388564, azure: 15794175, beige: 16119260, bisque: 16770244, black: 0, blanchedalmond: 16772045, blue: 255, blueviolet: 9055202, brown: 10824234, burlywood: 14596231, cadetblue: 6266528, chartreuse: 8388352, chocolate: 13789470, coral: 16744272, cornflowerblue: 6591981, cornsilk: 16775388, crimson: 14423100, cyan: 65535, darkblue: 139, darkcyan: 35723, darkgoldenrod: 12092939, darkgray: 11119017, darkgreen: 25600, darkgrey: 11119017, darkkhaki: 12433259, darkmagenta: 9109643, darkolivegreen: 5597999, darkorange: 16747520, darkorchid: 10040012, darkred: 9109504, darksalmon: 15308410, darkseagreen: 9419919, darkslateblue: 4734347, darkslategray: 3100495, darkslategrey: 3100495, darkturquoise: 52945, darkviolet: 9699539, deeppink: 16716947, deepskyblue: 49151, dimgray: 6908265, dimgrey: 6908265, dodgerblue: 2003199, firebrick: 11674146, floralwhite: 16775920, forestgreen: 2263842, fuchsia: 16711935, gainsboro: 14474460, ghostwhite: 16316671, gold: 16766720, goldenrod: 14329120, gray: 8421504, green: 32768, greenyellow: 11403055, grey: 8421504, honeydew: 15794160, hotpink: 16738740, indianred: 13458524, indigo: 4915330, ivory: 16777200, khaki: 15787660, lavender: 15132410, lavenderblush: 16773365, lawngreen: 8190976, lemonchiffon: 16775885, lightblue: 11393254, lightcoral: 15761536, lightcyan: 14745599, lightgoldenrodyellow: 16448210, lightgray: 13882323, lightgreen: 9498256, lightgrey: 13882323, lightpink: 16758465, lightsalmon: 16752762, lightseagreen: 2142890, lightskyblue: 8900346, lightslategray: 7833753, lightslategrey: 7833753, lightsteelblue: 11584734, lightyellow: 16777184, lime: 65280, limegreen: 3329330, linen: 16445670, magenta: 16711935, maroon: 8388608, mediumaquamarine: 6737322, mediumblue: 205, mediumorchid: 12211667, mediumpurple: 9662683, mediumseagreen: 3978097, mediumslateblue: 8087790, mediumspringgreen: 64154, mediumturquoise: 4772300, mediumvioletred: 13047173, midnightblue: 1644912, mintcream: 16121850, mistyrose: 16770273, moccasin: 16770229, navajowhite: 16768685, navy: 128, oldlace: 16643558, olive: 8421376, olivedrab: 7048739, orange: 16753920, orangered: 16729344, orchid: 14315734, palegoldenrod: 15657130, palegreen: 10025880, paleturquoise: 11529966, palevioletred: 14381203, papayawhip: 16773077, peachpuff: 16767673, peru: 13468991, pink: 16761035, plum: 14524637, powderblue: 11591910, purple: 8388736, red: 16711680, rosybrown: 12357519, royalblue: 4286945, saddlebrown: 9127187, salmon: 16416882, sandybrown: 16032864, seagreen: 3050327, seashell: 16774638, sienna: 10506797, silver: 12632256, skyblue: 8900331, slateblue: 6970061, slategray: 7372944, slategrey: 7372944, snow: 16775930, springgreen: 65407, steelblue: 4620980, tan: 13808780, teal: 32896, thistle: 14204888, tomato: 16737095, turquoise: 4251856, violet: 15631086, wheat: 16113331, white: 16777215, whitesmoke: 16119285, yellow: 16776960, yellowgreen: 10145074 }); d3_rgb_names.forEach(function(key, value) { d3_rgb_names.set(key, d3_rgbNumber(value)); }); function d3_functor(v) { return typeof v === ""function"" ? v : function() { return v; }; } d3.functor = d3_functor; function d3_identity(d) { return d; } d3.xhr = d3_xhrType(d3_identity); function d3_xhrType(response) { return function(url, mimeType, callback) { if (arguments.length === 2 && typeof mimeType === ""function"") callback = mimeType, mimeType = null; return d3_xhr(url, mimeType, response, callback); }; } function d3_xhr(url, mimeType, response, callback) { var xhr = {}, dispatch = d3.dispatch(""beforesend"", ""progress"", ""load"", ""error""), headers = {}, request = new XMLHttpRequest(), responseType = null; if (d3_window.XDomainRequest && !(""withCredentials"" in request) && /^(http(s)?:)?\/\//.test(url)) request = new XDomainRequest(); ""onload"" in request ? request.onload = request.onerror = respond : request.onreadystatechange = function() { request.readyState > 3 && respond(); }; function respond() { var status = request.status, result; if (!status && request.responseText || status >= 200 && status < 300 || status === 304) { try { result = response.call(xhr, request); } catch (e) { dispatch.error.call(xhr, e); return; } dispatch.load.call(xhr, result); } else { dispatch.error.call(xhr, request); } } request.onprogress = function(event) { var o = d3.event; d3.event = event; try { dispatch.progress.call(xhr, request); } finally { d3.event = o; } }; xhr.header = function(name, value) { name = (name + """").toLowerCase(); if (arguments.length < 2) return headers[name]; if (value == null) delete headers[name]; else headers[name] = value + """"; return xhr; }; xhr.mimeType = function(value) { if (!arguments.length) return mimeType; mimeType = value == null ? null : value + """"; return xhr; }; xhr.responseType = function(value) { if (!arguments.length) return responseType; responseType = value; return xhr; }; xhr.response = function(value) { response = value; return xhr; }; [ ""get"", ""post"" ].forEach(function(method) { xhr[method] = function() { return xhr.send.apply(xhr, [ method ].concat(d3_array(arguments))); }; }); xhr.send = function(method, data, callback) { if (arguments.length === 2 && typeof data === ""function"") callback = data, data = null; request.open(method, url, true); if (mimeType != null && !(""accept"" in headers)) headers[""accept""] = mimeType + "",*/*""; if (request.setRequestHeader) for (var name in headers) request.setRequestHeader(name, headers[name]); if (mimeType != null && request.overrideMimeType) request.overrideMimeType(mimeType); if (responseType != null) request.responseType = responseType; if (callback != null) xhr.on(""error"", callback).on(""load"", function(request) { callback(null, request); }); dispatch.beforesend.call(xhr, request); request.send(data == null ? null : data); return xhr; }; xhr.abort = function() { request.abort(); return xhr; }; d3.rebind(xhr, dispatch, ""on""); return callback == null ? xhr : xhr.get(d3_xhr_fixCallback(callback)); } function d3_xhr_fixCallback(callback) { return callback.length === 1 ? function(error, request) { callback(error == null ? request : null); } : callback; } d3.dsv = function(delimiter, mimeType) { var reFormat = new RegExp('[""' + delimiter + ""\n]""), delimiterCode = delimiter.charCodeAt(0); function dsv(url, row, callback) { if (arguments.length < 3) callback = row, row = null; var xhr = d3_xhr(url, mimeType, row == null ? response : typedResponse(row), callback); xhr.row = function(_) { return arguments.length ? xhr.response((row = _) == null ? response : typedResponse(_)) : row; }; return xhr; } function response(request) { return dsv.parse(request.responseText); } function typedResponse(f) { return function(request) { return dsv.parse(request.responseText, f); }; } dsv.parse = function(text, f) { var o; return dsv.parseRows(text, function(row, i) { if (o) return o(row, i - 1); var a = new Function(""d"", ""return {"" + row.map(function(name, i) { return JSON.stringify(name) + "": d["" + i + ""]""; }).join("","") + ""}""); o = f ? function(row, i) { return f(a(row), i); } : a; }); }; dsv.parseRows = function(text, f) { var EOL = {}, EOF = {}, rows = [], N = text.length, I = 0, n = 0, t, eol; function token() { if (I >= N) return EOF; if (eol) return eol = false, EOL; var j = I; if (text.charCodeAt(j) === 34) { var i = j; while (i++ < N) { if (text.charCodeAt(i) === 34) { if (text.charCodeAt(i + 1) !== 34) break; ++i; } } I = i + 2; var c = text.charCodeAt(i + 1); if (c === 13) { eol = true; if (text.charCodeAt(i + 2) === 10) ++I; } else if (c === 10) { eol = true; } return text.substring(j + 1, i).replace(/""""/g, '""'); } while (I < N) { var c = text.charCodeAt(I++), k = 1; if (c === 10) eol = true; else if (c === 13) { eol = true; if (text.charCodeAt(I) === 10) ++I, ++k; } else if (c !== delimiterCode) continue; return text.substring(j, I - k); } return text.substring(j); } while ((t = token()) !== EOF) { var a = []; while (t !== EOL && t !== EOF) { a.push(t); t = token(); } if (f && !(a = f(a, n++))) continue; rows.push(a); } return rows; }; dsv.format = function(rows) { if (Array.isArray(rows[0])) return dsv.formatRows(rows); var fieldSet = new d3_Set(), fields = []; rows.forEach(function(row) { for (var field in row) { if (!fieldSet.has(field)) { fields.push(fieldSet.add(field)); } } }); return [ fields.map(formatValue).join(delimiter) ].concat(rows.map(function(row) { return fields.map(function(field) { return formatValue(row[field]); }).join(delimiter); })).join(""\n""); }; dsv.formatRows = function(rows) { return rows.map(formatRow).join(""\n""); }; function formatRow(row) { return row.map(formatValue).join(delimiter); } function formatValue(text) { return reFormat.test(text) ? '""' + text.replace(/\""/g, '""""') + '""' : text; } return dsv; }; d3.csv = d3.dsv("","", ""text/csv""); d3.tsv = d3.dsv("" "", ""text/tab-separated-values""); d3.touch = function(container, touches, identifier) { if (arguments.length < 3) identifier = touches, touches = d3_eventSource().changedTouches; if (touches) for (var i = 0, n = touches.length, touch; i < n; ++i) { if ((touch = touches[i]).identifier === identifier) { return d3_mousePoint(container, touch); } } }; var d3_timer_queueHead, d3_timer_queueTail, d3_timer_interval, d3_timer_timeout, d3_timer_active, d3_timer_frame = d3_window[d3_vendorSymbol(d3_window, ""requestAnimationFrame"")] || function(callback) { setTimeout(callback, 17); }; d3.timer = function(callback, delay, then) { var n = arguments.length; if (n < 2) delay = 0; if (n < 3) then = Date.now(); var time = then + delay, timer = { c: callback, t: time, f: false, n: null }; if (d3_timer_queueTail) d3_timer_queueTail.n = timer; else d3_timer_queueHead = timer; d3_timer_queueTail = timer; if (!d3_timer_interval) { d3_timer_timeout = clearTimeout(d3_timer_timeout); d3_timer_interval = 1; d3_timer_frame(d3_timer_step); } }; function d3_timer_step() { var now = d3_timer_mark(), delay = d3_timer_sweep() - now; if (delay > 24) { if (isFinite(delay)) { clearTimeout(d3_timer_timeout); d3_timer_timeout = setTimeout(d3_timer_step, delay); } d3_timer_interval = 0; } else { d3_timer_interval = 1; d3_timer_frame(d3_timer_step); } } d3.timer.flush = function() { d3_timer_mark(); d3_timer_sweep(); }; function d3_timer_mark() { var now = Date.now(); d3_timer_active = d3_timer_queueHead; while (d3_timer_active) { if (now >= d3_timer_active.t) d3_timer_active.f = d3_timer_active.c(now - d3_timer_active.t); d3_timer_active = d3_timer_active.n; } return now; } function d3_timer_sweep() { var t0, t1 = d3_timer_queueHead, time = Infinity; while (t1) { if (t1.f) { t1 = t0 ? t0.n = t1.n : d3_timer_queueHead = t1.n; } else { if (t1.t < time) time = t1.t; t1 = (t0 = t1).n; } } d3_timer_queueTail = t0; return time; } function d3_format_precision(x, p) { return p - (x ? Math.ceil(Math.log(x) / Math.LN10) : 1); } d3.round = function(x, n) { return n ? Math.round(x * (n = Math.pow(10, n))) / n : Math.round(x); }; var d3_formatPrefixes = [ ""y"", ""z"", ""a"", ""f"", ""p"", ""n"", ""µ"", ""m"", """", ""k"", ""M"", ""G"", ""T"", ""P"", ""E"", ""Z"", ""Y"" ].map(d3_formatPrefix); d3.formatPrefix = function(value, precision) { var i = 0; if (value) { if (value < 0) value *= -1; if (precision) value = d3.round(value, d3_format_precision(value, precision)); i = 1 + Math.floor(1e-12 + Math.log(value) / Math.LN10); i = Math.max(-24, Math.min(24, Math.floor((i - 1) / 3) * 3)); } return d3_formatPrefixes[8 + i / 3]; }; function d3_formatPrefix(d, i) { var k = Math.pow(10, abs(8 - i) * 3); return { scale: i > 8 ? function(d) { return d / k; } : function(d) { return d * k; }, symbol: d }; } function d3_locale_numberFormat(locale) { var locale_decimal = locale.decimal, locale_thousands = locale.thousands, locale_grouping = locale.grouping, locale_currency = locale.currency, formatGroup = locale_grouping ? function(value) { var i = value.length, t = [], j = 0, g = locale_grouping[0]; while (i > 0 && g > 0) { t.push(value.substring(i -= g, i + g)); g = locale_grouping[j = (j + 1) % locale_grouping.length]; } return t.reverse().join(locale_thousands); } : d3_identity; return function(specifier) { var match = d3_format_re.exec(specifier), fill = match[1] || "" "", align = match[2] || "">"", sign = match[3] || """", symbol = match[4] || """", zfill = match[5], width = +match[6], comma = match[7], precision = match[8], type = match[9], scale = 1, prefix = """", suffix = """", integer = false; if (precision) precision = +precision.substring(1); if (zfill || fill === ""0"" && align === ""="") { zfill = fill = ""0""; align = ""=""; if (comma) width -= Math.floor((width - 1) / 4); } switch (type) { case ""n"": comma = true; type = ""g""; break; case ""%"": scale = 100; suffix = ""%""; type = ""f""; break; case ""p"": scale = 100; suffix = ""%""; type = ""r""; break; case ""b"": case ""o"": case ""x"": case ""X"": if (symbol === ""#"") prefix = ""0"" + type.toLowerCase(); case ""c"": case ""d"": integer = true; precision = 0; break; case ""s"": scale = -1; type = ""r""; break; } if (symbol === ""$"") prefix = locale_currency[0], suffix = locale_currency[1]; if (type == ""r"" && !precision) type = ""g""; if (precision != null) { if (type == ""g"") precision = Math.max(1, Math.min(21, precision)); else if (type == ""e"" || type == ""f"") precision = Math.max(0, Math.min(20, precision)); } type = d3_format_types.get(type) || d3_format_typeDefault; var zcomma = zfill && comma; return function(value) { var fullSuffix = suffix; if (integer && value % 1) return """"; var negative = value < 0 || value === 0 && 1 / value < 0 ? (value = -value, ""-"") : sign; if (scale < 0) { var unit = d3.formatPrefix(value, precision); value = unit.scale(value); fullSuffix = unit.symbol + suffix; } else { value *= scale; } value = type(value, precision); var i = value.lastIndexOf("".""), before = i < 0 ? value : value.substring(0, i), after = i < 0 ? """" : locale_decimal + value.substring(i + 1); if (!zfill && comma) before = formatGroup(before); var length = prefix.length + before.length + after.length + (zcomma ? 0 : negative.length), padding = length < width ? new Array(length = width - length + 1).join(fill) : """"; if (zcomma) before = formatGroup(padding + before); negative += prefix; value = before + after; return (align === ""<"" ? negative + value + padding : align === "">"" ? padding + negative + value : align === ""^"" ? padding.substring(0, length >>= 1) + negative + value + padding.substring(length) : negative + (zcomma ? value : padding + value)) + fullSuffix; }; }; } var d3_format_re = /(?:([^{])?([<>=^]))?([+\- ])?([$#])?(0)?(\d+)?(,)?(\.-?\d+)?([a-z%])?/i; var d3_format_types = d3.map({ b: function(x) { return x.toString(2); }, c: function(x) { return String.fromCharCode(x); }, o: function(x) { return x.toString(8); }, x: function(x) { return x.toString(16); }, X: function(x) { return x.toString(16).toUpperCase(); }, g: function(x, p) { return x.toPrecision(p); }, e: function(x, p) { return x.toExponential(p); }, f: function(x, p) { return x.toFixed(p); }, r: function(x, p) { return (x = d3.round(x, d3_format_precision(x, p))).toFixed(Math.max(0, Math.min(20, d3_format_precision(x * (1 + 1e-15), p)))); } }); function d3_format_typeDefault(x) { return x + """"; } var d3_time = d3.time = {}, d3_date = Date; function d3_date_utc() { this._ = new Date(arguments.length > 1 ? Date.UTC.apply(this, arguments) : arguments[0]); } d3_date_utc.prototype = { getDate: function() { return this._.getUTCDate(); }, getDay: function() { return this._.getUTCDay(); }, getFullYear: function() { return this._.getUTCFullYear(); }, getHours: function() { return this._.getUTCHours(); }, getMilliseconds: function() { return this._.getUTCMilliseconds(); }, getMinutes: function() { return this._.getUTCMinutes(); }, getMonth: function() { return this._.getUTCMonth(); }, getSeconds: function() { return this._.getUTCSeconds(); }, getTime: function() { return this._.getTime(); }, getTimezoneOffset: function() { return 0; }, valueOf: function() { return this._.valueOf(); }, setDate: function() { d3_time_prototype.setUTCDate.apply(this._, arguments); }, setDay: function() { d3_time_prototype.setUTCDay.apply(this._, arguments); }, setFullYear: function() { d3_time_prototype.setUTCFullYear.apply(this._, arguments); }, setHours: function() { d3_time_prototype.setUTCHours.apply(this._, arguments); }, setMilliseconds: function() { d3_time_prototype.setUTCMilliseconds.apply(this._, arguments); }, setMinutes: function() { d3_time_prototype.setUTCMinutes.apply(this._, arguments); }, setMonth: function() { d3_time_prototype.setUTCMonth.apply(this._, arguments); }, setSeconds: function() { d3_time_prototype.setUTCSeconds.apply(this._, arguments); }, setTime: function() { d3_time_prototype.setTime.apply(this._, arguments); } }; var d3_time_prototype = Date.prototype; function d3_time_interval(local, step, number) { function round(date) { var d0 = local(date), d1 = offset(d0, 1); return date - d0 < d1 - date ? d0 : d1; } function ceil(date) { step(date = local(new d3_date(date - 1)), 1); return date; } function offset(date, k) { step(date = new d3_date(+date), k); return date; } function range(t0, t1, dt) { var time = ceil(t0), times = []; if (dt > 1) { while (time < t1) { if (!(number(time) % dt)) times.push(new Date(+time)); step(time, 1); } } else { while (time < t1) times.push(new Date(+time)), step(time, 1); } return times; } function range_utc(t0, t1, dt) { try { d3_date = d3_date_utc; var utc = new d3_date_utc(); utc._ = t0; return range(utc, t1, dt); } finally { d3_date = Date; } } local.floor = local; local.round = round; local.ceil = ceil; local.offset = offset; local.range = range; var utc = local.utc = d3_time_interval_utc(local); utc.floor = utc; utc.round = d3_time_interval_utc(round); utc.ceil = d3_time_interval_utc(ceil); utc.offset = d3_time_interval_utc(offset); utc.range = range_utc; return local; } function d3_time_interval_utc(method) { return function(date, k) { try { d3_date = d3_date_utc; var utc = new d3_date_utc(); utc._ = date; return method(utc, k)._; } finally { d3_date = Date; } }; } d3_time.year = d3_time_interval(function(date) { date = d3_time.day(date); date.setMonth(0, 1); return date; }, function(date, offset) { date.setFullYear(date.getFullYear() + offset); }, function(date) { return date.getFullYear(); }); d3_time.years = d3_time.year.range; d3_time.years.utc = d3_time.year.utc.range; d3_time.day = d3_time_interval(function(date) { var day = new d3_date(2e3, 0); day.setFullYear(date.getFullYear(), date.getMonth(), date.getDate()); return day; }, function(date, offset) { date.setDate(date.getDate() + offset); }, function(date) { return date.getDate() - 1; }); d3_time.days = d3_time.day.range; d3_time.days.utc = d3_time.day.utc.range; d3_time.dayOfYear = function(date) { var year = d3_time.year(date); return Math.floor((date - year - (date.getTimezoneOffset() - year.getTimezoneOffset()) * 6e4) / 864e5); }; [ ""sunday"", ""monday"", ""tuesday"", ""wednesday"", ""thursday"", ""friday"", ""saturday"" ].forEach(function(day, i) { i = 7 - i; var interval = d3_time[day] = d3_time_interval(function(date) { (date = d3_time.day(date)).setDate(date.getDate() - (date.getDay() + i) % 7); return date; }, function(date, offset) { date.setDate(date.getDate() + Math.floor(offset) * 7); }, function(date) { var day = d3_time.year(date).getDay(); return Math.floor((d3_time.dayOfYear(date) + (day + i) % 7) / 7) - (day !== i); }); d3_time[day + ""s""] = interval.range; d3_time[day + ""s""].utc = interval.utc.range; d3_time[day + ""OfYear""] = function(date) { var day = d3_time.year(date).getDay(); return Math.floor((d3_time.dayOfYear(date) + (day + i) % 7) / 7); }; }); d3_time.week = d3_time.sunday; d3_time.weeks = d3_time.sunday.range; d3_time.weeks.utc = d3_time.sunday.utc.range; d3_time.weekOfYear = d3_time.sundayOfYear; function d3_locale_timeFormat(locale) { var locale_dateTime = locale.dateTime, locale_date = locale.date, locale_time = locale.time, locale_periods = locale.periods, locale_days = locale.days, locale_shortDays = locale.shortDays, locale_months = locale.months, locale_shortMonths = locale.shortMonths; function d3_time_format(template) { var n = template.length; function format(date) { var string = [], i = -1, j = 0, c, p, f; while (++i < n) { if (template.charCodeAt(i) === 37) { string.push(template.substring(j, i)); if ((p = d3_time_formatPads[c = template.charAt(++i)]) != null) c = template.charAt(++i); if (f = d3_time_formats[c]) c = f(date, p == null ? c === ""e"" ? "" "" : ""0"" : p); string.push(c); j = i + 1; } } string.push(template.substring(j, i)); return string.join(""""); } format.parse = function(string) { var d = { y: 1900, m: 0, d: 1, H: 0, M: 0, S: 0, L: 0, Z: null }, i = d3_time_parse(d, template, string, 0); if (i != string.length) return null; if (""p"" in d) d.H = d.H % 12 + d.p * 12; var localZ = d.Z != null && d3_date !== d3_date_utc, date = new (localZ ? d3_date_utc : d3_date)(); if (""j"" in d) date.setFullYear(d.y, 0, d.j); else if (""w"" in d && (""W"" in d || ""U"" in d)) { date.setFullYear(d.y, 0, 1); date.setFullYear(d.y, 0, ""W"" in d ? (d.w + 6) % 7 + d.W * 7 - (date.getDay() + 5) % 7 : d.w + d.U * 7 - (date.getDay() + 6) % 7); } else date.setFullYear(d.y, d.m, d.d); date.setHours(d.H + Math.floor(d.Z / 100), d.M + d.Z % 100, d.S, d.L); return localZ ? date._ : date; }; format.toString = function() { return template; }; return format; } function d3_time_parse(date, template, string, j) { var c, p, t, i = 0, n = template.length, m = string.length; while (i < n) { if (j >= m) return -1; c = template.charCodeAt(i++); if (c === 37) { t = template.charAt(i++); p = d3_time_parsers[t in d3_time_formatPads ? template.charAt(i++) : t]; if (!p || (j = p(date, string, j)) < 0) return -1; } else if (c != string.charCodeAt(j++)) { return -1; } } return j; } d3_time_format.utc = function(template) { var local = d3_time_format(template); function format(date) { try { d3_date = d3_date_utc; var utc = new d3_date(); utc._ = date; return local(utc); } finally { d3_date = Date; } } format.parse = function(string) { try { d3_date = d3_date_utc; var date = local.parse(string); return date && date._; } finally { d3_date = Date; } }; format.toString = local.toString; return format; }; d3_time_format.multi = d3_time_format.utc.multi = d3_time_formatMulti; var d3_time_periodLookup = d3.map(), d3_time_dayRe = d3_time_formatRe(locale_days), d3_time_dayLookup = d3_time_formatLookup(locale_days), d3_time_dayAbbrevRe = d3_time_formatRe(locale_shortDays), d3_time_dayAbbrevLookup = d3_time_formatLookup(locale_shortDays), d3_time_monthRe = d3_time_formatRe(locale_months), d3_time_monthLookup = d3_time_formatLookup(locale_months), d3_time_monthAbbrevRe = d3_time_formatRe(locale_shortMonths), d3_time_monthAbbrevLookup = d3_time_formatLookup(locale_shortMonths); locale_periods.forEach(function(p, i) { d3_time_periodLookup.set(p.toLowerCase(), i); }); var d3_time_formats = { a: function(d) { return locale_shortDays[d.getDay()]; }, A: function(d) { return locale_days[d.getDay()]; }, b: function(d) { return locale_shortMonths[d.getMonth()]; }, B: function(d) { return locale_months[d.getMonth()]; }, c: d3_time_format(locale_dateTime), d: function(d, p) { return d3_time_formatPad(d.getDate(), p, 2); }, e: function(d, p) { return d3_time_formatPad(d.getDate(), p, 2); }, H: function(d, p) { return d3_time_formatPad(d.getHours(), p, 2); }, I: function(d, p) { return d3_time_formatPad(d.getHours() % 12 || 12, p, 2); }, j: function(d, p) { return d3_time_formatPad(1 + d3_time.dayOfYear(d), p, 3); }, L: function(d, p) { return d3_time_formatPad(d.getMilliseconds(), p, 3); }, m: function(d, p) { return d3_time_formatPad(d.getMonth() + 1, p, 2); }, M: function(d, p) { return d3_time_formatPad(d.getMinutes(), p, 2); }, p: function(d) { return locale_periods[+(d.getHours() >= 12)]; }, S: function(d, p) { return d3_time_formatPad(d.getSeconds(), p, 2); }, U: function(d, p) { return d3_time_formatPad(d3_time.sundayOfYear(d), p, 2); }, w: function(d) { return d.getDay(); }, W: function(d, p) { return d3_time_formatPad(d3_time.mondayOfYear(d), p, 2); }, x: d3_time_format(locale_date), X: d3_time_format(locale_time), y: function(d, p) { return d3_time_formatPad(d.getFullYear() % 100, p, 2); }, Y: function(d, p) { return d3_time_formatPad(d.getFullYear() % 1e4, p, 4); }, Z: d3_time_zone, ""%"": function() { return ""%""; } }; var d3_time_parsers = { a: d3_time_parseWeekdayAbbrev, A: d3_time_parseWeekday, b: d3_time_parseMonthAbbrev, B: d3_time_parseMonth, c: d3_time_parseLocaleFull, d: d3_time_parseDay, e: d3_time_parseDay, H: d3_time_parseHour24, I: d3_time_parseHour24, j: d3_time_parseDayOfYear, L: d3_time_parseMilliseconds, m: d3_time_parseMonthNumber, M: d3_time_parseMinutes, p: d3_time_parseAmPm, S: d3_time_parseSeconds, U: d3_time_parseWeekNumberSunday, w: d3_time_parseWeekdayNumber, W: d3_time_parseWeekNumberMonday, x: d3_time_parseLocaleDate, X: d3_time_parseLocaleTime, y: d3_time_parseYear, Y: d3_time_parseFullYear, Z: d3_time_parseZone, ""%"": d3_time_parseLiteralPercent }; function d3_time_parseWeekdayAbbrev(date, string, i) { d3_time_dayAbbrevRe.lastIndex = 0; var n = d3_time_dayAbbrevRe.exec(string.substring(i)); return n ? (date.w = d3_time_dayAbbrevLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseWeekday(date, string, i) { d3_time_dayRe.lastIndex = 0; var n = d3_time_dayRe.exec(string.substring(i)); return n ? (date.w = d3_time_dayLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseMonthAbbrev(date, string, i) { d3_time_monthAbbrevRe.lastIndex = 0; var n = d3_time_monthAbbrevRe.exec(string.substring(i)); return n ? (date.m = d3_time_monthAbbrevLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseMonth(date, string, i) { d3_time_monthRe.lastIndex = 0; var n = d3_time_monthRe.exec(string.substring(i)); return n ? (date.m = d3_time_monthLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseLocaleFull(date, string, i) { return d3_time_parse(date, d3_time_formats.c.toString(), string, i); } function d3_time_parseLocaleDate(date, string, i) { return d3_time_parse(date, d3_time_formats.x.toString(), string, i); } function d3_time_parseLocaleTime(date, string, i) { return d3_time_parse(date, d3_time_formats.X.toString(), string, i); } function d3_time_parseAmPm(date, string, i) { var n = d3_time_periodLookup.get(string.substring(i, i += 2).toLowerCase()); return n == null ? -1 : (date.p = n, i); } return d3_time_format; } var d3_time_formatPads = { ""-"": """", _: "" "", ""0"": ""0"" }, d3_time_numberRe = /^\s*\d+/, d3_time_percentRe = /^%/; function d3_time_formatPad(value, fill, width) { var sign = value < 0 ? ""-"" : """", string = (sign ? -value : value) + """", length = string.length; return sign + (length < width ? new Array(width - length + 1).join(fill) + string : string); } function d3_time_formatRe(names) { return new RegExp(""^(?:"" + names.map(d3.requote).join(""|"") + "")"", ""i""); } function d3_time_formatLookup(names) { var map = new d3_Map(), i = -1, n = names.length; while (++i < n) map.set(names[i].toLowerCase(), i); return map; } function d3_time_parseWeekdayNumber(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 1)); return n ? (date.w = +n[0], i + n[0].length) : -1; } function d3_time_parseWeekNumberSunday(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i)); return n ? (date.U = +n[0], i + n[0].length) : -1; } function d3_time_parseWeekNumberMonday(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i)); return n ? (date.W = +n[0], i + n[0].length) : -1; } function d3_time_parseFullYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 4)); return n ? (date.y = +n[0], i + n[0].length) : -1; } function d3_time_parseYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.y = d3_time_expandYear(+n[0]), i + n[0].length) : -1; } function d3_time_parseZone(date, string, i) { return /^[+-]\d{4}$/.test(string = string.substring(i, i + 5)) ? (date.Z = +string, i + 5) : -1; } function d3_time_expandYear(d) { return d + (d > 68 ? 1900 : 2e3); } function d3_time_parseMonthNumber(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.m = n[0] - 1, i + n[0].length) : -1; } function d3_time_parseDay(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.d = +n[0], i + n[0].length) : -1; } function d3_time_parseDayOfYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 3)); return n ? (date.j = +n[0], i + n[0].length) : -1; } function d3_time_parseHour24(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.H = +n[0], i + n[0].length) : -1; } function d3_time_parseMinutes(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.M = +n[0], i + n[0].length) : -1; } function d3_time_parseSeconds(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.S = +n[0], i + n[0].length) : -1; } function d3_time_parseMilliseconds(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 3)); return n ? (date.L = +n[0], i + n[0].length) : -1; } function d3_time_zone(d) { var z = d.getTimezoneOffset(), zs = z > 0 ? ""-"" : ""+"", zh = ~~(abs(z) / 60), zm = abs(z) % 60; return zs + d3_time_formatPad(zh, ""0"", 2) + d3_time_formatPad(zm, ""0"", 2); } function d3_time_parseLiteralPercent(date, string, i) { d3_time_percentRe.lastIndex = 0; var n = d3_time_percentRe.exec(string.substring(i, i + 1)); return n ? i + n[0].length : -1; } function d3_time_formatMulti(formats) { var n = formats.length, i = -1; while (++i < n) formats[i][0] = this(formats[i][0]); return function(date) { var i = 0, f = formats[i]; while (!f[1](date)) f = formats[++i]; return f[0](date); }; } d3.locale = function(locale) { return { numberFormat: d3_locale_numberFormat(locale), timeFormat: d3_locale_timeFormat(locale) }; }; var d3_locale_enUS = d3.locale({ decimal: ""."", thousands: "","", grouping: [ 3 ], currency: [ ""$"", """" ], dateTime: ""%a %b %e %X %Y"", date: ""%m/%d/%Y"", time: ""%H:%M:%S"", periods: [ ""AM"", ""PM"" ], days: [ ""Sunday"", ""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday"" ], shortDays: [ ""Sun"", ""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"" ], months: [ ""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", ""August"", ""September"", ""October"", ""November"", ""December"" ], shortMonths: [ ""Jan"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec"" ] }); d3.format = d3_locale_enUS.numberFormat; d3.geo = {}; function d3_adder() {} d3_adder.prototype = { s: 0, t: 0, add: function(y) { d3_adderSum(y, this.t, d3_adderTemp); d3_adderSum(d3_adderTemp.s, this.s, this); if (this.s) this.t += d3_adderTemp.t; else this.s = d3_adderTemp.t; }, reset: function() { this.s = this.t = 0; }, valueOf: function() { return this.s; } }; var d3_adderTemp = new d3_adder(); function d3_adderSum(a, b, o) { var x = o.s = a + b, bv = x - a, av = x - bv; o.t = a - av + (b - bv); } d3.geo.stream = function(object, listener) { if (object && d3_geo_streamObjectType.hasOwnProperty(object.type)) { d3_geo_streamObjectType[object.type](object, listener); } else { d3_geo_streamGeometry(object, listener); } }; function d3_geo_streamGeometry(geometry, listener) { if (geometry && d3_geo_streamGeometryType.hasOwnProperty(geometry.type)) { d3_geo_streamGeometryType[geometry.type](geometry, listener); } } var d3_geo_streamObjectType = { Feature: function(feature, listener) { d3_geo_streamGeometry(feature.geometry, listener); }, FeatureCollection: function(object, listener) { var features = object.features, i = -1, n = features.length; while (++i < n) d3_geo_streamGeometry(features[i].geometry, listener); } }; var d3_geo_streamGeometryType = { Sphere: function(object, listener) { listener.sphere(); }, Point: function(object, listener) { object = object.coordinates; listener.point(object[0], object[1], object[2]); }, MultiPoint: function(object, listener) { var coordinates = object.coordinates, i = -1, n = coordinates.length; while (++i < n) object = coordinates[i], listener.point(object[0], object[1], object[2]); }, LineString: function(object, listener) { d3_geo_streamLine(object.coordinates, listener, 0); }, MultiLineString: function(object, listener) { var coordinates = object.coordinates, i = -1, n = coordinates.length; while (++i < n) d3_geo_streamLine(coordinates[i], listener, 0); }, Polygon: function(object, listener) { d3_geo_streamPolygon(object.coordinates, listener); }, MultiPolygon: function(object, listener) { var coordinates = object.coordinates, i = -1, n = coordinates.length; while (++i < n) d3_geo_streamPolygon(coordinates[i], listener); }, GeometryCollection: function(object, listener) { var geometries = object.geometries, i = -1, n = geometries.length; while (++i < n) d3_geo_streamGeometry(geometries[i], listener); } }; function d3_geo_streamLine(coordinates, listener, closed) { var i = -1, n = coordinates.length - closed, coordinate; listener.lineStart(); while (++i < n) coordinate = coordinates[i], listener.point(coordinate[0], coordinate[1], coordinate[2]); listener.lineEnd(); } function d3_geo_streamPolygon(coordinates, listener) { var i = -1, n = coordinates.length; listener.polygonStart(); while (++i < n) d3_geo_streamLine(coordinates[i], listener, 1); listener.polygonEnd(); } d3.geo.area = function(object) { d3_geo_areaSum = 0; d3.geo.stream(object, d3_geo_area); return d3_geo_areaSum; }; var d3_geo_areaSum, d3_geo_areaRingSum = new d3_adder(); var d3_geo_area = { sphere: function() { d3_geo_areaSum += 4 * π; }, point: d3_noop, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: function() { d3_geo_areaRingSum.reset(); d3_geo_area.lineStart = d3_geo_areaRingStart; }, polygonEnd: function() { var area = 2 * d3_geo_areaRingSum; d3_geo_areaSum += area < 0 ? 4 * π + area : area; d3_geo_area.lineStart = d3_geo_area.lineEnd = d3_geo_area.point = d3_noop; } }; function d3_geo_areaRingStart() { var λ00, φ00, λ0, cosφ0, sinφ0; d3_geo_area.point = function(λ, φ) { d3_geo_area.point = nextPoint; λ0 = (λ00 = λ) * d3_radians, cosφ0 = Math.cos(φ = (φ00 = φ) * d3_radians / 2 + π / 4), sinφ0 = Math.sin(φ); }; function nextPoint(λ, φ) { λ *= d3_radians; φ = φ * d3_radians / 2 + π / 4; var dλ = λ - λ0, sdλ = dλ >= 0 ? 1 : -1, adλ = sdλ * dλ, cosφ = Math.cos(φ), sinφ = Math.sin(φ), k = sinφ0 * sinφ, u = cosφ0 * cosφ + k * Math.cos(adλ), v = k * sdλ * Math.sin(adλ); d3_geo_areaRingSum.add(Math.atan2(v, u)); λ0 = λ, cosφ0 = cosφ, sinφ0 = sinφ; } d3_geo_area.lineEnd = function() { nextPoint(λ00, φ00); }; } function d3_geo_cartesian(spherical) { var λ = spherical[0], φ = spherical[1], cosφ = Math.cos(φ); return [ cosφ * Math.cos(λ), cosφ * Math.sin(λ), Math.sin(φ) ]; } function d3_geo_cartesianDot(a, b) { return a[0] * b[0] + a[1] * b[1] + a[2] * b[2]; } function d3_geo_cartesianCross(a, b) { return [ a[1] * b[2] - a[2] * b[1], a[2] * b[0] - a[0] * b[2], a[0] * b[1] - a[1] * b[0] ]; } function d3_geo_cartesianAdd(a, b) { a[0] += b[0]; a[1] += b[1]; a[2] += b[2]; } function d3_geo_cartesianScale(vector, k) { return [ vector[0] * k, vector[1] * k, vector[2] * k ]; } function d3_geo_cartesianNormalize(d) { var l = Math.sqrt(d[0] * d[0] + d[1] * d[1] + d[2] * d[2]); d[0] /= l; d[1] /= l; d[2] /= l; } function d3_geo_spherical(cartesian) { return [ Math.atan2(cartesian[1], cartesian[0]), d3_asin(cartesian[2]) ]; } function d3_geo_sphericalEqual(a, b) { return abs(a[0] - b[0]) < ε && abs(a[1] - b[1]) < ε; } d3.geo.bounds = function() { var λ0, φ0, λ1, φ1, λ_, λ__, φ__, p0, dλSum, ranges, range; var bound = { point: point, lineStart: lineStart, lineEnd: lineEnd, polygonStart: function() { bound.point = ringPoint; bound.lineStart = ringStart; bound.lineEnd = ringEnd; dλSum = 0; d3_geo_area.polygonStart(); }, polygonEnd: function() { d3_geo_area.polygonEnd(); bound.point = point; bound.lineStart = lineStart; bound.lineEnd = lineEnd; if (d3_geo_areaRingSum < 0) λ0 = -(λ1 = 180), φ0 = -(φ1 = 90); else if (dλSum > ε) φ1 = 90; else if (dλSum < -ε) φ0 = -90; range[0] = λ0, range[1] = λ1; } }; function point(λ, φ) { ranges.push(range = [ λ0 = λ, λ1 = λ ]); if (φ < φ0) φ0 = φ; if (φ > φ1) φ1 = φ; } function linePoint(λ, φ) { var p = d3_geo_cartesian([ λ * d3_radians, φ * d3_radians ]); if (p0) { var normal = d3_geo_cartesianCross(p0, p), equatorial = [ normal[1], -normal[0], 0 ], inflection = d3_geo_cartesianCross(equatorial, normal); d3_geo_cartesianNormalize(inflection); inflection = d3_geo_spherical(inflection); var dλ = λ - λ_, s = dλ > 0 ? 1 : -1, λi = inflection[0] * d3_degrees * s, antimeridian = abs(dλ) > 180; if (antimeridian ^ (s * λ_ < λi && λi < s * λ)) { var φi = inflection[1] * d3_degrees; if (φi > φ1) φ1 = φi; } else if (λi = (λi + 360) % 360 - 180, antimeridian ^ (s * λ_ < λi && λi < s * λ)) { var φi = -inflection[1] * d3_degrees; if (φi < φ0) φ0 = φi; } else { if (φ < φ0) φ0 = φ; if (φ > φ1) φ1 = φ; } if (antimeridian) { if (λ < λ_) { if (angle(λ0, λ) > angle(λ0, λ1)) λ1 = λ; } else { if (angle(λ, λ1) > angle(λ0, λ1)) λ0 = λ; } } else { if (λ1 >= λ0) { if (λ < λ0) λ0 = λ; if (λ > λ1) λ1 = λ; } else { if (λ > λ_) { if (angle(λ0, λ) > angle(λ0, λ1)) λ1 = λ; } else { if (angle(λ, λ1) > angle(λ0, λ1)) λ0 = λ; } } } } else { point(λ, φ); } p0 = p, λ_ = λ; } function lineStart() { bound.point = linePoint; } function lineEnd() { range[0] = λ0, range[1] = λ1; bound.point = point; p0 = null; } function ringPoint(λ, φ) { if (p0) { var dλ = λ - λ_; dλSum += abs(dλ) > 180 ? dλ + (dλ > 0 ? 360 : -360) : dλ; } else λ__ = λ, φ__ = φ; d3_geo_area.point(λ, φ); linePoint(λ, φ); } function ringStart() { d3_geo_area.lineStart(); } function ringEnd() { ringPoint(λ__, φ__); d3_geo_area.lineEnd(); if (abs(dλSum) > ε) λ0 = -(λ1 = 180); range[0] = λ0, range[1] = λ1; p0 = null; } function angle(λ0, λ1) { return (λ1 -= λ0) < 0 ? λ1 + 360 : λ1; } function compareRanges(a, b) { return a[0] - b[0]; } function withinRange(x, range) { return range[0] <= range[1] ? range[0] <= x && x <= range[1] : x < range[0] || range[1] < x; } return function(feature) { φ1 = λ1 = -(λ0 = φ0 = Infinity); ranges = []; d3.geo.stream(feature, bound); var n = ranges.length; if (n) { ranges.sort(compareRanges); for (var i = 1, a = ranges[0], b, merged = [ a ]; i < n; ++i) { b = ranges[i]; if (withinRange(b[0], a) || withinRange(b[1], a)) { if (angle(a[0], b[1]) > angle(a[0], a[1])) a[1] = b[1]; if (angle(b[0], a[1]) > angle(a[0], a[1])) a[0] = b[0]; } else { merged.push(a = b); } } var best = -Infinity, dλ; for (var n = merged.length - 1, i = 0, a = merged[n], b; i <= n; a = b, ++i) { b = merged[i]; if ((dλ = angle(a[1], b[0])) > best) best = dλ, λ0 = b[0], λ1 = a[1]; } } ranges = range = null; return λ0 === Infinity || φ0 === Infinity ? [ [ NaN, NaN ], [ NaN, NaN ] ] : [ [ λ0, φ0 ], [ λ1, φ1 ] ]; }; }(); d3.geo.centroid = function(object) { d3_geo_centroidW0 = d3_geo_centroidW1 = d3_geo_centroidX0 = d3_geo_centroidY0 = d3_geo_centroidZ0 = d3_geo_centroidX1 = d3_geo_centroidY1 = d3_geo_centroidZ1 = d3_geo_centroidX2 = d3_geo_centroidY2 = d3_geo_centroidZ2 = 0; d3.geo.stream(object, d3_geo_centroid); var x = d3_geo_centroidX2, y = d3_geo_centroidY2, z = d3_geo_centroidZ2, m = x * x + y * y + z * z; if (m < ε2) { x = d3_geo_centroidX1, y = d3_geo_centroidY1, z = d3_geo_centroidZ1; if (d3_geo_centroidW1 < ε) x = d3_geo_centroidX0, y = d3_geo_centroidY0, z = d3_geo_centroidZ0; m = x * x + y * y + z * z; if (m < ε2) return [ NaN, NaN ]; } return [ Math.atan2(y, x) * d3_degrees, d3_asin(z / Math.sqrt(m)) * d3_degrees ]; }; var d3_geo_centroidW0, d3_geo_centroidW1, d3_geo_centroidX0, d3_geo_centroidY0, d3_geo_centroidZ0, d3_geo_centroidX1, d3_geo_centroidY1, d3_geo_centroidZ1, d3_geo_centroidX2, d3_geo_centroidY2, d3_geo_centroidZ2; var d3_geo_centroid = { sphere: d3_noop, point: d3_geo_centroidPoint, lineStart: d3_geo_centroidLineStart, lineEnd: d3_geo_centroidLineEnd, polygonStart: function() { d3_geo_centroid.lineStart = d3_geo_centroidRingStart; }, polygonEnd: function() { d3_geo_centroid.lineStart = d3_geo_centroidLineStart; } }; function d3_geo_centroidPoint(λ, φ) { λ *= d3_radians; var cosφ = Math.cos(φ *= d3_radians); d3_geo_centroidPointXYZ(cosφ * Math.cos(λ), cosφ * Math.sin(λ), Math.sin(φ)); } function d3_geo_centroidPointXYZ(x, y, z) { ++d3_geo_centroidW0; d3_geo_centroidX0 += (x - d3_geo_centroidX0) / d3_geo_centroidW0; d3_geo_centroidY0 += (y - d3_geo_centroidY0) / d3_geo_centroidW0; d3_geo_centroidZ0 += (z - d3_geo_centroidZ0) / d3_geo_centroidW0; } function d3_geo_centroidLineStart() { var x0, y0, z0; d3_geo_centroid.point = function(λ, φ) { λ *= d3_radians; var cosφ = Math.cos(φ *= d3_radians); x0 = cosφ * Math.cos(λ); y0 = cosφ * Math.sin(λ); z0 = Math.sin(φ); d3_geo_centroid.point = nextPoint; d3_geo_centroidPointXYZ(x0, y0, z0); }; function nextPoint(λ, φ) { λ *= d3_radians; var cosφ = Math.cos(φ *= d3_radians), x = cosφ * Math.cos(λ), y = cosφ * Math.sin(λ), z = Math.sin(φ), w = Math.atan2(Math.sqrt((w = y0 * z - z0 * y) * w + (w = z0 * x - x0 * z) * w + (w = x0 * y - y0 * x) * w), x0 * x + y0 * y + z0 * z); d3_geo_centroidW1 += w; d3_geo_centroidX1 += w * (x0 + (x0 = x)); d3_geo_centroidY1 += w * (y0 + (y0 = y)); d3_geo_centroidZ1 += w * (z0 + (z0 = z)); d3_geo_centroidPointXYZ(x0, y0, z0); } } function d3_geo_centroidLineEnd() { d3_geo_centroid.point = d3_geo_centroidPoint; } function d3_geo_centroidRingStart() { var λ00, φ00, x0, y0, z0; d3_geo_centroid.point = function(λ, φ) { λ00 = λ, φ00 = φ; d3_geo_centroid.point = nextPoint; λ *= d3_radians; var cosφ = Math.cos(φ *= d3_radians); x0 = cosφ * Math.cos(λ); y0 = cosφ * Math.sin(λ); z0 = Math.sin(φ); d3_geo_centroidPointXYZ(x0, y0, z0); }; d3_geo_centroid.lineEnd = function() { nextPoint(λ00, φ00); d3_geo_centroid.lineEnd = d3_geo_centroidLineEnd; d3_geo_centroid.point = d3_geo_centroidPoint; }; function nextPoint(λ, φ) { λ *= d3_radians; var cosφ = Math.cos(φ *= d3_radians), x = cosφ * Math.cos(λ), y = cosφ * Math.sin(λ), z = Math.sin(φ), cx = y0 * z - z0 * y, cy = z0 * x - x0 * z, cz = x0 * y - y0 * x, m = Math.sqrt(cx * cx + cy * cy + cz * cz), u = x0 * x + y0 * y + z0 * z, v = m && -d3_acos(u) / m, w = Math.atan2(m, u); d3_geo_centroidX2 += v * cx; d3_geo_centroidY2 += v * cy; d3_geo_centroidZ2 += v * cz; d3_geo_centroidW1 += w; d3_geo_centroidX1 += w * (x0 + (x0 = x)); d3_geo_centroidY1 += w * (y0 + (y0 = y)); d3_geo_centroidZ1 += w * (z0 + (z0 = z)); d3_geo_centroidPointXYZ(x0, y0, z0); } } function d3_true() { return true; } function d3_geo_clipPolygon(segments, compare, clipStartInside, interpolate, listener) { var subject = [], clip = []; segments.forEach(function(segment) { if ((n = segment.length - 1) <= 0) return; var n, p0 = segment[0], p1 = segment[n]; if (d3_geo_sphericalEqual(p0, p1)) { listener.lineStart(); for (var i = 0; i < n; ++i) listener.point((p0 = segment[i])[0], p0[1]); listener.lineEnd(); return; } var a = new d3_geo_clipPolygonIntersection(p0, segment, null, true), b = new d3_geo_clipPolygonIntersection(p0, null, a, false); a.o = b; subject.push(a); clip.push(b); a = new d3_geo_clipPolygonIntersection(p1, segment, null, false); b = new d3_geo_clipPolygonIntersection(p1, null, a, true); a.o = b; subject.push(a); clip.push(b); }); clip.sort(compare); d3_geo_clipPolygonLinkCircular(subject); d3_geo_clipPolygonLinkCircular(clip); if (!subject.length) return; for (var i = 0, entry = clipStartInside, n = clip.length; i < n; ++i) { clip[i].e = entry = !entry; } var start = subject[0], points, point; while (1) { var current = start, isSubject = true; while (current.v) if ((current = current.n) === start) return; points = current.z; listener.lineStart(); do { current.v = current.o.v = true; if (current.e) { if (isSubject) { for (var i = 0, n = points.length; i < n; ++i) listener.point((point = points[i])[0], point[1]); } else { interpolate(current.x, current.n.x, 1, listener); } current = current.n; } else { if (isSubject) { points = current.p.z; for (var i = points.length - 1; i >= 0; --i) listener.point((point = points[i])[0], point[1]); } else { interpolate(current.x, current.p.x, -1, listener); } current = current.p; } current = current.o; points = current.z; isSubject = !isSubject; } while (!current.v); listener.lineEnd(); } } function d3_geo_clipPolygonLinkCircular(array) { if (!(n = array.length)) return; var n, i = 0, a = array[0], b; while (++i < n) { a.n = b = array[i]; b.p = a; a = b; } a.n = b = array[0]; b.p = a; } function d3_geo_clipPolygonIntersection(point, points, other, entry) { this.x = point; this.z = points; this.o = other; this.e = entry; this.v = false; this.n = this.p = null; } function d3_geo_clip(pointVisible, clipLine, interpolate, clipStart) { return function(rotate, listener) { var line = clipLine(listener), rotatedClipStart = rotate.invert(clipStart[0], clipStart[1]); var clip = { point: point, lineStart: lineStart, lineEnd: lineEnd, polygonStart: function() { clip.point = pointRing; clip.lineStart = ringStart; clip.lineEnd = ringEnd; segments = []; polygon = []; listener.polygonStart(); }, polygonEnd: function() { clip.point = point; clip.lineStart = lineStart; clip.lineEnd = lineEnd; segments = d3.merge(segments); var clipStartInside = d3_geo_pointInPolygon(rotatedClipStart, polygon); if (segments.length) { d3_geo_clipPolygon(segments, d3_geo_clipSort, clipStartInside, interpolate, listener); } else if (clipStartInside) { listener.lineStart(); interpolate(null, null, 1, listener); listener.lineEnd(); } listener.polygonEnd(); segments = polygon = null; }, sphere: function() { listener.polygonStart(); listener.lineStart(); interpolate(null, null, 1, listener); listener.lineEnd(); listener.polygonEnd(); } }; function point(λ, φ) { var point = rotate(λ, φ); if (pointVisible(λ = point[0], φ = point[1])) listener.point(λ, φ); } function pointLine(λ, φ) { var point = rotate(λ, φ); line.point(point[0], point[1]); } function lineStart() { clip.point = pointLine; line.lineStart(); } function lineEnd() { clip.point = point; line.lineEnd(); } var segments; var buffer = d3_geo_clipBufferListener(), ringListener = clipLine(buffer), polygon, ring; function pointRing(λ, φ) { ring.push([ λ, φ ]); var point = rotate(λ, φ); ringListener.point(point[0], point[1]); } function ringStart() { ringListener.lineStart(); ring = []; } function ringEnd() { pointRing(ring[0][0], ring[0][1]); ringListener.lineEnd(); var clean = ringListener.clean(), ringSegments = buffer.buffer(), segment, n = ringSegments.length; ring.pop(); polygon.push(ring); ring = null; if (!n) return; if (clean & 1) { segment = ringSegments[0]; var n = segment.length - 1, i = -1, point; listener.lineStart(); while (++i < n) listener.point((point = segment[i])[0], point[1]); listener.lineEnd(); return; } if (n > 1 && clean & 2) ringSegments.push(ringSegments.pop().concat(ringSegments.shift())); segments.push(ringSegments.filter(d3_geo_clipSegmentLength1)); } return clip; }; } function d3_geo_clipSegmentLength1(segment) { return segment.length > 1; } function d3_geo_clipBufferListener() { var lines = [], line; return { lineStart: function() { lines.push(line = []); }, point: function(λ, φ) { line.push([ λ, φ ]); }, lineEnd: d3_noop, buffer: function() { var buffer = lines; lines = []; line = null; return buffer; }, rejoin: function() { if (lines.length > 1) lines.push(lines.pop().concat(lines.shift())); } }; } function d3_geo_clipSort(a, b) { return ((a = a.x)[0] < 0 ? a[1] - halfπ - ε : halfπ - a[1]) - ((b = b.x)[0] < 0 ? b[1] - halfπ - ε : halfπ - b[1]); } function d3_geo_pointInPolygon(point, polygon) { var meridian = point[0], parallel = point[1], meridianNormal = [ Math.sin(meridian), -Math.cos(meridian), 0 ], polarAngle = 0, winding = 0; d3_geo_areaRingSum.reset(); for (var i = 0, n = polygon.length; i < n; ++i) { var ring = polygon[i], m = ring.length; if (!m) continue; var point0 = ring[0], λ0 = point0[0], φ0 = point0[1] / 2 + π / 4, sinφ0 = Math.sin(φ0), cosφ0 = Math.cos(φ0), j = 1; while (true) { if (j === m) j = 0; point = ring[j]; var λ = point[0], φ = point[1] / 2 + π / 4, sinφ = Math.sin(φ), cosφ = Math.cos(φ), dλ = λ - λ0, sdλ = dλ >= 0 ? 1 : -1, adλ = sdλ * dλ, antimeridian = adλ > π, k = sinφ0 * sinφ; d3_geo_areaRingSum.add(Math.atan2(k * sdλ * Math.sin(adλ), cosφ0 * cosφ + k * Math.cos(adλ))); polarAngle += antimeridian ? dλ + sdλ * τ : dλ; if (antimeridian ^ λ0 >= meridian ^ λ >= meridian) { var arc = d3_geo_cartesianCross(d3_geo_cartesian(point0), d3_geo_cartesian(point)); d3_geo_cartesianNormalize(arc); var intersection = d3_geo_cartesianCross(meridianNormal, arc); d3_geo_cartesianNormalize(intersection); var φarc = (antimeridian ^ dλ >= 0 ? -1 : 1) * d3_asin(intersection[2]); if (parallel > φarc || parallel === φarc && (arc[0] || arc[1])) { winding += antimeridian ^ dλ >= 0 ? 1 : -1; } } if (!j++) break; λ0 = λ, sinφ0 = sinφ, cosφ0 = cosφ, point0 = point; } } return (polarAngle < -ε || polarAngle < ε && d3_geo_areaRingSum < 0) ^ winding & 1; } var d3_geo_clipAntimeridian = d3_geo_clip(d3_true, d3_geo_clipAntimeridianLine, d3_geo_clipAntimeridianInterpolate, [ -π, -π / 2 ]); function d3_geo_clipAntimeridianLine(listener) { var λ0 = NaN, φ0 = NaN, sλ0 = NaN, clean; return { lineStart: function() { listener.lineStart(); clean = 1; }, point: function(λ1, φ1) { var sλ1 = λ1 > 0 ? π : -π, dλ = abs(λ1 - λ0); if (abs(dλ - π) < ε) { listener.point(λ0, φ0 = (φ0 + φ1) / 2 > 0 ? halfπ : -halfπ); listener.point(sλ0, φ0); listener.lineEnd(); listener.lineStart(); listener.point(sλ1, φ0); listener.point(λ1, φ0); clean = 0; } else if (sλ0 !== sλ1 && dλ >= π) { if (abs(λ0 - sλ0) < ε) λ0 -= sλ0 * ε; if (abs(λ1 - sλ1) < ε) λ1 -= sλ1 * ε; φ0 = d3_geo_clipAntimeridianIntersect(λ0, φ0, λ1, φ1); listener.point(sλ0, φ0); listener.lineEnd(); listener.lineStart(); listener.point(sλ1, φ0); clean = 0; } listener.point(λ0 = λ1, φ0 = φ1); sλ0 = sλ1; }, lineEnd: function() { listener.lineEnd(); λ0 = φ0 = NaN; }, clean: function() { return 2 - clean; } }; } function d3_geo_clipAntimeridianIntersect(λ0, φ0, λ1, φ1) { var cosφ0, cosφ1, sinλ0_λ1 = Math.sin(λ0 - λ1); return abs(sinλ0_λ1) > ε ? Math.atan((Math.sin(φ0) * (cosφ1 = Math.cos(φ1)) * Math.sin(λ1) - Math.sin(φ1) * (cosφ0 = Math.cos(φ0)) * Math.sin(λ0)) / (cosφ0 * cosφ1 * sinλ0_λ1)) : (φ0 + φ1) / 2; } function d3_geo_clipAntimeridianInterpolate(from, to, direction, listener) { var φ; if (from == null) { φ = direction * halfπ; listener.point(-π, φ); listener.point(0, φ); listener.point(π, φ); listener.point(π, 0); listener.point(π, -φ); listener.point(0, -φ); listener.point(-π, -φ); listener.point(-π, 0); listener.point(-π, φ); } else if (abs(from[0] - to[0]) > ε) { var s = from[0] < to[0] ? π : -π; φ = direction * s / 2; listener.point(-s, φ); listener.point(0, φ); listener.point(s, φ); } else { listener.point(to[0], to[1]); } } function d3_geo_clipCircle(radius) { var cr = Math.cos(radius), smallRadius = cr > 0, notHemisphere = abs(cr) > ε, interpolate = d3_geo_circleInterpolate(radius, 6 * d3_radians); return d3_geo_clip(visible, clipLine, interpolate, smallRadius ? [ 0, -radius ] : [ -π, radius - π ]); function visible(λ, φ) { return Math.cos(λ) * Math.cos(φ) > cr; } function clipLine(listener) { var point0, c0, v0, v00, clean; return { lineStart: function() { v00 = v0 = false; clean = 1; }, point: function(λ, φ) { var point1 = [ λ, φ ], point2, v = visible(λ, φ), c = smallRadius ? v ? 0 : code(λ, φ) : v ? code(λ + (λ < 0 ? π : -π), φ) : 0; if (!point0 && (v00 = v0 = v)) listener.lineStart(); if (v !== v0) { point2 = intersect(point0, point1); if (d3_geo_sphericalEqual(point0, point2) || d3_geo_sphericalEqual(point1, point2)) { point1[0] += ε; point1[1] += ε; v = visible(point1[0], point1[1]); } } if (v !== v0) { clean = 0; if (v) { listener.lineStart(); point2 = intersect(point1, point0); listener.point(point2[0], point2[1]); } else { point2 = intersect(point0, point1); listener.point(point2[0], point2[1]); listener.lineEnd(); } point0 = point2; } else if (notHemisphere && point0 && smallRadius ^ v) { var t; if (!(c & c0) && (t = intersect(point1, point0, true))) { clean = 0; if (smallRadius) { listener.lineStart(); listener.point(t[0][0], t[0][1]); listener.point(t[1][0], t[1][1]); listener.lineEnd(); } else { listener.point(t[1][0], t[1][1]); listener.lineEnd(); listener.lineStart(); listener.point(t[0][0], t[0][1]); } } } if (v && (!point0 || !d3_geo_sphericalEqual(point0, point1))) { listener.point(point1[0], point1[1]); } point0 = point1, v0 = v, c0 = c; }, lineEnd: function() { if (v0) listener.lineEnd(); point0 = null; }, clean: function() { return clean | (v00 && v0) << 1; } }; } function intersect(a, b, two) { var pa = d3_geo_cartesian(a), pb = d3_geo_cartesian(b); var n1 = [ 1, 0, 0 ], n2 = d3_geo_cartesianCross(pa, pb), n2n2 = d3_geo_cartesianDot(n2, n2), n1n2 = n2[0], determinant = n2n2 - n1n2 * n1n2; if (!determinant) return !two && a; var c1 = cr * n2n2 / determinant, c2 = -cr * n1n2 / determinant, n1xn2 = d3_geo_cartesianCross(n1, n2), A = d3_geo_cartesianScale(n1, c1), B = d3_geo_cartesianScale(n2, c2); d3_geo_cartesianAdd(A, B); var u = n1xn2, w = d3_geo_cartesianDot(A, u), uu = d3_geo_cartesianDot(u, u), t2 = w * w - uu * (d3_geo_cartesianDot(A, A) - 1); if (t2 < 0) return; var t = Math.sqrt(t2), q = d3_geo_cartesianScale(u, (-w - t) / uu); d3_geo_cartesianAdd(q, A); q = d3_geo_spherical(q); if (!two) return q; var λ0 = a[0], λ1 = b[0], φ0 = a[1], φ1 = b[1], z; if (λ1 < λ0) z = λ0, λ0 = λ1, λ1 = z; var δλ = λ1 - λ0, polar = abs(δλ - π) < ε, meridian = polar || δλ < ε; if (!polar && φ1 < φ0) z = φ0, φ0 = φ1, φ1 = z; if (meridian ? polar ? φ0 + φ1 > 0 ^ q[1] < (abs(q[0] - λ0) < ε ? φ0 : φ1) : φ0 <= q[1] && q[1] <= φ1 : δλ > π ^ (λ0 <= q[0] && q[0] <= λ1)) { var q1 = d3_geo_cartesianScale(u, (-w + t) / uu); d3_geo_cartesianAdd(q1, A); return [ q, d3_geo_spherical(q1) ]; } } function code(λ, φ) { var r = smallRadius ? radius : π - radius, code = 0; if (λ < -r) code |= 1; else if (λ > r) code |= 2; if (φ < -r) code |= 4; else if (φ > r) code |= 8; return code; } } function d3_geom_clipLine(x0, y0, x1, y1) { return function(line) { var a = line.a, b = line.b, ax = a.x, ay = a.y, bx = b.x, by = b.y, t0 = 0, t1 = 1, dx = bx - ax, dy = by - ay, r; r = x0 - ax; if (!dx && r > 0) return; r /= dx; if (dx < 0) { if (r < t0) return; if (r < t1) t1 = r; } else if (dx > 0) { if (r > t1) return; if (r > t0) t0 = r; } r = x1 - ax; if (!dx && r < 0) return; r /= dx; if (dx < 0) { if (r > t1) return; if (r > t0) t0 = r; } else if (dx > 0) { if (r < t0) return; if (r < t1) t1 = r; } r = y0 - ay; if (!dy && r > 0) return; r /= dy; if (dy < 0) { if (r < t0) return; if (r < t1) t1 = r; } else if (dy > 0) { if (r > t1) return; if (r > t0) t0 = r; } r = y1 - ay; if (!dy && r < 0) return; r /= dy; if (dy < 0) { if (r > t1) return; if (r > t0) t0 = r; } else if (dy > 0) { if (r < t0) return; if (r < t1) t1 = r; } if (t0 > 0) line.a = { x: ax + t0 * dx, y: ay + t0 * dy }; if (t1 < 1) line.b = { x: ax + t1 * dx, y: ay + t1 * dy }; return line; }; } var d3_geo_clipExtentMAX = 1e9; d3.geo.clipExtent = function() { var x0, y0, x1, y1, stream, clip, clipExtent = { stream: function(output) { if (stream) stream.valid = false; stream = clip(output); stream.valid = true; return stream; }, extent: function(_) { if (!arguments.length) return [ [ x0, y0 ], [ x1, y1 ] ]; clip = d3_geo_clipExtent(x0 = +_[0][0], y0 = +_[0][1], x1 = +_[1][0], y1 = +_[1][1]); if (stream) stream.valid = false, stream = null; return clipExtent; } }; return clipExtent.extent([ [ 0, 0 ], [ 960, 500 ] ]); }; function d3_geo_clipExtent(x0, y0, x1, y1) { return function(listener) { var listener_ = listener, bufferListener = d3_geo_clipBufferListener(), clipLine = d3_geom_clipLine(x0, y0, x1, y1), segments, polygon, ring; var clip = { point: point, lineStart: lineStart, lineEnd: lineEnd, polygonStart: function() { listener = bufferListener; segments = []; polygon = []; clean = true; }, polygonEnd: function() { listener = listener_; segments = d3.merge(segments); var clipStartInside = insidePolygon([ x0, y1 ]), inside = clean && clipStartInside, visible = segments.length; if (inside || visible) { listener.polygonStart(); if (inside) { listener.lineStart(); interpolate(null, null, 1, listener); listener.lineEnd(); } if (visible) { d3_geo_clipPolygon(segments, compare, clipStartInside, interpolate, listener); } listener.polygonEnd(); } segments = polygon = ring = null; } }; function insidePolygon(p) { var wn = 0, n = polygon.length, y = p[1]; for (var i = 0; i < n; ++i) { for (var j = 1, v = polygon[i], m = v.length, a = v[0], b; j < m; ++j) { b = v[j]; if (a[1] <= y) { if (b[1] > y && d3_cross2d(a, b, p) > 0) ++wn; } else { if (b[1] <= y && d3_cross2d(a, b, p) < 0) --wn; } a = b; } } return wn !== 0; } function interpolate(from, to, direction, listener) { var a = 0, a1 = 0; if (from == null || (a = corner(from, direction)) !== (a1 = corner(to, direction)) || comparePoints(from, to) < 0 ^ direction > 0) { do { listener.point(a === 0 || a === 3 ? x0 : x1, a > 1 ? y1 : y0); } while ((a = (a + direction + 4) % 4) !== a1); } else { listener.point(to[0], to[1]); } } function pointVisible(x, y) { return x0 <= x && x <= x1 && y0 <= y && y <= y1; } function point(x, y) { if (pointVisible(x, y)) listener.point(x, y); } var x__, y__, v__, x_, y_, v_, first, clean; function lineStart() { clip.point = linePoint; if (polygon) polygon.push(ring = []); first = true; v_ = false; x_ = y_ = NaN; } function lineEnd() { if (segments) { linePoint(x__, y__); if (v__ && v_) bufferListener.rejoin(); segments.push(bufferListener.buffer()); } clip.point = point; if (v_) listener.lineEnd(); } function linePoint(x, y) { x = Math.max(-d3_geo_clipExtentMAX, Math.min(d3_geo_clipExtentMAX, x)); y = Math.max(-d3_geo_clipExtentMAX, Math.min(d3_geo_clipExtentMAX, y)); var v = pointVisible(x, y); if (polygon) ring.push([ x, y ]); if (first) { x__ = x, y__ = y, v__ = v; first = false; if (v) { listener.lineStart(); listener.point(x, y); } } else { if (v && v_) listener.point(x, y); else { var l = { a: { x: x_, y: y_ }, b: { x: x, y: y } }; if (clipLine(l)) { if (!v_) { listener.lineStart(); listener.point(l.a.x, l.a.y); } listener.point(l.b.x, l.b.y); if (!v) listener.lineEnd(); clean = false; } else if (v) { listener.lineStart(); listener.point(x, y); clean = false; } } } x_ = x, y_ = y, v_ = v; } return clip; }; function corner(p, direction) { return abs(p[0] - x0) < ε ? direction > 0 ? 0 : 3 : abs(p[0] - x1) < ε ? direction > 0 ? 2 : 1 : abs(p[1] - y0) < ε ? direction > 0 ? 1 : 0 : direction > 0 ? 3 : 2; } function compare(a, b) { return comparePoints(a.x, b.x); } function comparePoints(a, b) { var ca = corner(a, 1), cb = corner(b, 1); return ca !== cb ? ca - cb : ca === 0 ? b[1] - a[1] : ca === 1 ? a[0] - b[0] : ca === 2 ? a[1] - b[1] : b[0] - a[0]; } } function d3_geo_compose(a, b) { function compose(x, y) { return x = a(x, y), b(x[0], x[1]); } if (a.invert && b.invert) compose.invert = function(x, y) { return x = b.invert(x, y), x && a.invert(x[0], x[1]); }; return compose; } function d3_geo_conic(projectAt) { var φ0 = 0, φ1 = π / 3, m = d3_geo_projectionMutator(projectAt), p = m(φ0, φ1); p.parallels = function(_) { if (!arguments.length) return [ φ0 / π * 180, φ1 / π * 180 ]; return m(φ0 = _[0] * π / 180, φ1 = _[1] * π / 180); }; return p; } function d3_geo_conicEqualArea(φ0, φ1) { var sinφ0 = Math.sin(φ0), n = (sinφ0 + Math.sin(φ1)) / 2, C = 1 + sinφ0 * (2 * n - sinφ0), ρ0 = Math.sqrt(C) / n; function forward(λ, φ) { var ρ = Math.sqrt(C - 2 * n * Math.sin(φ)) / n; return [ ρ * Math.sin(λ *= n), ρ0 - ρ * Math.cos(λ) ]; } forward.invert = function(x, y) { var ρ0_y = ρ0 - y; return [ Math.atan2(x, ρ0_y) / n, d3_asin((C - (x * x + ρ0_y * ρ0_y) * n * n) / (2 * n)) ]; }; return forward; } (d3.geo.conicEqualArea = function() { return d3_geo_conic(d3_geo_conicEqualArea); }).raw = d3_geo_conicEqualArea; d3.geo.albers = function() { return d3.geo.conicEqualArea().rotate([ 96, 0 ]).center([ -.6, 38.7 ]).parallels([ 29.5, 45.5 ]).scale(1070); }; d3.geo.albersUsa = function() { var lower48 = d3.geo.albers(); var alaska = d3.geo.conicEqualArea().rotate([ 154, 0 ]).center([ -2, 58.5 ]).parallels([ 55, 65 ]); var hawaii = d3.geo.conicEqualArea().rotate([ 157, 0 ]).center([ -3, 19.9 ]).parallels([ 8, 18 ]); var point, pointStream = { point: function(x, y) { point = [ x, y ]; } }, lower48Point, alaskaPoint, hawaiiPoint; function albersUsa(coordinates) { var x = coordinates[0], y = coordinates[1]; point = null; (lower48Point(x, y), point) || (alaskaPoint(x, y), point) || hawaiiPoint(x, y); return point; } albersUsa.invert = function(coordinates) { var k = lower48.scale(), t = lower48.translate(), x = (coordinates[0] - t[0]) / k, y = (coordinates[1] - t[1]) / k; return (y >= .12 && y < .234 && x >= -.425 && x < -.214 ? alaska : y >= .166 && y < .234 && x >= -.214 && x < -.115 ? hawaii : lower48).invert(coordinates); }; albersUsa.stream = function(stream) { var lower48Stream = lower48.stream(stream), alaskaStream = alaska.stream(stream), hawaiiStream = hawaii.stream(stream); return { point: function(x, y) { lower48Stream.point(x, y); alaskaStream.point(x, y); hawaiiStream.point(x, y); }, sphere: function() { lower48Stream.sphere(); alaskaStream.sphere(); hawaiiStream.sphere(); }, lineStart: function() { lower48Stream.lineStart(); alaskaStream.lineStart(); hawaiiStream.lineStart(); }, lineEnd: function() { lower48Stream.lineEnd(); alaskaStream.lineEnd(); hawaiiStream.lineEnd(); }, polygonStart: function() { lower48Stream.polygonStart(); alaskaStream.polygonStart(); hawaiiStream.polygonStart(); }, polygonEnd: function() { lower48Stream.polygonEnd(); alaskaStream.polygonEnd(); hawaiiStream.polygonEnd(); } }; }; albersUsa.precision = function(_) { if (!arguments.length) return lower48.precision(); lower48.precision(_); alaska.precision(_); hawaii.precision(_); return albersUsa; }; albersUsa.scale = function(_) { if (!arguments.length) return lower48.scale(); lower48.scale(_); alaska.scale(_ * .35); hawaii.scale(_); return albersUsa.translate(lower48.translate()); }; albersUsa.translate = function(_) { if (!arguments.length) return lower48.translate(); var k = lower48.scale(), x = +_[0], y = +_[1]; lower48Point = lower48.translate(_).clipExtent([ [ x - .455 * k, y - .238 * k ], [ x + .455 * k, y + .238 * k ] ]).stream(pointStream).point; alaskaPoint = alaska.translate([ x - .307 * k, y + .201 * k ]).clipExtent([ [ x - .425 * k + ε, y + .12 * k + ε ], [ x - .214 * k - ε, y + .234 * k - ε ] ]).stream(pointStream).point; hawaiiPoint = hawaii.translate([ x - .205 * k, y + .212 * k ]).clipExtent([ [ x - .214 * k + ε, y + .166 * k + ε ], [ x - .115 * k - ε, y + .234 * k - ε ] ]).stream(pointStream).point; return albersUsa; }; return albersUsa.scale(1070); }; var d3_geo_pathAreaSum, d3_geo_pathAreaPolygon, d3_geo_pathArea = { point: d3_noop, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: function() { d3_geo_pathAreaPolygon = 0; d3_geo_pathArea.lineStart = d3_geo_pathAreaRingStart; }, polygonEnd: function() { d3_geo_pathArea.lineStart = d3_geo_pathArea.lineEnd = d3_geo_pathArea.point = d3_noop; d3_geo_pathAreaSum += abs(d3_geo_pathAreaPolygon / 2); } }; function d3_geo_pathAreaRingStart() { var x00, y00, x0, y0; d3_geo_pathArea.point = function(x, y) { d3_geo_pathArea.point = nextPoint; x00 = x0 = x, y00 = y0 = y; }; function nextPoint(x, y) { d3_geo_pathAreaPolygon += y0 * x - x0 * y; x0 = x, y0 = y; } d3_geo_pathArea.lineEnd = function() { nextPoint(x00, y00); }; } var d3_geo_pathBoundsX0, d3_geo_pathBoundsY0, d3_geo_pathBoundsX1, d3_geo_pathBoundsY1; var d3_geo_pathBounds = { point: d3_geo_pathBoundsPoint, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: d3_noop, polygonEnd: d3_noop }; function d3_geo_pathBoundsPoint(x, y) { if (x < d3_geo_pathBoundsX0) d3_geo_pathBoundsX0 = x; if (x > d3_geo_pathBoundsX1) d3_geo_pathBoundsX1 = x; if (y < d3_geo_pathBoundsY0) d3_geo_pathBoundsY0 = y; if (y > d3_geo_pathBoundsY1) d3_geo_pathBoundsY1 = y; } function d3_geo_pathBuffer() { var pointCircle = d3_geo_pathBufferCircle(4.5), buffer = []; var stream = { point: point, lineStart: function() { stream.point = pointLineStart; }, lineEnd: lineEnd, polygonStart: function() { stream.lineEnd = lineEndPolygon; }, polygonEnd: function() { stream.lineEnd = lineEnd; stream.point = point; }, pointRadius: function(_) { pointCircle = d3_geo_pathBufferCircle(_); return stream; }, result: function() { if (buffer.length) { var result = buffer.join(""""); buffer = []; return result; } } }; function point(x, y) { buffer.push(""M"", x, "","", y, pointCircle); } function pointLineStart(x, y) { buffer.push(""M"", x, "","", y); stream.point = pointLine; } function pointLine(x, y) { buffer.push(""L"", x, "","", y); } function lineEnd() { stream.point = point; } function lineEndPolygon() { buffer.push(""Z""); } return stream; } function d3_geo_pathBufferCircle(radius) { return ""m0,"" + radius + ""a"" + radius + "","" + radius + "" 0 1,1 0,"" + -2 * radius + ""a"" + radius + "","" + radius + "" 0 1,1 0,"" + 2 * radius + ""z""; } var d3_geo_pathCentroid = { point: d3_geo_pathCentroidPoint, lineStart: d3_geo_pathCentroidLineStart, lineEnd: d3_geo_pathCentroidLineEnd, polygonStart: function() { d3_geo_pathCentroid.lineStart = d3_geo_pathCentroidRingStart; }, polygonEnd: function() { d3_geo_pathCentroid.point = d3_geo_pathCentroidPoint; d3_geo_pathCentroid.lineStart = d3_geo_pathCentroidLineStart; d3_geo_pathCentroid.lineEnd = d3_geo_pathCentroidLineEnd; } }; function d3_geo_pathCentroidPoint(x, y) { d3_geo_centroidX0 += x; d3_geo_centroidY0 += y; ++d3_geo_centroidZ0; } function d3_geo_pathCentroidLineStart() { var x0, y0; d3_geo_pathCentroid.point = function(x, y) { d3_geo_pathCentroid.point = nextPoint; d3_geo_pathCentroidPoint(x0 = x, y0 = y); }; function nextPoint(x, y) { var dx = x - x0, dy = y - y0, z = Math.sqrt(dx * dx + dy * dy); d3_geo_centroidX1 += z * (x0 + x) / 2; d3_geo_centroidY1 += z * (y0 + y) / 2; d3_geo_centroidZ1 += z; d3_geo_pathCentroidPoint(x0 = x, y0 = y); } } function d3_geo_pathCentroidLineEnd() { d3_geo_pathCentroid.point = d3_geo_pathCentroidPoint; } function d3_geo_pathCentroidRingStart() { var x00, y00, x0, y0; d3_geo_pathCentroid.point = function(x, y) { d3_geo_pathCentroid.point = nextPoint; d3_geo_pathCentroidPoint(x00 = x0 = x, y00 = y0 = y); }; function nextPoint(x, y) { var dx = x - x0, dy = y - y0, z = Math.sqrt(dx * dx + dy * dy); d3_geo_centroidX1 += z * (x0 + x) / 2; d3_geo_centroidY1 += z * (y0 + y) / 2; d3_geo_centroidZ1 += z; z = y0 * x - x0 * y; d3_geo_centroidX2 += z * (x0 + x); d3_geo_centroidY2 += z * (y0 + y); d3_geo_centroidZ2 += z * 3; d3_geo_pathCentroidPoint(x0 = x, y0 = y); } d3_geo_pathCentroid.lineEnd = function() { nextPoint(x00, y00); }; } function d3_geo_pathContext(context) { var pointRadius = 4.5; var stream = { point: point, lineStart: function() { stream.point = pointLineStart; }, lineEnd: lineEnd, polygonStart: function() { stream.lineEnd = lineEndPolygon; }, polygonEnd: function() { stream.lineEnd = lineEnd; stream.point = point; }, pointRadius: function(_) { pointRadius = _; return stream; }, result: d3_noop }; function point(x, y) { context.moveTo(x, y); context.arc(x, y, pointRadius, 0, τ); } function pointLineStart(x, y) { context.moveTo(x, y); stream.point = pointLine; } function pointLine(x, y) { context.lineTo(x, y); } function lineEnd() { stream.point = point; } function lineEndPolygon() { context.closePath(); } return stream; } function d3_geo_resample(project) { var δ2 = .5, cosMinDistance = Math.cos(30 * d3_radians), maxDepth = 16; function resample(stream) { return (maxDepth ? resampleRecursive : resampleNone)(stream); } function resampleNone(stream) { return d3_geo_transformPoint(stream, function(x, y) { x = project(x, y); stream.point(x[0], x[1]); }); } function resampleRecursive(stream) { var λ00, φ00, x00, y00, a00, b00, c00, λ0, x0, y0, a0, b0, c0; var resample = { point: point, lineStart: lineStart, lineEnd: lineEnd, polygonStart: function() { stream.polygonStart(); resample.lineStart = ringStart; }, polygonEnd: function() { stream.polygonEnd(); resample.lineStart = lineStart; } }; function point(x, y) { x = project(x, y); stream.point(x[0], x[1]); } function lineStart() { x0 = NaN; resample.point = linePoint; stream.lineStart(); } function linePoint(λ, φ) { var c = d3_geo_cartesian([ λ, φ ]), p = project(λ, φ); resampleLineTo(x0, y0, λ0, a0, b0, c0, x0 = p[0], y0 = p[1], λ0 = λ, a0 = c[0], b0 = c[1], c0 = c[2], maxDepth, stream); stream.point(x0, y0); } function lineEnd() { resample.point = point; stream.lineEnd(); } function ringStart() { lineStart(); resample.point = ringPoint; resample.lineEnd = ringEnd; } function ringPoint(λ, φ) { linePoint(λ00 = λ, φ00 = φ), x00 = x0, y00 = y0, a00 = a0, b00 = b0, c00 = c0; resample.point = linePoint; } function ringEnd() { resampleLineTo(x0, y0, λ0, a0, b0, c0, x00, y00, λ00, a00, b00, c00, maxDepth, stream); resample.lineEnd = lineEnd; lineEnd(); } return resample; } function resampleLineTo(x0, y0, λ0, a0, b0, c0, x1, y1, λ1, a1, b1, c1, depth, stream) { var dx = x1 - x0, dy = y1 - y0, d2 = dx * dx + dy * dy; if (d2 > 4 * δ2 && depth--) { var a = a0 + a1, b = b0 + b1, c = c0 + c1, m = Math.sqrt(a * a + b * b + c * c), φ2 = Math.asin(c /= m), λ2 = abs(abs(c) - 1) < ε || abs(λ0 - λ1) < ε ? (λ0 + λ1) / 2 : Math.atan2(b, a), p = project(λ2, φ2), x2 = p[0], y2 = p[1], dx2 = x2 - x0, dy2 = y2 - y0, dz = dy * dx2 - dx * dy2; if (dz * dz / d2 > δ2 || abs((dx * dx2 + dy * dy2) / d2 - .5) > .3 || a0 * a1 + b0 * b1 + c0 * c1 < cosMinDistance) { resampleLineTo(x0, y0, λ0, a0, b0, c0, x2, y2, λ2, a /= m, b /= m, c, depth, stream); stream.point(x2, y2); resampleLineTo(x2, y2, λ2, a, b, c, x1, y1, λ1, a1, b1, c1, depth, stream); } } } resample.precision = function(_) { if (!arguments.length) return Math.sqrt(δ2); maxDepth = (δ2 = _ * _) > 0 && 16; return resample; }; return resample; } d3.geo.path = function() { var pointRadius = 4.5, projection, context, projectStream, contextStream, cacheStream; function path(object) { if (object) { if (typeof pointRadius === ""function"") contextStream.pointRadius(+pointRadius.apply(this, arguments)); if (!cacheStream || !cacheStream.valid) cacheStream = projectStream(contextStream); d3.geo.stream(object, cacheStream); } return contextStream.result(); } path.area = function(object) { d3_geo_pathAreaSum = 0; d3.geo.stream(object, projectStream(d3_geo_pathArea)); return d3_geo_pathAreaSum; }; path.centroid = function(object) { d3_geo_centroidX0 = d3_geo_centroidY0 = d3_geo_centroidZ0 = d3_geo_centroidX1 = d3_geo_centroidY1 = d3_geo_centroidZ1 = d3_geo_centroidX2 = d3_geo_centroidY2 = d3_geo_centroidZ2 = 0; d3.geo.stream(object, projectStream(d3_geo_pathCentroid)); return d3_geo_centroidZ2 ? [ d3_geo_centroidX2 / d3_geo_centroidZ2, d3_geo_centroidY2 / d3_geo_centroidZ2 ] : d3_geo_centroidZ1 ? [ d3_geo_centroidX1 / d3_geo_centroidZ1, d3_geo_centroidY1 / d3_geo_centroidZ1 ] : d3_geo_centroidZ0 ? [ d3_geo_centroidX0 / d3_geo_centroidZ0, d3_geo_centroidY0 / d3_geo_centroidZ0 ] : [ NaN, NaN ]; }; path.bounds = function(object) { d3_geo_pathBoundsX1 = d3_geo_pathBoundsY1 = -(d3_geo_pathBoundsX0 = d3_geo_pathBoundsY0 = Infinity); d3.geo.stream(object, projectStream(d3_geo_pathBounds)); return [ [ d3_geo_pathBoundsX0, d3_geo_pathBoundsY0 ], [ d3_geo_pathBoundsX1, d3_geo_pathBoundsY1 ] ]; }; path.projection = function(_) { if (!arguments.length) return projection; projectStream = (projection = _) ? _.stream || d3_geo_pathProjectStream(_) : d3_identity; return reset(); }; path.context = function(_) { if (!arguments.length) return context; contextStream = (context = _) == null ? new d3_geo_pathBuffer() : new d3_geo_pathContext(_); if (typeof pointRadius !== ""function"") contextStream.pointRadius(pointRadius); return reset(); }; path.pointRadius = function(_) { if (!arguments.length) return pointRadius; pointRadius = typeof _ === ""function"" ? _ : (contextStream.pointRadius(+_), +_); return path; }; function reset() { cacheStream = null; return path; } return path.projection(d3.geo.albersUsa()).context(null); }; function d3_geo_pathProjectStream(project) { var resample = d3_geo_resample(function(x, y) { return project([ x * d3_degrees, y * d3_degrees ]); }); return function(stream) { return d3_geo_projectionRadians(resample(stream)); }; } d3.geo.transform = function(methods) { return { stream: function(stream) { var transform = new d3_geo_transform(stream); for (var k in methods) transform[k] = methods[k]; return transform; } }; }; function d3_geo_transform(stream) { this.stream = stream; } d3_geo_transform.prototype = { point: function(x, y) { this.stream.point(x, y); }, sphere: function() { this.stream.sphere(); }, lineStart: function() { this.stream.lineStart(); }, lineEnd: function() { this.stream.lineEnd(); }, polygonStart: function() { this.stream.polygonStart(); }, polygonEnd: function() { this.stream.polygonEnd(); } }; function d3_geo_transformPoint(stream, point) { return { point: point, sphere: function() { stream.sphere(); }, lineStart: function() { stream.lineStart(); }, lineEnd: function() { stream.lineEnd(); }, polygonStart: function() { stream.polygonStart(); }, polygonEnd: function() { stream.polygonEnd(); } }; } d3.geo.projection = d3_geo_projection; d3.geo.projectionMutator = d3_geo_projectionMutator; function d3_geo_projection(project) { return d3_geo_projectionMutator(function() { return project; })(); } function d3_geo_projectionMutator(projectAt) { var project, rotate, projectRotate, projectResample = d3_geo_resample(function(x, y) { x = project(x, y); return [ x[0] * k + δx, δy - x[1] * k ]; }), k = 150, x = 480, y = 250, λ = 0, φ = 0, δλ = 0, δφ = 0, δγ = 0, δx, δy, preclip = d3_geo_clipAntimeridian, postclip = d3_identity, clipAngle = null, clipExtent = null, stream; function projection(point) { point = projectRotate(point[0] * d3_radians, point[1] * d3_radians); return [ point[0] * k + δx, δy - point[1] * k ]; } function invert(point) { point = projectRotate.invert((point[0] - δx) / k, (δy - point[1]) / k); return point && [ point[0] * d3_degrees, point[1] * d3_degrees ]; } projection.stream = function(output) { if (stream) stream.valid = false; stream = d3_geo_projectionRadians(preclip(rotate, projectResample(postclip(output)))); stream.valid = true; return stream; }; projection.clipAngle = function(_) { if (!arguments.length) return clipAngle; preclip = _ == null ? (clipAngle = _, d3_geo_clipAntimeridian) : d3_geo_clipCircle((clipAngle = +_) * d3_radians); return invalidate(); }; projection.clipExtent = function(_) { if (!arguments.length) return clipExtent; clipExtent = _; postclip = _ ? d3_geo_clipExtent(_[0][0], _[0][1], _[1][0], _[1][1]) : d3_identity; return invalidate(); }; projection.scale = function(_) { if (!arguments.length) return k; k = +_; return reset(); }; projection.translate = function(_) { if (!arguments.length) return [ x, y ]; x = +_[0]; y = +_[1]; return reset(); }; projection.center = function(_) { if (!arguments.length) return [ λ * d3_degrees, φ * d3_degrees ]; λ = _[0] % 360 * d3_radians; φ = _[1] % 360 * d3_radians; return reset(); }; projection.rotate = function(_) { if (!arguments.length) return [ δλ * d3_degrees, δφ * d3_degrees, δγ * d3_degrees ]; δλ = _[0] % 360 * d3_radians; δφ = _[1] % 360 * d3_radians; δγ = _.length > 2 ? _[2] % 360 * d3_radians : 0; return reset(); }; d3.rebind(projection, projectResample, ""precision""); function reset() { projectRotate = d3_geo_compose(rotate = d3_geo_rotation(δλ, δφ, δγ), project); var center = project(λ, φ); δx = x - center[0] * k; δy = y + center[1] * k; return invalidate(); } function invalidate() { if (stream) stream.valid = false, stream = null; return projection; } return function() { project = projectAt.apply(this, arguments); projection.invert = project.invert && invert; return reset(); }; } function d3_geo_projectionRadians(stream) { return d3_geo_transformPoint(stream, function(x, y) { stream.point(x * d3_radians, y * d3_radians); }); } function d3_geo_equirectangular(λ, φ) { return [ λ, φ ]; } (d3.geo.equirectangular = function() { return d3_geo_projection(d3_geo_equirectangular); }).raw = d3_geo_equirectangular.invert = d3_geo_equirectangular; d3.geo.rotation = function(rotate) { rotate = d3_geo_rotation(rotate[0] % 360 * d3_radians, rotate[1] * d3_radians, rotate.length > 2 ? rotate[2] * d3_radians : 0); function forward(coordinates) { coordinates = rotate(coordinates[0] * d3_radians, coordinates[1] * d3_radians); return coordinates[0] *= d3_degrees, coordinates[1] *= d3_degrees, coordinates; } forward.invert = function(coordinates) { coordinates = rotate.invert(coordinates[0] * d3_radians, coordinates[1] * d3_radians); return coordinates[0] *= d3_degrees, coordinates[1] *= d3_degrees, coordinates; }; return forward; }; function d3_geo_identityRotation(λ, φ) { return [ λ > π ? λ - τ : λ < -π ? λ + τ : λ, φ ]; } d3_geo_identityRotation.invert = d3_geo_equirectangular; function d3_geo_rotation(δλ, δφ, δγ) { return δλ ? δφ || δγ ? d3_geo_compose(d3_geo_rotationλ(δλ), d3_geo_rotationφγ(δφ, δγ)) : d3_geo_rotationλ(δλ) : δφ || δγ ? d3_geo_rotationφγ(δφ, δγ) : d3_geo_identityRotation; } function d3_geo_forwardRotationλ(δλ) { return function(λ, φ) { return λ += δλ, [ λ > π ? λ - τ : λ < -π ? λ + τ : λ, φ ]; }; } function d3_geo_rotationλ(δλ) { var rotation = d3_geo_forwardRotationλ(δλ); rotation.invert = d3_geo_forwardRotationλ(-δλ); return rotation; } function d3_geo_rotationφγ(δφ, δγ) { var cosδφ = Math.cos(δφ), sinδφ = Math.sin(δφ), cosδγ = Math.cos(δγ), sinδγ = Math.sin(δγ); function rotation(λ, φ) { var cosφ = Math.cos(φ), x = Math.cos(λ) * cosφ, y = Math.sin(λ) * cosφ, z = Math.sin(φ), k = z * cosδφ + x * sinδφ; return [ Math.atan2(y * cosδγ - k * sinδγ, x * cosδφ - z * sinδφ), d3_asin(k * cosδγ + y * sinδγ) ]; } rotation.invert = function(λ, φ) { var cosφ = Math.cos(φ), x = Math.cos(λ) * cosφ, y = Math.sin(λ) * cosφ, z = Math.sin(φ), k = z * cosδγ - y * sinδγ; return [ Math.atan2(y * cosδγ + z * sinδγ, x * cosδφ + k * sinδφ), d3_asin(k * cosδφ - x * sinδφ) ]; }; return rotation; } d3.geo.circle = function() { var origin = [ 0, 0 ], angle, precision = 6, interpolate; function circle() { var center = typeof origin === ""function"" ? origin.apply(this, arguments) : origin, rotate = d3_geo_rotation(-center[0] * d3_radians, -center[1] * d3_radians, 0).invert, ring = []; interpolate(null, null, 1, { point: function(x, y) { ring.push(x = rotate(x, y)); x[0] *= d3_degrees, x[1] *= d3_degrees; } }); return { type: ""Polygon"", coordinates: [ ring ] }; } circle.origin = function(x) { if (!arguments.length) return origin; origin = x; return circle; }; circle.angle = function(x) { if (!arguments.length) return angle; interpolate = d3_geo_circleInterpolate((angle = +x) * d3_radians, precision * d3_radians); return circle; }; circle.precision = function(_) { if (!arguments.length) return precision; interpolate = d3_geo_circleInterpolate(angle * d3_radians, (precision = +_) * d3_radians); return circle; }; return circle.angle(90); }; function d3_geo_circleInterpolate(radius, precision) { var cr = Math.cos(radius), sr = Math.sin(radius); return function(from, to, direction, listener) { var step = direction * precision; if (from != null) { from = d3_geo_circleAngle(cr, from); to = d3_geo_circleAngle(cr, to); if (direction > 0 ? from < to : from > to) from += direction * τ; } else { from = radius + direction * τ; to = radius - .5 * step; } for (var point, t = from; direction > 0 ? t > to : t < to; t -= step) { listener.point((point = d3_geo_spherical([ cr, -sr * Math.cos(t), -sr * Math.sin(t) ]))[0], point[1]); } }; } function d3_geo_circleAngle(cr, point) { var a = d3_geo_cartesian(point); a[0] -= cr; d3_geo_cartesianNormalize(a); var angle = d3_acos(-a[1]); return ((-a[2] < 0 ? -angle : angle) + 2 * Math.PI - ε) % (2 * Math.PI); } d3.geo.distance = function(a, b) { var Δλ = (b[0] - a[0]) * d3_radians, φ0 = a[1] * d3_radians, φ1 = b[1] * d3_radians, sinΔλ = Math.sin(Δλ), cosΔλ = Math.cos(Δλ), sinφ0 = Math.sin(φ0), cosφ0 = Math.cos(φ0), sinφ1 = Math.sin(φ1), cosφ1 = Math.cos(φ1), t; return Math.atan2(Math.sqrt((t = cosφ1 * sinΔλ) * t + (t = cosφ0 * sinφ1 - sinφ0 * cosφ1 * cosΔλ) * t), sinφ0 * sinφ1 + cosφ0 * cosφ1 * cosΔλ); }; d3.geo.graticule = function() { var x1, x0, X1, X0, y1, y0, Y1, Y0, dx = 10, dy = dx, DX = 90, DY = 360, x, y, X, Y, precision = 2.5; function graticule() { return { type: ""MultiLineString"", coordinates: lines() }; } function lines() { return d3.range(Math.ceil(X0 / DX) * DX, X1, DX).map(X).concat(d3.range(Math.ceil(Y0 / DY) * DY, Y1, DY).map(Y)).concat(d3.range(Math.ceil(x0 / dx) * dx, x1, dx).filter(function(x) { return abs(x % DX) > ε; }).map(x)).concat(d3.range(Math.ceil(y0 / dy) * dy, y1, dy).filter(function(y) { return abs(y % DY) > ε; }).map(y)); } graticule.lines = function() { return lines().map(function(coordinates) { return { type: ""LineString"", coordinates: coordinates }; }); }; graticule.outline = function() { return { type: ""Polygon"", coordinates: [ X(X0).concat(Y(Y1).slice(1), X(X1).reverse().slice(1), Y(Y0).reverse().slice(1)) ] }; }; graticule.extent = function(_) { if (!arguments.length) return graticule.minorExtent(); return graticule.majorExtent(_).minorExtent(_); }; graticule.majorExtent = function(_) { if (!arguments.length) return [ [ X0, Y0 ], [ X1, Y1 ] ]; X0 = +_[0][0], X1 = +_[1][0]; Y0 = +_[0][1], Y1 = +_[1][1]; if (X0 > X1) _ = X0, X0 = X1, X1 = _; if (Y0 > Y1) _ = Y0, Y0 = Y1, Y1 = _; return graticule.precision(precision); }; graticule.minorExtent = function(_) { if (!arguments.length) return [ [ x0, y0 ], [ x1, y1 ] ]; x0 = +_[0][0], x1 = +_[1][0]; y0 = +_[0][1], y1 = +_[1][1]; if (x0 > x1) _ = x0, x0 = x1, x1 = _; if (y0 > y1) _ = y0, y0 = y1, y1 = _; return graticule.precision(precision); }; graticule.step = function(_) { if (!arguments.length) return graticule.minorStep(); return graticule.majorStep(_).minorStep(_); }; graticule.majorStep = function(_) { if (!arguments.length) return [ DX, DY ]; DX = +_[0], DY = +_[1]; return graticule; }; graticule.minorStep = function(_) { if (!arguments.length) return [ dx, dy ]; dx = +_[0], dy = +_[1]; return graticule; }; graticule.precision = function(_) { if (!arguments.length) return precision; precision = +_; x = d3_geo_graticuleX(y0, y1, 90); y = d3_geo_graticuleY(x0, x1, precision); X = d3_geo_graticuleX(Y0, Y1, 90); Y = d3_geo_graticuleY(X0, X1, precision); return graticule; }; return graticule.majorExtent([ [ -180, -90 + ε ], [ 180, 90 - ε ] ]).minorExtent([ [ -180, -80 - ε ], [ 180, 80 + ε ] ]); }; function d3_geo_graticuleX(y0, y1, dy) { var y = d3.range(y0, y1 - ε, dy).concat(y1); return function(x) { return y.map(function(y) { return [ x, y ]; }); }; } function d3_geo_graticuleY(x0, x1, dx) { var x = d3.range(x0, x1 - ε, dx).concat(x1); return function(y) { return x.map(function(x) { return [ x, y ]; }); }; } function d3_source(d) { return d.source; } function d3_target(d) { return d.target; } d3.geo.greatArc = function() { var source = d3_source, source_, target = d3_target, target_; function greatArc() { return { type: ""LineString"", coordinates: [ source_ || source.apply(this, arguments), target_ || target.apply(this, arguments) ] }; } greatArc.distance = function() { return d3.geo.distance(source_ || source.apply(this, arguments), target_ || target.apply(this, arguments)); }; greatArc.source = function(_) { if (!arguments.length) return source; source = _, source_ = typeof _ === ""function"" ? null : _; return greatArc; }; greatArc.target = function(_) { if (!arguments.length) return target; target = _, target_ = typeof _ === ""function"" ? null : _; return greatArc; }; greatArc.precision = function() { return arguments.length ? greatArc : 0; }; return greatArc; }; d3.geo.interpolate = function(source, target) { return d3_geo_interpolate(source[0] * d3_radians, source[1] * d3_radians, target[0] * d3_radians, target[1] * d3_radians); }; function d3_geo_interpolate(x0, y0, x1, y1) { var cy0 = Math.cos(y0), sy0 = Math.sin(y0), cy1 = Math.cos(y1), sy1 = Math.sin(y1), kx0 = cy0 * Math.cos(x0), ky0 = cy0 * Math.sin(x0), kx1 = cy1 * Math.cos(x1), ky1 = cy1 * Math.sin(x1), d = 2 * Math.asin(Math.sqrt(d3_haversin(y1 - y0) + cy0 * cy1 * d3_haversin(x1 - x0))), k = 1 / Math.sin(d); var interpolate = d ? function(t) { var B = Math.sin(t *= d) * k, A = Math.sin(d - t) * k, x = A * kx0 + B * kx1, y = A * ky0 + B * ky1, z = A * sy0 + B * sy1; return [ Math.atan2(y, x) * d3_degrees, Math.atan2(z, Math.sqrt(x * x + y * y)) * d3_degrees ]; } : function() { return [ x0 * d3_degrees, y0 * d3_degrees ]; }; interpolate.distance = d; return interpolate; } d3.geo.length = function(object) { d3_geo_lengthSum = 0; d3.geo.stream(object, d3_geo_length); return d3_geo_lengthSum; }; var d3_geo_lengthSum; var d3_geo_length = { sphere: d3_noop, point: d3_noop, lineStart: d3_geo_lengthLineStart, lineEnd: d3_noop, polygonStart: d3_noop, polygonEnd: d3_noop }; function d3_geo_lengthLineStart() { var λ0, sinφ0, cosφ0; d3_geo_length.point = function(λ, φ) { λ0 = λ * d3_radians, sinφ0 = Math.sin(φ *= d3_radians), cosφ0 = Math.cos(φ); d3_geo_length.point = nextPoint; }; d3_geo_length.lineEnd = function() { d3_geo_length.point = d3_geo_length.lineEnd = d3_noop; }; function nextPoint(λ, φ) { var sinφ = Math.sin(φ *= d3_radians), cosφ = Math.cos(φ), t = abs((λ *= d3_radians) - λ0), cosΔλ = Math.cos(t); d3_geo_lengthSum += Math.atan2(Math.sqrt((t = cosφ * Math.sin(t)) * t + (t = cosφ0 * sinφ - sinφ0 * cosφ * cosΔλ) * t), sinφ0 * sinφ + cosφ0 * cosφ * cosΔλ); λ0 = λ, sinφ0 = sinφ, cosφ0 = cosφ; } } function d3_geo_azimuthal(scale, angle) { function azimuthal(λ, φ) { var cosλ = Math.cos(λ), cosφ = Math.cos(φ), k = scale(cosλ * cosφ); return [ k * cosφ * Math.sin(λ), k * Math.sin(φ) ]; } azimuthal.invert = function(x, y) { var ρ = Math.sqrt(x * x + y * y), c = angle(ρ), sinc = Math.sin(c), cosc = Math.cos(c); return [ Math.atan2(x * sinc, ρ * cosc), Math.asin(ρ && y * sinc / ρ) ]; }; return azimuthal; } var d3_geo_azimuthalEqualArea = d3_geo_azimuthal(function(cosλcosφ) { return Math.sqrt(2 / (1 + cosλcosφ)); }, function(ρ) { return 2 * Math.asin(ρ / 2); }); (d3.geo.azimuthalEqualArea = function() { return d3_geo_projection(d3_geo_azimuthalEqualArea); }).raw = d3_geo_azimuthalEqualArea; var d3_geo_azimuthalEquidistant = d3_geo_azimuthal(function(cosλcosφ) { var c = Math.acos(cosλcosφ); return c && c / Math.sin(c); }, d3_identity); (d3.geo.azimuthalEquidistant = function() { return d3_geo_projection(d3_geo_azimuthalEquidistant); }).raw = d3_geo_azimuthalEquidistant; function d3_geo_conicConformal(φ0, φ1) { var cosφ0 = Math.cos(φ0), t = function(φ) { return Math.tan(π / 4 + φ / 2); }, n = φ0 === φ1 ? Math.sin(φ0) : Math.log(cosφ0 / Math.cos(φ1)) / Math.log(t(φ1) / t(φ0)), F = cosφ0 * Math.pow(t(φ0), n) / n; if (!n) return d3_geo_mercator; function forward(λ, φ) { if (F > 0) { if (φ < -halfπ + ε) φ = -halfπ + ε; } else { if (φ > halfπ - ε) φ = halfπ - ε; } var ρ = F / Math.pow(t(φ), n); return [ ρ * Math.sin(n * λ), F - ρ * Math.cos(n * λ) ]; } forward.invert = function(x, y) { var ρ0_y = F - y, ρ = d3_sgn(n) * Math.sqrt(x * x + ρ0_y * ρ0_y); return [ Math.atan2(x, ρ0_y) / n, 2 * Math.atan(Math.pow(F / ρ, 1 / n)) - halfπ ]; }; return forward; } (d3.geo.conicConformal = function() { return d3_geo_conic(d3_geo_conicConformal); }).raw = d3_geo_conicConformal; function d3_geo_conicEquidistant(φ0, φ1) { var cosφ0 = Math.cos(φ0), n = φ0 === φ1 ? Math.sin(φ0) : (cosφ0 - Math.cos(φ1)) / (φ1 - φ0), G = cosφ0 / n + φ0; if (abs(n) < ε) return d3_geo_equirectangular; function forward(λ, φ) { var ρ = G - φ; return [ ρ * Math.sin(n * λ), G - ρ * Math.cos(n * λ) ]; } forward.invert = function(x, y) { var ρ0_y = G - y; return [ Math.atan2(x, ρ0_y) / n, G - d3_sgn(n) * Math.sqrt(x * x + ρ0_y * ρ0_y) ]; }; return forward; } (d3.geo.conicEquidistant = function() { return d3_geo_conic(d3_geo_conicEquidistant); }).raw = d3_geo_conicEquidistant; var d3_geo_gnomonic = d3_geo_azimuthal(function(cosλcosφ) { return 1 / cosλcosφ; }, Math.atan); (d3.geo.gnomonic = function() { return d3_geo_projection(d3_geo_gnomonic); }).raw = d3_geo_gnomonic; function d3_geo_mercator(λ, φ) { return [ λ, Math.log(Math.tan(π / 4 + φ / 2)) ]; } d3_geo_mercator.invert = function(x, y) { return [ x, 2 * Math.atan(Math.exp(y)) - halfπ ]; }; function d3_geo_mercatorProjection(project) { var m = d3_geo_projection(project), scale = m.scale, translate = m.translate, clipExtent = m.clipExtent, clipAuto; m.scale = function() { var v = scale.apply(m, arguments); return v === m ? clipAuto ? m.clipExtent(null) : m : v; }; m.translate = function() { var v = translate.apply(m, arguments); return v === m ? clipAuto ? m.clipExtent(null) : m : v; }; m.clipExtent = function(_) { var v = clipExtent.apply(m, arguments); if (v === m) { if (clipAuto = _ == null) { var k = π * scale(), t = translate(); clipExtent([ [ t[0] - k, t[1] - k ], [ t[0] + k, t[1] + k ] ]); } } else if (clipAuto) { v = null; } return v; }; return m.clipExtent(null); } (d3.geo.mercator = function() { return d3_geo_mercatorProjection(d3_geo_mercator); }).raw = d3_geo_mercator; var d3_geo_orthographic = d3_geo_azimuthal(function() { return 1; }, Math.asin); (d3.geo.orthographic = function() { return d3_geo_projection(d3_geo_orthographic); }).raw = d3_geo_orthographic; var d3_geo_stereographic = d3_geo_azimuthal(function(cosλcosφ) { return 1 / (1 + cosλcosφ); }, function(ρ) { return 2 * Math.atan(ρ); }); (d3.geo.stereographic = function() { return d3_geo_projection(d3_geo_stereographic); }).raw = d3_geo_stereographic; function d3_geo_transverseMercator(λ, φ) { return [ Math.log(Math.tan(π / 4 + φ / 2)), -λ ]; } d3_geo_transverseMercator.invert = function(x, y) { return [ -y, 2 * Math.atan(Math.exp(x)) - halfπ ]; }; (d3.geo.transverseMercator = function() { var projection = d3_geo_mercatorProjection(d3_geo_transverseMercator), center = projection.center, rotate = projection.rotate; projection.center = function(_) { return _ ? center([ -_[1], _[0] ]) : (_ = center(), [ -_[1], _[0] ]); }; projection.rotate = function(_) { return _ ? rotate([ _[0], _[1], _.length > 2 ? _[2] + 90 : 90 ]) : (_ = rotate(), [ _[0], _[1], _[2] - 90 ]); }; return projection.rotate([ 0, 0 ]); }).raw = d3_geo_transverseMercator; d3.geom = {}; function d3_geom_pointX(d) { return d[0]; } function d3_geom_pointY(d) { return d[1]; } d3.geom.hull = function(vertices) { var x = d3_geom_pointX, y = d3_geom_pointY; if (arguments.length) return hull(vertices); function hull(data) { if (data.length < 3) return []; var fx = d3_functor(x), fy = d3_functor(y), i, n = data.length, points = [], flippedPoints = []; for (i = 0; i < n; i++) { points.push([ +fx.call(this, data[i], i), +fy.call(this, data[i], i), i ]); } points.sort(d3_geom_hullOrder); for (i = 0; i < n; i++) flippedPoints.push([ points[i][0], -points[i][1] ]); var upper = d3_geom_hullUpper(points), lower = d3_geom_hullUpper(flippedPoints); var skipLeft = lower[0] === upper[0], skipRight = lower[lower.length - 1] === upper[upper.length - 1], polygon = []; for (i = upper.length - 1; i >= 0; --i) polygon.push(data[points[upper[i]][2]]); for (i = +skipLeft; i < lower.length - skipRight; ++i) polygon.push(data[points[lower[i]][2]]); return polygon; } hull.x = function(_) { return arguments.length ? (x = _, hull) : x; }; hull.y = function(_) { return arguments.length ? (y = _, hull) : y; }; return hull; }; function d3_geom_hullUpper(points) { var n = points.length, hull = [ 0, 1 ], hs = 2; for (var i = 2; i < n; i++) { while (hs > 1 && d3_cross2d(points[hull[hs - 2]], points[hull[hs - 1]], points[i]) <= 0) --hs; hull[hs++] = i; } return hull.slice(0, hs); } function d3_geom_hullOrder(a, b) { return a[0] - b[0] || a[1] - b[1]; } d3.geom.polygon = function(coordinates) { d3_subclass(coordinates, d3_geom_polygonPrototype); return coordinates; }; var d3_geom_polygonPrototype = d3.geom.polygon.prototype = []; d3_geom_polygonPrototype.area = function() { var i = -1, n = this.length, a, b = this[n - 1], area = 0; while (++i < n) { a = b; b = this[i]; area += a[1] * b[0] - a[0] * b[1]; } return area * .5; }; d3_geom_polygonPrototype.centroid = function(k) { var i = -1, n = this.length, x = 0, y = 0, a, b = this[n - 1], c; if (!arguments.length) k = -1 / (6 * this.area()); while (++i < n) { a = b; b = this[i]; c = a[0] * b[1] - b[0] * a[1]; x += (a[0] + b[0]) * c; y += (a[1] + b[1]) * c; } return [ x * k, y * k ]; }; d3_geom_polygonPrototype.clip = function(subject) { var input, closed = d3_geom_polygonClosed(subject), i = -1, n = this.length - d3_geom_polygonClosed(this), j, m, a = this[n - 1], b, c, d; while (++i < n) { input = subject.slice(); subject.length = 0; b = this[i]; c = input[(m = input.length - closed) - 1]; j = -1; while (++j < m) { d = input[j]; if (d3_geom_polygonInside(d, a, b)) { if (!d3_geom_polygonInside(c, a, b)) { subject.push(d3_geom_polygonIntersect(c, d, a, b)); } subject.push(d); } else if (d3_geom_polygonInside(c, a, b)) { subject.push(d3_geom_polygonIntersect(c, d, a, b)); } c = d; } if (closed) subject.push(subject[0]); a = b; } return subject; }; function d3_geom_polygonInside(p, a, b) { return (b[0] - a[0]) * (p[1] - a[1]) < (b[1] - a[1]) * (p[0] - a[0]); } function d3_geom_polygonIntersect(c, d, a, b) { var x1 = c[0], x3 = a[0], x21 = d[0] - x1, x43 = b[0] - x3, y1 = c[1], y3 = a[1], y21 = d[1] - y1, y43 = b[1] - y3, ua = (x43 * (y1 - y3) - y43 * (x1 - x3)) / (y43 * x21 - x43 * y21); return [ x1 + ua * x21, y1 + ua * y21 ]; } function d3_geom_polygonClosed(coordinates) { var a = coordinates[0], b = coordinates[coordinates.length - 1]; return !(a[0] - b[0] || a[1] - b[1]); } var d3_geom_voronoiEdges, d3_geom_voronoiCells, d3_geom_voronoiBeaches, d3_geom_voronoiBeachPool = [], d3_geom_voronoiFirstCircle, d3_geom_voronoiCircles, d3_geom_voronoiCirclePool = []; function d3_geom_voronoiBeach() { d3_geom_voronoiRedBlackNode(this); this.edge = this.site = this.circle = null; } function d3_geom_voronoiCreateBeach(site) { var beach = d3_geom_voronoiBeachPool.pop() || new d3_geom_voronoiBeach(); beach.site = site; return beach; } function d3_geom_voronoiDetachBeach(beach) { d3_geom_voronoiDetachCircle(beach); d3_geom_voronoiBeaches.remove(beach); d3_geom_voronoiBeachPool.push(beach); d3_geom_voronoiRedBlackNode(beach); } function d3_geom_voronoiRemoveBeach(beach) { var circle = beach.circle, x = circle.x, y = circle.cy, vertex = { x: x, y: y }, previous = beach.P, next = beach.N, disappearing = [ beach ]; d3_geom_voronoiDetachBeach(beach); var lArc = previous; while (lArc.circle && abs(x - lArc.circle.x) < ε && abs(y - lArc.circle.cy) < ε) { previous = lArc.P; disappearing.unshift(lArc); d3_geom_voronoiDetachBeach(lArc); lArc = previous; } disappearing.unshift(lArc); d3_geom_voronoiDetachCircle(lArc); var rArc = next; while (rArc.circle && abs(x - rArc.circle.x) < ε && abs(y - rArc.circle.cy) < ε) { next = rArc.N; disappearing.push(rArc); d3_geom_voronoiDetachBeach(rArc); rArc = next; } disappearing.push(rArc); d3_geom_voronoiDetachCircle(rArc); var nArcs = disappearing.length, iArc; for (iArc = 1; iArc < nArcs; ++iArc) { rArc = disappearing[iArc]; lArc = disappearing[iArc - 1]; d3_geom_voronoiSetEdgeEnd(rArc.edge, lArc.site, rArc.site, vertex); } lArc = disappearing[0]; rArc = disappearing[nArcs - 1]; rArc.edge = d3_geom_voronoiCreateEdge(lArc.site, rArc.site, null, vertex); d3_geom_voronoiAttachCircle(lArc); d3_geom_voronoiAttachCircle(rArc); } function d3_geom_voronoiAddBeach(site) { var x = site.x, directrix = site.y, lArc, rArc, dxl, dxr, node = d3_geom_voronoiBeaches._; while (node) { dxl = d3_geom_voronoiLeftBreakPoint(node, directrix) - x; if (dxl > ε) node = node.L; else { dxr = x - d3_geom_voronoiRightBreakPoint(node, directrix); if (dxr > ε) { if (!node.R) { lArc = node; break; } node = node.R; } else { if (dxl > -ε) { lArc = node.P; rArc = node; } else if (dxr > -ε) { lArc = node; rArc = node.N; } else { lArc = rArc = node; } break; } } } var newArc = d3_geom_voronoiCreateBeach(site); d3_geom_voronoiBeaches.insert(lArc, newArc); if (!lArc && !rArc) return; if (lArc === rArc) { d3_geom_voronoiDetachCircle(lArc); rArc = d3_geom_voronoiCreateBeach(lArc.site); d3_geom_voronoiBeaches.insert(newArc, rArc); newArc.edge = rArc.edge = d3_geom_voronoiCreateEdge(lArc.site, newArc.site); d3_geom_voronoiAttachCircle(lArc); d3_geom_voronoiAttachCircle(rArc); return; } if (!rArc) { newArc.edge = d3_geom_voronoiCreateEdge(lArc.site, newArc.site); return; } d3_geom_voronoiDetachCircle(lArc); d3_geom_voronoiDetachCircle(rArc); var lSite = lArc.site, ax = lSite.x, ay = lSite.y, bx = site.x - ax, by = site.y - ay, rSite = rArc.site, cx = rSite.x - ax, cy = rSite.y - ay, d = 2 * (bx * cy - by * cx), hb = bx * bx + by * by, hc = cx * cx + cy * cy, vertex = { x: (cy * hb - by * hc) / d + ax, y: (bx * hc - cx * hb) / d + ay }; d3_geom_voronoiSetEdgeEnd(rArc.edge, lSite, rSite, vertex); newArc.edge = d3_geom_voronoiCreateEdge(lSite, site, null, vertex); rArc.edge = d3_geom_voronoiCreateEdge(site, rSite, null, vertex); d3_geom_voronoiAttachCircle(lArc); d3_geom_voronoiAttachCircle(rArc); } function d3_geom_voronoiLeftBreakPoint(arc, directrix) { var site = arc.site, rfocx = site.x, rfocy = site.y, pby2 = rfocy - directrix; if (!pby2) return rfocx; var lArc = arc.P; if (!lArc) return -Infinity; site = lArc.site; var lfocx = site.x, lfocy = site.y, plby2 = lfocy - directrix; if (!plby2) return lfocx; var hl = lfocx - rfocx, aby2 = 1 / pby2 - 1 / plby2, b = hl / plby2; if (aby2) return (-b + Math.sqrt(b * b - 2 * aby2 * (hl * hl / (-2 * plby2) - lfocy + plby2 / 2 + rfocy - pby2 / 2))) / aby2 + rfocx; return (rfocx + lfocx) / 2; } function d3_geom_voronoiRightBreakPoint(arc, directrix) { var rArc = arc.N; if (rArc) return d3_geom_voronoiLeftBreakPoint(rArc, directrix); var site = arc.site; return site.y === directrix ? site.x : Infinity; } function d3_geom_voronoiCell(site) { this.site = site; this.edges = []; } d3_geom_voronoiCell.prototype.prepare = function() { var halfEdges = this.edges, iHalfEdge = halfEdges.length, edge; while (iHalfEdge--) { edge = halfEdges[iHalfEdge].edge; if (!edge.b || !edge.a) halfEdges.splice(iHalfEdge, 1); } halfEdges.sort(d3_geom_voronoiHalfEdgeOrder); return halfEdges.length; }; function d3_geom_voronoiCloseCells(extent) { var x0 = extent[0][0], x1 = extent[1][0], y0 = extent[0][1], y1 = extent[1][1], x2, y2, x3, y3, cells = d3_geom_voronoiCells, iCell = cells.length, cell, iHalfEdge, halfEdges, nHalfEdges, start, end; while (iCell--) { cell = cells[iCell]; if (!cell || !cell.prepare()) continue; halfEdges = cell.edges; nHalfEdges = halfEdges.length; iHalfEdge = 0; while (iHalfEdge < nHalfEdges) { end = halfEdges[iHalfEdge].end(), x3 = end.x, y3 = end.y; start = halfEdges[++iHalfEdge % nHalfEdges].start(), x2 = start.x, y2 = start.y; if (abs(x3 - x2) > ε || abs(y3 - y2) > ε) { halfEdges.splice(iHalfEdge, 0, new d3_geom_voronoiHalfEdge(d3_geom_voronoiCreateBorderEdge(cell.site, end, abs(x3 - x0) < ε && y1 - y3 > ε ? { x: x0, y: abs(x2 - x0) < ε ? y2 : y1 } : abs(y3 - y1) < ε && x1 - x3 > ε ? { x: abs(y2 - y1) < ε ? x2 : x1, y: y1 } : abs(x3 - x1) < ε && y3 - y0 > ε ? { x: x1, y: abs(x2 - x1) < ε ? y2 : y0 } : abs(y3 - y0) < ε && x3 - x0 > ε ? { x: abs(y2 - y0) < ε ? x2 : x0, y: y0 } : null), cell.site, null)); ++nHalfEdges; } } } } function d3_geom_voronoiHalfEdgeOrder(a, b) { return b.angle - a.angle; } function d3_geom_voronoiCircle() { d3_geom_voronoiRedBlackNode(this); this.x = this.y = this.arc = this.site = this.cy = null; } function d3_geom_voronoiAttachCircle(arc) { var lArc = arc.P, rArc = arc.N; if (!lArc || !rArc) return; var lSite = lArc.site, cSite = arc.site, rSite = rArc.site; if (lSite === rSite) return; var bx = cSite.x, by = cSite.y, ax = lSite.x - bx, ay = lSite.y - by, cx = rSite.x - bx, cy = rSite.y - by; var d = 2 * (ax * cy - ay * cx); if (d >= -ε2) return; var ha = ax * ax + ay * ay, hc = cx * cx + cy * cy, x = (cy * ha - ay * hc) / d, y = (ax * hc - cx * ha) / d, cy = y + by; var circle = d3_geom_voronoiCirclePool.pop() || new d3_geom_voronoiCircle(); circle.arc = arc; circle.site = cSite; circle.x = x + bx; circle.y = cy + Math.sqrt(x * x + y * y); circle.cy = cy; arc.circle = circle; var before = null, node = d3_geom_voronoiCircles._; while (node) { if (circle.y < node.y || circle.y === node.y && circle.x <= node.x) { if (node.L) node = node.L; else { before = node.P; break; } } else { if (node.R) node = node.R; else { before = node; break; } } } d3_geom_voronoiCircles.insert(before, circle); if (!before) d3_geom_voronoiFirstCircle = circle; } function d3_geom_voronoiDetachCircle(arc) { var circle = arc.circle; if (circle) { if (!circle.P) d3_geom_voronoiFirstCircle = circle.N; d3_geom_voronoiCircles.remove(circle); d3_geom_voronoiCirclePool.push(circle); d3_geom_voronoiRedBlackNode(circle); arc.circle = null; } } function d3_geom_voronoiClipEdges(extent) { var edges = d3_geom_voronoiEdges, clip = d3_geom_clipLine(extent[0][0], extent[0][1], extent[1][0], extent[1][1]), i = edges.length, e; while (i--) { e = edges[i]; if (!d3_geom_voronoiConnectEdge(e, extent) || !clip(e) || abs(e.a.x - e.b.x) < ε && abs(e.a.y - e.b.y) < ε) { e.a = e.b = null; edges.splice(i, 1); } } } function d3_geom_voronoiConnectEdge(edge, extent) { var vb = edge.b; if (vb) return true; var va = edge.a, x0 = extent[0][0], x1 = extent[1][0], y0 = extent[0][1], y1 = extent[1][1], lSite = edge.l, rSite = edge.r, lx = lSite.x, ly = lSite.y, rx = rSite.x, ry = rSite.y, fx = (lx + rx) / 2, fy = (ly + ry) / 2, fm, fb; if (ry === ly) { if (fx < x0 || fx >= x1) return; if (lx > rx) { if (!va) va = { x: fx, y: y0 }; else if (va.y >= y1) return; vb = { x: fx, y: y1 }; } else { if (!va) va = { x: fx, y: y1 }; else if (va.y < y0) return; vb = { x: fx, y: y0 }; } } else { fm = (lx - rx) / (ry - ly); fb = fy - fm * fx; if (fm < -1 || fm > 1) { if (lx > rx) { if (!va) va = { x: (y0 - fb) / fm, y: y0 }; else if (va.y >= y1) return; vb = { x: (y1 - fb) / fm, y: y1 }; } else { if (!va) va = { x: (y1 - fb) / fm, y: y1 }; else if (va.y < y0) return; vb = { x: (y0 - fb) / fm, y: y0 }; } } else { if (ly < ry) { if (!va) va = { x: x0, y: fm * x0 + fb }; else if (va.x >= x1) return; vb = { x: x1, y: fm * x1 + fb }; } else { if (!va) va = { x: x1, y: fm * x1 + fb }; else if (va.x < x0) return; vb = { x: x0, y: fm * x0 + fb }; } } } edge.a = va; edge.b = vb; return true; } function d3_geom_voronoiEdge(lSite, rSite) { this.l = lSite; this.r = rSite; this.a = this.b = null; } function d3_geom_voronoiCreateEdge(lSite, rSite, va, vb) { var edge = new d3_geom_voronoiEdge(lSite, rSite); d3_geom_voronoiEdges.push(edge); if (va) d3_geom_voronoiSetEdgeEnd(edge, lSite, rSite, va); if (vb) d3_geom_voronoiSetEdgeEnd(edge, rSite, lSite, vb); d3_geom_voronoiCells[lSite.i].edges.push(new d3_geom_voronoiHalfEdge(edge, lSite, rSite)); d3_geom_voronoiCells[rSite.i].edges.push(new d3_geom_voronoiHalfEdge(edge, rSite, lSite)); return edge; } function d3_geom_voronoiCreateBorderEdge(lSite, va, vb) { var edge = new d3_geom_voronoiEdge(lSite, null); edge.a = va; edge.b = vb; d3_geom_voronoiEdges.push(edge); return edge; } function d3_geom_voronoiSetEdgeEnd(edge, lSite, rSite, vertex) { if (!edge.a && !edge.b) { edge.a = vertex; edge.l = lSite; edge.r = rSite; } else if (edge.l === rSite) { edge.b = vertex; } else { edge.a = vertex; } } function d3_geom_voronoiHalfEdge(edge, lSite, rSite) { var va = edge.a, vb = edge.b; this.edge = edge; this.site = lSite; this.angle = rSite ? Math.atan2(rSite.y - lSite.y, rSite.x - lSite.x) : edge.l === lSite ? Math.atan2(vb.x - va.x, va.y - vb.y) : Math.atan2(va.x - vb.x, vb.y - va.y); } d3_geom_voronoiHalfEdge.prototype = { start: function() { return this.edge.l === this.site ? this.edge.a : this.edge.b; }, end: function() { return this.edge.l === this.site ? this.edge.b : this.edge.a; } }; function d3_geom_voronoiRedBlackTree() { this._ = null; } function d3_geom_voronoiRedBlackNode(node) { node.U = node.C = node.L = node.R = node.P = node.N = null; } d3_geom_voronoiRedBlackTree.prototype = { insert: function(after, node) { var parent, grandpa, uncle; if (after) { node.P = after; node.N = after.N; if (after.N) after.N.P = node; after.N = node; if (after.R) { after = after.R; while (after.L) after = after.L; after.L = node; } else { after.R = node; } parent = after; } else if (this._) { after = d3_geom_voronoiRedBlackFirst(this._); node.P = null; node.N = after; after.P = after.L = node; parent = after; } else { node.P = node.N = null; this._ = node; parent = null; } node.L = node.R = null; node.U = parent; node.C = true; after = node; while (parent && parent.C) { grandpa = parent.U; if (parent === grandpa.L) { uncle = grandpa.R; if (uncle && uncle.C) { parent.C = uncle.C = false; grandpa.C = true; after = grandpa; } else { if (after === parent.R) { d3_geom_voronoiRedBlackRotateLeft(this, parent); after = parent; parent = after.U; } parent.C = false; grandpa.C = true; d3_geom_voronoiRedBlackRotateRight(this, grandpa); } } else { uncle = grandpa.L; if (uncle && uncle.C) { parent.C = uncle.C = false; grandpa.C = true; after = grandpa; } else { if (after === parent.L) { d3_geom_voronoiRedBlackRotateRight(this, parent); after = parent; parent = after.U; } parent.C = false; grandpa.C = true; d3_geom_voronoiRedBlackRotateLeft(this, grandpa); } } parent = after.U; } this._.C = false; }, remove: function(node) { if (node.N) node.N.P = node.P; if (node.P) node.P.N = node.N; node.N = node.P = null; var parent = node.U, sibling, left = node.L, right = node.R, next, red; if (!left) next = right; else if (!right) next = left; else next = d3_geom_voronoiRedBlackFirst(right); if (parent) { if (parent.L === node) parent.L = next; else parent.R = next; } else { this._ = next; } if (left && right) { red = next.C; next.C = node.C; next.L = left; left.U = next; if (next !== right) { parent = next.U; next.U = node.U; node = next.R; parent.L = node; next.R = right; right.U = next; } else { next.U = parent; parent = next; node = next.R; } } else { red = node.C; node = next; } if (node) node.U = parent; if (red) return; if (node && node.C) { node.C = false; return; } do { if (node === this._) break; if (node === parent.L) { sibling = parent.R; if (sibling.C) { sibling.C = false; parent.C = true; d3_geom_voronoiRedBlackRotateLeft(this, parent); sibling = parent.R; } if (sibling.L && sibling.L.C || sibling.R && sibling.R.C) { if (!sibling.R || !sibling.R.C) { sibling.L.C = false; sibling.C = true; d3_geom_voronoiRedBlackRotateRight(this, sibling); sibling = parent.R; } sibling.C = parent.C; parent.C = sibling.R.C = false; d3_geom_voronoiRedBlackRotateLeft(this, parent); node = this._; break; } } else { sibling = parent.L; if (sibling.C) { sibling.C = false; parent.C = true; d3_geom_voronoiRedBlackRotateRight(this, parent); sibling = parent.L; } if (sibling.L && sibling.L.C || sibling.R && sibling.R.C) { if (!sibling.L || !sibling.L.C) { sibling.R.C = false; sibling.C = true; d3_geom_voronoiRedBlackRotateLeft(this, sibling); sibling = parent.L; } sibling.C = parent.C; parent.C = sibling.L.C = false; d3_geom_voronoiRedBlackRotateRight(this, parent); node = this._; break; } } sibling.C = true; node = parent; parent = parent.U; } while (!node.C); if (node) node.C = false; } }; function d3_geom_voronoiRedBlackRotateLeft(tree, node) { var p = node, q = node.R, parent = p.U; if (parent) { if (parent.L === p) parent.L = q; else parent.R = q; } else { tree._ = q; } q.U = parent; p.U = q; p.R = q.L; if (p.R) p.R.U = p; q.L = p; } function d3_geom_voronoiRedBlackRotateRight(tree, node) { var p = node, q = node.L, parent = p.U; if (parent) { if (parent.L === p) parent.L = q; else parent.R = q; } else { tree._ = q; } q.U = parent; p.U = q; p.L = q.R; if (p.L) p.L.U = p; q.R = p; } function d3_geom_voronoiRedBlackFirst(node) { while (node.L) node = node.L; return node; } function d3_geom_voronoi(sites, bbox) { var site = sites.sort(d3_geom_voronoiVertexOrder).pop(), x0, y0, circle; d3_geom_voronoiEdges = []; d3_geom_voronoiCells = new Array(sites.length); d3_geom_voronoiBeaches = new d3_geom_voronoiRedBlackTree(); d3_geom_voronoiCircles = new d3_geom_voronoiRedBlackTree(); while (true) { circle = d3_geom_voronoiFirstCircle; if (site && (!circle || site.y < circle.y || site.y === circle.y && site.x < circle.x)) { if (site.x !== x0 || site.y !== y0) { d3_geom_voronoiCells[site.i] = new d3_geom_voronoiCell(site); d3_geom_voronoiAddBeach(site); x0 = site.x, y0 = site.y; } site = sites.pop(); } else if (circle) { d3_geom_voronoiRemoveBeach(circle.arc); } else { break; } } if (bbox) d3_geom_voronoiClipEdges(bbox), d3_geom_voronoiCloseCells(bbox); var diagram = { cells: d3_geom_voronoiCells, edges: d3_geom_voronoiEdges }; d3_geom_voronoiBeaches = d3_geom_voronoiCircles = d3_geom_voronoiEdges = d3_geom_voronoiCells = null; return diagram; } function d3_geom_voronoiVertexOrder(a, b) { return b.y - a.y || b.x - a.x; } d3.geom.voronoi = function(points) { var x = d3_geom_pointX, y = d3_geom_pointY, fx = x, fy = y, clipExtent = d3_geom_voronoiClipExtent; if (points) return voronoi(points); function voronoi(data) { var polygons = new Array(data.length), x0 = clipExtent[0][0], y0 = clipExtent[0][1], x1 = clipExtent[1][0], y1 = clipExtent[1][1]; d3_geom_voronoi(sites(data), clipExtent).cells.forEach(function(cell, i) { var edges = cell.edges, site = cell.site, polygon = polygons[i] = edges.length ? edges.map(function(e) { var s = e.start(); return [ s.x, s.y ]; }) : site.x >= x0 && site.x <= x1 && site.y >= y0 && site.y <= y1 ? [ [ x0, y1 ], [ x1, y1 ], [ x1, y0 ], [ x0, y0 ] ] : []; polygon.point = data[i]; }); return polygons; } function sites(data) { return data.map(function(d, i) { return { x: Math.round(fx(d, i) / ε) * ε, y: Math.round(fy(d, i) / ε) * ε, i: i }; }); } voronoi.links = function(data) { return d3_geom_voronoi(sites(data)).edges.filter(function(edge) { return edge.l && edge.r; }).map(function(edge) { return { source: data[edge.l.i], target: data[edge.r.i] }; }); }; voronoi.triangles = function(data) { var triangles = []; d3_geom_voronoi(sites(data)).cells.forEach(function(cell, i) { var site = cell.site, edges = cell.edges.sort(d3_geom_voronoiHalfEdgeOrder), j = -1, m = edges.length, e0, s0, e1 = edges[m - 1].edge, s1 = e1.l === site ? e1.r : e1.l; while (++j < m) { e0 = e1; s0 = s1; e1 = edges[j].edge; s1 = e1.l === site ? e1.r : e1.l; if (i < s0.i && i < s1.i && d3_geom_voronoiTriangleArea(site, s0, s1) < 0) { triangles.push([ data[i], data[s0.i], data[s1.i] ]); } } }); return triangles; }; voronoi.x = function(_) { return arguments.length ? (fx = d3_functor(x = _), voronoi) : x; }; voronoi.y = function(_) { return arguments.length ? (fy = d3_functor(y = _), voronoi) : y; }; voronoi.clipExtent = function(_) { if (!arguments.length) return clipExtent === d3_geom_voronoiClipExtent ? null : clipExtent; clipExtent = _ == null ? d3_geom_voronoiClipExtent : _; return voronoi; }; voronoi.size = function(_) { if (!arguments.length) return clipExtent === d3_geom_voronoiClipExtent ? null : clipExtent && clipExtent[1]; return voronoi.clipExtent(_ && [ [ 0, 0 ], _ ]); }; return voronoi; }; var d3_geom_voronoiClipExtent = [ [ -1e6, -1e6 ], [ 1e6, 1e6 ] ]; function d3_geom_voronoiTriangleArea(a, b, c) { return (a.x - c.x) * (b.y - a.y) - (a.x - b.x) * (c.y - a.y); } d3.geom.delaunay = function(vertices) { return d3.geom.voronoi().triangles(vertices); }; d3.geom.quadtree = function(points, x1, y1, x2, y2) { var x = d3_geom_pointX, y = d3_geom_pointY, compat; if (compat = arguments.length) { x = d3_geom_quadtreeCompatX; y = d3_geom_quadtreeCompatY; if (compat === 3) { y2 = y1; x2 = x1; y1 = x1 = 0; } return quadtree(points); } function quadtree(data) { var d, fx = d3_functor(x), fy = d3_functor(y), xs, ys, i, n, x1_, y1_, x2_, y2_; if (x1 != null) { x1_ = x1, y1_ = y1, x2_ = x2, y2_ = y2; } else { x2_ = y2_ = -(x1_ = y1_ = Infinity); xs = [], ys = []; n = data.length; if (compat) for (i = 0; i < n; ++i) { d = data[i]; if (d.x < x1_) x1_ = d.x; if (d.y < y1_) y1_ = d.y; if (d.x > x2_) x2_ = d.x; if (d.y > y2_) y2_ = d.y; xs.push(d.x); ys.push(d.y); } else for (i = 0; i < n; ++i) { var x_ = +fx(d = data[i], i), y_ = +fy(d, i); if (x_ < x1_) x1_ = x_; if (y_ < y1_) y1_ = y_; if (x_ > x2_) x2_ = x_; if (y_ > y2_) y2_ = y_; xs.push(x_); ys.push(y_); } } var dx = x2_ - x1_, dy = y2_ - y1_; if (dx > dy) y2_ = y1_ + dx; else x2_ = x1_ + dy; function insert(n, d, x, y, x1, y1, x2, y2) { if (isNaN(x) || isNaN(y)) return; if (n.leaf) { var nx = n.x, ny = n.y; if (nx != null) { if (abs(nx - x) + abs(ny - y) < .01) { insertChild(n, d, x, y, x1, y1, x2, y2); } else { var nPoint = n.point; n.x = n.y = n.point = null; insertChild(n, nPoint, nx, ny, x1, y1, x2, y2); insertChild(n, d, x, y, x1, y1, x2, y2); } } else { n.x = x, n.y = y, n.point = d; } } else { insertChild(n, d, x, y, x1, y1, x2, y2); } } function insertChild(n, d, x, y, x1, y1, x2, y2) { var sx = (x1 + x2) * .5, sy = (y1 + y2) * .5, right = x >= sx, bottom = y >= sy, i = (bottom << 1) + right; n.leaf = false; n = n.nodes[i] || (n.nodes[i] = d3_geom_quadtreeNode()); if (right) x1 = sx; else x2 = sx; if (bottom) y1 = sy; else y2 = sy; insert(n, d, x, y, x1, y1, x2, y2); } var root = d3_geom_quadtreeNode(); root.add = function(d) { insert(root, d, +fx(d, ++i), +fy(d, i), x1_, y1_, x2_, y2_); }; root.visit = function(f) { d3_geom_quadtreeVisit(f, root, x1_, y1_, x2_, y2_); }; i = -1; if (x1 == null) { while (++i < n) { insert(root, data[i], xs[i], ys[i], x1_, y1_, x2_, y2_); } --i; } else data.forEach(root.add); xs = ys = data = d = null; return root; } quadtree.x = function(_) { return arguments.length ? (x = _, quadtree) : x; }; quadtree.y = function(_) { return arguments.length ? (y = _, quadtree) : y; }; quadtree.extent = function(_) { if (!arguments.length) return x1 == null ? null : [ [ x1, y1 ], [ x2, y2 ] ]; if (_ == null) x1 = y1 = x2 = y2 = null; else x1 = +_[0][0], y1 = +_[0][1], x2 = +_[1][0], y2 = +_[1][1]; return quadtree; }; quadtree.size = function(_) { if (!arguments.length) return x1 == null ? null : [ x2 - x1, y2 - y1 ]; if (_ == null) x1 = y1 = x2 = y2 = null; else x1 = y1 = 0, x2 = +_[0], y2 = +_[1]; return quadtree; }; return quadtree; }; function d3_geom_quadtreeCompatX(d) { return d.x; } function d3_geom_quadtreeCompatY(d) { return d.y; } function d3_geom_quadtreeNode() { return { leaf: true, nodes: [], point: null, x: null, y: null }; } function d3_geom_quadtreeVisit(f, node, x1, y1, x2, y2) { if (!f(node, x1, y1, x2, y2)) { var sx = (x1 + x2) * .5, sy = (y1 + y2) * .5, children = node.nodes; if (children[0]) d3_geom_quadtreeVisit(f, children[0], x1, y1, sx, sy); if (children[1]) d3_geom_quadtreeVisit(f, children[1], sx, y1, x2, sy); if (children[2]) d3_geom_quadtreeVisit(f, children[2], x1, sy, sx, y2); if (children[3]) d3_geom_quadtreeVisit(f, children[3], sx, sy, x2, y2); } } d3.interpolateRgb = d3_interpolateRgb; function d3_interpolateRgb(a, b) { a = d3.rgb(a); b = d3.rgb(b); var ar = a.r, ag = a.g, ab = a.b, br = b.r - ar, bg = b.g - ag, bb = b.b - ab; return function(t) { return ""#"" + d3_rgb_hex(Math.round(ar + br * t)) + d3_rgb_hex(Math.round(ag + bg * t)) + d3_rgb_hex(Math.round(ab + bb * t)); }; } d3.interpolateObject = d3_interpolateObject; function d3_interpolateObject(a, b) { var i = {}, c = {}, k; for (k in a) { if (k in b) { i[k] = d3_interpolate(a[k], b[k]); } else { c[k] = a[k]; } } for (k in b) { if (!(k in a)) { c[k] = b[k]; } } return function(t) { for (k in i) c[k] = i[k](t); return c; }; } d3.interpolateNumber = d3_interpolateNumber; function d3_interpolateNumber(a, b) { b -= a = +a; return function(t) { return a + b * t; }; } d3.interpolateString = d3_interpolateString; function d3_interpolateString(a, b) { var m, i, j, s0 = 0, s1 = 0, s = [], q = [], n, o; a = a + """", b = b + """"; d3_interpolate_number.lastIndex = 0; for (i = 0; m = d3_interpolate_number.exec(b); ++i) { if (m.index) s.push(b.substring(s0, s1 = m.index)); q.push({ i: s.length, x: m[0] }); s.push(null); s0 = d3_interpolate_number.lastIndex; } if (s0 < b.length) s.push(b.substring(s0)); for (i = 0, n = q.length; (m = d3_interpolate_number.exec(a)) && i < n; ++i) { o = q[i]; if (o.x == m[0]) { if (o.i) { if (s[o.i + 1] == null) { s[o.i - 1] += o.x; s.splice(o.i, 1); for (j = i + 1; j < n; ++j) q[j].i--; } else { s[o.i - 1] += o.x + s[o.i + 1]; s.splice(o.i, 2); for (j = i + 1; j < n; ++j) q[j].i -= 2; } } else { if (s[o.i + 1] == null) { s[o.i] = o.x; } else { s[o.i] = o.x + s[o.i + 1]; s.splice(o.i + 1, 1); for (j = i + 1; j < n; ++j) q[j].i--; } } q.splice(i, 1); n--; i--; } else { o.x = d3_interpolateNumber(parseFloat(m[0]), parseFloat(o.x)); } } while (i < n) { o = q.pop(); if (s[o.i + 1] == null) { s[o.i] = o.x; } else { s[o.i] = o.x + s[o.i + 1]; s.splice(o.i + 1, 1); } n--; } if (s.length === 1) { return s[0] == null ? (o = q[0].x, function(t) { return o(t) + """"; }) : function() { return b; }; } return function(t) { for (i = 0; i < n; ++i) s[(o = q[i]).i] = o.x(t); return s.join(""""); }; } var d3_interpolate_number = /[-+]?(?:\d+\.?\d*|\.?\d+)(?:[eE][-+]?\d+)?/g; d3.interpolate = d3_interpolate; function d3_interpolate(a, b) { var i = d3.interpolators.length, f; while (--i >= 0 && !(f = d3.interpolators[i](a, b))) ; return f; } d3.interpolators = [ function(a, b) { var t = typeof b; return (t === ""string"" ? d3_rgb_names.has(b) || /^(#|rgb\(|hsl\()/.test(b) ? d3_interpolateRgb : d3_interpolateString : b instanceof d3_Color ? d3_interpolateRgb : Array.isArray(b) ? d3_interpolateArray : t === ""object"" && isNaN(b) ? d3_interpolateObject : d3_interpolateNumber)(a, b); } ]; d3.interpolateArray = d3_interpolateArray; function d3_interpolateArray(a, b) { var x = [], c = [], na = a.length, nb = b.length, n0 = Math.min(a.length, b.length), i; for (i = 0; i < n0; ++i) x.push(d3_interpolate(a[i], b[i])); for (;i < na; ++i) c[i] = a[i]; for (;i < nb; ++i) c[i] = b[i]; return function(t) { for (i = 0; i < n0; ++i) c[i] = x[i](t); return c; }; } var d3_ease_default = function() { return d3_identity; }; var d3_ease = d3.map({ linear: d3_ease_default, poly: d3_ease_poly, quad: function() { return d3_ease_quad; }, cubic: function() { return d3_ease_cubic; }, sin: function() { return d3_ease_sin; }, exp: function() { return d3_ease_exp; }, circle: function() { return d3_ease_circle; }, elastic: d3_ease_elastic, back: d3_ease_back, bounce: function() { return d3_ease_bounce; } }); var d3_ease_mode = d3.map({ ""in"": d3_identity, out: d3_ease_reverse, ""in-out"": d3_ease_reflect, ""out-in"": function(f) { return d3_ease_reflect(d3_ease_reverse(f)); } }); d3.ease = function(name) { var i = name.indexOf(""-""), t = i >= 0 ? name.substring(0, i) : name, m = i >= 0 ? name.substring(i + 1) : ""in""; t = d3_ease.get(t) || d3_ease_default; m = d3_ease_mode.get(m) || d3_identity; return d3_ease_clamp(m(t.apply(null, d3_arraySlice.call(arguments, 1)))); }; function d3_ease_clamp(f) { return function(t) { return t <= 0 ? 0 : t >= 1 ? 1 : f(t); }; } function d3_ease_reverse(f) { return function(t) { return 1 - f(1 - t); }; } function d3_ease_reflect(f) { return function(t) { return .5 * (t < .5 ? f(2 * t) : 2 - f(2 - 2 * t)); }; } function d3_ease_quad(t) { return t * t; } function d3_ease_cubic(t) { return t * t * t; } function d3_ease_cubicInOut(t) { if (t <= 0) return 0; if (t >= 1) return 1; var t2 = t * t, t3 = t2 * t; return 4 * (t < .5 ? t3 : 3 * (t - t2) + t3 - .75); } function d3_ease_poly(e) { return function(t) { return Math.pow(t, e); }; } function d3_ease_sin(t) { return 1 - Math.cos(t * halfπ); } function d3_ease_exp(t) { return Math.pow(2, 10 * (t - 1)); } function d3_ease_circle(t) { return 1 - Math.sqrt(1 - t * t); } function d3_ease_elastic(a, p) { var s; if (arguments.length < 2) p = .45; if (arguments.length) s = p / τ * Math.asin(1 / a); else a = 1, s = p / 4; return function(t) { return 1 + a * Math.pow(2, -10 * t) * Math.sin((t - s) * τ / p); }; } function d3_ease_back(s) { if (!s) s = 1.70158; return function(t) { return t * t * ((s + 1) * t - s); }; } function d3_ease_bounce(t) { return t < 1 / 2.75 ? 7.5625 * t * t : t < 2 / 2.75 ? 7.5625 * (t -= 1.5 / 2.75) * t + .75 : t < 2.5 / 2.75 ? 7.5625 * (t -= 2.25 / 2.75) * t + .9375 : 7.5625 * (t -= 2.625 / 2.75) * t + .984375; } d3.interpolateHcl = d3_interpolateHcl; function d3_interpolateHcl(a, b) { a = d3.hcl(a); b = d3.hcl(b); var ah = a.h, ac = a.c, al = a.l, bh = b.h - ah, bc = b.c - ac, bl = b.l - al; if (isNaN(bc)) bc = 0, ac = isNaN(ac) ? b.c : ac; if (isNaN(bh)) bh = 0, ah = isNaN(ah) ? b.h : ah; else if (bh > 180) bh -= 360; else if (bh < -180) bh += 360; return function(t) { return d3_hcl_lab(ah + bh * t, ac + bc * t, al + bl * t) + """"; }; } d3.interpolateHsl = d3_interpolateHsl; function d3_interpolateHsl(a, b) { a = d3.hsl(a); b = d3.hsl(b); var ah = a.h, as = a.s, al = a.l, bh = b.h - ah, bs = b.s - as, bl = b.l - al; if (isNaN(bs)) bs = 0, as = isNaN(as) ? b.s : as; if (isNaN(bh)) bh = 0, ah = isNaN(ah) ? b.h : ah; else if (bh > 180) bh -= 360; else if (bh < -180) bh += 360; return function(t) { return d3_hsl_rgb(ah + bh * t, as + bs * t, al + bl * t) + """"; }; } d3.interpolateLab = d3_interpolateLab; function d3_interpolateLab(a, b) { a = d3.lab(a); b = d3.lab(b); var al = a.l, aa = a.a, ab = a.b, bl = b.l - al, ba = b.a - aa, bb = b.b - ab; return function(t) { return d3_lab_rgb(al + bl * t, aa + ba * t, ab + bb * t) + """"; }; } d3.interpolateRound = d3_interpolateRound; function d3_interpolateRound(a, b) { b -= a; return function(t) { return Math.round(a + b * t); }; } d3.transform = function(string) { var g = d3_document.createElementNS(d3.ns.prefix.svg, ""g""); return (d3.transform = function(string) { if (string != null) { g.setAttribute(""transform"", string); var t = g.transform.baseVal.consolidate(); } return new d3_transform(t ? t.matrix : d3_transformIdentity); })(string); }; function d3_transform(m) { var r0 = [ m.a, m.b ], r1 = [ m.c, m.d ], kx = d3_transformNormalize(r0), kz = d3_transformDot(r0, r1), ky = d3_transformNormalize(d3_transformCombine(r1, r0, -kz)) || 0; if (r0[0] * r1[1] < r1[0] * r0[1]) { r0[0] *= -1; r0[1] *= -1; kx *= -1; kz *= -1; } this.rotate = (kx ? Math.atan2(r0[1], r0[0]) : Math.atan2(-r1[0], r1[1])) * d3_degrees; this.translate = [ m.e, m.f ]; this.scale = [ kx, ky ]; this.skew = ky ? Math.atan2(kz, ky) * d3_degrees : 0; } d3_transform.prototype.toString = function() { return ""translate("" + this.translate + "")rotate("" + this.rotate + "")skewX("" + this.skew + "")scale("" + this.scale + "")""; }; function d3_transformDot(a, b) { return a[0] * b[0] + a[1] * b[1]; } function d3_transformNormalize(a) { var k = Math.sqrt(d3_transformDot(a, a)); if (k) { a[0] /= k; a[1] /= k; } return k; } function d3_transformCombine(a, b, k) { a[0] += k * b[0]; a[1] += k * b[1]; return a; } var d3_transformIdentity = { a: 1, b: 0, c: 0, d: 1, e: 0, f: 0 }; d3.interpolateTransform = d3_interpolateTransform; function d3_interpolateTransform(a, b) { var s = [], q = [], n, A = d3.transform(a), B = d3.transform(b), ta = A.translate, tb = B.translate, ra = A.rotate, rb = B.rotate, wa = A.skew, wb = B.skew, ka = A.scale, kb = B.scale; if (ta[0] != tb[0] || ta[1] != tb[1]) { s.push(""translate("", null, "","", null, "")""); q.push({ i: 1, x: d3_interpolateNumber(ta[0], tb[0]) }, { i: 3, x: d3_interpolateNumber(ta[1], tb[1]) }); } else if (tb[0] || tb[1]) { s.push(""translate("" + tb + "")""); } else { s.push(""""); } if (ra != rb) { if (ra - rb > 180) rb += 360; else if (rb - ra > 180) ra += 360; q.push({ i: s.push(s.pop() + ""rotate("", null, "")"") - 2, x: d3_interpolateNumber(ra, rb) }); } else if (rb) { s.push(s.pop() + ""rotate("" + rb + "")""); } if (wa != wb) { q.push({ i: s.push(s.pop() + ""skewX("", null, "")"") - 2, x: d3_interpolateNumber(wa, wb) }); } else if (wb) { s.push(s.pop() + ""skewX("" + wb + "")""); } if (ka[0] != kb[0] || ka[1] != kb[1]) { n = s.push(s.pop() + ""scale("", null, "","", null, "")""); q.push({ i: n - 4, x: d3_interpolateNumber(ka[0], kb[0]) }, { i: n - 2, x: d3_interpolateNumber(ka[1], kb[1]) }); } else if (kb[0] != 1 || kb[1] != 1) { s.push(s.pop() + ""scale("" + kb + "")""); } n = q.length; return function(t) { var i = -1, o; while (++i < n) s[(o = q[i]).i] = o.x(t); return s.join(""""); }; } function d3_uninterpolateNumber(a, b) { b = b - (a = +a) ? 1 / (b - a) : 0; return function(x) { return (x - a) * b; }; } function d3_uninterpolateClamp(a, b) { b = b - (a = +a) ? 1 / (b - a) : 0; return function(x) { return Math.max(0, Math.min(1, (x - a) * b)); }; } d3.layout = {}; d3.layout.bundle = function() { return function(links) { var paths = [], i = -1, n = links.length; while (++i < n) paths.push(d3_layout_bundlePath(links[i])); return paths; }; }; function d3_layout_bundlePath(link) { var start = link.source, end = link.target, lca = d3_layout_bundleLeastCommonAncestor(start, end), points = [ start ]; while (start !== lca) { start = start.parent; points.push(start); } var k = points.length; while (end !== lca) { points.splice(k, 0, end); end = end.parent; } return points; } function d3_layout_bundleAncestors(node) { var ancestors = [], parent = node.parent; while (parent != null) { ancestors.push(node); node = parent; parent = parent.parent; } ancestors.push(node); return ancestors; } function d3_layout_bundleLeastCommonAncestor(a, b) { if (a === b) return a; var aNodes = d3_layout_bundleAncestors(a), bNodes = d3_layout_bundleAncestors(b), aNode = aNodes.pop(), bNode = bNodes.pop(), sharedNode = null; while (aNode === bNode) { sharedNode = aNode; aNode = aNodes.pop(); bNode = bNodes.pop(); } return sharedNode; } d3.layout.chord = function() { var chord = {}, chords, groups, matrix, n, padding = 0, sortGroups, sortSubgroups, sortChords; function relayout() { var subgroups = {}, groupSums = [], groupIndex = d3.range(n), subgroupIndex = [], k, x, x0, i, j; chords = []; groups = []; k = 0, i = -1; while (++i < n) { x = 0, j = -1; while (++j < n) { x += matrix[i][j]; } groupSums.push(x); subgroupIndex.push(d3.range(n)); k += x; } if (sortGroups) { groupIndex.sort(function(a, b) { return sortGroups(groupSums[a], groupSums[b]); }); } if (sortSubgroups) { subgroupIndex.forEach(function(d, i) { d.sort(function(a, b) { return sortSubgroups(matrix[i][a], matrix[i][b]); }); }); } k = (τ - padding * n) / k; x = 0, i = -1; while (++i < n) { x0 = x, j = -1; while (++j < n) { var di = groupIndex[i], dj = subgroupIndex[di][j], v = matrix[di][dj], a0 = x, a1 = x += v * k; subgroups[di + ""-"" + dj] = { index: di, subindex: dj, startAngle: a0, endAngle: a1, value: v }; } groups[di] = { index: di, startAngle: x0, endAngle: x, value: (x - x0) / k }; x += padding; } i = -1; while (++i < n) { j = i - 1; while (++j < n) { var source = subgroups[i + ""-"" + j], target = subgroups[j + ""-"" + i]; if (source.value || target.value) { chords.push(source.value < target.value ? { source: target, target: source } : { source: source, target: target }); } } } if (sortChords) resort(); } function resort() { chords.sort(function(a, b) { return sortChords((a.source.value + a.target.value) / 2, (b.source.value + b.target.value) / 2); }); } chord.matrix = function(x) { if (!arguments.length) return matrix; n = (matrix = x) && matrix.length; chords = groups = null; return chord; }; chord.padding = function(x) { if (!arguments.length) return padding; padding = x; chords = groups = null; return chord; }; chord.sortGroups = function(x) { if (!arguments.length) return sortGroups; sortGroups = x; chords = groups = null; return chord; }; chord.sortSubgroups = function(x) { if (!arguments.length) return sortSubgroups; sortSubgroups = x; chords = null; return chord; }; chord.sortChords = function(x) { if (!arguments.length) return sortChords; sortChords = x; if (chords) resort(); return chord; }; chord.chords = function() { if (!chords) relayout(); return chords; }; chord.groups = function() { if (!groups) relayout(); return groups; }; return chord; }; d3.layout.force = function() { var force = {}, event = d3.dispatch(""start"", ""tick"", ""end""), size = [ 1, 1 ], drag, alpha, friction = .9, linkDistance = d3_layout_forceLinkDistance, linkStrength = d3_layout_forceLinkStrength, charge = -30, chargeDistance2 = d3_layout_forceChargeDistance2, gravity = .1, theta2 = .64, nodes = [], links = [], distances, strengths, charges; function repulse(node) { return function(quad, x1, _, x2) { if (quad.point !== node) { var dx = quad.cx - node.x, dy = quad.cy - node.y, dw = x2 - x1, dn = dx * dx + dy * dy; if (dw * dw / theta2 < dn) { if (dn < chargeDistance2) { var k = quad.charge / dn; node.px -= dx * k; node.py -= dy * k; } return true; } if (quad.point && dn && dn < chargeDistance2) { var k = quad.pointCharge / dn; node.px -= dx * k; node.py -= dy * k; } } return !quad.charge; }; } force.tick = function() { if ((alpha *= .99) < .005) { event.end({ type: ""end"", alpha: alpha = 0 }); return true; } var n = nodes.length, m = links.length, q, i, o, s, t, l, k, x, y; for (i = 0; i < m; ++i) { o = links[i]; s = o.source; t = o.target; x = t.x - s.x; y = t.y - s.y; if (l = x * x + y * y) { l = alpha * strengths[i] * ((l = Math.sqrt(l)) - distances[i]) / l; x *= l; y *= l; t.x -= x * (k = s.weight / (t.weight + s.weight)); t.y -= y * k; s.x += x * (k = 1 - k); s.y += y * k; } } if (k = alpha * gravity) { x = size[0] / 2; y = size[1] / 2; i = -1; if (k) while (++i < n) { o = nodes[i]; o.x += (x - o.x) * k; o.y += (y - o.y) * k; } } if (charge) { d3_layout_forceAccumulate(q = d3.geom.quadtree(nodes), alpha, charges); i = -1; while (++i < n) { if (!(o = nodes[i]).fixed) { q.visit(repulse(o)); } } } i = -1; while (++i < n) { o = nodes[i]; if (o.fixed) { o.x = o.px; o.y = o.py; } else { o.x -= (o.px - (o.px = o.x)) * friction; o.y -= (o.py - (o.py = o.y)) * friction; } } event.tick({ type: ""tick"", alpha: alpha }); }; force.nodes = function(x) { if (!arguments.length) return nodes; nodes = x; return force; }; force.links = function(x) { if (!arguments.length) return links; links = x; return force; }; force.size = function(x) { if (!arguments.length) return size; size = x; return force; }; force.linkDistance = function(x) { if (!arguments.length) return linkDistance; linkDistance = typeof x === ""function"" ? x : +x; return force; }; force.distance = force.linkDistance; force.linkStrength = function(x) { if (!arguments.length) return linkStrength; linkStrength = typeof x === ""function"" ? x : +x; return force; }; force.friction = function(x) { if (!arguments.length) return friction; friction = +x; return force; }; force.charge = function(x) { if (!arguments.length) return charge; charge = typeof x === ""function"" ? x : +x; return force; }; force.chargeDistance = function(x) { if (!arguments.length) return Math.sqrt(chargeDistance2); chargeDistance2 = x * x; return force; }; force.gravity = function(x) { if (!arguments.length) return gravity; gravity = +x; return force; }; force.theta = function(x) { if (!arguments.length) return Math.sqrt(theta2); theta2 = x * x; return force; }; force.alpha = function(x) { if (!arguments.length) return alpha; x = +x; if (alpha) { if (x > 0) alpha = x; else alpha = 0; } else if (x > 0) { event.start({ type: ""start"", alpha: alpha = x }); d3.timer(force.tick); } return force; }; force.start = function() { var i, n = nodes.length, m = links.length, w = size[0], h = size[1], neighbors, o; for (i = 0; i < n; ++i) { (o = nodes[i]).index = i; o.weight = 0; } for (i = 0; i < m; ++i) { o = links[i]; if (typeof o.source == ""number"") o.source = nodes[o.source]; if (typeof o.target == ""number"") o.target = nodes[o.target]; ++o.source.weight; ++o.target.weight; } for (i = 0; i < n; ++i) { o = nodes[i]; if (isNaN(o.x)) o.x = position(""x"", w); if (isNaN(o.y)) o.y = position(""y"", h); if (isNaN(o.px)) o.px = o.x; if (isNaN(o.py)) o.py = o.y; } distances = []; if (typeof linkDistance === ""function"") for (i = 0; i < m; ++i) distances[i] = +linkDistance.call(this, links[i], i); else for (i = 0; i < m; ++i) distances[i] = linkDistance; strengths = []; if (typeof linkStrength === ""function"") for (i = 0; i < m; ++i) strengths[i] = +linkStrength.call(this, links[i], i); else for (i = 0; i < m; ++i) strengths[i] = linkStrength; charges = []; if (typeof charge === ""function"") for (i = 0; i < n; ++i) charges[i] = +charge.call(this, nodes[i], i); else for (i = 0; i < n; ++i) charges[i] = charge; function position(dimension, size) { if (!neighbors) { neighbors = new Array(n); for (j = 0; j < n; ++j) { neighbors[j] = []; } for (j = 0; j < m; ++j) { var o = links[j]; neighbors[o.source.index].push(o.target); neighbors[o.target.index].push(o.source); } } var candidates = neighbors[i], j = -1, m = candidates.length, x; while (++j < m) if (!isNaN(x = candidates[j][dimension])) return x; return Math.random() * size; } return force.resume(); }; force.resume = function() { return force.alpha(.1); }; force.stop = function() { return force.alpha(0); }; force.drag = function() { if (!drag) drag = d3.behavior.drag().origin(d3_identity).on(""dragstart.force"", d3_layout_forceDragstart).on(""drag.force"", dragmove).on(""dragend.force"", d3_layout_forceDragend); if (!arguments.length) return drag; this.on(""mouseover.force"", d3_layout_forceMouseover).on(""mouseout.force"", d3_layout_forceMouseout).call(drag); }; function dragmove(d) { d.px = d3.event.x, d.py = d3.event.y; force.resume(); } return d3.rebind(force, event, ""on""); }; function d3_layout_forceDragstart(d) { d.fixed |= 2; } function d3_layout_forceDragend(d) { d.fixed &= ~6; } function d3_layout_forceMouseover(d) { d.fixed |= 4; d.px = d.x, d.py = d.y; } function d3_layout_forceMouseout(d) { d.fixed &= ~4; } function d3_layout_forceAccumulate(quad, alpha, charges) { var cx = 0, cy = 0; quad.charge = 0; if (!quad.leaf) { var nodes = quad.nodes, n = nodes.length, i = -1, c; while (++i < n) { c = nodes[i]; if (c == null) continue; d3_layout_forceAccumulate(c, alpha, charges); quad.charge += c.charge; cx += c.charge * c.cx; cy += c.charge * c.cy; } } if (quad.point) { if (!quad.leaf) { quad.point.x += Math.random() - .5; quad.point.y += Math.random() - .5; } var k = alpha * charges[quad.point.index]; quad.charge += quad.pointCharge = k; cx += k * quad.point.x; cy += k * quad.point.y; } quad.cx = cx / quad.charge; quad.cy = cy / quad.charge; } var d3_layout_forceLinkDistance = 20, d3_layout_forceLinkStrength = 1, d3_layout_forceChargeDistance2 = Infinity; d3.layout.hierarchy = function() { var sort = d3_layout_hierarchySort, children = d3_layout_hierarchyChildren, value = d3_layout_hierarchyValue; function recurse(node, depth, nodes) { var childs = children.call(hierarchy, node, depth); node.depth = depth; nodes.push(node); if (childs && (n = childs.length)) { var i = -1, n, c = node.children = new Array(n), v = 0, j = depth + 1, d; while (++i < n) { d = c[i] = recurse(childs[i], j, nodes); d.parent = node; v += d.value; } if (sort) c.sort(sort); if (value) node.value = v; } else { delete node.children; if (value) { node.value = +value.call(hierarchy, node, depth) || 0; } } return node; } function revalue(node, depth) { var children = node.children, v = 0; if (children && (n = children.length)) { var i = -1, n, j = depth + 1; while (++i < n) v += revalue(children[i], j); } else if (value) { v = +value.call(hierarchy, node, depth) || 0; } if (value) node.value = v; return v; } function hierarchy(d) { var nodes = []; recurse(d, 0, nodes); return nodes; } hierarchy.sort = function(x) { if (!arguments.length) return sort; sort = x; return hierarchy; }; hierarchy.children = function(x) { if (!arguments.length) return children; children = x; return hierarchy; }; hierarchy.value = function(x) { if (!arguments.length) return value; value = x; return hierarchy; }; hierarchy.revalue = function(root) { revalue(root, 0); return root; }; return hierarchy; }; function d3_layout_hierarchyRebind(object, hierarchy) { d3.rebind(object, hierarchy, ""sort"", ""children"", ""value""); object.nodes = object; object.links = d3_layout_hierarchyLinks; return object; } function d3_layout_hierarchyChildren(d) { return d.children; } function d3_layout_hierarchyValue(d) { return d.value; } function d3_layout_hierarchySort(a, b) { return b.value - a.value; } function d3_layout_hierarchyLinks(nodes) { return d3.merge(nodes.map(function(parent) { return (parent.children || []).map(function(child) { return { source: parent, target: child }; }); })); } d3.layout.partition = function() { var hierarchy = d3.layout.hierarchy(), size = [ 1, 1 ]; function position(node, x, dx, dy) { var children = node.children; node.x = x; node.y = node.depth * dy; node.dx = dx; node.dy = dy; if (children && (n = children.length)) { var i = -1, n, c, d; dx = node.value ? dx / node.value : 0; while (++i < n) { position(c = children[i], x, d = c.value * dx, dy); x += d; } } } function depth(node) { var children = node.children, d = 0; if (children && (n = children.length)) { var i = -1, n; while (++i < n) d = Math.max(d, depth(children[i])); } return 1 + d; } function partition(d, i) { var nodes = hierarchy.call(this, d, i); position(nodes[0], 0, size[0], size[1] / depth(nodes[0])); return nodes; } partition.size = function(x) { if (!arguments.length) return size; size = x; return partition; }; return d3_layout_hierarchyRebind(partition, hierarchy); }; d3.layout.pie = function() { var value = Number, sort = d3_layout_pieSortByValue, startAngle = 0, endAngle = τ; function pie(data) { var values = data.map(function(d, i) { return +value.call(pie, d, i); }); var a = +(typeof startAngle === ""function"" ? startAngle.apply(this, arguments) : startAngle); var k = ((typeof endAngle === ""function"" ? endAngle.apply(this, arguments) : endAngle) - a) / d3.sum(values); var index = d3.range(data.length); if (sort != null) index.sort(sort === d3_layout_pieSortByValue ? function(i, j) { return values[j] - values[i]; } : function(i, j) { return sort(data[i], data[j]); }); var arcs = []; index.forEach(function(i) { var d; arcs[i] = { data: data[i], value: d = values[i], startAngle: a, endAngle: a += d * k }; }); return arcs; } pie.value = function(x) { if (!arguments.length) return value; value = x; return pie; }; pie.sort = function(x) { if (!arguments.length) return sort; sort = x; return pie; }; pie.startAngle = function(x) { if (!arguments.length) return startAngle; startAngle = x; return pie; }; pie.endAngle = function(x) { if (!arguments.length) return endAngle; endAngle = x; return pie; }; return pie; }; var d3_layout_pieSortByValue = {}; d3.layout.stack = function() { var values = d3_identity, order = d3_layout_stackOrderDefault, offset = d3_layout_stackOffsetZero, out = d3_layout_stackOut, x = d3_layout_stackX, y = d3_layout_stackY; function stack(data, index) { var series = data.map(function(d, i) { return values.call(stack, d, i); }); var points = series.map(function(d) { return d.map(function(v, i) { return [ x.call(stack, v, i), y.call(stack, v, i) ]; }); }); var orders = order.call(stack, points, index); series = d3.permute(series, orders); points = d3.permute(points, orders); var offsets = offset.call(stack, points, index); var n = series.length, m = series[0].length, i, j, o; for (j = 0; j < m; ++j) { out.call(stack, series[0][j], o = offsets[j], points[0][j][1]); for (i = 1; i < n; ++i) { out.call(stack, series[i][j], o += points[i - 1][j][1], points[i][j][1]); } } return data; } stack.values = function(x) { if (!arguments.length) return values; values = x; return stack; }; stack.order = function(x) { if (!arguments.length) return order; order = typeof x === ""function"" ? x : d3_layout_stackOrders.get(x) || d3_layout_stackOrderDefault; return stack; }; stack.offset = function(x) { if (!arguments.length) return offset; offset = typeof x === ""function"" ? x : d3_layout_stackOffsets.get(x) || d3_layout_stackOffsetZero; return stack; }; stack.x = function(z) { if (!arguments.length) return x; x = z; return stack; }; stack.y = function(z) { if (!arguments.length) return y; y = z; return stack; }; stack.out = function(z) { if (!arguments.length) return out; out = z; return stack; }; return stack; }; function d3_layout_stackX(d) { return d.x; } function d3_layout_stackY(d) { return d.y; } function d3_layout_stackOut(d, y0, y) { d.y0 = y0; d.y = y; } var d3_layout_stackOrders = d3.map({ ""inside-out"": function(data) { var n = data.length, i, j, max = data.map(d3_layout_stackMaxIndex), sums = data.map(d3_layout_stackReduceSum), index = d3.range(n).sort(function(a, b) { return max[a] - max[b]; }), top = 0, bottom = 0, tops = [], bottoms = []; for (i = 0; i < n; ++i) { j = index[i]; if (top < bottom) { top += sums[j]; tops.push(j); } else { bottom += sums[j]; bottoms.push(j); } } return bottoms.reverse().concat(tops); }, reverse: function(data) { return d3.range(data.length).reverse(); }, ""default"": d3_layout_stackOrderDefault }); var d3_layout_stackOffsets = d3.map({ silhouette: function(data) { var n = data.length, m = data[0].length, sums = [], max = 0, i, j, o, y0 = []; for (j = 0; j < m; ++j) { for (i = 0, o = 0; i < n; i++) o += data[i][j][1]; if (o > max) max = o; sums.push(o); } for (j = 0; j < m; ++j) { y0[j] = (max - sums[j]) / 2; } return y0; }, wiggle: function(data) { var n = data.length, x = data[0], m = x.length, i, j, k, s1, s2, s3, dx, o, o0, y0 = []; y0[0] = o = o0 = 0; for (j = 1; j < m; ++j) { for (i = 0, s1 = 0; i < n; ++i) s1 += data[i][j][1]; for (i = 0, s2 = 0, dx = x[j][0] - x[j - 1][0]; i < n; ++i) { for (k = 0, s3 = (data[i][j][1] - data[i][j - 1][1]) / (2 * dx); k < i; ++k) { s3 += (data[k][j][1] - data[k][j - 1][1]) / dx; } s2 += s3 * data[i][j][1]; } y0[j] = o -= s1 ? s2 / s1 * dx : 0; if (o < o0) o0 = o; } for (j = 0; j < m; ++j) y0[j] -= o0; return y0; }, expand: function(data) { var n = data.length, m = data[0].length, k = 1 / n, i, j, o, y0 = []; for (j = 0; j < m; ++j) { for (i = 0, o = 0; i < n; i++) o += data[i][j][1]; if (o) for (i = 0; i < n; i++) data[i][j][1] /= o; else for (i = 0; i < n; i++) data[i][j][1] = k; } for (j = 0; j < m; ++j) y0[j] = 0; return y0; }, zero: d3_layout_stackOffsetZero }); function d3_layout_stackOrderDefault(data) { return d3.range(data.length); } function d3_layout_stackOffsetZero(data) { var j = -1, m = data[0].length, y0 = []; while (++j < m) y0[j] = 0; return y0; } function d3_layout_stackMaxIndex(array) { var i = 1, j = 0, v = array[0][1], k, n = array.length; for (;i < n; ++i) { if ((k = array[i][1]) > v) { j = i; v = k; } } return j; } function d3_layout_stackReduceSum(d) { return d.reduce(d3_layout_stackSum, 0); } function d3_layout_stackSum(p, d) { return p + d[1]; } d3.layout.histogram = function() { var frequency = true, valuer = Number, ranger = d3_layout_histogramRange, binner = d3_layout_histogramBinSturges; function histogram(data, i) { var bins = [], values = data.map(valuer, this), range = ranger.call(this, values, i), thresholds = binner.call(this, range, values, i), bin, i = -1, n = values.length, m = thresholds.length - 1, k = frequency ? 1 : 1 / n, x; while (++i < m) { bin = bins[i] = []; bin.dx = thresholds[i + 1] - (bin.x = thresholds[i]); bin.y = 0; } if (m > 0) { i = -1; while (++i < n) { x = values[i]; if (x >= range[0] && x <= range[1]) { bin = bins[d3.bisect(thresholds, x, 1, m) - 1]; bin.y += k; bin.push(data[i]); } } } return bins; } histogram.value = function(x) { if (!arguments.length) return valuer; valuer = x; return histogram; }; histogram.range = function(x) { if (!arguments.length) return ranger; ranger = d3_functor(x); return histogram; }; histogram.bins = function(x) { if (!arguments.length) return binner; binner = typeof x === ""number"" ? function(range) { return d3_layout_histogramBinFixed(range, x); } : d3_functor(x); return histogram; }; histogram.frequency = function(x) { if (!arguments.length) return frequency; frequency = !!x; return histogram; }; return histogram; }; function d3_layout_histogramBinSturges(range, values) { return d3_layout_histogramBinFixed(range, Math.ceil(Math.log(values.length) / Math.LN2 + 1)); } function d3_layout_histogramBinFixed(range, n) { var x = -1, b = +range[0], m = (range[1] - b) / n, f = []; while (++x <= n) f[x] = m * x + b; return f; } function d3_layout_histogramRange(values) { return [ d3.min(values), d3.max(values) ]; } d3.layout.tree = function() { var hierarchy = d3.layout.hierarchy().sort(null).value(null), separation = d3_layout_treeSeparation, size = [ 1, 1 ], nodeSize = false; function tree(d, i) { var nodes = hierarchy.call(this, d, i), root = nodes[0]; function firstWalk(node, previousSibling) { var children = node.children, layout = node._tree; if (children && (n = children.length)) { var n, firstChild = children[0], previousChild, ancestor = firstChild, child, i = -1; while (++i < n) { child = children[i]; firstWalk(child, previousChild); ancestor = apportion(child, previousChild, ancestor); previousChild = child; } d3_layout_treeShift(node); var midpoint = .5 * (firstChild._tree.prelim + child._tree.prelim); if (previousSibling) { layout.prelim = previousSibling._tree.prelim + separation(node, previousSibling); layout.mod = layout.prelim - midpoint; } else { layout.prelim = midpoint; } } else { if (previousSibling) { layout.prelim = previousSibling._tree.prelim + separation(node, previousSibling); } } } function secondWalk(node, x) { node.x = node._tree.prelim + x; var children = node.children; if (children && (n = children.length)) { var i = -1, n; x += node._tree.mod; while (++i < n) { secondWalk(children[i], x); } } } function apportion(node, previousSibling, ancestor) { if (previousSibling) { var vip = node, vop = node, vim = previousSibling, vom = node.parent.children[0], sip = vip._tree.mod, sop = vop._tree.mod, sim = vim._tree.mod, som = vom._tree.mod, shift; while (vim = d3_layout_treeRight(vim), vip = d3_layout_treeLeft(vip), vim && vip) { vom = d3_layout_treeLeft(vom); vop = d3_layout_treeRight(vop); vop._tree.ancestor = node; shift = vim._tree.prelim + sim - vip._tree.prelim - sip + separation(vim, vip); if (shift > 0) { d3_layout_treeMove(d3_layout_treeAncestor(vim, node, ancestor), node, shift); sip += shift; sop += shift; } sim += vim._tree.mod; sip += vip._tree.mod; som += vom._tree.mod; sop += vop._tree.mod; } if (vim && !d3_layout_treeRight(vop)) { vop._tree.thread = vim; vop._tree.mod += sim - sop; } if (vip && !d3_layout_treeLeft(vom)) { vom._tree.thread = vip; vom._tree.mod += sip - som; ancestor = node; } } return ancestor; } d3_layout_treeVisitAfter(root, function(node, previousSibling) { node._tree = { ancestor: node, prelim: 0, mod: 0, change: 0, shift: 0, number: previousSibling ? previousSibling._tree.number + 1 : 0 }; }); firstWalk(root); secondWalk(root, -root._tree.prelim); var left = d3_layout_treeSearch(root, d3_layout_treeLeftmost), right = d3_layout_treeSearch(root, d3_layout_treeRightmost), deep = d3_layout_treeSearch(root, d3_layout_treeDeepest), x0 = left.x - separation(left, right) / 2, x1 = right.x + separation(right, left) / 2, y1 = deep.depth || 1; d3_layout_treeVisitAfter(root, nodeSize ? function(node) { node.x *= size[0]; node.y = node.depth * size[1]; delete node._tree; } : function(node) { node.x = (node.x - x0) / (x1 - x0) * size[0]; node.y = node.depth / y1 * size[1]; delete node._tree; }); return nodes; } tree.separation = function(x) { if (!arguments.length) return separation; separation = x; return tree; }; tree.size = function(x) { if (!arguments.length) return nodeSize ? null : size; nodeSize = (size = x) == null; return tree; }; tree.nodeSize = function(x) { if (!arguments.length) return nodeSize ? size : null; nodeSize = (size = x) != null; return tree; }; return d3_layout_hierarchyRebind(tree, hierarchy); }; function d3_layout_treeSeparation(a, b) { return a.parent == b.parent ? 1 : 2; } function d3_layout_treeLeft(node) { var children = node.children; return children && children.length ? children[0] : node._tree.thread; } function d3_layout_treeRight(node) { var children = node.children, n; return children && (n = children.length) ? children[n - 1] : node._tree.thread; } function d3_layout_treeSearch(node, compare) { var children = node.children; if (children && (n = children.length)) { var child, n, i = -1; while (++i < n) { if (compare(child = d3_layout_treeSearch(children[i], compare), node) > 0) { node = child; } } } return node; } function d3_layout_treeRightmost(a, b) { return a.x - b.x; } function d3_layout_treeLeftmost(a, b) { return b.x - a.x; } function d3_layout_treeDeepest(a, b) { return a.depth - b.depth; } function d3_layout_treeVisitAfter(node, callback) { function visit(node, previousSibling) { var children = node.children; if (children && (n = children.length)) { var child, previousChild = null, i = -1, n; while (++i < n) { child = children[i]; visit(child, previousChild); previousChild = child; } } callback(node, previousSibling); } visit(node, null); } function d3_layout_treeShift(node) { var shift = 0, change = 0, children = node.children, i = children.length, child; while (--i >= 0) { child = children[i]._tree; child.prelim += shift; child.mod += shift; shift += child.shift + (change += child.change); } } function d3_layout_treeMove(ancestor, node, shift) { ancestor = ancestor._tree; node = node._tree; var change = shift / (node.number - ancestor.number); ancestor.change += change; node.change -= change; node.shift += shift; node.prelim += shift; node.mod += shift; } function d3_layout_treeAncestor(vim, node, ancestor) { return vim._tree.ancestor.parent == node.parent ? vim._tree.ancestor : ancestor; } d3.layout.pack = function() { var hierarchy = d3.layout.hierarchy().sort(d3_layout_packSort), padding = 0, size = [ 1, 1 ], radius; function pack(d, i) { var nodes = hierarchy.call(this, d, i), root = nodes[0], w = size[0], h = size[1], r = radius == null ? Math.sqrt : typeof radius === ""function"" ? radius : function() { return radius; }; root.x = root.y = 0; d3_layout_treeVisitAfter(root, function(d) { d.r = +r(d.value); }); d3_layout_treeVisitAfter(root, d3_layout_packSiblings); if (padding) { var dr = padding * (radius ? 1 : Math.max(2 * root.r / w, 2 * root.r / h)) / 2; d3_layout_treeVisitAfter(root, function(d) { d.r += dr; }); d3_layout_treeVisitAfter(root, d3_layout_packSiblings); d3_layout_treeVisitAfter(root, function(d) { d.r -= dr; }); } d3_layout_packTransform(root, w / 2, h / 2, radius ? 1 : 1 / Math.max(2 * root.r / w, 2 * root.r / h)); return nodes; } pack.size = function(_) { if (!arguments.length) return size; size = _; return pack; }; pack.radius = function(_) { if (!arguments.length) return radius; radius = _ == null || typeof _ === ""function"" ? _ : +_; return pack; }; pack.padding = function(_) { if (!arguments.length) return padding; padding = +_; return pack; }; return d3_layout_hierarchyRebind(pack, hierarchy); }; function d3_layout_packSort(a, b) { return a.value - b.value; } function d3_layout_packInsert(a, b) { var c = a._pack_next; a._pack_next = b; b._pack_prev = a; b._pack_next = c; c._pack_prev = b; } function d3_layout_packSplice(a, b) { a._pack_next = b; b._pack_prev = a; } function d3_layout_packIntersects(a, b) { var dx = b.x - a.x, dy = b.y - a.y, dr = a.r + b.r; return .999 * dr * dr > dx * dx + dy * dy; } function d3_layout_packSiblings(node) { if (!(nodes = node.children) || !(n = nodes.length)) return; var nodes, xMin = Infinity, xMax = -Infinity, yMin = Infinity, yMax = -Infinity, a, b, c, i, j, k, n; function bound(node) { xMin = Math.min(node.x - node.r, xMin); xMax = Math.max(node.x + node.r, xMax); yMin = Math.min(node.y - node.r, yMin); yMax = Math.max(node.y + node.r, yMax); } nodes.forEach(d3_layout_packLink); a = nodes[0]; a.x = -a.r; a.y = 0; bound(a); if (n > 1) { b = nodes[1]; b.x = b.r; b.y = 0; bound(b); if (n > 2) { c = nodes[2]; d3_layout_packPlace(a, b, c); bound(c); d3_layout_packInsert(a, c); a._pack_prev = c; d3_layout_packInsert(c, b); b = a._pack_next; for (i = 3; i < n; i++) { d3_layout_packPlace(a, b, c = nodes[i]); var isect = 0, s1 = 1, s2 = 1; for (j = b._pack_next; j !== b; j = j._pack_next, s1++) { if (d3_layout_packIntersects(j, c)) { isect = 1; break; } } if (isect == 1) { for (k = a._pack_prev; k !== j._pack_prev; k = k._pack_prev, s2++) { if (d3_layout_packIntersects(k, c)) { break; } } } if (isect) { if (s1 < s2 || s1 == s2 && b.r < a.r) d3_layout_packSplice(a, b = j); else d3_layout_packSplice(a = k, b); i--; } else { d3_layout_packInsert(a, c); b = c; bound(c); } } } } var cx = (xMin + xMax) / 2, cy = (yMin + yMax) / 2, cr = 0; for (i = 0; i < n; i++) { c = nodes[i]; c.x -= cx; c.y -= cy; cr = Math.max(cr, c.r + Math.sqrt(c.x * c.x + c.y * c.y)); } node.r = cr; nodes.forEach(d3_layout_packUnlink); } function d3_layout_packLink(node) { node._pack_next = node._pack_prev = node; } function d3_layout_packUnlink(node) { delete node._pack_next; delete node._pack_prev; } function d3_layout_packTransform(node, x, y, k) { var children = node.children; node.x = x += k * node.x; node.y = y += k * node.y; node.r *= k; if (children) { var i = -1, n = children.length; while (++i < n) d3_layout_packTransform(children[i], x, y, k); } } function d3_layout_packPlace(a, b, c) { var db = a.r + c.r, dx = b.x - a.x, dy = b.y - a.y; if (db && (dx || dy)) { var da = b.r + c.r, dc = dx * dx + dy * dy; da *= da; db *= db; var x = .5 + (db - da) / (2 * dc), y = Math.sqrt(Math.max(0, 2 * da * (db + dc) - (db -= dc) * db - da * da)) / (2 * dc); c.x = a.x + x * dx + y * dy; c.y = a.y + x * dy - y * dx; } else { c.x = a.x + db; c.y = a.y; } } d3.layout.cluster = function() { var hierarchy = d3.layout.hierarchy().sort(null).value(null), separation = d3_layout_treeSeparation, size = [ 1, 1 ], nodeSize = false; function cluster(d, i) { var nodes = hierarchy.call(this, d, i), root = nodes[0], previousNode, x = 0; d3_layout_treeVisitAfter(root, function(node) { var children = node.children; if (children && children.length) { node.x = d3_layout_clusterX(children); node.y = d3_layout_clusterY(children); } else { node.x = previousNode ? x += separation(node, previousNode) : 0; node.y = 0; previousNode = node; } }); var left = d3_layout_clusterLeft(root), right = d3_layout_clusterRight(root), x0 = left.x - separation(left, right) / 2, x1 = right.x + separation(right, left) / 2; d3_layout_treeVisitAfter(root, nodeSize ? function(node) { node.x = (node.x - root.x) * size[0]; node.y = (root.y - node.y) * size[1]; } : function(node) { node.x = (node.x - x0) / (x1 - x0) * size[0]; node.y = (1 - (root.y ? node.y / root.y : 1)) * size[1]; }); return nodes; } cluster.separation = function(x) { if (!arguments.length) return separation; separation = x; return cluster; }; cluster.size = function(x) { if (!arguments.length) return nodeSize ? null : size; nodeSize = (size = x) == null; return cluster; }; cluster.nodeSize = function(x) { if (!arguments.length) return nodeSize ? size : null; nodeSize = (size = x) != null; return cluster; }; return d3_layout_hierarchyRebind(cluster, hierarchy); }; function d3_layout_clusterY(children) { return 1 + d3.max(children, function(child) { return child.y; }); } function d3_layout_clusterX(children) { return children.reduce(function(x, child) { return x + child.x; }, 0) / children.length; } function d3_layout_clusterLeft(node) { var children = node.children; return children && children.length ? d3_layout_clusterLeft(children[0]) : node; } function d3_layout_clusterRight(node) { var children = node.children, n; return children && (n = children.length) ? d3_layout_clusterRight(children[n - 1]) : node; } d3.layout.treemap = function() { var hierarchy = d3.layout.hierarchy(), round = Math.round, size = [ 1, 1 ], padding = null, pad = d3_layout_treemapPadNull, sticky = false, stickies, mode = ""squarify"", ratio = .5 * (1 + Math.sqrt(5)); function scale(children, k) { var i = -1, n = children.length, child, area; while (++i < n) { area = (child = children[i]).value * (k < 0 ? 0 : k); child.area = isNaN(area) || area <= 0 ? 0 : area; } } function squarify(node) { var children = node.children; if (children && children.length) { var rect = pad(node), row = [], remaining = children.slice(), child, best = Infinity, score, u = mode === ""slice"" ? rect.dx : mode === ""dice"" ? rect.dy : mode === ""slice-dice"" ? node.depth & 1 ? rect.dy : rect.dx : Math.min(rect.dx, rect.dy), n; scale(remaining, rect.dx * rect.dy / node.value); row.area = 0; while ((n = remaining.length) > 0) { row.push(child = remaining[n - 1]); row.area += child.area; if (mode !== ""squarify"" || (score = worst(row, u)) <= best) { remaining.pop(); best = score; } else { row.area -= row.pop().area; position(row, u, rect, false); u = Math.min(rect.dx, rect.dy); row.length = row.area = 0; best = Infinity; } } if (row.length) { position(row, u, rect, true); row.length = row.area = 0; } children.forEach(squarify); } } function stickify(node) { var children = node.children; if (children && children.length) { var rect = pad(node), remaining = children.slice(), child, row = []; scale(remaining, rect.dx * rect.dy / node.value); row.area = 0; while (child = remaining.pop()) { row.push(child); row.area += child.area; if (child.z != null) { position(row, child.z ? rect.dx : rect.dy, rect, !remaining.length); row.length = row.area = 0; } } children.forEach(stickify); } } function worst(row, u) { var s = row.area, r, rmax = 0, rmin = Infinity, i = -1, n = row.length; while (++i < n) { if (!(r = row[i].area)) continue; if (r < rmin) rmin = r; if (r > rmax) rmax = r; } s *= s; u *= u; return s ? Math.max(u * rmax * ratio / s, s / (u * rmin * ratio)) : Infinity; } function position(row, u, rect, flush) { var i = -1, n = row.length, x = rect.x, y = rect.y, v = u ? round(row.area / u) : 0, o; if (u == rect.dx) { if (flush || v > rect.dy) v = rect.dy; while (++i < n) { o = row[i]; o.x = x; o.y = y; o.dy = v; x += o.dx = Math.min(rect.x + rect.dx - x, v ? round(o.area / v) : 0); } o.z = true; o.dx += rect.x + rect.dx - x; rect.y += v; rect.dy -= v; } else { if (flush || v > rect.dx) v = rect.dx; while (++i < n) { o = row[i]; o.x = x; o.y = y; o.dx = v; y += o.dy = Math.min(rect.y + rect.dy - y, v ? round(o.area / v) : 0); } o.z = false; o.dy += rect.y + rect.dy - y; rect.x += v; rect.dx -= v; } } function treemap(d) { var nodes = stickies || hierarchy(d), root = nodes[0]; root.x = 0; root.y = 0; root.dx = size[0]; root.dy = size[1]; if (stickies) hierarchy.revalue(root); scale([ root ], root.dx * root.dy / root.value); (stickies ? stickify : squarify)(root); if (sticky) stickies = nodes; return nodes; } treemap.size = function(x) { if (!arguments.length) return size; size = x; return treemap; }; treemap.padding = function(x) { if (!arguments.length) return padding; function padFunction(node) { var p = x.call(treemap, node, node.depth); return p == null ? d3_layout_treemapPadNull(node) : d3_layout_treemapPad(node, typeof p === ""number"" ? [ p, p, p, p ] : p); } function padConstant(node) { return d3_layout_treemapPad(node, x); } var type; pad = (padding = x) == null ? d3_layout_treemapPadNull : (type = typeof x) === ""function"" ? padFunction : type === ""number"" ? (x = [ x, x, x, x ], padConstant) : padConstant; return treemap; }; treemap.round = function(x) { if (!arguments.length) return round != Number; round = x ? Math.round : Number; return treemap; }; treemap.sticky = function(x) { if (!arguments.length) return sticky; sticky = x; stickies = null; return treemap; }; treemap.ratio = function(x) { if (!arguments.length) return ratio; ratio = x; return treemap; }; treemap.mode = function(x) { if (!arguments.length) return mode; mode = x + """"; return treemap; }; return d3_layout_hierarchyRebind(treemap, hierarchy); }; function d3_layout_treemapPadNull(node) { return { x: node.x, y: node.y, dx: node.dx, dy: node.dy }; } function d3_layout_treemapPad(node, padding) { var x = node.x + padding[3], y = node.y + padding[0], dx = node.dx - padding[1] - padding[3], dy = node.dy - padding[0] - padding[2]; if (dx < 0) { x += dx / 2; dx = 0; } if (dy < 0) { y += dy / 2; dy = 0; } return { x: x, y: y, dx: dx, dy: dy }; } d3.random = { normal: function(µ, σ) { var n = arguments.length; if (n < 2) σ = 1; if (n < 1) µ = 0; return function() { var x, y, r; do { x = Math.random() * 2 - 1; y = Math.random() * 2 - 1; r = x * x + y * y; } while (!r || r > 1); return µ + σ * x * Math.sqrt(-2 * Math.log(r) / r); }; }, logNormal: function() { var random = d3.random.normal.apply(d3, arguments); return function() { return Math.exp(random()); }; }, bates: function(m) { var random = d3.random.irwinHall(m); return function() { return random() / m; }; }, irwinHall: function(m) { return function() { for (var s = 0, j = 0; j < m; j++) s += Math.random(); return s; }; } }; d3.scale = {}; function d3_scaleExtent(domain) { var start = domain[0], stop = domain[domain.length - 1]; return start < stop ? [ start, stop ] : [ stop, start ]; } function d3_scaleRange(scale) { return scale.rangeExtent ? scale.rangeExtent() : d3_scaleExtent(scale.range()); } function d3_scale_bilinear(domain, range, uninterpolate, interpolate) { var u = uninterpolate(domain[0], domain[1]), i = interpolate(range[0], range[1]); return function(x) { return i(u(x)); }; } function d3_scale_nice(domain, nice) { var i0 = 0, i1 = domain.length - 1, x0 = domain[i0], x1 = domain[i1], dx; if (x1 < x0) { dx = i0, i0 = i1, i1 = dx; dx = x0, x0 = x1, x1 = dx; } domain[i0] = nice.floor(x0); domain[i1] = nice.ceil(x1); return domain; } function d3_scale_niceStep(step) { return step ? { floor: function(x) { return Math.floor(x / step) * step; }, ceil: function(x) { return Math.ceil(x / step) * step; } } : d3_scale_niceIdentity; } var d3_scale_niceIdentity = { floor: d3_identity, ceil: d3_identity }; function d3_scale_polylinear(domain, range, uninterpolate, interpolate) { var u = [], i = [], j = 0, k = Math.min(domain.length, range.length) - 1; if (domain[k] < domain[0]) { domain = domain.slice().reverse(); range = range.slice().reverse(); } while (++j <= k) { u.push(uninterpolate(domain[j - 1], domain[j])); i.push(interpolate(range[j - 1], range[j])); } return function(x) { var j = d3.bisect(domain, x, 1, k) - 1; return i[j](u[j](x)); }; } d3.scale.linear = function() { return d3_scale_linear([ 0, 1 ], [ 0, 1 ], d3_interpolate, false); }; function d3_scale_linear(domain, range, interpolate, clamp) { var output, input; function rescale() { var linear = Math.min(domain.length, range.length) > 2 ? d3_scale_polylinear : d3_scale_bilinear, uninterpolate = clamp ? d3_uninterpolateClamp : d3_uninterpolateNumber; output = linear(domain, range, uninterpolate, interpolate); input = linear(range, domain, uninterpolate, d3_interpolate); return scale; } function scale(x) { return output(x); } scale.invert = function(y) { return input(y); }; scale.domain = function(x) { if (!arguments.length) return domain; domain = x.map(Number); return rescale(); }; scale.range = function(x) { if (!arguments.length) return range; range = x; return rescale(); }; scale.rangeRound = function(x) { return scale.range(x).interpolate(d3_interpolateRound); }; scale.clamp = function(x) { if (!arguments.length) return clamp; clamp = x; return rescale(); }; scale.interpolate = function(x) { if (!arguments.length) return interpolate; interpolate = x; return rescale(); }; scale.ticks = function(m) { return d3_scale_linearTicks(domain, m); }; scale.tickFormat = function(m, format) { return d3_scale_linearTickFormat(domain, m, format); }; scale.nice = function(m) { d3_scale_linearNice(domain, m); return rescale(); }; scale.copy = function() { return d3_scale_linear(domain, range, interpolate, clamp); }; return rescale(); } function d3_scale_linearRebind(scale, linear) { return d3.rebind(scale, linear, ""range"", ""rangeRound"", ""interpolate"", ""clamp""); } function d3_scale_linearNice(domain, m) { return d3_scale_nice(domain, d3_scale_niceStep(d3_scale_linearTickRange(domain, m)[2])); } function d3_scale_linearTickRange(domain, m) { if (m == null) m = 10; var extent = d3_scaleExtent(domain), span = extent[1] - extent[0], step = Math.pow(10, Math.floor(Math.log(span / m) / Math.LN10)), err = m / span * step; if (err <= .15) step *= 10; else if (err <= .35) step *= 5; else if (err <= .75) step *= 2; extent[0] = Math.ceil(extent[0] / step) * step; extent[1] = Math.floor(extent[1] / step) * step + step * .5; extent[2] = step; return extent; } function d3_scale_linearTicks(domain, m) { return d3.range.apply(d3, d3_scale_linearTickRange(domain, m)); } function d3_scale_linearTickFormat(domain, m, format) { var range = d3_scale_linearTickRange(domain, m); if (format) { var match = d3_format_re.exec(format); match.shift(); if (match[8] === ""s"") { var prefix = d3.formatPrefix(Math.max(abs(range[0]), abs(range[1]))); if (!match[7]) match[7] = ""."" + d3_scale_linearPrecision(prefix.scale(range[2])); match[8] = ""f""; format = d3.format(match.join("""")); return function(d) { return format(prefix.scale(d)) + prefix.symbol; }; } if (!match[7]) match[7] = ""."" + d3_scale_linearFormatPrecision(match[8], range); format = match.join(""""); } else { format = "",."" + d3_scale_linearPrecision(range[2]) + ""f""; } return d3.format(format); } var d3_scale_linearFormatSignificant = { s: 1, g: 1, p: 1, r: 1, e: 1 }; function d3_scale_linearPrecision(value) { return -Math.floor(Math.log(value) / Math.LN10 + .01); } function d3_scale_linearFormatPrecision(type, range) { var p = d3_scale_linearPrecision(range[2]); return type in d3_scale_linearFormatSignificant ? Math.abs(p - d3_scale_linearPrecision(Math.max(abs(range[0]), abs(range[1])))) + +(type !== ""e"") : p - (type === ""%"") * 2; } d3.scale.log = function() { return d3_scale_log(d3.scale.linear().domain([ 0, 1 ]), 10, true, [ 1, 10 ]); }; function d3_scale_log(linear, base, positive, domain) { function log(x) { return (positive ? Math.log(x < 0 ? 0 : x) : -Math.log(x > 0 ? 0 : -x)) / Math.log(base); } function pow(x) { return positive ? Math.pow(base, x) : -Math.pow(base, -x); } function scale(x) { return linear(log(x)); } scale.invert = function(x) { return pow(linear.invert(x)); }; scale.domain = function(x) { if (!arguments.length) return domain; positive = x[0] >= 0; linear.domain((domain = x.map(Number)).map(log)); return scale; }; scale.base = function(_) { if (!arguments.length) return base; base = +_; linear.domain(domain.map(log)); return scale; }; scale.nice = function() { var niced = d3_scale_nice(domain.map(log), positive ? Math : d3_scale_logNiceNegative); linear.domain(niced); domain = niced.map(pow); return scale; }; scale.ticks = function() { var extent = d3_scaleExtent(domain), ticks = [], u = extent[0], v = extent[1], i = Math.floor(log(u)), j = Math.ceil(log(v)), n = base % 1 ? 2 : base; if (isFinite(j - i)) { if (positive) { for (;i < j; i++) for (var k = 1; k < n; k++) ticks.push(pow(i) * k); ticks.push(pow(i)); } else { ticks.push(pow(i)); for (;i++ < j; ) for (var k = n - 1; k > 0; k--) ticks.push(pow(i) * k); } for (i = 0; ticks[i] < u; i++) {} for (j = ticks.length; ticks[j - 1] > v; j--) {} ticks = ticks.slice(i, j); } return ticks; }; scale.tickFormat = function(n, format) { if (!arguments.length) return d3_scale_logFormat; if (arguments.length < 2) format = d3_scale_logFormat; else if (typeof format !== ""function"") format = d3.format(format); var k = Math.max(.1, n / scale.ticks().length), f = positive ? (e = 1e-12, Math.ceil) : (e = -1e-12, Math.floor), e; return function(d) { return d / pow(f(log(d) + e)) <= k ? format(d) : """"; }; }; scale.copy = function() { return d3_scale_log(linear.copy(), base, positive, domain); }; return d3_scale_linearRebind(scale, linear); } var d3_scale_logFormat = d3.format("".0e""), d3_scale_logNiceNegative = { floor: function(x) { return -Math.ceil(-x); }, ceil: function(x) { return -Math.floor(-x); } }; d3.scale.pow = function() { return d3_scale_pow(d3.scale.linear(), 1, [ 0, 1 ]); }; function d3_scale_pow(linear, exponent, domain) { var powp = d3_scale_powPow(exponent), powb = d3_scale_powPow(1 / exponent); function scale(x) { return linear(powp(x)); } scale.invert = function(x) { return powb(linear.invert(x)); }; scale.domain = function(x) { if (!arguments.length) return domain; linear.domain((domain = x.map(Number)).map(powp)); return scale; }; scale.ticks = function(m) { return d3_scale_linearTicks(domain, m); }; scale.tickFormat = function(m, format) { return d3_scale_linearTickFormat(domain, m, format); }; scale.nice = function(m) { return scale.domain(d3_scale_linearNice(domain, m)); }; scale.exponent = function(x) { if (!arguments.length) return exponent; powp = d3_scale_powPow(exponent = x); powb = d3_scale_powPow(1 / exponent); linear.domain(domain.map(powp)); return scale; }; scale.copy = function() { return d3_scale_pow(linear.copy(), exponent, domain); }; return d3_scale_linearRebind(scale, linear); } function d3_scale_powPow(e) { return function(x) { return x < 0 ? -Math.pow(-x, e) : Math.pow(x, e); }; } d3.scale.sqrt = function() { return d3.scale.pow().exponent(.5); }; d3.scale.ordinal = function() { return d3_scale_ordinal([], { t: ""range"", a: [ [] ] }); }; function d3_scale_ordinal(domain, ranger) { var index, range, rangeBand; function scale(x) { return range[((index.get(x) || (ranger.t === ""range"" ? index.set(x, domain.push(x)) : NaN)) - 1) % range.length]; } function steps(start, step) { return d3.range(domain.length).map(function(i) { return start + step * i; }); } scale.domain = function(x) { if (!arguments.length) return domain; domain = []; index = new d3_Map(); var i = -1, n = x.length, xi; while (++i < n) if (!index.has(xi = x[i])) index.set(xi, domain.push(xi)); return scale[ranger.t].apply(scale, ranger.a); }; scale.range = function(x) { if (!arguments.length) return range; range = x; rangeBand = 0; ranger = { t: ""range"", a: arguments }; return scale; }; scale.rangePoints = function(x, padding) { if (arguments.length < 2) padding = 0; var start = x[0], stop = x[1], step = (stop - start) / (Math.max(1, domain.length - 1) + padding); range = steps(domain.length < 2 ? (start + stop) / 2 : start + step * padding / 2, step); rangeBand = 0; ranger = { t: ""rangePoints"", a: arguments }; return scale; }; scale.rangeBands = function(x, padding, outerPadding) { if (arguments.length < 2) padding = 0; if (arguments.length < 3) outerPadding = padding; var reverse = x[1] < x[0], start = x[reverse - 0], stop = x[1 - reverse], step = (stop - start) / (domain.length - padding + 2 * outerPadding); range = steps(start + step * outerPadding, step); if (reverse) range.reverse(); rangeBand = step * (1 - padding); ranger = { t: ""rangeBands"", a: arguments }; return scale; }; scale.rangeRoundBands = function(x, padding, outerPadding) { if (arguments.length < 2) padding = 0; if (arguments.length < 3) outerPadding = padding; var reverse = x[1] < x[0], start = x[reverse - 0], stop = x[1 - reverse], step = Math.floor((stop - start) / (domain.length - padding + 2 * outerPadding)), error = stop - start - (domain.length - padding) * step; range = steps(start + Math.round(error / 2), step); if (reverse) range.reverse(); rangeBand = Math.round(step * (1 - padding)); ranger = { t: ""rangeRoundBands"", a: arguments }; return scale; }; scale.rangeBand = function() { return rangeBand; }; scale.rangeExtent = function() { return d3_scaleExtent(ranger.a[0]); }; scale.copy = function() { return d3_scale_ordinal(domain, ranger); }; return scale.domain(domain); } d3.scale.category10 = function() { return d3.scale.ordinal().range(d3_category10); }; d3.scale.category20 = function() { return d3.scale.ordinal().range(d3_category20); }; d3.scale.category20b = function() { return d3.scale.ordinal().range(d3_category20b); }; d3.scale.category20c = function() { return d3.scale.ordinal().range(d3_category20c); }; var d3_category10 = [ 2062260, 16744206, 2924588, 14034728, 9725885, 9197131, 14907330, 8355711, 12369186, 1556175 ].map(d3_rgbString); var d3_category20 = [ 2062260, 11454440, 16744206, 16759672, 2924588, 10018698, 14034728, 16750742, 9725885, 12955861, 9197131, 12885140, 14907330, 16234194, 8355711, 13092807, 12369186, 14408589, 1556175, 10410725 ].map(d3_rgbString); var d3_category20b = [ 3750777, 5395619, 7040719, 10264286, 6519097, 9216594, 11915115, 13556636, 9202993, 12426809, 15186514, 15190932, 8666169, 11356490, 14049643, 15177372, 8077683, 10834324, 13528509, 14589654 ].map(d3_rgbString); var d3_category20c = [ 3244733, 7057110, 10406625, 13032431, 15095053, 16616764, 16625259, 16634018, 3253076, 7652470, 10607003, 13101504, 7695281, 10394312, 12369372, 14342891, 6513507, 9868950, 12434877, 14277081 ].map(d3_rgbString); d3.scale.quantile = function() { return d3_scale_quantile([], []); }; function d3_scale_quantile(domain, range) { var thresholds; function rescale() { var k = 0, q = range.length; thresholds = []; while (++k < q) thresholds[k - 1] = d3.quantile(domain, k / q); return scale; } function scale(x) { if (!isNaN(x = +x)) return range[d3.bisect(thresholds, x)]; } scale.domain = function(x) { if (!arguments.length) return domain; domain = x.filter(function(d) { return !isNaN(d); }).sort(d3_ascending); return rescale(); }; scale.range = function(x) { if (!arguments.length) return range; range = x; return rescale(); }; scale.quantiles = function() { return thresholds; }; scale.invertExtent = function(y) { y = range.indexOf(y); return y < 0 ? [ NaN, NaN ] : [ y > 0 ? thresholds[y - 1] : domain[0], y < thresholds.length ? thresholds[y] : domain[domain.length - 1] ]; }; scale.copy = function() { return d3_scale_quantile(domain, range); }; return rescale(); } d3.scale.quantize = function() { return d3_scale_quantize(0, 1, [ 0, 1 ]); }; function d3_scale_quantize(x0, x1, range) { var kx, i; function scale(x) { return range[Math.max(0, Math.min(i, Math.floor(kx * (x - x0))))]; } function rescale() { kx = range.length / (x1 - x0); i = range.length - 1; return scale; } scale.domain = function(x) { if (!arguments.length) return [ x0, x1 ]; x0 = +x[0]; x1 = +x[x.length - 1]; return rescale(); }; scale.range = function(x) { if (!arguments.length) return range; range = x; return rescale(); }; scale.invertExtent = function(y) { y = range.indexOf(y); y = y < 0 ? NaN : y / kx + x0; return [ y, y + 1 / kx ]; }; scale.copy = function() { return d3_scale_quantize(x0, x1, range); }; return rescale(); } d3.scale.threshold = function() { return d3_scale_threshold([ .5 ], [ 0, 1 ]); }; function d3_scale_threshold(domain, range) { function scale(x) { if (x <= x) return range[d3.bisect(domain, x)]; } scale.domain = function(_) { if (!arguments.length) return domain; domain = _; return scale; }; scale.range = function(_) { if (!arguments.length) return range; range = _; return scale; }; scale.invertExtent = function(y) { y = range.indexOf(y); return [ domain[y - 1], domain[y] ]; }; scale.copy = function() { return d3_scale_threshold(domain, range); }; return scale; } d3.scale.identity = function() { return d3_scale_identity([ 0, 1 ]); }; function d3_scale_identity(domain) { function identity(x) { return +x; } identity.invert = identity; identity.domain = identity.range = function(x) { if (!arguments.length) return domain; domain = x.map(identity); return identity; }; identity.ticks = function(m) { return d3_scale_linearTicks(domain, m); }; identity.tickFormat = function(m, format) { return d3_scale_linearTickFormat(domain, m, format); }; identity.copy = function() { return d3_scale_identity(domain); }; return identity; } d3.svg = {}; d3.svg.arc = function() { var innerRadius = d3_svg_arcInnerRadius, outerRadius = d3_svg_arcOuterRadius, startAngle = d3_svg_arcStartAngle, endAngle = d3_svg_arcEndAngle; function arc() { var r0 = innerRadius.apply(this, arguments), r1 = outerRadius.apply(this, arguments), a0 = startAngle.apply(this, arguments) + d3_svg_arcOffset, a1 = endAngle.apply(this, arguments) + d3_svg_arcOffset, da = (a1 < a0 && (da = a0, a0 = a1, a1 = da), a1 - a0), df = da < π ? ""0"" : ""1"", c0 = Math.cos(a0), s0 = Math.sin(a0), c1 = Math.cos(a1), s1 = Math.sin(a1); return da >= d3_svg_arcMax ? r0 ? ""M0,"" + r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + -r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + r1 + ""M0,"" + r0 + ""A"" + r0 + "","" + r0 + "" 0 1,0 0,"" + -r0 + ""A"" + r0 + "","" + r0 + "" 0 1,0 0,"" + r0 + ""Z"" : ""M0,"" + r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + -r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + r1 + ""Z"" : r0 ? ""M"" + r1 * c0 + "","" + r1 * s0 + ""A"" + r1 + "","" + r1 + "" 0 "" + df + "",1 "" + r1 * c1 + "","" + r1 * s1 + ""L"" + r0 * c1 + "","" + r0 * s1 + ""A"" + r0 + "","" + r0 + "" 0 "" + df + "",0 "" + r0 * c0 + "","" + r0 * s0 + ""Z"" : ""M"" + r1 * c0 + "","" + r1 * s0 + ""A"" + r1 + "","" + r1 + "" 0 "" + df + "",1 "" + r1 * c1 + "","" + r1 * s1 + ""L0,0"" + ""Z""; } arc.innerRadius = function(v) { if (!arguments.length) return innerRadius; innerRadius = d3_functor(v); return arc; }; arc.outerRadius = function(v) { if (!arguments.length) return outerRadius; outerRadius = d3_functor(v); return arc; }; arc.startAngle = function(v) { if (!arguments.length) return startAngle; startAngle = d3_functor(v); return arc; }; arc.endAngle = function(v) { if (!arguments.length) return endAngle; endAngle = d3_functor(v); return arc; }; arc.centroid = function() { var r = (innerRadius.apply(this, arguments) + outerRadius.apply(this, arguments)) / 2, a = (startAngle.apply(this, arguments) + endAngle.apply(this, arguments)) / 2 + d3_svg_arcOffset; return [ Math.cos(a) * r, Math.sin(a) * r ]; }; return arc; }; var d3_svg_arcOffset = -halfπ, d3_svg_arcMax = τ - ε; function d3_svg_arcInnerRadius(d) { return d.innerRadius; } function d3_svg_arcOuterRadius(d) { return d.outerRadius; } function d3_svg_arcStartAngle(d) { return d.startAngle; } function d3_svg_arcEndAngle(d) { return d.endAngle; } function d3_svg_line(projection) { var x = d3_geom_pointX, y = d3_geom_pointY, defined = d3_true, interpolate = d3_svg_lineLinear, interpolateKey = interpolate.key, tension = .7; function line(data) { var segments = [], points = [], i = -1, n = data.length, d, fx = d3_functor(x), fy = d3_functor(y); function segment() { segments.push(""M"", interpolate(projection(points), tension)); } while (++i < n) { if (defined.call(this, d = data[i], i)) { points.push([ +fx.call(this, d, i), +fy.call(this, d, i) ]); } else if (points.length) { segment(); points = []; } } if (points.length) segment(); return segments.length ? segments.join("""") : null; } line.x = function(_) { if (!arguments.length) return x; x = _; return line; }; line.y = function(_) { if (!arguments.length) return y; y = _; return line; }; line.defined = function(_) { if (!arguments.length) return defined; defined = _; return line; }; line.interpolate = function(_) { if (!arguments.length) return interpolateKey; if (typeof _ === ""function"") interpolateKey = interpolate = _; else interpolateKey = (interpolate = d3_svg_lineInterpolators.get(_) || d3_svg_lineLinear).key; return line; }; line.tension = function(_) { if (!arguments.length) return tension; tension = _; return line; }; return line; } d3.svg.line = function() { return d3_svg_line(d3_identity); }; var d3_svg_lineInterpolators = d3.map({ linear: d3_svg_lineLinear, ""linear-closed"": d3_svg_lineLinearClosed, step: d3_svg_lineStep, ""step-before"": d3_svg_lineStepBefore, ""step-after"": d3_svg_lineStepAfter, basis: d3_svg_lineBasis, ""basis-open"": d3_svg_lineBasisOpen, ""basis-closed"": d3_svg_lineBasisClosed, bundle: d3_svg_lineBundle, cardinal: d3_svg_lineCardinal, ""cardinal-open"": d3_svg_lineCardinalOpen, ""cardinal-closed"": d3_svg_lineCardinalClosed, monotone: d3_svg_lineMonotone }); d3_svg_lineInterpolators.forEach(function(key, value) { value.key = key; value.closed = /-closed$/.test(key); }); function d3_svg_lineLinear(points) { return points.join(""L""); } function d3_svg_lineLinearClosed(points) { return d3_svg_lineLinear(points) + ""Z""; } function d3_svg_lineStep(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""H"", (p[0] + (p = points[i])[0]) / 2, ""V"", p[1]); if (n > 1) path.push(""H"", p[0]); return path.join(""""); } function d3_svg_lineStepBefore(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""V"", (p = points[i])[1], ""H"", p[0]); return path.join(""""); } function d3_svg_lineStepAfter(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""H"", (p = points[i])[0], ""V"", p[1]); return path.join(""""); } function d3_svg_lineCardinalOpen(points, tension) { return points.length < 4 ? d3_svg_lineLinear(points) : points[1] + d3_svg_lineHermite(points.slice(1, points.length - 1), d3_svg_lineCardinalTangents(points, tension)); } function d3_svg_lineCardinalClosed(points, tension) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite((points.push(points[0]), points), d3_svg_lineCardinalTangents([ points[points.length - 2] ].concat(points, [ points[1] ]), tension)); } function d3_svg_lineCardinal(points, tension) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite(points, d3_svg_lineCardinalTangents(points, tension)); } function d3_svg_lineHermite(points, tangents) { if (tangents.length < 1 || points.length != tangents.length && points.length != tangents.length + 2) { return d3_svg_lineLinear(points); } var quad = points.length != tangents.length, path = """", p0 = points[0], p = points[1], t0 = tangents[0], t = t0, pi = 1; if (quad) { path += ""Q"" + (p[0] - t0[0] * 2 / 3) + "","" + (p[1] - t0[1] * 2 / 3) + "","" + p[0] + "","" + p[1]; p0 = points[1]; pi = 2; } if (tangents.length > 1) { t = tangents[1]; p = points[pi]; pi++; path += ""C"" + (p0[0] + t0[0]) + "","" + (p0[1] + t0[1]) + "","" + (p[0] - t[0]) + "","" + (p[1] - t[1]) + "","" + p[0] + "","" + p[1]; for (var i = 2; i < tangents.length; i++, pi++) { p = points[pi]; t = tangents[i]; path += ""S"" + (p[0] - t[0]) + "","" + (p[1] - t[1]) + "","" + p[0] + "","" + p[1]; } } if (quad) { var lp = points[pi]; path += ""Q"" + (p[0] + t[0] * 2 / 3) + "","" + (p[1] + t[1] * 2 / 3) + "","" + lp[0] + "","" + lp[1]; } return path; } function d3_svg_lineCardinalTangents(points, tension) { var tangents = [], a = (1 - tension) / 2, p0, p1 = points[0], p2 = points[1], i = 1, n = points.length; while (++i < n) { p0 = p1; p1 = p2; p2 = points[i]; tangents.push([ a * (p2[0] - p0[0]), a * (p2[1] - p0[1]) ]); } return tangents; } function d3_svg_lineBasis(points) { if (points.length < 3) return d3_svg_lineLinear(points); var i = 1, n = points.length, pi = points[0], x0 = pi[0], y0 = pi[1], px = [ x0, x0, x0, (pi = points[1])[0] ], py = [ y0, y0, y0, pi[1] ], path = [ x0, "","", y0, ""L"", d3_svg_lineDot4(d3_svg_lineBasisBezier3, px), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, py) ]; points.push(points[n - 1]); while (++i <= n) { pi = points[i]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } points.pop(); path.push(""L"", pi); return path.join(""""); } function d3_svg_lineBasisOpen(points) { if (points.length < 4) return d3_svg_lineLinear(points); var path = [], i = -1, n = points.length, pi, px = [ 0 ], py = [ 0 ]; while (++i < 3) { pi = points[i]; px.push(pi[0]); py.push(pi[1]); } path.push(d3_svg_lineDot4(d3_svg_lineBasisBezier3, px) + "","" + d3_svg_lineDot4(d3_svg_lineBasisBezier3, py)); --i; while (++i < n) { pi = points[i]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBasisClosed(points) { var path, i = -1, n = points.length, m = n + 4, pi, px = [], py = []; while (++i < 4) { pi = points[i % n]; px.push(pi[0]); py.push(pi[1]); } path = [ d3_svg_lineDot4(d3_svg_lineBasisBezier3, px), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, py) ]; --i; while (++i < m) { pi = points[i % n]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBundle(points, tension) { var n = points.length - 1; if (n) { var x0 = points[0][0], y0 = points[0][1], dx = points[n][0] - x0, dy = points[n][1] - y0, i = -1, p, t; while (++i <= n) { p = points[i]; t = i / n; p[0] = tension * p[0] + (1 - tension) * (x0 + t * dx); p[1] = tension * p[1] + (1 - tension) * (y0 + t * dy); } } return d3_svg_lineBasis(points); } function d3_svg_lineDot4(a, b) { return a[0] * b[0] + a[1] * b[1] + a[2] * b[2] + a[3] * b[3]; } var d3_svg_lineBasisBezier1 = [ 0, 2 / 3, 1 / 3, 0 ], d3_svg_lineBasisBezier2 = [ 0, 1 / 3, 2 / 3, 0 ], d3_svg_lineBasisBezier3 = [ 0, 1 / 6, 2 / 3, 1 / 6 ]; function d3_svg_lineBasisBezier(path, x, y) { path.push(""C"", d3_svg_lineDot4(d3_svg_lineBasisBezier1, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier1, y), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier2, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier2, y), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, y)); } function d3_svg_lineSlope(p0, p1) { return (p1[1] - p0[1]) / (p1[0] - p0[0]); } function d3_svg_lineFiniteDifferences(points) { var i = 0, j = points.length - 1, m = [], p0 = points[0], p1 = points[1], d = m[0] = d3_svg_lineSlope(p0, p1); while (++i < j) { m[i] = (d + (d = d3_svg_lineSlope(p0 = p1, p1 = points[i + 1]))) / 2; } m[i] = d; return m; } function d3_svg_lineMonotoneTangents(points) { var tangents = [], d, a, b, s, m = d3_svg_lineFiniteDifferences(points), i = -1, j = points.length - 1; while (++i < j) { d = d3_svg_lineSlope(points[i], points[i + 1]); if (abs(d) < ε) { m[i] = m[i + 1] = 0; } else { a = m[i] / d; b = m[i + 1] / d; s = a * a + b * b; if (s > 9) { s = d * 3 / Math.sqrt(s); m[i] = s * a; m[i + 1] = s * b; } } } i = -1; while (++i <= j) { s = (points[Math.min(j, i + 1)][0] - points[Math.max(0, i - 1)][0]) / (6 * (1 + m[i] * m[i])); tangents.push([ s || 0, m[i] * s || 0 ]); } return tangents; } function d3_svg_lineMonotone(points) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite(points, d3_svg_lineMonotoneTangents(points)); } d3.svg.line.radial = function() { var line = d3_svg_line(d3_svg_lineRadial); line.radius = line.x, delete line.x; line.angle = line.y, delete line.y; return line; }; function d3_svg_lineRadial(points) { var point, i = -1, n = points.length, r, a; while (++i < n) { point = points[i]; r = point[0]; a = point[1] + d3_svg_arcOffset; point[0] = r * Math.cos(a); point[1] = r * Math.sin(a); } return points; } function d3_svg_area(projection) { var x0 = d3_geom_pointX, x1 = d3_geom_pointX, y0 = 0, y1 = d3_geom_pointY, defined = d3_true, interpolate = d3_svg_lineLinear, interpolateKey = interpolate.key, interpolateReverse = interpolate, L = ""L"", tension = .7; function area(data) { var segments = [], points0 = [], points1 = [], i = -1, n = data.length, d, fx0 = d3_functor(x0), fy0 = d3_functor(y0), fx1 = x0 === x1 ? function() { return x; } : d3_functor(x1), fy1 = y0 === y1 ? function() { return y; } : d3_functor(y1), x, y; function segment() { segments.push(""M"", interpolate(projection(points1), tension), L, interpolateReverse(projection(points0.reverse()), tension), ""Z""); } while (++i < n) { if (defined.call(this, d = data[i], i)) { points0.push([ x = +fx0.call(this, d, i), y = +fy0.call(this, d, i) ]); points1.push([ +fx1.call(this, d, i), +fy1.call(this, d, i) ]); } else if (points0.length) { segment(); points0 = []; points1 = []; } } if (points0.length) segment(); return segments.length ? segments.join("""") : null; } area.x = function(_) { if (!arguments.length) return x1; x0 = x1 = _; return area; }; area.x0 = function(_) { if (!arguments.length) return x0; x0 = _; return area; }; area.x1 = function(_) { if (!arguments.length) return x1; x1 = _; return area; }; area.y = function(_) { if (!arguments.length) return y1; y0 = y1 = _; return area; }; area.y0 = function(_) { if (!arguments.length) return y0; y0 = _; return area; }; area.y1 = function(_) { if (!arguments.length) return y1; y1 = _; return area; }; area.defined = function(_) { if (!arguments.length) return defined; defined = _; return area; }; area.interpolate = function(_) { if (!arguments.length) return interpolateKey; if (typeof _ === ""function"") interpolateKey = interpolate = _; else interpolateKey = (interpolate = d3_svg_lineInterpolators.get(_) || d3_svg_lineLinear).key; interpolateReverse = interpolate.reverse || interpolate; L = interpolate.closed ? ""M"" : ""L""; return area; }; area.tension = function(_) { if (!arguments.length) return tension; tension = _; return area; }; return area; } d3_svg_lineStepBefore.reverse = d3_svg_lineStepAfter; d3_svg_lineStepAfter.reverse = d3_svg_lineStepBefore; d3.svg.area = function() { return d3_svg_area(d3_identity); }; d3.svg.area.radial = function() { var area = d3_svg_area(d3_svg_lineRadial); area.radius = area.x, delete area.x; area.innerRadius = area.x0, delete area.x0; area.outerRadius = area.x1, delete area.x1; area.angle = area.y, delete area.y; area.startAngle = area.y0, delete area.y0; area.endAngle = area.y1, delete area.y1; return area; }; d3.svg.chord = function() { var source = d3_source, target = d3_target, radius = d3_svg_chordRadius, startAngle = d3_svg_arcStartAngle, endAngle = d3_svg_arcEndAngle; function chord(d, i) { var s = subgroup(this, source, d, i), t = subgroup(this, target, d, i); return ""M"" + s.p0 + arc(s.r, s.p1, s.a1 - s.a0) + (equals(s, t) ? curve(s.r, s.p1, s.r, s.p0) : curve(s.r, s.p1, t.r, t.p0) + arc(t.r, t.p1, t.a1 - t.a0) + curve(t.r, t.p1, s.r, s.p0)) + ""Z""; } function subgroup(self, f, d, i) { var subgroup = f.call(self, d, i), r = radius.call(self, subgroup, i), a0 = startAngle.call(self, subgroup, i) + d3_svg_arcOffset, a1 = endAngle.call(self, subgroup, i) + d3_svg_arcOffset; return { r: r, a0: a0, a1: a1, p0: [ r * Math.cos(a0), r * Math.sin(a0) ], p1: [ r * Math.cos(a1), r * Math.sin(a1) ] }; } function equals(a, b) { return a.a0 == b.a0 && a.a1 == b.a1; } function arc(r, p, a) { return ""A"" + r + "","" + r + "" 0 "" + +(a > π) + "",1 "" + p; } function curve(r0, p0, r1, p1) { return ""Q 0,0 "" + p1; } chord.radius = function(v) { if (!arguments.length) return radius; radius = d3_functor(v); return chord; }; chord.source = function(v) { if (!arguments.length) return source; source = d3_functor(v); return chord; }; chord.target = function(v) { if (!arguments.length) return target; target = d3_functor(v); return chord; }; chord.startAngle = function(v) { if (!arguments.length) return startAngle; startAngle = d3_functor(v); return chord; }; chord.endAngle = function(v) { if (!arguments.length) return endAngle; endAngle = d3_functor(v); return chord; }; return chord; }; function d3_svg_chordRadius(d) { return d.radius; } d3.svg.diagonal = function() { var source = d3_source, target = d3_target, projection = d3_svg_diagonalProjection; function diagonal(d, i) { var p0 = source.call(this, d, i), p3 = target.call(this, d, i), m = (p0.y + p3.y) / 2, p = [ p0, { x: p0.x, y: m }, { x: p3.x, y: m }, p3 ]; p = p.map(projection); return ""M"" + p[0] + ""C"" + p[1] + "" "" + p[2] + "" "" + p[3]; } diagonal.source = function(x) { if (!arguments.length) return source; source = d3_functor(x); return diagonal; }; diagonal.target = function(x) { if (!arguments.length) return target; target = d3_functor(x); return diagonal; }; diagonal.projection = function(x) { if (!arguments.length) return projection; projection = x; return diagonal; }; return diagonal; }; function d3_svg_diagonalProjection(d) { return [ d.x, d.y ]; } d3.svg.diagonal.radial = function() { var diagonal = d3.svg.diagonal(), projection = d3_svg_diagonalProjection, projection_ = diagonal.projection; diagonal.projection = function(x) { return arguments.length ? projection_(d3_svg_diagonalRadialProjection(projection = x)) : projection; }; return diagonal; }; function d3_svg_diagonalRadialProjection(projection) { return function() { var d = projection.apply(this, arguments), r = d[0], a = d[1] + d3_svg_arcOffset; return [ r * Math.cos(a), r * Math.sin(a) ]; }; } d3.svg.symbol = function() { var type = d3_svg_symbolType, size = d3_svg_symbolSize; function symbol(d, i) { return (d3_svg_symbols.get(type.call(this, d, i)) || d3_svg_symbolCircle)(size.call(this, d, i)); } symbol.type = function(x) { if (!arguments.length) return type; type = d3_functor(x); return symbol; }; symbol.size = function(x) { if (!arguments.length) return size; size = d3_functor(x); return symbol; }; return symbol; }; function d3_svg_symbolSize() { return 64; } function d3_svg_symbolType() { return ""circle""; } function d3_svg_symbolCircle(size) { var r = Math.sqrt(size / π); return ""M0,"" + r + ""A"" + r + "","" + r + "" 0 1,1 0,"" + -r + ""A"" + r + "","" + r + "" 0 1,1 0,"" + r + ""Z""; } var d3_svg_symbols = d3.map({ circle: d3_svg_symbolCircle, cross: function(size) { var r = Math.sqrt(size / 5) / 2; return ""M"" + -3 * r + "","" + -r + ""H"" + -r + ""V"" + -3 * r + ""H"" + r + ""V"" + -r + ""H"" + 3 * r + ""V"" + r + ""H"" + r + ""V"" + 3 * r + ""H"" + -r + ""V"" + r + ""H"" + -3 * r + ""Z""; }, diamond: function(size) { var ry = Math.sqrt(size / (2 * d3_svg_symbolTan30)), rx = ry * d3_svg_symbolTan30; return ""M0,"" + -ry + ""L"" + rx + "",0"" + "" 0,"" + ry + "" "" + -rx + "",0"" + ""Z""; }, square: function(size) { var r = Math.sqrt(size) / 2; return ""M"" + -r + "","" + -r + ""L"" + r + "","" + -r + "" "" + r + "","" + r + "" "" + -r + "","" + r + ""Z""; }, ""triangle-down"": function(size) { var rx = Math.sqrt(size / d3_svg_symbolSqrt3), ry = rx * d3_svg_symbolSqrt3 / 2; return ""M0,"" + ry + ""L"" + rx + "","" + -ry + "" "" + -rx + "","" + -ry + ""Z""; }, ""triangle-up"": function(size) { var rx = Math.sqrt(size / d3_svg_symbolSqrt3), ry = rx * d3_svg_symbolSqrt3 / 2; return ""M0,"" + -ry + ""L"" + rx + "","" + ry + "" "" + -rx + "","" + ry + ""Z""; } }); d3.svg.symbolTypes = d3_svg_symbols.keys(); var d3_svg_symbolSqrt3 = Math.sqrt(3), d3_svg_symbolTan30 = Math.tan(30 * d3_radians); function d3_transition(groups, id) { d3_subclass(groups, d3_transitionPrototype); groups.id = id; return groups; } var d3_transitionPrototype = [], d3_transitionId = 0, d3_transitionInheritId, d3_transitionInherit; d3_transitionPrototype.call = d3_selectionPrototype.call; d3_transitionPrototype.empty = d3_selectionPrototype.empty; d3_transitionPrototype.node = d3_selectionPrototype.node; d3_transitionPrototype.size = d3_selectionPrototype.size; d3.transition = function(selection) { return arguments.length ? d3_transitionInheritId ? selection.transition() : selection : d3_selectionRoot.transition(); }; d3.transition.prototype = d3_transitionPrototype; d3_transitionPrototype.select = function(selector) { var id = this.id, subgroups = [], subgroup, subnode, node; selector = d3_selection_selector(selector); for (var j = -1, m = this.length; ++j < m; ) { subgroups.push(subgroup = []); for (var group = this[j], i = -1, n = group.length; ++i < n; ) { if ((node = group[i]) && (subnode = selector.call(node, node.__data__, i, j))) { if (""__data__"" in node) subnode.__data__ = node.__data__; d3_transitionNode(subnode, i, id, node.__transition__[id]); subgroup.push(subnode); } else { subgroup.push(null); } } } return d3_transition(subgroups, id); }; d3_transitionPrototype.selectAll = function(selector) { var id = this.id, subgroups = [], subgroup, subnodes, node, subnode, transition; selector = d3_selection_selectorAll(selector); for (var j = -1, m = this.length; ++j < m; ) { for (var group = this[j], i = -1, n = group.length; ++i < n; ) { if (node = group[i]) { transition = node.__transition__[id]; subnodes = selector.call(node, node.__data__, i, j); subgroups.push(subgroup = []); for (var k = -1, o = subnodes.length; ++k < o; ) { if (subnode = subnodes[k]) d3_transitionNode(subnode, k, id, transition); subgroup.push(subnode); } } } } return d3_transition(subgroups, id); }; d3_transitionPrototype.filter = function(filter) { var subgroups = [], subgroup, group, node; if (typeof filter !== ""function"") filter = d3_selection_filter(filter); for (var j = 0, m = this.length; j < m; j++) { subgroups.push(subgroup = []); for (var group = this[j], i = 0, n = group.length; i < n; i++) { if ((node = group[i]) && filter.call(node, node.__data__, i, j)) { subgroup.push(node); } } } return d3_transition(subgroups, this.id); }; d3_transitionPrototype.tween = function(name, tween) { var id = this.id; if (arguments.length < 2) return this.node().__transition__[id].tween.get(name); return d3_selection_each(this, tween == null ? function(node) { node.__transition__[id].tween.remove(name); } : function(node) { node.__transition__[id].tween.set(name, tween); }); }; function d3_transition_tween(groups, name, value, tween) { var id = groups.id; return d3_selection_each(groups, typeof value === ""function"" ? function(node, i, j) { node.__transition__[id].tween.set(name, tween(value.call(node, node.__data__, i, j))); } : (value = tween(value), function(node) { node.__transition__[id].tween.set(name, value); })); } d3_transitionPrototype.attr = function(nameNS, value) { if (arguments.length < 2) { for (value in nameNS) this.attr(value, nameNS[value]); return this; } var interpolate = nameNS == ""transform"" ? d3_interpolateTransform : d3_interpolate, name = d3.ns.qualify(nameNS); function attrNull() { this.removeAttribute(name); } function attrNullNS() { this.removeAttributeNS(name.space, name.local); } function attrTween(b) { return b == null ? attrNull : (b += """", function() { var a = this.getAttribute(name), i; return a !== b && (i = interpolate(a, b), function(t) { this.setAttribute(name, i(t)); }); }); } function attrTweenNS(b) { return b == null ? attrNullNS : (b += """", function() { var a = this.getAttributeNS(name.space, name.local), i; return a !== b && (i = interpolate(a, b), function(t) { this.setAttributeNS(name.space, name.local, i(t)); }); }); } return d3_transition_tween(this, ""attr."" + nameNS, value, name.local ? attrTweenNS : attrTween); }; d3_transitionPrototype.attrTween = function(nameNS, tween) { var name = d3.ns.qualify(nameNS); function attrTween(d, i) { var f = tween.call(this, d, i, this.getAttribute(name)); return f && function(t) { this.setAttribute(name, f(t)); }; } function attrTweenNS(d, i) { var f = tween.call(this, d, i, this.getAttributeNS(name.space, name.local)); return f && function(t) { this.setAttributeNS(name.space, name.local, f(t)); }; } return this.tween(""attr."" + nameNS, name.local ? attrTweenNS : attrTween); }; d3_transitionPrototype.style = function(name, value, priority) { var n = arguments.length; if (n < 3) { if (typeof name !== ""string"") { if (n < 2) value = """"; for (priority in name) this.style(priority, name[priority], value); return this; } priority = """"; } function styleNull() { this.style.removeProperty(name); } function styleString(b) { return b == null ? styleNull : (b += """", function() { var a = d3_window.getComputedStyle(this, null).getPropertyValue(name), i; return a !== b && (i = d3_interpolate(a, b), function(t) { this.style.setProperty(name, i(t), priority); }); }); } return d3_transition_tween(this, ""style."" + name, value, styleString); }; d3_transitionPrototype.styleTween = function(name, tween, priority) { if (arguments.length < 3) priority = """"; function styleTween(d, i) { var f = tween.call(this, d, i, d3_window.getComputedStyle(this, null).getPropertyValue(name)); return f && function(t) { this.style.setProperty(name, f(t), priority); }; } return this.tween(""style."" + name, styleTween); }; d3_transitionPrototype.text = function(value) { return d3_transition_tween(this, ""text"", value, d3_transition_text); }; function d3_transition_text(b) { if (b == null) b = """"; return function() { this.textContent = b; }; } d3_transitionPrototype.remove = function() { return this.each(""end.transition"", function() { var p; if (this.__transition__.count < 2 && (p = this.parentNode)) p.removeChild(this); }); }; d3_transitionPrototype.ease = function(value) { var id = this.id; if (arguments.length < 1) return this.node().__transition__[id].ease; if (typeof value !== ""function"") value = d3.ease.apply(d3, arguments); return d3_selection_each(this, function(node) { node.__transition__[id].ease = value; }); }; d3_transitionPrototype.delay = function(value) { var id = this.id; if (arguments.length < 1) return this.node().__transition__[id].delay; return d3_selection_each(this, typeof value === ""function"" ? function(node, i, j) { node.__transition__[id].delay = +value.call(node, node.__data__, i, j); } : (value = +value, function(node) { node.__transition__[id].delay = value; })); }; d3_transitionPrototype.duration = function(value) { var id = this.id; if (arguments.length < 1) return this.node().__transition__[id].duration; return d3_selection_each(this, typeof value === ""function"" ? function(node, i, j) { node.__transition__[id].duration = Math.max(1, value.call(node, node.__data__, i, j)); } : (value = Math.max(1, value), function(node) { node.__transition__[id].duration = value; })); }; d3_transitionPrototype.each = function(type, listener) { var id = this.id; if (arguments.length < 2) { var inherit = d3_transitionInherit, inheritId = d3_transitionInheritId; d3_transitionInheritId = id; d3_selection_each(this, function(node, i, j) { d3_transitionInherit = node.__transition__[id]; type.call(node, node.__data__, i, j); }); d3_transitionInherit = inherit; d3_transitionInheritId = inheritId; } else { d3_selection_each(this, function(node) { var transition = node.__transition__[id]; (transition.event || (transition.event = d3.dispatch(""start"", ""end""))).on(type, listener); }); } return this; }; d3_transitionPrototype.transition = function() { var id0 = this.id, id1 = ++d3_transitionId, subgroups = [], subgroup, group, node, transition; for (var j = 0, m = this.length; j < m; j++) { subgroups.push(subgroup = []); for (var group = this[j], i = 0, n = group.length; i < n; i++) { if (node = group[i]) { transition = Object.create(node.__transition__[id0]); transition.delay += transition.duration; d3_transitionNode(node, i, id1, transition); } subgroup.push(node); } } return d3_transition(subgroups, id1); }; function d3_transitionNode(node, i, id, inherit) { var lock = node.__transition__ || (node.__transition__ = { active: 0, count: 0 }), transition = lock[id]; if (!transition) { var time = inherit.time; transition = lock[id] = { tween: new d3_Map(), time: time, ease: inherit.ease, delay: inherit.delay, duration: inherit.duration }; ++lock.count; d3.timer(function(elapsed) { var d = node.__data__, ease = transition.ease, delay = transition.delay, duration = transition.duration, timer = d3_timer_active, tweened = []; timer.t = delay + time; if (delay <= elapsed) return start(elapsed - delay); timer.c = start; function start(elapsed) { if (lock.active > id) return stop(); lock.active = id; transition.event && transition.event.start.call(node, d, i); transition.tween.forEach(function(key, value) { if (value = value.call(node, d, i)) { tweened.push(value); } }); d3.timer(function() { timer.c = tick(elapsed || 1) ? d3_true : tick; return 1; }, 0, time); } function tick(elapsed) { if (lock.active !== id) return stop(); var t = elapsed / duration, e = ease(t), n = tweened.length; while (n > 0) { tweened[--n].call(node, e); } if (t >= 1) { transition.event && transition.event.end.call(node, d, i); return stop(); } } function stop() { if (--lock.count) delete lock[id]; else delete node.__transition__; return 1; } }, 0, time); } } d3.svg.axis = function() { var scale = d3.scale.linear(), orient = d3_svg_axisDefaultOrient, innerTickSize = 6, outerTickSize = 6, tickPadding = 3, tickArguments_ = [ 10 ], tickValues = null, tickFormat_; function axis(g) { g.each(function() { var g = d3.select(this); var scale0 = this.__chart__ || scale, scale1 = this.__chart__ = scale.copy(); var ticks = tickValues == null ? scale1.ticks ? scale1.ticks.apply(scale1, tickArguments_) : scale1.domain() : tickValues, tickFormat = tickFormat_ == null ? scale1.tickFormat ? scale1.tickFormat.apply(scale1, tickArguments_) : d3_identity : tickFormat_, tick = g.selectAll("".tick"").data(ticks, scale1), tickEnter = tick.enter().insert(""g"", "".domain"").attr(""class"", ""tick"").style(""opacity"", ε), tickExit = d3.transition(tick.exit()).style(""opacity"", ε).remove(), tickUpdate = d3.transition(tick.order()).style(""opacity"", 1), tickTransform; var range = d3_scaleRange(scale1), path = g.selectAll("".domain"").data([ 0 ]), pathUpdate = (path.enter().append(""path"").attr(""class"", ""domain""), d3.transition(path)); tickEnter.append(""line""); tickEnter.append(""text""); var lineEnter = tickEnter.select(""line""), lineUpdate = tickUpdate.select(""line""), text = tick.select(""text"").text(tickFormat), textEnter = tickEnter.select(""text""), textUpdate = tickUpdate.select(""text""); switch (orient) { case ""bottom"": { tickTransform = d3_svg_axisX; lineEnter.attr(""y2"", innerTickSize); textEnter.attr(""y"", Math.max(innerTickSize, 0) + tickPadding); lineUpdate.attr(""x2"", 0).attr(""y2"", innerTickSize); textUpdate.attr(""x"", 0).attr(""y"", Math.max(innerTickSize, 0) + tickPadding); text.attr(""dy"", "".71em"").style(""text-anchor"", ""middle""); pathUpdate.attr(""d"", ""M"" + range[0] + "","" + outerTickSize + ""V0H"" + range[1] + ""V"" + outerTickSize); break; } case ""top"": { tickTransform = d3_svg_axisX; lineEnter.attr(""y2"", -innerTickSize); textEnter.attr(""y"", -(Math.max(innerTickSize, 0) + tickPadding)); lineUpdate.attr(""x2"", 0).attr(""y2"", -innerTickSize); textUpdate.attr(""x"", 0).attr(""y"", -(Math.max(innerTickSize, 0) + tickPadding)); text.attr(""dy"", ""0em"").style(""text-anchor"", ""middle""); pathUpdate.attr(""d"", ""M"" + range[0] + "","" + -outerTickSize + ""V0H"" + range[1] + ""V"" + -outerTickSize); break; } case ""left"": { tickTransform = d3_svg_axisY; lineEnter.attr(""x2"", -innerTickSize); textEnter.attr(""x"", -(Math.max(innerTickSize, 0) + tickPadding)); lineUpdate.attr(""x2"", -innerTickSize).attr(""y2"", 0); textUpdate.attr(""x"", -(Math.max(innerTickSize, 0) + tickPadding)).attr(""y"", 0); text.attr(""dy"", "".32em"").style(""text-anchor"", ""end""); pathUpdate.attr(""d"", ""M"" + -outerTickSize + "","" + range[0] + ""H0V"" + range[1] + ""H"" + -outerTickSize); break; } case ""right"": { tickTransform = d3_svg_axisY; lineEnter.attr(""x2"", innerTickSize); textEnter.attr(""x"", Math.max(innerTickSize, 0) + tickPadding); lineUpdate.attr(""x2"", innerTickSize).attr(""y2"", 0); textUpdate.attr(""x"", Math.max(innerTickSize, 0) + tickPadding).attr(""y"", 0); text.attr(""dy"", "".32em"").style(""text-anchor"", ""start""); pathUpdate.attr(""d"", ""M"" + outerTickSize + "","" + range[0] + ""H0V"" + range[1] + ""H"" + outerTickSize); break; } } if (scale1.rangeBand) { var x = scale1, dx = x.rangeBand() / 2; scale0 = scale1 = function(d) { return x(d) + dx; }; } else if (scale0.rangeBand) { scale0 = scale1; } else { tickExit.call(tickTransform, scale1); } tickEnter.call(tickTransform, scale0); tickUpdate.call(tickTransform, scale1); }); } axis.scale = function(x) { if (!arguments.length) return scale; scale = x; return axis; }; axis.orient = function(x) { if (!arguments.length) return orient; orient = x in d3_svg_axisOrients ? x + """" : d3_svg_axisDefaultOrient; return axis; }; axis.ticks = function() { if (!arguments.length) return tickArguments_; tickArguments_ = arguments; return axis; }; axis.tickValues = function(x) { if (!arguments.length) return tickValues; tickValues = x; return axis; }; axis.tickFormat = function(x) { if (!arguments.length) return tickFormat_; tickFormat_ = x; return axis; }; axis.tickSize = function(x) { var n = arguments.length; if (!n) return innerTickSize; innerTickSize = +x; outerTickSize = +arguments[n - 1]; return axis; }; axis.innerTickSize = function(x) { if (!arguments.length) return innerTickSize; innerTickSize = +x; return axis; }; axis.outerTickSize = function(x) { if (!arguments.length) return outerTickSize; outerTickSize = +x; return axis; }; axis.tickPadding = function(x) { if (!arguments.length) return tickPadding; tickPadding = +x; return axis; }; axis.tickSubdivide = function() { return arguments.length && axis; }; return axis; }; var d3_svg_axisDefaultOrient = ""bottom"", d3_svg_axisOrients = { top: 1, right: 1, bottom: 1, left: 1 }; function d3_svg_axisX(selection, x) { selection.attr(""transform"", function(d) { return ""translate("" + x(d) + "",0)""; }); } function d3_svg_axisY(selection, y) { selection.attr(""transform"", function(d) { return ""translate(0,"" + y(d) + "")""; }); } d3.svg.brush = function() { var event = d3_eventDispatch(brush, ""brushstart"", ""brush"", ""brushend""), x = null, y = null, xExtent = [ 0, 0 ], yExtent = [ 0, 0 ], xExtentDomain, yExtentDomain, xClamp = true, yClamp = true, resizes = d3_svg_brushResizes[0]; function brush(g) { g.each(function() { var g = d3.select(this).style(""pointer-events"", ""all"").style(""-webkit-tap-highlight-color"", ""rgba(0,0,0,0)"").on(""mousedown.brush"", brushstart).on(""touchstart.brush"", brushstart); var background = g.selectAll("".background"").data([ 0 ]); background.enter().append(""rect"").attr(""class"", ""background"").style(""visibility"", ""hidden"").style(""cursor"", ""crosshair""); g.selectAll("".extent"").data([ 0 ]).enter().append(""rect"").attr(""class"", ""extent"").style(""cursor"", ""move""); var resize = g.selectAll("".resize"").data(resizes, d3_identity); resize.exit().remove(); resize.enter().append(""g"").attr(""class"", function(d) { return ""resize "" + d; }).style(""cursor"", function(d) { return d3_svg_brushCursor[d]; }).append(""rect"").attr(""x"", function(d) { return /[ew]$/.test(d) ? -3 : null; }).attr(""y"", function(d) { return /^[ns]/.test(d) ? -3 : null; }).attr(""width"", 6).attr(""height"", 6).style(""visibility"", ""hidden""); resize.style(""display"", brush.empty() ? ""none"" : null); var gUpdate = d3.transition(g), backgroundUpdate = d3.transition(background), range; if (x) { range = d3_scaleRange(x); backgroundUpdate.attr(""x"", range[0]).attr(""width"", range[1] - range[0]); redrawX(gUpdate); } if (y) { range = d3_scaleRange(y); backgroundUpdate.attr(""y"", range[0]).attr(""height"", range[1] - range[0]); redrawY(gUpdate); } redraw(gUpdate); }); } brush.event = function(g) { g.each(function() { var event_ = event.of(this, arguments), extent1 = { x: xExtent, y: yExtent, i: xExtentDomain, j: yExtentDomain }, extent0 = this.__chart__ || extent1; this.__chart__ = extent1; if (d3_transitionInheritId) { d3.select(this).transition().each(""start.brush"", function() { xExtentDomain = extent0.i; yExtentDomain = extent0.j; xExtent = extent0.x; yExtent = extent0.y; event_({ type: ""brushstart"" }); }).tween(""brush:brush"", function() { var xi = d3_interpolateArray(xExtent, extent1.x), yi = d3_interpolateArray(yExtent, extent1.y); xExtentDomain = yExtentDomain = null; return function(t) { xExtent = extent1.x = xi(t); yExtent = extent1.y = yi(t); event_({ type: ""brush"", mode: ""resize"" }); }; }).each(""end.brush"", function() { xExtentDomain = extent1.i; yExtentDomain = extent1.j; event_({ type: ""brush"", mode: ""resize"" }); event_({ type: ""brushend"" }); }); } else { event_({ type: ""brushstart"" }); event_({ type: ""brush"", mode: ""resize"" }); event_({ type: ""brushend"" }); } }); }; function redraw(g) { g.selectAll("".resize"").attr(""transform"", function(d) { return ""translate("" + xExtent[+/e$/.test(d)] + "","" + yExtent[+/^s/.test(d)] + "")""; }); } function redrawX(g) { g.select("".extent"").attr(""x"", xExtent[0]); g.selectAll("".extent,.n>rect,.s>rect"").attr(""width"", xExtent[1] - xExtent[0]); } function redrawY(g) { g.select("".extent"").attr(""y"", yExtent[0]); g.selectAll("".extent,.e>rect,.w>rect"").attr(""height"", yExtent[1] - yExtent[0]); } function brushstart() { var target = this, eventTarget = d3.select(d3.event.target), event_ = event.of(target, arguments), g = d3.select(target), resizing = eventTarget.datum(), resizingX = !/^(n|s)$/.test(resizing) && x, resizingY = !/^(e|w)$/.test(resizing) && y, dragging = eventTarget.classed(""extent""), dragRestore = d3_event_dragSuppress(), center, origin = d3.mouse(target), offset; var w = d3.select(d3_window).on(""keydown.brush"", keydown).on(""keyup.brush"", keyup); if (d3.event.changedTouches) { w.on(""touchmove.brush"", brushmove).on(""touchend.brush"", brushend); } else { w.on(""mousemove.brush"", brushmove).on(""mouseup.brush"", brushend); } g.interrupt().selectAll(""*"").interrupt(); if (dragging) { origin[0] = xExtent[0] - origin[0]; origin[1] = yExtent[0] - origin[1]; } else if (resizing) { var ex = +/w$/.test(resizing), ey = +/^n/.test(resizing); offset = [ xExtent[1 - ex] - origin[0], yExtent[1 - ey] - origin[1] ]; origin[0] = xExtent[ex]; origin[1] = yExtent[ey]; } else if (d3.event.altKey) center = origin.slice(); g.style(""pointer-events"", ""none"").selectAll("".resize"").style(""display"", null); d3.select(""body"").style(""cursor"", eventTarget.style(""cursor"")); event_({ type: ""brushstart"" }); brushmove(); function keydown() { if (d3.event.keyCode == 32) { if (!dragging) { center = null; origin[0] -= xExtent[1]; origin[1] -= yExtent[1]; dragging = 2; } d3_eventPreventDefault(); } } function keyup() { if (d3.event.keyCode == 32 && dragging == 2) { origin[0] += xExtent[1]; origin[1] += yExtent[1]; dragging = 0; d3_eventPreventDefault(); } } function brushmove() { var point = d3.mouse(target), moved = false; if (offset) { point[0] += offset[0]; point[1] += offset[1]; } if (!dragging) { if (d3.event.altKey) { if (!center) center = [ (xExtent[0] + xExtent[1]) / 2, (yExtent[0] + yExtent[1]) / 2 ]; origin[0] = xExtent[+(point[0] < center[0])]; origin[1] = yExtent[+(point[1] < center[1])]; } else center = null; } if (resizingX && move1(point, x, 0)) { redrawX(g); moved = true; } if (resizingY && move1(point, y, 1)) { redrawY(g); moved = true; } if (moved) { redraw(g); event_({ type: ""brush"", mode: dragging ? ""move"" : ""resize"" }); } } function move1(point, scale, i) { var range = d3_scaleRange(scale), r0 = range[0], r1 = range[1], position = origin[i], extent = i ? yExtent : xExtent, size = extent[1] - extent[0], min, max; if (dragging) { r0 -= position; r1 -= size + position; } min = (i ? yClamp : xClamp) ? Math.max(r0, Math.min(r1, point[i])) : point[i]; if (dragging) { max = (min += position) + size; } else { if (center) position = Math.max(r0, Math.min(r1, 2 * center[i] - min)); if (position < min) { max = min; min = position; } else { max = position; } } if (extent[0] != min || extent[1] != max) { if (i) yExtentDomain = null; else xExtentDomain = null; extent[0] = min; extent[1] = max; return true; } } function brushend() { brushmove(); g.style(""pointer-events"", ""all"").selectAll("".resize"").style(""display"", brush.empty() ? ""none"" : null); d3.select(""body"").style(""cursor"", null); w.on(""mousemove.brush"", null).on(""mouseup.brush"", null).on(""touchmove.brush"", null).on(""touchend.brush"", null).on(""keydown.brush"", null).on(""keyup.brush"", null); dragRestore(); event_({ type: ""brushend"" }); } } brush.x = function(z) { if (!arguments.length) return x; x = z; resizes = d3_svg_brushResizes[!x << 1 | !y]; return brush; }; brush.y = function(z) { if (!arguments.length) return y; y = z; resizes = d3_svg_brushResizes[!x << 1 | !y]; return brush; }; brush.clamp = function(z) { if (!arguments.length) return x && y ? [ xClamp, yClamp ] : x ? xClamp : y ? yClamp : null; if (x && y) xClamp = !!z[0], yClamp = !!z[1]; else if (x) xClamp = !!z; else if (y) yClamp = !!z; return brush; }; brush.extent = function(z) { var x0, x1, y0, y1, t; if (!arguments.length) { if (x) { if (xExtentDomain) { x0 = xExtentDomain[0], x1 = xExtentDomain[1]; } else { x0 = xExtent[0], x1 = xExtent[1]; if (x.invert) x0 = x.invert(x0), x1 = x.invert(x1); if (x1 < x0) t = x0, x0 = x1, x1 = t; } } if (y) { if (yExtentDomain) { y0 = yExtentDomain[0], y1 = yExtentDomain[1]; } else { y0 = yExtent[0], y1 = yExtent[1]; if (y.invert) y0 = y.invert(y0), y1 = y.invert(y1); if (y1 < y0) t = y0, y0 = y1, y1 = t; } } return x && y ? [ [ x0, y0 ], [ x1, y1 ] ] : x ? [ x0, x1 ] : y && [ y0, y1 ]; } if (x) { x0 = z[0], x1 = z[1]; if (y) x0 = x0[0], x1 = x1[0]; xExtentDomain = [ x0, x1 ]; if (x.invert) x0 = x(x0), x1 = x(x1); if (x1 < x0) t = x0, x0 = x1, x1 = t; if (x0 != xExtent[0] || x1 != xExtent[1]) xExtent = [ x0, x1 ]; } if (y) { y0 = z[0], y1 = z[1]; if (x) y0 = y0[1], y1 = y1[1]; yExtentDomain = [ y0, y1 ]; if (y.invert) y0 = y(y0), y1 = y(y1); if (y1 < y0) t = y0, y0 = y1, y1 = t; if (y0 != yExtent[0] || y1 != yExtent[1]) yExtent = [ y0, y1 ]; } return brush; }; brush.clear = function() { if (!brush.empty()) { xExtent = [ 0, 0 ], yExtent = [ 0, 0 ]; xExtentDomain = yExtentDomain = null; } return brush; }; brush.empty = function() { return !!x && xExtent[0] == xExtent[1] || !!y && yExtent[0] == yExtent[1]; }; return d3.rebind(brush, event, ""on""); }; var d3_svg_brushCursor = { n: ""ns-resize"", e: ""ew-resize"", s: ""ns-resize"", w: ""ew-resize"", nw: ""nwse-resize"", ne: ""nesw-resize"", se: ""nwse-resize"", sw: ""nesw-resize"" }; var d3_svg_brushResizes = [ [ ""n"", ""e"", ""s"", ""w"", ""nw"", ""ne"", ""se"", ""sw"" ], [ ""e"", ""w"" ], [ ""n"", ""s"" ], [] ]; var d3_time_format = d3_time.format = d3_locale_enUS.timeFormat; var d3_time_formatUtc = d3_time_format.utc; var d3_time_formatIso = d3_time_formatUtc(""%Y-%m-%dT%H:%M:%S.%LZ""); d3_time_format.iso = Date.prototype.toISOString && +new Date(""2000-01-01T00:00:00.000Z"") ? d3_time_formatIsoNative : d3_time_formatIso; function d3_time_formatIsoNative(date) { return date.toISOString(); } d3_time_formatIsoNative.parse = function(string) { var date = new Date(string); return isNaN(date) ? null : date; }; d3_time_formatIsoNative.toString = d3_time_formatIso.toString; d3_time.second = d3_time_interval(function(date) { return new d3_date(Math.floor(date / 1e3) * 1e3); }, function(date, offset) { date.setTime(date.getTime() + Math.floor(offset) * 1e3); }, function(date) { return date.getSeconds(); }); d3_time.seconds = d3_time.second.range; d3_time.seconds.utc = d3_time.second.utc.range; d3_time.minute = d3_time_interval(function(date) { return new d3_date(Math.floor(date / 6e4) * 6e4); }, function(date, offset) { date.setTime(date.getTime() + Math.floor(offset) * 6e4); }, function(date) { return date.getMinutes(); }); d3_time.minutes = d3_time.minute.range; d3_time.minutes.utc = d3_time.minute.utc.range; d3_time.hour = d3_time_interval(function(date) { var timezone = date.getTimezoneOffset() / 60; return new d3_date((Math.floor(date / 36e5 - timezone) + timezone) * 36e5); }, function(date, offset) { date.setTime(date.getTime() + Math.floor(offset) * 36e5); }, function(date) { return date.getHours(); }); d3_time.hours = d3_time.hour.range; d3_time.hours.utc = d3_time.hour.utc.range; d3_time.month = d3_time_interval(function(date) { date = d3_time.day(date); date.setDate(1); return date; }, function(date, offset) { date.setMonth(date.getMonth() + offset); }, function(date) { return date.getMonth(); }); d3_time.months = d3_time.month.range; d3_time.months.utc = d3_time.month.utc.range; function d3_time_scale(linear, methods, format) { function scale(x) { return linear(x); } scale.invert = function(x) { return d3_time_scaleDate(linear.invert(x)); }; scale.domain = function(x) { if (!arguments.length) return linear.domain().map(d3_time_scaleDate); linear.domain(x); return scale; }; function tickMethod(extent, count) { var span = extent[1] - extent[0], target = span / count, i = d3.bisect(d3_time_scaleSteps, target); return i == d3_time_scaleSteps.length ? [ methods.year, d3_scale_linearTickRange(extent.map(function(d) { return d / 31536e6; }), count)[2] ] : !i ? [ d3_time_scaleMilliseconds, d3_scale_linearTickRange(extent, count)[2] ] : methods[target / d3_time_scaleSteps[i - 1] < d3_time_scaleSteps[i] / target ? i - 1 : i]; } scale.nice = function(interval, skip) { var domain = scale.domain(), extent = d3_scaleExtent(domain), method = interval == null ? tickMethod(extent, 10) : typeof interval === ""number"" && tickMethod(extent, interval); if (method) interval = method[0], skip = method[1]; function skipped(date) { return !isNaN(date) && !interval.range(date, d3_time_scaleDate(+date + 1), skip).length; } return scale.domain(d3_scale_nice(domain, skip > 1 ? { floor: function(date) { while (skipped(date = interval.floor(date))) date = d3_time_scaleDate(date - 1); return date; }, ceil: function(date) { while (skipped(date = interval.ceil(date))) date = d3_time_scaleDate(+date + 1); return date; } } : interval)); }; scale.ticks = function(interval, skip) { var extent = d3_scaleExtent(scale.domain()), method = interval == null ? tickMethod(extent, 10) : typeof interval === ""number"" ? tickMethod(extent, interval) : !interval.range && [ { range: interval }, skip ]; if (method) interval = method[0], skip = method[1]; return interval.range(extent[0], d3_time_scaleDate(+extent[1] + 1), skip < 1 ? 1 : skip); }; scale.tickFormat = function() { return format; }; scale.copy = function() { return d3_time_scale(linear.copy(), methods, format); }; return d3_scale_linearRebind(scale, linear); } function d3_time_scaleDate(t) { return new Date(t); } var d3_time_scaleSteps = [ 1e3, 5e3, 15e3, 3e4, 6e4, 3e5, 9e5, 18e5, 36e5, 108e5, 216e5, 432e5, 864e5, 1728e5, 6048e5, 2592e6, 7776e6, 31536e6 ]; var d3_time_scaleLocalMethods = [ [ d3_time.second, 1 ], [ d3_time.second, 5 ], [ d3_time.second, 15 ], [ d3_time.second, 30 ], [ d3_time.minute, 1 ], [ d3_time.minute, 5 ], [ d3_time.minute, 15 ], [ d3_time.minute, 30 ], [ d3_time.hour, 1 ], [ d3_time.hour, 3 ], [ d3_time.hour, 6 ], [ d3_time.hour, 12 ], [ d3_time.day, 1 ], [ d3_time.day, 2 ], [ d3_time.week, 1 ], [ d3_time.month, 1 ], [ d3_time.month, 3 ], [ d3_time.year, 1 ] ]; var d3_time_scaleLocalFormat = d3_time_format.multi([ [ "".%L"", function(d) { return d.getMilliseconds(); } ], [ "":%S"", function(d) { return d.getSeconds(); } ], [ ""%I:%M"", function(d) { return d.getMinutes(); } ], [ ""%I %p"", function(d) { return d.getHours(); } ], [ ""%a %d"", function(d) { return d.getDay() && d.getDate() != 1; } ], [ ""%b %d"", function(d) { return d.getDate() != 1; } ], [ ""%B"", function(d) { return d.getMonth(); } ], [ ""%Y"", d3_true ] ]); var d3_time_scaleMilliseconds = { range: function(start, stop, step) { return d3.range(Math.ceil(start / step) * step, +stop, step).map(d3_time_scaleDate); }, floor: d3_identity, ceil: d3_identity }; d3_time_scaleLocalMethods.year = d3_time.year; d3_time.scale = function() { return d3_time_scale(d3.scale.linear(), d3_time_scaleLocalMethods, d3_time_scaleLocalFormat); }; var d3_time_scaleUtcMethods = d3_time_scaleLocalMethods.map(function(m) { return [ m[0].utc, m[1] ]; }); var d3_time_scaleUtcFormat = d3_time_formatUtc.multi([ [ "".%L"", function(d) { return d.getUTCMilliseconds(); } ], [ "":%S"", function(d) { return d.getUTCSeconds(); } ], [ ""%I:%M"", function(d) { return d.getUTCMinutes(); } ], [ ""%I %p"", function(d) { return d.getUTCHours(); } ], [ ""%a %d"", function(d) { return d.getUTCDay() && d.getUTCDate() != 1; } ], [ ""%b %d"", function(d) { return d.getUTCDate() != 1; } ], [ ""%B"", function(d) { return d.getUTCMonth(); } ], [ ""%Y"", d3_true ] ]); d3_time_scaleUtcMethods.year = d3_time.year.utc; d3_time.scale.utc = function() { return d3_time_scale(d3.scale.linear(), d3_time_scaleUtcMethods, d3_time_scaleUtcFormat); }; d3.text = d3_xhrType(function(request) { return request.responseText; }); d3.json = function(url, callback) { return d3_xhr(url, ""application/json"", d3_json, callback); }; function d3_json(request) { return JSON.parse(request.responseText); } d3.html = function(url, callback) { return d3_xhr(url, ""text/html"", d3_html, callback); }; function d3_html(request) { var range = d3_document.createRange(); range.selectNode(d3_document.body); return range.createContextualFragment(request.responseText); } d3.xml = d3_xhrType(function(request) { return request.responseXML; }); if (typeof define === ""function"" && define.amd) { define(d3); } else if (typeof module === ""object"" && module.exports) { module.exports = d3; } else { this.d3 = d3; } }();",,15469,0
openstack%2Ftripleo-ci~master~Iabaf3e73dfc6aafbd9f57cee62e5b662234d74b7,openstack/tripleo-ci,master,Iabaf3e73dfc6aafbd9f57cee62e5b662234d74b7,Make scenario003-standalone job voting,MERGED,2019-01-03 19:30:03.000000000,2019-01-07 10:25:43.000000000,2019-01-07 10:25:43.000000000,"[{'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-03 19:30:03.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/285f245ea28cc03f899fb074c9d3306dacf3365c', 'message': 'Make scenario003-standalone job voting\n\nscen3 standalone is pretty stable:\nhttp://zuul.openstack.org/builds?job_name=tripleo-ci-centos-7-scenario003-standalone\n\nChange-Id: Iabaf3e73dfc6aafbd9f57cee62e5b662234d74b7\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/533\n'}]",0,628273,285f245ea28cc03f899fb074c9d3306dacf3365c,9,5,1,8175,,,0,"Make scenario003-standalone job voting

scen3 standalone is pretty stable:
http://zuul.openstack.org/builds?job_name=tripleo-ci-centos-7-scenario003-standalone

Change-Id: Iabaf3e73dfc6aafbd9f57cee62e5b662234d74b7
Story: https://tree.taiga.io/project/tripleo-ci-board/us/533
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/73/628273/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,285f245ea28cc03f899fb074c9d3306dacf3365c,replace-scen3, voting: true, voting: false,1,1
openstack%2Fpython-cyborgclient~feature%2Fcyborg-nova-pilot~I98b68ff4be3896c294eacd9105b2ef31a204506a,openstack/python-cyborgclient,feature/cyborg-nova-pilot,I98b68ff4be3896c294eacd9105b2ef31a204506a,Enable v2 version and set it as default.,NEW,2019-01-07 10:01:52.000000000,2019-01-07 10:16:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-07 10:01:52.000000000', 'files': ['cyborgclient/__init__.py', 'cyborgclient/common/httpclient.py', 'cyborgclient/osc/plugin.py', 'cyborgclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/134c2e7a65207da3616cf58ff188de81de467664', 'message': 'Enable v2 version and set it as default.\n\nChange-Id: I98b68ff4be3896c294eacd9105b2ef31a204506a\n'}]",0,628924,134c2e7a65207da3616cf58ff188de81de467664,2,1,1,21672,,,0,"Enable v2 version and set it as default.

Change-Id: I98b68ff4be3896c294eacd9105b2ef31a204506a
",git fetch https://review.opendev.org/openstack/python-cyborgclient refs/changes/24/628924/1 && git format-patch -1 --stdout FETCH_HEAD,"['cyborgclient/__init__.py', 'cyborgclient/common/httpclient.py', 'cyborgclient/osc/plugin.py', 'cyborgclient/shell.py']",4,134c2e7a65207da3616cf58ff188de81de467664,,"from cyborgclient.v2 import client as client_v2 from cyborgclient.v2 import shell as shell_v2LATEST_API_VERSION = ('2', 'latest') '1': shell_v1.COMMAND_MODULES, '2': shell_v2.COMMAND_MODULES actions_modules = shell_v2.COMMAND_MODULES # Default value of cyborg_api_version is LATEST_API_VERSION. cyborg_api_version = LATEST_API_VERSION '2': client_v2, client = client_v2","LATEST_API_VERSION = ('1', 'latest') '1': shell_v1.COMMAND_MODULES actions_modules = shell_v1.COMMAND_MODULES # Default value of cyborg_api_version is '1'. cyborg_api_version = None client = client_v1",18,13
openstack%2Fhorizon~master~I93251d6d12cf89a331b5c051bf4fe10a6e470f51,openstack/horizon,master,I93251d6d12cf89a331b5c051bf4fe10a6e470f51,Changed the message level for deleting some resources to info,MERGED,2019-01-03 05:49:43.000000000,2019-01-07 10:12:08.000000000,2019-01-07 10:12:08.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27658}]","[{'number': 1, 'created': '2019-01-03 05:49:43.000000000', 'files': ['openstack_dashboard/dashboards/project/images/images/tables.py', 'horizon/tables/actions.py', 'openstack_dashboard/dashboards/project/volumes/tables.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2a3b04ce6cf4e3a48b893a4ee2dc9f8f246938b1', 'message': 'Changed the message level for deleting some resources to info\n\nAdded functionality to the handle function in the BatchAction class\nin action.py and allowed the easy changing between the alert types\nand made deleting images, instances, and volumes give an info alert\nrather than a success message and altered the testing parameters\n\nChange-Id: I93251d6d12cf89a331b5c051bf4fe10a6e470f51\nCloses-Bug: #1291681\n'}]",2,628103,2a3b04ce6cf4e3a48b893a4ee2dc9f8f246938b1,8,5,1,10420,,,0,"Changed the message level for deleting some resources to info

Added functionality to the handle function in the BatchAction class
in action.py and allowed the easy changing between the alert types
and made deleting images, instances, and volumes give an info alert
rather than a success message and altered the testing parameters

Change-Id: I93251d6d12cf89a331b5c051bf4fe10a6e470f51
Closes-Bug: #1291681
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/628103/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/images/images/tables.py', 'horizon/tables/actions.py', 'openstack_dashboard/dashboards/project/volumes/tables.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py']",5,2a3b04ce6cf4e3a48b893a4ee2dc9f8f246938b1,bug/1291681," default_message_level = ""info""",,6,3
openstack%2Fpython-cyborgclient~feature%2Fcyborg-nova-pilot~I498c9763ffa4f1d5bb069fca9f74d12438485fdc,openstack/python-cyborgclient,feature/cyborg-nova-pilot,I498c9763ffa4f1d5bb069fca9f74d12438485fdc,Disable some old tests so that new code can be added.,NEW,2019-01-07 10:01:52.000000000,2019-01-07 10:11:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-07 10:01:52.000000000', 'files': ['cyborgclient/tests/unit/test_shell.py', 'cyborgclient/tests/unit/common/test_httpclient.py'], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/502875ce5742de7010ab9132b2ff6e324892d111', 'message': 'Disable some old tests so that new code can be added.\n\nChange-Id: I498c9763ffa4f1d5bb069fca9f74d12438485fdc\n'}]",0,628922,502875ce5742de7010ab9132b2ff6e324892d111,2,1,1,21672,,,0,"Disable some old tests so that new code can be added.

Change-Id: I498c9763ffa4f1d5bb069fca9f74d12438485fdc
",git fetch https://review.opendev.org/openstack/python-cyborgclient refs/changes/22/628922/1 && git format-patch -1 --stdout FETCH_HEAD,"['cyborgclient/tests/unit/test_shell.py', 'cyborgclient/tests/unit/common/test_httpclient.py']",2,502875ce5742de7010ab9132b2ff6e324892d111,, def _test_get_connection_params_with_version(self): def _test_get_connection_params_with_version_trailing_slash(self): def _test_get_connection_params_with_subpath_version(self): def _test_get_connection_params_with_subpath_version_trailing_slash(self):, def test_get_connection_params_with_version(self): def test_get_connection_params_with_version_trailing_slash(self): def test_get_connection_params_with_subpath_version(self): def test_get_connection_params_with_subpath_version_trailing_slash(self):,19,19
openstack%2Ftripleo-quickstart~master~Ib83818e0f64a0bff129cad56b2acd91315e08ba0,openstack/tripleo-quickstart,master,Ib83818e0f64a0bff129cad56b2acd91315e08ba0,Replace tripleo-scenario003-multinode with scenario003-standalone,MERGED,2019-01-03 19:42:02.000000000,2019-01-07 10:10:10.000000000,2019-01-07 10:10:10.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-03 19:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/340f474ea0f9989fa25f22ff81d7240a3a275631', 'message': 'Replace tripleo-scenario003-multinode with scenario003-standalone\n\nChange-Id: Ib83818e0f64a0bff129cad56b2acd91315e08ba0\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/533\n'}, {'number': 2, 'created': '2019-01-04 12:47:11.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4a4df7ffa5ec431b68f4a822e8aa33544db669b5', 'message': 'Replace tripleo-scenario003-multinode with scenario003-standalone\n\nChange-Id: Ib83818e0f64a0bff129cad56b2acd91315e08ba0\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/533\n'}]",4,628281,4a4df7ffa5ec431b68f4a822e8aa33544db669b5,15,6,2,8175,,,0,"Replace tripleo-scenario003-multinode with scenario003-standalone

Change-Id: Ib83818e0f64a0bff129cad56b2acd91315e08ba0
Story: https://tree.taiga.io/project/tripleo-ci-board/us/533
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/81/628281/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,340f474ea0f9989fa25f22ff81d7240a3a275631,replace-scen3, - tripleo-ci-centos-7-scenario003-standalone:, - tripleo-ci-centos-7-scenario003-multinode-oooq-container:,1,1
openstack%2Fpython-dracclient~master~I01528a3c52ce08326db1e451af19e29b8f2a40a9,openstack/python-dracclient,master,I01528a3c52ce08326db1e451af19e29b8f2a40a9,Updated comments and removed comments for affected methods,ABANDONED,2019-01-03 09:16:01.000000000,2019-01-07 10:05:35.000000000,,"[{'_account_id': 10250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 09:16:01.000000000', 'files': ['dracclient/client.py', 'dracclient/resources/raid.py', 'dracclient/resources/bios.py'], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/9f0477794325168a1954310b98348191841678d3', 'message': 'Updated comments and removed comments for affected methods\n\nChange-Id: I01528a3c52ce08326db1e451af19e29b8f2a40a9\n'}]",0,628127,9f0477794325168a1954310b98348191841678d3,4,2,1,29405,,,0,"Updated comments and removed comments for affected methods

Change-Id: I01528a3c52ce08326db1e451af19e29b8f2a40a9
",git fetch https://review.opendev.org/openstack/python-dracclient refs/changes/27/628127/1 && git format-patch -1 --stdout FETCH_HEAD,"['dracclient/client.py', 'dracclient/resources/raid.py', 'dracclient/resources/bios.py']",3,9f0477794325168a1954310b98348191841678d3,experimental_upstream_ironic,, - The commit_required key with a boolean value indicating whether a config job must be created for the values to be applied. This key actually has a value that indicates if a reboot is required. This key has been deprecated and will be removed in a future release.,8,33
openstack%2Fcookbook-openstack-ops-database~master~I8efc34c220fec59826bbea51e3ebf3fbc0e5b530,openstack/cookbook-openstack-ops-database,master,I8efc34c220fec59826bbea51e3ebf3fbc0e5b530,Chef 14 stable release updates and fixes,MERGED,2018-12-21 05:45:31.000000000,2019-01-07 10:04:37.000000000,2019-01-07 10:04:37.000000000,"[{'_account_id': 11915}, {'_account_id': 19193}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-21 05:45:31.000000000', 'files': ['spec/openstack-db_spec.rb', 'spec/spec_helper.rb', 'recipes/openstack-db.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/0eec9ecac8e9d92838b3aa26e85a5277e79247c8', 'message': 'Chef 14 stable release updates and fixes\n\nThis change corrects some of the issues with resource naming[1] as well\nas prunes some failing unit tests that would be obsoleted with the changes\nin the service renaming[2].\n\n[1]: https://docs.chef.io/ruby.html#use-of-hyphens\n[2]: https://review.openstack.org/#/q/topic:chef_14_fixes+(status:open+OR+status:merged)\n\nDepends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c\nChange-Id: I8efc34c220fec59826bbea51e3ebf3fbc0e5b530\n'}]",0,626811,0eec9ecac8e9d92838b3aa26e85a5277e79247c8,7,3,1,14790,,,0,"Chef 14 stable release updates and fixes

This change corrects some of the issues with resource naming[1] as well
as prunes some failing unit tests that would be obsoleted with the changes
in the service renaming[2].

[1]: https://docs.chef.io/ruby.html#use-of-hyphens
[2]: https://review.openstack.org/#/q/topic:chef_14_fixes+(status:open+OR+status:merged)

Depends-On: Ic2b6d8f1cdf719791faaebdbd7e29e789eb3f31c
Change-Id: I8efc34c220fec59826bbea51e3ebf3fbc0e5b530
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/11/626811/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/openstack-db_spec.rb', 'spec/spec_helper.rb', 'recipes/openstack-db.rb']",3,0eec9ecac8e9d92838b3aa26e85a5277e79247c8,chef_14_fixes, old_services = %w(baremetal block-storage application-catalog object-storage telemetry-metric) next if old_services.include?(service) username = node['openstack']['db'][service]['username'] user username, user node['openstack']['db'][service]['username'],11,9
openstack%2Ftripleo-heat-templates~stable%2Frocky~I96fd7dfc5468bf1dbdc665b3d848b40223ee9454,openstack/tripleo-heat-templates,stable/rocky,I96fd7dfc5468bf1dbdc665b3d848b40223ee9454,Add missing role_specific tag for NUMA aware vswitches params,MERGED,2019-01-05 09:19:12.000000000,2019-01-07 10:04:08.000000000,2019-01-07 10:04:08.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-05 09:19:12.000000000', 'files': ['puppet/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c2504ed9b2de29d3c86cc363e225aefdbef24a5f', 'message': 'Add missing role_specific tag for NUMA aware vswitches params\n\nChange I318ba9c262f64c0d416a017ed836ae0729acedb4 expose NUMA\naware vswitches configuration parameter, which are role-specific.\n\nThe proposed patch adds role_specific tag for those parameters\nwhich is missed in original patch.\n\nChange-Id: I96fd7dfc5468bf1dbdc665b3d848b40223ee9454\n(cherry picked from commit 90717bdca62ef7408958942efec85c89202a939c)\n'}]",0,628725,c2504ed9b2de29d3c86cc363e225aefdbef24a5f,8,8,1,20733,,,0,"Add missing role_specific tag for NUMA aware vswitches params

Change I318ba9c262f64c0d416a017ed836ae0729acedb4 expose NUMA
aware vswitches configuration parameter, which are role-specific.

The proposed patch adds role_specific tag for those parameters
which is missed in original patch.

Change-Id: I96fd7dfc5468bf1dbdc665b3d848b40223ee9454
(cherry picked from commit 90717bdca62ef7408958942efec85c89202a939c)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/628725/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/nova-compute.yaml'],1,c2504ed9b2de29d3c86cc363e225aefdbef24a5f,missing-role-specific-tag-stable/rocky, tags: - role_specific tags: - role_specific,,4,0
openstack%2Ftacker~master~I1a9132a54b82ab8afa833ebae3621f7597883fb3,openstack/tacker,master,I1a9132a54b82ab8afa833ebae3621f7597883fb3,Remove deprecated note for tacker cli,MERGED,2018-12-06 08:54:21.000000000,2019-01-07 10:02:25.000000000,2019-01-07 10:02:25.000000000,"[{'_account_id': 18955}, {'_account_id': 19644}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 27153}, {'_account_id': 29383}]","[{'number': 1, 'created': '2018-12-06 08:54:21.000000000', 'files': ['doc/source/user/vnffg_usage_guide.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/85d5a4d33024ce222950bff6065d3d0b45985b78', 'message': 'Remove deprecated note for tacker cli\n\nAs Tacker cli already removed from docs, removing reference.\n\nChange-Id: I1a9132a54b82ab8afa833ebae3621f7597883fb3\n'}]",0,623165,85d5a4d33024ce222950bff6065d3d0b45985b78,9,6,1,18955,,,0,"Remove deprecated note for tacker cli

As Tacker cli already removed from docs, removing reference.

Change-Id: I1a9132a54b82ab8afa833ebae3621f7597883fb3
",git fetch https://review.opendev.org/openstack/tacker refs/changes/65/623165/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/vnffg_usage_guide.rst'],1,85d5a4d33024ce222950bff6065d3d0b45985b78,,,".. note:: Deprecated: 'tacker' command line is deprecated, will be deleted after Rocky is released. Please use 'openstack' client command line instead. Read more: https://docs.openstack.org/tacker/latest/admin/index.html ",0,8
openstack%2Ftacker~master~If5b06b7cbf2c46a5f2f82027ba97c7920855d0cd,openstack/tacker,master,If5b06b7cbf2c46a5f2f82027ba97c7920855d0cd,Device Refactor.,MERGED,2018-12-12 12:10:42.000000000,2019-01-07 09:58:15.000000000,2019-01-07 09:58:15.000000000,"[{'_account_id': 16237}, {'_account_id': 18955}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 29383}]","[{'number': 1, 'created': '2018-12-12 12:10:42.000000000', 'files': ['tacker/agent/linux/utils.py', 'tacker/vnfm/mgmt_drivers/noop.py', 'tacker/vnfm/mgmt_drivers/abstract_driver.py', 'tacker/vnfm/infra_drivers/kubernetes/kubernetes_driver.py', 'tacker/vnfm/infra_drivers/openstack/openstack.py', 'setup.cfg', 'tacker/vnfm/infra_drivers/noop.py', 'tacker/vnfm/mgmt_drivers/openwrt/openwrt.py', 'tacker/vnfm/infra_drivers/abstract_driver.py', 'tacker/tests/unit/vnfm/test_monitor.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/0e7b4d31bc76ae5b993b16bf6647f6ac42673ec8', 'message': 'Device Refactor.\n\nRefactor devide with Vnf and clean references and unused code.\n\nChange-Id: If5b06b7cbf2c46a5f2f82027ba97c7920855d0cd\n'}]",0,624682,0e7b4d31bc76ae5b993b16bf6647f6ac42673ec8,11,6,1,18955,,,0,"Device Refactor.

Refactor devide with Vnf and clean references and unused code.

Change-Id: If5b06b7cbf2c46a5f2f82027ba97c7920855d0cd
",git fetch https://review.opendev.org/openstack/tacker refs/changes/82/624682/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/agent/linux/utils.py', 'tacker/vnfm/mgmt_drivers/abstract_driver.py', 'tacker/vnfm/mgmt_drivers/noop.py', 'tacker/vnfm/infra_drivers/kubernetes/kubernetes_driver.py', 'setup.cfg', 'tacker/vnfm/infra_drivers/openstack/openstack.py', 'tacker/vnfm/infra_drivers/noop.py', 'tacker/vnfm/mgmt_drivers/openwrt/openwrt.py', 'tacker/vnfm/infra_drivers/abstract_driver.py', 'tacker/tests/unit/vnfm/test_monitor.py']",10,0e7b4d31bc76ae5b993b16bf6647f6ac42673ec8,,"MOCK_VNF_ID = 'a737497c-761c-11e5-89c3-9cb6541d805d' MOCK_VNF = { 'id': MOCK_VNF_ID, 'id': MOCK_VNF_ID, MOCK_VNF['monitoring_policy']) 'id': MOCK_VNF_ID, 'monitoring_policy': MOCK_VNF['monitoring_policy'] 'id': MOCK_VNF_ID, MOCK_VNF['monitoring_policy']) self.assertEqual(MOCK_VNF_ID, test_vnf_id) test_hosting_vnf = MOCK_VNF","MOCK_DEVICE_ID = 'a737497c-761c-11e5-89c3-9cb6541d805d' MOCK_VNF_DEVICE = { 'id': MOCK_DEVICE_ID, 'id': MOCK_DEVICE_ID, MOCK_VNF_DEVICE['monitoring_policy']) 'id': MOCK_DEVICE_ID, 'monitoring_policy': MOCK_VNF_DEVICE['monitoring_policy'] 'id': MOCK_DEVICE_ID, MOCK_VNF_DEVICE['monitoring_policy']) self.assertEqual(MOCK_DEVICE_ID, test_vnf_id) test_hosting_vnf = MOCK_VNF_DEVICE",22,54
openstack%2Fopenstack-ansible-ops~master~I907d57ffc841e98412ccce95713cb18c4a02c7d3,openstack/openstack-ansible-ops,master,I907d57ffc841e98412ccce95713cb18c4a02c7d3,Destroy VMs instead of shutting down during save,ABANDONED,2018-11-14 15:52:53.000000000,2019-01-07 09:48:02.000000000,,"[{'_account_id': 290}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-14 15:52:53.000000000', 'files': ['multi-node-aio/playbooks/save-vms.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/333049d47af44fb3021bf48123c2999f582f692e', 'message': 'Destroy VMs instead of shutting down during save\n\nWith a regular shutdown, in some cases it appears MariaDB will remove\nthe gvwstate.dat as part of the shutdown.  In order to capture that file\nto rebuild the cluster, turn off the VM instead of shutting down.\n\nChange-Id: I907d57ffc841e98412ccce95713cb18c4a02c7d3\n'}]",0,617990,333049d47af44fb3021bf48123c2999f582f692e,7,3,1,290,,,0,"Destroy VMs instead of shutting down during save

With a regular shutdown, in some cases it appears MariaDB will remove
the gvwstate.dat as part of the shutdown.  In order to capture that file
to rebuild the cluster, turn off the VM instead of shutting down.

Change-Id: I907d57ffc841e98412ccce95713cb18c4a02c7d3
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/90/617990/1 && git format-patch -1 --stdout FETCH_HEAD,['multi-node-aio/playbooks/save-vms.yml'],1,333049d47af44fb3021bf48123c2999f582f692e,destroy_vms, - name: Destroy all running VM's command: destroy, - name: Shut down all running VM's command: shutdown,2,2
openstack%2Fkolla-ansible~master~I7670544f4bc41c93ac1d081486502f9ffb8f2286,openstack/kolla-ansible,master,I7670544f4bc41c93ac1d081486502f9ffb8f2286,Fix ironic inspector dnsmasq listening interface,MERGED,2018-08-06 08:26:36.000000000,2019-01-07 09:42:48.000000000,2018-08-07 07:31:28.000000000,"[{'_account_id': 7488}, {'_account_id': 9820}, {'_account_id': 19316}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-08-06 08:26:36.000000000', 'files': ['ansible/roles/ironic/templates/ironic-dnsmasq.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ea2cda217ed3d3fbb1a829a82509dbfd79622e8d', 'message': ""Fix ironic inspector dnsmasq listening interface\n\nThe variable 'ironic_dnsmasq_interface' is used to configure the interface\nused by the ironic inspector dnsmasq service for DHCP on the inspection\nnetwork. It is being used correctly in inspector.conf, but not in the\ndnsmasq configuration file, which uses api_interface. This change modifies\nthe dnsmasq configuration file to also use ironic_dnsmasq_interface.\n\nChange-Id: I7670544f4bc41c93ac1d081486502f9ffb8f2286\nCloses-Bug: #1785574\n""}]",0,589073,ea2cda217ed3d3fbb1a829a82509dbfd79622e8d,13,8,1,14826,,,0,"Fix ironic inspector dnsmasq listening interface

The variable 'ironic_dnsmasq_interface' is used to configure the interface
used by the ironic inspector dnsmasq service for DHCP on the inspection
network. It is being used correctly in inspector.conf, but not in the
dnsmasq configuration file, which uses api_interface. This change modifies
the dnsmasq configuration file to also use ironic_dnsmasq_interface.

Change-Id: I7670544f4bc41c93ac1d081486502f9ffb8f2286
Closes-Bug: #1785574
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/73/589073/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ironic/templates/ironic-dnsmasq.conf.j2'],1,ea2cda217ed3d3fbb1a829a82509dbfd79622e8d,bug/1785574,interface={{ ironic_dnsmasq_interface }},interface={{ api_interface }},1,1
openstack%2Fpuppet-ceph~master~I1f1e8461cf49c680de2630396cdec5ff5774f0ec,openstack/puppet-ceph,master,I1f1e8461cf49c680de2630396cdec5ff5774f0ec,Do not enable Ceph el7 repos for Fedora,MERGED,2018-12-04 11:52:42.000000000,2019-01-07 09:40:10.000000000,2019-01-07 09:40:10.000000000,"[{'_account_id': 3153}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-04 11:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/9059b6db62a0179c16fac69ca80c75629f5f7734', 'message': 'Do not enable Ceph el7 repos for Fedora\n\nFedora Base repo includes ceph packages, so\nno extra repo required as the packages in Fedora\nrepo conflicts with el7 repo.\n\nThe ceph packages are also being added to fedora\nstable-base([1]) consumed in Fedora Testing.\n\n[1] https://review.rdoproject.org/r/#/c/17650/\n\nChange-Id: I1f1e8461cf49c680de2630396cdec5ff5774f0ec\n'}, {'number': 2, 'created': '2019-01-07 06:36:47.000000000', 'files': ['manifests/repo.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/698def7bfd927c889a37c30ee517c7723baff20e', 'message': 'Do not enable Ceph el7 repos for Fedora\n\nFedora Base repo includes ceph packages, so\nno extra repo required as the packages in Fedora\nrepo conflicts with el7 repo.\n\nThe ceph packages are also being added to fedora\nstable-base([1]) consumed in Fedora Testing.\n\n[1] https://review.rdoproject.org/r/#/c/17650/\n\nChange-Id: I1f1e8461cf49c680de2630396cdec5ff5774f0ec\n'}]",0,622252,698def7bfd927c889a37c30ee517c7723baff20e,18,6,2,13861,,,0,"Do not enable Ceph el7 repos for Fedora

Fedora Base repo includes ceph packages, so
no extra repo required as the packages in Fedora
repo conflicts with el7 repo.

The ceph packages are also being added to fedora
stable-base([1]) consumed in Fedora Testing.

[1] https://review.rdoproject.org/r/#/c/17650/

Change-Id: I1f1e8461cf49c680de2630396cdec5ff5774f0ec
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/52/622252/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/repo.pp'],1,9059b6db62a0179c16fac69ca80c75629f5f7734,py3-enable," if ($::operatingsystem != 'Fedora') { yumrepo { 'ext-ceph': # puppet versions prior to 3.5 do not support ensure, use enabled instead descr => ""External Ceph ${release}"", name => ""ext-ceph-${release}"", baseurl => ""http://download.ceph.com/rpm-${release}/el${el}/\$basearch"", gpgkey => 'https://download.ceph.com/keys/release.asc', priority => '10', # prefer ceph repos over EPEL yumrepo { 'ext-ceph-noarch': # puppet versions prior to 3.5 do not support ensure, use enabled instead enabled => $enabled, descr => 'External Ceph noarch', name => ""ext-ceph-${release}-noarch"", baseurl => ""http://download.ceph.com/rpm-${release}/el${el}/noarch"", gpgcheck => '1', gpgkey => 'https://download.ceph.com/keys/release.asc', mirrorlist => absent, priority => '10', # prefer ceph repos over EPEL tag => 'ceph', } if $fastcgi { yumrepo { 'ext-ceph-fastcgi': enabled => $enabled, descr => 'FastCGI basearch packages for Ceph', name => 'ext-ceph-fastcgi', baseurl => ""http://gitbuilder.ceph.com/mod_fastcgi-rpm-rhel${el}-x86_64-basic/ref/master"", gpgcheck => '1', gpgkey => 'https://download.ceph.com/keys/autobuild.asc', mirrorlist => absent, priority => '20', # prefer ceph repos over EPEL tag => 'ceph', } }"," yumrepo { 'ext-ceph': # puppet versions prior to 3.5 do not support ensure, use enabled instead enabled => $enabled, descr => ""External Ceph ${release}"", name => ""ext-ceph-${release}"", baseurl => ""http://download.ceph.com/rpm-${release}/el${el}/\$basearch"", gpgcheck => '1', gpgkey => 'https://download.ceph.com/keys/release.asc', mirrorlist => absent, priority => '10', # prefer ceph repos over EPEL tag => 'ceph', } yumrepo { 'ext-ceph-noarch': # puppet versions prior to 3.5 do not support ensure, use enabled instead enabled => $enabled, descr => 'External Ceph noarch', name => ""ext-ceph-${release}-noarch"", baseurl => ""http://download.ceph.com/rpm-${release}/el${el}/noarch"", gpgcheck => '1', gpgkey => 'https://download.ceph.com/keys/release.asc', mirrorlist => absent, priority => '10', # prefer ceph repos over EPEL tag => 'ceph', } if $fastcgi { yumrepo { 'ext-ceph-fastcgi': descr => 'FastCGI basearch packages for Ceph', name => 'ext-ceph-fastcgi', baseurl => ""http://gitbuilder.ceph.com/mod_fastcgi-rpm-rhel${el}-x86_64-basic/ref/master"", gpgkey => 'https://download.ceph.com/keys/autobuild.asc', priority => '20', # prefer ceph repos over EPEL",35,33
openstack%2Frpm-packaging~master~I60a54d95b4d3920c576b00aab1ccfcb994b0b774,openstack/rpm-packaging,master,I60a54d95b4d3920c576b00aab1ccfcb994b0b774,update python-tripleoclient to 11.1.0,MERGED,2018-09-06 23:08:23.000000000,2019-01-07 09:38:42.000000000,2019-01-07 09:38:42.000000000,"[{'_account_id': 1916}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-06 23:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/83f7a603b4b12abcaf5fa51ffabf86b5755d93a1', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 2, 'created': '2018-09-07 00:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/90b073643b0669897b2ffaa7bc7bdcbb88d5f9e3', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 3, 'created': '2018-09-11 00:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1e5f7cbf7fde9a1d1191b8757bd0e7799515781d', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 4, 'created': '2018-09-11 16:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/750afb108e92271be4856efefca9cfc9524c3538', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 5, 'created': '2018-12-12 22:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e988f9a379e56f183b05af03ce3ca00bd8ea501d', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 6, 'created': '2019-01-03 19:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/943fd08552d63b51507709e78a983a0aa61a28f8', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 7, 'created': '2019-01-03 19:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5d9e6b946d7a096cf6c03ad1bfac7595927447f7', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 8, 'created': '2019-01-03 19:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/941badb4214ea1eb0afa324ed8c78ce50b48bb8a', 'message': 'update python-tripleoclient to 10.5.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}, {'number': 9, 'created': '2019-01-05 00:16:25.000000000', 'files': ['openstack/python-tripleoclient/python-tripleoclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5c9e26fc8950aa07693da1efe331f0ead0d552d5', 'message': 'update python-tripleoclient to 11.1.0\n\nChange-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774\n'}]",2,600579,5c9e26fc8950aa07693da1efe331f0ead0d552d5,53,8,9,1916,,,0,"update python-tripleoclient to 11.1.0

Change-Id: I60a54d95b4d3920c576b00aab1ccfcb994b0b774
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/79/600579/8 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-tripleoclient/python-tripleoclient.spec.j2'],1,83f7a603b4b12abcaf5fa51ffabf86b5755d93a1,update-python-tripleoclient,Version: 10.5.0,Version: 9.2.0,1,1
openstack%2Fos-service-types~master~I72a882f2c33ea8c5b79625b3bb3e951204e0bba7,openstack/os-service-types,master,I72a882f2c33ea8c5b79625b3bb3e951204e0bba7,Update hacking version,MERGED,2019-01-04 16:43:02.000000000,2019-01-07 09:13:20.000000000,2019-01-07 09:13:20.000000000,"[{'_account_id': 2}, {'_account_id': 8482}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/95929c1e8b44d3a2905d09cfdda90c302c72dae6', 'message': 'Update hacking version to latest\n\nChange-Id: I72a882f2c33ea8c5b79625b3bb3e951204e0bba7\n'}, {'number': 2, 'created': '2019-01-06 10:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/39eeb928d2409231bb862fefab39aff0a83ae328', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I72a882f2c33ea8c5b79625b3bb3e951204e0bba7\n'}, {'number': 3, 'created': '2019-01-06 11:06:20.000000000', 'files': ['test-requirements.txt', 'os_service_types/service_types.py', 'os_service_types/data/__init__.py', 'os_service_types/exc.py'], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/fb33d01882517e6982463f100546e386660f0135', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I72a882f2c33ea8c5b79625b3bb3e951204e0bba7\n'}]",0,628602,fb33d01882517e6982463f100546e386660f0135,13,4,3,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I72a882f2c33ea8c5b79625b3bb3e951204e0bba7
",git fetch https://review.opendev.org/openstack/os-service-types refs/changes/02/628602/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,95929c1e8b44d3a2905d09cfdda90c302c72dae6,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.13,>=0.12.0 # Apache-2.0",1,1
openstack%2Ftripleo-heat-templates~master~I20d00c79fc898b0c4e535662ee6a70472e075b36,openstack/tripleo-heat-templates,master,I20d00c79fc898b0c4e535662ee6a70472e075b36,Ensure we get the right SELinux context for config-data sub-dir,MERGED,2019-01-03 14:36:48.000000000,2019-01-07 09:10:35.000000000,2019-01-07 09:10:34.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 19138}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-01-03 14:36:48.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee7fbe5963f5f080b4be59879176c6f688f07ed2', 'message': 'Ensure we get the right SELinux context for config-data sub-dir\n\nWhen docker was used, its ""create host directory tree"" feature was\nused. It apparently created directories with ""container_var_lib_t""\ntype, and this prevents podman container to access the content with\nAVC errors (permission denied).\n\nThe following patch ensures we get a recursive chcon running.\n\nWe\'re using ""command"" instead of ""file"" module because ansible doesn\'t\nlike broken symlink (in fact, they are symlink with relative path\nwithin containers).\n\nChange-Id: I20d00c79fc898b0c4e535662ee6a70472e075b36\n'}]",0,628191,ee7fbe5963f5f080b4be59879176c6f688f07ed2,12,9,1,28223,,,0,"Ensure we get the right SELinux context for config-data sub-dir

When docker was used, its ""create host directory tree"" feature was
used. It apparently created directories with ""container_var_lib_t""
type, and this prevents podman container to access the content with
AVC errors (permission denied).

The following patch ensures we get a recursive chcon running.

We're using ""command"" instead of ""file"" module because ansible doesn't
like broken symlink (in fact, they are symlink with relative path
within containers).

Change-Id: I20d00c79fc898b0c4e535662ee6a70472e075b36
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/628191/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,ee7fbe5963f5f080b4be59879176c6f688f07ed2,upgrade/podman-selinux, - name: ensure we get the right selinux context command: chcon -R -t svirt_sandbox_file_t /var/lib/config-data args: warn: no,,4,0
openstack%2Fmagnum~master~Ib337be87c2f62ab911a56c24bbe3a03b402d812d,openstack/magnum,master,Ib337be87c2f62ab911a56c24bbe3a03b402d812d,k8s_build: Build kubernetes v1.11.6 containers,MERGED,2018-12-18 11:26:45.000000000,2019-01-07 09:09:23.000000000,2019-01-07 09:09:23.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2018-12-18 11:26:45.000000000', 'files': ['playbooks/container-builder-vars.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b577aa42c3a6b88664baff3ea91d9a1b1a2b9e8b', 'message': 'k8s_build: Build kubernetes v1.11.6 containers\n\n* swicth from testing repo to openstackmagnum\n\nChange-Id: Ib337be87c2f62ab911a56c24bbe3a03b402d812d\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",0,625884,b577aa42c3a6b88664baff3ea91d9a1b1a2b9e8b,9,4,1,20498,,,0,"k8s_build: Build kubernetes v1.11.6 containers

* swicth from testing repo to openstackmagnum

Change-Id: Ib337be87c2f62ab911a56c24bbe3a03b402d812d
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/84/625884/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/container-builder-vars.yaml'],1,b577aa42c3a6b88664baff3ea91d9a1b1a2b9e8b,build-k8s-v1.11.6,magnum_repository: openstackmagnum kubernetes_version: v1.11.6,magnum_repository: openstackmagnumtest kubernetes_version: v1.11.3,2,2
openstack%2Ftempest~master~I8ef691da35aa7ad570d78b1f795f622443665fbc,openstack/tempest,master,I8ef691da35aa7ad570d78b1f795f622443665fbc,[WIP] Add tempest last command,ABANDONED,2019-01-07 06:43:46.000000000,2019-01-07 09:02:34.000000000,,"[{'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 25457}]","[{'number': 1, 'created': '2019-01-07 06:43:46.000000000', 'files': ['tempest/cmd/last.py', 'tempest/cmd/main.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/945b5c78f792498b94c7d065576ea744f0eb02e7', 'message': '[WIP] Add tempest last command\n\nOnce Tempest run finishes, User wants to generate subunit stream\nin v2 format from the last run. Currently when we use tempest run\n--subunit it always returns 0 as exit status irrespective of the\ntest failures as it is the known behavior of stestr run --subunit\nwhich confuses users whether last tempest run was successful.\ntempest last --subunit will solve this issue and will be useful\nfor users.\n\n[1.] https://github.com/mtreinish/stestr/issues/210\n\nChange-Id: I8ef691da35aa7ad570d78b1f795f622443665fbc\n'}]",0,628875,945b5c78f792498b94c7d065576ea744f0eb02e7,4,11,1,12393,,,0,"[WIP] Add tempest last command

Once Tempest run finishes, User wants to generate subunit stream
in v2 format from the last run. Currently when we use tempest run
--subunit it always returns 0 as exit status irrespective of the
test failures as it is the known behavior of stestr run --subunit
which confuses users whether last tempest run was successful.
tempest last --subunit will solve this issue and will be useful
for users.

[1.] https://github.com/mtreinish/stestr/issues/210

Change-Id: I8ef691da35aa7ad570d78b1f795f622443665fbc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/75/628875/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cmd/last.py', 'tempest/cmd/main.py']",2,945b5c78f792498b94c7d065576ea744f0eb02e7,tempest_last," def last_command(self, cmd): self.log.debug('last_command %s', cmd.__class__.__name__) ",,50,0
openstack%2Ftripleo-quickstart~master~I5e9c1d0b3561abc643620eb832c6309d45cdbb47,openstack/tripleo-quickstart,master,I5e9c1d0b3561abc643620eb832c6309d45cdbb47,Resolve ansible warnings and deprecated syntax,MERGED,2018-12-31 17:14:05.000000000,2019-01-07 09:01:40.000000000,2019-01-07 09:01:40.000000000,"[{'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2018-12-31 17:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/73369aa61b1b90e80d7f5588e32864c566929e65', 'message': 'Resolve ansible warnings and deprecated syntax\n\nRemoves Ansible deprecation warnings by adopting recommended syntax.\n\nAlso fixes triple warning caused by the missing hosts file due to its\nremoval by creating a valid hosts file that contains only localhost\nand which is loaded without any warnings.\n\nChange-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47\nDepends-On: https://review.openstack.org/#/c/627877/\nDepends-On: https://review.openstack.org/#/c/627879/\n'}, {'number': 2, 'created': '2019-01-02 11:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f3820d677a711d46d780c2ba7d2cebc6c1789a81', 'message': 'Resolve ansible warnings and deprecated syntax\n\nRemoves Ansible deprecation warnings by adopting recommended syntax.\n\nAlso fixes triple warning caused by the missing hosts file due to its\nremoval by creating a valid hosts file that contains only localhost\nand which is loaded without any warnings.\n\nChange-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47\n'}, {'number': 3, 'created': '2019-01-02 12:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8901b05dc12847ff0e32c0e88340c9fe9b7591f6', 'message': 'Resolve ansible warnings and deprecated syntax\n\nRemoves Ansible deprecation warnings by adopting recommended syntax.\n\nAlso fixes triple warning caused by the missing hosts file due to its\nremoval by creating a valid hosts file that contains only localhost\nand which is loaded without any warnings.\n\nChange-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47\n'}, {'number': 4, 'created': '2019-01-04 11:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6973aebec24d1611ddd5d79d91b3ee67ef8d5bab', 'message': 'Resolve ansible warnings and deprecated syntax\n\nRemoves Ansible deprecation warnings by adopting recommended syntax.\n\nAlso fixes triple warning caused by the missing hosts file due to its\nremoval by creating a valid hosts file that contains only localhost\nand which is loaded without any warnings.\n\nChange-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47\n'}, {'number': 5, 'created': '2019-01-04 11:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4ec0f0e5d87b195f0ab96caa63edd02b1a74f2ae', 'message': 'Resolve ansible warnings and deprecated syntax\n\nRemoves Ansible deprecation warnings by adopting recommended syntax.\n\nAlso fixes triple warning caused by the missing hosts file due to its\nremoval by creating a valid hosts file that contains only localhost\nand which is loaded without any warnings.\n\nChange-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47\n'}, {'number': 6, 'created': '2019-01-04 11:51:00.000000000', 'files': ['roles/repo-setup/tasks/main.yml', 'roles/fetch-images/tasks/main.yml', 'roles/virtbmc/tasks/main.yml', 'ci-scripts/usbkey/quickstart-usb.yml', 'playbooks/build-images-and-quickstart.yml', 'roles/libvirt/setup/overcloud/tasks/main.yml', 'doc/source/working-with-extras.rst', 'playbooks/quickstart.yml', 'roles/libvirt/setup/supplemental/tasks/main.yml', 'playbooks/provision.yml', 'roles/repo-setup/tasks/get-dlrn-hash.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6b6e758a1fc60b1437103d33f2ae7d836504362b', 'message': 'Resolve ansible warnings and deprecated syntax\n\nRemoves Ansible deprecation warnings by adopting recommended syntax.\n\nChange-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47\n'}]",4,627881,6b6e758a1fc60b1437103d33f2ae7d836504362b,31,13,6,24162,,,0,"Resolve ansible warnings and deprecated syntax

Removes Ansible deprecation warnings by adopting recommended syntax.

Change-Id: I5e9c1d0b3561abc643620eb832c6309d45cdbb47
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/81/627881/6 && git format-patch -1 --stdout FETCH_HEAD,"['roles/repo-setup/tasks/main.yml', 'playbooks/build-images-and-quickstart.yml', 'roles/libvirt/setup/overcloud/tasks/main.yml', 'roles/fetch-images/tasks/main.yml', 'roles/virtbmc/tasks/main.yml', 'ci-scripts/usbkey/quickstart-usb.yml', 'doc/source/working-with-extras.rst', 'playbooks/quickstart.yml', 'roles/libvirt/setup/supplemental/tasks/main.yml', 'playbooks/provision.yml', 'quickstart.sh', 'roles/repo-setup/tasks/get-dlrn-hash.yml']",12,73369aa61b1b90e80d7f5588e32864c566929e65,oooq/unwarn," - not dlrn_hash_tag is match(""[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}"") when: dlrn_hash_tag is match(""[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}"")"," - not dlrn_hash_tag | match(""[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}"") when: dlrn_hash_tag | match(""[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}"")",22,19
openstack%2Ftripleo-common~master~I5713c9128047357832ff7823df601a6af7691c52,openstack/tripleo-common,master,I5713c9128047357832ff7823df601a6af7691c52,Replace tripleo-scenario002-multinode with scenario002-standalone,MERGED,2019-01-03 18:48:31.000000000,2019-01-07 09:01:38.000000000,2019-01-07 09:01:38.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-03 18:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3b2e4f384400e0ac14ee8e209dc17bcc8bff801b', 'message': 'Replace tripleo-scenario002-multinode with scenario002-standalone\n\nChange-Id: I5713c9128047357832ff7823df601a6af7691c52\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/532\n'}, {'number': 2, 'created': '2019-01-04 12:34:03.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/99f95f89591d6339dc2f01559c3098dac1444368', 'message': 'Replace tripleo-scenario002-multinode with scenario002-standalone\n\nChange-Id: I5713c9128047357832ff7823df601a6af7691c52\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/532\n'}]",0,628262,99f95f89591d6339dc2f01559c3098dac1444368,13,5,2,8175,,,0,"Replace tripleo-scenario002-multinode with scenario002-standalone

Change-Id: I5713c9128047357832ff7823df601a6af7691c52
Story: https://tree.taiga.io/project/tripleo-ci-board/us/532
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/62/628262/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,3b2e4f384400e0ac14ee8e209dc17bcc8bff801b,replace-scen2, - tripleo-ci-centos-7-scenario002-standalone:, - tripleo-ci-centos-7-scenario002-multinode-oooq-container:,1,1
openstack%2Fzun~master~I1ac40bfc67d49c60a026cc8bdf006aeb16eafa87,openstack/zun,master,I1ac40bfc67d49c60a026cc8bdf006aeb16eafa87,Support private registry - objects layer,MERGED,2019-01-06 19:26:45.000000000,2019-01-07 08:55:15.000000000,2019-01-07 08:55:15.000000000,"[{'_account_id': 21428}, {'_account_id': 22076}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2019-01-06 19:26:45.000000000', 'files': ['zun/objects/registry.py', 'zun/objects/__init__.py', 'zun/tests/unit/objects/test_registry.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/31aa2fdfb255c3fd3a6d678a98718f4b4b13789d', 'message': 'Support private registry - objects layer\n\nChange-Id: I1ac40bfc67d49c60a026cc8bdf006aeb16eafa87\nPartial-Bug: #1702830\n'}]",0,628784,31aa2fdfb255c3fd3a6d678a98718f4b4b13789d,11,4,1,11536,,,0,"Support private registry - objects layer

Change-Id: I1ac40bfc67d49c60a026cc8bdf006aeb16eafa87
Partial-Bug: #1702830
",git fetch https://review.opendev.org/openstack/zun refs/changes/84/628784/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/objects/registry.py', 'zun/objects/__init__.py', 'zun/tests/unit/objects/test_registry.py', 'zun/tests/unit/objects/test_objects.py']",4,31aa2fdfb255c3fd3a6d678a98718f4b4b13789d,bug/1809067," 'Registry': '1.0-21ed56234497120755c60deba7c9e1dc',",,270,0
openstack%2Fheat-dashboard~master~I6d69299c6099bdcd3671e7e7c764604676e8eaef,openstack/heat-dashboard,master,I6d69299c6099bdcd3671e7e7c764604676e8eaef,Use template for lower-constraints,MERGED,2018-12-20 20:00:27.000000000,2019-01-07 08:50:55.000000000,2019-01-07 08:50:55.000000000,"[{'_account_id': 1736}, {'_account_id': 4257}, {'_account_id': 19224}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-20 20:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/84a91beda55c2dd29f27e8e02d7cad94ff5e1172', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nChange-Id: I6d69299c6099bdcd3671e7e7c764604676e8eaef\nNeeded-By: https://review.openstack.org/623229\n'}, {'number': 2, 'created': '2018-12-20 20:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/3326308bff4e566811827ffd6bb6d552ee92f878', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nAlso, update minimal requirement for django-babel since horizon needs\n0.6.2 as minimal version. This is needed to pass the lower-constraints\njob.\n\nChange-Id: I6d69299c6099bdcd3671e7e7c764604676e8eaef\nNeeded-By: https://review.openstack.org/623229\n'}, {'number': 3, 'created': '2018-12-20 21:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/6a980dd0f1e8254711978e30e85422f460364350', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nAlso, update minimal requirement for django-babel and django since horizon\nneeds newer versions. This is needed to pass the lower-constraints\njob.\n\nChange-Id: I6d69299c6099bdcd3671e7e7c764604676e8eaef\nNeeded-By: https://review.openstack.org/623229\n'}, {'number': 4, 'created': '2018-12-21 08:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/c31cc75981e9d97321792f3459b058062cfc6240', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nAlso, update some minimal requirement for horizon\nneeds newer versions. This is needed to pass the lower-constraints\njob.\n\nChange-Id: I6d69299c6099bdcd3671e7e7c764604676e8eaef\nNeeded-By: https://review.openstack.org/623229\n'}, {'number': 5, 'created': '2018-12-21 08:58:05.000000000', 'files': ['.zuul.yaml', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/e952fd0ff3076cb333b53e2f0b7c08566e590933', 'message': 'Use template for lower-constraints\n\nSmall cleanups:\n\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nAlso, update some minimal requirement for horizon\nneeds newer versions. This is needed to pass the lower-constraints\njob.\n\nChange-Id: I6d69299c6099bdcd3671e7e7c764604676e8eaef\nNeeded-By: https://review.openstack.org/623229\n'}]",0,626686,e952fd0ff3076cb333b53e2f0b7c08566e590933,17,4,5,6547,,,0,"Use template for lower-constraints

Small cleanups:

* Use openstack-lower-constraints-jobs template, remove individual
  jobs.
* Sort list of templates

Also, update some minimal requirement for horizon
needs newer versions. This is needed to pass the lower-constraints
job.

Change-Id: I6d69299c6099bdcd3671e7e7c764604676e8eaef
Needed-By: https://review.openstack.org/623229
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/86/626686/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,84a91beda55c2dd29f27e8e02d7cad94ff5e1172,cd/py36-lower-constraints, - nodejs4-jobs - openstack-lower-constraints-jobs - publish-openstack-docs-pti, - publish-openstack-docs-pti - nodejs4-jobs - openstack-tox-lower-constraints - openstack-tox-lower-constraints,3,4
openstack%2Fcharm-swift-proxy~master~Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0,openstack/charm-swift-proxy,master,Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0,Support deploy of Swift with internal S3 support,MERGED,2018-11-28 10:13:30.000000000,2019-01-07 08:30:32.000000000,2019-01-07 08:30:32.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-28 10:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/6c2b4efef634264c16486b59b98f0e90ee88ebd6', 'message': 'Drop install of swift-plugin-s3 at Rocky\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 2, 'created': '2018-11-30 09:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/fd879f524b79bfcbd9ed8395a975567d35e37f14', 'message': 'Drop install of swift-plugin-s3 at Rocky\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 3, 'created': '2018-12-12 10:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/a448ddd9de918dfc69b12142050d56a5e8e3b6f6', 'message': 'Support deploy of Swift with internal S3 support\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nAdd new template for Rocky to use the in-tree s3api and s3token\nmiddleware.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 4, 'created': '2018-12-12 14:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/a47fb2e66723217e66eaf6e951930f39b512eedc', 'message': 'Support deploy of Swift with internal S3 support\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nAdd new template for Rocky to use the in-tree s3api and s3token\nmiddleware.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 5, 'created': '2018-12-13 14:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/1b677a86e2c5fcce7c2d74dabb31d179c7d53546', 'message': 'Support deploy of Swift with internal S3 support\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nAdd new template for Rocky to use the in-tree s3api and s3token\nmiddleware.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 6, 'created': '2018-12-14 10:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/7031287bb3e484d9ef8c8e21efe9150218425124', 'message': 'Support deploy of Swift with internal S3 support\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nAdd new template for Rocky to use the in-tree s3api and s3token\nmiddleware.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 7, 'created': '2018-12-18 10:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/68c8e5a3eb5801a08398e2fc3d529e2bd2fc39c6', 'message': 'Support deploy of Swift with internal S3 support\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nAdd new template for Rocky to use the in-tree s3api and s3token\nmiddleware.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}, {'number': 8, 'created': '2018-12-18 10:12:26.000000000', 'files': ['lib/swift_utils.py', 'tests/basic_deployment.py', 'unit_tests/test_swift_utils.py', 'templates/rocky/proxy-server.conf', 'tests/gate-basic-cosmic-rocky', 'templates/queens/proxy-server.conf'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/8cf9dd4e1ad7dd4013472e781babbac4e4c55662', 'message': 'Support deploy of Swift with internal S3 support\n\nSwift support is in-tree for Swift since OpenStack Rocky, and\nthe swift-plugin-s3 package has been removed from the archive at\nCosmic so drop installation at Rocky.\n\nAdd new template for Rocky to use the in-tree s3api and s3token\nmiddleware.\n\nEnable cosmic test to validate changes.\n\nChange-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0\nCloses-Bug: 1805597\n'}]",1,620549,8cf9dd4e1ad7dd4013472e781babbac4e4c55662,37,4,8,935,,,0,"Support deploy of Swift with internal S3 support

Swift support is in-tree for Swift since OpenStack Rocky, and
the swift-plugin-s3 package has been removed from the archive at
Cosmic so drop installation at Rocky.

Add new template for Rocky to use the in-tree s3api and s3token
middleware.

Enable cosmic test to validate changes.

Change-Id: Ie5447dc44203c1ea2ad27e6d71248ba59d7549d0
Closes-Bug: 1805597
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/49/620549/8 && git format-patch -1 --stdout FETCH_HEAD,"['lib/swift_utils.py', 'unit_tests/test_swift_utils.py']",2,6c2b4efef634264c16486b59b98f0e90ee88ebd6,bug/1805597," def test_determine_packages(self): self.assertEqual( ['swift', 'swift-proxy', 'memcached', 'apache2', 'python-keystone'], swift_utils.determine_packages('essex') ) self.assertEqual( ['swift', 'swift-proxy', 'memcached', 'apache2', 'python-keystone', 'swift-plugin-s3', 'swauth'], swift_utils.determine_packages('folsom') ) self.assertEqual( ['swift', 'swift-proxy', 'memcached', 'apache2', 'python-keystone', 'swift-plugin-s3', 'swauth', 'python-ceilometermiddleware'], swift_utils.determine_packages('mitaka') ) self.assertEqual( ['swift', 'swift-proxy', 'memcached', 'apache2', 'python-keystone', 'swauth', 'python-ceilometermiddleware'], swift_utils.determine_packages('rocky') )",,53,7
openstack%2Fnetworking-onos~stable%2Fqueens~Ic399c1d4b55912c664b7f8fc82428e499107021c,openstack/networking-onos,stable/queens,Ic399c1d4b55912c664b7f8fc82428e499107021c,Support GENEVE tunnel type,MERGED,2019-01-07 07:37:46.000000000,2019-01-07 08:11:34.000000000,2019-01-07 08:11:34.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2019-01-07 07:37:46.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/92237d30afd8bf010aff9180dbae842274cde3d0', 'message': 'Support GENEVE tunnel type\n\nChange-Id: Ic399c1d4b55912c664b7f8fc82428e499107021c\n'}]",0,628894,92237d30afd8bf010aff9180dbae842274cde3d0,7,3,1,28180,,,0,"Support GENEVE tunnel type

Change-Id: Ic399c1d4b55912c664b7f8fc82428e499107021c
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/94/628894/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,92237d30afd8bf010aff9180dbae842274cde3d0,," n_const.TYPE_GENEVE,",,1,0
openstack%2Fnetworking-onos~stable%2Focata~Id3ba7fe5f341b5daceea0000379aee058fc8c596,openstack/networking-onos,stable/ocata,Id3ba7fe5f341b5daceea0000379aee058fc8c596,Support GENEVE tunnel type,MERGED,2019-01-07 07:45:06.000000000,2019-01-07 08:11:33.000000000,2019-01-07 08:11:33.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2019-01-07 07:45:06.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/16dfd038e1fc7653432a3951bf0b3098dcfa7bfe', 'message': 'Support GENEVE tunnel type\n\nChange-Id: Id3ba7fe5f341b5daceea0000379aee058fc8c596\n'}]",0,628899,16dfd038e1fc7653432a3951bf0b3098dcfa7bfe,7,3,1,28180,,,0,"Support GENEVE tunnel type

Change-Id: Id3ba7fe5f341b5daceea0000379aee058fc8c596
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/99/628899/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,16dfd038e1fc7653432a3951bf0b3098dcfa7bfe,," constants.TYPE_GENEVE,",,1,0
openstack%2Ftripleo-heat-templates~master~I3606c356a2103ce1e26e78e1192f0713b51e1ca4,openstack/tripleo-heat-templates,master,I3606c356a2103ce1e26e78e1192f0713b51e1ca4,Fix check-run-nova-compute script shebang,MERGED,2018-11-08 23:51:33.000000000,2019-01-07 08:06:52.000000000,2018-11-18 03:49:47.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 17823}, {'_account_id': 20778}, {'_account_id': 20866}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-08 23:51:33.000000000', 'files': ['extraconfig/tasks/instanceha/check-run-nova-compute'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc274133ff9b1769776d8dfc69b41b33a78a1ebb', 'message': ""Fix check-run-nova-compute script shebang\n\nFor python3 packaging we are looking for /usr/bin/env python to swap out\nwith the python3 binary in the packaging. Rather than look for\n/usr/bin/python, it's easier to use /usr/bin/env python since the other\nfiles have this. Update this script for consistency.\n\nChange-Id: I3606c356a2103ce1e26e78e1192f0713b51e1ca4\nRelated-Blueprint: python3-support\n""}]",1,616715,dc274133ff9b1769776d8dfc69b41b33a78a1ebb,14,8,1,14985,,,0,"Fix check-run-nova-compute script shebang

For python3 packaging we are looking for /usr/bin/env python to swap out
with the python3 binary in the packaging. Rather than look for
/usr/bin/python, it's easier to use /usr/bin/env python since the other
files have this. Update this script for consistency.

Change-Id: I3606c356a2103ce1e26e78e1192f0713b51e1ca4
Related-Blueprint: python3-support
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/616715/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/instanceha/check-run-nova-compute'],1,dc274133ff9b1769776d8dfc69b41b33a78a1ebb,bp/python3-support,#!/usr/bin/env python,#!/usr/bin/python -utt,1,1
openstack%2Fnetworking-onos~stable%2Frocky~If99615c1b772ab5c3d8040057a0edcb3b65b66b9,openstack/networking-onos,stable/rocky,If99615c1b772ab5c3d8040057a0edcb3b65b66b9,Support GENEVE tunnel type,MERGED,2019-01-07 07:35:03.000000000,2019-01-07 08:06:25.000000000,2019-01-07 08:06:25.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2019-01-07 07:35:03.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/4ec74857893353c7e2a803bd91f0d9acf44fe372', 'message': 'Support GENEVE tunnel type\n\nChange-Id: If99615c1b772ab5c3d8040057a0edcb3b65b66b9\n'}]",0,628893,4ec74857893353c7e2a803bd91f0d9acf44fe372,7,3,1,28180,,,0,"Support GENEVE tunnel type

Change-Id: If99615c1b772ab5c3d8040057a0edcb3b65b66b9
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/93/628893/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,4ec74857893353c7e2a803bd91f0d9acf44fe372,," n_const.TYPE_GENEVE,",,1,0
openstack%2Fnetworking-onos~stable%2Fpike~I9ceb5a9646aef66600df40d74ac3dfb4e73aa876,openstack/networking-onos,stable/pike,I9ceb5a9646aef66600df40d74ac3dfb4e73aa876,Support GENEVE tunnel type,MERGED,2019-01-07 07:39:34.000000000,2019-01-07 08:05:33.000000000,2019-01-07 08:05:33.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2019-01-07 07:39:34.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/5bca7c8b0dc528f1bce9628c89baec7f60691986', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I9ceb5a9646aef66600df40d74ac3dfb4e73aa876\n'}]",0,628896,5bca7c8b0dc528f1bce9628c89baec7f60691986,7,3,1,28180,,,0,"Support GENEVE tunnel type

Change-Id: I9ceb5a9646aef66600df40d74ac3dfb4e73aa876
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/96/628896/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,5bca7c8b0dc528f1bce9628c89baec7f60691986,," n_const.TYPE_GENEVE,",,1,0
openstack%2Fcinder~master~I9f69ec2145e56d413392e47774f61e73399737f6,openstack/cinder,master,I9f69ec2145e56d413392e47774f61e73399737f6,Delete the duplicate words in  cinder.po,ABANDONED,2019-01-07 06:43:27.000000000,2019-01-07 08:01:53.000000000,,"[{'_account_id': 9008}, {'_account_id': 16897}, {'_account_id': 17130}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 26537}]","[{'number': 1, 'created': '2019-01-07 06:43:27.000000000', 'files': ['cinder/locale/zh_TW/LC_MESSAGES/cinder.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9eb2fd6edc7465e784571c98525bd327c949d82b', 'message': 'Delete the duplicate words in  cinder.po\n\nChange-Id: I9f69ec2145e56d413392e47774f61e73399737f6\n'}]",0,628874,9eb2fd6edc7465e784571c98525bd327c949d82b,8,6,1,29423,,,0,"Delete the duplicate words in  cinder.po

Change-Id: I9f69ec2145e56d413392e47774f61e73399737f6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/74/628874/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/locale/zh_TW/LC_MESSAGES/cinder.po'],1,9eb2fd6edc7465e784571c98525bd327c949d82b,,"""SSC extra specs. The proxy version must be at least %(min_version)s.""","""SSC extra specs. The proxy version must be at at least %(min_version)s.""",1,1
openstack%2Fsolum~master~I6a98546a2ef2590909661a7e54c8520f7e42bd1e,openstack/solum,master,I6a98546a2ef2590909661a7e54c8520f7e42bd1e,Using rootwrap for build-lp,ABANDONED,2017-09-08 06:37:15.000000000,2019-01-07 07:41:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-09-08 06:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4ab0048c29d8bd7413ddc7ff1c15dbc4eea2898b', 'message': 'Using rootwrap for build-lp\n\nChange-Id: I6a98546a2ef2590909661a7e54c8520f7e42bd1e\nPartially-Implements: blueprint solum-rootwrap\n'}, {'number': 2, 'created': '2018-07-25 12:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d9e64355ad28db43e2d4d8402e032650e7c48bce', 'message': 'Using rootwrap for build-lp\n\nChange-Id: I6a98546a2ef2590909661a7e54c8520f7e42bd1e\nPartially-Implements: blueprint solum-rootwrap\n'}, {'number': 3, 'created': '2018-07-26 06:12:27.000000000', 'files': ['solum/worker/handlers/shell.py', 'etc/solum/rootwrap.d/solum.filters', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/solum/commit/8aa4c3886986c91eea61be2aeb1240cd2147ddd8', 'message': 'Using rootwrap for build-lp\n\nChange-Id: I6a98546a2ef2590909661a7e54c8520f7e42bd1e\nPartially-Implements: blueprint solum-rootwrap\n'}]",0,501969,8aa4c3886986c91eea61be2aeb1240cd2147ddd8,10,1,3,14107,,,0,"Using rootwrap for build-lp

Change-Id: I6a98546a2ef2590909661a7e54c8520f7e42bd1e
Partially-Implements: blueprint solum-rootwrap
",git fetch https://review.opendev.org/openstack/solum refs/changes/69/501969/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/handlers/shell.py', 'etc/solum/rootwrap.d/solum.filters', 'devstack/plugin.sh']",3,4ab0048c29d8bd7413ddc7ff1c15dbc4eea2898b,bp/solum-rootwrap," # config solum rootwrap filters sed -i ""s#SOLUM_DIR#$SOLUM_DIR#g"" ${SOLUM_DIR}/etc/solum/rootwrap.d/solum.filters ",,14,3
openstack%2Fmurano-deployment~master~I379c64805e45a3462d5d2530865cec2f878d57d3,openstack/murano-deployment,master,I379c64805e45a3462d5d2530865cec2f878d57d3,Retire murano-deployment,MERGED,2019-01-07 03:31:41.000000000,2019-01-07 07:33:40.000000000,2019-01-07 07:33:40.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 03:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/b570b11fc7702f3edbe10714ec4153e8a9ea4fb1', 'message': 'Retire murano-deployment\n\nDepends-On: https://review.openstack.org/628850\nChange-Id: I379c64805e45a3462d5d2530865cec2f878d57d3\n'}, {'number': 2, 'created': '2019-01-07 05:13:31.000000000', 'files': ['contrib/windows/WindowsPowerShell/Modules/CoreFunctions/en-US/about_CoreFunctions.help.txt', 'contrib/windows/ExecutionPlan/DeployWebApp/ExecutionPlan.yaml', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/GenerateJSON.sh', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/init.pp', 'contrib/windows/WindowsPowerShell/Functions/OptionParser.ps1', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InstallSqlServerForAOAG.yaml', 'contrib/windows/Unattended/ws-2012-full-unattend.xml', 'murano-ci/nodepool/scripts/restrict_memory.sh', 'contrib/windows/image-builder/lib/templates/smbshare.conf.template', 'murano-ci/jenkins/data/README.md', 'murano-ci/config/puppet-ci/modules/ssh/templates/common-session.erb', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/agent.pp', 'murano-ci/config/devstack/README.rst', 'contrib/windows/ExecutionPlan/2.JoinDomain/GenerateJSON.bat', 'murano-ci/jenkins/jobs/murano_jobs.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverClusterPrerequisites.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/WindowsPowerShell/Functions/New-SqlServerSystemAccount.ps1', 'contrib/cirros/README.rst', 'contrib/cirros/cloud-userdata.patch', 'contrib/windows/WindowsAgent/README.rst', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/CreatePrimaryDC.json', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/ConfigureEnvironmentForAOAG.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGSecondaryReplica.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/1.Windows-Post-Install.ps1', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/params.pp', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/SqlFunctions.ps1', 'murano-ci/config/puppet-ci/modules/pdnsd/templates/resolv.conf-head.erb', 'murano-ci/config/puppet-ci/modules/zabbix/templates/frontend/zabbix.conf.php.erb', 'murano-ci/config/puppet-ci/hiera/etc/globals.yaml', 'murano-ci/scripts/functions.inc', 'contrib/windows/ExecutionPlan/InstallIIS/Install-WebServer.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/README.rst', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverCluster.yaml.json', 'contrib/windows/ExecutionPlan/FailoverCluster/GenerateJSON.sh', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/proxy.pp', 'contrib/windows/ExecutionPlan/Newtonsoft.Json.dll', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/unattend.xml.template', 'murano-ci/config/puppet-ci/modules/muranoci-extras/files/jenkins.conf', 'contrib/windows/ExecutionPlan/2.JoinDomain/ExecutionPlan.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InstallSqlServerForAOAG.yaml.json', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/GenerateJSON.sh', 'murano-ci/config/puppet-ci/deploy.sh', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Functions.ps1', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/ExecutionPlan.yaml', 'murano-ci/nodepool/nodepool.yaml', 'murano-ci/config/puppet-ci/Puppetfile', 'contrib/windows/WindowsPowerShell/Functions/FailoverCluster.ps1', 'murano-ci/config/puppet-ci/modules/ssh/templates/sshd_config.erb', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/install.pp', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/GenerateJSON.bat', 'contrib/cirros/build-murano-cirros.sh', 'murano-ci/config/puppet-ci/modules/muranoci-extras/templates/vhost_custom.conf.erb', 'murano-ci/jenkins/jobs/hooks.yaml', 'murano-ci/scripts/templates/empty.template', 'murano-ci/config/devstack/post-stack.sh', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/ExecutionPlan.yaml', 'murano-ci/config/devstack/setup.sh', 'README', 'murano-ci/jenkins/jobs/macros.yaml', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/Install-RoleSecondaryDomainController.ps1', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/GenerateJSON.bat', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/temp/.hidden', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/Install-RoleSecondaryDomainController.ps1', 'murano-ci/scripts/prepare_tests.sh', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/ExecutionPlan.txt', 'murano-ci/scripts/templates/report.template', 'README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/autounattend.xml.template', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/GenerateJSON.bat', 'contrib/windows/WindowsPowerShell/Functions/Start-PowerShellProcess.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/Ionic.Zip.dll', 'contrib/windows/WindowsPowerShell/Functions/SQLServerInstaller.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/CoreFunctions.psm1', 'murano-ci/config/devstack/build-murano-image.sh', 'murano-ci/config/puppet-ci/modules/zabbix/templates/frontend/ping.php.erb', 'contrib/windows/ExecutionPlan/InstallIIS/GenerateJSON.bat', 'contrib/cirros/config.local.sh', 'contrib/windows/ExecutionPlan/DeployWebApp/GenerateJSON.bat', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/README.rst', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/item.pp', 'murano-ci/config/devstack/post-unstack.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/README.rst', 'murano-ci/infra/configure_api.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/2.Start-Sysprep.ps1', 'contrib/windows/ExecutionPlan/InstallSQL/GenerateJSON.sh', 'contrib/windows/WindowsPowerShell/Functions/Join-Domain.ps1', 'murano-ci/config/puppet-ci/manifests/ssh.pp', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAlwaysOn.yaml', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Base64.ps1', 'contrib/windows/ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/README.md', 'contrib/windows/image-builder/lib/templates/README.rst', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGPrimaryReplica.yaml', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/unattend.xml.template', 'murano-ci/config/puppet-ci/manifests/jenkins.pp', 'murano-ci/jenkins/jobs/ci-infra.yaml', 'murano-ci/config/puppet-ci/modules/pdnsd/templates/default_pdnsd.erb', 'contrib/windows/ExecutionPlan/InstallIIS/ExecutionPlan.yaml', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/ExecutionPlan.txt', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/frontend.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/proxy/zabbix_proxy.conf.erb', 'murano-ci/scripts/run_tests.sh', 'contrib/windows/WindowsPowerShell/Functions/Failover-Cluster.ps1', 'contrib/windows/ExecutionPlan/DeployWebApp/ExecutionPlan.txt', 'murano-ci/config/puppet-ci/doc/single_node_hiera_examples.rst', 'murano-ci/scripts/collect_results.sh', 'contrib/windows/image-builder/launch-vm.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/unattend.xml.template', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/ExecutionPlan.yaml', 'murano-ci/config/puppet-ci/doc/config_example.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/ConfigureEnvironmentForAOAG.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/autounattend.xml.template', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/Install-RolePrimaryDomainController.ps1', 'contrib/windows/ExecutionPlan/2.JoinDomain/GenerateJSON.sh', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverClusterPrerequisites.yaml', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/GenerateJSON.sh', 'murano-ci/nodepool/scripts/prepare_node_murano_devstack.sh', 'murano-ci/config/puppet-ci/modules/ssh/templates/nsswitch.conf.erb', 'murano-ci/scripts/syntax_check.sh', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverCluster.yaml', 'murano-ci/config/puppet-ci/README.rst', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/log4net.config', 'murano-ci/config/puppet-ci/modules/ssh/manifests/banner.pp', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/README.rst', 'murano-ci/config/puppet-ci/modules/zabbix/templates/proxy/zabbix_proxy_defaults.erb', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/README.rst', 'murano-ci/config/puppet-ci/modules/ssh/manifests/known_host.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/item.erb', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/ExecutionPlan.txt', 'murano-ci/tools/update_config.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/Config.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/3.Start-AtFirstBoot.ps1', 'murano-ci/tools/split-logs.sh', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/out.json', 'murano-ci/nodepool/elements/README.md', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Module.ps1', 'murano-ci/config/puppet-ci/hiera/etc/config.yaml', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/NotCoreFunctions.ps1', 'murano-ci/scripts/collect_logs.sh', 'murano-ci/config/puppet-ci/modules/ssh/manifests/sshd.pp', 'murano-ci/infra/RabbitMQ.py', 'murano-ci/config/puppet-ci/hiera/hiera.yaml', 'contrib/windows/WindowsPowerShell/Makefile', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/service.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/server/zabbix_server.conf.erb', 'murano-ci/config/puppet-ci/hiera/etc/users.yaml', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/Get-DnsListeningIpAddress.ps1', 'contrib/windows/WindowsPowerShell/Functions/Update-ServiceConfig.ps1', 'murano-ci/scripts/generate_html_report.py', 'murano-ci/config/puppet-ci/manifests/zuul.pp', 'contrib/windows/WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'murano-ci/nodepool/scripts/ready_script_murano.sh', 'murano-ci/config/puppet-ci/manifests/jenkins_jobs.pp', 'murano-ci/config/puppet-ci/modules/ssh/manifests/ldap.pp', 'murano-ci/config/puppet-ci/modules/ssh/templates/ldap.conf.erb', 'murano-ci/config/puppet-ci/manifests/users.pp', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/config.pp', 'murano-ci/scripts/common.inc', 'contrib/cirros/murano-agent.init', 'murano-ci/README.md', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/log4net.dll', 'contrib/windows/image-builder/README.rst', 'contrib/windows/ExecutionPlan/2.JoinDomain/ExecutionPlan.txt', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/server.pp', 'contrib/windows/image-builder/lib/windowssetup/unattend/README.rst', 'murano-ci/config/devstack/local.sh', 'murano-ci/tools/rotate-devstack-logs.sh', 'murano-ci/config/puppet-ci/manifests/nodepool.pp', 'contrib/windows/Unattended/ws-2012-core-unattended.xml', 'contrib/windows/ExecutionPlan/README.rst', 'contrib/windows/ExecutionPlan/InstallSQL/ExecutionPlan.yaml', 'contrib/windows/WindowsPowerShell/Functions/Install-SQLServer.ps1', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/GenerateJSON.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/autounattend.xml.template', 'murano-ci/config/puppet-ci/modules/ssh/manifests/params.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/agent/zabbix_agentd.conf.erb', 'murano-ci/config/puppet-ci/manifests/ntp.pp', '.gitreview', 'murano-ci/nodepool/scripts/README.md', 'contrib/windows/WindowsPowerShell/Functions/Write-InvocationInfo.ps1', 'murano-ci/jenkins/scripts/README.md', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/CoreFunctions.psd1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/1.Windows-Post-Install.ps1', 'murano-ci/infra/deploy_component_new.sh', 'contrib/windows/ExecutionPlan/InstallIIS/ExecutionPlan.txt', 'contrib/windows/WindowsPowerShell/README.rst', 'murano-ci/config/puppet-ci/modules/pdnsd/templates/pdnsd.conf.erb', 'murano-ci/config/puppet-ci/modules/ssh/manifests/authorized_keys.pp', 'contrib/windows/WindowsPowerShell/Functions/SQLServerForAOAG.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Zip.ps1', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAlwaysOn.yaml.json', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/server/alertscript.pp', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/ExecutionPlan/DeployWebApp/Deploy-WebApp.ps1', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverClusterPrerequisites.yaml.json', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/out.json', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/config.ini', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/ExecutionPlan.yaml', 'murano-ci/config/puppet-ci/modules/zabbix/templates/sudoers.erb', 'murano-ci/scripts/start_gate.sh', 'contrib/windows/ExecutionPlan/InstallIIS/GenerateJSON.sh', 'contrib/windows/WindowsPowerShell/Functions/ImportCoreFunctions.ps1', 'murano-ci/jenkins/jobs/defaults.yaml', 'murano-ci/config/puppet-ci/modules/muranoci-extras/files/jenkins.default', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/autounattend.xml.template', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/out.json', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/ExecutionPlan.ps1', 'murano-ci/config/devstack/local.conf', 'murano-ci/scripts/deploy_devstack.sh', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverClusterPrerequisites.yaml', 'murano-ci/tools/update_pool.sh', 'murano-ci/config/puppet-ci/manifests/monitoring.pp', 'murano-ci/jenkins/jobs/README.md', 'contrib/windows/ExecutionPlan/2.JoinDomain/out.json', 'murano-ci/config/puppet-ci/manifests/dns.pp', 'contrib/windows/ExecutionPlan/ExecutionPlanGenerator.py', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/GenerateJSON.sh', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/agent/service.pp', 'contrib/windows/image-builder/lib/templates/deafultnet.template', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Logger.ps1', 'murano-ci/config/puppet-ci/modules/zabbix/templates/server/zabbix_server_default.erb', 'murano-ci/nodepool/scripts/prepare_node.sh', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGSecondaryReplica.yaml', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverCluster.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGPrimaryReplica.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/README.rst', 'murano-ci/zuul/openstack_functions.py', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/params.pp', 'contrib/windows/WindowsPowerShell/Functions/Export-Function.ps1', 'contrib/windows/ExecutionPlan/InstallIIS/out.json', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverCluster.yaml.json', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/GenerateJSON.bat', 'contrib/windows/ExecutionPlan/ExecutionPlanGenerator.exe', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/ExecutionPlan.txt', 'contrib/windows/ExecutionPlan/DeployWebApp/GenerateJSON.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/2.Start-Sysprep.ps1', 'murano-ci/zuul/layout.yaml', 'contrib/windows/Unattended/README.rst', 'contrib/windows/image-builder/runme.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/c75c682069b681cd0c70488dedcfc71ea5fb3839', 'message': 'Retire murano-deployment\n\nChange-Id: I379c64805e45a3462d5d2530865cec2f878d57d3\n'}]",0,628855,c75c682069b681cd0c70488dedcfc71ea5fb3839,9,2,2,14107,,,0,"Retire murano-deployment

Change-Id: I379c64805e45a3462d5d2530865cec2f878d57d3
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/55/628855/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/windows/WindowsPowerShell/Modules/CoreFunctions/en-US/about_CoreFunctions.help.txt', 'contrib/windows/ExecutionPlan/DeployWebApp/ExecutionPlan.yaml', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/GenerateJSON.sh', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/init.pp', 'contrib/windows/WindowsPowerShell/Functions/OptionParser.ps1', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InstallSqlServerForAOAG.yaml', 'contrib/windows/Unattended/ws-2012-full-unattend.xml', 'murano-ci/nodepool/scripts/restrict_memory.sh', 'contrib/windows/image-builder/lib/templates/smbshare.conf.template', 'murano-ci/jenkins/data/README.md', 'murano-ci/config/puppet-ci/modules/ssh/templates/common-session.erb', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/agent.pp', 'murano-ci/config/devstack/README.rst', 'contrib/windows/ExecutionPlan/2.JoinDomain/GenerateJSON.bat', 'murano-ci/jenkins/jobs/murano_jobs.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverClusterPrerequisites.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/WindowsPowerShell/Functions/New-SqlServerSystemAccount.ps1', 'contrib/cirros/README.rst', 'contrib/cirros/cloud-userdata.patch', 'contrib/windows/WindowsAgent/README.rst', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/CreatePrimaryDC.json', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/ConfigureEnvironmentForAOAG.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGSecondaryReplica.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/1.Windows-Post-Install.ps1', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/params.pp', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/SqlFunctions.ps1', 'murano-ci/config/puppet-ci/modules/pdnsd/templates/resolv.conf-head.erb', 'murano-ci/config/puppet-ci/modules/zabbix/templates/frontend/zabbix.conf.php.erb', 'murano-ci/config/puppet-ci/hiera/etc/globals.yaml', 'murano-ci/scripts/functions.inc', 'contrib/windows/ExecutionPlan/InstallIIS/Install-WebServer.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/README.rst', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverCluster.yaml.json', 'contrib/windows/ExecutionPlan/FailoverCluster/GenerateJSON.sh', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/proxy.pp', 'contrib/windows/ExecutionPlan/Newtonsoft.Json.dll', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/unattend.xml.template', 'murano-ci/config/puppet-ci/modules/muranoci-extras/files/jenkins.conf', 'contrib/windows/ExecutionPlan/2.JoinDomain/ExecutionPlan.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InstallSqlServerForAOAG.yaml.json', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/GenerateJSON.sh', 'murano-ci/config/puppet-ci/deploy.sh', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Functions.ps1', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/ExecutionPlan.yaml', 'murano-ci/nodepool/nodepool.yaml', 'murano-ci/config/puppet-ci/Puppetfile', 'contrib/windows/WindowsPowerShell/Functions/FailoverCluster.ps1', 'murano-ci/config/puppet-ci/modules/ssh/templates/sshd_config.erb', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/install.pp', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/GenerateJSON.bat', 'contrib/cirros/build-murano-cirros.sh', 'murano-ci/config/puppet-ci/modules/muranoci-extras/templates/vhost_custom.conf.erb', 'murano-ci/jenkins/jobs/hooks.yaml', 'murano-ci/scripts/templates/empty.template', 'murano-ci/config/devstack/post-stack.sh', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/ExecutionPlan.yaml', 'murano-ci/config/devstack/setup.sh', 'README', 'murano-ci/jenkins/jobs/macros.yaml', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/Install-RoleSecondaryDomainController.ps1', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/GenerateJSON.bat', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/temp/.hidden', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/Install-RoleSecondaryDomainController.ps1', 'murano-ci/scripts/prepare_tests.sh', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/ExecutionPlan.txt', 'murano-ci/scripts/templates/report.template', 'README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/autounattend.xml.template', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/GenerateJSON.bat', 'contrib/windows/WindowsPowerShell/Functions/Start-PowerShellProcess.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/Ionic.Zip.dll', 'contrib/windows/WindowsPowerShell/Functions/SQLServerInstaller.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/CoreFunctions.psm1', 'murano-ci/config/devstack/build-murano-image.sh', 'murano-ci/config/puppet-ci/modules/zabbix/templates/frontend/ping.php.erb', 'contrib/windows/ExecutionPlan/InstallIIS/GenerateJSON.bat', 'contrib/cirros/config.local.sh', 'contrib/windows/ExecutionPlan/DeployWebApp/GenerateJSON.bat', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/README.rst', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/item.pp', 'murano-ci/config/devstack/post-unstack.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/README.rst', 'murano-ci/infra/configure_api.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/2.Start-Sysprep.ps1', 'contrib/windows/ExecutionPlan/InstallSQL/GenerateJSON.sh', 'contrib/windows/WindowsPowerShell/Functions/Join-Domain.ps1', 'murano-ci/config/puppet-ci/manifests/ssh.pp', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAlwaysOn.yaml', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Base64.ps1', 'contrib/windows/ExecutionPlan/InstallSQL/ExecutionPlan.yaml.json', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/README.md', 'contrib/windows/image-builder/lib/templates/README.rst', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGPrimaryReplica.yaml', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/unattend.xml.template', 'murano-ci/config/puppet-ci/manifests/jenkins.pp', 'murano-ci/jenkins/jobs/ci-infra.yaml', 'murano-ci/config/puppet-ci/modules/pdnsd/templates/default_pdnsd.erb', 'contrib/windows/ExecutionPlan/InstallIIS/ExecutionPlan.yaml', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/ExecutionPlan.txt', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/frontend.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/proxy/zabbix_proxy.conf.erb', 'murano-ci/scripts/run_tests.sh', 'contrib/windows/WindowsPowerShell/Functions/Failover-Cluster.ps1', 'contrib/windows/ExecutionPlan/DeployWebApp/ExecutionPlan.txt', 'murano-ci/config/puppet-ci/doc/single_node_hiera_examples.rst', 'murano-ci/scripts/collect_results.sh', 'contrib/windows/image-builder/launch-vm.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/unattend.xml.template', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/ExecutionPlan.yaml', 'murano-ci/config/puppet-ci/doc/config_example.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/ConfigureEnvironmentForAOAG.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/autounattend.xml.template', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/Install-RolePrimaryDomainController.ps1', 'contrib/windows/ExecutionPlan/2.JoinDomain/GenerateJSON.sh', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverClusterPrerequisites.yaml', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/GenerateJSON.sh', 'murano-ci/nodepool/scripts/prepare_node_murano_devstack.sh', 'murano-ci/config/puppet-ci/modules/ssh/templates/nsswitch.conf.erb', 'murano-ci/scripts/syntax_check.sh', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverCluster.yaml', 'murano-ci/config/puppet-ci/README.rst', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/log4net.config', 'murano-ci/config/puppet-ci/modules/ssh/manifests/banner.pp', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/README.rst', 'murano-ci/config/puppet-ci/modules/zabbix/templates/proxy/zabbix_proxy_defaults.erb', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/README.rst', 'murano-ci/config/puppet-ci/modules/ssh/manifests/known_host.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/item.erb', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/ExecutionPlan.txt', 'murano-ci/tools/update_config.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/Config.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/3.Start-AtFirstBoot.ps1', 'murano-ci/tools/split-logs.sh', 'contrib/windows/ExecutionPlan/3.CreateSecondaryDC/out.json', 'murano-ci/nodepool/elements/README.md', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Module.ps1', 'murano-ci/config/puppet-ci/hiera/etc/config.yaml', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/NotCoreFunctions.ps1', 'murano-ci/scripts/collect_logs.sh', 'murano-ci/config/puppet-ci/modules/ssh/manifests/sshd.pp', 'murano-ci/infra/RabbitMQ.py', 'murano-ci/config/puppet-ci/hiera/hiera.yaml', 'contrib/windows/WindowsPowerShell/Makefile', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/service.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/server/zabbix_server.conf.erb', 'murano-ci/config/puppet-ci/hiera/etc/users.yaml', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/Get-DnsListeningIpAddress.ps1', 'contrib/windows/WindowsPowerShell/Functions/Update-ServiceConfig.ps1', 'murano-ci/scripts/generate_html_report.py', 'murano-ci/config/puppet-ci/manifests/zuul.pp', 'contrib/windows/WindowsPowerShell/Functions/SQLServerOptionParsers.ps1', 'murano-ci/nodepool/scripts/ready_script_murano.sh', 'murano-ci/config/puppet-ci/manifests/jenkins_jobs.pp', 'murano-ci/config/puppet-ci/modules/ssh/manifests/ldap.pp', 'murano-ci/config/puppet-ci/modules/ssh/templates/ldap.conf.erb', 'murano-ci/config/puppet-ci/manifests/users.pp', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/config.pp', 'murano-ci/scripts/common.inc', 'contrib/cirros/murano-agent.init', 'murano-ci/README.md', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/log4net.dll', 'contrib/windows/image-builder/README.rst', 'contrib/windows/ExecutionPlan/2.JoinDomain/ExecutionPlan.txt', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/server.pp', 'contrib/windows/image-builder/lib/windowssetup/unattend/README.rst', 'murano-ci/config/devstack/local.sh', 'murano-ci/tools/rotate-devstack-logs.sh', 'murano-ci/config/puppet-ci/manifests/nodepool.pp', 'contrib/windows/Unattended/ws-2012-core-unattended.xml', 'contrib/windows/ExecutionPlan/README.rst', 'contrib/windows/ExecutionPlan/InstallSQL/ExecutionPlan.yaml', 'contrib/windows/WindowsPowerShell/Functions/Install-SQLServer.ps1', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/GenerateJSON.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/autounattend.xml.template', 'murano-ci/config/puppet-ci/modules/ssh/manifests/params.pp', 'murano-ci/config/puppet-ci/modules/zabbix/templates/agent/zabbix_agentd.conf.erb', 'murano-ci/config/puppet-ci/manifests/ntp.pp', '.gitreview', 'murano-ci/nodepool/scripts/README.md', 'contrib/windows/WindowsPowerShell/Functions/Write-InvocationInfo.ps1', 'murano-ci/jenkins/scripts/README.md', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/CoreFunctions.psd1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/1.Windows-Post-Install.ps1', 'murano-ci/infra/deploy_component_new.sh', 'contrib/windows/ExecutionPlan/InstallIIS/ExecutionPlan.txt', 'contrib/windows/WindowsPowerShell/README.rst', 'murano-ci/config/puppet-ci/modules/pdnsd/templates/pdnsd.conf.erb', 'murano-ci/config/puppet-ci/modules/ssh/manifests/authorized_keys.pp', 'contrib/windows/WindowsPowerShell/Functions/SQLServerForAOAG.ps1', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Zip.ps1', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAlwaysOn.yaml.json', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/server/alertscript.pp', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/ExecutionPlan/DeployWebApp/Deploy-WebApp.ps1', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverClusterPrerequisites.yaml.json', 'contrib/windows/ExecutionPlan/GetDnsIpAddressesOnDc/out.json', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/config.ini', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/ExecutionPlan.yaml', 'murano-ci/config/puppet-ci/modules/zabbix/templates/sudoers.erb', 'murano-ci/scripts/start_gate.sh', 'contrib/windows/ExecutionPlan/InstallIIS/GenerateJSON.sh', 'contrib/windows/WindowsPowerShell/Functions/ImportCoreFunctions.ps1', 'murano-ci/jenkins/jobs/defaults.yaml', 'murano-ci/config/puppet-ci/modules/muranoci-extras/files/jenkins.default', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/autounattend.xml.template', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/out.json', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/ExecutionPlan.ps1', 'murano-ci/config/devstack/local.conf', 'murano-ci/scripts/deploy_devstack.sh', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverClusterPrerequisites.yaml', 'murano-ci/tools/update_pool.sh', 'murano-ci/config/puppet-ci/manifests/monitoring.pp', 'murano-ci/jenkins/jobs/README.md', 'contrib/windows/ExecutionPlan/2.JoinDomain/out.json', 'murano-ci/config/puppet-ci/manifests/dns.pp', 'contrib/windows/ExecutionPlan/ExecutionPlanGenerator.py', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/GenerateJSON.sh', 'murano-ci/config/puppet-ci/modules/zabbix/manifests/agent/service.pp', 'contrib/windows/image-builder/lib/templates/deafultnet.template', 'contrib/windows/WindowsPowerShell/Modules/CoreFunctions/include/Logger.ps1', 'murano-ci/config/puppet-ci/modules/zabbix/templates/server/zabbix_server_default.erb', 'murano-ci/nodepool/scripts/prepare_node.sh', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGSecondaryReplica.yaml', 'contrib/windows/ExecutionPlan/FailoverCluster/InstallFailoverCluster.yaml', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/InitializeAOAGPrimaryReplica.yaml.json', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/README.rst', 'murano-ci/zuul/openstack_functions.py', 'murano-ci/config/puppet-ci/modules/pdnsd/manifests/params.pp', 'contrib/windows/WindowsPowerShell/Functions/Export-Function.ps1', 'contrib/windows/ExecutionPlan/InstallIIS/out.json', 'contrib/windows/ExecutionPlan/SqlServerAlwaysOnAvailabilityGroup/FailoverCluster.yaml.json', 'contrib/windows/ExecutionPlan/1.CreatePrimaryDC/GenerateJSON.bat', 'contrib/windows/ExecutionPlan/ExecutionPlanGenerator.exe', 'contrib/windows/ExecutionPlan/4.JoinAndPromote/ExecutionPlan.txt', 'contrib/windows/ExecutionPlan/DeployWebApp/GenerateJSON.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/2.Start-Sysprep.ps1', 'murano-ci/zuul/layout.yaml', 'contrib/windows/Unattended/README.rst', 'contrib/windows/image-builder/runme.sh']",249,b570b11fc7702f3edbe10714ec4153e8a9ea4fb1,retire-murano-deployment,,"#!/bin/bash # Copyright (c) 2015 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # START_DIR=$(cd ""$(dirname ""${0}"")"" && pwd) WORK_DIR=""${START_DIR}/workspace"" CFG_FILE=""${CFG_FILE:-$START_DIR/config.ini}"" LOG_DIR=""${START_DIR}/logs"" LOG_FILE=""${LOG_DIR}/run_$(date +%Y-%m-%d_%H).log"" LOG_LVL=3 declare -A Config ######## FUNCTIONS ############## # logler function log() { local input=""$*"" if [ ! -d ""${LOG_DIR}"" ]; then mkdir -p ""${LOG_DIR}"" fi case ""${LOG_LVL}"" in 3) if [ ! -z ""${input}"" ]; then echo ""${input}"" | tee -a ""${LOG_FILE}"" fi ;; 2) if [ ! -z ""${input}"" ]; then echo ""${input}"" >> ""${LOG_FILE}"" fi ;; 1) if [ ! -z ""${input}"" ]; then echo ""${input}"" fi ;; *) ;; esac } # iniget config-file section option function iniget { local xtrace='' xtrace=$(set +o | grep xtrace) set +o xtrace local file=$1 local section=$2 local option=$3 local line line=$(sed -ne ""/^\[$section\]/,/^\[.*\]/ { /^$option[ \t]*=/ p; }"" ""$file"") echo ""${line#*=}"" $xtrace } # ini_has_option config-file section option function ini_has_option_sudo() { local file=$1 local section=$2 local option=$3 local line line=$(sudo sed -ne ""/^\[$section\]/,/^\[.*\]/ { /^$option[ \t]*=/ p; }"" ""$file"") [ -n ""$line"" ] } # iniset config-file section option value function iniset_sudo() { local xtrace=$(set +o | grep xtrace) set +o xtrace local file=$1 local section=$2 local option=$3 local value=$4 [[ -z $section || -z $option ]] && return if ! sudo grep -q ""^\[$section\]"" ""$file"" 2>/dev/null; then # Add section at the end echo -e ""\n[$section]"" | sudo tee -a ""$file"" fi if ! ini_has_option_sudo ""$file"" ""$section"" ""$option""; then # Add it sudo sed -i -e ""/^\[$section\]/ a\\ $option = $value "" ""$file"" else local sep=$(echo -ne ""\x01"") # Replace it sudo sed -i -e '/^\['${section}'\]/,/^\[.*\]/ s'${sep}'^\('${option}'[ \t]*=[ \t]*\).*$'${sep}'\1'""${value}""${sep} ""$file"" 2>/dev/null fi $xtrace } # check reuirements function check_sys_packages() { local forceinstall=""${1:-false}"" local retval=0 local packages=""qemu-kvm virt-manager virt-goodies virtinst bridge-utils libvirt-bin uuid-runtime samba samba-common cifs-utils zip"" if [ ! -f ""/etc/debian_version"" ] || ! lsb_release -a 2>/dev/null | grep -qE '(Mint|Ubuntu|Debian)'; then log ""Err: Ubuntu like distros only supported for now !"" exit 2 fi for package in ${packages} do dpkg-query --status ""${package}"" >> /dev/null 2>&1 if [ ""$?"" -ne 0 ]; then if [ ""${forceinstall}"" == true ]; then sudo apt-get install -y ""${package}"" || retval=$? else log ""Wrn: ${package} required, please install it !"" retval=1 fi fi done sudo usermod -a -G libvirtd ""${USER}"" 2>/dev/null return ""${retval}"" } # read configuration function init() { local wdir='' local vmswdir='' #local vioiso='' local reqsoft='' local winrels='' local prun='' local smbmode='' local smbhost='' local smbuser='' local smbdomain='' local smbpasswd='' local smbcredsfile='' local smbsharename='' wdir=$(iniget ""${CFG_FILE}"" ""default"" ""workdir"") vmswdir=$(iniget ""${CFG_FILE}"" ""default"" ""vmsworkdir"") prun=$(iniget ""${CFG_FILE}"" ""default"" ""runparallel"") reqsoft=$(iniget ""${CFG_FILE}"" ""default"" ""requirements"") winrels=$(iniget ""${CFG_FILE}"" ""default"" ""available_win_versions"") smbmode=$(iniget ""${CFG_FILE}"" ""samba"" ""mode"") smbhost=$(iniget ""${CFG_FILE}"" ""samba"" ""host"") smbuser=$(iniget ""${CFG_FILE}"" ""samba"" ""user"") smbdomain=$(iniget ""${CFG_FILE}"" ""samba"" ""domain"") smbpasswd=$(iniget ""${CFG_FILE}"" ""samba"" ""password"") smbsharename=$(iniget ""${CFG_FILE}"" ""samba"" ""sharename"") if [ ! -z ""${reqsoft}"" ]; then Config[""requirements""]=""${reqsoft}""; fi if [ ! -z ""${winrels}"" ]; then Config[""win_releases""]=""${winrels}""; fi if [ ! -z ""${prun}"" ]; then Config[""runparallel""]=""${prun}""; fi if [ ! -z ""${wdir}"" ]; then WORK_DIR=""${wdir}/workspace""; fi if [ ! -z ""${vmswdir}"" ]; then sudo mkdir -p ""${vmswdir}"" && sudo chown -R ""${USER}"" ""${vmswdir}"" || exit 2 Config[""vmsworkdir""]=""${vmswdir}"" fi if [ ! -d ""$WORK_DIR"" ]; then sudo mkdir -p ""${WORK_DIR}"" && sudo chown -R ""${USER}"":""${USER}"" ""${WORK_DIR}""/ || exit $? fi mkdir -p ""${WORK_DIR}/mnt"" || exit $? mkdir -p ""${WORK_DIR}/downloads"" || exit $? smbcredsfile=""${WORK_DIR}/smb.creds"" Config[""smbcredsfile""]=""${smbcredsfile}"" Config[""loopmountoptions""]=""-o uid=$(id -u),gid=$(id -g),loop"" Config[""smbmountoptions""]=""-o vers=2.0,nounix,iocharset=utf8,uid=$(id -u),gid=$(id -g)"" if [ ""${smbmode}"" == ""local"" ]; then Config[""smblocalsetuprequired""]=true else Config[""smblocalsetuprequired""]=false fi if [ ""${smbuser}"" != ""guest"" ]; then if [ -f ""${Config[""smbcredsfile""]}"" ]; then rm -f ""${Config[""smbcredsfile""]}"" || exit $?; fi echo username=""${smbuser}"" > ""${Config[""smbcredsfile""]}"" if [ ! -z ""${smbdomain}"" ]; then echo domain=""${smbdomain}"" >> ""${Config[""smbcredsfile""]}"" else echo domain=""${smbhost}"" >> ""${Config[""smbcredsfile""]}"" fi echo password=""${smbpasswd}"" >> ""${Config[""smbcredsfile""]}"" Config[""smbmountoptions""]+="",credentials=${Config[""smbcredsfile""]}"" else Config[""smbmountoptions""]+="",guest"" fi Config[""smbmountpoint""]=""${WORK_DIR}/mnt"" Config[""smbshare""]=""//${smbhost}/${smbsharename}"" Config[""downloadsdir""]=""${WORK_DIR}/downloads"" } # check disk space function check_free_space() { #directory should have at least 50G of free space local min_free_g=""50"" let min_free=${min_free_g}*1024*1024 local sys_free='' log ""Checking free space for ${Config[""vmsworkdir""]} folder partition..."" sys_free=$(sudo df ""${Config[""vmsworkdir""]}"" --total -k --output=avail | head -n2 | tail -n1) if [ ""${sys_free}"" -lt ""${min_free}"" ]; then log ""Err: You have not enough free space ${sys_free} at ${Config[""vmsworkdir""]}, required - ${min_free_g}G!"" exit 2 fi } # check libvirt function check_libvirtnet() { local networkname='default' log ""Checking libvirt network..."" virsh net-list | grep -q ""${networkname}"" if [ ""$?"" -ne 0 ]; then virsh net-define ""${START_DIR}/lib/templates/defaultnet.template"" || exit 2 virsh net-autostart ""${networkname}"" || exit 2 virsh net-start ""${networkname}"" || exit 2 fi } # iptables rules for local Samba server function set_iptables_smb_rules() { log ""Configuring iptables rules..."" sudo iptables -nvL INPUT | grep -q 'NetBIOS Name Service' || sudo iptables -A INPUT -p udp --dport 137 -m comment --comment ""add by winimage-builder - NetBIOS Name Service"" -j ACCEPT sudo iptables -nvL INPUT | grep -q 'NetBIOS Datagram Service' || sudo iptables -A INPUT -p udp --dport 138 -m comment --comment ""add by winimage-builder - NetBIOS Datagram Service"" -j ACCEPT sudo iptables -nvL INPUT | grep -q 'NetBIOS Session Service' || sudo iptables -A INPUT -p tcp --dport 139 -m comment --comment ""add by winimage-builder - NetBIOS Session Service"" -j ACCEPT sudo iptables -nvL INPUT | grep -q 'Microsoft Directory Service' || sudo iptables -A INPUT -p tcp --dport 445 -m comment --comment ""add by winimage-builder - Microsoft Directory Service"" -j ACCEPT } # check & configure local Samba server function prepare_local_sambaserver() { local share_path='' local sharename='' local makeserviceconfiguration=""${1:-false}"" local showtip=""${2:-false}"" local smbconf_path=""/etc/samba/smb.conf"" if [ ""${Config[""smblocalsetuprequired""]}"" == true ]; then if [ -f ""${smbconf_path}"" ] && [ ""${makeserviceconfiguration}"" == true ]; then log ""Configuring local Samba server..."" share_path=""${WORK_DIR}/smbshare"" sudo mkdir -p ""${share_path}"" || return $? sudo chown -R nobody:nogroup ""${share_path}"" sharename=$(iniget ""${CFG_FILE}"" ""samba"" ""sharename"") iniset_sudo ${smbconf_path} ""${sharename}"" 'comment' 'Image Builder Share' iniset_sudo ${smbconf_path} ""${sharename}"" 'path' ""${share_path}"" iniset_sudo ${smbconf_path} ""${sharename}"" 'browsable' ""yes"" iniset_sudo ${smbconf_path} ""${sharename}"" 'guest ok' ""yes"" iniset_sudo ${smbconf_path} ""${sharename}"" 'guest account' ""nobody"" iniset_sudo ${smbconf_path} ""${sharename}"" 'read only' ""no"" iniset_sudo ${smbconf_path} ""${sharename}"" 'create mask' ""0755"" log ""Restarting Samba services..."" sudo restart smbd || return $? sudo restart nmbd || return $? sleep 3 set_iptables_smb_rules return 0 else log ""Err: File ${smbconf_path} not found!"" return 1 fi else if [ ""${showtip}"" == true ]; then log ""FYI: please, configure youre remote samba resource properly with rw access and make modifications at ${CFG_FILE}, [samba] section!"" log ""FYI: Linux /etc/samba/smb.conf part template could looks like this:"" cat ""${START_DIR}/lib/templates/smbshare.conf.template"" fi fi return 0 } # mounting cifs/smbfs function checkmountremote() { sudo mount | grep -q ""${Config[""smbmountpoint""]}"" && umountremote sleep 1 } function mountremote() { log ""Mounting Samba share and checking rw access..."" sudo mount -t cifs ${Config[""smbshare""]} ${Config[""smbmountpoint""]} ${Config[""smbmountoptions""]} if [ ""$?"" -ne 0 ]; then log ""ERR: Can't mount ${Config[""smbshare""]}!""; exit 1;fi touch ""${Config[""smbmountpoint""]}/testfile"" && rm -f ""${Config[""smbmountpoint""]}/testfile"" || exit $? } # function umountremote() { log ""Unounting Samba share..."" sudo umount ""${Config[""smbmountpoint""]}"" if [ ""$?"" -ne 0 ]; then log ""ERR: Can't unmount ${Config[""smbmountpoint""]}!""; exit 1;fi } # prepare CoreFunctions function prepare_corefunctions_ps() { local cf_src_dir='' local cf_zipfile='' cf_src_dir=$(cd ""${START_DIR}""/../WindowsPowerShell && pwd) cd ""${cf_src_dir}"" && make all >> /dev/null 2>&1 if [ ""$?"" -ne 0 ]; then log ""Err: Can't build powershell CoreFunctions !"" exit 2 fi cf_zipfile=""${cf_src_dir}""/CoreFunctions.zip if [ ! -f ""${cf_zipfile}"" ]; then log ""Err: Please, check make parameters at ${cf_src_dir} of file name for ${cf_zipfile} !"" exit 2 fi mv ""${cf_zipfile}"" ""${Config[""downloadsdir""]}"" } # Download function downloadrequirements() { local sw_required=false local sw_redownload=false local sw_download_from='' local sw_download_as='' local sw_download_as_fullpath='' for requirement in ${Config[""requirements""]} do sw_required=$(iniget ""${CFG_FILE}"" ""${requirement}"" ""required"") if [ ""${sw_required}"" == true ]; then sw_download_as=$(iniget ""${CFG_FILE}"" ""${requirement}"" ""saveas"") sw_download_from=$(iniget ""${CFG_FILE}"" ""${requirement}"" ""url"") sw_redownload=$(iniget ""${CFG_FILE}"" ""${requirement}"" ""redownload"") if [ ""${requirement}"" == ""virtio_iso"" ]; then sw_download_as_fullpath=""${WORK_DIR}/${sw_download_as}"" Config[""virtio_iso""]=""${sw_download_as_fullpath}"" else sw_download_as_fullpath=""${Config[""downloadsdir""]}/${sw_download_as}"" fi if [ ! -f ""${sw_download_as_fullpath}"" ] || [ ""${sw_redownload}"" == true ]; then log ""Downloading ${requirement}..."" if [ ""${sw_redownload}"" == true ]; then rm -f ""${sw_download_as_fullpath}""; log "".redownload for ${requirement} enabled"" ;fi wget -q ""${sw_download_from}"" -O ""${sw_download_as_fullpath}"" if [ ""$?"" -ne 0 ]; then log ""Wrn: Error occurred during downloading of ${sw_download_from} !"";fi fi fi done } # show win_releases function show_configured_win_releases() { local rel_enabled=false local rel_iso='' local rel_desc='' local rel_edits='' for release in ${Config[""win_releases""]} do rel_enabled=$(iniget ""${CFG_FILE}"" ""${release}"" ""enabled"") if [ ""${rel_enabled}"" == true ]; then rel_iso=$(iniget ""${CFG_FILE}"" ""${release}"" ""iso"") if [ -f ""${rel_iso}"" ]; then rel_desc=$(iniget ""${CFG_FILE}"" ""${release}"" ""description"") rel_edits=$(iniget ""${CFG_FILE}"" ""${release}"" ""editions"") log ""[${release}] - ${rel_desc}(${rel_edits/ /,})"" else log ""Err: Can't access ${rel_iso}, please check ${CFG_FILE} [${release}] section!"" fi fi done } # prepare mirror function preparemirror() { local mirrordir=""${WORK_DIR}/mirror"" if [ ! -d ""${mirrordir}"" ]; then mkdir ""${mirrordir}"" else rm -rf ""${mirrordir}"" fi mkdir -p ""${mirrordir}/Scripts"" mkdir -p ""${mirrordir}/Files"" cp -r ""${Config[""downloadsdir""]}""/* ""${mirrordir}""/Files/ cp -r ""${START_DIR}""/lib/windowssetup/scripts/* ""${mirrordir}""/Scripts/ } # copy mirror to smbshare function copymirrortomnt() { local mirrordir=""${WORK_DIR}/mirror"" cp -r ""${mirrordir}""/* ""${Config[""smbmountpoint""]}""/ || exit $? rm -rf ""${mirrordir}"" } # prepare virtual floppy image function make_virtualfloppy() { local unattend_dir=""${1}"" local vms_path=""${2}"" local vfloppy='' local smbcreds='' local retval=0 if [ ! -d ""${vms_path}"" ]; then log ""Err: Can't access ${vms_path}, check [defaults]/vmsworkdir parameter !""; return ""${retval}""; fi vfloppy=""${vms_path}/startup.vfd"" sudo rm -f $vfloppy if [ ! -f ""${vfloppy}"" ]; then dd bs=512 count=2880 if=/dev/zero of=""${vfloppy}"" >> /dev/null 2>&1 || return $? mkfs.msdos ""${vfloppy}"" >> /dev/null || retval=$? mkdir -p ""${vms_path}""/mnt/floppy || retval=$? mount | grep -q ""${vms_path}""/mnt/floppy && sudo umount ""${vms_path}""/mnt/floppy 2>/dev/null sudo mount -t vfat ${Config[""loopmountoptions""]} ""${vfloppy}"" ""${vms_path}""/mnt/floppy/ || return $? cp ""${unattend_dir}/autounattend.xml.template"" ""${vms_path}""/mnt/floppy/autounattend.xml cp ""${unattend_dir}/unattend.xml.template"" ""${vms_path}""/mnt/floppy/nextunattend.xml sed ""s/%_IMAGE_BUILDER_HOST_%/$(iniget ""${CFG_FILE}"" ""samba"" ""host"")/g"" -i ""${vms_path}""/mnt/floppy/autounattend.xml || retval=$? sed ""s/%_SHARE_PATH_%/$(iniget ""${CFG_FILE}"" ""samba"" ""sharename"")/g"" -i ""${vms_path}""/mnt/floppy/autounattend.xml || retval=$? if [ ""$(iniget ""${CFG_FILE}"" ""samba"" ""mode"")"" == ""local"" ]; then smbcreds='' else local smbdomain smbdomain=$(iniget ""${CFG_FILE}"" ""samba"" ""domain"") if [ -z ""${smbdomain}"" ]; then smbdomain=$(iniget ""${CFG_FILE}"" ""samba"" ""host""); fi smbcreds=""\""$(iniget ""${CFG_FILE}"" ""samba"" ""password"")\"" \/USER:${smbdomain}\\\\$(iniget ""${CFG_FILE}"" ""samba"" ""user"")"" fi sed ""s/%_SHARE_CREDS_%/${smbcreds}/g"" -i ""${vms_path}""/mnt/floppy/autounattend.xml || retval=$? sleep 1 sudo umount ""${vms_path}""/mnt/floppy || return $? rm -rf ""${vms_path}""/mnt || return $? fi return ""${retval}"" } # copy virtio iso- function copy_virtiodrv() { local vms_path=""${1}"" if [ ! -f ""${Config[""virtio_iso""]}"" ]; then log ""Err: Cant access ${Config[""virtio_iso""]}, check [vitrio_iso] configuration section or file ${Config[""virtio_iso""]} exists !"" exit 2 else cp -f ""${Config[""virtio_iso""]}"" ""${vms_path}""/virtio.iso || return $? fi return 0 } # start install function start_win_vm() { local vms_path=""${1}"" local win_boot_iso_path=""${2}"" local vm_virtio_iso_path='' local vm_setup_vfd_path='' local vm_name='' local vm_build_log='' local vm_img_ref_path='' vm_virtio_iso_path=""${vms_path}""/virtio.iso vm_setup_vfd_path=""${vms_path}""/startup.vfd vm_name=""$(basename ""${vms_path}"")-$(uuidgen --time)"" vm_build_log=""${LOG_DIR}/${vm_name}.log"" vm_img_ref_path=""${WORK_DIR}/$(basename ""${vms_path}"")-ref.qcow2"" if [ ""${Config[""runparallel""]}"" == true ]; then IMAGE_BUILDER_ROOT=${vms_path} IMAGE_NAME=${vm_name} VIRTIO_ISO=${vm_virtio_iso_path} FLOPPY_IMG=${vm_setup_vfd_path} BOOT_ISO=${win_boot_iso_path} VM_REF_IMG_COPY_TO_WORKSPACE=${vm_img_ref_path} bash ""${START_DIR}/launch-vm.sh"" >> ""${vm_build_log}"" 2>&1 & log "" vm preparations in progress, reference image would be built as ${vm_img_ref_path}, check build logfile - ${vm_build_log} !"" else IMAGE_BUILDER_ROOT=${vms_path} IMAGE_NAME=${vm_name} VIRTIO_ISO=${vm_virtio_iso_path} FLOPPY_IMG=${vm_setup_vfd_path} BOOT_ISO=${win_boot_iso_path} VM_REF_IMG_COPY_TO_WORKSPACE=${vm_img_ref_path} bash ""${START_DIR}/launch-vm.sh"" 2>&1 | tee -a ""${vm_build_log}"" fi } # cycled build function process_windows() { local rel_enabled=false local rel_iso='' local rel_desc='' local rel_edits='' local rel_unattend_templ_prefix='' local rel_unattend_templ_dir='' local rel_vms_temp_dir='' for release in ${Config[""win_releases""]} do rel_enabled=$(iniget ""${CFG_FILE}"" ""${release}"" ""enabled"") if [ ""${rel_enabled}"" == true ]; then rel_desc=$(iniget ""${CFG_FILE}"" ""${release}"" ""description"") rel_iso=$(iniget ""${CFG_FILE}"" ""${release}"" ""iso"") rel_edits=$(iniget ""${CFG_FILE}"" ""${release}"" ""editions"") rel_unattend_templ_prefix=$(iniget ""${CFG_FILE}"" ""${release}"" ""unattend_template_prefix"") if [ -z ""${rel_unattend_templ_prefix}"" ]; then rel_unattend_templ_prefix=""${release}"" fi if [ -f ""${rel_iso}"" ]; then for rel_edition in ${rel_edits} do rel_unattend_templ_dir=""${START_DIR}/lib/windowssetup/unattend/${rel_unattend_templ_prefix}-${rel_edition}"" rel_vms_temp_dir=""${Config[""vmsworkdir""]}/${rel_unattend_templ_prefix}-${rel_edition}"" mkdir -p ""${rel_vms_temp_dir}"" || exit 2 make_virtualfloppy ""${rel_unattend_templ_dir}"" ""${rel_vms_temp_dir}"" if [ ""$?"" -ne 0 ]; then log ""Err: Can't create virtual floppy at ${rel_vms_temp_dir} with autounattend.xml !"" exit 2 fi copy_virtiodrv ""${rel_vms_temp_dir}"" if [ ""$?"" -ne 0 ]; then log ""Err: Can't copy virt-io drivers iso(${Config[""virtio_iso""]}) to ${rel_vms_temp_dir} !"" exit 2 fi log ""[${release}] - ${rel_edition} - build started at - ${rel_vms_temp_dir}..."" start_win_vm ""${rel_vms_temp_dir}"" ""${rel_iso}"" done else log ""Err: Can't access ${rel_iso}, please check ${CFG_FILE} [${release}] section!"" fi fi done } # usage function usage() { echo ""${0} --help - Help information --check-smb - Check or configure Samba server, please RUN this command at 1st!(${CFG_FILE} [samba] options) --download-requirements - Download required software dicribed in ${CFG_FILE} --show-configured - Display chosen MS Windows releases to build(${CFG_FILE} [default]/available_win_versions value) --run - Run automated image creation"" } # aka main function run_normal() { check_free_space check_libvirtnet prepare_corefunctions_ps downloadrequirements preparemirror prepare_local_sambaserver true false if [ ""$?"" -eq 0 ]; then checkmountremote mountremote copymirrortomnt process_windows sleep 1 umountremote fi rm -f ""${Config[""smbcredsfile""]}"" 2>/dev/null } #------------------------------------------------------------------------------ # start of main logic # if [ ""$#"" -eq 0 ]; then usage exit 1 fi # check_sys_packages false init # processing command line args while [ ""$#"" -ge 1 ] do key=""${1}"" case ${key} in --show-configured) show_configured_win_releases break ;; --config-file) if [ ! -z ""${2}"" ] & [ -f ""${2}"" ]; then CFG_FILE=""${2}"" init else echo ""Config file not set properly!"" exit 2 fi shift ;; --download-requirements) downloadrequirements break ;; --check-smb) prepare_local_sambaserver true true if [ ""$?"" -eq 0 ]; then checkmountremote mountremote sleep 1 umountremote rm -f ""${Config[""smbcredsfile""]}"" 2>/dev/null fi break ;; --forceinstall-dependencies) check_sys_packages true shift ;; --run) run_normal break ;; *) usage break ;; esac shift done #------------------------------------------------------------------------------ ",9,17906
openstack%2Fnetworking-onos~master~If9016c96282c5cd4b3391f06cf2ffb2eccda27eb,openstack/networking-onos,master,If9016c96282c5cd4b3391f06cf2ffb2eccda27eb,Support GENEVE tunnel type,ABANDONED,2019-01-07 07:26:58.000000000,2019-01-07 07:30:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-07 07:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/44020b96406cf18778610d367177b688c2400357', 'message': 'Support GENEVE tunnel type\n\nChange-Id: If9016c96282c5cd4b3391f06cf2ffb2eccda27eb\n'}, {'number': 2, 'created': '2019-01-07 07:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/6f3d5f706235d5e1cc5532da9a520b9d998dd588', 'message': 'Support GENEVE tunnel type\n\nChange-Id: If9016c96282c5cd4b3391f06cf2ffb2eccda27eb\n'}]",0,628890,6f3d5f706235d5e1cc5532da9a520b9d998dd588,4,1,2,28180,,,0,"Support GENEVE tunnel type

Change-Id: If9016c96282c5cd4b3391f06cf2ffb2eccda27eb
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/90/628890/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,44020b96406cf18778610d367177b688c2400357,stable/rocky," n_const.TYPE_GENEVE,",,1,0
openstack%2Fnova~master~I1614eae02d62aeab6936932bcdb15e893afa21aa,openstack/nova,master,I1614eae02d62aeab6936932bcdb15e893afa21aa,Rename method _gather_port_ids_and_networks to _get_cached_network_info,ABANDONED,2019-01-03 13:28:42.000000000,2019-01-07 07:29:09.000000000,,"[{'_account_id': 7}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-03 13:28:42.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/41d3e4e7ba420084212b4272f030f0026412e59f', 'message': 'Rename method _gather_port_ids_and_networks to _get_cached_network_info\n\nThe _gather_port_ids_and_networks method returns data based on\ndata stored in InstanceInfoCaches object.\nWe should differentiate it from other methods that base on\nNeutron point of view.\n\nChange-Id: I1614eae02d62aeab6936932bcdb15e893afa21aa\n'}]",0,628175,41d3e4e7ba420084212b4272f030f0026412e59f,15,13,1,24791,,,0,"Rename method _gather_port_ids_and_networks to _get_cached_network_info

The _gather_port_ids_and_networks method returns data based on
data stored in InstanceInfoCaches object.
We should differentiate it from other methods that base on
Neutron point of view.

Change-Id: I1614eae02d62aeab6936932bcdb15e893afa21aa
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/628175/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,41d3e4e7ba420084212b4272f030f0026412e59f,bug/1751923," @mock.patch('nova.network.neutronv2.api.API._get_cached_network_info') self, mock_get_cached_network_info, mock_get_cached_network_info.return_value = ([], []) _get_cached_network_info doesn't contain any duplicates The _get_cached_network_info method will be called with the new_networks, new_port_ids = self.api._get_cached_network_info( def test_get_cached_network_info_wrong_params(self): api._get_cached_network_info, api._get_cached_network_info, # We should not get as far as calling _get_cached_network_info mock.patch.object(self.api, '_get_cached_network_info', # We should not get as far as calling _get_cached_network_info mock.patch.object(self.api, '_get_cached_network_info', # We should not get as far as calling _get_cached_network_info self.api, '_get_cached_network_info',"," @mock.patch('nova.network.neutronv2.api.API._gather_port_ids_and_networks') self, mock_gather_port_ids_and_networks, mock_gather_port_ids_and_networks.return_value = ([], []) _gather_port_ids_and_networks doesn't contain any duplicates The _gather_port_ids_and_networks method will be called with the new_networks, new_port_ids = self.api._gather_port_ids_and_networks( def test_gather_port_ids_and_networks_wrong_params(self): api._gather_port_ids_and_networks, api._gather_port_ids_and_networks, # We should not get as far as calling _gather_port_ids_and_networks mock.patch.object(self.api, '_gather_port_ids_and_networks', # We should not get as far as calling _gather_port_ids_and_networks mock.patch.object(self.api, '_gather_port_ids_and_networks', # We should not get as far as calling _gather_port_ids_and_networks self.api, '_gather_port_ids_and_networks',",17,17
openstack%2Fopenstack-helm~master~Id2660a1c7f1808b7f74b3960abbd5bf6b72aa387,openstack/openstack-helm,master,Id2660a1c7f1808b7f74b3960abbd5bf6b72aa387,spelling errors,MERGED,2018-12-31 07:29:58.000000000,2019-01-07 07:14:06.000000000,2019-01-07 07:14:06.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 25747}, {'_account_id': 27507}]","[{'number': 1, 'created': '2018-12-31 07:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cc2db348b3a8271a98c4ea37c2ec4f741f795208', 'message': 'spelling errors\n\nChange-Id: Id2660a1c7f1808b7f74b3960abbd5bf6b72aa387\n'}, {'number': 2, 'created': '2019-01-05 04:40:00.000000000', 'files': ['doc/source/testing/ceph-resiliency/disk-failure.rst', 'keystone/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/50a65ca2979b11962ea7b3c75a0e4e3680a9eadf', 'message': 'spelling errors\n\nChange-Id: Id2660a1c7f1808b7f74b3960abbd5bf6b72aa387\n'}]",0,627863,50a65ca2979b11962ea7b3c75a0e4e3680a9eadf,11,5,2,29558,,,0,"spelling errors

Change-Id: Id2660a1c7f1808b7f74b3960abbd5bf6b72aa387
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/63/627863/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/testing/ceph-resiliency/disk-failure.rst', 'keystone/values.yaml']",2,cc2db348b3a8271a98c4ea37c2ec4f741f795208,," # NOTE(portdirect): to retain portability across images, and allow"," # NOTE(portdirect): to retain portability accross images, and allow",2,2
openstack%2Fironic~master~I2f20f13c9b3d92962db808fb8f1ffa2840f42334,openstack/ironic,master,I2f20f13c9b3d92962db808fb8f1ffa2840f42334,Fixing Redfish inspection,ABANDONED,2018-12-17 16:45:57.000000000,2019-01-07 07:06:06.000000000,,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 16635}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 25547}, {'_account_id': 26340}, {'_account_id': 28429}]","[{'number': 1, 'created': '2018-12-17 16:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e8ec687b78059320d027220e359de2bf05e470fd', 'message': 'Fixing Redfish inspection\n\nRedfish inspect operation now ignores missing ``local_gb`` property.\nFailure to detect ``local_gb`` should not make the inspection fail,\nfor instance it can be a disk-less node.\n\nThis patch also properly namespaces SushyError exception.\n\nIntroducing a new helper method, named\n``create_ports_for_enabled_macs_if_not_exist`` in inspect_utils\nmodule to handle Sushy returned ethernet summary results.\n\nStory: 2004622\nTask: 28542\n\nChange-Id: I2f20f13c9b3d92962db808fb8f1ffa2840f42334\nStory: 2004560\nTask: 28543\n'}, {'number': 2, 'created': '2018-12-18 11:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/74a744c9b38627b3225657d61dcabfba4ee1824c', 'message': 'Fixing Redfish inspection\n\nRedfish inspect operation now ignores missing ``local_gb`` property.\nFailure to detect ``local_gb`` should not make the inspection fail,\nfor instance it can be a disk-less node.\n\nThis patch also properly namespaces SushyError exception.\n\nIntroducing a new helper method, named\n``create_ports_for_enabled_macs_if_not_exist`` in inspect_utils\nmodule to handle Sushy returned ethernet summary results.\n\nStory: 2004622\nTask: 28542\n\nStory: 2004560\nTask: 28543\n\nChange-Id: I2f20f13c9b3d92962db808fb8f1ffa2840f42334\n'}, {'number': 3, 'created': '2018-12-18 11:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e38cba2957b1cb954bb21110da8199b6713f7943', 'message': 'Fixing Redfish inspection\n\nRedfish inspect operation now ignores missing ``local_gb`` property.\nFailure to detect ``local_gb`` should not make the inspection fail,\nfor instance it can be a disk-less node.\n\nThis patch also properly namespaces SushyError exception.\n\nIntroducing a new helper method, named\n``create_ports_for_enabled_macs_if_not_exist`` in inspect_utils\nmodule to handle Sushy returned ethernet summary results.\n\nStory: 2004622\nTask: 28542\n\nStory: 2004560\nTask: 28543\n\nChange-Id: I2f20f13c9b3d92962db808fb8f1ffa2840f42334\n'}, {'number': 4, 'created': '2018-12-18 17:56:45.000000000', 'files': ['doc/source/admin/drivers/redfish.rst', 'ironic/tests/unit/drivers/modules/redfish/test_inspect.py', 'ironic/tests/unit/drivers/modules/test_inspect_utils.py', 'ironic/tests/unit/drivers/third_party_driver_mock_specs.py', 'ironic/drivers/modules/inspect_utils.py', 'ironic/tests/unit/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/redfish/inspect.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cb4f03f77a23702ad1753c083593bf41a7cef927', 'message': 'Fixing Redfish inspection\n\nRedfish inspect operation now ignores missing ``local_gb`` property.\nFailure to detect ``local_gb`` should not make the inspection fail,\nfor instance it can be a disk-less node. Other bug fixes are:\n\n  - Properly namespaces SushyError exception.\n  - Replaces ``eth_summary`` with ``summary`` attribute on\n    ethernet_interfaces.\n\nIntroduces a new helper method, named\n``create_ports_for_enabled_macs_if_not_exist`` in inspect_utils\nmodule to handle Sushy returned ethernet summary results.\n\nStory: 2004622\nTask: 28542\n\nStory: 2004560\nTask: 28543\n\nStory: 2004638\nTask: 28574\n\nChange-Id: I2f20f13c9b3d92962db808fb8f1ffa2840f42334\n'}]",9,625659,cb4f03f77a23702ad1753c083593bf41a7cef927,40,12,4,16635,,,0,"Fixing Redfish inspection

Redfish inspect operation now ignores missing ``local_gb`` property.
Failure to detect ``local_gb`` should not make the inspection fail,
for instance it can be a disk-less node. Other bug fixes are:

  - Properly namespaces SushyError exception.
  - Replaces ``eth_summary`` with ``summary`` attribute on
    ethernet_interfaces.

Introduces a new helper method, named
``create_ports_for_enabled_macs_if_not_exist`` in inspect_utils
module to handle Sushy returned ethernet summary results.

Story: 2004622
Task: 28542

Story: 2004560
Task: 28543

Story: 2004638
Task: 28574

Change-Id: I2f20f13c9b3d92962db808fb8f1ffa2840f42334
",git fetch https://review.opendev.org/openstack/ironic refs/changes/59/625659/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/redfish/test_inspect.py', 'ironic/tests/unit/drivers/modules/test_inspect_utils.py', 'ironic/tests/unit/drivers/third_party_driver_mock_specs.py', 'ironic/drivers/modules/inspect_utils.py', 'ironic/tests/unit/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/redfish/inspect.py']",6,e8ec687b78059320d027220e359de2bf05e470fd,fix-redfish-inspect," except sushy.exceptions.SushyError as ex: except sushy.exceptions.SushyError as ex: try: if storage_size == 0: LOG.debug(""Attempting to get storage disk information for "" ""node %(node)s"", {'node': task.node.uuid}) if system.storage and system.storage.drives_sizes_bytes: storage_size = [ size for size in system.storage.drives_sizes_bytes if size >= 4 * units.Gi ] or [0] storage_size = storage_size[0] except sushy.exceptions.SushyError as ex: LOG.debug(""No storage disk information discovered "" ""for node %(node)s: %(err)s"", {'node': task.node.uuid, 'err': ex}) ""for node %(node)s. Assuming this is a disk-less node"", {'node': task.node.uuid}) inspected_properties['local_gb'] = '0' system.ethernet_interfaces.summary): macs = system.ethernet_interfaces.summary # Create ports for the enabled state NICs detected. inspect_utils.create_ports_for_enabled_macs_if_not_exist( task, macs)"," except sushy.SushyError as ex: except sushy.SushyError as ex: ""for node %(node)s"", {'node': task.node.uuid}) system.ethernet_interfaces.eth_summary): macs = system.ethernet_interfaces.eth_summary # Create ports for the nics detected. inspect_utils.create_ports_if_not_exist(task, macs) ",120,30
openstack%2Frequirements~master~I9aecf86063d234ad9a7068d08fc64b99a14e83f3,openstack/requirements,master,I9aecf86063d234ad9a7068d08fc64b99a14e83f3,Updated from generate-constraints,MERGED,2019-01-05 06:11:33.000000000,2019-01-07 06:19:50.000000000,2019-01-07 06:19:50.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-05 06:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c263d2444f078315419e6335d05bdf63a39e9350', 'message': 'Updated from generate-constraints\n\nChange-Id: I9aecf86063d234ad9a7068d08fc64b99a14e83f3\n'}, {'number': 2, 'created': '2019-01-06 21:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6f43a893742a9f8dc6ecb3098496d112c9f1dc2b', 'message': 'Updated from generate-constraints\n\nChange-Id: I9aecf86063d234ad9a7068d08fc64b99a14e83f3\n'}, {'number': 3, 'created': '2019-01-06 23:26:55.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/76cc89d307a3b1d75a54ed43b1c8d99f6ada66df', 'message': 'Updated from generate-constraints\n\nChange-Id: I9aecf86063d234ad9a7068d08fc64b99a14e83f3\n'}]",0,628720,76cc89d307a3b1d75a54ed43b1c8d99f6ada66df,12,2,3,11131,,,0,"Updated from generate-constraints

Change-Id: I9aecf86063d234ad9a7068d08fc64b99a14e83f3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/20/628720/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,c263d2444f078315419e6335d05bdf63a39e9350,openstack/requirements/constraints/noclob,lxml===4.3.0rsd-lib===0.3.1tornado===4.5.3;python_version=='3.4' tornado===4.5.3;python_version=='3.5' tornado===4.5.3;python_version=='3.6' tornado===5.1.1;python_version=='2.7'openshift===0.8.2opentracing===2.0.0salt===2018.3.3botocore===1.12.74Django===1.11.18;python_version=='2.7' Django===2.0.10;python_version=='3.4' Django===2.0.10;python_version=='3.5' Django===2.0.10;python_version=='3.6',lxml===4.2.6rsd-lib===0.3.0tornado===4.5.3openshift===0.8.1opentracing===1.3.0salt===2018.3.2botocore===1.12.73Django===1.11.17;python_version=='2.7' Django===2.0.9;python_version=='3.4' Django===2.0.9;python_version=='3.5' Django===2.0.9;python_version=='3.6',14,11
openstack%2Ftripleo-repos~master~I23df8f6fe68ba47c92bdb3c031de44b47b1a16e2,openstack/tripleo-repos,master,I23df8f6fe68ba47c92bdb3c031de44b47b1a16e2,Add fedora support to tripleo-repos,MERGED,2018-11-05 23:56:22.000000000,2019-01-07 06:08:20.000000000,2018-11-12 02:19:43.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-11-05 23:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/bbdcb51c26df01bf504e846acd25b358d1640f25', 'message': 'Add fedora support to tripleo-repos\n\nFor Stein we are working on tripleo support as part of the python3 code.\nIn order to assist in the development, tripleo-repos should allow for\nfedora to be passed into the command.\n\nChange-Id: I23df8f6fe68ba47c92bdb3c031de44b47b1a16e2\nRelated-Blueprint: python3-support\n'}, {'number': 2, 'created': '2018-11-06 00:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/ca40311783b3e8a2f0ae742d81f52ec0ea9e21ea', 'message': 'Add fedora support to tripleo-repos\n\nFor Stein we are working on tripleo support as part of the python3 code.\nIn order to assist in the development, tripleo-repos should allow for\nfedora to be passed into the command.\n\nChange-Id: I23df8f6fe68ba47c92bdb3c031de44b47b1a16e2\nRelated-Blueprint: python3-support\n'}, {'number': 3, 'created': '2018-11-06 16:00:56.000000000', 'files': ['tripleo_repos/tests/test_main.py', 'tripleo_repos/main.py'], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/1389b7a9dbd00e6d340341c7bd36d181d6a9cab2', 'message': 'Add fedora support to tripleo-repos\n\nFor Stein we are working on tripleo support as part of the python3 code.\nIn order to assist in the development, tripleo-repos should allow for\nfedora to be passed into the command.\n\nChange-Id: I23df8f6fe68ba47c92bdb3c031de44b47b1a16e2\nRelated-Blueprint: python3-support\n'}]",1,615693,1389b7a9dbd00e6d340341c7bd36d181d6a9cab2,13,3,3,14985,,,0,"Add fedora support to tripleo-repos

For Stein we are working on tripleo support as part of the python3 code.
In order to assist in the development, tripleo-repos should allow for
fedora to be passed into the command.

Change-Id: I23df8f6fe68ba47c92bdb3c031de44b47b1a16e2
Related-Blueprint: python3-support
",git fetch https://review.opendev.org/openstack/tripleo-repos refs/changes/93/615693/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_repos/tests/test_main.py', 'tripleo_repos/main.py']",2,bbdcb51c26df01bf504e846acd25b358d1640f25,bp/python3-support,"def _validate_distro_repos(args): """"""Validate requested repos are valid for the distro"""""" if args.distro in ['fedora']: valid_repos = ['current', 'ceph', 'deps'] elif args.distro in ['centos7']: valid_repos = ['ceph', 'current', 'current-tripleo', 'current-tripleo-dev', 'deps'] invalid_repos = filter(lambda x: x not in valid_repos, args.repos) if len(invalid_repos) > 0: raise InvalidArguments('{} repo(s) are not valid for {}. Valid repos ' 'are: {}'.format(invalid_repos, args.distro, valid_repos)) return True if args.distro not in ['centos7', 'fedora']: raise InvalidArguments('centos7 or fedora is the only supported ' 'distros at this time') _validate_distro_repos(args) if args.distro not in ['centos7']: raise InvalidArguments('Branches only suppported with centos7')def _run_pkg_clean(distro): pkg_mgr = 'yum' if distro == 'centos7' else 'dnf' try: subprocess.check_call([pkg_mgr, 'clean', 'metadata']) if args.distro in ['centos7']: _install_priorities() _run_pkg_clean(args.distro)"," if args.distro != 'centos7': raise InvalidArguments('centos7 is the only supported distro')def _run_yum_clean(): try: subprocess.check_call(['yum', 'clean', 'metadata']) _install_priorities() _run_yum_clean()",88,20
openstack%2Fpuppet-qdr~master~Ia70639a6f794bd86d247050ea2bd5292e826cd19,openstack/puppet-qdr,master,Ia70639a6f794bd86d247050ea2bd5292e826cd19,Use 'dnf' provider for Fedora and RedHat > 7,MERGED,2018-12-19 09:41:05.000000000,2019-01-07 05:58:58.000000000,2019-01-07 05:58:58.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2018-12-19 09:41:05.000000000', 'files': ['manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-qdr/commit/08d62670e73197df47f77985cc3a6ae1da53bda0', 'message': ""Use 'dnf' provider for Fedora and RedHat > 7\n\nChange-Id: Ia70639a6f794bd86d247050ea2bd5292e826cd19\n""}]",0,626129,08d62670e73197df47f77985cc3a6ae1da53bda0,8,5,1,13861,,,0,"Use 'dnf' provider for Fedora and RedHat > 7

Change-Id: Ia70639a6f794bd86d247050ea2bd5292e826cd19
",git fetch https://review.opendev.org/openstack/puppet-qdr refs/changes/29/626129/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/params.pp'],1,08d62670e73197df47f77985cc3a6ae1da53bda0,py3-enable, if ($::os['name'] == 'Fedora') or ($::os['family'] == 'RedHat' and Integer.new($::os['release']['major']) > 7) { $_package_provider = 'dnf' } else { $_package_provider = 'yum' } $package_provider = $_package_provider, $package_provider = 'yum',7,1
openstack%2Fmonasca-analytics~master~I3bb98ef733ff16558d241968b06c31fa7508d047,openstack/monasca-analytics,master,I3bb98ef733ff16558d241968b06c31fa7508d047,Update requirements,MERGED,2018-11-05 12:09:25.000000000,2019-01-07 05:50:23.000000000,2019-01-07 05:50:23.000000000,"[{'_account_id': 12193}, {'_account_id': 14162}, {'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-05 12:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/440d9ea732d02fad27b5432d79810ebcc9241031', 'message': 'Update requirements\n\n""findspark"" and ""libpgm"" packages are no longer in use.\n""global-reqirements"" needs ""scikit-learn"" instead of ""sklearn"" which is old package name.\n\nChange-Id: I3bb98ef733ff16558d241968b06c31fa7508d047\n'}, {'number': 2, 'created': '2018-12-27 11:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/a224fbcc00825b19ce01a81c56eb5661b604e77e', 'message': 'Update requirements\n\n""findspark"" and ""libpgm"" packages are no longer in use.\n""global-reqirements"" needs ""scikit-learn"" instead of ""sklearn"" which is old package name.\nRemove ""docopt"" and re-wite code wihtout ""docopt"".\n\nChange-Id: I3bb98ef733ff16558d241968b06c31fa7508d047\n'}, {'number': 3, 'created': '2019-01-07 05:33:12.000000000', 'files': ['requirements.txt', 'run.py', '.zuul.yaml', 'test/test_run.py'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/3542d404c59d1f3fbd42effe642175e804327d2a', 'message': 'Update requirements\n\nThis patch includes the following updates.\n\n- Remove ""findspark"" and ""libpgm"" packages.\n    There are no longer in use.\n\n- Rename ""sklearn"" to ""scikit-learn"".\n    ""global-reqirements"" needs ""scikit-learn"" instead of ""sklearn"" which is old package name.\n\n- Pin scipy version less than 1.2.0.\n    Currently, according to upper-constraints.txt of openstack/requirements, scipy version is \'1.2.0\'.\n    However, this scipy version seems to be unable to import and use some scikit-learn libraries.\n\n- Remove ""docopt"" and re-wite code wihtout ""docopt"".\n    ""docopt"" is not used in OpenStack.\n\n- Remove requirements-check job.\n    Currently, ""tornado"" is a required package, but requirements-check job has a error.\n    However, to remove that error, adding ""tornado"" package to openstack/requirements was refused.\n\nChange-Id: I3bb98ef733ff16558d241968b06c31fa7508d047\n'}]",0,615542,3542d404c59d1f3fbd42effe642175e804327d2a,20,4,3,14162,,,0,"Update requirements

This patch includes the following updates.

- Remove ""findspark"" and ""libpgm"" packages.
    There are no longer in use.

- Rename ""sklearn"" to ""scikit-learn"".
    ""global-reqirements"" needs ""scikit-learn"" instead of ""sklearn"" which is old package name.

- Pin scipy version less than 1.2.0.
    Currently, according to upper-constraints.txt of openstack/requirements, scipy version is '1.2.0'.
    However, this scipy version seems to be unable to import and use some scikit-learn libraries.

- Remove ""docopt"" and re-wite code wihtout ""docopt"".
    ""docopt"" is not used in OpenStack.

- Remove requirements-check job.
    Currently, ""tornado"" is a required package, but requirements-check job has a error.
    However, to remove that error, adding ""tornado"" package to openstack/requirements was refused.

Change-Id: I3bb98ef733ff16558d241968b06c31fa7508d047
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/42/615542/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,440d9ea732d02fad27b5432d79810ebcc9241031,requirements,scikit-learn,findspark libpgmsklearn,1,3
openstack%2Fneutron-vpnaas~master~I718bc2b9db7f2199369e1d85ddb49ebd9774439d,openstack/neutron-vpnaas,master,I718bc2b9db7f2199369e1d85ddb49ebd9774439d,Increment versioning with pbr instruction,MERGED,2018-10-15 13:47:41.000000000,2019-01-07 04:32:41.000000000,2019-01-07 04:32:41.000000000,"[{'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 8871}, {'_account_id': 11904}, {'_account_id': 15905}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-15 13:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/d143ee8b65fa85d3f8571fe13a9fd1e4efd0c765', 'message': 'Increment versioning with pbr instruction\n\nWith moving away from required milestone releases, the version numbers\ncalculated by PBR on the master branch will not work for those testing\nupgrades from the last stable release. More details can be found in the\nmailing list post here:\n\n    http://lists.openstack.org/pipermail/openstack-dev/2018-October/135706.html\n\nThis is an empty commit that will cause PBR to increment its calculated\nversion to get around this.\n\nPBR will see the following which will cause it to increment the version:\n\nSem-Ver: feature\n\nPlease merge this patch as soon as possible to support those testing\nupgrades.\n\nChange-Id: I718bc2b9db7f2199369e1d85ddb49ebd9774439d\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2018-12-20 17:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/f26ef2ff11723dff83cdf4e134c6198ef63de9d0', 'message': 'Increment versioning with pbr instruction\n\nWith moving away from required milestone releases, the version numbers\ncalculated by PBR on the master branch will not work for those testing\nupgrades from the last stable release. More details can be found in the\nmailing list post here:\n\n    http://lists.openstack.org/pipermail/openstack-dev/2018-October/135706.html\n\nThis is an empty commit that will cause PBR to increment its calculated\nversion to get around this.\n\nPBR will see the following which will cause it to increment the version:\n\nSem-Ver: feature\n\nPlease merge this patch as soon as possible to support those testing\nupgrades.\n\nChange-Id: I718bc2b9db7f2199369e1d85ddb49ebd9774439d\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,610537,f26ef2ff11723dff83cdf4e134c6198ef63de9d0,28,7,2,11904,,,0,"Increment versioning with pbr instruction

With moving away from required milestone releases, the version numbers
calculated by PBR on the master branch will not work for those testing
upgrades from the last stable release. More details can be found in the
mailing list post here:

    http://lists.openstack.org/pipermail/openstack-dev/2018-October/135706.html

This is an empty commit that will cause PBR to increment its calculated
version to get around this.

PBR will see the following which will cause it to increment the version:

Sem-Ver: feature

Please merge this patch as soon as possible to support those testing
upgrades.

Change-Id: I718bc2b9db7f2199369e1d85ddb49ebd9774439d
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/37/610537/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,d143ee8b65fa85d3f8571fe13a9fd1e4efd0c765,sem-ver,,,0,0
openstack%2Fmonasca-analytics~master~Ida186d3a556bbe58d1806cd50a60b90b3a8344d8,openstack/monasca-analytics,master,Ida186d3a556bbe58d1806cd50a60b90b3a8344d8,Pin scipy version less than 1.2.0,ABANDONED,2018-12-29 03:59:16.000000000,2019-01-07 04:32:07.000000000,,"[{'_account_id': 10311}, {'_account_id': 12193}, {'_account_id': 14162}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-29 03:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/76438566740792ef51014013c5dc45c5a951ffa1', 'message': ""Pin scipy version less than 1.2.06\n\nCurrently, according to upper-constraints.txt of openstack/requirements,\nscipy version is '1.2.0'.\n\nHowever, this scipy version seems to be unable to import and use some scikit-learn libraries.\nTherefore, openstack-tox-py27 of Zuul check has failed.\n\nChange-Id: Ida186d3a556bbe58d1806cd50a60b90b3a8344d8\n""}, {'number': 2, 'created': '2018-12-29 04:00:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-analytics/commit/9ed2752dac13903c44ec3ac24d335cd2a9fdab85', 'message': ""Pin scipy version less than 1.2.0\n\nCurrently, according to upper-constraints.txt of openstack/requirements,\nscipy version is '1.2.0'.\n\nHowever, this scipy version seems to be unable to import and use some scikit-learn libraries.\nTherefore, openstack-tox-py27 of Zuul check has failed.\n\nChange-Id: Ida186d3a556bbe58d1806cd50a60b90b3a8344d8\n""}]",0,627757,9ed2752dac13903c44ec3ac24d335cd2a9fdab85,7,4,2,14162,,,0,"Pin scipy version less than 1.2.0

Currently, according to upper-constraints.txt of openstack/requirements,
scipy version is '1.2.0'.

However, this scipy version seems to be unable to import and use some scikit-learn libraries.
Therefore, openstack-tox-py27 of Zuul check has failed.

Change-Id: Ida186d3a556bbe58d1806cd50a60b90b3a8344d8
",git fetch https://review.opendev.org/openstack/monasca-analytics refs/changes/57/627757/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,76438566740792ef51014013c5dc45c5a951ffa1,pkg/scipy,scipy < 1.2.0,scipy,1,1
openstack%2Fkeystone~master~I39235a394d6bc59aad84e6f6a779d39036199302,openstack/keystone,master,I39235a394d6bc59aad84e6f6a779d39036199302,Add prerequisites section to keystone-to-keystone,MERGED,2018-12-30 20:01:06.000000000,2019-01-07 04:04:37.000000000,2019-01-07 04:04:37.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 20:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d8cfeaf442b3fafb4efab48d05b49ada55d5ea59', 'message': 'Add prerequisites section to keystone-to-keystone\n\nMake the keystone-to-keystone section mirror the keystone-as-sp section\nby adding a prerequisites section that identifies some useful background\ninformation, and clean up some outdated information.\n\nPartial-bug: #1793374\n\nChange-Id: I39235a394d6bc59aad84e6f6a779d39036199302\n'}, {'number': 2, 'created': '2019-01-02 12:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/19b439ca3e50e40d5d10c8dd16aa071c34d990f6', 'message': 'Add prerequisites section to keystone-to-keystone\n\nMake the keystone-to-keystone section mirror the keystone-as-sp section\nby adding a prerequisites section that identifies some useful background\ninformation, and clean up some outdated information.\n\nPartial-bug: #1793374\n\nChange-Id: I39235a394d6bc59aad84e6f6a779d39036199302\n'}, {'number': 3, 'created': '2019-01-04 09:46:47.000000000', 'files': ['doc/source/admin/federation/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/94b3ba6310f2bb241d9295b1f0d1c241cf1667e5', 'message': 'Add prerequisites section to keystone-to-keystone\n\nMake the keystone-to-keystone section mirror the keystone-as-sp section\nby adding a prerequisites section that identifies some useful background\ninformation, and clean up some outdated information.\n\nPartial-bug: #1793374\n\nChange-Id: I39235a394d6bc59aad84e6f6a779d39036199302\n'}]",2,627847,94b3ba6310f2bb241d9295b1f0d1c241cf1667e5,14,4,3,8482,,,0,"Add prerequisites section to keystone-to-keystone

Make the keystone-to-keystone section mirror the keystone-as-sp section
by adding a prerequisites section that identifies some useful background
information, and clean up some outdated information.

Partial-bug: #1793374

Change-Id: I39235a394d6bc59aad84e6f6a779d39036199302
",git fetch https://review.opendev.org/openstack/keystone refs/changes/47/627847/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/federation/configure_federation.rst'],1,d8cfeaf442b3fafb4efab48d05b49ada55d5ea59,bug/1793374,"Prerequisites ------------- When keystone is configured as an Identity Provider, it is often refered to as `Keystone to Keystone`, because enables federation between multiple OpenStack clouds using the SAML2.0 protocol. If you are not familiar with the idea of federated identity, see the `introduction`_ first. When setting up `Keystone to Keystone`, it is easiest to `configure a keystone Service Provider`_ first with a sandbox Identity Provider such as `samltest.id`_. .. _configure a keystone Service Provider: :ref:`Keystone as a Service Provider (SP)` .. _samltest.id: https://samltest.id This feature requires installation of the xmlsec1 tool via your distribution packaging system (for instance apt or yum) .. code-block:: bash # apt-get install xmlsec1",.. NOTE:: This feature is experimental and unsupported in Juno (with several issues that will not be backported). These issues have been fixed and this feature is considered stable and supported as of the Kilo release. .. NOTE:: This feature requires installation of the xmlsec1 tool via your distribution packaging system (for instance apt or yum) Example for apt: .. code-block:: bash # apt-get install xmlsec1,17,10
openstack%2Fkeystone~master~I75a342e84cddf6023470cd00fb34ca1c40dab956,openstack/keystone,master,I75a342e84cddf6023470cd00fb34ca1c40dab956,Remove duplicate RBAC logging from enforcer,MERGED,2018-12-12 20:04:53.000000000,2019-01-07 04:04:35.000000000,2019-01-07 04:04:35.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-12-12 20:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/78395bc56afaf226d2d3754b8cdfb679089f962f', 'message': 'Remove duplicate RBAC logging from enforcer\n\nA recent change to oslo.policy allowed RBAC enforcement data to be\nlogged there, making it more reusable and consistent for other\nservices using oslo.policy:\n\n  I4642c57990b145c0e691140970574412682e66a5\n\nThis commit removes keystone-specific code for debug logging the same\ninformation.\n\nChange-Id: I75a342e84cddf6023470cd00fb34ca1c40dab956\n'}, {'number': 2, 'created': '2019-01-03 09:40:19.000000000', 'files': ['keystone/common/rbac_enforcer/enforcer.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/969fa5df6f7e3bdd7c13799848cbe404101f8505', 'message': 'Remove duplicate RBAC logging from enforcer\n\nA recent change to oslo.policy allowed RBAC enforcement data to be\nlogged there, making it more reusable and consistent for other\nservices using oslo.policy:\n\n  I4642c57990b145c0e691140970574412682e66a5\n\nThis commit removes keystone-specific code for debug logging the same\ninformation.\n\nChange-Id: I75a342e84cddf6023470cd00fb34ca1c40dab956\n'}]",3,624799,969fa5df6f7e3bdd7c13799848cbe404101f8505,12,5,2,5046,,,0,"Remove duplicate RBAC logging from enforcer

A recent change to oslo.policy allowed RBAC enforcement data to be
logged there, making it more reusable and consistent for other
services using oslo.policy:

  I4642c57990b145c0e691140970574412682e66a5

This commit removes keystone-specific code for debug logging the same
information.

Change-Id: I75a342e84cddf6023470cd00fb34ca1c40dab956
",git fetch https://review.opendev.org/openstack/keystone refs/changes/99/624799/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/rbac_enforcer/enforcer.py'],1,78395bc56afaf226d2d3754b8cdfb679089f962f,624799, ctxt = cls._get_oslo_req_context()," ctxt = cls._get_oslo_req_context() creds = ctxt.to_policy_values() # LOG the Cred Data cred_str = ', '.join(['%s=%s' % (k, v) for k, v in creds.items()]) cred_str = strutils.mask_password(cred_str) LOG.debug('RBAC: Policy Enforcement Cred Data ' '`%(action)s creds(%(cred_str)s)`', {'action': action, 'cred_str': cred_str}) # Log the Target Data target_str = ', '.join( ['%s=%s' % (k, v) for k, v in flattened.items()]) target_str = strutils.mask_password(target_str) LOG.debug('RBAC: Policy Enforcement Target Data ' '`%(action)s => target(%(target_str)s)`', {'action': action, 'target_str': target_str}) ",1,17
openstack%2Fopenstack-ansible-specs~master~I5ab52716f806862d1265c51617fc6b8ad2598ab9,openstack/openstack-ansible-specs,master,I5ab52716f806862d1265c51617fc6b8ad2598ab9,[Trivial Fix] dumplicate words was deleted in developer-docs.rst,MERGED,2019-01-07 03:03:05.000000000,2019-01-07 03:51:03.000000000,2019-01-07 03:51:03.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 03:03:05.000000000', 'files': ['specs/kilo/developer-docs.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-specs/commit/055cfacf8321559920b7805a054601758818311c', 'message': '[Trivial Fix] dumplicate words was deleted in developer-docs.rst\n\nChange-Id: I5ab52716f806862d1265c51617fc6b8ad2598ab9\n'}]",0,628840,055cfacf8321559920b7805a054601758818311c,6,2,1,27565,,,0,"[Trivial Fix] dumplicate words was deleted in developer-docs.rst

Change-Id: I5ab52716f806862d1265c51617fc6b8ad2598ab9
",git fetch https://review.opendev.org/openstack/openstack-ansible-specs refs/changes/40/628840/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/developer-docs.rst'],1,055cfacf8321559920b7805a054601758818311c,, file and the inventory_management.py files., file and and the inventory_management.py files.,1,1
openstack%2Fneutron~master~Ie819c215944514d0bb43c2ce87394825bda41e94,openstack/neutron,master,Ie819c215944514d0bb43c2ce87394825bda41e94,Add bulk port creation of DB objects,MERGED,2018-07-23 20:46:31.000000000,2019-01-07 03:47:33.000000000,2018-11-30 22:39:34.000000000,"[{'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4187}, {'_account_id': 8871}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 17120}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-07-23 20:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5437b6d317b1a024d3c635712fe19effec747b7', 'message': '[WIP] Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nImplements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 2, 'created': '2018-08-21 15:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45837ff98b6b5b85969b2130e619bd31c1aef19b', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nImplements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 3, 'created': '2018-08-21 21:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5646656fd8cb68d20b8f2652ebf7db3359fe0197', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nImplements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 4, 'created': '2018-08-22 15:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15e684e063483fbb1c90575e4bc2336b25e53f39', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 5, 'created': '2018-08-31 13:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1a47523a10b924cbd6c3d4df9197e9131c0d6e3', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 6, 'created': '2018-10-02 00:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4c76d40099870744562073180e0af0711dd3690', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 7, 'created': '2018-10-05 20:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3435082338a245dfe3338255ce67d47d2220348a', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 8, 'created': '2018-10-17 13:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ac05d1a1b6b9396de696e9fe6d919d2068a8e69', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 9, 'created': '2018-10-31 20:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50b815109b3a83408a38eb919bf02a539f5af1a0', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 10, 'created': '2018-11-01 01:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da25c9365c59db3950067420402a7f707459083c', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 11, 'created': '2018-11-08 18:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70f7523fb2b8a2b80770119ee9e718322b2b85cd', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 12, 'created': '2018-11-08 19:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efa02693247c826a02981b506922e30148109d15', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 13, 'created': '2018-11-12 23:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1b824f07559a51ceca1e9a5a1ee94688746c513', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 14, 'created': '2018-11-13 12:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa326e0cc95a057c595284696875e7a5fce57ca6', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 15, 'created': '2018-11-19 21:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc1772dba886dd5596627ad5d7dc5e53721fd4b4', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 16, 'created': '2018-11-21 16:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/91db0a32938a3928eee0a2c3842e4be42d6e3abf', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 17, 'created': '2018-11-21 21:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d012fde5f883ba7ab257fa5067850c96e5c67f6', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 18, 'created': '2018-11-21 22:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab96b11df4176d6aaa5cd2f6ff8b0bfadac4b8f9', 'message': 'Add bulk port creation of DB objects\n\nFor port creation methods that are truly optimized for bulk operation,\na new create_port_db routines must be created that operates on an array.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 19, 'created': '2018-11-26 20:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f2a83ab4ecdc576acfde12a6f3bc24c769d266a', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 20, 'created': '2018-11-26 22:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7de610a2c0c804ec0c7faf3d8b221aae1b067901', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 21, 'created': '2018-11-27 13:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41d3af622fa431fa5a7251070b6abcb0b245a8dd', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 22, 'created': '2018-11-27 15:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d73785f185c6fc858f11ea716c450b9e1611bd7', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 23, 'created': '2018-11-27 19:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9777186aa6642023cdef0bb46d4b1a9a5694dfd', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 24, 'created': '2018-11-28 16:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/150f959bb95f6d3ee79c00f0d44ab45f3a0ff226', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 25, 'created': '2018-11-28 20:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a96d5ad87de234a10d9a41bcdda062e1c338097f', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}, {'number': 26, 'created': '2018-11-29 15:07:30.000000000', 'files': ['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/plugins/ml2/common/exceptions.py', 'neutron/db/ipam_pluggable_backend.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/80b48ebd4a376cae38062b85221e0b74ad3db893', 'message': 'Add bulk port creation of DB objects\n\nImplement a new function called create_port_obj_bulk that optimizes\nbulk port creation operations by streamlining ensuring network existence\nand operates on an array of port data.\n\nChange-Id: Ie819c215944514d0bb43c2ce87394825bda41e94\nPartially-Implements: blueprint speed-up-neutron-bulk-creation\n'}]",87,585028,80b48ebd4a376cae38062b85221e0b74ad3db893,203,18,26,13995,,,0,"Add bulk port creation of DB objects

Implement a new function called create_port_obj_bulk that optimizes
bulk port creation operations by streamlining ensuring network existence
and operates on an array of port data.

Change-Id: Ie819c215944514d0bb43c2ce87394825bda41e94
Partially-Implements: blueprint speed-up-neutron-bulk-creation
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/585028/17 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,e5437b6d317b1a024d3c635712fe19effec747b7,bp/speed-up-neutron-bulk-creation," def _create_db_port_obj_bulk(self, context, port_data, count=1): db_ports = [] macs = self._generate_mac(count) for mac in range(macs): db_port = models_v2.Port(mac_address=mac, id=uuidutils.generate_uuid(), **port_data) context.session.add(db_port) db_ports.append(db_port) return db_ports def create_port_db_bulk(self, context, ports): bulk_port_data = [dict(tenant_id=port['port'].get('tenant_id'), name=port['port'].get('name'), network_id=port['port'].get('network_id'), admin_state_up=port['port'].get('admin_state_up'), status=port['port'].get('status', constants.PORT_STATUS_ACTIVE), device_id=port['port'].get('device_id'), device_owner=port['port'].get('device_owner'), description=port['port'].get('description')) for port in ports] network_id = bulk_port_data[0].get('network_id') with db_api.context_manager.writer.using(context): # Ensure that the network exists. self._get_network(context, network_id) db_ports = self._create_db_port_obj_bulk(context, bulk_port_data[0], len(bulk_port_data)) result_ports = [] for db_port in db_ports: try: self.ipam.allocate_ips_for_port_and_store( context, db_port, db_port['id']) db_port['ip_allocation'] = (ipalloc_apidef. IP_ALLOCATION_IMMEDIATE) except ipam_exc.DeferIpam: db_port['ip_allocation'] = (ipalloc_apidef. IP_ALLOCATION_DEFERRED) result_ports.append(db_port) return result_ports ",,46,0
openstack%2Fproject-config~master~I99b6c8f03c10eb19031454e07bb67737235ebc60,openstack/project-config,master,I99b6c8f03c10eb19031454e07bb67737235ebc60,Add 'Review-Priority' for Zaqar repos,MERGED,2019-01-04 02:19:28.000000000,2019-01-07 03:46:45.000000000,2019-01-07 03:46:45.000000000,"[{'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 02:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/037a5f9fffbf8a1c03a7757aea0add0151924249', 'message': ""Add 'Review-Priority' for Zaqar repos\n\nChange-Id: I99b6c8f03c10eb19031454e07bb67737235ebc60\n""}, {'number': 2, 'created': '2019-01-04 07:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/34fe710c502b415d30ece261197d5aa0fa5c4f46', 'message': ""Add 'Review-Priority' for Zaqar repos\n\nChange-Id: I99b6c8f03c10eb19031454e07bb67737235ebc60\n""}, {'number': 3, 'created': '2019-01-05 01:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eac4315ed4302cd9f9a7a26bfc04fe5ba753170d', 'message': ""Add 'Review-Priority' for Zaqar repos\n\nChange-Id: I99b6c8f03c10eb19031454e07bb67737235ebc60\n""}, {'number': 4, 'created': '2019-01-05 01:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b8bf2933e20d3024d4627f6b57633951c70c1f74', 'message': ""Add 'Review-Priority' for Zaqar repos\n\nChange-Id: I99b6c8f03c10eb19031454e07bb67737235ebc60\n""}, {'number': 5, 'created': '2019-01-05 01:51:18.000000000', 'files': ['gerrit/acls/openstack/zaqar-ui.config', 'gerrit/acls/openstack/zaqar.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0ced8ad2660ada5beb8e398de98102e24722beee', 'message': ""Add 'Review-Priority' for Zaqar repos\n\nChange-Id: I99b6c8f03c10eb19031454e07bb67737235ebc60\n""}]",2,628323,0ced8ad2660ada5beb8e398de98102e24722beee,19,4,5,8846,,,0,"Add 'Review-Priority' for Zaqar repos

Change-Id: I99b6c8f03c10eb19031454e07bb67737235ebc60
",git fetch https://review.opendev.org/openstack/project-config refs/changes/23/628323/5 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/zaqar-ui.config', 'gerrit/acls/openstack/zaqar.config']",2,037a5f9fffbf8a1c03a7757aea0add0151924249,add-review-priority-for-zaqar-repos,"[label ""Review-Priority""] copyAllScoresIfNoCodeChange = true copyAllScoresOnTrivialRebase = true copyMaxScore = true copyMinScore = true defaultValue = 0 function = AnyWithBlock value = -1 Branch Freeze value = 0 No Priority value = +1 Important Change value = +2 Gate Blocker Fix / Urgent Change ",,24,0
openstack%2Fpython-novaclient~master~I484a40fe3cb868d223a807edcd3e20f5e0ebdf4e,openstack/python-novaclient,master,I484a40fe3cb868d223a807edcd3e20f5e0ebdf4e,Update hacking version,MERGED,2018-12-28 15:05:56.000000000,2019-01-07 03:45:40.000000000,2019-01-07 03:45:40.000000000,"[{'_account_id': 679}, {'_account_id': 7634}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-28 15:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/726fb22e44a751514fc432359e625dea47b0a503', 'message': 'Update hacking version\n\nChange-Id: I484a40fe3cb868d223a807edcd3e20f5e0ebdf4e\n'}, {'number': 2, 'created': '2019-01-02 16:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/785e508085faaa39ad16b9c241a54d8003fd0924', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix the pep8 failed\n\nChange-Id: I484a40fe3cb868d223a807edcd3e20f5e0ebdf4e\n'}, {'number': 3, 'created': '2019-01-04 06:46:16.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt', 'novaclient/api_versions.py', 'tox.ini', 'novaclient/tests/unit/fixture_data/server_groups.py', 'novaclient/client.py', 'novaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/85e9b58e9b638bc49679d2c7460dd1db7f39f48a', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix the pep8 failed\n\nChange-Id: I484a40fe3cb868d223a807edcd3e20f5e0ebdf4e\n'}]",0,627726,85e9b58e9b638bc49679d2c7460dd1db7f39f48a,18,5,3,21691,,,0,"Update hacking version

1. update hacking version to latest
2. fix the pep8 failed

Change-Id: I484a40fe3cb868d223a807edcd3e20f5e0ebdf4e
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/26/627726/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,726fb22e44a751514fc432359e625dea47b0a503,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fheat~stable%2Fqueens~Iefa706f91382f7d1c47e09e8f67a9fad53a9390b,openstack/heat,stable/queens,Iefa706f91382f7d1c47e09e8f67a9fad53a9390b,Ignore errors in purging events,MERGED,2018-06-28 14:14:23.000000000,2019-01-07 03:38:05.000000000,2018-07-05 15:54:03.000000000,"[{'_account_id': 4257}, {'_account_id': 7404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-28 14:14:23.000000000', 'files': ['heat/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/057231929e6100de26265b1585077329145735f5', 'message': ""Ignore errors in purging events\n\nThere is a known issue with purging the resource properties data for events\nwhere the same resource properties data is referenced by a resource or\nevent in the backup stack.\n\nIt's more important that we are able to store a new event than that we are\nable to purge old events, so catch any exceptions in purging and log an\nerror, rather than allowing the exception to abort the event creation.\n\nAlso use a transaction to ensure that we roll back the deletion of the\nevents when we encounter an error. This ensures that any resource\nproperties data *not* referenced by the backup stack is not orphaned\nbecause of failures deleting other rows. This will allow us to properly\npurge the database once the issue is fixed.\n\nChange-Id: Iefa706f91382f7d1c47e09e8f67a9fad53a9390b\nStory: #2002643\nTask: 22334\n(cherry picked from commit 6169ed4660232871c8e47690257612a363bc88d3)\n""}]",0,578816,057231929e6100de26265b1585077329145735f5,8,3,1,8833,,,0,"Ignore errors in purging events

There is a known issue with purging the resource properties data for events
where the same resource properties data is referenced by a resource or
event in the backup stack.

It's more important that we are able to store a new event than that we are
able to purge old events, so catch any exceptions in purging and log an
error, rather than allowing the exception to abort the event creation.

Also use a transaction to ensure that we roll back the deletion of the
events when we encounter an error. This ensures that any resource
properties data *not* referenced by the backup stack is not orphaned
because of failures deleting other rows. This will allow us to properly
purge the database once the issue is fixed.

Change-Id: Iefa706f91382f7d1c47e09e8f67a9fad53a9390b
Story: #2002643
Task: 22334
(cherry picked from commit 6169ed4660232871c8e47690257612a363bc88d3)
",git fetch https://review.opendev.org/openstack/heat refs/changes/16/578816/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/db/sqlalchemy/api.py'],1,057231929e6100de26265b1585077329145735f5,," with session.begin(): query = _query_all_by_stack(context, stack_id) query = query.order_by(models.Event.id).limit(limit) id_pairs = [(e.id, e.rsrc_prop_data_id) for e in query.all()] if not id_pairs: return 0 (ids, rsrc_prop_ids) = zip(*id_pairs) max_id = ids[-1] # delete the events retval = session.query(models.Event.id).filter( models.Event.id <= max_id).filter( models.Event.stack_id == stack_id).delete() # delete unreferenced resource_properties_data if rsrc_prop_ids: ev_ref_ids = set(e.rsrc_prop_data_id for e in _query_all_by_stack(context, stack_id).all()) rsrc_ref_ids = set(r.rsrc_prop_data_id for r in session.query(models.Resource).filter_by( stack_id=stack_id).all()) clr_prop_ids = set(rsrc_prop_ids) - ev_ref_ids - rsrc_ref_ids q_rpd = session.query(models.ResourcePropertiesData.id).filter( models.ResourcePropertiesData.id.in_(clr_prop_ids)) q_rpd.delete(synchronize_session=False) try: _delete_event_rows(context, values['stack_id'], cfg.CONF.event_purge_batch_size) except db_exception.DBError as exc: LOG.error('Failed to purge events: %s', six.text_type(exc))"," query = _query_all_by_stack(context, stack_id) id_pairs = [(e.id, e.rsrc_prop_data_id) for e in query.order_by( models.Event.id).limit(limit).all()] if id_pairs is None: return 0 (ids, rsrc_prop_ids) = zip(*id_pairs) max_id = ids[-1] # delete the events retval = session.query(models.Event.id).filter( models.Event.id <= max_id).filter( models.Event.stack_id == stack_id).delete() # delete unreferenced resource_properties_data rsrc_prop_ids = set(rsrc_prop_ids) if rsrc_prop_ids: still_ref_ids_from_events = [e.rsrc_prop_data_id for e in _query_all_by_stack( context, stack_id).all()] still_ref_ids_from_rsrcs = [r.rsrc_prop_data_id for r in context.session.query(models.Resource). filter_by(stack_id=stack_id).all()] rsrc_prop_ids = rsrc_prop_ids - set(still_ref_ids_from_events) \ - set(still_ref_ids_from_rsrcs) q_rpd = session.query(models.ResourcePropertiesData.id).filter( models.ResourcePropertiesData.id.in_(rsrc_prop_ids)) q_rpd.delete(synchronize_session=False) _delete_event_rows( context, values['stack_id'], cfg.CONF.event_purge_batch_size)",28,27
openstack%2Fnetworking-onos~master~Ida406df13a61d814cd7b10ce378c8a4928699a7d,openstack/networking-onos,master,Ida406df13a61d814cd7b10ce378c8a4928699a7d,Support GENEVE tunnel type,MERGED,2018-12-17 02:47:20.000000000,2019-01-07 02:37:39.000000000,2019-01-07 02:37:39.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2018-12-17 02:47:20.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/080f8b5ba3d4e055e94ad1018c4d7c13f8035b5c', 'message': 'Support GENEVE tunnel type\n\nChange-Id: Ida406df13a61d814cd7b10ce378c8a4928699a7d\n'}]",0,625466,080f8b5ba3d4e055e94ad1018c4d7c13f8035b5c,7,3,1,28180,,,0,"Support GENEVE tunnel type

Change-Id: Ida406df13a61d814cd7b10ce378c8a4928699a7d
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/66/625466/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,080f8b5ba3d4e055e94ad1018c4d7c13f8035b5c,," n_const.TYPE_GENEVE,",,1,0
openstack%2Fnetworking-onos~master~I59fb5bdcf1d53e7ff8c1fe2554add2d14fe2a30d,openstack/networking-onos,master,I59fb5bdcf1d53e7ff8c1fe2554add2d14fe2a30d,Support GENEVE tunnel type,MERGED,2018-12-17 02:42:56.000000000,2019-01-07 02:37:38.000000000,2019-01-07 02:37:38.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2018-12-17 02:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/a7e4385ce36a559155bcce73f496f47641b6dad6', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I59fb5bdcf1d53e7ff8c1fe2554add2d14fe2a30d\n'}, {'number': 2, 'created': '2018-12-17 02:43:21.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/83cf401d3c8734581680e9600243874601a4bc6d', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I59fb5bdcf1d53e7ff8c1fe2554add2d14fe2a30d\n'}]",0,625464,83cf401d3c8734581680e9600243874601a4bc6d,9,3,2,28180,,,0,"Support GENEVE tunnel type

Change-Id: I59fb5bdcf1d53e7ff8c1fe2554add2d14fe2a30d
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/64/625464/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,a7e4385ce36a559155bcce73f496f47641b6dad6,stable/queens," n_const.TYPE_GENEVE,",,1,0
openstack%2Fnetworking-onos~master~I94637ced738031baade0c90c8d6bac1775fdbcc6,openstack/networking-onos,master,I94637ced738031baade0c90c8d6bac1775fdbcc6,Support GENEVE tunnel type,MERGED,2018-12-17 02:45:31.000000000,2019-01-07 02:37:23.000000000,2019-01-07 02:37:23.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2018-12-17 02:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/e129565afae200d0d44ff1aedab353ae215cc942', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I94637ced738031baade0c90c8d6bac1775fdbcc6\n'}, {'number': 2, 'created': '2018-12-17 02:45:38.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/9f5ec5fa49fdfb83408044c8a496d1ec6a3e886e', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I94637ced738031baade0c90c8d6bac1775fdbcc6\n'}]",0,625465,9f5ec5fa49fdfb83408044c8a496d1ec6a3e886e,8,3,2,28180,,,0,"Support GENEVE tunnel type

Change-Id: I94637ced738031baade0c90c8d6bac1775fdbcc6
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/65/625465/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,e129565afae200d0d44ff1aedab353ae215cc942,stable/rocky," n_const.TYPE_GENEVE,",,1,0
openstack%2Fnetworking-onos~master~I2841634040de642a4541cae55da4e2484e5144db,openstack/networking-onos,master,I2841634040de642a4541cae55da4e2484e5144db,Support GENEVE tunnel type,MERGED,2018-12-17 02:39:23.000000000,2019-01-07 02:37:23.000000000,2019-01-07 02:37:23.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2018-12-17 02:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/64ee0ff1e666b6cf7b9f99c28c6d0487a08c36aa', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I2841634040de642a4541cae55da4e2484e5144db\n'}, {'number': 2, 'created': '2018-12-17 02:39:42.000000000', 'files': ['networking_onos/plugins/ml2/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/9565a764609d2603e80de5ac8f84f7ca36979ee3', 'message': 'Support GENEVE tunnel type\n\nChange-Id: I2841634040de642a4541cae55da4e2484e5144db\n'}]",0,625462,9565a764609d2603e80de5ac8f84f7ca36979ee3,9,3,2,28180,,,0,"Support GENEVE tunnel type

Change-Id: I2841634040de642a4541cae55da4e2484e5144db
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/62/625462/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/ml2/driver.py'],1,64ee0ff1e666b6cf7b9f99c28c6d0487a08c36aa,stable/pike," n_const.TYPE_GENEVE,",,1,0
openstack%2Fmagnum-tempest-plugin~master~I455df933f0ef8da10c673a878b69e1c6bc7f7e20,openstack/magnum-tempest-plugin,master,I455df933f0ef8da10c673a878b69e1c6bc7f7e20,[Trivial Fix] update home-page url,ABANDONED,2018-10-29 08:28:54.000000000,2019-01-07 02:35:15.000000000,,"[{'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-10-29 08:28:54.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/43f4a2583e3148ff4515cc2f3756c56d95eb1c09', 'message': '[Trivial Fix] update home-page url\n\nChange-Id: I455df933f0ef8da10c673a878b69e1c6bc7f7e20\n'}]",0,613859,43f4a2583e3148ff4515cc2f3756c56d95eb1c09,3,2,1,27565,,,0,"[Trivial Fix] update home-page url

Change-Id: I455df933f0ef8da10c673a878b69e1c6bc7f7e20
",git fetch https://review.opendev.org/openstack/magnum-tempest-plugin refs/changes/59/613859/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,43f4a2583e3148ff4515cc2f3756c56d95eb1c09,,home-page = http://docs.openstack.org/magnum/latest,home-page = http://www.openstack.org/,1,1
openstack%2Ftelemetry-tempest-plugin~master~Iefff0dbb7b6380661d614ddfd6ff8dda8888c5fe,openstack/telemetry-tempest-plugin,master,Iefff0dbb7b6380661d614ddfd6ff8dda8888c5fe,[Trivial Fix] update home-page url,ABANDONED,2018-10-29 08:12:56.000000000,2019-01-07 02:35:07.000000000,,"[{'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-10-29 08:12:56.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/telemetry-tempest-plugin/commit/15339bec45d0aa197d6e94c2838e0a7ea087658e', 'message': '[Trivial Fix] update home-page url\n\nChange-Id: Iefff0dbb7b6380661d614ddfd6ff8dda8888c5fe\n'}]",0,613852,15339bec45d0aa197d6e94c2838e0a7ea087658e,3,2,1,27565,,,0,"[Trivial Fix] update home-page url

Change-Id: Iefff0dbb7b6380661d614ddfd6ff8dda8888c5fe
",git fetch https://review.opendev.org/openstack/telemetry-tempest-plugin refs/changes/52/613852/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,15339bec45d0aa197d6e94c2838e0a7ea087658e,,home-page = https://docs.openstack.org/developer/ceilometer,home-page = http://www.openstack.org/,1,1
openstack%2Fopenstack-ansible-lxc_hosts~master~I13bfa1357ca067e31d4b12f48fd28751a6e492d5,openstack/openstack-ansible-lxc_hosts,master,I13bfa1357ca067e31d4b12f48fd28751a6e492d5,"[Trivial Fix] Update the typo ""dont"" to ""don't""",ABANDONED,2018-10-29 06:33:00.000000000,2019-01-07 02:34:59.000000000,,"[{'_account_id': 19298}, {'_account_id': 22348}, {'_account_id': 27565}, {'_account_id': 28842}]","[{'number': 1, 'created': '2018-10-29 06:33:00.000000000', 'files': ['handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ed50beb6f255602c5779f86d1665c75c84c66231', 'message': '[Trivial Fix] Update the typo ""dont"" to ""don\'t""\n\nChange-Id: I13bfa1357ca067e31d4b12f48fd28751a6e492d5\n'}]",0,613839,ed50beb6f255602c5779f86d1665c75c84c66231,4,4,1,27565,,,0,"[Trivial Fix] Update the typo ""dont"" to ""don't""

Change-Id: I13bfa1357ca067e31d4b12f48fd28751a6e492d5
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/39/613839/1 && git format-patch -1 --stdout FETCH_HEAD,['handlers/main.yml'],1,ed50beb6f255602c5779f86d1665c75c84c66231,,"# mount because we don't want to ""restart"" the","# mount because we dont want to ""restart"" the",1,1
openstack%2Fopenstack-ansible-os_neutron~master~Id8537f8e73d2f351dce3b4bb264ff3e9a10c8e7f,openstack/openstack-ansible-os_neutron,master,Id8537f8e73d2f351dce3b4bb264ff3e9a10c8e7f,[Trivial Fix] Replace Chinese punctuation with English punctuation,ABANDONED,2018-09-28 01:19:00.000000000,2019-01-07 02:34:53.000000000,,"[{'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-28 01:19:00.000000000', 'files': ['doc/source/app-nuage.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/10fb01c4c9f6fd49e6c27a6bdc14f50b0c7f44bf', 'message': '[Trivial Fix] Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input method.\nWhen read from english context, it makes some confusion.\n\nChange-Id: Id8537f8e73d2f351dce3b4bb264ff3e9a10c8e7f\n'}]",0,605899,10fb01c4c9f6fd49e6c27a6bdc14f50b0c7f44bf,7,2,1,27565,,,0,"[Trivial Fix] Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input method.
When read from english context, it makes some confusion.

Change-Id: Id8537f8e73d2f351dce3b4bb264ff3e9a10c8e7f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/99/605899/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/app-nuage.rst'],1,10fb01c4c9f6fd49e6c27a6bdc14f50b0c7f44bf,fix_punctuation," the Nuage OpenStack Python packages in "".whl"" format:", the Nuage OpenStack Python packages in “.whl” format:,1,1
openstack%2Fzun~master~If5532555e09d909d76025eafc99b5f6b2eeef19e,openstack/zun,master,If5532555e09d909d76025eafc99b5f6b2eeef19e,Support private registry - DB layer,MERGED,2019-01-06 19:08:24.000000000,2019-01-07 02:23:26.000000000,2019-01-07 02:23:26.000000000,"[{'_account_id': 22076}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2019-01-06 19:08:24.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/tests/unit/db/test_registry.py', 'zun/db/api.py', 'zun/db/sqlalchemy/models.py', 'zun/common/exception.py', 'zun/db/sqlalchemy/api.py', 'zun/db/sqlalchemy/alembic/versions/5ffc1cabe6b4_add_registry_table.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/f320089c152877db8cc3c16ed77dec7c12f9f152', 'message': ""Support private registry - DB layer\n\nAdd database table 'registry'. This table will store information\nabout a registry, such as domain, username and password.\n\nChange-Id: If5532555e09d909d76025eafc99b5f6b2eeef19e\nPartial-Bug: #1702830\n""}]",0,628783,f320089c152877db8cc3c16ed77dec7c12f9f152,7,3,1,11536,,,0,"Support private registry - DB layer

Add database table 'registry'. This table will store information
about a registry, such as domain, username and password.

Change-Id: If5532555e09d909d76025eafc99b5f6b2eeef19e
Partial-Bug: #1702830
",git fetch https://review.opendev.org/openstack/zun refs/changes/83/628783/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/db/utils.py', 'zun/tests/unit/db/test_registry.py', 'zun/db/api.py', 'zun/db/sqlalchemy/models.py', 'zun/common/exception.py', 'zun/db/sqlalchemy/api.py', 'zun/db/sqlalchemy/alembic/versions/5ffc1cabe6b4_add_registry_table.py']",7,f320089c152877db8cc3c16ed77dec7c12f9f152,bug/1809067,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""add registry table Revision ID: 5ffc1cabe6b4 Revises: 21fa080c818a Create Date: 2019-01-04 02:22:45.889795 """""" # revision identifiers, used by Alembic. revision = '5ffc1cabe6b4' down_revision = '21fa080c818a' branch_labels = None depends_on = None from alembic import op import sqlalchemy as sa def upgrade(): op.create_table( 'registry', sa.Column('created_at', sa.DateTime(), nullable=True), sa.Column('updated_at', sa.DateTime(), nullable=True), sa.Column('id', sa.Integer(), nullable=False), sa.Column('project_id', sa.String(length=255), nullable=True), sa.Column('user_id', sa.String(length=255), nullable=True), sa.Column('uuid', sa.String(length=36), nullable=True), sa.Column('name', sa.String(length=255), nullable=True), sa.Column('domain', sa.String(length=255), nullable=False), sa.Column('username', sa.String(length=255), nullable=True), sa.Column('password', sa.String(length=255), nullable=True), sa.PrimaryKeyConstraint('id'), sa.UniqueConstraint('uuid', name='uniq_registry0uuid'), mysql_charset='utf8', mysql_engine='InnoDB' ) ",,433,0
openstack%2Fzun~master~I255556fbff1b2303de2b41648538f7ec3871f1ba,openstack/zun,master,I255556fbff1b2303de2b41648538f7ec3871f1ba,Implement a upgrade check for 'numactl',MERGED,2018-12-12 04:54:54.000000000,2019-01-07 02:20:26.000000000,2019-01-07 02:20:26.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2018-12-12 04:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/874a88b1214ed92fbdfebb9e6a7722f128a3d185', 'message': ""Implement a upgrade check for 'numactl'\n\nAfter the implementation of the cpu pinning feature [1], the program\n'numactl' must exist. This commit implements a upgrade check for\nexistence of this binary.\n\n[1] https://review.openstack.org/#/c/617928/\n\nChange-Id: I255556fbff1b2303de2b41648538f7ec3871f1ba\n""}, {'number': 2, 'created': '2018-12-13 03:21:20.000000000', 'files': ['zun/tests/unit/cmd/test_status.py', 'zun/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/70a2332234fa35db0ce5b79565f17d84294fb0eb', 'message': ""Implement a upgrade check for 'numactl'\n\nAfter the implementation of the cpu pinning feature [1], the program\n'numactl' must exist. This commit implements a upgrade check for\nexistence of this binary.\n\n[1] https://review.openstack.org/#/c/617928/\n\nChange-Id: I255556fbff1b2303de2b41648538f7ec3871f1ba\n""}]",0,624572,70a2332234fa35db0ce5b79565f17d84294fb0eb,10,3,2,11536,,,0,"Implement a upgrade check for 'numactl'

After the implementation of the cpu pinning feature [1], the program
'numactl' must exist. This commit implements a upgrade check for
existence of this binary.

[1] https://review.openstack.org/#/c/617928/

Change-Id: I255556fbff1b2303de2b41648538f7ec3871f1ba
",git fetch https://review.opendev.org/openstack/zun refs/changes/72/624572/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/cmd/status.py'],1,874a88b1214ed92fbdfebb9e6a7722f128a3d185,,"import osimport shutil def _cmd_exists(self, cmd): try: return shutil.which(cmd) is not None except AttributeError: # shutil.which is not available in python 2.x so try an # alternative approach return any( os.access(os.path.join(path, cmd), os.X_OK) for path in os.environ[""PATH""].split(os.pathsep) ) def _numactl_check(self): """"""This is a check for existence of numactl binary if self._cmd_exists('numactl'): return upgradecheck.Result(upgradecheck.Code.SUCCESS) else: msg = _(""The program 'numactl' is currently not installed."") return upgradecheck.Result(upgradecheck.Code.FAILURE, msg) (_('Numactl Check'), _numactl_check),"," def _sample_check(self): """"""This is sample check added to test the upgrade check framework return upgradecheck.Result(upgradecheck.Code.SUCCESS, 'Sample detail') # Sample check added for now. # Whereas in future real checks must be added here in tuple (_('Sample Check'), _sample_check),",21,6
openstack%2Fzun~master~I16833dca7f442e5700a84dca042f04fb0edf25c7,openstack/zun,master,I16833dca7f442e5700a84dca042f04fb0edf25c7,Make multinode job voting,MERGED,2018-12-26 16:35:17.000000000,2019-01-07 02:15:05.000000000,2019-01-07 02:15:05.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2018-12-26 16:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2f2f0587fa5159e05a5cf1624cdeb6a67f6fbc0d', 'message': '[WIP] Make multinode job voting\n\nThe multinode job is useful for catching issues on multinode\nenvironment and this commit promote this job to voting.\n\nChange-Id: I16833dca7f442e5700a84dca042f04fb0edf25c7\n'}, {'number': 2, 'created': '2018-12-27 21:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/80839efad3650c2e557a7b6525a01697ce968fe9', 'message': '[WIP] Make multinode job voting\n\nThe multinode job is useful for catching issues on multinode\nenvironment and this commit promote this job to voting.\n\nChange-Id: I16833dca7f442e5700a84dca042f04fb0edf25c7\n'}, {'number': 3, 'created': '2018-12-30 03:21:42.000000000', 'files': ['devstack/lib/zun', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/zun/commit/50c581766ab9893616801b7b990c90f4c52f75a1', 'message': ""Make multinode job voting\n\nThe multinode job is useful for catching issues on multinode\nenvironment and this commit promote this job to voting.\n\nIn order to make the job success, this commit also fixes\ntwo issues:\n* Fix the nodeset of compute node (it should be 'subnode' instead\n  of 'peers').\n* Don't perform API-related configuration in compute node.\n\nChange-Id: I16833dca7f442e5700a84dca042f04fb0edf25c7\n""}]",0,627413,50c581766ab9893616801b7b990c90f4c52f75a1,12,3,3,11536,,,0,"Make multinode job voting

The multinode job is useful for catching issues on multinode
environment and this commit promote this job to voting.

In order to make the job success, this commit also fixes
two issues:
* Fix the nodeset of compute node (it should be 'subnode' instead
  of 'peers').
* Don't perform API-related configuration in compute node.

Change-Id: I16833dca7f442e5700a84dca042f04fb0edf25c7
",git fetch https://review.opendev.org/openstack/zun refs/changes/13/627413/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2f2f0587fa5159e05a5cf1624cdeb6a67f6fbc0d,, - zun-tempest-multinode-docker-sql, voting: false,1,1
openstack%2Fcloudkitty~master~I2aaec32f62d45ff741f6815a2ad770e45427c9ff,openstack/cloudkitty,master,I2aaec32f62d45ff741f6815a2ad770e45427c9ff,Update hacking version to latest,ABANDONED,2019-01-04 17:08:44.000000000,2019-01-07 02:03:18.000000000,,"[{'_account_id': 12015}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 17:08:44.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/94395e90d3613ed0be0234ffba6f97b911ce596f', 'message': 'Update hacking version to latest\n\nChange-Id: I2aaec32f62d45ff741f6815a2ad770e45427c9ff\n'}]",0,628626,94395e90d3613ed0be0234ffba6f97b911ce596f,4,2,1,27781,,,0,"Update hacking version to latest

Change-Id: I2aaec32f62d45ff741f6815a2ad770e45427c9ff
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/26/628626/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,94395e90d3613ed0be0234ffba6f97b911ce596f,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fzun~master~I429a4a88623b984238b65159232ea55c880f6cd3,openstack/zun,master,I429a4a88623b984238b65159232ea55c880f6cd3,Support auth with docker registry,MERGED,2018-12-30 22:43:30.000000000,2019-01-07 02:03:10.000000000,2019-01-07 02:03:10.000000000,"[{'_account_id': 21428}, {'_account_id': 22348}, {'_account_id': 23365}, {'_account_id': 23829}]","[{'number': 1, 'created': '2018-12-30 22:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/a728ca069fed0f743f57e9c6e7388b15425a5b95', 'message': '[WIP] Support auth with docker registry\n\nThis allows allow operators to configure username/password\nof the default registry. The credential is used to authenticate\nwith registry on pulling docker images.\n\nPartial-Bug: #1702830\nChange-Id: I429a4a88623b984238b65159232ea55c880f6cd3\n'}, {'number': 2, 'created': '2018-12-31 00:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/986e604cd2a8f789f3dc1b82daee0ca477b1ffc9', 'message': '[WIP] Support auth with docker registry\n\nThis allows allow operators to configure username/password\nof the default registry. The credential is used to authenticate\nwith registry on pulling docker images.\n\nPartial-Bug: #1702830\nChange-Id: I429a4a88623b984238b65159232ea55c880f6cd3\n'}, {'number': 3, 'created': '2018-12-31 16:38:54.000000000', 'files': ['zun/image/docker/driver.py', 'zun/tests/unit/image/docker/test_driver.py', 'zun/conf/docker.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/fbbbc827314228a91f7442c66695b8ec3b22b9bd', 'message': 'Support auth with docker registry\n\nThis allows allow operators to configure username/password\nof the default registry. The credential is used to authenticate\nwith registry on pulling docker images.\n\nPartial-Bug: #1702830\nChange-Id: I429a4a88623b984238b65159232ea55c880f6cd3\n'}]",0,627852,fbbbc827314228a91f7442c66695b8ec3b22b9bd,10,4,3,11536,,,0,"Support auth with docker registry

This allows allow operators to configure username/password
of the default registry. The credential is used to authenticate
with registry on pulling docker images.

Partial-Bug: #1702830
Change-Id: I429a4a88623b984238b65159232ea55c880f6cd3
",git fetch https://review.opendev.org/openstack/zun refs/changes/52/627852/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/image/docker/driver.py', 'zun/conf/docker.py']",2,a728ca069fed0f743f57e9c6e7388b15425a5b95,bug/1809067," cfg.StrOpt('default_registry_username', help='The username of the default registry.'), cfg.StrOpt('default_registry_password', help='The password of the default registry.'),",,13,1
openstack%2Fzun~master~I797afadef1e2ebd9d198baf308bcecca973e0b0d,openstack/zun,master,I797afadef1e2ebd9d198baf308bcecca973e0b0d,Add support for default registry,MERGED,2018-12-30 16:44:19.000000000,2019-01-07 02:02:28.000000000,2019-01-07 02:02:28.000000000,"[{'_account_id': 22348}, {'_account_id': 23365}, {'_account_id': 23829}]","[{'number': 1, 'created': '2018-12-30 16:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/e4e4fda2b328bad628ea418fe2ce31808afc9d17', 'message': ""[WIP] Add support for default registry\n\nIn before, if users don't specify the registry in image name\n(i.e. 'zun run coreos/etcd' instead of 'zun run quay.io/coreos/etcd').\nZun will pull image from the default registry which is 'docker.io'.\nThis commit makes the default registry configurable. As a result,\noperators can specify a default registry.\n\nFor example, the config file can be set as following:\n\n  [docker]\n  default_registry = quay.io\n  ...\n\nThen, if users run a container like:\n\n  $ zun run coreos/etcd\n\nZun will pull the image from 'quay.io/coreos/etcd'\n\nChange-Id: I797afadef1e2ebd9d198baf308bcecca973e0b0d\n""}, {'number': 2, 'created': '2018-12-30 22:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c5c56caa919ac25fca6ff6b97487704191b36e31', 'message': ""Add support for default registry\n\nIn before, if users don't specify the registry in image name\n(i.e. 'zun run coreos/etcd' instead of 'zun run quay.io/coreos/etcd').\nZun will pull image from the default registry which is 'docker.io'.\nThis commit makes the default registry configurable. As a result,\noperators can specify a default registry.\n\nFor example, the config file can be set as following:\n\n  [docker]\n  default_registry = quay.io\n  ...\n\nThen, if users run a container like:\n\n  $ zun run coreos/etcd\n\nZun will pull the image from 'quay.io/coreos/etcd'\n\nChange-Id: I797afadef1e2ebd9d198baf308bcecca973e0b0d\n""}, {'number': 3, 'created': '2018-12-31 16:29:40.000000000', 'files': ['zun/common/utils.py', 'zun/image/docker/driver.py', 'zun/container/docker/driver.py', 'zun/tests/unit/image/docker/test_driver.py', 'zun/conf/docker.py', 'zun/tests/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/34b6187d325181f52d4c8429274a93a8ffe8a229', 'message': ""Add support for default registry\n\nIn before, if users don't specify the registry in image name\n(i.e. 'zun run coreos/etcd' instead of 'zun run quay.io/coreos/etcd').\nZun will pull image from the default registry which is 'docker.io'.\nThis commit makes the default registry configurable. As a result,\noperators can specify a default registry.\n\nFor example, the config file can be set as following:\n\n  [docker]\n  default_registry = quay.io\n  ...\n\nThen, if users run a container like:\n\n  $ zun run coreos/etcd\n\nZun will pull the image from 'quay.io/coreos/etcd'\n\nChange-Id: I797afadef1e2ebd9d198baf308bcecca973e0b0d\n""}]",0,627840,34b6187d325181f52d4c8429274a93a8ffe8a229,11,3,3,11536,,,0,"Add support for default registry

In before, if users don't specify the registry in image name
(i.e. 'zun run coreos/etcd' instead of 'zun run quay.io/coreos/etcd').
Zun will pull image from the default registry which is 'docker.io'.
This commit makes the default registry configurable. As a result,
operators can specify a default registry.

For example, the config file can be set as following:

  [docker]
  default_registry = quay.io
  ...

Then, if users run a container like:

  $ zun run coreos/etcd

Zun will pull the image from 'quay.io/coreos/etcd'

Change-Id: I797afadef1e2ebd9d198baf308bcecca973e0b0d
",git fetch https://review.opendev.org/openstack/zun refs/changes/40/627840/2 && git format-patch -1 --stdout FETCH_HEAD,"['zun/image/docker/driver.py', 'zun/container/docker/driver.py', 'zun/conf/docker.py']",3,e4e4fda2b328bad628ea418fe2ce31808afc9d17,bug/1809067," cfg.StrOpt('default_registry', help='The default registry from which docker images are ' 'pulled. Its value can be the registry domain name ' '(e.g. docker.io) or None.'),",,15,0
openstack%2Fzun~master~Ic1fcd03c27ca057ed289fab2d6a7df81fb1361a0,openstack/zun,master,Ic1fcd03c27ca057ed289fab2d6a7df81fb1361a0,Fix hostname of docker image,MERGED,2018-12-30 21:00:21.000000000,2019-01-07 01:58:38.000000000,2019-01-07 01:58:37.000000000,"[{'_account_id': 21428}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 21:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/36aab9af97b2c519cf88a8d22c072535879a7239', 'message': '[WIP] Fix hostname of docker image\n\nChange-Id: Ic1fcd03c27ca057ed289fab2d6a7df81fb1361a0\n'}, {'number': 2, 'created': '2018-12-30 21:13:38.000000000', 'files': ['zun/common/docker_image/reference.py', 'zun/tests/unit/common/docker_image/test_reference.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/6cb9c7e309b839edb5ddc061c1cae6ed0694483c', 'message': ""Fix hostname of docker image\n\nWhen we parse the docker image name, the hostname component\nmust contain '.' or ':' unless it is 'localhost'.\n\nChange-Id: Ic1fcd03c27ca057ed289fab2d6a7df81fb1361a0\n""}]",0,627849,6cb9c7e309b839edb5ddc061c1cae6ed0694483c,7,2,2,11536,,,0,"Fix hostname of docker image

When we parse the docker image name, the hostname component
must contain '.' or ':' unless it is 'localhost'.

Change-Id: Ic1fcd03c27ca057ed289fab2d6a7df81fb1361a0
",git fetch https://review.opendev.org/openstack/zun refs/changes/49/627849/2 && git format-patch -1 --stdout FETCH_HEAD,"['zun/common/docker_image/reference.py', 'zun/tests/unit/common/docker_image/test_reference.py']",2,36aab9af97b2c519cf88a8d22c072535879a7239,bug/1809067," hostname='', hostname='', hostname='', if tc['repository'] is not None: if tc['hostname'] is not None: if tc['path'] is not None: if tc['tag'] is not None: if tc['digest'] is not None:"," hostname='a', hostname='foo', if tc['repository']: if tc['hostname']: if tc['path']: if tc['tag']: if tc['digest']:",14,7
openstack%2Fzun~master~I932d6a61027d292a94e9591511efa5fdf9b07950,openstack/zun,master,I932d6a61027d292a94e9591511efa5fdf9b07950,Add more test cases for image reference,MERGED,2018-12-30 16:58:14.000000000,2019-01-07 01:47:38.000000000,2019-01-07 01:47:38.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2018-12-30 16:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/83d3cb767af08e2a4a5f1506be3d73a45da3bd3f', 'message': 'Add more test cases for image reference\n\nChange-Id: I932d6a61027d292a94e9591511efa5fdf9b07950\n'}, {'number': 2, 'created': '2018-12-30 17:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/6f9b31588a76ed4d159ba04bce00deab1cb25c13', 'message': '[WIP] Add more test cases for image reference\n\nChange-Id: I932d6a61027d292a94e9591511efa5fdf9b07950\n'}, {'number': 3, 'created': '2018-12-30 19:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/ef652c198f67032a393dd586c145b760796efc11', 'message': 'Add more test cases for image reference\n\nChange-Id: I932d6a61027d292a94e9591511efa5fdf9b07950\n'}, {'number': 4, 'created': '2018-12-30 21:07:29.000000000', 'files': ['zun/tests/unit/common/docker_image/test_reference.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/80021a5010282ed31a1f502b8ac36322d312bb6a', 'message': 'Add more test cases for image reference\n\nChange-Id: I932d6a61027d292a94e9591511efa5fdf9b07950\n'}]",0,627841,80021a5010282ed31a1f502b8ac36322d312bb6a,13,3,4,11536,,,0,"Add more test cases for image reference

Change-Id: I932d6a61027d292a94e9591511efa5fdf9b07950
",git fetch https://review.opendev.org/openstack/zun refs/changes/41/627841/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/tests/unit/common/docker_image/test_reference.py'],1,83d3cb767af08e2a4a5f1506be3d73a45da3bd3f,bug/1809067," create_test_case(input_='test.com/foo', repository='test.com/foo', hostname='test.com'), create_test_case(input_='test_com/foo', repository='test_com/foo', hostname=''), create_test_case(input_='test:8080/foo', repository='test:8080/foo', hostname='test:8080'), create_test_case(input_='test.com:8080/foo', repository='test.com:8080/foo', hostname='test.com:8080'), create_test_case(input_='test-com:8080/foo', repository='test-com:8080/foo', hostname='test-com:8080'), create_test_case(input_='xn--n3h.com:18080/foo', repository='xn--n3h.com:18080/foo', hostname='xn--n3h.com:18080'),",,18,0
openstack%2Fkeystone~master~I0e5c4ccde4c88bec3fa78114e1ede9545ed98678,openstack/keystone,master,I0e5c4ccde4c88bec3fa78114e1ede9545ed98678,Update federation SP prerequisites section,MERGED,2018-12-30 20:01:06.000000000,2019-01-07 01:36:55.000000000,2019-01-07 01:36:55.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 20:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/82b9a39d3cb3945d4227799d34b49396af202db2', 'message': 'Update federation SP prerequisites section\n\nRemove outdated information, update version information and expand on\npreliminary information that will be needed throughout the rest of the\nguide.\n\nPartial-bug: #1793374\n\nChange-Id: I0e5c4ccde4c88bec3fa78114e1ede9545ed98678\n'}, {'number': 2, 'created': '2019-01-02 12:57:34.000000000', 'files': ['doc/source/admin/federation/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bc202f70433f435fc335bf0ddf460d89df55350a', 'message': 'Update federation SP prerequisites section\n\nRemove outdated information, update version information and expand on\npreliminary information that will be needed throughout the rest of the\nguide.\n\nPartial-bug: #1793374\n\nChange-Id: I0e5c4ccde4c88bec3fa78114e1ede9545ed98678\n'}]",2,627846,bc202f70433f435fc335bf0ddf460d89df55350a,12,4,2,8482,,,0,"Update federation SP prerequisites section

Remove outdated information, update version information and expand on
preliminary information that will be needed throughout the rest of the
guide.

Partial-bug: #1793374

Change-Id: I0e5c4ccde4c88bec3fa78114e1ede9545ed98678
",git fetch https://review.opendev.org/openstack/keystone refs/changes/46/627846/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/federation/configure_federation.rst'],1,82b9a39d3cb3945d4227799d34b49396af202db2,bug/1793374,"If you are not familiar with the idea of federated identity, see the `introduction`_ first.Ubuntu 16.04 and Apache 2.4.18. To enable federation, you'll need to run keystone behind a web server such as Apache rather than running the WSGI application directly with uWSGI or Gunicorn. See the installation guide for `SUSE`_, `RedHat`_ or `Ubuntu`_ to configure the Apache web server for keystone. Throughout the rest of the guide, you will need to decide on three pieces of information and use them consistently throughout your configuration: 1. The protocol name. This must be a valid keystone auth method and must match one of: ``saml2``, ``openid``, ``mapped`` or a `custom auth method`_ for which you must `register as an external driver`_. 2. The identity provider name. This can be arbitrary. 3. The entity ID of the service provider. This should be a URN but need not resolve to anything. You will also need to decide what HTTPD module to use as a Service Provider. This guide provides examples for ``mod_shib`` and ``mod_auth_mellon`` as SAML service providers, and ``mod_auth_openidc`` as an OpenID Connect Service Provider... _introduction: introduction.. _SUSE: ../../install/keystone-install-obs.html#configure-the-apache-http-server .. _RedHat: ../../install/keystone-install-rdo.html#configure-the-apache-http-server .. _Ubuntu: ../../install/keystone-install-ubuntu.html#configure-the-apache-http-server .. _custom auth method: ../../contributor/auth-plugins .. _register as an external driver: ../../contributor/developing-drivers",".. NOTE:: This feature is considered stable and supported as of the Juno release. This approach to federation supports keystone as a Service Provider, consuming identity properties issued by an external Identity Provider, such as SAML assertions or OpenID Connect claims, or by using `Keystone as an Identity Provider (IdP)`_. Federated users are not mirrored in the keystone identity backend (for example, using the SQL driver). The external Identity Provider is responsible for authenticating users, and communicates the result of authentication to keystone using identity properties. Keystone maps these values to keystone user groups and assignments created in keystone.Ubuntu 14.04 and Apache 2.4.7. To enable federation, you'll need to: 1. Run keystone under Apache for `SUSE`_, `RedHat`_ or `Ubuntu`_, rather than using uwsgi command. 2. `Configure Apache to use a federation capable authentication method`_. 3. `Configure Federation in Keystone`_... _`SUSE`: ../../install/keystone-install-obs.html#configure-the-apache-http-server .. _`RedHat`: ../../install/keystone-install-rdo.html#configure-the-apache-http-server .. _`Ubuntu`: ../../install/keystone-install-ubuntu.html#configure-the-apache-http-server",29,23
openstack%2Fkeystone~master~I2633ba460182ed8ed5195a10cdaae663add8b1aa,openstack/keystone,master,I2633ba460182ed8ed5195a10cdaae663add8b1aa,Use samltest.id as an example sandbox IdP,MERGED,2018-12-30 20:01:06.000000000,2019-01-07 01:35:56.000000000,2019-01-07 01:35:56.000000000,"[{'_account_id': 5046}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 20:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/82dbf66cc406de120eddb6b3f9645305a9023119', 'message': ""Use samltest.id as an example sandbox IdP\n\nThe federation documentation inconsistently references samltest.id\n(formerly testshib.org, which is not well maintained) or a keystone IdP\n(before keystone-to-keystone is introduced). This change switches the\nexamples to use samltest.id[1] and renames 'myidp' to 'samltest' where\nappropriate. In the case of the WebSSO horizon configuration examples,\nit's not appropriate to switch the openid examples to samltest because\nsamltest.id does not support OpenIDC. The examples are meant to show\nthat you can pair different protocols to a single IdP, so use 'acme' as\nthe example.\n\n[1] https://samltest.id\n\nPartial-bug: #1793374\n\nChange-Id: I2633ba460182ed8ed5195a10cdaae663add8b1aa\n""}, {'number': 2, 'created': '2019-01-02 12:57:34.000000000', 'files': ['doc/source/admin/federation/mellon.rst', 'doc/source/admin/federation/shibboleth.rst', 'doc/source/admin/federation/configure_federation.rst', 'doc/source/admin/federation/websso.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5cc61bb644133f6e36f3255fada95ae78a65edf4', 'message': ""Use samltest.id as an example sandbox IdP\n\nThe federation documentation inconsistently references samltest.id\n(formerly testshib.org, which is not well maintained) or a keystone IdP\n(before keystone-to-keystone is introduced). This change switches the\nexamples to use samltest.id[1] and renames 'myidp' to 'samltest' where\nappropriate. In the case of the WebSSO horizon configuration examples,\nit's not appropriate to switch the openid examples to samltest because\nsamltest.id does not support OpenIDC. The examples are meant to show\nthat you can pair different protocols to a single IdP, so use 'acme' as\nthe example.\n\n[1] https://samltest.id\n\nPartial-bug: #1793374\n\nChange-Id: I2633ba460182ed8ed5195a10cdaae663add8b1aa\n""}]",0,627845,5cc61bb644133f6e36f3255fada95ae78a65edf4,10,3,2,8482,,,0,"Use samltest.id as an example sandbox IdP

The federation documentation inconsistently references samltest.id
(formerly testshib.org, which is not well maintained) or a keystone IdP
(before keystone-to-keystone is introduced). This change switches the
examples to use samltest.id[1] and renames 'myidp' to 'samltest' where
appropriate. In the case of the WebSSO horizon configuration examples,
it's not appropriate to switch the openid examples to samltest because
samltest.id does not support OpenIDC. The examples are meant to show
that you can pair different protocols to a single IdP, so use 'acme' as
the example.

[1] https://samltest.id

Partial-bug: #1793374

Change-Id: I2633ba460182ed8ed5195a10cdaae663add8b1aa
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/627845/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/federation/mellon.rst', 'doc/source/admin/federation/shibboleth.rst', 'doc/source/admin/federation/configure_federation.rst', 'doc/source/admin/federation/websso.rst']",4,82dbf66cc406de120eddb6b3f9645305a9023119,bug/1793374," <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/samltest/protocols/saml2/websso""> OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/identity_providers/samltest/protocols/openid/websso <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/samltest/protocols/openid/websso""> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/samltest/protocols/kerberos/websso""> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/samltest/protocols/saml2/websso""> (""acme_openid"", ""Acme Corporation - OpenID Connect""), (""acme_saml2"", ""Acme Corporation - SAML2"") ""acme_openid"": (""acme"", ""openid""), ""acme_saml2"": (""acme"", ""saml2"")"," <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/saml2/websso""> OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso""> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/kerberos/websso""> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/saml2/websso""> (""myidp_openid"", ""Acme Corporation - OpenID Connect""), (""myidp_saml2"", ""Acme Corporation - SAML2"") ""myidp_openid"": (""myidp"", ""openid""), ""myidp_saml2"": (""myidp"", ""saml2"")",43,39
openstack%2Fkeystone~master~Ia9e5280d131e1aa50af41aff6155eb07954b7d15,openstack/keystone,master,Ia9e5280d131e1aa50af41aff6155eb07954b7d15,Fix nits in code blocks in federation guide,MERGED,2018-12-30 20:01:06.000000000,2019-01-07 01:35:54.000000000,2019-01-07 01:35:54.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 20:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/be8d0ab9f98da19d8eeef6c225d619b49577df5e', 'message': 'Fix nits in code blocks in federation guide\n\nFix inconsistent indentation of code-blocks and ensure shell samples\ncorrectly differentiate betweeen root-required commands and non-root\ncommands in accordance with the openstack-manuals recommendations[1].\n\n[1] http://git.openstack.org/cgit/openstack/openstack-manuals/tree/doc/common/conventions.rst\n\nPartial-bug: #1793374\n\nChange-Id: Ia9e5280d131e1aa50af41aff6155eb07954b7d15\n'}, {'number': 2, 'created': '2019-01-02 12:57:34.000000000', 'files': ['doc/source/admin/federation/openidc.rst', 'doc/source/admin/federation/mapping_combinations.rst', 'doc/source/admin/federation/mellon.rst', 'doc/source/admin/federation/shibboleth.rst', 'doc/source/admin/federation/configure_federation.rst', 'doc/source/admin/federation/websso.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9bc2b8875d8c2bba6038185a68bfce05afdb36e2', 'message': 'Fix nits in code blocks in federation guide\n\nFix inconsistent indentation of code-blocks, ensure shell samples\ncorrectly differentiate betweeen root-required commands and non-root\ncommands in accordance with the openstack-manuals recommendations[1],\nand use proper markup for interactive shell examples.\n\n[1] http://git.openstack.org/cgit/openstack/openstack-manuals/tree/doc/common/conventions.rst\n\nPartial-bug: #1793374\n\nChange-Id: Ia9e5280d131e1aa50af41aff6155eb07954b7d15\n'}]",4,627844,9bc2b8875d8c2bba6038185a68bfce05afdb36e2,13,4,2,8482,,,0,"Fix nits in code blocks in federation guide

Fix inconsistent indentation of code-blocks, ensure shell samples
correctly differentiate betweeen root-required commands and non-root
commands in accordance with the openstack-manuals recommendations[1],
and use proper markup for interactive shell examples.

[1] http://git.openstack.org/cgit/openstack/openstack-manuals/tree/doc/common/conventions.rst

Partial-bug: #1793374

Change-Id: Ia9e5280d131e1aa50af41aff6155eb07954b7d15
",git fetch https://review.opendev.org/openstack/keystone refs/changes/44/627844/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/federation/openidc.rst', 'doc/source/admin/federation/mapping_combinations.rst', 'doc/source/admin/federation/mellon.rst', 'doc/source/admin/federation/shibboleth.rst', 'doc/source/admin/federation/configure_federation.rst', 'doc/source/admin/federation/websso.rst']",6,be8d0ab9f98da19d8eeef6c225d619b49577df5e,bug/1793374," [federation] trusted_dashboard = http://acme.horizon.com/auth/websso/ trusted_dashboard = http://beta.horizon.com/auth/websso/.. code-block:: apache <VirtualHost *:5000> ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/saml2""> AuthType shibboleth Require valid-user ShibRequestSetting requireSession 1 ShibRequireSession On ShibExportAssertion Off </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/saml2/websso""> AuthType shibboleth Require valid-user </Location> </VirtualHost>.. code-block:: apache <VirtualHost *:5000> OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/websso OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/openid""> AuthType openid-connect Require valid-user ... </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso""> AuthType openid-connect Require valid-user ... </Location> </VirtualHost>.. code-block:: apache <VirtualHost *:5000> ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/kerberos""> AuthType Kerberos AuthName ""Acme Corporation"" KrbMethodNegotiate on KrbMethodK5Passwd off Krb5Keytab /etc/apache2/http.keytab ... </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/kerberos/websso""> AuthType Kerberos AuthName ""Acme Corporation"" KrbMethodNegotiate on KrbMethodK5Passwd off Krb5Keytab /etc/apache2/http.keytab ... </Location> </VirtualHost>.. code-block:: apache <VirtualHost *:5000> ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/saml2""> AuthType Mellon MellonEnable auth Require valid-user ... </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/saml2/websso""> AuthType Mellon MellonEnable auth Require valid-user ... </Location> </VirtualHost> [saml2] remote_id_attribute = Shib-Identity-Provider [openid] remote_id_attribute = HTTP_OIDC_ISS [federation] remote_id_attribute = HTTP_OIDC_ISS WEBSSO_ENABLED = True WEBSSO_CHOICES = ( (""credentials"", _(""Keystone Credentials"")), (""openid"", _(""OpenID Connect"")), (""saml2"", _(""Security Assertion Markup Language"")), (""myidp_openid"", ""Acme Corporation - OpenID Connect""), (""myidp_saml2"", ""Acme Corporation - SAML2"") ) WEBSSO_IDP_MAPPING = { ""myidp_openid"": (""myidp"", ""openid""), ""myidp_saml2"": (""myidp"", ""saml2"") } WEBSSO_INITIAL_CHOICE = ""credentials"" # service apache2 restart"," [federation] trusted_dashboard = http://acme.horizon.com/auth/websso/ trusted_dashboard = http://beta.horizon.com/auth/websso/.. code-block:: none <VirtualHost *:5000> ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/saml2""> AuthType shibboleth Require valid-user ShibRequestSetting requireSession 1 ShibRequireSession On ShibExportAssertion Off </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/saml2/websso""> AuthType shibboleth Require valid-user </Location> </VirtualHost>.. code-block:: none <VirtualHost *:5000> OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/websso OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/openid""> AuthType openid-connect Require valid-user ... </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso""> AuthType openid-connect Require valid-user ... </Location> </VirtualHost>.. code-block:: none <VirtualHost *:5000> ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/kerberos""> AuthType Kerberos AuthName ""Acme Corporation"" KrbMethodNegotiate on KrbMethodK5Passwd off Krb5Keytab /etc/apache2/http.keytab ... </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/kerberos/websso""> AuthType Kerberos AuthName ""Acme Corporation"" KrbMethodNegotiate on KrbMethodK5Passwd off Krb5Keytab /etc/apache2/http.keytab ... </Location> </VirtualHost>.. code-block:: none <VirtualHost *:5000> ... <Location ~ ""/v3/auth/OS-FEDERATION/websso/saml2""> AuthType Mellon MellonEnable auth Require valid-user ... </Location> <Location ~ ""/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/saml2/websso""> AuthType Mellon MellonEnable auth Require valid-user ... </Location> </VirtualHost> [saml2] remote_id_attribute = Shib-Identity-Provider [openid] remote_id_attribute = HTTP_OIDC_ISS [federation] remote_id_attribute = HTTP_OIDC_ISS WEBSSO_ENABLED = True WEBSSO_CHOICES = ( (""credentials"", _(""Keystone Credentials"")), (""openid"", _(""OpenID Connect"")), (""saml2"", _(""Security Assertion Markup Language"")), (""myidp_openid"", ""Acme Corporation - OpenID Connect""), (""myidp_saml2"", ""Acme Corporation - SAML2"") ) WEBSSO_IDP_MAPPING = { ""myidp_openid"": (""myidp"", ""openid""), ""myidp_saml2"": (""myidp"", ""saml2"") } WEBSSO_INITIAL_CHOICE = ""credentials"" $ sudo service apache2 restart",838,836
openstack%2Fkeystone~master~I8e12edaa589be3c8e71b10d0609c057fd2bfb247,openstack/keystone,master,I8e12edaa589be3c8e71b10d0609c057fd2bfb247,Bring SP/IdP URLs closer to style guide guidance,MERGED,2018-12-30 20:01:06.000000000,2019-01-07 01:35:52.000000000,2019-01-07 01:35:52.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-30 20:01:06.000000000', 'files': ['doc/source/admin/federation/openidc.rst', 'doc/source/admin/federation/mellon.rst', 'doc/source/admin/federation/shibboleth.rst', 'doc/source/admin/federation/configure_federation.rst', 'doc/source/admin/federation/websso.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/40e0f5d976d6b5172a408bdd548937e24361db35', 'message': ""Bring SP/IdP URLs closer to style guide guidance\n\nThe documentation style guide recommends using example URLs for\nOpenStack services that look like\n`http://<service>.openstack.example.org`. This patch changes the URLs\nfor hypothetical keystone Service Providers to use HTTPS endpoints to\nset a good example of security, to use the example.org domain instead of\nlocalhost or example.com, to include keystone in the name for clarity of\nwhat the service is, and to use a consistent URL path and port. It\ndoesn't include 'openstack' in the domain name because that becomes a\nbit long.\n\n[1] https://docs.openstack.org/doc-contrib-guide/writing-style/urls.html\n\nPartial-bug: #1793374\n\nChange-Id: I8e12edaa589be3c8e71b10d0609c057fd2bfb247\n""}]",4,627843,40e0f5d976d6b5172a408bdd548937e24361db35,10,4,1,8482,,,0,"Bring SP/IdP URLs closer to style guide guidance

The documentation style guide recommends using example URLs for
OpenStack services that look like
`http://<service>.openstack.example.org`. This patch changes the URLs
for hypothetical keystone Service Providers to use HTTPS endpoints to
set a good example of security, to use the example.org domain instead of
localhost or example.com, to include keystone in the name for clarity of
what the service is, and to use a consistent URL path and port. It
doesn't include 'openstack' in the domain name because that becomes a
bit long.

[1] https://docs.openstack.org/doc-contrib-guide/writing-style/urls.html

Partial-bug: #1793374

Change-Id: I8e12edaa589be3c8e71b10d0609c057fd2bfb247
",git fetch https://review.opendev.org/openstack/keystone refs/changes/43/627843/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/federation/openidc.rst', 'doc/source/admin/federation/mellon.rst', 'doc/source/admin/federation/shibboleth.rst', 'doc/source/admin/federation/configure_federation.rst', 'doc/source/admin/federation/websso.rst']",5,40e0f5d976d6b5172a408bdd548937e24361db35,bug/1793374, OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/websso OIDCRedirectURI https://sp.keystone.example.org/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso, OIDCRedirectURI http://localhost:5000/v3/auth/OS-FEDERATION/websso OIDCRedirectURI http://localhost:5000/v3/auth/OS-FEDERATION/identity_providers/myidp/protocols/openid/websso,41,21
openstack%2Fvitrage~master~I34c9f750901b9cdd0866fe5d16e65b90be8b6541,openstack/vitrage,master,I34c9f750901b9cdd0866fe5d16e65b90be8b6541,Handle if graph_vertex is None,ABANDONED,2019-01-02 10:23:34.000000000,2019-01-07 01:19:55.000000000,,"[{'_account_id': 19159}, {'_account_id': 22348}, {'_account_id': 22406}]","[{'number': 1, 'created': '2019-01-02 10:23:34.000000000', 'files': ['vitrage/entity_graph/processor/processor.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/2de171f988ae1a0bdd57621f9280dd1b1f2be3a2', 'message': 'Handle if graph_vertex is None\n\nChange-Id: I34c9f750901b9cdd0866fe5d16e65b90be8b6541\nStory: #2004689\nTask: #28699\n'}]",0,627951,2de171f988ae1a0bdd57621f9280dd1b1f2be3a2,7,3,1,22406,,,0,"Handle if graph_vertex is None

Change-Id: I34c9f750901b9cdd0866fe5d16e65b90be8b6541
Story: #2004689
Task: #28699
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/51/627951/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/entity_graph/processor/processor.py'],1,2de171f988ae1a0bdd57621f9280dd1b1f2be3a2,2004689," if graph_vertex: self.info_mapper.vitrage_aggregate_values( vertex, graph_vertex)"," self.info_mapper.vitrage_aggregate_values(vertex, graph_vertex)",3,2
openstack%2Fmurano~master~Ieb20557342fd9a133df5046e69c563235fbfb601,openstack/murano,master,Ieb20557342fd9a133df5046e69c563235fbfb601,DNM: Murano Python3 devstack test,ABANDONED,2018-12-12 07:54:44.000000000,2019-01-07 00:34:15.000000000,,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-12 07:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/41e9e3db62a445ae5d50dba8631e148c264768b5', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 2, 'created': '2018-12-12 09:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bf6af8139e8c6ff588a8c3b5408256e8752764a6', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 3, 'created': '2018-12-13 05:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/489bf3ae39c2b64e45a29e7aabbfea27e80855a6', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 4, 'created': '2018-12-24 01:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0c64214bc33985dd42152da23afd6e05a37ae792', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627088/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 5, 'created': '2018-12-24 02:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a265b78fc3aecd5be4fc58d72b0da9b1f4a4f48d', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627088/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 6, 'created': '2018-12-24 05:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0cf8304520183ed88753f9b07058c03092c1dc70', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627088/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 7, 'created': '2018-12-24 05:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b006cb31656a035d8555c06b8f97ca18f5eab565', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627088/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 8, 'created': '2018-12-24 05:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0b58d77b4a499de81b009cb491648ed67e1b8363', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627088/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 9, 'created': '2018-12-24 07:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/4338713f7217fe498eb5f2e53adbd2f50c279727', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627150/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 10, 'created': '2018-12-28 05:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/51cf188f5106eaec16fc17ae4ee248d44dd163ec', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627150/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 11, 'created': '2019-01-03 00:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6192cf3dc1972ecd6eb46ddb91df51ae284f122b', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627150/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 12, 'created': '2019-01-03 02:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c826b9b96dd3e640579c4acfa459ea71054b1ceb', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627150/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}, {'number': 13, 'created': '2019-01-03 02:47:44.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/murano/commit/fc1c9e920afff8e379bef3040a7912f69668ab09', 'message': 'DNM: Murano Python3 devstack test\n\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624849/\nDepends-On: https://review.openstack.org/#/c/624859/\nDepends-On: https://review.openstack.org/#/c/627150/\nDepends-On: https://review.openstack.org/#/c/628093/\nChange-Id: Ieb20557342fd9a133df5046e69c563235fbfb601\n'}]",0,624600,fc1c9e920afff8e379bef3040a7912f69668ab09,36,2,13,14107,,,0,"DNM: Murano Python3 devstack test

Depends-On: https://review.openstack.org/#/c/622415/
Depends-On: https://review.openstack.org/#/c/624849/
Depends-On: https://review.openstack.org/#/c/624859/
Depends-On: https://review.openstack.org/#/c/627150/
Depends-On: https://review.openstack.org/#/c/628093/
Change-Id: Ieb20557342fd9a133df5046e69c563235fbfb601
",git fetch https://review.opendev.org/openstack/murano refs/changes/00/624600/4 && git format-patch -1 --stdout FETCH_HEAD,['murano/context.py'],1,41e9e3db62a445ae5d50dba8631e148c264768b5,, as well as additional test request information., as well as additional request information.,1,1
openstack%2Frpm-packaging~master~I8ea27b2fbf867bc782f4076ce1f01325852cd13f,openstack/rpm-packaging,master,I8ea27b2fbf867bc782f4076ce1f01325852cd13f,neutron-lib: Update to 1.21.0,MERGED,2019-01-05 10:29:14.000000000,2019-01-07 00:26:40.000000000,2019-01-07 00:26:40.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-05 10:29:14.000000000', 'files': ['openstack/neutron-lib/neutron-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a6c0bce83cdbae0e7e77adeb246d43eb684dca9a', 'message': 'neutron-lib: Update to 1.21.0\n\nChange-Id: I8ea27b2fbf867bc782f4076ce1f01325852cd13f\n'}]",0,628727,a6c0bce83cdbae0e7e77adeb246d43eb684dca9a,9,5,1,6593,,,0,"neutron-lib: Update to 1.21.0

Change-Id: I8ea27b2fbf867bc782f4076ce1f01325852cd13f
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/27/628727/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/neutron-lib/neutron-lib.spec.j2'],1,a6c0bce83cdbae0e7e77adeb246d43eb684dca9a,oslo_2019,Version: 1.21.0,Version: 1.19.0,1,1
openstack%2Fmagnum~master~Ife5558f1db4e581b64cc4a8ffead151f7b405702,openstack/magnum,master,Ife5558f1db4e581b64cc4a8ffead151f7b405702,k8s_fedora: Use external kubernetes/cloud-provider-openstack,MERGED,2018-06-22 17:10:17.000000000,2019-01-06 22:12:22.000000000,2019-01-06 22:12:21.000000000,"[{'_account_id': 5638}, {'_account_id': 6484}, {'_account_id': 9373}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 28022}, {'_account_id': 28411}, {'_account_id': 28502}]","[{'number': 1, 'created': '2018-06-22 17:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4013cd4103c5e6297f5626a81ad31b4933b9d47f', 'message': 'Updating cloud-controller arguments for external providers\n\nThe current configuration for external cloud providers is incorrect and\nthe kubelet requires different arguments to work with external cloud\nresources. These changes will allow the cloud controller manager to be\noperational.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\n'}, {'number': 2, 'created': '2018-06-22 17:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d0b2bf6a89234182f6132554c57b5837390456b7', 'message': 'Updating cloud-controller arguments for external providers\n\nThe current configuration for external cloud providers is incorrect and\nthe kubelet requires different arguments to work with external cloud\nresources. These changes will allow the cloud controller manager to be\noperational.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\n'}, {'number': 3, 'created': '2018-12-07 18:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/21b1e319c69b192ba860f7d7cb6bd1d73f17a39c', 'message': 'Updating cloud-controller arguments for external providers\n\nThe current configuration for external cloud providers is incorrect and\nthe kubelet requires different arguments to work with external cloud\nresources. These changes will allow the cloud controller manager to be\noperational.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 4, 'created': '2018-12-11 20:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c3ce967c577575fddc5d9369e4bcb5928ed20956', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 5, 'created': '2018-12-13 08:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/24dd7c2967192093300537b9fe696a66531609ae', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 6, 'created': '2018-12-13 09:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2d0bbcce2a4ee46f075045ef5efc9338c83d381d', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 7, 'created': '2018-12-14 02:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a3116fb172065f4b82152d7fc6aa97407bec1035', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 8, 'created': '2018-12-18 09:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c955ed941822e818e8f452e2ecf100342ab7d708', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n* create a copy of the cloud config name exactly /etc/kubernetes/cloud-config,\n  for cinder to work kubelet expects the cloud config name only like this.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 9, 'created': '2018-12-18 10:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c6f3923b97d36c53a6d9f5933835458c39e9faca', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n* Rename kube_openstack_config to cloud-config,\n  for cinder to workm the kubelet expects the cloud config name only\n  like this. Keep a copy of kube_openstack_config for backwards\n  compatibility.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 10, 'created': '2018-12-18 11:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a6d5a9d5ac08a237076228ae2758c490b92144ab', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n* Rename kube_openstack_config to cloud-config,\n  for cinder to workm the kubelet expects the cloud config name only\n  like this. Keep a copy of kube_openstack_config for backwards\n  compatibility.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 11, 'created': '2018-12-19 09:57:00.000000000', 'files': ['doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/drivers/common/templates/kubernetes/fragments/kube-apiserver-to-kubelet-role.sh', 'releasenotes/notes/kubernetes-cloud-config-6c9a4bfec47e3bb4.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/tests/contrib/copy_instance_logs.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-kube-os-config.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6c61a1a949615f6dc1df36f3098cd97466ac7238', 'message': 'k8s_fedora: Use external kubernetes/cloud-provider-openstack\n\n* Use the external cloud-provider [0]\n* Label master nodes\n* Make the script the deploys the cloud-provider and clusterroles\n  for the apiserver a SoftwareDeployment\n* Rename kube_openstack_config to cloud-config,\n  for cinder to workm the kubelet expects the cloud config name only\n  like this. Keep a copy of kube_openstack_config for backwards\n  compatibility.\n\nChange-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702\nTask: 22361\nStory: 2002652\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",30,577477,6c61a1a949615f6dc1df36f3098cd97466ac7238,64,9,11,28411,,,0,"k8s_fedora: Use external kubernetes/cloud-provider-openstack

* Use the external cloud-provider [0]
* Label master nodes
* Make the script the deploys the cloud-provider and clusterroles
  for the apiserver a SoftwareDeployment
* Rename kube_openstack_config to cloud-config,
  for cinder to workm the kubelet expects the cloud config name only
  like this. Keep a copy of kube_openstack_config for backwards
  compatibility.

Change-Id: Ife5558f1db4e581b64cc4a8ffead151f7b405702
Task: 22361
Story: 2002652
Co-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/77/577477/5 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/common/templates/kubernetes/fragments/kube-apiserver-to-kubelet-role.sh', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-kube-os-config.sh']",4,4013cd4103c5e6297f5626a81ad31b4933b9d47f,openstack-cloud-controller-manager," if [ -z ""${TRUST_ID}"" ]; then exit 0 fi ",,92,10
openstack%2Fcinder~stable%2Fqueens~I997109d6bd1adbcbf72c056f78f1e01547d0fcbd,openstack/cinder,stable/queens,I997109d6bd1adbcbf72c056f78f1e01547d0fcbd,Correct default policy file,MERGED,2018-12-06 22:22:03.000000000,2019-01-06 19:04:12.000000000,2018-12-10 16:38:41.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15670}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 24230}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-12-06 22:22:03.000000000', 'files': ['releasenotes/notes/bug-1805550-default-policy-file-db15eaa76fefa115.yaml', 'cinder/policy.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/61e90d528d444fd98d6f34c4b0f81e4ac1e1f0d4', 'message': 'Correct default policy file\n\nSince Queens, the default policy file is policy.yaml, but the\ncode is still looking for policy.json.  This patch corrects the\nlocation and includes a release note.\n\nChange-Id: I997109d6bd1adbcbf72c056f78f1e01547d0fcbd\nCloses-bug: #1805550\n(cherry picked from commit f6c11c2ceab035c65dedab6f514b6be28b1859bb)\n(cherry picked from commit d07abe397c5bdfb45a82150fb7e1a9efaf21ce42)\n'}]",0,623340,61e90d528d444fd98d6f34c4b0f81e4ac1e1f0d4,34,19,1,5314,,,0,"Correct default policy file

Since Queens, the default policy file is policy.yaml, but the
code is still looking for policy.json.  This patch corrects the
location and includes a release note.

Change-Id: I997109d6bd1adbcbf72c056f78f1e01547d0fcbd
Closes-bug: #1805550
(cherry picked from commit f6c11c2ceab035c65dedab6f514b6be28b1859bb)
(cherry picked from commit d07abe397c5bdfb45a82150fb7e1a9efaf21ce42)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/40/623340/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1805550-default-policy-file-db15eaa76fefa115.yaml', 'cinder/policy.py']",2,61e90d528d444fd98d6f34c4b0f81e4ac1e1f0d4,bug/1805550-stable/rocky-stable/queens,"policy_opts.set_defaults(cfg.CONF, 'policy.yaml')","policy_opts.set_defaults(cfg.CONF, 'policy.json')",49,1
openstack%2Fproject-config~master~If01bdd7b7656b1a9ebaa5d5d7d021f82093db8ac,openstack/project-config,master,If01bdd7b7656b1a9ebaa5d5d7d021f82093db8ac,Run fetch-output before removing ssh keys,MERGED,2019-01-06 16:47:31.000000000,2019-01-06 17:00:24.000000000,2019-01-06 17:00:23.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-06 16:47:31.000000000', 'files': ['playbooks/base-test/post.yaml', 'zuul.d/jobs.yaml', 'playbooks/base-test/post-logs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1376bf10cbc6b270da5e8419516b2ccf4cd4b86e', 'message': ""Run fetch-output before removing ssh keys\n\nRename post-ssh to just post. It's really the main post stuff\nthat needs to happen before log publication.\n\nChange-Id: If01bdd7b7656b1a9ebaa5d5d7d021f82093db8ac\n""}]",0,628780,1376bf10cbc6b270da5e8419516b2ccf4cd4b86e,7,3,1,2,,,0,"Run fetch-output before removing ssh keys

Rename post-ssh to just post. It's really the main post stuff
that needs to happen before log publication.

Change-Id: If01bdd7b7656b1a9ebaa5d5d7d021f82093db8ac
",git fetch https://review.opendev.org/openstack/project-config refs/changes/80/628780/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/base-test/post.yaml', 'zuul.d/jobs.yaml', 'playbooks/base-test/post-logs.yaml']",3,1376bf10cbc6b270da5e8419516b2ccf4cd4b86e,zuulv3-output,,- hosts: all roles: - fetch-output ,5,5
openstack%2Fdevstack~master~Id777576d8876d7ba257f0243f3b4ce5756dd9b58,openstack/devstack,master,Id777576d8876d7ba257f0243f3b4ce5756dd9b58,typo fixed,MERGED,2018-12-20 12:56:35.000000000,2019-01-06 13:38:06.000000000,2019-01-06 13:38:06.000000000,"[{'_account_id': 1653}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-20 12:56:35.000000000', 'files': ['clean.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6a7e3ec6479097f4918eb66d25b52cfa46953dec', 'message': 'typo fixed\n\nChange-Id: Id777576d8876d7ba257f0243f3b4ce5756dd9b58\n'}]",0,626569,6a7e3ec6479097f4918eb66d25b52cfa46953dec,9,5,1,15685,,,0,"typo fixed

Change-Id: Id777576d8876d7ba257f0243f3b4ce5756dd9b58
",git fetch https://review.opendev.org/openstack/devstack refs/changes/69/626569/1 && git format-patch -1 --stdout FETCH_HEAD,['clean.sh'],1,6a7e3ec6479097f4918eb66d25b52cfa46953dec,branch_typo_fix,# Clean out the systemd user unit files if systemd was used.,# Clean out the sytemd user unit files if systemd was used.,1,1
openstack%2Fdevstack~master~I12e287e36f01581f1c7145545ab05be527ed15c6,openstack/devstack,master,I12e287e36f01581f1c7145545ab05be527ed15c6,Update supported Fedora releases,MERGED,2018-12-07 19:01:54.000000000,2019-01-06 13:38:05.000000000,2019-01-06 13:38:04.000000000,"[{'_account_id': 1653}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 13252}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-07 19:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/97eaae7be23d77f7def9247b98c38a8c19f5adcb', 'message': 'Update supported Fedora releases\n\nFedora 27 has now hit EOL [1] while Fedora 29 has been released [2].\n\n[1] https://fedoramagazine.org/fedora-27-end-of-life/\n[2] https://fedoramagazine.org/announcing-fedora-29/\n\nChange-Id: I12e287e36f01581f1c7145545ab05be527ed15c6\n'}, {'number': 2, 'created': '2018-12-07 23:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ecc4ca8cccdd9e86fd85b7527470786cf7470690', 'message': 'Update supported Fedora releases\n\nFedora 27 has now hit EOL [1] while Fedora 29 has been released [2].\n\n[1] https://fedoramagazine.org/fedora-27-end-of-life/\n[2] https://fedoramagazine.org/announcing-fedora-29/\n\nChange-Id: I12e287e36f01581f1c7145545ab05be527ed15c6\n'}, {'number': 3, 'created': '2019-01-04 20:53:44.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/77866259e4204eb08afd55e8a29994ad49c58e0b', 'message': 'Update supported Fedora releases\n\nFedora 27 has now hit EOL [1] while Fedora 29 has been released [2].\n\n[1] https://fedoramagazine.org/fedora-27-end-of-life/\n[2] https://fedoramagazine.org/announcing-fedora-29/\n\nChange-Id: I12e287e36f01581f1c7145545ab05be527ed15c6\n'}]",0,623560,77866259e4204eb08afd55e8a29994ad49c58e0b,27,8,3,10135,,,0,"Update supported Fedora releases

Fedora 27 has now hit EOL [1] while Fedora 29 has been released [2].

[1] https://fedoramagazine.org/fedora-27-end-of-life/
[2] https://fedoramagazine.org/announcing-fedora-29/

Change-Id: I12e287e36f01581f1c7145545ab05be527ed15c6
",git fetch https://review.opendev.org/openstack/devstack refs/changes/60/623560/3 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,97eaae7be23d77f7def9247b98c38a8c19f5adcb,f29,if [[ ! ${DISTRO} =~ (xenial|artful|bionic|stretch|jessie|f28|f29|opensuse-42.3|opensuse-15.0|opensuse-tumbleweed|rhel7) ]]; then,if [[ ! ${DISTRO} =~ (xenial|artful|bionic|stretch|jessie|f27|f28|opensuse-42.3|opensuse-15.0|opensuse-tumbleweed|rhel7) ]]; then,1,1
openstack%2Fpbr~master~I605bb328937d8809e0ab543e16c921be2a3b1d51,openstack/pbr,master,I605bb328937d8809e0ab543e16c921be2a3b1d51,Removed older version of python3.4,ABANDONED,2019-01-06 07:21:42.000000000,2019-01-06 13:18:44.000000000,,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-06 07:21:42.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/pbr/commit/9ee56d9dfb4617007791eafab9cddd89e44c80a1', 'message': 'Removed older version of python3.4\n\nChange-Id: I605bb328937d8809e0ab543e16c921be2a3b1d51\nCloses-Bug:  #1801855\n'}]",0,628754,9ee56d9dfb4617007791eafab9cddd89e44c80a1,4,2,1,17130,,,0,"Removed older version of python3.4

Change-Id: I605bb328937d8809e0ab543e16c921be2a3b1d51
Closes-Bug:  #1801855
",git fetch https://review.opendev.org/openstack/pbr refs/changes/54/628754/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9ee56d9dfb4617007791eafab9cddd89e44c80a1,bug/1801855,, Programming Language :: Python :: 3.4,0,1
openstack%2Fnova~stable%2Fqueens~Ieba216275c07ab16414065ee47e66915e9e9477d,openstack/nova,stable/queens,Ieba216275c07ab16414065ee47e66915e9e9477d,Ensure rbd auth fallback uses matching credentials,MERGED,2018-12-21 22:09:09.000000000,2019-01-06 13:17:54.000000000,2019-01-06 13:17:54.000000000,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11805}, {'_account_id': 14595}, {'_account_id': 18058}, {'_account_id': 22348}, {'_account_id': 24230}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-21 22:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9025a8fe899394b360799e2f32ed06cef1e03496', 'message': 'Ensure rbd auth fallback uses matching credentials\n\nAs of Ocata, cinder config is preferred for rbd auth values with a\nfallback to nova values [1]. The fallback path, for the case when\nrbd_user is configured in cinder.conf and rbd_secret_uuid is not\nconfigured in cinder.conf, results in the mismatched use of cinder\nrbd_user with nova rbd_secret_uuid.\n\nThis fixes that fallback path to use nova rbd_user from nova.conf\nwith rbd_secret_uuid from nova.conf.\n\n[1] See commit f2d27f6a8afb62815fb6a885bd4f8ae4ed287fd3\n\nThanks to David Ames for this fix.\n\nChange-Id: Ieba216275c07ab16414065ee47e66915e9e9477d\nCo-Authored-By: David Ames <david.ames@canonical.com>\nCloses-Bug: #1809454\n'}, {'number': 2, 'created': '2019-01-02 14:06:20.000000000', 'files': ['nova/virt/libvirt/volume/net.py', 'nova/tests/unit/virt/libvirt/volume/test_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/accef50f9648dc40f1a6f457f83f5359e9dd2a24', 'message': 'Ensure rbd auth fallback uses matching credentials\n\nAs of Ocata, cinder config is preferred for rbd auth values with a\nfallback to nova values [1]. The fallback path, for the case when\nrbd_user is configured in cinder.conf and rbd_secret_uuid is not\nconfigured in cinder.conf, results in the mismatched use of cinder\nrbd_user with nova rbd_secret_uuid.\n\nThis fixes that fallback path to use nova rbd_user from nova.conf\nwith rbd_secret_uuid from nova.conf.\n\n[1] See commit f2d27f6a8afb62815fb6a885bd4f8ae4ed287fd3\n\nThanks to David Ames for this fix.\n\nChange-Id: Ieba216275c07ab16414065ee47e66915e9e9477d\nCo-Authored-By: David Ames <david.ames@canonical.com>\nCloses-Bug: #1809454\n(cherry picked from commit 47b7c4f3cc582bf463fd0c796df84736a0074f48)\n(cherry picked from commit f5d8ee1bfc3b7b9f1a25f85b42e207db0c9f4b04)\n'}]",0,627010,accef50f9648dc40f1a6f457f83f5359e9dd2a24,24,11,2,11805,,,0,"Ensure rbd auth fallback uses matching credentials

As of Ocata, cinder config is preferred for rbd auth values with a
fallback to nova values [1]. The fallback path, for the case when
rbd_user is configured in cinder.conf and rbd_secret_uuid is not
configured in cinder.conf, results in the mismatched use of cinder
rbd_user with nova rbd_secret_uuid.

This fixes that fallback path to use nova rbd_user from nova.conf
with rbd_secret_uuid from nova.conf.

[1] See commit f2d27f6a8afb62815fb6a885bd4f8ae4ed287fd3

Thanks to David Ames for this fix.

Change-Id: Ieba216275c07ab16414065ee47e66915e9e9477d
Co-Authored-By: David Ames <david.ames@canonical.com>
Closes-Bug: #1809454
(cherry picked from commit 47b7c4f3cc582bf463fd0c796df84736a0074f48)
(cherry picked from commit f5d8ee1bfc3b7b9f1a25f85b42e207db0c9f4b04)
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/627010/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/volume/net.py', 'nova/tests/unit/virt/libvirt/volume/test_net.py']",2,9025a8fe899394b360799e2f32ed06cef1e03496,bug/1809454-stable/queens," this case we fallback to use the local config for secret_uuid and username. self.assertEqual(flags_user, tree.find('./auth').get('username'))"," this case we fallback to use the local config for secret_uuid. self.assertEqual(self.user, tree.find('./auth').get('username'))",7,3
openstack%2Fneutron-fwaas~master~Ic891dd25460d98fcdaa5e6c01dc702482be8e77b,openstack/neutron-fwaas,master,Ic891dd25460d98fcdaa5e6c01dc702482be8e77b,test,ABANDONED,2019-01-06 13:15:49.000000000,2019-01-06 13:17:09.000000000,,[],"[{'number': 1, 'created': '2019-01-06 13:15:49.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/774a546897b83fd84ae8e7719c8cb93ff896ddf6', 'message': 'test\n\nChange-Id: Ic891dd25460d98fcdaa5e6c01dc702482be8e77b\n'}]",0,628775,774a546897b83fd84ae8e7719c8cb93ff896ddf6,2,0,1,22165,,,0,"test

Change-Id: Ic891dd25460d98fcdaa5e6c01dc702482be8e77b
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/75/628775/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,774a546897b83fd84ae8e7719c8cb93ff896ddf6,,test ,,1,0
openstack%2Fpuppet-glance~master~Id33a11d8eb74bc4685b7c1e88de9f73df1404e03,openstack/puppet-glance,master,Id33a11d8eb74bc4685b7c1e88de9f73df1404e03,Remove deprecated logging,MERGED,2018-11-29 09:19:24.000000000,2019-01-06 12:40:59.000000000,2019-01-06 12:40:59.000000000,"[{'_account_id': 3153}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-11-29 09:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/807c2b00a1a5a30a991771c6704eafa0f839c248', 'message': 'Remove deprecated logging\n\nChange-Id: Id33a11d8eb74bc4685b7c1e88de9f73df1404e03\n'}, {'number': 2, 'created': '2018-12-01 15:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/fd39a16e59f8e43d86c1cbf10769cbda6ed4f627', 'message': 'Remove deprecated logging\n\nChange-Id: Id33a11d8eb74bc4685b7c1e88de9f73df1404e03\n'}, {'number': 3, 'created': '2018-12-12 10:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/f18e224f94e39eaad3f191d7ae2f73f629b4742d', 'message': 'Remove deprecated logging\n\nChange-Id: Id33a11d8eb74bc4685b7c1e88de9f73df1404e03\n'}, {'number': 4, 'created': '2019-01-05 21:12:34.000000000', 'files': ['manifests/api/logging.pp', 'manifests/cache/logging.pp', 'manifests/registry.pp', 'manifests/api.pp', 'releasenotes/notes/remove-deprecated-logging-59abbf51ce252346.yaml', 'spec/classes/glance_registry_spec.rb', 'spec/classes/glance_api_spec.rb', 'manifests/registry/logging.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/f09800121b7f3220eb9760df14c21818f9a2f591', 'message': 'Remove deprecated logging\n\nChange-Id: Id33a11d8eb74bc4685b7c1e88de9f73df1404e03\n'}]",0,620829,f09800121b7f3220eb9760df14c21818f9a2f591,36,6,4,16137,,,0,"Remove deprecated logging

Change-Id: Id33a11d8eb74bc4685b7c1e88de9f73df1404e03
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/29/620829/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api/logging.pp', 'manifests/cache/logging.pp', 'manifests/registry.pp', 'manifests/api.pp', 'releasenotes/notes/remove-deprecated-logging-59abbf51ce252346.yaml', 'spec/classes/glance_api_spec.rb', 'spec/classes/glance_registry_spec.rb', 'manifests/registry/logging.pp']",8,807c2b00a1a5a30a991771c6704eafa0f839c248,logging," oslo::log { 'glance_registry_config': debug => $debug, use_stderr => $use_stderr, use_syslog => $use_syslog, log_dir => $log_dir, log_file => $log_file, syslog_log_facility => $log_facility,"," # NOTE(spredzy): In order to keep backward compatibility we rely on the pick function # to use glance::<myparam> first, then glance::logging::<myparam>. $use_syslog_real = pick($::glance::registry::use_syslog,$use_syslog) $use_stderr_real = pick($::glance::registry::use_stderr,$use_stderr) $log_facility_real = pick($::glance::registry::log_facility,$log_facility) if $log_dir != '' { $log_dir_real = pick($::glance::registry::log_dir,$log_dir) } else { $log_dir_real = $log_dir } $log_file_real = pick($::glance::registry::log_file,$log_file) $debug_real = pick($::glance::registry::debug,$debug) oslo::log { 'glance_registry_config': debug => $debug_real, use_stderr => $use_stderr_real, use_syslog => $use_syslog_real, log_dir => $log_dir_real, log_file => $log_file_real, syslog_log_facility => $log_facility_real,",23,121
openstack%2Fglance~master~I345ec8d65d650acf15f9c501921121e92476e99a,openstack/glance,master,I345ec8d65d650acf15f9c501921121e92476e99a,Change openstack-dev to openstack-discuss,ABANDONED,2018-12-09 01:51:24.000000000,2019-01-06 12:13:46.000000000,,"[{'_account_id': 9008}, {'_account_id': 9414}, {'_account_id': 11904}, {'_account_id': 18279}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 27336}]","[{'number': 1, 'created': '2018-12-09 01:51:24.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/glance/commit/9fefdedeaa097f9edf7a5abae835e3ecb50144d9', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces\nopenstack-dev.\n\nChange-Id: I345ec8d65d650acf15f9c501921121e92476e99a\n'}]",0,623708,9fefdedeaa097f9edf7a5abae835e3ecb50144d9,17,7,1,27336,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces
openstack-dev.

Change-Id: I345ec8d65d650acf15f9c501921121e92476e99a
",git fetch https://review.opendev.org/openstack/glance refs/changes/08/623708/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9fefdedeaa097f9edf7a5abae835e3ecb50144d9,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fnetworking-odl~master~I265d66a05eecb50e82caaf28d38b4bfb9f820dd2,openstack/networking-odl,master,I265d66a05eecb50e82caaf28d38b4bfb9f820dd2,Add the project source code repository in README,MERGED,2018-11-05 08:57:24.000000000,2019-01-06 12:04:47.000000000,2019-01-06 12:04:47.000000000,"[{'_account_id': 22348}, {'_account_id': 26507}]","[{'number': 1, 'created': '2018-11-05 08:57:24.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/65331764c94e94876b2fd4cc83fa02f0a221869a', 'message': 'Add the project source code repository in README\n\nChange-Id: I265d66a05eecb50e82caaf28d38b4bfb9f820dd2\n'}]",0,615505,65331764c94e94876b2fd4cc83fa02f0a221869a,6,2,1,28956,,,0,"Add the project source code repository in README

Change-Id: I265d66a05eecb50e82caaf28d38b4bfb9f820dd2
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/05/615505/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,65331764c94e94876b2fd4cc83fa02f0a221869a,, The project source code repository is located at: https://git.openstack.org/cgit/openstack/networking-odl,,3,0
openstack%2Fnetworking-odl~master~I835178f3690ab326528ce5b6bb01b9c89c1c0d77,openstack/networking-odl,master,I835178f3690ab326528ce5b6bb01b9c89c1c0d77,[Trivial fix] Correct spelling error,MERGED,2018-11-05 03:34:26.000000000,2019-01-06 12:00:19.000000000,2019-01-06 12:00:19.000000000,"[{'_account_id': 22348}, {'_account_id': 26507}]","[{'number': 1, 'created': '2018-11-05 03:34:26.000000000', 'files': ['doc/source/contributor/specs/pike/neutron-port-dhcp.rst', 'doc/source/contributor/quickstart.rst', 'doc/source/contributor/specs/ocata/journal-recovery.rst', 'doc/source/contributor/drivers_architecture.rst'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/4812d24ee5f994fa294662f6f759f4db7b4564eb', 'message': '[Trivial fix] Correct spelling error\n\nSmall modification to correct spelling mistake.\n\nChange-Id: I835178f3690ab326528ce5b6bb01b9c89c1c0d77\n'}]",0,615468,4812d24ee5f994fa294662f6f759f4db7b4564eb,6,2,1,28956,,,0,"[Trivial fix] Correct spelling error

Small modification to correct spelling mistake.

Change-Id: I835178f3690ab326528ce5b6bb01b9c89c1c0d77
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/68/615468/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/specs/pike/neutron-port-dhcp.rst', 'doc/source/contributor/quickstart.rst', 'doc/source/contributor/specs/ocata/journal-recovery.rst', 'doc/source/contributor/drivers_architecture.rst']",4,4812d24ee5f994fa294662f6f759f4db7b4564eb,correct-spelling,Note: This architecture has been deprecated in Queens and removed in Rocky.a different architecture.representing that operation and triggers the journaling thread to take care of,Note: This arhitecture has been deprecated in Queens and removed in Rocky.a diffrent architecture.representing that operation and triggers the journalling thread to take care of,8,8
openstack%2Fnetworking-odl~master~If635475407af284c73bb0fae3dabfef134090436,openstack/networking-odl,master,If635475407af284c73bb0fae3dabfef134090436,fix typo mistakes,MERGED,2018-12-11 11:59:05.000000000,2019-01-06 11:59:05.000000000,2019-01-06 11:59:05.000000000,"[{'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26507}, {'_account_id': 27549}, {'_account_id': 29558}]","[{'number': 1, 'created': '2018-12-11 11:59:05.000000000', 'files': ['doc/source/contributor/quickstart.rst', 'doc/source/contributor/drivers_architecture.rst'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/48f7bf25210c680ba44c20ca243328e669ec6c96', 'message': 'fix typo mistakes\n\nChange-Id: If635475407af284c73bb0fae3dabfef134090436\n'}]",0,624372,48f7bf25210c680ba44c20ca243328e669ec6c96,9,5,1,27507,,,0,"fix typo mistakes

Change-Id: If635475407af284c73bb0fae3dabfef134090436
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/72/624372/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/quickstart.rst', 'doc/source/contributor/drivers_architecture.rst']",2,48f7bf25210c680ba44c20ca243328e669ec6c96,,a different architecture.,a diffrent architecture.,4,4
openstack%2Frpm-packaging~master~If2428b7c3683847ff1b1a3933640aec1656ec065,openstack/rpm-packaging,master,If2428b7c3683847ff1b1a3933640aec1656ec065,update oslo.cache url and switch to stestr,ABANDONED,2018-07-30 06:42:34.000000000,2019-01-06 11:52:50.000000000,,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26431}, {'_account_id': 28654}]","[{'number': 1, 'created': '2018-07-30 06:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/61feae056840e56b584246466ac5ceeed7377f59', 'message': 'update oslo.cache url\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 2, 'created': '2018-08-09 06:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0f172ab1c6705c0f7633c194ea5f6eb81241b431', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 3, 'created': '2018-08-11 15:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3ad0b77f7c374589dc561c987ef250d5c75836e7', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 4, 'created': '2018-08-13 01:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a20eda45200574bfb8d507a2b6234cd4b661c17f', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 5, 'created': '2018-08-15 03:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a269172c82458b6d1b51139369350caa538a1268', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 6, 'created': '2018-08-21 09:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/37008c3eb172a981106239f6698f63d4cd26a242', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 7, 'created': '2018-08-21 11:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/40798bcc6c2d2c96705e7a800923d6c976598404', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 8, 'created': '2018-08-21 11:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a971ecc4a49a96b1e587f60beb1ca632402dda43', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 9, 'created': '2018-08-22 01:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b89c0da0a6002e0268f4d78d88dc260d9ea36e9c', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}, {'number': 10, 'created': '2018-12-11 21:52:47.000000000', 'files': ['openstack/oslo.cache/oslo.cache.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/248435b27bdd4e6cf222db1a32bf9550c65d4563', 'message': 'update oslo.cache url and switch to stestr\n\nChange-Id: If2428b7c3683847ff1b1a3933640aec1656ec065\n'}]",1,586948,248435b27bdd4e6cf222db1a32bf9550c65d4563,60,10,10,28654,,,0,"update oslo.cache url and switch to stestr

Change-Id: If2428b7c3683847ff1b1a3933640aec1656ec065
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/48/586948/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.cache/oslo.cache.spec.j2'],1,61feae056840e56b584246466ac5ceeed7377f59,oslo-cache-url-link-error,URL: https://launchpad.net/{{ pypi_name }},URL: http://launchpad.net/%{sname},1,1
openstack%2Fcinder~master~I8a8fbf96875319a7e5ca167fcd2bca45f57649c8,openstack/cinder,master,I8a8fbf96875319a7e5ca167fcd2bca45f57649c8,Ensure image utils don't block greenthreads,MERGED,2018-11-06 16:35:17.000000000,2019-01-06 09:36:06.000000000,2018-12-09 19:54:06.000000000,"[{'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9373}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 20284}, {'_account_id': 20813}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26490}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-11-06 16:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f13ea86b422c55a21d39e21f4fd82942733cb00', 'message': ""Ensure image utils don't block greenthreads\n\nWhe doing image operations in Cinder we may start getting errors on\nRabbitMQ and DB connections, which result in the volume service\nappearing as down to the scheduler.\n\nThis is caused by file I/O operations, that in some cases block\ngreenthreads, preventing switching to another greenthread on I/O as they\nshould.\n\nThis results in many different errors, so this patch makes sure that\nimage operations (fetch, put, verify image, ...) that could prevent\ngreenthread switching are execute in native threads.\n\nCloses-Bug: #1801958\nChange-Id: I8a8fbf96875319a7e5ca167fcd2bca45f57649c8\n""}, {'number': 2, 'created': '2018-12-06 19:24:03.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e4de4fb33d3c54ee48fa2e3689e45787557ee805', 'message': ""Ensure image utils don't block greenthreads\n\nWhen doing image operations in Cinder we may start getting errors on\nRabbitMQ and DB connections, which result in the volume service\nappearing as down to the scheduler.\n\nThis is caused by file I/O operations, that in some cases block\ngreenthreads, preventing switching to another greenthread on I/O as they\nshould.\n\nThis results in many different errors, so this patch makes sure that\nimage operations (fetch, put, verify image, ...) that could prevent\ngreenthread switching are executed in native threads.\n\nCloses-Bug: #1801958\nChange-Id: I8a8fbf96875319a7e5ca167fcd2bca45f57649c8\n""}]",4,615934,e4de4fb33d3c54ee48fa2e3689e45787557ee805,115,43,2,9535,,,0,"Ensure image utils don't block greenthreads

When doing image operations in Cinder we may start getting errors on
RabbitMQ and DB connections, which result in the volume service
appearing as down to the scheduler.

This is caused by file I/O operations, that in some cases block
greenthreads, preventing switching to another greenthread on I/O as they
should.

This results in many different errors, so this patch makes sure that
image operations (fetch, put, verify image, ...) that could prevent
greenthread switching are executed in native threads.

Closes-Bug: #1801958
Change-Id: I8a8fbf96875319a7e5ca167fcd2bca45f57649c8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/615934/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py']",2,7f13ea86b422c55a21d39e21f4fd82942733cb00,bug/1801958," @mock.patch('eventlet.tpool.Proxy') def test_defaults(self, mock_fileutils, mock_stat, mock_proxy): mock_proxy.assert_called_once_with(mock_open.return_value) mock_proxy.return_value) @mock.patch('six.moves.builtins.open') @mock.patch('eventlet.tpool.execute') def test_image_signature_verify_success(self, mock_remove, mock_get, mock_exec, mock_open): mock_exec.assert_called_once_with( image_utils._verify_image, mock_open.return_value.__enter__.return_value, mock_get.return_value) @mock.patch('eventlet.tpool.Proxy') mock_info, mock_open, mock_conf, mock_proxy): mock_proxy.assert_called_once_with( image_service.update.assert_called_once_with( ctxt, image_meta['id'], {}, mock_proxy.return_value) @mock.patch('eventlet.tpool.Proxy') mock_open, mock_conf, mock_chown, mock_proxy): mock_proxy.assert_called_once_with( image_service.update.assert_called_once_with( ctxt, image_meta['id'], {}, mock_proxy.return_value) @mock.patch('eventlet.tpool.Proxy') mock_info, mock_open, mock_conf, mock_chown, mock_proxy): mock_proxy.assert_called_once_with( image_service.update.assert_called_once_with( ctxt, image_meta['id'], {}, mock_proxy.return_value)"," def test_defaults(self, mock_fileutils, mock_stat): mock_open.return_value) def test_image_signature_verify_success(self, mock_remove, mock_get): self.mock_object(builtins, 'open', mock.mock_open()) mock_info, mock_open, mock_conf): image_service.update.assert_called_once_with( ctxt, image_meta['id'], {}, mock_open, mock_conf, mock_chown): image_service.update.assert_called_once_with( ctxt, image_meta['id'], {}, mock_info, mock_open, mock_conf, mock_chown): image_service.update.assert_called_once_with( ctxt, image_meta['id'], {},",52,24
openstack%2Fvitrage~master~If687da3ed0e3dd76df7164b19fcdfa8b36985ec3,openstack/vitrage,master,If687da3ed0e3dd76df7164b19fcdfa8b36985ec3,Update hacking version to latest,MERGED,2019-01-04 15:59:32.000000000,2019-01-06 09:24:52.000000000,2019-01-06 09:24:52.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 15:59:32.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/ed952f747819e3510590f3b4372ac674baed80cf', 'message': 'Update hacking version to latest\n\nChange-Id: If687da3ed0e3dd76df7164b19fcdfa8b36985ec3\n'}]",0,628513,ed952f747819e3510590f3b4372ac674baed80cf,7,3,1,27781,,,0,"Update hacking version to latest

Change-Id: If687da3ed0e3dd76df7164b19fcdfa8b36985ec3
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/13/628513/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ed952f747819e3510590f3b4372ac674baed80cf,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Foctavia-dashboard~master~I2b38132d9c93627d07bb9f8afe21a2944e795207,openstack/octavia-dashboard,master,I2b38132d9c93627d07bb9f8afe21a2944e795207,Modify http to https.,MERGED,2018-12-11 07:08:51.000000000,2019-01-06 08:57:11.000000000,2019-01-06 08:57:11.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-11 07:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/219847081fe0ca44c5f0751bce535e49793b79a8', 'message': 'Modify http to https.\n\nChange-Id: I2b38132d9c93627d07bb9f8afe21a2944e795207\n'}, {'number': 2, 'created': '2018-12-11 07:10:00.000000000', 'files': ['octavia_dashboard/static/dashboard/project/lbaasv2/workflow/certificates/certificates.help.html'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/be784a5304db440031e64f0e1388e5189ba7cbef', 'message': 'Modify http to https.\n\nChange-Id: I2b38132d9c93627d07bb9f8afe21a2944e795207\n'}]",0,624296,be784a5304db440031e64f0e1388e5189ba7cbef,8,3,2,27566,,,0,"Modify http to https.

Change-Id: I2b38132d9c93627d07bb9f8afe21a2944e795207
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/96/624296/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_dashboard/static/dashboard/project/lbaasv2/workflow/certificates/certificates.help.html'],1,219847081fe0ca44c5f0751bce535e49793b79a8,," <a target=""_blank"" href=""https://developer.openstack.org/api-guide/key-manager/containers.html#certificate-containers"">"," <a target=""_blank"" href=""http://developer.openstack.org/api-guide/key-manager/containers.html#certificate-containers"">",1,1
openstack%2Fhorizon~master~Id5c2f52b2578628f299e464a521061ee4f18a527,openstack/horizon,master,Id5c2f52b2578628f299e464a521061ee4f18a527,Imported Translations from Zanata,MERGED,2019-01-05 06:53:02.000000000,2019-01-06 08:37:05.000000000,2019-01-06 08:37:05.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-05 06:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c07c9daa2bfe5ea3c2ce4b170d72dbb5974bb77c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id5c2f52b2578628f299e464a521061ee4f18a527\n'}, {'number': 2, 'created': '2019-01-06 06:48:02.000000000', 'files': ['doc/source/locale/eo/LC_MESSAGES/doc-install.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'doc/source/locale/ja/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-configuration.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'doc/source/locale/id/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc-install.po', 'doc/source/locale/id/LC_MESSAGES/doc-configuration.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d0297a5ed0ba47327daf74fdb9c3211276c1fcf2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id5c2f52b2578628f299e464a521061ee4f18a527\n'}]",0,628721,d0297a5ed0ba47327daf74fdb9c3211276c1fcf2,9,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Id5c2f52b2578628f299e464a521061ee4f18a527
",git fetch https://review.opendev.org/openstack/horizon refs/changes/21/628721/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/locale/eo/LC_MESSAGES/doc-install.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'doc/source/locale/ja/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-configuration.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'doc/source/locale/id/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc-install.po', 'doc/source/locale/id/LC_MESSAGES/doc-configuration.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po']",40,c07c9daa2bfe5ea3c2ce4b170d72dbb5974bb77c,zanata/translations,"""POT-Creation-Date: 2019-01-04 16:33+0000\n""msgid ""Edit Policy"" msgstr ""Editar Política"" ","""POT-Creation-Date: 2018-12-26 19:24+0000\n""",144,103
openstack%2Fbifrost~master~I685efd14bf3567a126311b676a50b0abb0f043db,openstack/bifrost,master,I685efd14bf3567a126311b676a50b0abb0f043db,Perform ironic online data migrations,MERGED,2018-12-27 11:19:42.000000000,2019-01-06 08:12:22.000000000,2019-01-05 01:21:31.000000000,"[{'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-27 11:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/c7227488e14287a98e46d71779ffccdeea4f1081', 'message': 'Perform ironic online data migrations\n\nOnline data migrations are necessary for performing an upgrade of\nironic. Without this change, an error such as the following may be seen\nin task \'bifrost-ironic-install : Upgrade ironic DB Schema\'.\n\nThe database is not compatible with this release of ironic (10.1.7).\nPlease run ""ironic-dbsync online_data_migrations"" using the previous\nrelease.\n\nChange-Id: I685efd14bf3567a126311b676a50b0abb0f043db\nStory: 2004670\nTask: 28658\n'}, {'number': 2, 'created': '2019-01-03 17:53:03.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/705a58f6ebbc0948a703648952dfc1301334c75c', 'message': 'Perform ironic online data migrations\n\nOnline data migrations are necessary for performing an upgrade of\nironic. Without this change, an error such as the following may be seen\nin task \'bifrost-ironic-install : Upgrade ironic DB Schema\'.\n\nThe database is not compatible with this release of ironic (10.1.7).\nPlease run ""ironic-dbsync online_data_migrations"" using the previous\nrelease.\n\nChange-Id: I685efd14bf3567a126311b676a50b0abb0f043db\nStory: 2004670\nTask: 28658\n'}]",2,627513,705a58f6ebbc0948a703648952dfc1301334c75c,15,4,2,14826,,,0,"Perform ironic online data migrations

Online data migrations are necessary for performing an upgrade of
ironic. Without this change, an error such as the following may be seen
in task 'bifrost-ironic-install : Upgrade ironic DB Schema'.

The database is not compatible with this release of ironic (10.1.7).
Please run ""ironic-dbsync online_data_migrations"" using the previous
release.

Change-Id: I685efd14bf3567a126311b676a50b0abb0f043db
Story: 2004670
Task: 28658
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/13/627513/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/tasks/migrations.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'releasenotes/notes/ironic-online-migrations-092aef2b4c2ec75f.yaml']",4,c7227488e14287a98e46d71779ffccdeea4f1081,story/2004670,--- features: - | Adds support for performing ironic online data migrations. ,,32,0
openstack%2Fkuryr-libnetwork~master~I9930f3bcc3a6dbf4b23bf8488f08655bc43b5ba8,openstack/kuryr-libnetwork,master,I9930f3bcc3a6dbf4b23bf8488f08655bc43b5ba8,Avoid changing name of existing ports,MERGED,2018-12-23 22:49:23.000000000,2019-01-06 06:33:26.000000000,2019-01-06 06:33:26.000000000,"[{'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 11536}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 22:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/30e969c0d7da9b7add669105e3e636c0d5dd5cfc', 'message': '[WIP] Avoid changing name of existing ports\n\nChange-Id: I9930f3bcc3a6dbf4b23bf8488f08655bc43b5ba8\n'}, {'number': 2, 'created': '2018-12-24 22:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/0531a1c588edeb3498e90c159b969531e1134483', 'message': 'Avoid changing name of existing ports\n\nIn before, we renamed existing neutron ports in order to make\nthe ports searchable by using endpoint_id.\nHowever, user experience is bad on such renaming because the original\nname is lost. This commit proposes to use tagging approach instead.\nIn particular, we tag the endpoint_id to the existing ports so that\nthe ports are still searchable by using tags.\n\nChange-Id: I9930f3bcc3a6dbf4b23bf8488f08655bc43b5ba8\n'}, {'number': 3, 'created': '2019-01-01 22:59:28.000000000', 'files': ['kuryr_libnetwork/tests/unit/test_kuryr.py', 'kuryr_libnetwork/tests/unit/port_driver/drivers/test_vlan.py', 'kuryr_libnetwork/tests/unit/test_kuryr_endpoint.py', 'kuryr_libnetwork/tests/unit/base.py', 'kuryr_libnetwork/tests/unit/port_driver/drivers/test_veth.py', 'kuryr_libnetwork/tests/unit/test_kuryr_ipam.py', 'kuryr_libnetwork/controllers.py', 'kuryr_libnetwork/utils.py', 'kuryr_libnetwork/port_driver/driver.py'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/a9a70b3178c4f9653b880cf4da4f160dc860b23f', 'message': 'Avoid changing name of existing ports\n\nIn before, we renamed existing neutron ports in order to make\nthe ports searchable by using endpoint_id.\nHowever, user experience is bad on such renaming because the original\nname is lost. This commit proposes to use tagging approach instead.\nIn particular, we tag the endpoint_id to the existing ports so that\nthe ports are still searchable by using tags.\n\nCloses-Bug: #1810219\nChange-Id: I9930f3bcc3a6dbf4b23bf8488f08655bc43b5ba8\n'}]",2,627086,a9a70b3178c4f9653b880cf4da4f160dc860b23f,14,7,3,11536,,,0,"Avoid changing name of existing ports

In before, we renamed existing neutron ports in order to make
the ports searchable by using endpoint_id.
However, user experience is bad on such renaming because the original
name is lost. This commit proposes to use tagging approach instead.
In particular, we tag the endpoint_id to the existing ports so that
the ports are still searchable by using tags.

Closes-Bug: #1810219
Change-Id: I9930f3bcc3a6dbf4b23bf8488f08655bc43b5ba8
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/86/627086/3 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_libnetwork/controllers.py', 'kuryr_libnetwork/utils.py', 'kuryr_libnetwork/port_driver/driver.py']",3,30e969c0d7da9b7add669105e3e636c0d5dd5cfc,bug/1809306," #port['name'] = libnet_utils.get_neutron_port_name(endpoint_id) #'name': port['name'],"," port['name'] = libnet_utils.get_neutron_port_name(endpoint_id) 'name': port['name'],",67,13
openstack%2Fkuryr-libnetwork~master~Iffa5fbf27c64f1aad0a9bb97da9c4e7c5015a196,openstack/kuryr-libnetwork,master,Iffa5fbf27c64f1aad0a9bb97da9c4e7c5015a196,Untag resource if it was tagged,MERGED,2018-12-23 00:26:04.000000000,2019-01-06 06:33:17.000000000,2019-01-06 06:33:17.000000000,"[{'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-23 00:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/174ff64fa0dc8e71f7f1e9635779ffa6c3fc4d58', 'message': ""[WIP] Untag resource if it was tagged\n\nOn removing a tag to a resource (port/subnet/subnetpool/network),\nif the resource doesn't have the tag, skip the neutron API call to\nremove_tag because the tags will be unchanged.\nThis will avoid one or two Neutron API calls and optimize the\nperformance a bit.\n\nPartial-Bug: #1809306\nChange-Id: Iffa5fbf27c64f1aad0a9bb97da9c4e7c5015a196\n""}, {'number': 2, 'created': '2018-12-23 19:12:19.000000000', 'files': ['kuryr_libnetwork/tests/unit/test_kuryr_existing_network.py', 'kuryr_libnetwork/controllers.py'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/b194b0732fd4c0ed7ecaf211de06952339b38e3e', 'message': ""Untag resource if it was tagged\n\nOn removing a tag to a resource (port/subnet/subnetpool/network),\nif the resource doesn't have the tag, skip the neutron API call to\nremove_tag because the tags will be unchanged.\nThis will avoid one or two Neutron API calls and optimize the\nperformance a bit.\n\nPartial-Bug: #1809306\nChange-Id: Iffa5fbf27c64f1aad0a9bb97da9c4e7c5015a196\n""}]",0,627057,b194b0732fd4c0ed7ecaf211de06952339b38e3e,9,6,2,11536,,,0,"Untag resource if it was tagged

On removing a tag to a resource (port/subnet/subnetpool/network),
if the resource doesn't have the tag, skip the neutron API call to
remove_tag because the tags will be unchanged.
This will avoid one or two Neutron API calls and optimize the
performance a bit.

Partial-Bug: #1809306
Change-Id: Iffa5fbf27c64f1aad0a9bb97da9c4e7c5015a196
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/57/627057/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_libnetwork/controllers.py'],1,174ff64fa0dc8e71f7f1e9635779ffa6c3fc4d58,bug/1809306,"def _neutron_net_remove_tag(net, tag): _neutron_remove_tag('networks', net, tag) def _neutron_net_remove_tags(net, tag): _neutron_net_remove_tag(net, tag)def _neutron_subnetpool_remove_tag(pool, tag): _neutron_remove_tag('subnetpools', pool, tag)def _neutron_subnet_remove_tag(subnet, tag): _neutron_remove_tag('subnets', subnet, tag)def _neutron_port_remove_tag(port, tag): _neutron_remove_tag('ports', port, tag)def _neutron_remove_tag(resource_type, resource, tag): if tag in resource['tags']: app.neutron.remove_tag(resource_type, resource['id'], tag) neutron_net = existing_networks[0] neutron_net_id = neutron_net['id'] _neutron_net_remove_tags(neutron_net, container_net_id) _neutron_net_remove_tag(neutron_net, _neutron_subnet_remove_tag(tmp_subnet, pool_id) pools[0], const.KURYR_EXISTING_NEUTRON_SUBNETPOOL) port, const.KURYR_EXISTING_NEUTRON_PORT)","def _neutron_net_remove_tag(netid, tag): _neutron_remove_tag('networks', netid, tag) def _neutron_net_remove_tags(netid, tag): _neutron_net_remove_tag(netid, tag)def _neutron_subnetpool_remove_tag(poolid, tag): _neutron_remove_tag('subnetpools', poolid, tag)def _neutron_subnet_remove_tag(subnetid, tag): _neutron_remove_tag('subnets', subnetid, tag)def _neutron_port_remove_tag(portid, tag): _neutron_remove_tag('ports', portid, tag)def _neutron_remove_tag(resource_type, resource_id, tag): app.neutron.remove_tag(resource_type, resource_id, tag) neutron_net_id = existing_networks[0]['id'] _neutron_net_remove_tags(neutron_net_id, container_net_id) _neutron_net_remove_tag(neutron_net_id, _neutron_subnet_remove_tag(tmp_subnet['id'], pool_id) pool_id, const.KURYR_EXISTING_NEUTRON_SUBNETPOOL) port['id'], const.KURYR_EXISTING_NEUTRON_PORT)",20,18
openstack%2Fkuryr-libnetwork~master~I8a181d6af5228007d36fa8b217fec7f766dd37fd,openstack/kuryr-libnetwork,master,I8a181d6af5228007d36fa8b217fec7f766dd37fd,Tag resource if it was not tagged,MERGED,2018-12-22 23:47:28.000000000,2019-01-06 06:30:38.000000000,2019-01-06 06:30:38.000000000,"[{'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-22 23:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/ae1e0c72850af71b57b8492340b8ca53ecee36a5', 'message': '[WIP] Tag resource if it was not tagged\n\nChange-Id: I8a181d6af5228007d36fa8b217fec7f766dd37fd\n'}, {'number': 2, 'created': '2018-12-23 00:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/042d4148721178a4b419c1f6559833bee8f1ac07', 'message': '[WIP] Tag resource if it was not tagged\n\nOn adding a tag to a resource (port/subnet/subnetpool/network),\nif the resource already exists, skip the neutron API call to add_tag\nbecause the tag will be unchanged.\nThis will avoid one or two Neutron API calls and optimize the\nperformance a bit.\n\nPartial-Bug: #1809306\nChange-Id: I8a181d6af5228007d36fa8b217fec7f766dd37fd\n'}, {'number': 3, 'created': '2018-12-23 00:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/ee7329c0cc41566dde69d3055da2c89dacf159e7', 'message': '[WIP] Tag resource if it was not tagged\n\nOn adding a tag to a resource (port/subnet/subnetpool/network),\nif the resource already has the tag, skip the neutron API call to\nadd_tag because the tags will be unchanged.\nThis will avoid one or two Neutron API calls and optimize the\nperformance a bit.\n\nPartial-Bug: #1809306\nChange-Id: I8a181d6af5228007d36fa8b217fec7f766dd37fd\n'}, {'number': 4, 'created': '2018-12-23 17:14:57.000000000', 'files': ['kuryr_libnetwork/tests/unit/test_kuryr.py', 'kuryr_libnetwork/tests/unit/test_kuryr_existing_network.py', 'kuryr_libnetwork/tests/unit/base.py', 'kuryr_libnetwork/controllers.py'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/dc3cf2cc93a36006f8c16450a3e11b146314258c', 'message': 'Tag resource if it was not tagged\n\nOn adding a tag to a resource (port/subnet/subnetpool/network),\nif the resource already has the tag, skip the neutron API call to\nadd_tag because the tags will be unchanged.\nThis will avoid one or two Neutron API calls and optimize the\nperformance a bit.\n\nPartial-Bug: #1809306\nChange-Id: I8a181d6af5228007d36fa8b217fec7f766dd37fd\n'}]",0,627055,dc3cf2cc93a36006f8c16450a3e11b146314258c,11,6,4,11536,,,0,"Tag resource if it was not tagged

On adding a tag to a resource (port/subnet/subnetpool/network),
if the resource already has the tag, skip the neutron API call to
add_tag because the tags will be unchanged.
This will avoid one or two Neutron API calls and optimize the
performance a bit.

Partial-Bug: #1809306
Change-Id: I8a181d6af5228007d36fa8b217fec7f766dd37fd
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/55/627055/4 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_libnetwork/controllers.py'],1,ae1e0c72850af71b57b8492340b8ca53ecee36a5,bug/1809306,"def _neutron_net_add_tag(net, tag): _neutron_add_tag('networks', net, tag) def _neutron_net_add_tags(net, tag, tags=True): _neutron_net_add_tag(net, tag)def _neutron_subnetpool_add_tag(pool, tag): _neutron_add_tag('subnetpools', pool, tag)def _neutron_subnet_add_tag(subnet, tag): _neutron_add_tag('subnets', subnet, tag)def _neutron_port_add_tag(port, tag): _neutron_add_tag('ports', port, tag)def _neutron_add_tag(resource_type, resource, tag): if tag not in resource['tags']: try: app.neutron.add_tag(resource_type, resource['id'], tag) except n_exceptions.NotFound: LOG.warning(""Neutron tags extension for given "" ""resource type is not supported, "" ""cannot add tag to %s."", resource_type) _neutron_subnet_add_tag(subnet, pool_id) _neutron_subnetpool_add_tag(pool, pool_tag) network = network['network'] _neutron_net_add_tags(network['network'], container_net_id, network = networks[0] _neutron_net_add_tags(network, container_net_id, tags=app.tag) _neutron_net_add_tag(network, 'network_id': network['id'], _neutron_subnet_add_tag(subnet[0], pool_id) existing_pools[0], const.KURYR_EXISTING_NEUTRON_SUBNETPOOL) created_port, _neutron_port_add_tag(created_port,","def _neutron_net_add_tag(netid, tag): _neutron_add_tag('networks', netid, tag) def _neutron_net_add_tags(netid, tag, tags=True): _neutron_net_add_tag(netid, tag)def _neutron_subnetpool_add_tag(poolid, tag): _neutron_add_tag('subnetpools', poolid, tag)def _neutron_subnet_add_tag(subnetid, tag): _neutron_add_tag('subnets', subnetid, tag)def _neutron_port_add_tag(portid, tag): _neutron_add_tag('ports', portid, tag)def _neutron_add_tag(resource_type, resource_id, tag): try: app.neutron.add_tag(resource_type, resource_id, tag) except n_exceptions.NotFound: LOG.warning(""Neutron tags extension for given "" ""resource type is not supported, "" ""cannot add tag to %s."", resource_type) _neutron_subnet_add_tag(subnet['id'], pool_id) _neutron_subnetpool_add_tag(pool['id'], pool_tag) network_id = network['network']['id'] _neutron_net_add_tags(network['network']['id'], container_net_id, network_id = networks[0]['id'] _neutron_net_add_tags(network_id, container_net_id, tags=app.tag) _neutron_net_add_tag(network_id, 'network_id': network_id, _neutron_subnet_add_tag(subnet[0]['id'], pool_id) pool_id, const.KURYR_EXISTING_NEUTRON_SUBNETPOOL) created_port['id'], _neutron_port_add_tag(created_port['id'],",30,29
openstack%2Fkuryr-libnetwork~master~I743b2088366d910902775cabefa43be2865e37c5,openstack/kuryr-libnetwork,master,I743b2088366d910902775cabefa43be2865e37c5,Remove unnecessary port update,MERGED,2018-12-22 23:14:16.000000000,2019-01-06 06:18:53.000000000,2019-01-06 06:18:53.000000000,"[{'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 11536}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-22 23:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/ccbb3a55f5f10f72865e47913696c97ef4ffbb71', 'message': ""[WIP] Remove unnecessary port update\n\nKuryr update pre-created neutron port twice. The first one is in\n'ipam_request_address' and it updates the following attributes:\n* name\n* admin_state_up\n* mac_address\n\nThe second port update is in 'network_driver_create_endpoint' and\nseveral attributes are written including name and mac_address.\nThis commit remove the first port update to optimize the performance.\nThe update of admin_state_up will be moved to the second port update.\n\nChange-Id: I743b2088366d910902775cabefa43be2865e37c5\nPartial-Bug: #1809306\n""}, {'number': 2, 'created': '2018-12-23 16:12:18.000000000', 'files': ['kuryr_libnetwork/tests/unit/port_driver/drivers/test_vlan.py', 'kuryr_libnetwork/tests/unit/port_driver/drivers/test_veth.py', 'kuryr_libnetwork/tests/unit/test_kuryr_ipam.py', 'kuryr_libnetwork/controllers.py', 'kuryr_libnetwork/port_driver/driver.py'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/610fd5f02443f2b97e9d10557bc680868951dbb9', 'message': ""Remove unnecessary port update\n\nKuryr update pre-created neutron port twice. The first one is in\n'ipam_request_address' and it updates the following attributes:\n* name\n* admin_state_up\n* mac_address\n\nThe second port update is in 'network_driver_create_endpoint' and\nseveral attributes are written including name and mac_address.\nThis commit remove the first port update to optimize the performance.\nThe update of admin_state_up will be moved to the second port update.\n\nChange-Id: I743b2088366d910902775cabefa43be2865e37c5\nPartial-Bug: #1809306\n""}]",0,627054,610fd5f02443f2b97e9d10557bc680868951dbb9,10,7,2,11536,,,0,"Remove unnecessary port update

Kuryr update pre-created neutron port twice. The first one is in
'ipam_request_address' and it updates the following attributes:
* name
* admin_state_up
* mac_address

The second port update is in 'network_driver_create_endpoint' and
several attributes are written including name and mac_address.
This commit remove the first port update to optimize the performance.
The update of admin_state_up will be moved to the second port update.

Change-Id: I743b2088366d910902775cabefa43be2865e37c5
Partial-Bug: #1809306
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/54/627054/2 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_libnetwork/controllers.py', 'kuryr_libnetwork/port_driver/driver.py']",2,ccbb3a55f5f10f72865e47913696c97ef4ffbb71,bug/1809306," 'admin_state_up': True,",,2,30
openstack%2Fsenlin~master~I8e79d9fd00aaf79a68fd3756e0999f54e6c9e2ec,openstack/senlin,master,I8e79d9fd00aaf79a68fd3756e0999f54e6c9e2ec,"[Trivial Fix] Correct spelling error of ""exception""",ABANDONED,2019-01-06 03:04:00.000000000,2019-01-06 03:05:07.000000000,,[],"[{'number': 1, 'created': '2019-01-06 03:04:00.000000000', 'files': ['senlin/tests/unit/api/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/bedfaccad873afa1b060700fb704e7f76c491e4e', 'message': '[Trivial Fix] Correct spelling error of ""exception""\n\nChange-Id: I8e79d9fd00aaf79a68fd3756e0999f54e6c9e2ec\n'}]",0,628749,bedfaccad873afa1b060700fb704e7f76c491e4e,2,0,1,17130,,,0,"[Trivial Fix] Correct spelling error of ""exception""

Change-Id: I8e79d9fd00aaf79a68fd3756e0999f54e6c9e2ec
",git fetch https://review.opendev.org/openstack/senlin refs/changes/49/628749/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/unit/api/common/test_wsgi.py'],1,bedfaccad873afa1b060700fb704e7f76c491e4e,fixtypo," def __init__(self, exception_to_raise): self.exception_to_raise = exception_to_raise raise self.exception_to_raise()"," def __init__(self, excpetion_to_raise): self.excpetion_to_raise = excpetion_to_raise raise self.excpetion_to_raise()",3,3
openstack%2Fopenstack-ansible-nspawn_hosts~master~I3b87457e8871128c32b8829f440ea69e0623bfd8,openstack/openstack-ansible-nspawn_hosts,master,I3b87457e8871128c32b8829f440ea69e0623bfd8,Change subvolume create to unmask errors,MERGED,2018-06-27 19:16:53.000000000,2019-01-06 01:37:29.000000000,2019-01-06 01:37:29.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-27 19:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_hosts/commit/5b36534d07d73efec13aa005667f32351d3a18af', 'message': ""Change subvolume create to unmask errors\n\nThe subvolume creation task was running such that all errors were being\nmasked. This change uses the creates argument to give us an idempotent\ntask while also ensuring we're not masking real errors.\n\nChange-Id: I3b87457e8871128c32b8829f440ea69e0623bfd8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 2, 'created': '2019-01-04 20:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_hosts/commit/e589a97c69ed7198ca8c0bb42cb4c9eddd4bf432', 'message': ""Change subvolume create to unmask errors\n\nThe subvolume creation task was running such that all errors were being\nmasked. This change uses the creates argument to give us an idempotent\ntask while also ensuring we're not masking real errors.\n\nChange-Id: I3b87457e8871128c32b8829f440ea69e0623bfd8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 3, 'created': '2019-01-05 04:07:05.000000000', 'files': ['tasks/nspawn_cache.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_hosts/commit/144bf1ccd933461e7fdb23ed65542f67dde75fca', 'message': ""Change subvolume create to unmask errors\n\nThe subvolume creation task was running such that all errors were being\nmasked. This change uses the creates argument to give us an idempotent\ntask while also ensuring we're not masking real errors.\n\nChange-Id: I3b87457e8871128c32b8829f440ea69e0623bfd8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,578535,144bf1ccd933461e7fdb23ed65542f67dde75fca,10,2,3,7353,,,0,"Change subvolume create to unmask errors

The subvolume creation task was running such that all errors were being
masked. This change uses the creates argument to give us an idempotent
task while also ensuring we're not masking real errors.

Change-Id: I3b87457e8871128c32b8829f440ea69e0623bfd8
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-nspawn_hosts refs/changes/35/578535/3 && git format-patch -1 --stdout FETCH_HEAD,['tasks/nspawn_cache.yml'],1,5b36534d07d73efec13aa005667f32351d3a18af,," args: creates: ""/var/lib/machines/{{ nspawn_container_base_name }}"""," failed_when: cache_refresh_del.rc not in [0, 1] changed_when: cache_refresh_add.rc == 0 failed_when: cache_refresh_add.rc not in [0, 1]",2,3
openstack%2Fpuppet-watcher~master~Ie8fcb02ef4d32e412120f66b7e736e63c9fe564b,openstack/puppet-watcher,master,Ie8fcb02ef4d32e412120f66b7e736e63c9fe564b,Remove config of ZeroMQ,ABANDONED,2018-07-12 02:14:43.000000000,2019-01-05 21:46:14.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-07-12 02:14:43.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-watcher/commit/a2d7700822e2e2ddf141261ab72786cc2343488c', 'message': 'Remove config of ZeroMQ\n\nZeroMQ driver is deprecated, as per the Dublin 2018 PTG decision:\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-March/128055.html\n\nChange-Id: Ie8fcb02ef4d32e412120f66b7e736e63c9fe564b\n'}]",0,581930,a2d7700822e2e2ddf141261ab72786cc2343488c,3,1,1,16523,,,0,"Remove config of ZeroMQ

ZeroMQ driver is deprecated, as per the Dublin 2018 PTG decision:
http://lists.openstack.org/pipermail/openstack-dev/2018-March/128055.html

Change-Id: Ie8fcb02ef4d32e412120f66b7e736e63c9fe564b
",git fetch https://review.opendev.org/openstack/puppet-watcher refs/changes/30/581930/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,a2d7700822e2e2ddf141261ab72786cc2343488c,remove-zeromq,,"# [*rpc_zmq_bind_address*] # (optional) ZeroMQ bind address. # Should be a wildcard (*), an ethernet interface, or IP. # The ""host"" option should point or resolve to this address. # Defaults to $::os_service_default. # # [*rpc_zmq_bind_port_retries*] # (optional) Number of retries to find free port number # before fail with ZMQBindError. # Defaults to $::os_service_default. # # [*rpc_zmq_concurrency*] # (optional) Type of concurrency used. # Either ""native"" or ""eventlet"". # Defaults to $::os_service_default. # # [*rpc_zmq_contexts*] # (optional) Number of ZeroMQ contexts. # Defaults to $::os_service_default. # # [*rpc_zmq_host*] # (optional) Name of this node. # Must be a valid hostname, FQDN, or IP address. # Must match ""host"" option, if running Nova. # Defaults to $::os_service_default. # # [*rpc_zmq_ipc_dir*] # (optional) Directory for holding IPC sockets. # Defaults to $::os_service_default. # # [*rpc_zmq_matchmaker*] # (optional) MatchMaker driver. # Defaults to $::os_service_default. # # [*rpc_zmq_max_port*] # (optional) Maximal port number for random ports range. # Defaults to $::os_service_default. # # [*rpc_zmq_min_port*] # (optional) Minimal port number for random ports range. # Defaults to $::os_service_default. # # [*rpc_zmq_topic_backlog*] # (optional) Maximum number of ingress messages to locally buffer per topic. # Defaults to $::os_service_default. # # [*use_pub_sub*] # (optional) Use PUB/SUB pattern for fanout methods. # PUB/SUB always uses proxy. # Defaults to $::os_service_default. # # [*zmq_target_expire*] # (optional) Expiration timeout in seconds of a name service # record about existing target ( < 0 means no timeout). # Defaults to $::os_service_default. # # zmq $rpc_cast_timeout = $::os_service_default, $rpc_poll_timeout = $::os_service_default, $rpc_zmq_bind_address = $::os_service_default, $rpc_zmq_bind_port_retries = $::os_service_default, $rpc_zmq_concurrency = $::os_service_default, $rpc_zmq_contexts = $::os_service_default, $rpc_zmq_host = $::os_service_default, $rpc_zmq_ipc_dir = $::os_service_default, $rpc_zmq_matchmaker = $::os_service_default, $rpc_zmq_max_port = $::os_service_default, $rpc_zmq_min_port = $::os_service_default, $rpc_zmq_topic_backlog = $::os_service_default, $use_pub_sub = $::os_service_default, $zmq_target_expire = $::os_service_default, oslo::messaging::zmq { 'watcher_config': rpc_cast_timeout => $rpc_cast_timeout, rpc_poll_timeout => $rpc_poll_timeout, rpc_zmq_bind_address => $rpc_zmq_bind_address, rpc_zmq_bind_port_retries => $rpc_zmq_bind_port_retries, rpc_zmq_concurrency => $rpc_zmq_concurrency, rpc_zmq_contexts => $rpc_zmq_contexts, rpc_zmq_host => $rpc_zmq_host, rpc_zmq_ipc_dir => $rpc_zmq_ipc_dir, rpc_zmq_matchmaker => $rpc_zmq_matchmaker, rpc_zmq_max_port => $rpc_zmq_max_port, rpc_zmq_min_port => $rpc_zmq_min_port, rpc_zmq_topic_backlog => $rpc_zmq_topic_backlog, use_pub_sub => $use_pub_sub, zmq_target_expire => $zmq_target_expire, } ",0,88
openstack%2Fpuppet-keystone~master~I6b28a31baee2eb0c00798ae694c658b0720d5fb6,openstack/puppet-keystone,master,I6b28a31baee2eb0c00798ae694c658b0720d5fb6,"Revert ""Remove auth_uri""",MERGED,2018-12-28 15:55:46.000000000,2019-01-05 21:41:55.000000000,2018-12-28 23:00:00.000000000,"[{'_account_id': 3153}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-28 15:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cbdc4cc9fd59133ab27d9665dce22abc4f7fe19f', 'message': 'Revert ""Remove auth_uri""\n\nMistral is still using auth_uri, we need to look why but\nthis patch broke TripleO CI.\nLet\'s revert it for now, and investigate how we can\nfix the Mistral.\n\nThis reverts commit 2f8d0c392690883d5c409f7002c6a99a32342059.\nRelated-Bug: #1809974\n\nChange-Id: I6b28a31baee2eb0c00798ae694c658b0720d5fb6\n'}, {'number': 2, 'created': '2018-12-28 15:55:54.000000000', 'files': ['releasenotes/notes/remove-auth-uri-9cfa0ed6b68486e4.yaml', 'manifests/resource/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/5a932874744399ce3330b98bb986ba02803d9394', 'message': 'Revert ""Remove auth_uri""\n\nMistral is still using auth_uri, we need to look why but\nthis patch broke TripleO CI.\nLet\'s revert it for now, and investigate how we can\nfix the Mistral.\n\nThis reverts commit 2f8d0c392690883d5c409f7002c6a99a32342059.\nRelated-Bug: #1809974\n\nChange-Id: I6b28a31baee2eb0c00798ae694c658b0720d5fb6\n'}]",0,627729,5a932874744399ce3330b98bb986ba02803d9394,14,6,2,3153,,,0,"Revert ""Remove auth_uri""

Mistral is still using auth_uri, we need to look why but
this patch broke TripleO CI.
Let's revert it for now, and investigate how we can
fix the Mistral.

This reverts commit 2f8d0c392690883d5c409f7002c6a99a32342059.
Related-Bug: #1809974

Change-Id: I6b28a31baee2eb0c00798ae694c658b0720d5fb6
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/29/627729/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/resource/authtoken.pp', 'releasenotes/notes/remove-auth-uri-9cfa0ed6b68486e4.yaml']",2,cbdc4cc9fd59133ab27d9665dce22abc4f7fe19f,remove-auth-uri,,"--- upgrade: - | The deprecated parameter auth_uri is now removed, please use www_authenticate_uri. ",13,5
openstack%2Fmanila-tempest-plugin~master~I2a044ba76970393c587d6bc8d07280a7727bbe21,openstack/manila-tempest-plugin,master,I2a044ba76970393c587d6bc8d07280a7727bbe21,Py3: Use urlopen from six.moves.urllib.request,MERGED,2019-01-04 20:26:35.000000000,2019-01-05 21:21:28.000000000,2019-01-05 21:21:28.000000000,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-01-04 20:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/49df4bfbabf8e21a9a1ba81a2b88e572779af2a2', 'message': 'Py3: Use urlopen from six.moves.urllib.request\n\nNamespaces within the urllib2 package have\nchanged between python2x and python3x.\n\nChange-Id: I2a044ba76970393c587d6bc8d07280a7727bbe21\n'}, {'number': 2, 'created': '2019-01-05 18:39:16.000000000', 'files': ['manila_tempest_tests/tests/scenario/manager_share.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/8e9a39abbf0bfff5448422dc1bcc6bddb7682355', 'message': 'Py3: Use urlopen from six.moves.urllib.request\n\nNamespaces within the urllib2 package have\nchanged between python2x and python3x.\n\nCloses-bug: #1810610\nChange-Id: I2a044ba76970393c587d6bc8d07280a7727bbe21\n'}]",0,628675,8e9a39abbf0bfff5448422dc1bcc6bddb7682355,11,4,2,16643,,,0,"Py3: Use urlopen from six.moves.urllib.request

Namespaces within the urllib2 package have
changed between python2x and python3x.

Closes-bug: #1810610
Change-Id: I2a044ba76970393c587d6bc8d07280a7727bbe21
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/75/628675/2 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/scenario/manager_share.py'],1,49df4bfbabf8e21a9a1ba81a2b88e572779af2a2,python3,from six.moves.urllib.request import urlopen,from urllib2 import urlopen,1,1
openstack%2Fpuppet-nova~stable%2Frocky~I3b98f07b7f5e62e17dee23a405e34ad483320bbe,openstack/puppet-nova,stable/rocky,I3b98f07b7f5e62e17dee23a405e34ad483320bbe,Add testing for to_array_of_json_strings func,ABANDONED,2018-11-04 12:18:57.000000000,2019-01-05 21:16:49.000000000,,"[{'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-04 12:18:57.000000000', 'files': ['spec/functions/to_array_of_json_strings_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1d073a213a928234f2db6d811651f5e5811ab9a0', 'message': 'Add testing for to_array_of_json_strings func\n\nAdds the unit test for the to_array_of_json_strings\nfunction that is proposed here [1].\n\nThis is to ensure we did not break the function with\nthe following fix [2].\n\nSome scenarios in the testing will fail because [1] also\nfixes a broken functionality that was never discovered due\nto having no testing before.\n\n[1] https://review.openstack.org/#/c/614241/\n[2] https://review.openstack.org/#/c/613445/\n\nChange-Id: I3b98f07b7f5e62e17dee23a405e34ad483320bbe\n'}]",0,615426,1d073a213a928234f2db6d811651f5e5811ab9a0,5,2,1,16137,,,0,"Add testing for to_array_of_json_strings func

Adds the unit test for the to_array_of_json_strings
function that is proposed here [1].

This is to ensure we did not break the function with
the following fix [2].

Some scenarios in the testing will fail because [1] also
fixes a broken functionality that was never discovered due
to having no testing before.

[1] https://review.openstack.org/#/c/614241/
[2] https://review.openstack.org/#/c/613445/

Change-Id: I3b98f07b7f5e62e17dee23a405e34ad483320bbe
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/26/615426/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/functions/to_array_of_json_strings_spec.rb'],1,1d073a213a928234f2db6d811651f5e5811ab9a0,,"require 'spec_helper' describe 'to_array_of_json_strings' do it 'exists' do is_expected.not_to eq(nil) end it 'fails with no arguments' do is_expected.to run.with_params.and_raise_error(Puppet::ParseError) end it 'fails with too many arguments' do is_expected.to run.with_params('arg1', 'arg2').and_raise_error(Puppet::ParseError) end it 'fails with invalid json string' do data = 'invalid json' is_expected.to run.with_params(data).and_raise_error(Puppet::ParseError) end it 'fails with array of json string' do data = ['{""valid"": ""json"", ""syntax"": ""here""}', '{""some"": ""data""}'] is_expected.to run.with_params(data).and_raise_error(Puppet::ParseError) end it 'works with valid json string' do data = '{""valid"": ""json"", ""syntax"": ""here""}' retval = ['{""valid"":""json"",""syntax"":""here""}'] is_expected.to run.with_params(data).and_return(retval) end it 'fails unless its an array or string' do is_expected.to run.with_params(1234).and_raise_error(Puppet::ParseError) end it 'fails unless array doesnt have hashes' do data = [12, 23] is_expected.to run.with_params(data).and_raise_error(Puppet::ParseError) end it 'fails if array but only some entries are valid' do data = [{:some => ""entry""}, 23] is_expected.to run.with_params(data).and_raise_error(Puppet::ParseError) end it 'works with an array of hashes' do data = [{:some => ""entry""}, {:with => ""data""}] retval = ['{""some"":""entry""}','{""with"":""data""}'] is_expected.to run.with_params(data).and_return(retval) end end ",,51,0
openstack%2Fmanila~master~I291f7734f6332914c63a125b590e0cc7495f3a96,openstack/manila,master,I291f7734f6332914c63a125b590e0cc7495f3a96,DNM - test Ubuntu Bionic CephFS jobs under python3,ABANDONED,2019-01-02 16:51:13.000000000,2019-01-05 20:43:18.000000000,,"[{'_account_id': 12016}, {'_account_id': 14384}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-01-02 16:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2ebaeec160b3fbb03cfc2edd75ebcf843da9a479', 'message': 'DNM - test Ubuntu Bionic CephFS jobs under python3\n\nChange-Id: I291f7734f6332914c63a125b590e0cc7495f3a96\nDepends-On: https://review.openstack.org/#/c/626921/\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624467/\n'}, {'number': 2, 'created': '2019-01-03 11:19:40.000000000', 'files': ['DNM'], 'web_link': 'https://opendev.org/openstack/manila/commit/39c5779e3e04f72c997e707dcb160bdd2a6ca58c', 'message': 'DNM - test Ubuntu Bionic CephFS jobs under python3\n\nChange-Id: I291f7734f6332914c63a125b590e0cc7495f3a96\nDepends-On: https://review.openstack.org/#/c/626921/\nDepends-On: https://review.openstack.org/#/c/622415/\nDepends-On: https://review.openstack.org/#/c/624467/\n'}]",0,628003,39c5779e3e04f72c997e707dcb160bdd2a6ca58c,22,10,2,9003,,,0,"DNM - test Ubuntu Bionic CephFS jobs under python3

Change-Id: I291f7734f6332914c63a125b590e0cc7495f3a96
Depends-On: https://review.openstack.org/#/c/626921/
Depends-On: https://review.openstack.org/#/c/622415/
Depends-On: https://review.openstack.org/#/c/624467/
",git fetch https://review.opendev.org/openstack/manila refs/changes/03/628003/2 && git format-patch -1 --stdout FETCH_HEAD,['DNM'],1,2ebaeec160b3fbb03cfc2edd75ebcf843da9a479,,,,0,0
openstack%2Fopenstack-helm-infra~master~I9c00f3baa6c427e6223596ade95c65c331e763fb,openstack/openstack-helm-infra,master,I9c00f3baa6c427e6223596ade95c65c331e763fb,Uplift Ceph charts to the Mimic release,MERGED,2019-01-02 21:41:11.000000000,2019-01-05 19:39:57.000000000,2019-01-05 19:39:57.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 29198}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-02 21:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/993facf26aeaa14d8e14a3b260890c7ce0cb09b1', 'message': '[WIP] Use Mimic release for Ceph Charts\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 2, 'created': '2019-01-03 02:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f486e2490278d540f3e52588d02ccaeab99152bf', 'message': '[WIP] Use Mimic release for Ceph Charts\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 3, 'created': '2019-01-03 03:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/17969743a11a21108f639c1e45dd7121f5ed1754', 'message': '[WIP] Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- All Luminous test now test for both Luminous/Mimic\n- Playbooks will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 4, 'created': '2019-01-03 03:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7addc9fd1c9862ea107868ed9e99331edc5ef8a9', 'message': '[WIP] Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- All Luminous test now test for both Luminous/Mimic\n- Playbooks will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 5, 'created': '2019-01-03 04:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f705fa2373a883c11ffc5699d90edce32712562c', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend\n- All Luminous test now test for both Luminous/Mimic\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 6, 'created': '2019-01-03 04:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f9b8e10206e9251587a17081b9c541eaaf7d3de5', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend\n- All Luminous test now test for both Luminous/Mimic\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 7, 'created': '2019-01-03 15:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9523b93a8e1c2290e3ad43963ac4dc05559aa121', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend\n- All Luminous test now test for both Luminous/Mimic\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 8, 'created': '2019-01-03 15:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2688acdf240be2e2fc24779e73e352a2c6a1e2c3', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend\n- All Luminous test now test for both Luminous/Mimic\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 9, 'created': '2019-01-03 16:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c6381d8e2aa80436c03c7f252953ea3813d0783a', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.3\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend\n- All Luminous test now test for both Luminous/Mimic\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 10, 'created': '2019-01-03 16:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1e8b3ac2b960b49515c029fc2a399b3ac92348c2', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend\n- All Luminous test now test for both Luminous/Mimic\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 11, 'created': '2019-01-03 19:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/673baacd8914585ee7d98032fe967306ce8ec357', 'message': '[WIP] Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- RadosGW by default will now use the Beast backend.\n- Increased RadosGW resource limits for backend change.\n- All Luminous test now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 12, 'created': '2019-01-03 19:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/165ad263ee3edca58d46d7c099200d2cc04b6d86', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 13, 'created': '2019-01-03 21:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7b40e01baaad283c92dc0135655b5d2db7c711aa', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 14, 'created': '2019-01-04 06:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9ec87d4546655dd68f9ca1dd289c2a6e52a38149', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 15, 'created': '2019-01-04 15:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7375cc15b3222b3d43717f92690930f4adab174e', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n- Modify the Elastisearch chart with the proper bucket naming\nconvention required for S3 (underscores are not S3 name compliant)\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 16, 'created': '2019-01-04 15:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/37cd822298d7fb03df504cb61fdfb988cdf8a163', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 17, 'created': '2019-01-04 19:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cec365188b9208e39e792da251e357d824d1bda3', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- RadosGW has relaxed settings enabled for S3 naming conventions.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 18, 'created': '2019-01-04 22:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cafa605a7b0ff7701dbb1f184e5c5e866fc03491', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- RadosGW has relaxed settings enabled for S3 naming conventions.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}, {'number': 19, 'created': '2019-01-05 14:38:38.000000000', 'files': ['tools/images/libvirt/Dockerfile.ubuntu.xenial', 'ceph-osd/values.yaml', 'gnocchi/templates/bin/_storage-init.sh.tpl', 'ceph-rgw/templates/bin/rgw/_init_keystone.sh.tpl', 'ceph-rgw/templates/bin/rgw/_start.sh.tpl', 'ceph-client/values.yaml', 'ceph-rgw/values.yaml', 'ceph-osd/templates/bin/osd/_common.sh.tpl', 'ceph-provisioners/values.yaml', 'tools/deployment/common/005-deploy-k8s.sh', 'tools/images/kubeadm-aio/assets/opt/playbooks/roles/deploy-kubelet/tasks/support-packages.yaml', 'ceph-rgw/templates/deployment-rgw.yaml', 'tools/images/libvirt/Makefile', 'tools/images/libvirt/README.rst', 'ceph-mon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c0d028e2453b0f4d78d9e207439a5f9e9f13955d', 'message': 'Uplift Ceph charts to the Mimic release\n\nChange the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2\n(Mimic). Additionally use supported RHEL/Centos Images rather then\nUbuntu images, which are now considered deprecated by Redhat.\n\n- Uplift all Ceph images to the latest 13.2.2 ceph-container images.\n- RadosGW by default will now use the Beast backend.\n- RadosGW has relaxed settings enabled for S3 naming conventions.\n- Increased RadosGW resource limits due to backend change.\n- All Luminous specific tests now test for both Luminous/Mimic.\n- Gate scripts will remove all none required ceph packages. This is\nrequired to not conflict with the pid/gid that the Redhat container\nuses.\n\nChange-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb\n'}]",2,628051,c0d028e2453b0f4d78d9e207439a5f9e9f13955d,43,7,19,29268,,,0,"Uplift Ceph charts to the Mimic release

Change the release of Ceph from 12.2.3 (Luminous) to latest 13.2.2
(Mimic). Additionally use supported RHEL/Centos Images rather then
Ubuntu images, which are now considered deprecated by Redhat.

- Uplift all Ceph images to the latest 13.2.2 ceph-container images.
- RadosGW by default will now use the Beast backend.
- RadosGW has relaxed settings enabled for S3 naming conventions.
- Increased RadosGW resource limits due to backend change.
- All Luminous specific tests now test for both Luminous/Mimic.
- Gate scripts will remove all none required ceph packages. This is
required to not conflict with the pid/gid that the Redhat container
uses.

Change-Id: I9c00f3baa6c427e6223596ade95c65c331e763fb
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/51/628051/7 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-provisioners/values.yaml', 'ceph-osd/values.yaml', 'ceph-client/values.yaml', 'ceph-rgw/values.yaml', 'ceph-osd/templates/bin/osd/_common.sh.tpl', 'ceph-mon/values.yaml']",6,993facf26aeaa14d8e14a3b260890c7ce0cb09b1,mimic_support, ceph_bootstrap: 'docker.io/ceph/daemon:tag-build-master-0b3eb04-mimic-centos-7-x86_64' ceph_mon: 'docker.io/ceph/daemon:tag-build-master-0b3eb04-mimic-centos-7-x86_64' image_repo_sync: 'docker.io/docker:17.07.0', ceph_bootstrap: 'docker.io/ceph/daemon:tag-build-master-luminous-ubuntu-16.04' ceph_mon: 'docker.io/ceph/daemon:tag-build-master-luminous-ubuntu-16.04' image_repo_sync: docker.io/docker:17.07.0,14,14
openstack%2Fopenstack-helm-infra~master~I305062a5daa063bfe21a12448d7a3957bca00bf4,openstack/openstack-helm-infra,master,I305062a5daa063bfe21a12448d7a3957bca00bf4,Helm-toolkit: Update job for creating s3 buckets,MERGED,2019-01-04 22:27:13.000000000,2019-01-05 19:36:35.000000000,2019-01-05 19:36:35.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-04 22:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/561660fd093a2eba4440bf12a29f5228e84b53bb', 'message': 'Helm-toolkit: Update job for creating s3 buckets\n\nThis updates the helm-toolkit manifest template and scipts for\ncreating an S3 bucket and linking it to a user. This moves away\nfrom the previous python implementation that used rgwadmin, and\ninstead uses s3cmd for a cleaner approach that can support more\nrecent versions of ceph\n\nChange-Id: I305062a5daa063bfe21a12448d7a3957bca00bf4\n'}, {'number': 2, 'created': '2019-01-05 14:37:50.000000000', 'files': ['elasticsearch/templates/configmap-bin.yaml', 'helm-toolkit/templates/scripts/_create-s3-bucket.py.tpl', 'elasticsearch/values.yaml', 'helm-toolkit/templates/scripts/_create-s3-bucket.sh.tpl', 'helm-toolkit/templates/manifests/_job-s3-bucket.yaml.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/818063573368f3162e95f70bd63821d1b96ad8df', 'message': 'Helm-toolkit: Update job for creating s3 buckets\n\nThis updates the helm-toolkit manifest template and scipts for\ncreating an S3 bucket and linking it to a user. This moves away\nfrom the previous python implementation that used rgwadmin, and\ninstead uses s3cmd for a cleaner approach that can support more\nrecent versions of ceph\n\nChange-Id: I305062a5daa063bfe21a12448d7a3957bca00bf4\n'}]",2,628696,818063573368f3162e95f70bd63821d1b96ad8df,14,5,2,17591,,,0,"Helm-toolkit: Update job for creating s3 buckets

This updates the helm-toolkit manifest template and scipts for
creating an S3 bucket and linking it to a user. This moves away
from the previous python implementation that used rgwadmin, and
instead uses s3cmd for a cleaner approach that can support more
recent versions of ceph

Change-Id: I305062a5daa063bfe21a12448d7a3957bca00bf4
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/96/628696/1 && git format-patch -1 --stdout FETCH_HEAD,"['elasticsearch/templates/configmap-bin.yaml', 'helm-toolkit/templates/scripts/_create-s3-bucket.py.tpl', 'elasticsearch/values.yaml', 'helm-toolkit/templates/scripts/_create-s3-bucket.sh.tpl', 'helm-toolkit/templates/manifests/_job-s3-bucket.yaml.tpl']",5,561660fd093a2eba4440bf12a29f5228e84b53bb,htk/update-s3-manifests, - /tmp/create-s3-bucket.sh - name: s3-bucket-sh mountPath: /tmp/create-s3-bucket.sh subPath: create-s3-bucket.sh - name: s3-bucket-sh, - /tmp/create-s3-bucket.py - name: s3-bucket-py mountPath: /tmp/create-s3-bucket.py subPath: create-s3-bucket.py - name: s3-bucket-py,53,102
openstack%2Fdevstack~master~Ic6a5adfbcf2841656929e6c3875889a31d314089,openstack/devstack,master,Ic6a5adfbcf2841656929e6c3875889a31d314089,Cleanup LDAP integration guide,MERGED,2019-01-04 15:23:13.000000000,2019-01-05 17:31:13.000000000,2019-01-05 17:31:13.000000000,"[{'_account_id': 5046}, {'_account_id': 10385}, {'_account_id': 13252}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 15:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e065e45440ee7ae2ce19370dfbe7168072099fbc', 'message': 'Cleanup LDAP integration guide\n\nThis commit fixes a grammar issue in the LDAP integration guide\nand it adds prompts to the command-line examples to be more\nexplicit about where or how commands are being run.\n\nChange-Id: Ic6a5adfbcf2841656929e6c3875889a31d314089\n'}, {'number': 2, 'created': '2019-01-04 17:37:27.000000000', 'files': ['doc/source/guides/devstack-with-ldap.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8e802da4069349a2f6ccdef348999304669a6cbe', 'message': 'Cleanup LDAP integration guide\n\nThis commit fixes a grammar issue in the LDAP integration guide\nand it adds prompts to the command-line examples to be more\nexplicit about where or how commands are being run.\n\nChange-Id: Ic6a5adfbcf2841656929e6c3875889a31d314089\n'}]",2,628454,8e802da4069349a2f6ccdef348999304669a6cbe,16,6,2,5046,,,0,"Cleanup LDAP integration guide

This commit fixes a grammar issue in the LDAP integration guide
and it adds prompts to the command-line examples to be more
explicit about where or how commands are being run.

Change-Id: Ic6a5adfbcf2841656929e6c3875889a31d314089
",git fetch https://review.opendev.org/openstack/devstack refs/changes/54/628454/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/guides/devstack-with-ldap.rst'],1,e065e45440ee7ae2ce19370dfbe7168072099fbc,628454,"can authenticate against keystone, assume role assignments, and interact with other OpenStack services. $ enable_service ldap $ ./stack.sh $ ldapsearch -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ $ ldapadd -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ $ ldapdelete -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ $ ldapadd -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ $ ldapdelete -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \","will can authenticate against keystone, assume role assignments, and interact with other OpenStack services. enable_service ldap ./stack.sh ldapsearch -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ ldapadd -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ ldapdelete -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ ldapadd -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \ ldapdelete -x -w LDAP_PASSWORD -D cn=Manager,dc=openstack,dc=org \",9,9
openstack%2Fdevstack~master~I6871a7765e3e04122d8d546f43d36bb8415383fc,openstack/devstack,master,I6871a7765e3e04122d8d546f43d36bb8415383fc,Drop the deprecated and now removed barrier XFS mount options,MERGED,2018-12-03 14:30:58.000000000,2019-01-05 17:31:12.000000000,2019-01-05 17:31:12.000000000,"[{'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 13252}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-03 14:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7d150211e4218a211041cc5f126e99b876e94d4a', 'message': 'Remove the deprecated and removed nobarrier mount option\n\nBoth barrier and nobarrier were deprecated with the 4.10 kernel [1] and\nthen removed [2] with the 4.19 kernel as used by Fedora >= 28.\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4cf4573\n[2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1c02d50\n\nChange-Id: I6871a7765e3e04122d8d546f43d36bb8415383fc\n'}, {'number': 2, 'created': '2018-12-06 10:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/25c8d0fb88a17d71f59950ded81e73348ee84146', 'message': 'Drop the deprecated and now removed barrier XFS mount options\n\nBoth barrier and nobarrier were deprecated with the 4.10 kernel [1] and\nthen removed [2] with the 4.19 kernel as now used by Fedora >= 28. Both\nshould be safe to drop at this point.\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4cf4573\n[2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1c02d50\n\nChange-Id: I6871a7765e3e04122d8d546f43d36bb8415383fc\n'}, {'number': 3, 'created': '2018-12-07 23:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ba1f1ec708b2d40488e943b0a008397dd6b145aa', 'message': 'Drop the deprecated and now removed barrier XFS mount options\n\nBoth barrier and nobarrier were deprecated with the 4.10 kernel [1] and\nthen removed [2] with the 4.19 kernel as now used by Fedora >= 28. Both\nshould be safe to drop at this point.\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4cf4573\n[2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1c02d50\n\nChange-Id: I6871a7765e3e04122d8d546f43d36bb8415383fc\n'}, {'number': 4, 'created': '2019-01-04 20:53:29.000000000', 'files': ['functions', 'lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5d7d891380f569deaf403aae46a9354eb0243999', 'message': 'Drop the deprecated and now removed barrier XFS mount options\n\nBoth barrier and nobarrier were deprecated with the 4.10 kernel [1] and\nthen removed [2] with the 4.19 kernel as now used by Fedora >= 28. Both\nshould be safe to drop at this point.\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4cf4573\n[2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1c02d50\n\nChange-Id: I6871a7765e3e04122d8d546f43d36bb8415383fc\n'}]",0,621590,5d7d891380f569deaf403aae46a9354eb0243999,31,9,4,10135,,,0,"Drop the deprecated and now removed barrier XFS mount options

Both barrier and nobarrier were deprecated with the 4.10 kernel [1] and
then removed [2] with the 4.19 kernel as now used by Fedora >= 28. Both
should be safe to drop at this point.

[1] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4cf4573
[2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1c02d50

Change-Id: I6871a7765e3e04122d8d546f43d36bb8415383fc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/90/621590/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,7d150211e4218a211041cc5f126e99b876e94d4a,f29," sudo mount -t xfs -o loop,noatime,nodiratime,logbufs=8 \"," sudo mount -t xfs -o loop,noatime,nodiratime,nobarrier,logbufs=8 \",1,1
openstack%2Frpm-packaging~stable%2Frocky~I6983a6df2aad5fd41f0b3b62de652c3c64a3d31e,openstack/rpm-packaging,stable/rocky,I6983a6df2aad5fd41f0b3b62de652c3c64a3d31e,Added spec template for horizon heat-dashboard plugin ui,MERGED,2018-12-17 20:22:17.000000000,2019-01-05 16:32:35.000000000,2019-01-05 16:32:35.000000000,"[{'_account_id': 1916}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25630}]","[{'number': 1, 'created': '2018-12-17 20:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/35e0b3ce2fb03faf728d318b23b9b716c93e7074', 'message': 'Added spec template for horizon heat-dashboard plugin ui\n\nChange-Id: I6983a6df2aad5fd41f0b3b62de652c3c64a3d31e\n(cherry picked from commit d025311f271e5c85b1a63b74703f5ea0b16f52c4)\n'}, {'number': 2, 'created': '2019-01-03 17:58:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a18ffd0f944b97d61e6806dd5ea5c4c9574d0c78', 'message': 'Added spec template for horizon heat-dashboard plugin ui\n\nChange-Id: I6983a6df2aad5fd41f0b3b62de652c3c64a3d31e\n(cherry picked from commit d025311f271e5c85b1a63b74703f5ea0b16f52c4)\n'}, {'number': 3, 'created': '2019-01-03 21:48:05.000000000', 'files': ['openstack/heat-dashboard/heat-dashboard.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/46c4d73259d3e6585149ff7a3148dbecfa921b56', 'message': 'Added spec template for horizon heat-dashboard plugin ui\n\nChange-Id: I6983a6df2aad5fd41f0b3b62de652c3c64a3d31e\n(cherry picked from commit d025311f271e5c85b1a63b74703f5ea0b16f52c4)\n'}]",3,625708,46c4d73259d3e6585149ff7a3148dbecfa921b56,31,8,3,25630,,,0,"Added spec template for horizon heat-dashboard plugin ui

Change-Id: I6983a6df2aad5fd41f0b3b62de652c3c64a3d31e
(cherry picked from commit d025311f271e5c85b1a63b74703f5ea0b16f52c4)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/08/625708/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/heat-dashboard/heat-dashboard.spec.j2'],1,35e0b3ce2fb03faf728d318b23b9b716c93e7074,623101-stable/rocky,"{% set pypi_name = 'heat-dashboard' %} {% set source = fetch_source(""https://tarballs.openstack.org/heat-dashboard/heat-dashboard-master.tar.gz"") %} {% set upstream_version = upstream_version() %} {% set rpm_release = '1' %} %if 0%{?rhel} || 0%{?fedora} %global http_dashboard_dir %{_datarootdir}/openstack-dashboard %else %global http_dashboard_dir /srv/www/openstack-dashboard %endif Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Horizon plugin for heat License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://launchpad.net/{{ pypi_name }} Source0: {{ source|basename }} BuildRequires: fdupes BuildRequires: {{ py2pkg('horizon') }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('XStatic-Angular-UUID') }} BuildRequires: {{ py2pkg('XStatic-Angular-Vis') }} BuildRequires: {{ py2pkg('XStatic-FileSaver') }} BuildRequires: {{ py2pkg('XStatic-JS-Yaml') }} BuildRequires: {{ py2pkg('XStatic-Json2yaml') }} BuildRequires: {{ py2pkg('python-heatclient') }} BuildRequires: {{ py2pkg('mock') }} BuildRequires: {{ py2pkg('pbr') }} Requires: {{ py2pkg('horizon-plugin-heat-ui') }} = %{version} BuildArch: noarch %description Heat dashboard is a horizon plugin for Heat. %package -n {{ py2pkg('horizon-plugin-heat-ui') }} Summary: Horizon plugin for heat - Python Module Requires: {{ py2pkg('XStatic-Angular-UUID') }} Requires: {{ py2pkg('XStatic-Angular-Vis') }} Requires: {{ py2pkg('XStatic-FileSaver') }} Requires: {{ py2pkg('XStatic-JS-Yaml') }} Requires: {{ py2pkg('XStatic-Json2yaml') }} Requires: {{ py2pkg('python-heatclient') }} Requires: {{ py2pkg('pbr') }} %description -n {{ py2pkg('horizon-plugin-heat-ui') }} OpenStack Heat plugin for Horizon. This package contains the core Python module of the heat-ui. %package test Summary: Heat Management Plugin for Horizon - Testsuite Requires: {{ py2pkg('mock') }} #Requires: {{ py2pkg('nodeenv') }} Requires: {{ py2pkg('testtools') }} %description test OpenStack Heat management plugin for Horizon. It is used to verify the functionality of the Heat UI Plugin. %prep %autosetup -p1 -n {{ pypi_name }}-{{upstream_version}} %py_req_cleanup %build %py2_build %check PYTHONPATH=%{http_dashboard_dir} python manage.py test heat_dashboard --settings=heat_dashboard.test.settings %install %py2_install install -m 0755 -d %{buildroot}%{http_dashboard_dir}/openstack_dashboard/enabled/ cp -a heat_dashboard/enabled/*.py %{buildroot}%{http_dashboard_dir}/openstack_dashboard/enabled/ %fdupes %{buildroot}%{python2_sitelib} %fdupes %{buildroot}%{http_dashboard_dir} %post su %{apache_user} -s /bin/sh -c ""python %{http_dashboard_dir}/manage.py collectstatic --noinput --clear > /dev/null"" su %{apache_user} -s /bin/sh -c ""python %{http_dashboard_dir}/manage.py compress --force > /dev/null"" %postun su %{apache_user} -s /bin/sh -c ""python %{http_dashboard_dir}/manage.py collectstatic --noinput --clear > /dev/null"" su %{apache_user} -s /bin/sh -c ""python %{http_dashboard_dir}/manage.py compress --force > /dev/null"" %files %doc ChangeLog CONTRIBUTING.rst README.rst %license LICENSE %{http_dashboard_dir}/openstack_dashboard/enabled/*.py %files -n {{ py2pkg('horizon-plugin-heat-ui') }} %doc README.rst %license LICENSE %{python2_sitelib}/heat_dashboard/ %{python2_sitelib}/heat_dashboard-*.egg-info %exclude %{http_dashboard_dir}/openstack_dashboard/enabled/*.pyc %exclude %{http_dashboard_dir}/openstack_dashboard/enabled/*.pyo %exclude %{python_sitelib}/heat_dashboard/test* %files test %{python_sitelib}/heat_dashboard/test* %changelog ",,105,0
openstack%2Fnetworking-bagpipe~master~I5df1200161b6348c615165cc1d982ee22a78f2d6,openstack/networking-bagpipe,master,I5df1200161b6348c615165cc1d982ee22a78f2d6,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 11:33:45.000000000,2019-01-05 15:52:41.000000000,2019-01-05 15:52:41.000000000,"[{'_account_id': 5367}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-04 11:33:45.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/159194411f2b6ef2f634a103271dece213199d51', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: I5df1200161b6348c615165cc1d982ee22a78f2d6\n'}]",0,622233,159194411f2b6ef2f634a103271dece213199d51,7,3,1,17130,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces openstack-dev.

Change-Id: I5df1200161b6348c615165cc1d982ee22a78f2d6
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/33/622233/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,159194411f2b6ef2f634a103271dece213199d51,mail-list,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fhorizon~master~I69f1e16ff1b88cec78580df0911fe3c01b7507dd,openstack/horizon,master,I69f1e16ff1b88cec78580df0911fe3c01b7507dd,Rework old customization templates and add new blocks,MERGED,2018-04-17 07:47:46.000000000,2019-01-05 15:19:06.000000000,2019-01-05 15:19:06.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 10420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-04-17 07:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1941265e2bd28cb95804da52decc7e0e17bed490', 'message': 'Add a new block and template for analytics\n\nMost deployers want to be able to include analytics code\ninto their theme for Horizon, but often in doing so end up\nhaving that code run on all pages. Some plugins and pages\nideally should not be tracked, and need a better way to\nturn of tracking for those pages.\n\nThis gives us a block we can override to be emtpy on pages\ndeemed sensitive provided the deployers are following our\nsuggested usage guide.\n\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n'}, {'number': 2, 'created': '2018-04-18 02:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c645ae314dd544bec015cccb19d44e627f0506da', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recurvive template\nimporting. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto overextend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and use to show how this work.\n\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 3, 'created': '2018-04-18 03:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/47c4da09f98e5dfe8b05a4e931aa2d638d460420', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recurvive template\nimporting. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto overextend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and use to show how this work.\n\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 4, 'created': '2018-04-20 04:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a67afee9a4631908dd552825267dc8e6851e176c', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recurvive template\nimporting. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto overextend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 5, 'created': '2018-04-26 00:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/97c9d6e9ebeffc8ae2043f1ccaf5bbf42415deb7', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recurive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 6, 'created': '2018-04-26 00:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/22bfa931a28297d653692bd229d41de909d71ebe', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 7, 'created': '2018-05-15 04:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/24432c3c6fee0ccbc524e99141745d155992858d', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 8, 'created': '2018-05-15 05:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b9c986be36a8c3a17f0c2be8ac0c05562c005c55', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 9, 'created': '2018-05-15 05:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e511b669fae2c2e4cdf41a1232a494eee8e06747', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 10, 'created': '2018-05-15 06:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5d856f92cbaa120cd7c08d5cd2fec8b7fda7528c', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 11, 'created': '2018-05-23 01:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/588fecbd6912eec08d41773906acdaf9f05c82dd', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 12, 'created': '2018-05-28 02:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3f79739483b7b73c4cf365f448925a5967c4159f', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 13, 'created': '2018-06-07 02:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d8343a997c2b51344cca27ae8eb2c18dad6ba35b', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 14, 'created': '2018-06-21 07:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7d6a6b421bcde199780aead0bd7b70c604546ea1', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 15, 'created': '2018-06-27 05:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c73e12e843d3401956f50904847961418e4c51e3', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 16, 'created': '2018-07-17 01:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e315b4c0dcc5312725d826ebed14f0084f11367c', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 17, 'created': '2018-07-22 23:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/afd54f0954541ebccaafb68a86906179b32baf93', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 18, 'created': '2019-01-03 03:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ed535eb59fbdfa2d0cc870acc7ba41bb079dcc65', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 19, 'created': '2019-01-03 04:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5bbc0e96d21b614feb929001dd8adfd0b97d8054', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}, {'number': 20, 'created': '2019-01-03 04:45:45.000000000', 'files': ['openstack_dashboard/themes/example/templates/auth/_login_form.html', 'openstack_dashboard/themes/example/static/_styles.scss', 'openstack_dashboard/themes/example/templates/base.html', 'openstack_dashboard/templates/_footer.html', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/themes/example/templates/auth/login.html', 'doc/source/configuration/customizing.rst', 'openstack_dashboard/templates/horizon/_custom_head_js.html', 'openstack_dashboard/themes/example/static/_variables.scss', 'openstack_dashboard/templates/base.html', 'openstack_dashboard/themes/example/static/js/my_custom_js.js', 'releasenotes/notes/bp-less-customization-templates-30384e91c5565328.yaml', 'openstack_dashboard/templates/_login_form_footer.html', 'openstack_dashboard/templates/horizon/_custom_meta.html', 'openstack_dashboard/templates/_login_footer.html', 'openstack_dashboard/themes/example/static/js/my_analytics_js.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e9f8abb65911a6280abf36becb2c8c31058d0763', 'message': ""Rework old customization templates and add new blocks\n\nFrom Rocky we can now support Django's recursive template\ninheritance. Let's move away from all these stand alone\ntemplates for deployers to override and instead direct them\nto recursively extend the existing templates and the blocks they\nneed.\n\nThis adds more blocks, docs on how to use them, and an example\ntheme which can be turned on and used to show how this works.\n\nblueprint: less-customization-templates\nChange-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd\n""}]",13,561822,e9f8abb65911a6280abf36becb2c8c31058d0763,73,5,20,10420,,,0,"Rework old customization templates and add new blocks

From Rocky we can now support Django's recursive template
inheritance. Let's move away from all these stand alone
templates for deployers to override and instead direct them
to recursively extend the existing templates and the blocks they
need.

This adds more blocks, docs on how to use them, and an example
theme which can be turned on and used to show how this works.

blueprint: less-customization-templates
Change-Id: I69f1e16ff1b88cec78580df0911fe3c01b7507dd
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/561822/20 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/templates/horizon/_analytics.html', 'openstack_dashboard/templates/base.html', 'doc/source/configuration/customizing.rst']",3,1941265e2bd28cb95804da52decc7e0e17bed490,bp/less-customization-templates,"Additionally, some scripts require you to place them within the page's <head> tag. To do this, place them within the ``horizon/_custom_head_js.html`` file. Similar to the ``_scripts.html`` file mentioned above, you may link to an existing file:: <script src='{{ STATIC_URL }}/my_custom_dashboard/js/my_custom_js.js' type='text/javascript' charset='utf-8'></script>Custom Analytics ---------------- .. warning:: For the security of your deployment and users, don't use ``horizon/_custom_head_js.html`` for analytics tracking. For analytics or tracking script you should avoid the ``horizon/_custom_head_js.html``. For this we have a specific template instead with ``horizon/_analytics.html``. Much like the custom js template this inserts additional content into the header of the ``base.html`` template and it will be on all pages: <script src='{{ STATIC_URL }}/my_custom_dashboard/js/my_tracking_js.js' type='text/javascript' charset='utf-8'></script> For security purposes we want to be able to turn off tracking on certain pages that we deem sensitive. This is done for the safety of the users and the cloud admins. By using this template instead, pages using ``base.html`` can override the ``analytics`` block when they want to avoid tracking. They can't simply override the custom js because it may be non-tracking code. ","Additionally, some marketing and analytics scripts require you to place them within the page's <head> tag. To do this, place them within the ``horizon/_custom_head_js.html`` file. Similar to the ``_scripts.html`` file mentioned above, you may link to an existing file:: <script src='{{ STATIC_URL }}/my_custom_dashboard/js/my_marketing_js.js' type='text/javascript' charset='utf-8'></script>",36,5
openstack%2Fhorizon~stable%2Fqueens~I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4,openstack/horizon,stable/queens,I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4,Restores deletion in flat network topology,MERGED,2018-12-21 11:19:16.000000000,2019-01-05 15:17:37.000000000,2019-01-05 15:17:37.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 9642}, {'_account_id': 21967}, {'_account_id': 22348}, {'_account_id': 26546}]","[{'number': 1, 'created': '2018-12-21 11:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b493070ffa3a69a5ccb540e45741c600545c4363', 'message': 'Restores deletion in flat network topology\n\n- Removes an inappropriate condition for the device deletion button\n- Fixes a jquery selector for the confirmation dialog that pops up on\n  deletion\n\nChange-Id: I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4\nCloses-Bug: 1781911\n'}, {'number': 2, 'created': '2018-12-21 11:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2f814110f4833f659cb352d3ad504ede596a83e0', 'message': 'Restores deletion in flat network topology\n\n- Removes an inappropriate condition for the device deletion button\n- Fixes a jquery selector for the confirmation dialog that pops up on\n  deletion\n\nChange-Id: I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4\nCloses-Bug: 1781911\n(cherry picked from commit a42a56f495568de4d2136530129825f4e27377b1)\n(cherry picked from commit c9c91325eca56f31f836554a3286e95bd4d87368)\n'}, {'number': 3, 'created': '2018-12-21 11:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7e73a09f902d74ce6f0a5122f90de18cc2aeb03d', 'message': 'Restores deletion in flat network topology\n\n- Removes an inappropriate condition for the device deletion button\n- Fixes a jquery selector for the confirmation dialog that pops up on\n  deletion\n\nChange-Id: I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4\nCloses-Bug: 1781911\n(cherry picked from commit a42a56f495568de4d2136530129825f4e27377b1)\n'}, {'number': 4, 'created': '2019-01-02 09:47:33.000000000', 'files': ['openstack_dashboard/static/js/horizon.flatnetworktopology.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f7dd73008dd6cec63018476711fad83c35dbbb0d', 'message': 'Restores deletion in flat network topology\n\n- Removes an inappropriate condition for the device deletion button\n\nChange-Id: I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4\nCloses-Bug: 1781911\n(cherry picked from commit a42a56f495568de4d2136530129825f4e27377b1)\n'}]",1,626880,f7dd73008dd6cec63018476711fad83c35dbbb0d,16,6,4,8674,,,0,"Restores deletion in flat network topology

- Removes an inappropriate condition for the device deletion button

Change-Id: I0a4c7dd5782524a875bf208d4ea63ac6df4a62b4
Closes-Bug: 1781911
(cherry picked from commit a42a56f495568de4d2136530129825f4e27377b1)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/80/626880/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/js/horizon.flatnetworktopology.js'],1,b493070ffa3a69a5ccb540e45741c600545c4363,bug/1781911, delete_modal.find('.btn.btn-danger').click(function () { delete_modal.find('.btn.btn-danger').click(function () { delete_balloon: function() {, delete_modal.find('.btn-primary').click(function () { delete_modal.find('.btn-primary').click(function () { delete_balloon:function() {,3,3
openstack%2Fproject-config~master~I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb,openstack/project-config,master,I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb,Add fetch-output to base-test,MERGED,2017-10-13 13:36:37.000000000,2019-01-05 14:17:39.000000000,2019-01-05 14:17:39.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-13 13:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5f2506d08a523a40fdc6779a679666698cfaab9c', 'message': 'Add fetch-output to base-test\n\nChange-Id: I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb\nDepends-On: I3dfbbd4327102b62160713ca782dfa4b13d26924\n'}, {'number': 2, 'created': '2018-07-10 20:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1164d97ea66e9b84e82f2bd74fb580c498441369', 'message': 'Add fetch-output to base-test\n\nChange-Id: I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb\nDepends-On: I3dfbbd4327102b62160713ca782dfa4b13d26924\n'}, {'number': 3, 'created': '2019-01-04 23:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c1579636e98a84b66a52f93372863fcfc0000586', 'message': 'Add fetch-output to base-test\n\nChange-Id: I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb\nDepends-On: I3dfbbd4327102b62160713ca782dfa4b13d26924\n'}, {'number': 4, 'created': '2019-01-05 00:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d98e76072d7ae28866bee8927cce6709d3e19522', 'message': 'Add fetch-output to base-test\n\nChange-Id: I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb\nDepends-On: https://review.openstack.org/628707\n'}, {'number': 5, 'created': '2019-01-05 01:07:05.000000000', 'files': ['playbooks/base-test/post-logs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e675b7fe65cdc77f2673e1689e4aaf9c9118d160', 'message': 'Add fetch-output to base-test\n\nChange-Id: I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb\nDepends-On: https://review.openstack.org/628707\n'}]",0,511850,e675b7fe65cdc77f2673e1689e4aaf9c9118d160,18,6,5,2,,,0,"Add fetch-output to base-test

Change-Id: I2cdf4535e7b0bfd1ccfee0ea0cd76602a82474bb
Depends-On: https://review.openstack.org/628707
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/511850/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/base-test/post-logs.yaml'],1,5f2506d08a523a40fdc6779a679666698cfaab9c,zuulv3-output,- hosts: all roles: - fetch-output ,,4,0
openstack%2Fnova~stable%2Frocky~I6915b7deca20eabb88c231b287586c64cdcf3646,openstack/nova,stable/rocky,I6915b7deca20eabb88c231b287586c64cdcf3646,Migrate nova v2.0 legacy job to zuulv3,MERGED,2018-11-28 11:39:43.000000000,2019-01-05 13:14:18.000000000,2019-01-05 13:14:18.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-28 11:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba9e4113daae0a5ace9302c6b00f491338e09991', 'message': 'Migrate nova v2.0 legacy job to zuulv3\n\nThis commit migrate the legacy-tempest-dsvm-nova-v20-api\njob to zullv3 native with new job - tempest-nova-v2-api\n\nChange-Id: I6915b7deca20eabb88c231b287586c64cdcf3646\n(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)\n'}, {'number': 2, 'created': '2018-11-28 12:01:47.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/a8b5d0c2bd62dbfae01512d3fdd235ae3dbe3e4c', 'message': 'Migrate nova v2.0 legacy job to zuulv3\n\nThis commit migrate the legacy-tempest-dsvm-nova-v20-api\njob to zullv3 native with new job - tempest-nova-v2-api\n\nConflicts:\n      .zuul.yaml\n\nThe conflict is due to Ife046b91c96dd300e8c46125b75623d8e12b8da3\n\nChange-Id: I6915b7deca20eabb88c231b287586c64cdcf3646\n(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)\n'}]",0,620571,a8b5d0c2bd62dbfae01512d3fdd235ae3dbe3e4c,24,11,2,8556,,,0,"Migrate nova v2.0 legacy job to zuulv3

This commit migrate the legacy-tempest-dsvm-nova-v20-api
job to zullv3 native with new job - tempest-nova-v2-api

Conflicts:
      .zuul.yaml

The conflict is due to Ife046b91c96dd300e8c46125b75623d8e12b8da3

Change-Id: I6915b7deca20eabb88c231b287586c64cdcf3646
(cherry picked from commit f7a4ba969abdeb6b307ca4052da317b7c0b2ec3f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/620571/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,ba9e4113daae0a5ace9302c6b00f491338e09991,zuulv3-nova,- job: name: tempest-nova-v2-api parent: devstack-tempest branches: - master description: | This job runs the Tempest compute tests against v2.0 endpoint. Former names for this job was: * legacy-tempest-dsvm-nova-v20-api vars: tox_envlist: all tempest_test_regex: api.*compute devstack_localrc: TEMPEST_COMPUTE_TYPE: compute_legacy - tempest-nova-v2-api:, - legacy-tempest-dsvm-nova-v20-api:,16,1
openstack%2Fmanila~master~I0189580ae40b180249fd5846aa986052e44ce2c2,openstack/manila,master,I0189580ae40b180249fd5846aa986052e44ce2c2,devstack: Do a vgscan before checking if the VG is there,MERGED,2019-01-04 11:06:55.000000000,2019-01-05 13:01:57.000000000,2019-01-04 19:07:36.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-01-04 11:06:55.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/49e68f84093bb0765f44523c9333d3d86178d49a', 'message': 'devstack: Do a vgscan before checking if the VG is there\n\nThere might be a rescan for volume groups needed before checking if\nthe volume group is already there. Otherwise, the check for the volume\ngroup fails which means the code tries to create the volume, but that\nfails then because the volume is already there.\nHere is the devstack run log:\n\n  [...]\n  plugin.sh:configure_backing_file:538  sudo losetup -f --show /opt/stack/data/lvm-shares-backing-file\n  plugin.sh:configure_backing_file:538  DEV=/dev/loop2\n  plugin.sh:configure_backing_file:543  sudo vgs lvm-shares\n    Volume group ""lvm-shares"" not found\n    Cannot process volume group lvm-shares\n  plugin.sh:configure_backing_file:543  sudo vgcreate lvm-shares /dev/loop2\n    Physical volume \'/dev/loop2\' is already in volume group \'lvm-shares\'\n    Unable to add physical volume \'/dev/loop2\' to volume group \'lvm-shares\'\n    /dev/loop2: physical volume not initialized.\n  plugin.sh:configure_backing_file:1  exit_trap\n  [...]\n\nChange-Id: I0189580ae40b180249fd5846aa986052e44ce2c2\n'}]",0,628399,49e68f84093bb0765f44523c9333d3d86178d49a,18,13,1,7102,,,0,"devstack: Do a vgscan before checking if the VG is there

There might be a rescan for volume groups needed before checking if
the volume group is already there. Otherwise, the check for the volume
group fails which means the code tries to create the volume, but that
fails then because the volume is already there.
Here is the devstack run log:

  [...]
  plugin.sh:configure_backing_file:538  sudo losetup -f --show /opt/stack/data/lvm-shares-backing-file
  plugin.sh:configure_backing_file:538  DEV=/dev/loop2
  plugin.sh:configure_backing_file:543  sudo vgs lvm-shares
    Volume group ""lvm-shares"" not found
    Cannot process volume group lvm-shares
  plugin.sh:configure_backing_file:543  sudo vgcreate lvm-shares /dev/loop2
    Physical volume '/dev/loop2' is already in volume group 'lvm-shares'
    Unable to add physical volume '/dev/loop2' to volume group 'lvm-shares'
    /dev/loop2: physical volume not initialized.
  plugin.sh:configure_backing_file:1  exit_trap
  [...]

Change-Id: I0189580ae40b180249fd5846aa986052e44ce2c2
",git fetch https://review.opendev.org/openstack/manila refs/changes/99/628399/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,49e68f84093bb0765f44523c9333d3d86178d49a,, sudo vgscan,,1,0
openstack%2Ftripleo-heat-templates~master~I47805608b90d8fda7d8357d3cb55f6372e746da1,openstack/tripleo-heat-templates,master,I47805608b90d8fda7d8357d3cb55f6372e746da1,Allow customization of more openshift-ansible vars,MERGED,2018-12-04 17:27:56.000000000,2019-01-05 12:51:25.000000000,2019-01-05 12:14:19.000000000,"[{'_account_id': 360}, {'_account_id': 11391}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-04 17:27:56.000000000', 'files': ['extraconfig/services/openshift-master.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7c4b027a75afbf1491d7f74695be0f72b79e7320', 'message': 'Allow customization of more openshift-ansible vars\n\nThe `openshift_master_cluster_hostname` and\n`openshift_master_cluster_public_hostname` variables are set to IP\naddresses by tripleo, but were wrongly combined with the\nopenshift_global_vars dictionnary in a way that prevented customization\nvia the OpenShiftGlobalVariables heat parameter.\n\nReverse the order of the combine to make customization possible as they\nshould.\n\nChange-Id: I47805608b90d8fda7d8357d3cb55f6372e746da1\nCloses-Bug: #1806736\n'}]",0,622455,7c4b027a75afbf1491d7f74695be0f72b79e7320,19,7,1,13039,,,0,"Allow customization of more openshift-ansible vars

The `openshift_master_cluster_hostname` and
`openshift_master_cluster_public_hostname` variables are set to IP
addresses by tripleo, but were wrongly combined with the
openshift_global_vars dictionnary in a way that prevented customization
via the OpenShiftGlobalVariables heat parameter.

Reverse the order of the combine to make customization possible as they
should.

Change-Id: I47805608b90d8fda7d8357d3cb55f6372e746da1
Closes-Bug: #1806736
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/55/622455/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/services/openshift-master.yaml'],1,7c4b027a75afbf1491d7f74695be0f72b79e7320,bug/1806736," openshift_global_vars: ""{{ openshift_master_cluster_vars | combine(openshift_global_vars) }}"""," openshift_global_vars: ""{{ openshift_global_vars | combine(openshift_master_cluster_vars) }}""",1,1
openstack%2Fmanila~master~Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39,openstack/manila,master,Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39,Adjust ssh timeouts,MERGED,2018-12-30 02:49:58.000000000,2019-01-05 12:37:17.000000000,2019-01-02 12:12:35.000000000,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 24236}, {'_account_id': 25243}]","[{'number': 1, 'created': '2018-12-30 02:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a22dd6772bf2ea7e9d4db5f01a2b374bf36735f5', 'message': 'Adjust ssh timeouts\n\nGeneric driver jobs are failing because of timeouts when\nestablishing the initial ssh connection from manila-share\nto the service VM.\n\nBump up the default value of the connection timeout for paramiko\nclient and also set the banner timeout since the failure occurred\nduring banner exchange.  Set the two timeouts to the same value\nfor now.  This ensures that the connection timeout is at least as\nlong as the banner timeout and there is no current need in manila\nto control these independently.\n\nThis is more of a workaround than a real fix since a real fix\nwould remove the delay during banner exchange.  I suspect that\nthe real fix will need to be in neutron/ovs though.\n\nChange-Id: Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39\nPartial-bug: #1807216\n'}, {'number': 2, 'created': '2018-12-30 17:25:50.000000000', 'files': ['manila/tests/test_utils.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'devstack/plugin.sh', 'manila/utils.py', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/manila/commit/7548706b0928f2c23bf27e10d116ceca585660e4', 'message': 'Adjust ssh timeouts\n\nGeneric driver jobs are failing because of timeouts when\nestablishing the initial ssh connection from manila-share\nto the service VM.\n\nBump up the default value of the connection timeout for paramiko\nclient and also set the banner timeout since the failure occurred\nduring banner exchange.  Set the two timeouts to the same value\nfor now.  This ensures that the connection timeout is at least as\nlong as the banner timeout and there is no current need in manila\nto control these independently.\n\nThis is more of a workaround than a real fix since a real fix\nwould remove the delay during banner exchange.  I suspect that\nthe real fix will need to be in neutron/ovs though.\n\nChange-Id: Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39\nPartial-bug: #1807216\n'}]",0,627794,7548706b0928f2c23bf27e10d116ceca585660e4,34,13,2,9003,,,0,"Adjust ssh timeouts

Generic driver jobs are failing because of timeouts when
establishing the initial ssh connection from manila-share
to the service VM.

Bump up the default value of the connection timeout for paramiko
client and also set the banner timeout since the failure occurred
during banner exchange.  Set the two timeouts to the same value
for now.  This ensures that the connection timeout is at least as
long as the banner timeout and there is no current need in manila
to control these independently.

This is more of a workaround than a real fix since a real fix
would remove the delay during banner exchange.  I suspect that
the real fix will need to be in neutron/ovs though.

Change-Id: Ib5e59faaf9667b9cb5e7d4072531b7d6c3d4da39
Partial-bug: #1807216
",git fetch https://review.opendev.org/openstack/manila refs/changes/94/627794/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'manila/utils.py', 'devstack/settings']",3,a22dd6772bf2ea7e9d4db5f01a2b374bf36735f5,bug/1673662,# SSH TIMEOUT MANILA_SSH_TIMEOUT=${MANILA_SSH_TIMEOUT:-180} ,,20,1
openstack%2Fnetworking-sfc~master~I6f9bd2d74072d22cea0b290da7c590a1ad680426,openstack/networking-sfc,master,I6f9bd2d74072d22cea0b290da7c590a1ad680426,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 05:43:49.000000000,2019-01-05 12:15:09.000000000,2019-01-05 12:15:09.000000000,"[{'_account_id': 841}, {'_account_id': 12021}, {'_account_id': 21798}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 28637}]","[{'number': 1, 'created': '2018-12-04 05:43:49.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/16f1a86d9738c8c80549361fdeb8ea18f47b4045', 'message': 'Change openstack-dev to openstack-discuss\n\nMailing lists have been updated. openstack-discuss replaces\nopenstack-dev.\n\nChange-Id: I6f9bd2d74072d22cea0b290da7c590a1ad680426\n'}]",0,622000,16f1a86d9738c8c80549361fdeb8ea18f47b4045,11,6,1,18955,,,0,"Change openstack-dev to openstack-discuss

Mailing lists have been updated. openstack-discuss replaces
openstack-dev.

Change-Id: I6f9bd2d74072d22cea0b290da7c590a1ad680426
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/00/622000/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,16f1a86d9738c8c80549361fdeb8ea18f47b4045,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fnetworking-sfc~master~Ia98573704e93d8c70e5c6448a548ce68b0427fee,openstack/networking-sfc,master,Ia98573704e93d8c70e5c6448a548ce68b0427fee,Increment versioning with pbr instruction,MERGED,2018-10-15 13:47:48.000000000,2019-01-05 12:15:08.000000000,2019-01-05 12:15:08.000000000,"[{'_account_id': 841}, {'_account_id': 2472}, {'_account_id': 8871}, {'_account_id': 11904}, {'_account_id': 12021}, {'_account_id': 17068}, {'_account_id': 18955}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 26222}]","[{'number': 1, 'created': '2018-10-15 13:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/7a19063f9631e1d95a1e01e522564c14ce54e884', 'message': 'Increment versioning with pbr instruction\n\nWith moving away from required milestone releases, the version numbers\ncalculated by PBR on the master branch will not work for those testing\nupgrades from the last stable release. More details can be found in the\nmailing list post here:\n\n    http://lists.openstack.org/pipermail/openstack-dev/2018-October/135706.html\n\nThis is an empty commit that will cause PBR to increment its calculated\nversion to get around this.\n\nPBR will see the following which will cause it to increment the version:\n\nSem-Ver: feature\n\nPlease merge this patch as soon as possible to support those testing\nupgrades.\n\nChange-Id: Ia98573704e93d8c70e5c6448a548ce68b0427fee\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2019-01-03 07:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/3e65a808f08fa41a8e3bd96272384b6138c9ebd3', 'message': 'Increment versioning with pbr instruction\n\nWith moving away from required milestone releases, the version numbers\ncalculated by PBR on the master branch will not work for those testing\nupgrades from the last stable release. More details can be found in the\nmailing list post here:\n\n    http://lists.openstack.org/pipermail/openstack-dev/2018-October/135706.html\n\nThis is an empty commit that will cause PBR to increment its calculated\nversion to get around this.\n\nPBR will see the following which will cause it to increment the version:\n\nSem-Ver: feature\n\nPlease merge this patch as soon as possible to support those testing\nupgrades.\n\nChange-Id: Ia98573704e93d8c70e5c6448a548ce68b0427fee\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,610542,3e65a808f08fa41a8e3bd96272384b6138c9ebd3,17,10,2,11904,,,0,"Increment versioning with pbr instruction

With moving away from required milestone releases, the version numbers
calculated by PBR on the master branch will not work for those testing
upgrades from the last stable release. More details can be found in the
mailing list post here:

    http://lists.openstack.org/pipermail/openstack-dev/2018-October/135706.html

This is an empty commit that will cause PBR to increment its calculated
version to get around this.

PBR will see the following which will cause it to increment the version:

Sem-Ver: feature

Please merge this patch as soon as possible to support those testing
upgrades.

Change-Id: Ia98573704e93d8c70e5c6448a548ce68b0427fee
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/42/610542/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,7a19063f9631e1d95a1e01e522564c14ce54e884,sem-ver,,,0,0
openstack%2Fnetworking-bgpvpn~master~I3e58cf9393c52c47192099fc244426d910b53e22,openstack/networking-bgpvpn,master,I3e58cf9393c52c47192099fc244426d910b53e22,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 11:36:51.000000000,2019-01-05 11:00:00.000000000,2019-01-05 11:00:00.000000000,"[{'_account_id': 12021}, {'_account_id': 22348}, {'_account_id': 28637}]","[{'number': 1, 'created': '2018-12-04 11:36:51.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/201b3ee2a195e12ba02784b39ed63268c61954bf', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: I3e58cf9393c52c47192099fc244426d910b53e22\n'}]",0,622236,201b3ee2a195e12ba02784b39ed63268c61954bf,7,3,1,17130,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces openstack-dev.

Change-Id: I3e58cf9393c52c47192099fc244426d910b53e22
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/36/622236/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,201b3ee2a195e12ba02784b39ed63268c61954bf,mail-list,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fnetworking-bgpvpn~master~I28d197968671da2f7ed1c0c604be50eb82a63f32,openstack/networking-bgpvpn,master,I28d197968671da2f7ed1c0c604be50eb82a63f32,Change openstack-dev to openstack-discuss,ABANDONED,2018-12-09 02:54:52.000000000,2019-01-05 10:41:30.000000000,,"[{'_account_id': 9414}, {'_account_id': 12021}, {'_account_id': 22348}, {'_account_id': 28637}]","[{'number': 1, 'created': '2018-12-09 02:54:52.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/8368ac2db1b8b821b2e2501110147b0089c22ff2', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces\nopenstack-dev.\n\nChange-Id: I28d197968671da2f7ed1c0c604be50eb82a63f32\n'}]",0,623780,8368ac2db1b8b821b2e2501110147b0089c22ff2,8,4,1,27336,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces
openstack-dev.

Change-Id: I28d197968671da2f7ed1c0c604be50eb82a63f32
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/80/623780/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,8368ac2db1b8b821b2e2501110147b0089c22ff2,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fopenstack-helm~master~Ib3f09128226f0bcc78384b1ee2da811d62a5b59d,openstack/openstack-helm,master,Ib3f09128226f0bcc78384b1ee2da811d62a5b59d,Update docs building,MERGED,2018-12-12 19:44:11.000000000,2019-01-05 10:32:33.000000000,2019-01-05 10:32:33.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2018-12-12 19:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f5f4607e4c352e15fae880f8bd499a232c160d1f', 'message': 'Update docs building\n\nThe repo used both openstackdocstheme and oslosphinx in requirements but\nthen configured openstackdocstheme, remove oslosphinx everywhere.\n\nInstead of using sphinx-build, use  docstheme-build-translated.sh to\nbuild English and translated documents.\n\nUpdate doc/source/conf.py for newer openstackdocstheme and require\na new enough version.\n\nRemove module index - it does not exist, this is not a python repo where\nautodoc works.\n\nChange-Id: Ib3f09128226f0bcc78384b1ee2da811d62a5b59d\n'}, {'number': 2, 'created': '2018-12-12 19:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ef5927d64a1d13af8cd2adbd9c767190fbe986e5', 'message': ""Update docs building\n\nThe repo used both openstackdocstheme and oslosphinx in requirements but\nthen configured openstackdocstheme, remove oslosphinx everywhere.\n\nInstead of using sphinx-build, use  docstheme-build-translated.sh to\nbuild English and translated documents.\n\nUpdate doc/source/conf.py for newer openstackdocstheme and require\na new enough version.\n\nRemove module index - it does not exist, this is not a python repo where\nautodoc works.\n\nRemove sphinx-quickstart generated output from index.rst, it's not\nneeded anymore.\n\nChange-Id: Ib3f09128226f0bcc78384b1ee2da811d62a5b59d\n""}, {'number': 3, 'created': '2019-01-05 09:22:36.000000000', 'files': ['doc/source/index.rst', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1d5dfa2468a9ad28cd19f37198370b56a0c47a26', 'message': ""Update docs building\n\nThe repo used both openstackdocstheme and oslosphinx in requirements but\nthen configured openstackdocstheme, remove oslosphinx everywhere.\n\nInstead of using sphinx-build, use  docstheme-build-translated.sh to\nbuild English and translated documents.\n\nUpdate doc/source/conf.py for newer openstackdocstheme and require\na new enough version.\n\nRemove module index - it does not exist, this is not a python repo where\nautodoc works.\n\nRemove sphinx-quickstart generated output from index.rst, it's not\nneeded anymore.\n\nChange-Id: Ib3f09128226f0bcc78384b1ee2da811d62a5b59d\n""}]",0,624793,1d5dfa2468a9ad28cd19f37198370b56a0c47a26,14,4,3,6547,,,0,"Update docs building

The repo used both openstackdocstheme and oslosphinx in requirements but
then configured openstackdocstheme, remove oslosphinx everywhere.

Instead of using sphinx-build, use  docstheme-build-translated.sh to
build English and translated documents.

Update doc/source/conf.py for newer openstackdocstheme and require
a new enough version.

Remove module index - it does not exist, this is not a python repo where
autodoc works.

Remove sphinx-quickstart generated output from index.rst, it's not
needed anymore.

Change-Id: Ib3f09128226f0bcc78384b1ee2da811d62a5b59d
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/93/624793/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,f5f4607e4c352e15fae880f8bd499a232c160d1f,openstackdocstheme, docstheme-build-translated.sh, python setup.py build_sphinx,4,7
openstack%2Fmanila~master~Iaef8d8cb4be0d8872a2796c0fc69279c14f15a80,openstack/manila,master,Iaef8d8cb4be0d8872a2796c0fc69279c14f15a80,QNAP: Fix inconsistent cases while create/manage from snapshot,MERGED,2019-01-04 06:23:59.000000000,2019-01-05 09:56:27.000000000,2019-01-04 16:55:03.000000000,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22450}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 26134}]","[{'number': 1, 'created': '2019-01-04 06:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/51befeb3a0d2d52cacba9d3fb90741f4adeb1911', 'message': 'QNAP: Fix inconsistent cases while create/manage from snapshot\n\nThere are two situation may cause the size of share/snapshot\nmanaged by manila is inconsistent with the NAS backend.\nOne is to create a share from snapshot. While the other one\nis to manage an existing snapshot.\n\nChange-Id: Iaef8d8cb4be0d8872a2796c0fc69279c14f15a80\nCloses-Bug: #1810476\n'}, {'number': 2, 'created': '2019-01-04 10:40:02.000000000', 'files': ['releasenotes/notes/qnap-fix-share-and-snapshot-inconsistant-bd628c6e14eeab14.yaml', 'manila/share/drivers/qnap/api.py', 'manila/tests/share/drivers/qnap/fakes.py', 'manila/tests/share/drivers/qnap/test_api.py', 'manila/share/drivers/qnap/qnap.py', 'manila/tests/share/drivers/qnap/test_qnap.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ad62e9dde3fe1ad555f412e8f01680ab5bd7fd52', 'message': 'QNAP: Fix inconsistent cases while create/manage from snapshot\n\nThere are two situation may cause the size of share/snapshot\nmanaged by manila is inconsistent with the NAS backend.\nOne is to create a share from snapshot. While the other one\nis to manage an existing snapshot.\n\nChange-Id: Iaef8d8cb4be0d8872a2796c0fc69279c14f15a80\nCloses-Bug: #1810476\n'}]",2,628342,ad62e9dde3fe1ad555f412e8f01680ab5bd7fd52,33,14,2,26134,,,0,"QNAP: Fix inconsistent cases while create/manage from snapshot

There are two situation may cause the size of share/snapshot
managed by manila is inconsistent with the NAS backend.
One is to create a share from snapshot. While the other one
is to manage an existing snapshot.

Change-Id: Iaef8d8cb4be0d8872a2796c0fc69279c14f15a80
Closes-Bug: #1810476
",git fetch https://review.opendev.org/openstack/manila refs/changes/42/628342/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/qnap-fix-share-and-snapshot-inconsistant-bd628c6e14eeab14.yaml', 'manila/share/drivers/qnap/api.py', 'manila/tests/share/drivers/qnap/fakes.py', 'manila/tests/share/drivers/qnap/test_api.py', 'manila/share/drivers/qnap/qnap.py', 'manila/tests/share/drivers/qnap/test_qnap.py']",6,51befeb3a0d2d52cacba9d3fb90741f4adeb1911,bug/1810476," 'fakeShareName@fakeSnapshotName', 'fakeShareName', 10) 'fakeShareName@fakeSnapshotName', 'fakeShareName', 10) mock_api_executor.return_value.get_snapshot_info.return_value = ( self.get_snapshot_info_return_value())"," 'fake_basic_info': fakes.FakeGetBasicInfoResponseTdsTs_4_3_0(), 'expect_result': api.QnapAPIExecutorTS }, { 'fake_basic_info': fakes.FakeGetBasicInfoResponseTdsEs_2_1_0(), 'expect_result': api.QnapAPIExecutor }, { 'fake_basic_info': fakes.FakeGetBasicInfoResponseTdsTs_4_0_0(), 'expect_result': exception.ShareBackendException }, { 'fake_basic_info': fakes.FakeGetBasicInfoResponseTdsEs_1_1_1(), 'expect_result': exception.ShareBackendException }, { 'fake_basic_info': fakes.FakeGetBasicInfoResponseTdsEs_2_2_0(), 'expect_result': exception.ShareBackendException }, { 'fakeShareName@fakeSnapshotName', 'fakeShareName') @mock.patch('manila.share.API') mock_share_api, mock_share_api.return_value.get.return_value = {'size': 5} mock_api_executor.return_value.edit_share.return_value = ( None) 'fakeShareName@fakeSnapshotName', 'fakeShareName') expect_share_dict = { 'sharename': 'fakeShareName', 'old_sharename': 'fakeShareName', 'new_size': 10, 'thin_provision': True, 'compression': True, 'deduplication': False, 'ssd_cache': False, 'share_proto': 'NFS' } mock_api_return.edit_share.assert_called_once_with( expect_share_dict) @mock.patch.object(qnap.QnapShareDriver, '_get_location_path') def test_manage_existing_snapshot_not_exist( self, mock_get_location_path): """"""Test manage existing snapshot with snapshot which does not exist."""""" fake_snapshot = fakes.SnapshotClass( 10, 'fakeShareName@fakeSnapshotName') mock_api_executor = qnap.QnapShareDriver._create_api_executor mock_api_executor.return_value.get_share_info.return_value = ( self.get_share_info_return_value()) mock_api_executor.return_value.get_snapshot_info.return_value = None mock_private_storage = mock.Mock() mock_private_storage.get.side_effect = [ 'fakeVolId', 'fakeVolName'] self._do_setup('http://1.2.3.4:8080', '1.2.3.4', 'admin', 'qnapadmin', 'Storage Pool 1', private_storage=mock_private_storage) mock_api_return = mock_api_executor.return_value self.assertRaises( exception.InvalidParameterValue, self.driver.manage_existing_snapshot, snapshot=fake_snapshot, driver_options='driver_options') mock_api_return.get_share_info.assert_called_once_with( 'Storage Pool 1', vol_no='fakeVolId') ",29,191
openstack%2Frpm-packaging~master~Icdda110c19509dbd66a00609c625b38767e6961f,openstack/rpm-packaging,master,Icdda110c19509dbd66a00609c625b38767e6961f,Remove documentation-build error flag globally on prepare cleanup,MERGED,2017-09-25 16:53:32.000000000,2019-01-05 09:38:13.000000000,2019-01-05 09:38:13.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-09-25 16:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7b3e44d4f9aaa68f6cd7dca52f5039add7d68f26', 'message': 'Remove documentation-build error flag globally on prepare cleanup\n\nThis is a common operation in all the spec files so it makes\nsense to add it to the globally executed macro in the prep step.\n\nChange-Id: Icdda110c19509dbd66a00609c625b38767e6961f\n'}, {'number': 2, 'created': '2017-09-26 16:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5a0dd31b257d0efbcbb4026e09c78fc2781b0969', 'message': 'Remove documentation-build error flag globally on prepare cleanup\n\nThis is a common operation in all the spec files so it makes\nsense to add it to the globally executed macro in the prep step.\n\nChange-Id: Icdda110c19509dbd66a00609c625b38767e6961f\n'}, {'number': 3, 'created': '2018-12-11 21:55:47.000000000', 'files': ['openstack/openstack-macros/macros.openstack-rdo', 'openstack/openstack-macros/openstack-macros.spec.j2', 'openstack/openstack-macros/macros.openstack-suse'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0561daeaca429a97d6db3d3b841f0828528fbe50', 'message': 'Remove documentation-build error flag globally on prepare cleanup\n\nThis is a common operation in all the spec files so it makes\nsense to add it to the globally executed macro in the prep step.\n\nChange-Id: Icdda110c19509dbd66a00609c625b38767e6961f\n'}]",4,507209,0561daeaca429a97d6db3d3b841f0828528fbe50,34,8,3,6593,,,0,"Remove documentation-build error flag globally on prepare cleanup

This is a common operation in all the spec files so it makes
sense to add it to the globally executed macro in the prep step.

Change-Id: Icdda110c19509dbd66a00609c625b38767e6961f
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/09/507209/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/openstack-macros/macros.openstack-rdo', 'openstack/openstack-macros/openstack-macros.spec.j2', 'openstack/openstack-macros/macros.openstack-suse']",3,7b3e44d4f9aaa68f6cd7dca52f5039add7d68f26,507209,%py_req_cleanup sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,%py_req_cleanup true,6,3
openstack%2Frpm-packaging~master~I237ff7f7ae466372f544c303de1387c2fbc0e372,openstack/rpm-packaging,master,I237ff7f7ae466372f544c303de1387c2fbc0e372,pymod2pkg: Update to 0.17.1,MERGED,2019-01-02 16:19:31.000000000,2019-01-05 09:32:18.000000000,2019-01-05 09:32:18.000000000,"[{'_account_id': 1916}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-02 16:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/aea6ba25f68738307a681244e9fece4ae92358ae', 'message': 'pymod2pkg: Update to 0.17.1\n\nChange-Id: I237ff7f7ae466372f544c303de1387c2fbc0e372\nDepends-On: https://review.openstack.org/#/c/627984/\n'}, {'number': 2, 'created': '2019-01-04 19:05:19.000000000', 'files': ['openstack/pymod2pkg/pymod2pkg.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f25448084330854932289bea0742068ff71417c7', 'message': 'pymod2pkg: Update to 0.17.1\n\nChange-Id: I237ff7f7ae466372f544c303de1387c2fbc0e372\nDepends-On: https://review.openstack.org/#/c/627984/\n'}]",1,628000,f25448084330854932289bea0742068ff71417c7,26,7,2,6593,,,0,"pymod2pkg: Update to 0.17.1

Change-Id: I237ff7f7ae466372f544c303de1387c2fbc0e372
Depends-On: https://review.openstack.org/#/c/627984/
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/00/628000/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/pymod2pkg/pymod2pkg.spec.j2'],1,aea6ba25f68738307a681244e9fece4ae92358ae,,{% set upstream_version = upstream_version('0.17.1') %},{% set upstream_version = upstream_version('0.17.0') %},1,1
openstack%2Ftripleo-heat-templates~master~I96fd7dfc5468bf1dbdc665b3d848b40223ee9454,openstack/tripleo-heat-templates,master,I96fd7dfc5468bf1dbdc665b3d848b40223ee9454,Add missing role_specific tag for NUMA aware vswitches params,MERGED,2018-12-18 09:58:51.000000000,2019-01-05 09:19:12.000000000,2019-01-03 19:03:12.000000000,"[{'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 8042}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2018-12-18 09:58:51.000000000', 'files': ['puppet/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/90717bdca62ef7408958942efec85c89202a939c', 'message': 'Add missing role_specific tag for NUMA aware vswitches params\n\nChange I318ba9c262f64c0d416a017ed836ae0729acedb4 expose NUMA\naware vswitches configuration parameter, which are role-specific.\n\nThe proposed patch adds role_specific tag for those parameters\nwhich is missed in original patch.\n\nChange-Id: I96fd7dfc5468bf1dbdc665b3d848b40223ee9454\n'}]",0,625864,90717bdca62ef7408958942efec85c89202a939c,45,10,1,20733,,,0,"Add missing role_specific tag for NUMA aware vswitches params

Change I318ba9c262f64c0d416a017ed836ae0729acedb4 expose NUMA
aware vswitches configuration parameter, which are role-specific.

The proposed patch adds role_specific tag for those parameters
which is missed in original patch.

Change-Id: I96fd7dfc5468bf1dbdc665b3d848b40223ee9454
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/625864/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/nova-compute.yaml'],1,90717bdca62ef7408958942efec85c89202a939c,missing-role-specific-tag, tags: - role_specific tags: - role_specific,,4,0
openstack%2Fopenstack-helm-infra~master~I5a52397185610e19ce5861ce3c3b3303006a296b,openstack/openstack-helm-infra,master,I5a52397185610e19ce5861ce3c3b3303006a296b,Parameterize hugepage pod cgroup,MERGED,2019-01-03 22:13:14.000000000,2019-01-05 09:17:11.000000000,2019-01-05 09:17:11.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26449}, {'_account_id': 26686}]","[{'number': 1, 'created': '2019-01-03 22:13:14.000000000', 'files': ['libvirt/templates/bin/_libvirt.sh.tpl', 'libvirt/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ff7985e391379336a9b9821307c267559ac12075', 'message': 'Parameterize hugepage pod cgroup\n\nChange-Id: I5a52397185610e19ce5861ce3c3b3303006a296b\n'}]",2,628314,ff7985e391379336a9b9821307c267559ac12075,17,6,1,26686,,,0,"Parameterize hugepage pod cgroup

Change-Id: I5a52397185610e19ce5861ce3c3b3303006a296b
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/14/628314/1 && git format-patch -1 --stdout FETCH_HEAD,"['libvirt/templates/bin/_libvirt.sh.tpl', 'libvirt/values.yaml']",2,ff7985e391379336a9b9821307c267559ac12075,," kubernetes: cgroup: ""kubepods""",,6,1
openstack%2Fcongress~master~Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec,openstack/congress,master,Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec,Fix congre command excute error when using python3.6,MERGED,2019-01-03 02:46:38.000000000,2019-01-05 08:47:15.000000000,2019-01-05 08:47:15.000000000,"[{'_account_id': 14107}, {'_account_id': 18591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-03 02:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3b81f6b81569f9808916ef702002e62728ccbbed', 'message': '[TEST]congressclient\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n'}, {'number': 2, 'created': '2019-01-03 05:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a60a247cff3e153d056690add98113cebbdc4f75', 'message': '[TEST]congressclient\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n'}, {'number': 3, 'created': '2019-01-03 06:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/73a1196c50b9380ae3be53d3cf82f289d0d10ec4', 'message': '[TEST]congressclient\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n'}, {'number': 4, 'created': '2019-01-03 07:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/ba2b607c511ea552f4e77c747b2d9e8055cabc88', 'message': ""Fix congressclient install when using python3.6\n\nwhen test murano python3 in patch [0], murano-congress-devstack\nfailed when excute congress command, error as below:\n2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 : \nout='openstack: '\\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin \n--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\\'' \nis not an openstack command. See '\\''openstack --help'\\''.\n2018-12-28 05:33:03.601983 | controller | Did you mean one of these?\n2018-12-28 05:33:03.602029 | controller |   address scope create\n2018-12-28 05:33:03.602057 | controller |   address scope delete\n2018-12-28 05:33:03.602082 | controller |   address scope list\n2018-12-28 05:33:03.602122 | controller |   address scope set\n2018-12-28 05:33:03.602149 | controller |   address scope show'\n2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap\nThis patch using setup_dev_lib function from devstack install python-congressclient,\nalso this patch add a way to install congresscliet from requirements.\n\n[0]: https://review.openstack.org/#/c/624600/\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n""}, {'number': 5, 'created': '2019-01-03 07:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/59bff7d5e831ff70a49840dad574950f9a1aa5b3', 'message': ""Fix congre command excute error when using python3.6\n\nwhen test murano python3 in patch [0], murano-congress-devstack\nfailed when excute congress command, error as below:\n2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 :\nout='openstack: '\\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin\n--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\\''\nis not an openstack command. See '\\''openstack --help'\\''.\n2018-12-28 05:33:03.601983 | controller | Did you mean one of these?\n2018-12-28 05:33:03.602029 | controller |   address scope create\n2018-12-28 05:33:03.602057 | controller |   address scope delete\n2018-12-28 05:33:03.602082 | controller |   address scope list\n2018-12-28 05:33:03.602122 | controller |   address scope set\n2018-12-28 05:33:03.602149 | controller |   address scope show'\n2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap\nThis patch using setup_dev_lib function from devstack install python-congressclient,\nalso this patch add a way to install congresscliet from requirements.\n\n[0]: https://review.openstack.org/#/c/624600/\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n""}, {'number': 6, 'created': '2019-01-03 08:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/79e2c33969749f089ae7c81cd3e20d195ad6f7ea', 'message': ""Fix congre command excute error when using python3.6\n\nwhen test murano python3 in patch [0], murano-congress-devstack\nfailed when excute congress command, error as below:\n2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 :\nout='openstack: '\\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin\n--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\\''\nis not an openstack command. See '\\''openstack --help'\\''.\n2018-12-28 05:33:03.601983 | controller | Did you mean one of these?\n2018-12-28 05:33:03.602029 | controller |   address scope create\n2018-12-28 05:33:03.602057 | controller |   address scope delete\n2018-12-28 05:33:03.602082 | controller |   address scope list\n2018-12-28 05:33:03.602122 | controller |   address scope set\n2018-12-28 05:33:03.602149 | controller |   address scope show'\n2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap\nThis patch using setup_dev_lib function from devstack install python-congressclient,\nalso this patch add a way to install congresscliet from requirements.\n\n[0]: https://review.openstack.org/#/c/624600/\n\nDepends-On: https://review.openstack.org/#/c/628122/\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n""}, {'number': 7, 'created': '2019-01-03 10:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d87f4567a9797aff87ea48ab7d62ac01cddce0ad', 'message': ""Fix congre command excute error when using python3.6\n\nwhen test murano python3 in patch [0], murano-congress-devstack\nfailed when excute congress command, error as below:\n2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 :\nout='openstack: '\\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin\n--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\\''\nis not an openstack command. See '\\''openstack --help'\\''.\n2018-12-28 05:33:03.601983 | controller | Did you mean one of these?\n2018-12-28 05:33:03.602029 | controller |   address scope create\n2018-12-28 05:33:03.602057 | controller |   address scope delete\n2018-12-28 05:33:03.602082 | controller |   address scope list\n2018-12-28 05:33:03.602122 | controller |   address scope set\n2018-12-28 05:33:03.602149 | controller |   address scope show'\n2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap\nThis patch using setup_dev_lib function from devstack install python-congressclient,\nalso this patch add a way to install congresscliet from requirements.\n\n[0]: https://review.openstack.org/#/c/624600/\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n""}, {'number': 8, 'created': '2019-01-04 00:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/37dab3cb9ed0217511fae0ad3032df20f53b4ef1', 'message': ""Fix congre command excute error when using python3.6\n\nwhen test murano python3 in patch [0], murano-congress-devstack\nfailed when excute congress command, error as below:\n2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 :\nout='openstack: '\\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin\n--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\\''\nis not an openstack command. See '\\''openstack --help'\\''.\n2018-12-28 05:33:03.601983 | controller | Did you mean one of these?\n2018-12-28 05:33:03.602029 | controller |   address scope create\n2018-12-28 05:33:03.602057 | controller |   address scope delete\n2018-12-28 05:33:03.602082 | controller |   address scope list\n2018-12-28 05:33:03.602122 | controller |   address scope set\n2018-12-28 05:33:03.602149 | controller |   address scope show'\n2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap\nThis patch using setup_dev_lib function from devstack install python-congressclient,\nalso this patch add a way to install congresscliet from requirements.\n\n[0]: https://review.openstack.org/#/c/624600/\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n""}, {'number': 9, 'created': '2019-01-04 02:38:20.000000000', 'files': ['playbooks/legacy/congress-devstack-api-base/run.yaml', 'playbooks/legacy/congress-pe-replicated-base/run.yaml', 'playbooks/legacy/congress-devstack-py35-api-mysql/run.yaml', 'devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/congress/commit/21f075faacf0c260c5f4899cd6ba16d369e1b787', 'message': ""Fix congre command excute error when using python3.6\n\nwhen test murano python3 in patch [0], murano-congress-devstack\nfailed when excute congress command, error as below:\n2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 :\nout='openstack: '\\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin\n--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\\''\nis not an openstack command. See '\\''openstack --help'\\''.\n2018-12-28 05:33:03.601983 | controller | Did you mean one of these?\n2018-12-28 05:33:03.602029 | controller |   address scope create\n2018-12-28 05:33:03.602057 | controller |   address scope delete\n2018-12-28 05:33:03.602082 | controller |   address scope list\n2018-12-28 05:33:03.602122 | controller |   address scope set\n2018-12-28 05:33:03.602149 | controller |   address scope show'\n2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap\nThis patch using setup_dev_lib function from devstack install python-congressclient,\nalso this patch add a way to install congresscliet from requirements.\n\n[0]: https://review.openstack.org/#/c/624600/\n\nChange-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec\n""}]",0,628093,21f075faacf0c260c5f4899cd6ba16d369e1b787,25,3,9,14107,,,0,"Fix congre command excute error when using python3.6

when test murano python3 in patch [0], murano-congress-devstack
failed when excute congress command, error as below:
2018-12-28 05:33:03.601901 | controller | ++ functions-common:oscwrap:2287 :
out='openstack: '\''congress datasource create neutronv2 neutronv2 --config poll_time=10 --config username=admin
--config tenant_name=admin --config password=secretadmin --config auth_url=http://38.108.68.25/identity'\''
is not an openstack command. See '\''openstack --help'\''.
2018-12-28 05:33:03.601983 | controller | Did you mean one of these?
2018-12-28 05:33:03.602029 | controller |   address scope create
2018-12-28 05:33:03.602057 | controller |   address scope delete
2018-12-28 05:33:03.602082 | controller |   address scope list
2018-12-28 05:33:03.602122 | controller |   address scope set
2018-12-28 05:33:03.602149 | controller |   address scope show'
2018-12-28 05:33:03.604233 | controller | + functions-common:oscwrap:1               :   exit_trap
This patch using setup_dev_lib function from devstack install python-congressclient,
also this patch add a way to install congresscliet from requirements.

[0]: https://review.openstack.org/#/c/624600/

Change-Id: Ifda90653ca515bd5e21e5ed7338ab9fbdacc86ec
",git fetch https://review.opendev.org/openstack/congress refs/changes/93/628093/8 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,3b81f6b81569f9808916ef702002e62728ccbbed,,"function install_congress_pythonclient() { # For using non-released client from git branch, need to add # LIBS_FROM_GIT=python-congressclient parameter to localrc. # Otherwise, congress will install python-congressclient from requirements. if use_library_from_git ""python-congressclient""; then git_clone_by_name ""python-congressclient"" setup_dev_lib ""python-congressclient"" # Installing bash_completion for congress sudo install -D -m 0644 -o $STACK_USER {${GITDIR[""python-congressclient""]}/tools/,/etc/bash_completion.d/}congress.bash_completion fi } install_congress_pythonclient", git_clone $CONGRESSCLIENT_REPO $CONGRESSCLIENT_DIR $CONGRESSCLIENT_BRANCH setup_develop $CONGRESSCLIENT_DIR,14,2
openstack%2Fmurano-dashboard~master~Id9b541f40bc43ac79ae0f6d9464a8eafd56a381b,openstack/murano-dashboard,master,Id9b541f40bc43ac79ae0f6d9464a8eafd56a381b,add py36 to classifier and UT job,MERGED,2019-01-05 03:20:47.000000000,2019-01-05 08:13:57.000000000,2019-01-05 08:13:56.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-05 03:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/84194d71134b5d26696d02c9e046a9151a1378ad', 'message': 'add py36 to classifier and UT job\n\nChange-Id: Id9b541f40bc43ac79ae0f6d9464a8eafd56a381b\n'}, {'number': 2, 'created': '2019-01-05 03:24:55.000000000', 'files': ['.zuul.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/704a2ff22517ab730287b63eadcd56df1489ed17', 'message': 'add py36 to classifier and UT job\n\nChange-Id: Id9b541f40bc43ac79ae0f6d9464a8eafd56a381b\n'}]",0,628714,704a2ff22517ab730287b63eadcd56df1489ed17,7,2,2,14107,,,0,"add py36 to classifier and UT job

Change-Id: Id9b541f40bc43ac79ae0f6d9464a8eafd56a381b
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/14/628714/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,84194d71134b5d26696d02c9e046a9151a1378ad,,"envlist = py36,py35,py27,pep8","envlist = py35,py27,pep8",2,1
