id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ftripleo-heat-templates~master~I087439eee69394fad8e5872e64557d2f6c5cd83e,openstack/tripleo-heat-templates,master,I087439eee69394fad8e5872e64557d2f6c5cd83e,Wire up new tripleo upgrades jobs template,MERGED,2020-11-03 16:06:03.000000000,2021-01-07 16:26:01.000000000,2021-01-07 16:26:01.000000000,"[{'_account_id': 8175}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29775}, {'_account_id': 30742}, {'_account_id': 31075}]","[{'number': 1, 'created': '2020-11-03 16:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1854cfdbc9e1c9d2dff8e3d80983d9f0ed755d45', 'message': 'WIP - wire up master standalone-upgrade content provider template\n\nThe depends-on tries to split the upgrade jobs to a template per\nbranch to prevent redundant content providers.\n\nDepends-On: I728b56e98b376051dc350b0779e656cd12a80c77\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n'}, {'number': 2, 'created': '2020-11-04 13:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/254e5fe55c1e4b29c25d8aa02ba5fff98dfa3e9b', 'message': 'WIP - wire up master standalone-upgrade content provider template\n\nThe depends-on tries to split the upgrade jobs to a template per\nbranch to prevent redundant content providers.\n\nDepends-On: https://review.opendev.org/761188\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n'}, {'number': 3, 'created': '2020-11-24 12:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4da4754c221ef890b7c9d5a5cfd28e55deabebe5', 'message': 'WIP - wire up master standalone-upgrade content provider template\n\nThe depends-on tries to split the upgrade jobs to a template per\nbranch to prevent redundant content providers.\n\nDepends-On: https://review.opendev.org/761188\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n'}, {'number': 4, 'created': '2020-12-22 16:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/401d9718a2109134c098e95bbf266191d208e52d', 'message': 'WIP - wire up master standalone-upgrade content provider template\n\nThe depends-on tries to split the upgrade jobs to a template per\nbranch to prevent redundant content providers.\n\nDepends-On: https://review.opendev.org/761188\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n'}, {'number': 5, 'created': '2021-01-04 12:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a44962c98cfab96b6036d74b0004879bfbbdd42e', 'message': 'Wire up master standalone-upgrade content provider template\n\nThe depends-on adds a new upgrade jobs template which is wired up\nhere. Once wired up across tripleo we can remove excess content\nproviders with [1].\n\n[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131\nDepends-On: https://review.opendev.org/761188\n\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n'}, {'number': 6, 'created': '2021-01-04 14:21:52.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/38c3cdb815b9b46ac83f946811a86285e56730f4', 'message': 'Wire up new tripleo upgrades jobs template\n\nThe depends-on adds a new upgrade jobs template which is wired up\nhere. Once wired up across tripleo we can remove excess content\nproviders with [1].\n\n[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131\nDepends-On: https://review.opendev.org/761188\n\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n'}]",0,761189,38c3cdb815b9b46ac83f946811a86285e56730f4,23,11,6,8449,,,0,"Wire up new tripleo upgrades jobs template

The depends-on adds a new upgrade jobs template which is wired up
here. Once wired up across tripleo we can remove excess content
providers with [1].

[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131
Depends-On: https://review.opendev.org/761188

Change-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/89/761189/6 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,1854cfdbc9e1c9d2dff8e3d80983d9f0ed755d45,reduce-content-providers, - tripleo-standalone-upgrades-master-pipeline,,1,0
openstack%2Fcharm-ceph-iscsi~master~I9cb75ddaa8334a09727610889ca32a9a415481fd,openstack/charm-ceph-iscsi,master,I9cb75ddaa8334a09727610889ca32a9a415481fd,Stop leaking secrets in the logs,MERGED,2021-01-07 10:54:54.000000000,2021-01-07 15:38:28.000000000,2021-01-07 15:38:28.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-07 10:54:54.000000000', 'files': ['src/gwcli_client.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/81fdd34d12be0dd35a800200b030e83d501df060', 'message': 'Stop leaking secrets in the logs\n\nChange-Id: I9cb75ddaa8334a09727610889ca32a9a415481fd\n'}]",0,769707,81fdd34d12be0dd35a800200b030e83d501df060,10,3,1,31289,,,0,"Stop leaking secrets in the logs

Change-Id: I9cb75ddaa8334a09727610889ca32a9a415481fd
",git fetch https://review.opendev.org/openstack/charm-ceph-iscsi refs/changes/07/769707/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/gwcli_client.py', 'README.md']",2,81fdd34d12be0dd35a800200b030e83d501df060,stop-leaking-secrets,* Deploying four ceph-iscsi units is theoretically possible but it is not an,* Deploying four ceph-iscsi units is theoretical possible but it is not an,17,3
openstack%2Fironic~stable%2Fvictoria~I5499fa42c1d82a1a29099fbbba6f45d440448b72,openstack/ironic,stable/victoria,I5499fa42c1d82a1a29099fbbba6f45d440448b72,Simplify injecting network data into an ISO image,MERGED,2021-01-05 13:48:31.000000000,2021-01-07 15:30:35.000000000,2021-01-07 15:25:13.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-01-05 13:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c3937309bdd6dfafac2bb22d5e9f49fa36c954cb', 'message': ""Simplify injecting network data into an ISO image\n\nCurrently we're building a VFAT image with the network data just\nto unpack it back on the next step. Just pass the file directly.\nThis fixes a permission denied problem on Bifrost on Fedora\n(at least).\n\nAs a nice side effect, the change reduces the amount of IO done\nfor virtual media quite substantially.\n\nChange-Id: I5499fa42c1d82a1a29099fbbba6f45d440448b72\n(cherry picked from commit d48479b52da7ede21f26299db4bd0370bb71ec21)\n""}, {'number': 2, 'created': '2021-01-06 08:30:53.000000000', 'files': ['ironic/tests/unit/common/test_images.py', 'ironic/tests/unit/drivers/modules/test_image_utils.py', 'releasenotes/notes/vmedia-inject-files-b6e226e2db4cff06.yaml', 'ironic/common/images.py', 'ironic/drivers/modules/image_utils.py', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/401f1af79118f1f7e071a742d509710a327004bf', 'message': ""Simplify injecting network data into an ISO image\n\nCurrently we're building a VFAT image with the network data just\nto unpack it back on the next step. Just pass the file directly.\nThis fixes a permission denied problem on Bifrost on Fedora\n(at least).\n\nAs a nice side effect, the change reduces the amount of IO done\nfor virtual media quite substantially.\n\nAlso re-enable ironic-tempest-partition-uefi-redfish-vmedia\n\nChange-Id: I5499fa42c1d82a1a29099fbbba6f45d440448b72\n(cherry picked from commit d48479b52da7ede21f26299db4bd0370bb71ec21)\n""}]",0,769194,401f1af79118f1f7e071a742d509710a327004bf,15,4,2,23851,,,0,"Simplify injecting network data into an ISO image

Currently we're building a VFAT image with the network data just
to unpack it back on the next step. Just pass the file directly.
This fixes a permission denied problem on Bifrost on Fedora
(at least).

As a nice side effect, the change reduces the amount of IO done
for virtual media quite substantially.

Also re-enable ironic-tempest-partition-uefi-redfish-vmedia

Change-Id: I5499fa42c1d82a1a29099fbbba6f45d440448b72
(cherry picked from commit d48479b52da7ede21f26299db4bd0370bb71ec21)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/94/769194/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/common/test_images.py', 'ironic/tests/unit/drivers/modules/test_image_utils.py', 'releasenotes/notes/vmedia-inject-files-b6e226e2db4cff06.yaml', 'ironic/common/images.py', 'ironic/drivers/modules/image_utils.py']",5,c3937309bdd6dfafac2bb22d5e9f49fa36c954cb,vmedia-inject-files-stable/victoria," bootloader_href=None, root_uuid=None, params=None, base_iso=None, inject_files=None): :param inject_files: Mapping of local source file paths to their location on the final ISO image. boot_iso_tmp_file = boot_fileobj.name images.create_boot_iso( task.context, boot_iso_tmp_file, kernel_href, ramdisk_href, esp_image_href=bootloader_href, root_uuid=root_uuid, kernel_params=kernel_params, boot_mode=boot_mode, base_iso=base_iso, inject_files=inject_files) iso_object_name = _get_iso_image_name(task.node) image_url = img_handler.publish_image( boot_iso_tmp_file, iso_object_name) a `network_data.json` will be written into an appropriate location on the final ISO. inject_files = {} network_data = json.dumps(network_data, indent=2).encode('utf-8') inject_files[network_data] = ( 'openstack/latest/network_data.json' ) return prepare_iso_image(inject_files=inject_files)","from oslo_serialization import base64 bootloader_href=None, configdrive=None, root_uuid=None, params=None, base_iso=None): If `configdrive` is specified it will be eventually written onto the boot ISO image. :param configdrive: URL to or a compressed blob of a ISO9660 or FAT-formatted OpenStack config drive image. This image will be written onto the built ISO image. Optional. with tempfile.NamedTemporaryFile( dir=CONF.tempdir, suffix='.img') as cfgdrv_fileobj: configdrive_href = configdrive # FIXME(TheJulia): This is treated as conditional with # a base_iso as the intent, eventually, is to support # injection into the supplied image. if configdrive and not base_iso: parsed_url = urlparse.urlparse(configdrive) if not parsed_url.scheme: cfgdrv_blob = base64.decode_as_bytes(configdrive) with open(cfgdrv_fileobj.name, 'wb') as f: f.write(cfgdrv_blob) configdrive_href = urlparse.urlunparse( ('file', '', cfgdrv_fileobj.name, '', '', '')) LOG.debug(""Built configdrive out of configdrive blob "" ""for node %(node)s"", {'node': task.node.uuid}) boot_iso_tmp_file = boot_fileobj.name images.create_boot_iso( task.context, boot_iso_tmp_file, kernel_href, ramdisk_href, esp_image_href=bootloader_href, configdrive_href=configdrive_href, root_uuid=root_uuid, kernel_params=kernel_params, boot_mode=boot_mode, base_iso=base_iso) iso_object_name = _get_iso_image_name(task.node) image_url = img_handler.publish_image( boot_iso_tmp_file, iso_object_name) a new `configdrive` will be created with `network_data.json` inside, and eventually written down onto the boot ISO. with tempfile.NamedTemporaryFile(dir=CONF.tempdir, suffix='.iso') as metadata_fileobj: with open(metadata_fileobj.name, 'w') as f: json.dump(network_data, f, indent=2) files_info = { metadata_fileobj.name: 'openstack/latest/network_data.json' } with tempfile.NamedTemporaryFile( dir=CONF.tempdir, suffix='.img') as cfgdrv_fileobj: images.create_vfat_image(cfgdrv_fileobj.name, files_info) configdrive_href = urlparse.urlunparse( ('file', '', cfgdrv_fileobj.name, '', '', '')) LOG.debug(""Built configdrive %(name)s out of network data "" ""for node %(node)s"", {'name': configdrive_href, 'node': task.node.uuid}) return prepare_iso_image(configdrive=configdrive_href) return prepare_iso_image()",132,244
openstack%2Fopenstack-helm~master~I35c9f561421ffa747634976e3e48bd5e6d40983c,openstack/openstack-helm,master,I35c9f561421ffa747634976e3e48bd5e6d40983c,[HEAT] [NOVA] [CINDER] Add WSGISocketPrefix to Conf Overrides,ABANDONED,2020-10-21 22:01:55.000000000,2021-01-07 15:30:13.000000000,,"[{'_account_id': 11934}, {'_account_id': 18213}, {'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 24780}, {'_account_id': 28025}, {'_account_id': 29144}, {'_account_id': 29161}, {'_account_id': 29585}, {'_account_id': 30495}]","[{'number': 1, 'created': '2020-10-21 22:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c9bdd8fa52930824eacd6657b7dc141bb0322246', 'message': ""[WIP] [NOVA] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per documentation:\nhttps://modwsgi.readthedocs.io/en/develop/user-guides/configzuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 2, 'created': '2020-10-21 23:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2541611a3179cc77c3dd12f41bff3aeaf2bf3cfc', 'message': ""[WIP] [NOVA] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per documentation:\nhttps://modwsgi.readthedocs.io/en/develop/user-guides/configzuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 3, 'created': '2020-10-22 00:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5a5eaa53c8c2f0cf90fe0a67f3f9cbf7c9dd55ca', 'message': ""[WIP] [NOVA] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 4, 'created': '2020-10-26 20:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cdefe636d3ea0bc157a85f1b5cfe5d8997b68000', 'message': ""[WIP] [NOVA] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 5, 'created': '2020-10-29 19:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/44000635af08f272c64162d42b8679b087cecd57', 'message': ""[WIP] [NOVA] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 6, 'created': '2020-10-29 19:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4f324037f45057e4b7342bb6d0f70044ec8f85cb', 'message': ""[WIP] [NOVA] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 7, 'created': '2020-10-29 19:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/55f04dade452aa2a273d9ec121d2391b2881c29b', 'message': ""[WIP] [NOVA] [CINDER] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 8, 'created': '2020-10-29 23:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/684503036f06db8b805517a75da400c63c41dd14', 'message': ""[WIP] [NOVA] [CINDER] Add WSGISocketPrefix to Nova Conf Override\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 9, 'created': '2020-10-30 15:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bae3e9487568e3b0fe50d9ef78a1aa7898c600f3', 'message': ""[HEAT] [NOVA] [CINDER] Add WSGISocketPrefix to Conf Overrides\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}, {'number': 10, 'created': '2020-11-05 14:59:08.000000000', 'files': ['heat/values_overrides/tls.yaml', 'nova/values_overrides/tls.yaml', 'heat/Chart.yaml', 'cinder/Chart.yaml', 'cinder/values_overrides/tls.yaml', 'nova/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b6d5d71f60aea807d9b1d7dc8a2fd6ab19d8b2cc', 'message': ""[HEAT] [NOVA] [CINDER] Add WSGISocketPrefix to Conf Overrides\n\nAdding WSGISocketPrefix to resolve 503's detected from nova per doc:\nmodwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html\n\nChange-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c\n""}]",2,759148,b6d5d71f60aea807d9b1d7dc8a2fd6ab19d8b2cc,39,14,10,30495,,,0,"[HEAT] [NOVA] [CINDER] Add WSGISocketPrefix to Conf Overrides

Adding WSGISocketPrefix to resolve 503's detected from nova per doc:
modwsgi.readthedocs.io/en/develop/user-guides/configuration-issues.html

Change-Id: I35c9f561421ffa747634976e3e48bd5e6d40983c
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/48/759148/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/values_overrides/tls.yaml', 'nova/Chart.yaml']",2,c9bdd8fa52930824eacd6657b7dc141bb0322246,,version: 0.1.4,version: 0.1.3,3,1
openstack%2Fcharm-glance~master~Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3,openstack/charm-glance,master,Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3,Add Groovy to the test gate,MERGED,2020-11-05 11:46:42.000000000,2021-01-07 15:17:23.000000000,2021-01-07 15:17:23.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/789bd40ea4a0b25c2db0cf9c48790439bc6de4eb', 'message': 'Add Groovy to the test gate\n\nChange-Id: Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3\n'}, {'number': 2, 'created': '2020-11-27 16:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/e268647f6a81c960ea10728cd98a4a1907f91425', 'message': 'Add Groovy to the test gate\n\nAlso sync charm-helpers and release-tools.\n\nChange-Id: Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3\n'}, {'number': 3, 'created': '2020-12-01 10:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/d4519e77659a6b34c54d090fe02a4ae566aef803', 'message': 'Add Groovy to the test gate\n\nAlso sync charm-helpers and release-tools.\n\nChange-Id: Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3\n'}, {'number': 4, 'created': '2021-01-07 09:45:48.000000000', 'files': ['tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/3b34673d3e8388c0a90562642bb9a5ea5073f733', 'message': 'Add Groovy to the test gate\n\nChange-Id: Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3\n'}]",0,761556,3b34673d3e8388c0a90562642bb9a5ea5073f733,22,3,4,31289,,,0,"Add Groovy to the test gate

Change-Id: Ib244713fa78d4b0d8e37db2dcc16ba18ae1749a3
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/56/761556/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'test-requirements.txt']",3,789bd40ea4a0b25c2db0cf9c48790439bc6de4eb,groovy-charm-gate,,git+https://opendev.org/openstack/tempest.git#egg=tempest;python_version>='3.6' tempest;python_version<'3.6',1,4
openstack%2Fkolla-ansible~stable%2Ftrain~Ibd06726ac6edcb63a1d5d4f4148851876316dc5b,openstack/kolla-ansible,stable/train,Ibd06726ac6edcb63a1d5d4f4148851876316dc5b,CI: add missing --fail argument to curl,MERGED,2020-11-15 09:03:55.000000000,2021-01-07 15:17:16.000000000,2021-01-07 15:13:53.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-15 09:03:55.000000000', 'files': ['tools/init-runonce', 'tests/test-ironic.sh'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cf5a94767da9e43513d152a26d4ce7a2e664ac08', 'message': 'CI: add missing --fail argument to curl\n\nChange-Id: Ibd06726ac6edcb63a1d5d4f4148851876316dc5b\n(cherry picked from commit 944463107820393081989c4c17e95a7c024f6b1c)\n(cherry picked from commit 0852c7735589a6d406ff8b0301f2796f0fdbc7c7)\n'}]",0,762747,cf5a94767da9e43513d152a26d4ce7a2e664ac08,7,3,1,30491,,,0,"CI: add missing --fail argument to curl

Change-Id: Ibd06726ac6edcb63a1d5d4f4148851876316dc5b
(cherry picked from commit 944463107820393081989c4c17e95a7c024f6b1c)
(cherry picked from commit 0852c7735589a6d406ff8b0301f2796f0fdbc7c7)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/47/762747/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/init-runonce', 'tests/test-ironic.sh']",2,cf5a94767da9e43513d152a26d4ce7a2e664ac08,ci-add-fail-stable/train," curl --fail -L -o jq https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 providers=$(curl --fail -sH ""X-Auth-Token: $token"" $endpoint/resource_providers \"," curl -L -o jq https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 providers=$(curl -sH ""X-Auth-Token: $token"" $endpoint/resource_providers \",3,3
openstack%2Fcharm-keystone-ldap~master~Ibe4c4ea4d561068c318be0739607eee4ff45592e,openstack/charm-keystone-ldap,master,Ibe4c4ea4d561068c318be0739607eee4ff45592e,Add Groovy to the test gate,MERGED,2020-11-05 11:48:25.000000000,2021-01-07 15:14:29.000000000,2021-01-07 15:14:29.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-ldap/commit/f5e4251b64708896416afae70648cfce90065148', 'message': 'Add Groovy to the test gate\n\nChange-Id: Ibe4c4ea4d561068c318be0739607eee4ff45592e\n'}, {'number': 2, 'created': '2021-01-07 10:11:31.000000000', 'files': ['src/tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-keystone-ldap/commit/5d1b90c2bd0c8c84cd61da633af3e60f1e95d289', 'message': 'Add Groovy to the test gate\n\nChange-Id: Ibe4c4ea4d561068c318be0739607eee4ff45592e\n'}]",0,761563,5d1b90c2bd0c8c84cd61da633af3e60f1e95d289,12,3,2,31289,,,0,"Add Groovy to the test gate

Change-Id: Ibe4c4ea4d561068c318be0739607eee4ff45592e
",git fetch https://review.opendev.org/openstack/charm-keystone-ldap refs/changes/63/761563/1 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/tests.yaml'],1,f5e4251b64708896416afae70648cfce90065148,groovy-charm-gate, - trusty-mitaka, - trusty-mitaka dev_bundles:,1,3
openstack%2Fnova~stable%2Fussuri~Iabe37dbdc244b019cb68099739b2c1c81b94a30d,openstack/nova,stable/ussuri,Iabe37dbdc244b019cb68099739b2c1c81b94a30d,functional: Clean up PCI tests,ABANDONED,2020-12-14 05:02:32.000000000,2021-01-07 15:08:58.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-14 05:02:32.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ae80c06686b62e806b337720906e5b33691eec19', 'message': ""functional: Clean up PCI tests\n\nThese were not using the stock '_create_server' helper when they could\nbe. Correct this.\n\nChange-Id: Iabe37dbdc244b019cb68099739b2c1c81b94a30d\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 0ab8a03c782851d4019c90e6159bd1f83c0658e6)\n""}]",0,766879,ae80c06686b62e806b337720906e5b33691eec19,4,2,1,10366,,,0,"functional: Clean up PCI tests

These were not using the stock '_create_server' helper when they could
be. Correct this.

Change-Id: Iabe37dbdc244b019cb68099739b2c1c81b94a30d
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
(cherry picked from commit 0ab8a03c782851d4019c90e6159bd1f83c0658e6)
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/766879/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/libvirt/test_pci_sriov_servers.py'],1,ae80c06686b62e806b337720906e5b33691eec19,," microversion = '2.48' def setUp(self): super().setUp() def test_create_server_with_VF(self): """"""Create a server with an SR-IOV VF-type PCI device."""""" # create a server self._create_server(flavor_id=flavor_id, networks='none') # ensure the filter was called self.assertTrue(self.mock_filter.called) def test_create_server_with_PF(self): """"""Create a server with an SR-IOV PF-type PCI device."""""" host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo() fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # create a server extra_spec = {""pci_passthrough:alias"": ""%s:1"" % self.PFS_ALIAS_NAME} flavor_id = self._create_flavor(extra_spec=extra_spec) self._create_server(flavor_id=flavor_id, networks='none') # ensure the filter was called self.assertTrue(self.mock_filter.called) def test_create_server_with_PF_no_VF(self): """"""Create a server with a PF and ensure the VFs are then reserved."""""" host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo(num_pfs=1, num_vfs=4) fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # create a server using the PF extra_spec_pfs = {""pci_passthrough:alias"": f""{self.PFS_ALIAS_NAME}:1""} flavor_id_pfs = self._create_flavor(extra_spec=extra_spec_pfs) self._create_server(flavor_id=flavor_id_pfs, networks='none') # now attempt to build another server, this time using the VF; this # should fail because the VF is used by an instance extra_spec_vfs = {""pci_passthrough:alias"": f""{self.VFS_ALIAS_NAME}:1""} flavor_id_vfs = self._create_flavor(extra_spec=extra_spec_vfs) self._create_server( flavor_id=flavor_id_vfs, networks='none', expected_state='ERROR', ) def test_create_server_with_VF_no_PF(self): """"""Create a server with a VF and ensure the PF is then reserved."""""" host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo(num_pfs=1, num_vfs=4) fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # create a server using the VF extra_spec_vfs = {'pci_passthrough:alias': f'{self.VFS_ALIAS_NAME}:1'} flavor_id_vfs = self._create_flavor(extra_spec=extra_spec_vfs) self._create_server(flavor_id=flavor_id_vfs, networks='none') # now attempt to build another server, this time using the PF; this # should fail because the PF is used by an instance extra_spec_pfs = {'pci_passthrough:alias': f'{self.PFS_ALIAS_NAME}:1'} flavor_id_pfs = self._create_flavor(extra_spec=extra_spec_pfs) self._create_server( flavor_id=flavor_id_pfs, networks='none', expected_state='ERROR', ) def test_get_server_diagnostics_server_with_VF(self): """"""Ensure server disagnostics include info on VF-type PCI devices."""""" host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo() fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # create a server using the VF and multiple networks extra_spec = {'pci_passthrough:alias': f'{self.VFS_ALIAS_NAME}:1'} flavor_id = self._create_flavor(extra_spec=extra_spec) server = self._create_server( flavor_id=flavor_id, networks=[ {'uuid': base.LibvirtNeutronFixture.network_1['id']}, {'uuid': base.LibvirtNeutronFixture.network_4['id']}, ], ) # now check the server diagnostics to ensure the VF-type PCI device is # attached diagnostics = self.api.get_server_diagnostics(server['id']) self.assertEqual( base.LibvirtNeutronFixture.network_1_port_2['mac_address'], diagnostics['nic_details'][0]['mac_address'], ) self.assertEqual( base.LibvirtNeutronFixture.network_4_port_1['mac_address'], diagnostics['nic_details'][1]['mac_address'], ) microversion = 'latest' self._create_server(flavor_id=flavor_id, networks='none') extra_spec = {'hw:cpu_policy': 'dedicated'} self._create_server(flavor_id=flavor_id, networks='none') self._create_server( flavor_id=flavor_id, networks='none', expected_state='ERROR') expected_state = 'ACTIVE' self._create_server(flavor_id=flavor_id) self._create_server( flavor_id=flavor_id, expected_state=self.expected_state) expected_state = 'ERROR' self._create_server(flavor_id=flavor_id, expected_state=status) if status == 'ACTIVE': self.assertTrue(self.mock_filter.called) else: # the PciPassthroughFilter should not have been called, since the # NUMATopologyFilter should have eliminated the filter first self.assertFalse(self.mock_filter.called)"," def _run_build_test(self, flavor_id, end_status='ACTIVE'): if not self.compute_started: self.compute = self.start_service('compute', host='test_compute0') self.compute_started = True # Create server good_server = self._build_server(flavor_id=flavor_id) post = {'server': good_server} created_server = self.api.post_server(post) LOG.debug(""created_server: %s"", created_server) self.assertTrue(created_server['id']) created_server_id = created_server['id'] # Validate that the server has been created found_server = self.api.get_server(created_server_id) self.assertEqual(created_server_id, found_server['id']) # It should also be in the all-servers list servers = self.api.get_servers() server_ids = [s['id'] for s in servers] self.assertIn(created_server_id, server_ids) # Validate that PciPassthroughFilter has been called self.assertTrue(self.mock_filter.called) found_server = self._wait_for_state_change(found_server, end_status) self.addCleanup(self._delete_server, found_server) return created_server def test_create_server_with_VF(self): host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo() fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # Create a flavor extra_spec = {""pci_passthrough:alias"": ""%s:1"" % self.VFS_ALIAS_NAME} flavor_id = self._create_flavor(extra_spec=extra_spec) self._run_build_test(flavor_id) def test_create_server_with_PF(self): host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo() fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # Create a flavor extra_spec = {""pci_passthrough:alias"": ""%s:1"" % self.PFS_ALIAS_NAME} flavor_id = self._create_flavor(extra_spec=extra_spec) self._run_build_test(flavor_id) def test_create_server_with_PF_no_VF(self): host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo(num_pfs=1, num_vfs=4) fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # Create a flavor extra_spec_pfs = {""pci_passthrough:alias"": ""%s:1"" % self.PFS_ALIAS_NAME} extra_spec_vfs = {""pci_passthrough:alias"": ""%s:1"" % self.VFS_ALIAS_NAME} flavor_id_pfs = self._create_flavor(extra_spec=extra_spec_pfs) flavor_id_vfs = self._create_flavor(extra_spec=extra_spec_vfs) self._run_build_test(flavor_id_pfs) self._run_build_test(flavor_id_vfs, end_status='ERROR') def test_create_server_with_VF_no_PF(self): host_info = fakelibvirt.HostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000) pci_info = fakelibvirt.HostPCIDevicesInfo(num_pfs=1, num_vfs=4) fake_connection = self._get_connection(host_info, pci_info) self.mock_conn.return_value = fake_connection # Create a flavor extra_spec_pfs = {""pci_passthrough:alias"": ""%s:1"" % self.PFS_ALIAS_NAME} extra_spec_vfs = {""pci_passthrough:alias"": ""%s:1"" % self.VFS_ALIAS_NAME} flavor_id_pfs = self._create_flavor(extra_spec=extra_spec_pfs) flavor_id_vfs = self._create_flavor(extra_spec=extra_spec_vfs) self._run_build_test(flavor_id_vfs) self._run_build_test(flavor_id_pfs, end_status='ERROR') class GetServerDiagnosticsServerWithVfTestV21(_PCIServersTestBase): api_major_version = 'v2.1' microversion = '2.48' image_ref_parameter = 'imageRef' VFS_ALIAS_NAME = 'vfs' PCI_PASSTHROUGH_WHITELIST = [jsonutils.dumps(x) for x in ( { 'vendor_id': fakelibvirt.PCI_VEND_ID, 'product_id': fakelibvirt.VF_PROD_ID, }, )] PCI_ALIAS = [jsonutils.dumps(x) for x in ( { 'vendor_id': fakelibvirt.PCI_VEND_ID, 'product_id': fakelibvirt.VF_PROD_ID, 'name': VFS_ALIAS_NAME, }, )] def setUp(self): super(GetServerDiagnosticsServerWithVfTestV21, self).setUp() self.api.microversion = self.microversion def test_get_server_diagnostics_server_with_VF(self): # Create a flavor if not self.compute_started: self.compute = self.start_service('compute', host='test_compute0') self.compute_started = True # Create server good_server = self._build_server( image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6', flavor_id=flavor_id) good_server['networks'] = [ {'uuid': base.LibvirtNeutronFixture.network_1['id']}, {'uuid': base.LibvirtNeutronFixture.network_4['id']}, ] post = {'server': good_server} created_server = self.api.post_server(post) self._wait_for_state_change(created_server, 'ACTIVE') diagnostics = self.api.get_server_diagnostics(created_server['id']) self.assertEqual(base.LibvirtNeutronFixture. network_1_port_2['mac_address'], diagnostics['nic_details'][0]['mac_address']) self.assertEqual(base.LibvirtNeutronFixture. network_4_port_1['mac_address'], diagnostics['nic_details'][1]['mac_address']) self._run_build_test(flavor_id) extra_spec = { 'hw:cpu_policy': 'dedicated', } self._run_build_test(flavor_id) self._run_build_test(flavor_id, end_status='ERROR') end_status = 'ACTIVE' self._run_build_test(flavor_id) self._run_build_test(flavor_id, end_status=self.end_status) end_status = 'ERROR' # The order of the filters is required to make the assertion that the # PciPassthroughFilter is invoked in _run_build_test pass in the # numa affinity tests otherwise the NUMATopologyFilter will eliminate # all hosts before we execute the PciPassthroughFilter. ADDITIONAL_FILTERS = ['PciPassthroughFilter', 'NUMATopologyFilter'] self._run_build_test(flavor_id, end_status=status)",121,171
openstack%2Fkolla-ansible~stable%2Fussuri~I979f88162ad8a206e413b37ac7fb09bcc912e016,openstack/kolla-ansible,stable/ussuri,I979f88162ad8a206e413b37ac7fb09bcc912e016,Install gnupg before adding docker apt gpg key during pre-install,MERGED,2021-01-05 15:18:44.000000000,2021-01-07 15:00:37.000000000,2021-01-07 14:59:00.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 32761}, {'_account_id': 32860}]","[{'number': 1, 'created': '2021-01-05 15:18:44.000000000', 'files': ['ansible/roles/baremetal/tasks/pre-install.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6aa55368530316ffd393ace54c208ad33e39de43', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)\n'}]",0,769358,6aa55368530316ffd393ace54c208ad33e39de43,11,5,1,14826,,,0,"Install gnupg before adding docker apt gpg key during pre-install

Adding docker apt gpg key requires gpupg to be installed.
Task will fail on minimal Debian 10 install as gnupg absent.

Change-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016
(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/58/769358/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/baremetal/tasks/pre-install.yml'],1,6aa55368530316ffd393ace54c208ad33e39de43,, - name: Install CA certificates and gnupg packages - gnupg, - name: Install ca certs,2,1
openstack%2Fkolla-ansible~stable%2Fvictoria~I979f88162ad8a206e413b37ac7fb09bcc912e016,openstack/kolla-ansible,stable/victoria,I979f88162ad8a206e413b37ac7fb09bcc912e016,Install gnupg before adding docker apt gpg key during pre-install,MERGED,2021-01-05 15:18:30.000000000,2021-01-07 15:00:09.000000000,2021-01-07 14:58:56.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 32761}, {'_account_id': 32860}]","[{'number': 1, 'created': '2021-01-05 15:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4b9772c241b1ea384698737124ccabdf00f59b92', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)\n'}, {'number': 2, 'created': '2021-01-05 15:18:37.000000000', 'files': ['ansible/roles/baremetal/tasks/pre-install.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/25286fbf1e6968f61daada34cb8d434a2c7eb199', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)\n'}]",0,769357,25286fbf1e6968f61daada34cb8d434a2c7eb199,12,5,2,14826,,,0,"Install gnupg before adding docker apt gpg key during pre-install

Adding docker apt gpg key requires gpupg to be installed.
Task will fail on minimal Debian 10 install as gnupg absent.

Change-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016
(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/57/769357/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/baremetal/tasks/pre-install.yml'],1,4b9772c241b1ea384698737124ccabdf00f59b92,, - name: Install CA certificates and gnupg packages - gnupg, - name: Install ca certs,2,1
openstack%2Fkolla-ansible~stable%2Ftrain~I979f88162ad8a206e413b37ac7fb09bcc912e016,openstack/kolla-ansible,stable/train,I979f88162ad8a206e413b37ac7fb09bcc912e016,Install gnupg before adding docker apt gpg key during pre-install,MERGED,2021-01-05 15:18:49.000000000,2021-01-07 14:51:35.000000000,2021-01-07 14:50:05.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 32761}, {'_account_id': 32860}]","[{'number': 1, 'created': '2021-01-05 15:18:49.000000000', 'files': ['ansible/roles/baremetal/tasks/pre-install.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2316dcbf5608267f82632d73695b1555f12ba45a', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)\n'}]",0,769359,2316dcbf5608267f82632d73695b1555f12ba45a,10,5,1,14826,,,0,"Install gnupg before adding docker apt gpg key during pre-install

Adding docker apt gpg key requires gpupg to be installed.
Task will fail on minimal Debian 10 install as gnupg absent.

Change-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016
(cherry picked from commit 027b8d244c4c58d98dfadf2933ab5e1c7e43b869)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/59/769359/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/baremetal/tasks/pre-install.yml'],1,2316dcbf5608267f82632d73695b1555f12ba45a,, - name: Install CA certificates and gnupg packages - gnupg, - name: Install ca certs,2,1
openstack%2Fopenstacksdk~master~I8665650e578730d4fa6d77ffc26a14caa23ada4a,openstack/openstacksdk,master,I8665650e578730d4fa6d77ffc26a14caa23ada4a,Add use of flake8-bugbear,ABANDONED,2020-06-25 14:20:10.000000000,2021-01-07 14:51:34.000000000,,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-06-25 14:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/03a9c0c6ee341369a209f45abd007eecb3edf024', 'message': ""Add use of flake8-bugbear\n\nRan this on a whim, and darned if it didn't find a few actual\nissues.\n\nChange-Id: I8665650e578730d4fa6d77ffc26a14caa23ada4a\n""}, {'number': 2, 'created': '2020-06-26 22:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/19b0799b218f3256f8b80e2c922d5a1ae4bf6161', 'message': ""Add use of flake8-bugbear\n\nRan this on a whim, and darned if it didn't find a few actual\nissues.\n\nChange-Id: I8665650e578730d4fa6d77ffc26a14caa23ada4a\n""}, {'number': 3, 'created': '2020-06-27 15:11:01.000000000', 'files': ['openstack/tests/unit/cloud/test_caching.py', 'openstack/tests/functional/cloud/test_compute.py', 'openstack/image/v2/_proxy.py', 'openstack/tests/unit/cloud/test_baremetal_node.py', 'openstack/cloud/cmd/inventory.py', 'openstack/cloud/_identity.py', 'openstack/resource.py', 'openstack/config/cloud_region.py', 'openstack/tests/fakes.py', 'openstack/baremetal/v1/_proxy.py', 'openstack/tests/unit/test_stats.py', 'openstack/cloud/_clustering.py', 'openstack/tests/unit/cloud/test_shade.py', 'openstack/tests/unit/cloud/test_volume.py', 'openstack/cloud/_baremetal.py', 'openstack/cloud/_image.py', 'openstack/orchestration/util/template_utils.py', 'openstack/cloud/_block_storage.py', 'openstack/tests/unit/test_connection.py', 'openstack/config/loader.py', 'openstack/tests/unit/test_resource.py', 'openstack/load_balancer/v2/_proxy.py', 'openstack/tests/functional/cloud/test_volume.py', 'openstack/tests/unit/test_utils.py', 'openstack/baremetal/v1/allocation.py', 'openstack/cloud/_compute.py', 'tox.ini', 'openstack/baremetal/v1/node.py', 'openstack/baremetal_introspection/v1/introspection.py', 'openstack/cloud/_floating_ip.py', 'openstack/cloud/meta.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/42d202493fec2a89df88c260ca02ea693db72b11', 'message': ""Add use of flake8-bugbear\n\nRan this on a whim, and darned if it didn't find a few actual\nissues.\n\nChange-Id: I8665650e578730d4fa6d77ffc26a14caa23ada4a\n""}]",6,738041,42d202493fec2a89df88c260ca02ea693db72b11,14,3,3,2,,,0,"Add use of flake8-bugbear

Ran this on a whim, and darned if it didn't find a few actual
issues.

Change-Id: I8665650e578730d4fa6d77ffc26a14caa23ada4a
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/41/738041/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/cloud/test_caching.py', 'openstack/tests/functional/cloud/test_compute.py', 'openstack/image/v2/_proxy.py', 'openstack/tests/unit/cloud/test_baremetal_node.py', 'openstack/cloud/cmd/inventory.py', 'openstack/cloud/_identity.py', 'openstack/resource.py', 'openstack/config/cloud_region.py', 'openstack/tests/fakes.py', 'openstack/baremetal/v1/_proxy.py', 'openstack/tests/unit/test_stats.py', 'openstack/cloud/_clustering.py', 'openstack/tests/unit/cloud/test_shade.py', 'openstack/tests/unit/cloud/test_volume.py', 'openstack/cloud/_baremetal.py', 'openstack/cloud/_image.py', 'openstack/orchestration/util/template_utils.py', 'openstack/cloud/_block_storage.py', 'openstack/tests/unit/test_connection.py', 'openstack/config/loader.py', 'openstack/tests/unit/test_resource.py', 'openstack/load_balancer/v2/_proxy.py', 'openstack/tests/functional/cloud/test_volume.py', 'openstack/tests/unit/test_utils.py', 'openstack/baremetal/v1/allocation.py', 'openstack/cloud/_compute.py', 'tox.ini', 'openstack/baremetal/v1/node.py', 'openstack/baremetal_introspection/v1/introspection.py', 'openstack/cloud/_floating_ip.py', 'openstack/cloud/meta.py']",31,03a9c0c6ee341369a209f45abd007eecb3edf024,use-bugbear, for _ in utils.iterate_timeout(, for count in utils.iterate_timeout(,70,59
openstack%2Fopenstacksdk~master~Ic2ee2f8425f0b0f6350395378eb56a6c57047ac9,openstack/openstacksdk,master,Ic2ee2f8425f0b0f6350395378eb56a6c57047ac9,Sort imports with isort,ABANDONED,2020-06-26 22:08:33.000000000,2021-01-07 14:51:10.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-06-26 22:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ba7c51dfd7dc63f8f957a6368ea7a82b02ba2ff9', 'message': ""Sort imports with isort\n\nThis is a one-time tool use - we don't need to do this\nongoing, hacking should keep us in line. The command run\nwas:\n\n  isort --multi-line=3 --trailing-comma --force-grid-wrap=0 --use-parentheses --line-width=88 -rc openstack\n\nafter isort[requirements] was installed.\n\nChange-Id: Ic2ee2f8425f0b0f6350395378eb56a6c57047ac9\n""}, {'number': 2, 'created': '2020-06-27 15:11:01.000000000', 'files': ['openstack/tests/unit/config/test_from_session.py', 'openstack/image/v2/_proxy.py', 'openstack/tests/unit/cloud/test_server_group.py', 'openstack/tests/unit/test_exceptions.py', 'openstack/tests/unit/load_balancer/test_l7rule.py', 'openstack/tests/unit/accelerator/v2/test_accelerator_request.py', 'openstack/tests/unit/clustering/v1/test_policy.py', 'openstack/tests/unit/block_storage/v2/test_backup.py', 'openstack/baremetal/v1/chassis.py', 'openstack/block_storage/v2/volume.py', 'openstack/orchestration/v1/stack.py', 'openstack/tests/unit/identity/v3/test_project.py', 'openstack/clustering/v1/node.py', 'openstack/tests/unit/network/v2/test_pool.py', 'openstack/block_storage/v2/_proxy.py', 'openstack/tests/unit/config/test_from_conf.py', 'openstack/tests/unit/compute/v2/test_server_diagnostics.py', 'openstack/baremetal/v1/_common.py', 'openstack/tests/unit/compute/v2/test_limits.py', 'openstack/tests/unit/test_connection.py', 'openstack/tests/unit/baremetal_introspection/v1/test_proxy.py', 'openstack/tests/unit/message/test_version.py', 'openstack/tests/unit/test_missing_version.py', 'openstack/tests/unit/config/test_config.py', 'openstack/tests/unit/compute/v2/test_server_interface.py', 'openstack/image/v2/image.py', 'openstack/tests/unit/network/v2/test_quota.py', 'openstack/tests/functional/examples/test_network.py', 'openstack/tests/unit/image/v1/test_proxy.py', 'openstack/tests/unit/network/v2/test_load_balancer.py', 'openstack/proxy.py', 'openstack/tests/unit/cloud/test_network.py', 'openstack/tests/unit/database/v1/test_proxy.py', 'openstack/tests/unit/network/v2/test_subnet_pool.py', 'openstack/tests/unit/network/v2/test_port_forwarding.py', 'openstack/tests/unit/identity/v3/test_role_assignment.py', 'openstack/network/v2/network.py', 'openstack/tests/unit/cloud/test_subnet.py', 'openstack/tests/unit/load_balancer/test_flavor_profile.py', 'openstack/identity/v2/_proxy.py', 'openstack/tests/functional/cloud/test_clustering.py', 'openstack/tests/unit/message/v2/test_subscription.py', 'openstack/tests/unit/network/v2/test_address_scope.py', 'openstack/tests/unit/identity/v3/test_credential.py', 'openstack/tests/unit/network/v2/test_qos_rule_type.py', 'openstack/tests/unit/database/v1/test_database.py', 'openstack/tests/functional/examples/test_identity.py', 'openstack/baremetal/v1/node.py', 'openstack/cloud/_security_group.py', 'openstack/cloud/_network.py', 'openstack/tests/unit/dns/v2/test_recordset.py', 'openstack/database/v1/instance.py', 'openstack/tests/unit/compute/v2/test_metadata.py', 'openstack/tests/unit/network/v2/test_subnet.py', 'openstack/object_store/v1/container.py', 'openstack/tests/unit/object_store/v1/test_proxy.py', 'openstack/tests/unit/cloud/test_object.py', 'openstack/tests/unit/identity/v3/test_policy.py', 'openstack/tests/unit/identity/v3/test_service.py', 'openstack/tests/unit/network/v2/test_health_monitor.py', 'openstack/orchestration/orchestration_service.py', 'openstack/tests/unit/clustering/v1/test_cluster_attr.py', 'openstack/block_storage/v2/backup.py', 'openstack/tests/unit/network/v2/test_security_group.py', 'openstack/tests/unit/cloud/test_fwaas.py', 'openstack/tests/unit/baremetal/v1/test_allocation.py', 'openstack/tests/functional/cloud/test_inventory.py', 'openstack/instance_ha/instance_ha_service.py', 'openstack/tests/unit/network/v2/test_agent.py', 'openstack/tests/unit/message/v2/test_claim.py', 'openstack/cloud/_network_common.py', 'openstack/object_store/v1/_base.py', 'openstack/network/v2/floating_ip.py', 'openstack/tests/unit/network/v2/test_service_profile.py', 'openstack/image/_base_proxy.py', 'openstack/tests/unit/compute/v2/test_image.py', 'openstack/tests/unit/network/v2/test_service_provider.py', 'openstack/clustering/v1/profile_type.py', 'openstack/tests/unit/identity/v3/test_role_project_user_assignment.py', 'openstack/tests/unit/identity/test_version.py', 'openstack/tests/functional/cloud/test_cluster_templates.py', 'openstack/tests/unit/clustering/test_version.py', 'openstack/network/v2/vpn_service.py', 'openstack/tests/unit/baremetal/test_version.py', 'openstack/tests/functional/network/v2/test_router_add_remove_interface.py', 'openstack/tests/unit/image/v2/test_task.py', 'openstack/tests/unit/load_balancer/test_quota.py', 'openstack/network/v2/_proxy.py', 'openstack/tests/unit/orchestration/test_version.py', 'openstack/tests/unit/load_balancer/test_health_monitor.py', 'openstack/database/v1/user.py', 'openstack/tests/unit/image/v2/test_image.py', 'openstack/object_store/v1/obj.py', 'openstack/key_manager/v1/secret.py', 'openstack/tests/unit/clustering/v1/test_receiver.py', 'openstack/tests/unit/workflow/test_version.py', 'openstack/load_balancer/v2/_proxy.py', 'openstack/tests/functional/cloud/test_volume.py', 'openstack/key_manager/key_manager_service.py', 'openstack/baremetal/v1/allocation.py', 'openstack/tests/unit/load_balancer/test_amphora.py', 'openstack/tests/functional/network/v2/test_segment.py', 'openstack/tests/unit/dns/v2/test_floating_ip.py', 'openstack/block_storage/block_storage_service.py', 'openstack/tests/unit/cloud/test_server_console.py', 'openstack/tests/unit/cloud/test_endpoints.py', 'openstack/accelerator/v2/deployable.py', 'openstack/tests/unit/cloud/test_cluster_templates.py', 'openstack/identity/v2/role.py', 'openstack/tests/unit/identity/v3/test_registered_limit.py', 'openstack/key_manager/v1/order.py', 'openstack/tests/unit/load_balancer/test_listener.py', 'openstack/tests/unit/baremetal/v1/test_chassis.py', 'openstack/cloud/_image.py', 'openstack/image/v1/image.py', 'openstack/tests/unit/network/v2/test_pool_member.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/tests/unit/clustering/v1/test_action.py', 'openstack/tests/functional/network/v2/test_floating_ip.py', 'openstack/tests/unit/clustering/v1/test_profile_type.py', 'openstack/tests/unit/network/v2/test_network_ip_availability.py', 'openstack/database/v1/_proxy.py', 'openstack/tests/functional/network/v2/test_trunk.py', 'openstack/cloud/cmd/inventory.py', 'openstack/tests/unit/workflow/test_workflow.py', 'openstack/cloud/_identity.py', 'openstack/tests/unit/block_storage/v2/test_volume.py', 'openstack/tests/unit/workflow/test_execution.py', 'openstack/cloud/_normalize.py', 'openstack/tests/unit/clustering/v1/test_profile.py', 'openstack/tests/unit/compute/v2/test_server.py', 'openstack/baremetal_introspection/v1/_proxy.py', 'openstack/tests/unit/dns/v2/test_proxy.py', 'openstack/cloud/inventory.py', 'openstack/tests/unit/load_balancer/test_availability_zone.py', 'openstack/service_description.py', 'openstack/tests/unit/baremetal/v1/test_port.py', 'openstack/tests/unit/workflow/test_proxy.py', 'openstack/cloud/_block_storage.py', 'openstack/message/message_service.py', 'openstack/tests/functional/network/v2/test_firewall_rule_insert_remove_policy.py', 'openstack/tests/unit/network/v2/test_flavor.py', 'openstack/tests/unit/accelerator/v2/test_deployable.py', 'openstack/cloud/_utils.py', 'openstack/tests/unit/cloud/test_recordset.py', 'openstack/tests/unit/identity/v3/test_application_credential.py', 'openstack/tests/unit/compute/v2/test_availability_zone.py', 'openstack/tests/unit/network/v2/test_network_segment_range.py', 'openstack/tests/unit/identity/v3/test_user.py', 'openstack/tests/unit/baremetal/v1/test_node.py', 'openstack/tests/unit/image/v2/test_member.py', 'openstack/clustering/v1/_proxy.py', 'openstack/block_storage/_base_proxy.py', 'openstack/tests/functional/network/v2/test_security_group_rule.py', 'openstack/tests/functional/network/v2/test_port_forwarding.py', 'openstack/tests/unit/network/v2/test_extension.py', 'openstack/cloud/openstackcloud.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'openstack/tests/unit/message/v2/test_proxy.py', 'openstack/tests/unit/network/v2/test_listener.py', 'openstack/block_storage/v3/snapshot.py', 'openstack/tests/unit/compute/v2/test_server_ip.py', 'openstack/tests/unit/cloud/test_security_groups.py', 'openstack/tests/unit/cloud/test_services.py', 'openstack/tests/unit/identity/v2/test_tenant.py', 'openstack/tests/unit/cloud/test_floating_ip_pool.py', 'openstack/tests/unit/network/v2/test_metering_label.py', 'openstack/tests/unit/network/test_version.py', 'openstack/tests/unit/clustering/v1/test_event.py', 'openstack/accelerator/v2/accelerator_request.py', 'openstack/tests/unit/network/v2/test_router.py', 'openstack/tests/unit/cloud/test__utils.py', 'openstack/tests/unit/image/v2/test_service_info.py', 'openstack/block_storage/v3/backup.py', 'openstack/compute/v2/image.py', 'openstack/tests/functional/network/v2/test_rbac_policy.py', 'openstack/tests/unit/cloud/test_caching.py', 'openstack/instance_ha/v1/_proxy.py', 'openstack/tests/unit/clustering/v1/test_node.py', 'openstack/tests/unit/identity/v2/test_user.py', 'openstack/tests/unit/load_balancer/test_version.py', 'openstack/tests/unit/cloud/test_inventory.py', 'openstack/tests/unit/cloud/test_baremetal_node.py', 'openstack/tests/functional/cloud/test_floating_ip.py', 'openstack/tests/functional/cloud/test_port.py', 'openstack/tests/unit/compute/v2/test_hypervisor.py', 'openstack/compute/v2/server_group.py', 'openstack/tests/unit/message/v2/test_queue.py', 'openstack/tests/unit/network/v2/test_network.py', 'openstack/tests/unit/network/v2/test_metering_label_rule.py', 'openstack/tests/unit/orchestration/v1/test_resource.py', 'openstack/compute/v2/server_ip.py', 'openstack/tests/unit/key_manager/v1/test_secret.py', 'openstack/tests/unit/block_storage/v3/test_volume.py', 'openstack/tests/unit/block_storage/v2/test_snapshot.py', 'openstack/tests/unit/network/v2/test_port.py', 'openstack/tests/unit/cloud/test_availability_zones.py', 'openstack/tests/unit/clustering/v1/test_proxy.py', 'openstack/tests/unit/compute/v2/test_service.py', 'openstack/dns/v2/zone.py', 'openstack/load_balancer/load_balancer_service.py', 'openstack/tests/functional/network/v2/test_subnet_from_subnet_pool.py', 'openstack/tests/unit/identity/v3/test_federation_protocol.py', 'openstack/tests/base.py', 'openstack/clustering/v1/cluster.py', 'openstack/tests/unit/identity/v3/test_region.py', 'openstack/tests/unit/test_resource.py', 'openstack/tests/unit/database/v1/test_flavor.py', 'openstack/tests/unit/block_storage/v3/test_backup.py', 'openstack/tests/unit/identity/v3/test_trust.py', 'openstack/tests/unit/identity/v2/test_proxy.py', 'openstack/config/vendors/__init__.py', 'openstack/tests/functional/cloud/test_floating_ip_pool.py', 'openstack/tests/unit/compute/v2/test_extension.py', 'openstack/tests/unit/accelerator/v2/test_device.py', 'openstack/tests/unit/orchestration/v1/test_template.py', 'openstack/dns/v2/_proxy.py', 'openstack/image/v1/_proxy.py', 'openstack/tests/unit/dns/v2/test_zone.py', 'openstack/tests/unit/cloud/test_floating_ip_neutron.py', 'openstack/tests/unit/cloud/test_shade.py', 'openstack/tests/unit/load_balancer/test_load_balancer.py', 'openstack/baremetal/v1/port.py', 'openstack/tests/unit/orchestration/v1/test_stack.py', 'openstack/tests/unit/load_balancer/test_member.py', 'openstack/tests/unit/orchestration/v1/test_software_deployment.py', 'openstack/object_store/object_store_service.py', 'openstack/tests/unit/test_format.py', 'openstack/compute/v2/aggregate.py', 'openstack/config/loader.py', 'openstack/cloud/_orchestration.py', 'openstack/dns/v2/_base.py', 'openstack/block_storage/v3/volume.py', 'openstack/block_storage/v3/_proxy.py', 'openstack/orchestration/util/utils.py', 'openstack/tests/unit/network/v2/test_qos_dscp_marking_rule.py', 'openstack/image/image_service.py', 'openstack/tests/unit/dns/v2/test_zone_transfer.py', 'openstack/tests/unit/block_storage/v3/test_snapshot.py', 'openstack/image/_download.py', 'openstack/tests/unit/block_storage/v2/test_stats.py', 'openstack/tests/unit/dns/v2/test_zone_import.py', 'openstack/tests/functional/network/v2/test_subnet.py', 'openstack/tests/unit/compute/v2/test_proxy.py', 'openstack/tests/unit/identity/v3/test_limit.py', 'openstack/tests/unit/network/v2/test_rbac_policy.py', 'openstack/tests/unit/identity/v3/test_domain.py', 'openstack/tests/unit/identity/v3/test_identity_provider.py', 'openstack/tests/unit/compute/v2/test_keypair.py', 'openstack/tests/unit/message/v2/test_message.py', 'openstack/connection.py', 'openstack/orchestration/util/template_utils.py', 'openstack/baremetal/v1/port_group.py', 'openstack/tests/unit/cloud/test_create_server.py', 'openstack/tests/unit/orchestration/v1/test_software_config.py', 'openstack/tests/unit/load_balancer/test_availability_zone_profile.py', 'openstack/tests/unit/base.py', 'openstack/tests/unit/load_balancer/test_flavor.py', 'openstack/tests/unit/cloud/test_delete_volume_snapshot.py', 'openstack/compute/v2/_proxy.py', 'openstack/tests/unit/key_manager/v1/test_order.py', 'openstack/tests/functional/cloud/test_compute.py', 'openstack/network/v2/port.py', 'openstack/tests/unit/baremetal/v1/test_driver.py', 'openstack/resource.py', 'openstack/dns/dns_service.py', 'openstack/key_manager/v1/container.py', 'openstack/clustering/v1/_async_resource.py', 'openstack/tests/unit/load_balancer/test_proxy.py', 'openstack/compute/v2/server.py', 'openstack/tests/unit/dns/v2/test_zone_export.py', 'openstack/block_storage/v2/snapshot.py', 'openstack/tests/unit/network/v2/test_qos_policy.py', 'openstack/tests/unit/identity/v3/test_proxy.py', 'openstack/tests/functional/base.py', 'openstack/tests/unit/key_manager/v1/test_container.py', 'openstack/fixture/connection.py', 'openstack/object_store/v1/_proxy.py', 'openstack/tests/unit/cloud/test_role_assignment.py', 'openstack/identity/v3/_proxy.py', 'openstack/database/database_service.py', 'openstack/key_manager/v1/_format.py', 'openstack/tests/functional/cloud/test_services.py', 'openstack/tests/unit/identity/v3/test_role_project_group_assignment.py', 'openstack/tests/unit/test_proxy.py', 'openstack/network/v2/trunk.py', 'openstack/tests/unit/orchestration/v1/test_stack_template.py', 'openstack/baremetal/v1/_proxy.py', 'openstack/network/v2/agent.py', 'openstack/tests/unit/compute/v2/test_flavor.py', 'openstack/tests/unit/cloud/test_accelerator.py', 'openstack/tests/unit/image/v1/test_image.py', 'openstack/tests/unit/config/test_environ.py', 'openstack/baremetal_introspection/v1/introspection.py', 'openstack/cloud/meta.py', 'openstack/identity/v3/project.py', 'openstack/tests/unit/network/v2/test_auto_allocated_topology.py', 'openstack/network/v2/firewall_policy.py', 'openstack/tests/unit/compute/v2/test_server_group.py', 'openstack/tests/unit/identity/v3/test_mapping.py', 'openstack/tests/functional/network/v2/test_port.py', 'openstack/accelerator/v2/_proxy.py', 'openstack/network/v2/security_group_rule.py', 'openstack/key_manager/v1/_proxy.py', 'openstack/tests/unit/config/test_cloud_config.py', 'openstack/tests/unit/cloud/test_clustering.py', 'openstack/dns/v2/recordset.py', 'openstack/cloud/_dns.py', 'openstack/tests/unit/block_storage/v2/test_type.py', 'openstack/tests/unit/load_balancer/test_provider.py', 'openstack/cloud/_clustering.py', 'openstack/compute/v2/metadata.py', 'openstack/message/v2/_proxy.py', 'openstack/object_store/v1/info.py', 'openstack/tests/unit/network/v2/test_qos_minimum_bandwidth_rule.py', 'openstack/tests/unit/cloud/test_stack.py', 'openstack/cloud/_baremetal.py', 'openstack/tests/unit/instance_ha/v1/test_proxy.py', 'openstack/utils.py', 'openstack/tests/functional/block_storage/v3/test_backup.py', 'openstack/tests/unit/database/v1/test_instance.py', 'openstack/image/image_signer.py', 'openstack/tests/unit/block_storage/v3/test_proxy.py', 'openstack/tests/unit/cloud/test_zone.py', 'openstack/tests/unit/database/v1/test_user.py', 'openstack/cloud/_compute.py', 'openstack/object_store/v1/account.py', 'openstack/tests/functional/block_storage/v2/test_backup.py', 'openstack/tests/unit/network/v2/test_qos_bandwidth_limit_rule.py', 'openstack/identity/identity_service.py', 'openstack/tests/unit/load_balancer/test_pool.py', 'openstack/dns/v2/zone_transfer.py', 'openstack/orchestration/util/environment_format.py', 'openstack/tests/unit/identity/v3/test_role_domain_user_assignment.py', 'openstack/network/network_service.py', 'openstack/cloud/_object_store.py', 'openstack/tests/functional/cloud/test_router.py', 'openstack/tests/unit/accelerator/v2/test_device_profile.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/tests/unit/network/v2/test_vpn_service.py', 'openstack/tests/unit/accelerator/v2/test_proxy.py', 'openstack/tests/functional/cloud/test_endpoints.py', 'openstack/tests/unit/compute/v2/test_volume_attachment.py', 'openstack/tests/fakes.py', 'openstack/tests/unit/test_stats.py', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/tests/unit/clustering/v1/test_cluster.py', 'openstack/tests/unit/baremetal/v1/test_proxy.py', 'openstack/compute/v2/service.py', 'openstack/tests/unit/compute/test_version.py', 'openstack/dns/v2/zone_export.py', 'openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/tests/unit/cloud/test_aggregate.py', 'openstack/network/v2/flavor.py', 'openstack/network/v2/security_group.py', 'openstack/tests/functional/network/v2/test_network_ip_availability.py', 'openstack/tests/unit/load_balancer/test_l7policy.py', 'openstack/tests/functional/identity/v3/test_application_credential.py', 'openstack/tests/unit/cloud/test_router.py', 'openstack/tests/unit/identity/v2/test_role.py', 'openstack/network/v2/subnet.py', 'openstack/__init__.py', 'openstack/tests/functional/examples/test_image.py', 'openstack/tests/unit/network/v2/test_segment.py', 'openstack/tests/unit/cloud/test_image.py', 'openstack/tests/unit/identity/v2/test_extension.py', 'openstack/dns/v2/zone_import.py', 'openstack/tests/functional/examples/test_compute.py', 'openstack/tests/unit/key_manager/v1/test_proxy.py', 'openstack/tests/unit/clustering/v1/test_service.py', 'openstack/tests/unit/test_utils.py', 'openstack/tests/unit/clustering/v1/test_policy_type.py', 'tox.ini', 'openstack/cloud/_floating_ip.py', 'openstack/cloud/_coe.py', 'openstack/tests/unit/network/v2/test_availability_zone.py', 'openstack/orchestration/util/template_format.py', 'openstack/tests/unit/network/v2/test_security_group_rule.py', 'openstack/tests/unit/identity/v3/test_endpoint.py', 'openstack/dns/v2/floating_ip.py', 'openstack/tests/unit/block_storage/v2/test_proxy.py', 'openstack/tests/unit/orchestration/v1/test_stack_files.py', 'openstack/tests/unit/compute/v2/test_aggregate.py', 'openstack/network/v2/router.py', 'openstack/tests/unit/baremetal/v1/test_port_group.py', 'openstack/tests/functional/cloud/test_volume_type.py', 'openstack/tests/unit/identity/v3/test_group.py', 'openstack/tests/unit/cloud/test_identity_roles.py', 'openstack/tests/unit/identity/v3/test_role_domain_group_assignment.py', 'openstack/tests/unit/identity/v3/test_role.py', 'openstack/clustering/clustering_service.py', 'openstack/tests/unit/block_storage/v3/test_type.py', 'openstack/tests/unit/network/v2/test_firewall_policy.py', 'openstack/tests/unit/cloud/test_magnum_services.py', 'openstack/config/cloud_region.py', 'openstack/tests/unit/clustering/v1/test_cluster_policy.py', 'openstack/tests/unit/orchestration/v1/test_stack_environment.py', 'openstack/tests/unit/accelerator/test_version.py', 'openstack/network/v2/qos_policy.py', 'openstack/tests/unit/image/v2/test_schema.py', 'openstack/identity/v3/domain.py', 'openstack/tests/unit/cloud/test_create_volume_snapshot.py', 'openstack/tests/unit/object_store/v1/test_account.py', 'openstack/tests/unit/clustering/v1/test_build_info.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eca37a2396d022e8bb4a3dc06bd606d9e7b42dbc', 'message': ""Sort imports with isort\n\nThis is a one-time tool use - we don't need to do this\nongoing, hacking should keep us in line. The command run\nwas:\n\n  isort --multi-line=3 --trailing-comma --force-grid-wrap=0 --use-parentheses --line-width=88 -rc openstack\n\nafter isort[requirements] was installed.\n\nChange-Id: Ic2ee2f8425f0b0f6350395378eb56a6c57047ac9\n""}]",0,738287,eca37a2396d022e8bb4a3dc06bd606d9e7b42dbc,7,1,2,2,,,0,"Sort imports with isort

This is a one-time tool use - we don't need to do this
ongoing, hacking should keep us in line. The command run
was:

  isort --multi-line=3 --trailing-comma --force-grid-wrap=0 --use-parentheses --line-width=88 -rc openstack

after isort[requirements] was installed.

Change-Id: Ic2ee2f8425f0b0f6350395378eb56a6c57047ac9
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/87/738287/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/config/test_from_session.py', 'openstack/image/v2/_proxy.py', 'openstack/tests/unit/cloud/test_server_group.py', 'openstack/tests/unit/test_exceptions.py', 'openstack/tests/unit/load_balancer/test_l7rule.py', 'openstack/tests/unit/accelerator/v2/test_accelerator_request.py', 'openstack/tests/unit/clustering/v1/test_policy.py', 'openstack/tests/unit/block_storage/v2/test_backup.py', 'openstack/baremetal/v1/chassis.py', 'openstack/block_storage/v2/volume.py', 'openstack/orchestration/v1/stack.py', 'openstack/tests/unit/identity/v3/test_project.py', 'openstack/clustering/v1/node.py', 'openstack/tests/unit/network/v2/test_pool.py', 'openstack/block_storage/v2/_proxy.py', 'openstack/tests/unit/config/test_from_conf.py', 'openstack/tests/unit/compute/v2/test_server_diagnostics.py', 'openstack/baremetal/v1/_common.py', 'openstack/tests/unit/compute/v2/test_limits.py', 'openstack/tests/unit/test_connection.py', 'openstack/tests/unit/baremetal_introspection/v1/test_proxy.py', 'openstack/tests/unit/message/test_version.py', 'openstack/tests/unit/test_missing_version.py', 'openstack/tests/unit/config/test_config.py', 'openstack/tests/unit/compute/v2/test_server_interface.py', 'openstack/image/v2/image.py', 'openstack/tests/unit/network/v2/test_quota.py', 'openstack/tests/functional/examples/test_network.py', 'openstack/tests/unit/image/v1/test_proxy.py', 'openstack/tests/unit/network/v2/test_load_balancer.py', 'openstack/proxy.py', 'openstack/tests/unit/cloud/test_network.py', 'openstack/tests/unit/database/v1/test_proxy.py', 'openstack/tests/unit/network/v2/test_subnet_pool.py', 'openstack/tests/unit/network/v2/test_port_forwarding.py', 'openstack/tests/unit/identity/v3/test_role_assignment.py', 'openstack/network/v2/network.py', 'openstack/tests/unit/cloud/test_subnet.py', 'openstack/tests/unit/load_balancer/test_flavor_profile.py', 'openstack/identity/v2/_proxy.py', 'openstack/tests/functional/cloud/test_clustering.py', 'openstack/tests/unit/message/v2/test_subscription.py', 'openstack/tests/unit/network/v2/test_address_scope.py', 'openstack/tests/unit/identity/v3/test_credential.py', 'openstack/tests/unit/network/v2/test_qos_rule_type.py', 'openstack/tests/unit/database/v1/test_database.py', 'openstack/tests/functional/examples/test_identity.py', 'openstack/baremetal/v1/node.py', 'openstack/cloud/_security_group.py', 'openstack/cloud/_network.py', 'openstack/tests/unit/dns/v2/test_recordset.py', 'openstack/database/v1/instance.py', 'openstack/tests/unit/compute/v2/test_metadata.py', 'openstack/tests/unit/network/v2/test_subnet.py', 'openstack/object_store/v1/container.py', 'openstack/tests/unit/object_store/v1/test_proxy.py', 'openstack/tests/unit/cloud/test_object.py', 'openstack/tests/unit/identity/v3/test_policy.py', 'openstack/tests/unit/identity/v3/test_service.py', 'openstack/tests/unit/network/v2/test_health_monitor.py', 'openstack/orchestration/orchestration_service.py', 'openstack/tests/unit/clustering/v1/test_cluster_attr.py', 'openstack/block_storage/v2/backup.py', 'openstack/tests/unit/network/v2/test_security_group.py', 'openstack/tests/unit/cloud/test_fwaas.py', 'openstack/tests/unit/baremetal/v1/test_allocation.py', 'openstack/tests/functional/cloud/test_inventory.py', 'openstack/instance_ha/instance_ha_service.py', 'openstack/tests/unit/network/v2/test_agent.py', 'openstack/tests/unit/message/v2/test_claim.py', 'openstack/cloud/_network_common.py', 'openstack/object_store/v1/_base.py', 'openstack/network/v2/floating_ip.py', 'openstack/tests/unit/network/v2/test_service_profile.py', 'openstack/image/_base_proxy.py', 'openstack/tests/unit/compute/v2/test_image.py', 'openstack/tests/unit/network/v2/test_service_provider.py', 'openstack/clustering/v1/profile_type.py', 'openstack/tests/unit/identity/v3/test_role_project_user_assignment.py', 'openstack/tests/unit/identity/test_version.py', 'openstack/tests/functional/cloud/test_cluster_templates.py', 'openstack/tests/unit/clustering/test_version.py', 'openstack/network/v2/vpn_service.py', 'openstack/tests/unit/baremetal/test_version.py', 'openstack/tests/functional/network/v2/test_router_add_remove_interface.py', 'openstack/tests/unit/image/v2/test_task.py', 'openstack/tests/unit/load_balancer/test_quota.py', 'openstack/network/v2/_proxy.py', 'openstack/tests/unit/orchestration/test_version.py', 'openstack/tests/unit/load_balancer/test_health_monitor.py', 'openstack/database/v1/user.py', 'openstack/tests/unit/image/v2/test_image.py', 'openstack/object_store/v1/obj.py', 'openstack/key_manager/v1/secret.py', 'openstack/tests/unit/clustering/v1/test_receiver.py', 'openstack/tests/unit/workflow/test_version.py', 'openstack/load_balancer/v2/_proxy.py', 'openstack/tests/functional/cloud/test_volume.py', 'openstack/key_manager/key_manager_service.py', 'openstack/baremetal/v1/allocation.py', 'openstack/tests/unit/load_balancer/test_amphora.py', 'openstack/tests/functional/network/v2/test_segment.py', 'openstack/tests/unit/dns/v2/test_floating_ip.py', 'openstack/block_storage/block_storage_service.py', 'openstack/tests/unit/cloud/test_server_console.py', 'openstack/tests/unit/cloud/test_endpoints.py', 'openstack/accelerator/v2/deployable.py', 'openstack/tests/unit/cloud/test_cluster_templates.py', 'openstack/identity/v2/role.py', 'openstack/tests/unit/identity/v3/test_registered_limit.py', 'openstack/key_manager/v1/order.py', 'openstack/tests/unit/load_balancer/test_listener.py', 'openstack/tests/unit/baremetal/v1/test_chassis.py', 'openstack/cloud/_image.py', 'openstack/image/v1/image.py', 'openstack/tests/unit/network/v2/test_pool_member.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/tests/unit/clustering/v1/test_action.py', 'openstack/tests/functional/network/v2/test_floating_ip.py', 'openstack/tests/unit/clustering/v1/test_profile_type.py', 'openstack/tests/unit/network/v2/test_network_ip_availability.py', 'openstack/database/v1/_proxy.py', 'openstack/tests/functional/network/v2/test_trunk.py', 'openstack/cloud/cmd/inventory.py', 'openstack/tests/unit/workflow/test_workflow.py', 'openstack/cloud/_identity.py', 'openstack/tests/unit/block_storage/v2/test_volume.py', 'openstack/tests/unit/workflow/test_execution.py', 'openstack/cloud/_normalize.py', 'openstack/tests/unit/clustering/v1/test_profile.py', 'openstack/tests/unit/compute/v2/test_server.py', 'openstack/baremetal_introspection/v1/_proxy.py', 'openstack/tests/unit/dns/v2/test_proxy.py', 'openstack/cloud/inventory.py', 'openstack/tests/unit/load_balancer/test_availability_zone.py', 'openstack/service_description.py', 'openstack/tests/unit/baremetal/v1/test_port.py', 'openstack/tests/unit/workflow/test_proxy.py', 'openstack/cloud/_block_storage.py', 'openstack/message/message_service.py', 'openstack/tests/functional/network/v2/test_firewall_rule_insert_remove_policy.py', 'openstack/tests/unit/network/v2/test_flavor.py', 'openstack/tests/unit/accelerator/v2/test_deployable.py', 'openstack/cloud/_utils.py', 'openstack/tests/unit/cloud/test_recordset.py', 'openstack/tests/unit/identity/v3/test_application_credential.py', 'openstack/tests/unit/compute/v2/test_availability_zone.py', 'openstack/tests/unit/network/v2/test_network_segment_range.py', 'openstack/tests/unit/identity/v3/test_user.py', 'openstack/tests/unit/baremetal/v1/test_node.py', 'openstack/tests/unit/image/v2/test_member.py', 'openstack/clustering/v1/_proxy.py', 'openstack/block_storage/_base_proxy.py', 'openstack/tests/functional/network/v2/test_security_group_rule.py', 'openstack/tests/functional/network/v2/test_port_forwarding.py', 'openstack/tests/unit/network/v2/test_extension.py', 'openstack/cloud/openstackcloud.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'openstack/tests/unit/message/v2/test_proxy.py', 'openstack/tests/unit/network/v2/test_listener.py', 'openstack/block_storage/v3/snapshot.py', 'openstack/tests/unit/compute/v2/test_server_ip.py', 'openstack/tests/unit/cloud/test_security_groups.py', 'openstack/tests/unit/cloud/test_services.py', 'openstack/tests/unit/identity/v2/test_tenant.py', 'openstack/tests/unit/cloud/test_floating_ip_pool.py', 'openstack/tests/unit/network/v2/test_metering_label.py', 'openstack/tests/unit/network/test_version.py', 'openstack/tests/unit/clustering/v1/test_event.py', 'openstack/accelerator/v2/accelerator_request.py', 'openstack/tests/unit/network/v2/test_router.py', 'openstack/tests/unit/cloud/test__utils.py', 'openstack/tests/unit/image/v2/test_service_info.py', 'openstack/block_storage/v3/backup.py', 'openstack/compute/v2/image.py', 'openstack/tests/functional/network/v2/test_rbac_policy.py', 'openstack/tests/unit/cloud/test_caching.py', 'openstack/instance_ha/v1/_proxy.py', 'openstack/tests/unit/clustering/v1/test_node.py', 'openstack/tests/unit/identity/v2/test_user.py', 'openstack/tests/unit/load_balancer/test_version.py', 'openstack/tests/unit/cloud/test_inventory.py', 'openstack/tests/unit/cloud/test_baremetal_node.py', 'openstack/tests/functional/cloud/test_floating_ip.py', 'openstack/tests/functional/cloud/test_port.py', 'openstack/tests/unit/compute/v2/test_hypervisor.py', 'openstack/compute/v2/server_group.py', 'openstack/tests/unit/message/v2/test_queue.py', 'openstack/tests/unit/network/v2/test_network.py', 'openstack/tests/unit/network/v2/test_metering_label_rule.py', 'openstack/tests/unit/orchestration/v1/test_resource.py', 'openstack/compute/v2/server_ip.py', 'openstack/tests/unit/key_manager/v1/test_secret.py', 'openstack/tests/unit/block_storage/v3/test_volume.py', 'openstack/tests/unit/block_storage/v2/test_snapshot.py', 'openstack/tests/unit/network/v2/test_port.py', 'openstack/tests/unit/cloud/test_availability_zones.py', 'openstack/tests/unit/clustering/v1/test_proxy.py', 'openstack/tests/unit/compute/v2/test_service.py', 'openstack/dns/v2/zone.py', 'openstack/load_balancer/load_balancer_service.py', 'openstack/tests/functional/network/v2/test_subnet_from_subnet_pool.py', 'openstack/tests/unit/identity/v3/test_federation_protocol.py', 'openstack/tests/base.py', 'openstack/clustering/v1/cluster.py', 'openstack/tests/unit/identity/v3/test_region.py', 'openstack/tests/unit/test_resource.py', 'openstack/tests/unit/database/v1/test_flavor.py', 'openstack/tests/unit/block_storage/v3/test_backup.py', 'openstack/tests/unit/identity/v3/test_trust.py', 'openstack/tests/unit/identity/v2/test_proxy.py', 'openstack/config/vendors/__init__.py', 'openstack/tests/functional/cloud/test_floating_ip_pool.py', 'openstack/tests/unit/compute/v2/test_extension.py', 'openstack/tests/unit/accelerator/v2/test_device.py', 'openstack/tests/unit/orchestration/v1/test_template.py', 'openstack/dns/v2/_proxy.py', 'openstack/image/v1/_proxy.py', 'openstack/tests/unit/dns/v2/test_zone.py', 'openstack/tests/unit/cloud/test_floating_ip_neutron.py', 'openstack/tests/unit/cloud/test_shade.py', 'openstack/tests/unit/load_balancer/test_load_balancer.py', 'openstack/baremetal/v1/port.py', 'openstack/tests/unit/orchestration/v1/test_stack.py', 'openstack/tests/unit/load_balancer/test_member.py', 'openstack/tests/unit/orchestration/v1/test_software_deployment.py', 'openstack/object_store/object_store_service.py', 'openstack/tests/unit/test_format.py', 'openstack/compute/v2/aggregate.py', 'openstack/config/loader.py', 'openstack/cloud/_orchestration.py', 'openstack/dns/v2/_base.py', 'openstack/block_storage/v3/volume.py', 'openstack/block_storage/v3/_proxy.py', 'openstack/orchestration/util/utils.py', 'openstack/tests/unit/network/v2/test_qos_dscp_marking_rule.py', 'openstack/image/image_service.py', 'openstack/tests/unit/dns/v2/test_zone_transfer.py', 'openstack/tests/unit/block_storage/v3/test_snapshot.py', 'openstack/image/_download.py', 'openstack/tests/unit/block_storage/v2/test_stats.py', 'openstack/tests/unit/dns/v2/test_zone_import.py', 'openstack/tests/functional/network/v2/test_subnet.py', 'openstack/tests/unit/compute/v2/test_proxy.py', 'openstack/tests/unit/identity/v3/test_limit.py', 'openstack/tests/unit/network/v2/test_rbac_policy.py', 'openstack/tests/unit/identity/v3/test_domain.py', 'openstack/tests/unit/identity/v3/test_identity_provider.py', 'openstack/tests/unit/compute/v2/test_keypair.py', 'openstack/tests/unit/message/v2/test_message.py', 'openstack/connection.py', 'openstack/orchestration/util/template_utils.py', 'openstack/baremetal/v1/port_group.py', 'openstack/tests/unit/cloud/test_create_server.py', 'openstack/tests/unit/orchestration/v1/test_software_config.py', 'openstack/tests/unit/load_balancer/test_availability_zone_profile.py', 'openstack/tests/unit/base.py', 'openstack/tests/unit/load_balancer/test_flavor.py', 'openstack/tests/unit/cloud/test_delete_volume_snapshot.py', 'openstack/compute/v2/_proxy.py', 'openstack/tests/unit/key_manager/v1/test_order.py', 'openstack/tests/functional/cloud/test_compute.py', 'openstack/network/v2/port.py', 'openstack/tests/unit/baremetal/v1/test_driver.py', 'openstack/resource.py', 'openstack/dns/dns_service.py', 'openstack/key_manager/v1/container.py', 'openstack/clustering/v1/_async_resource.py', 'openstack/tests/unit/load_balancer/test_proxy.py', 'openstack/compute/v2/server.py', 'openstack/tests/unit/dns/v2/test_zone_export.py', 'openstack/block_storage/v2/snapshot.py', 'openstack/tests/unit/network/v2/test_qos_policy.py', 'openstack/tests/unit/identity/v3/test_proxy.py', 'openstack/tests/functional/base.py', 'openstack/tests/unit/key_manager/v1/test_container.py', 'openstack/fixture/connection.py', 'openstack/object_store/v1/_proxy.py', 'openstack/tests/unit/cloud/test_role_assignment.py', 'openstack/identity/v3/_proxy.py', 'openstack/database/database_service.py', 'openstack/key_manager/v1/_format.py', 'openstack/tests/functional/cloud/test_services.py', 'openstack/tests/unit/identity/v3/test_role_project_group_assignment.py', 'openstack/tests/unit/test_proxy.py', 'openstack/network/v2/trunk.py', 'openstack/tests/unit/orchestration/v1/test_stack_template.py', 'openstack/baremetal/v1/_proxy.py', 'openstack/network/v2/agent.py', 'openstack/tests/unit/compute/v2/test_flavor.py', 'openstack/tests/unit/cloud/test_accelerator.py', 'openstack/tests/unit/image/v1/test_image.py', 'openstack/tests/unit/config/test_environ.py', 'openstack/baremetal_introspection/v1/introspection.py', 'openstack/cloud/meta.py', 'openstack/identity/v3/project.py', 'openstack/tests/unit/network/v2/test_auto_allocated_topology.py', 'openstack/network/v2/firewall_policy.py', 'openstack/tests/unit/compute/v2/test_server_group.py', 'openstack/tests/unit/identity/v3/test_mapping.py', 'openstack/tests/functional/network/v2/test_port.py', 'openstack/accelerator/v2/_proxy.py', 'openstack/network/v2/security_group_rule.py', 'openstack/key_manager/v1/_proxy.py', 'openstack/tests/unit/config/test_cloud_config.py', 'openstack/tests/unit/cloud/test_clustering.py', 'openstack/dns/v2/recordset.py', 'openstack/cloud/_dns.py', 'openstack/tests/unit/block_storage/v2/test_type.py', 'openstack/tests/unit/load_balancer/test_provider.py', 'openstack/cloud/_clustering.py', 'openstack/compute/v2/metadata.py', 'openstack/message/v2/_proxy.py', 'openstack/object_store/v1/info.py', 'openstack/tests/unit/network/v2/test_qos_minimum_bandwidth_rule.py', 'openstack/tests/unit/cloud/test_stack.py', 'openstack/cloud/_baremetal.py', 'openstack/tests/unit/instance_ha/v1/test_proxy.py', 'openstack/utils.py', 'openstack/tests/functional/block_storage/v3/test_backup.py', 'openstack/tests/unit/database/v1/test_instance.py', 'openstack/image/image_signer.py', 'openstack/tests/unit/block_storage/v3/test_proxy.py', 'openstack/tests/unit/cloud/test_zone.py', 'openstack/tests/unit/database/v1/test_user.py', 'openstack/cloud/_compute.py', 'openstack/object_store/v1/account.py', 'openstack/tests/functional/block_storage/v2/test_backup.py', 'openstack/tests/unit/network/v2/test_qos_bandwidth_limit_rule.py', 'openstack/identity/identity_service.py', 'openstack/tests/unit/load_balancer/test_pool.py', 'openstack/dns/v2/zone_transfer.py', 'openstack/orchestration/util/environment_format.py', 'openstack/tests/unit/identity/v3/test_role_domain_user_assignment.py', 'openstack/network/network_service.py', 'openstack/cloud/_object_store.py', 'openstack/tests/functional/cloud/test_router.py', 'openstack/tests/unit/accelerator/v2/test_device_profile.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/tests/unit/network/v2/test_vpn_service.py', 'openstack/tests/unit/accelerator/v2/test_proxy.py', 'openstack/tests/functional/cloud/test_endpoints.py', 'openstack/tests/unit/compute/v2/test_volume_attachment.py', 'openstack/tests/fakes.py', 'openstack/tests/unit/test_stats.py', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/tests/unit/clustering/v1/test_cluster.py', 'openstack/tests/unit/baremetal/v1/test_proxy.py', 'openstack/compute/v2/service.py', 'openstack/tests/unit/compute/test_version.py', 'openstack/dns/v2/zone_export.py', 'openstack/tests/functional/load_balancer/v2/test_load_balancer.py', 'openstack/tests/unit/cloud/test_aggregate.py', 'openstack/network/v2/flavor.py', 'openstack/network/v2/security_group.py', 'openstack/tests/functional/network/v2/test_network_ip_availability.py', 'openstack/tests/unit/load_balancer/test_l7policy.py', 'openstack/tests/functional/identity/v3/test_application_credential.py', 'openstack/tests/unit/cloud/test_router.py', 'openstack/tests/unit/identity/v2/test_role.py', 'openstack/network/v2/subnet.py', 'openstack/__init__.py', 'openstack/tests/functional/examples/test_image.py', 'openstack/tests/unit/network/v2/test_segment.py', 'openstack/tests/unit/cloud/test_image.py', 'openstack/tests/unit/identity/v2/test_extension.py', 'openstack/dns/v2/zone_import.py', 'openstack/tests/functional/examples/test_compute.py', 'openstack/tests/unit/key_manager/v1/test_proxy.py', 'openstack/tests/unit/clustering/v1/test_service.py', 'openstack/tests/unit/test_utils.py', 'openstack/tests/unit/clustering/v1/test_policy_type.py', 'tox.ini', 'openstack/cloud/_floating_ip.py', 'openstack/cloud/_coe.py', 'openstack/tests/unit/network/v2/test_availability_zone.py', 'openstack/orchestration/util/template_format.py', 'openstack/tests/unit/network/v2/test_security_group_rule.py', 'openstack/tests/unit/identity/v3/test_endpoint.py', 'openstack/dns/v2/floating_ip.py', 'openstack/tests/unit/block_storage/v2/test_proxy.py', 'openstack/tests/unit/orchestration/v1/test_stack_files.py', 'openstack/tests/unit/compute/v2/test_aggregate.py', 'openstack/network/v2/router.py', 'openstack/tests/unit/baremetal/v1/test_port_group.py', 'openstack/tests/functional/cloud/test_volume_type.py', 'openstack/tests/unit/identity/v3/test_group.py', 'openstack/tests/unit/cloud/test_identity_roles.py', 'openstack/tests/unit/identity/v3/test_role_domain_group_assignment.py', 'openstack/tests/unit/identity/v3/test_role.py', 'openstack/clustering/clustering_service.py', 'openstack/tests/unit/block_storage/v3/test_type.py', 'openstack/tests/unit/network/v2/test_firewall_policy.py', 'openstack/tests/unit/cloud/test_magnum_services.py', 'openstack/config/cloud_region.py', 'openstack/tests/unit/clustering/v1/test_cluster_policy.py', 'openstack/tests/unit/orchestration/v1/test_stack_environment.py', 'openstack/tests/unit/accelerator/test_version.py', 'openstack/network/v2/qos_policy.py', 'openstack/tests/unit/image/v2/test_schema.py', 'openstack/identity/v3/domain.py', 'openstack/tests/unit/cloud/test_create_volume_snapshot.py', 'openstack/tests/unit/object_store/v1/test_account.py', 'openstack/tests/unit/clustering/v1/test_build_info.py']",404,ba7c51dfd7dc63f8f957a6368ea7a82b02ba2ff9,use-bugbear,from openstack.tests.unit import base,from openstack.tests.unit import base ,690,1087
openstack%2Ftripleo-heat-templates~master~Ia18c8b88a51314a4a37fa763547d26c13c5598c0,openstack/tripleo-heat-templates,master,Ia18c8b88a51314a4a37fa763547d26c13c5598c0,Add ControlePlaneStaticRoutes back in,ABANDONED,2021-01-06 19:28:00.000000000,2021-01-07 14:17:55.000000000,,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-06 19:28:00.000000000', 'files': ['overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/388b30eb2fd6e165eed1edc145781f63fc2dfa92', 'message': 'Add ControlePlaneStaticRoutes back in\n\nIn the conversion from the old network configurations to the new ones,\nwe lost the ability to control the static routes for the Control Plane.\nThis change adds ControlPlaneStaticRoutes back in to the system which\nwill be appended to any network generated routes.  Our previous use case\nwas a standalone deployment on a single nic needed the default gateway\nadded into the network configuration. Since the network configuration\nfor the standalone uses the control plane network by default, we need to\nallow people to continue to use ControlePlaneStaticRoutes.\n\nChange-Id: Ia18c8b88a51314a4a37fa763547d26c13c5598c0\n'}]",1,769603,388b30eb2fd6e165eed1edc145781f63fc2dfa92,7,3,1,14985,,,0,"Add ControlePlaneStaticRoutes back in

In the conversion from the old network configurations to the new ones,
we lost the ability to control the static routes for the Control Plane.
This change adds ControlPlaneStaticRoutes back in to the system which
will be appended to any network generated routes.  Our previous use case
was a standalone deployment on a single nic needed the default gateway
added into the network configuration. Since the network configuration
for the standalone uses the control plane network by default, we need to
allow people to continue to use ControlePlaneStaticRoutes.

Change-Id: Ia18c8b88a51314a4a37fa763547d26c13c5598c0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/769603/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.j2.yaml'],1,388b30eb2fd6e165eed1edc145781f63fc2dfa92,fix-standalone-single-nic," ControlPlaneStaticRoutes: default: [] description: > Extra routes for the ctlplane network traffic. JSON route e.g. [{'destination':'10.0.0.0/16', 'nexthop':'10.0.0.1'}] This is added to existing calculated ControlePlaneStaticRoutes. type: json - {get_param: ControlePlaneStaticRoute}",,8,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I1d74af75a2c99996d392dc314d67b33dc1ab5d57,openstack/tripleo-heat-templates,stable/queens,I1d74af75a2c99996d392dc314d67b33dc1ab5d57,[QUEENS-ONLY] - Add ignore_errors to the docker stop task,ABANDONED,2021-01-07 12:43:53.000000000,2021-01-07 14:07:00.000000000,,"[{'_account_id': 6796}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2021-01-07 12:43:53.000000000', 'files': ['docker/services/ceph-ansible/ceph-mon.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0defbe447941bc592e7a971baf47211ae55af653', 'message': '[QUEENS-ONLY] - Add ignore_errors to the docker stop task\n\nAs per [1] when the docker package is updated a ""docker stop""\ntask should be run against ceph-mon containers to make them\naligned with their systemd units.\nHowever, if systemctl is-active ceph-mon@* task fails (returning\na value != 0), the next one should be skipped.\nSince evaluating the output of the shell command cannot give\nmore details about the reason of the failure, adding an ignore\nerrors should be safe to prevent whole playbook to fail during\nthe attempt of recovering the ceph-mon systemd unit.\n\n[1] https://review.opendev.org/753636/\n\nChange-Id: I1d74af75a2c99996d392dc314d67b33dc1ab5d57\n'}]",0,769721,0defbe447941bc592e7a971baf47211ae55af653,3,4,1,25402,,,0,"[QUEENS-ONLY] - Add ignore_errors to the docker stop task

As per [1] when the docker package is updated a ""docker stop""
task should be run against ceph-mon containers to make them
aligned with their systemd units.
However, if systemctl is-active ceph-mon@* task fails (returning
a value != 0), the next one should be skipped.
Since evaluating the output of the shell command cannot give
more details about the reason of the failure, adding an ignore
errors should be safe to prevent whole playbook to fail during
the attempt of recovering the ceph-mon systemd unit.

[1] https://review.opendev.org/753636/

Change-Id: I1d74af75a2c99996d392dc314d67b33dc1ab5d57
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/769721/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-mon.yaml'],1,0defbe447941bc592e7a971baf47211ae55af653,, ignore_errors: true,,1,0
openstack%2Fkayobe-config~master~Ic2b7e23e749b9405aee3a4459a85073876c7c721,openstack/kayobe-config,master,Ic2b7e23e749b9405aee3a4459a85073876c7c721,Remove Retired Karbor Support,MERGED,2020-12-16 23:18:01.000000000,2021-01-07 14:00:45.000000000,2021-01-07 14:00:45.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-16 23:18:01.000000000', 'files': ['etc/kayobe/kolla.yml'], 'web_link': 'https://opendev.org/openstack/kayobe-config/commit/9813f25f4522b8d1cc520fea77fe283618063e5d', 'message': 'Remove Retired Karbor Support\n\nAs announced on the openstack-discuss ML[1], Karbor is retiring\nthis cycle (Wallaby).\n\nNeeded-By: https://review.opendev.org/c/openstack/karbor/+/767032\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nChange-Id: Ic2b7e23e749b9405aee3a4459a85073876c7c721\n'}]",0,767435,9813f25f4522b8d1cc520fea77fe283618063e5d,7,2,1,16708,,,0,"Remove Retired Karbor Support

As announced on the openstack-discuss ML[1], Karbor is retiring
this cycle (Wallaby).

Needed-By: https://review.opendev.org/c/openstack/karbor/+/767032

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html

Change-Id: Ic2b7e23e749b9405aee3a4459a85073876c7c721
",git fetch https://review.opendev.org/openstack/kayobe-config refs/changes/35/767435/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/kolla.yml'],1,9813f25f4522b8d1cc520fea77fe283618063e5d,retire-karbor,,#kolla_enable_horizon_karbor:#kolla_enable_karbor:,0,2
openstack%2Fdesignate-dashboard~master~I66100bfb31f10178f8576211bf068dabb76b8ee0,openstack/designate-dashboard,master,I66100bfb31f10178f8576211bf068dabb76b8ee0,Dropping lower constraints testing,ABANDONED,2020-12-18 17:31:44.000000000,2021-01-07 13:59:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-18 17:31:44.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/afb62233c8576541617445dda085764c98789a30', 'message': 'Dropping lower constraints testing\n\nWe facing errors related to the new pip resolver, this topic was\ndiscussed on the ML and QA team proposed to to test lower-constraints\n[1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I66100bfb31f10178f8576211bf068dabb76b8ee0\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}]",0,767925,afb62233c8576541617445dda085764c98789a30,5,1,1,19298,,,0,"Dropping lower constraints testing

We facing errors related to the new pip resolver, this topic was
discussed on the ML and QA team proposed to to test lower-constraints
[1].

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html

Change-Id: I66100bfb31f10178f8576211bf068dabb76b8ee0
Signed-off-by: Nicolas Bock <nicolas.bock@canonical.com>
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/25/767925/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,afb62233c8576541617445dda085764c98789a30,oslo_lc_drop,, - openstack-lower-constraints-jobs,0,1
openstack%2Fkuryr-kubernetes~master~I721a46ea0379382f7eb2e13c59bd193314f37e7f,openstack/kuryr-kubernetes,master,I721a46ea0379382f7eb2e13c59bd193314f37e7f,Added function for figure out link for the resource.,MERGED,2020-12-23 10:25:47.000000000,2021-01-07 13:36:39.000000000,2021-01-07 13:35:29.000000000,"[{'_account_id': 11600}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-12-23 10:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/e64f3e0890df2d40581e8520ca627c8a0e73a7ac', 'message': 'Added function for figure out link for the resource.\n\nBecause Kubernetes will stop propagating metadata.selLink field in\nrelease 1.20 and it will be removed in release 1.21, we need to adapt\nand calculate selfLink equivalent by ourselves.\n\nIn this patch new function is introduced, which will return the path for\nprovided resource.\n\nChange-Id: I721a46ea0379382f7eb2e13c59bd193314f37e7f\n'}, {'number': 2, 'created': '2020-12-23 13:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/1ea6437e3e9bcd56d5794bff62d9b9f8b3224fd3', 'message': 'Added function for figure out link for the resource.\n\nBecause Kubernetes will stop propagating metadata.selLink field in\nrelease 1.20 and it will be removed in release 1.21, we need to adapt\nand calculate selfLink equivalent by ourselves.\n\nIn this patch new function is introduced, which will return the path for\nprovided resource.\n\nChange-Id: I721a46ea0379382f7eb2e13c59bd193314f37e7f\n'}, {'number': 3, 'created': '2021-01-04 07:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ed0075579d72937436675cced22f9e87c19f4b33', 'message': 'Added function for figure out link for the resource.\n\nBecause Kubernetes will stop propagating metadata.selLink field in\nrelease 1.20 and it will be removed in release 1.21, we need to adapt\nand calculate selfLink equivalent by ourselves.\n\nIn this patch new function is introduced, which will return the path for\nprovided resource.\n\nImplements: blueprint selflink\nChange-Id: I721a46ea0379382f7eb2e13c59bd193314f37e7f\n'}, {'number': 4, 'created': '2021-01-05 16:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/a4aa241111b0130bd5abee4c62a45702976ee610', 'message': ""Added function for figure out link for the resource.\n\nBecause Kubernetes will stop propagating metadata.selLink field in\nrelease 1.20 and it will be removed in release 1.21, we need to adapt\nand calculate selfLink equivalent by ourselves.\n\nIn this patch new function is introduced, which will return the path for\nprovided resource.\n\nAlso, we need to deal with list of resources, since for some reason CRs\ndo have information regarding apiVersion and the kind, while as for core\nresources the apiVersion is only on top of the list object, kind is\nsomething like *List, and object within 'items' are without either\napiVersion nor kind.\n\nImplements: blueprint selflink\nChange-Id: I721a46ea0379382f7eb2e13c59bd193314f37e7f\n""}, {'number': 5, 'created': '2021-01-07 09:41:48.000000000', 'files': ['kuryr_kubernetes/tests/unit/test_k8s_client.py', 'kuryr_kubernetes/watcher.py', 'kuryr_kubernetes/k8s_client.py', 'kuryr_kubernetes/utils.py', 'kuryr_kubernetes/tests/unit/test_utils.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/e3ff9547a6d54a04d3620128bcbfdd61033c0b12', 'message': ""Added function for figure out link for the resource.\n\nBecause Kubernetes will stop propagating metadata.selLink field in\nrelease 1.20 and it will be removed in release 1.21, we need to adapt\nand calculate selfLink equivalent by ourselves.\n\nIn this patch new function is introduced, which will return the path for\nprovided resource.\n\nAlso, we need to deal with list of resources, since for some reason CRs\ndo have information regarding apiVersion and the kind, while as for core\nresources the apiVersion is only on top of the list object, kind is\nsomething like *List, and object within 'items' are without either\napiVersion nor kind.\n\nImplements: blueprint selflink\nChange-Id: I721a46ea0379382f7eb2e13c59bd193314f37e7f\n""}]",7,768318,e3ff9547a6d54a04d3620128bcbfdd61033c0b12,29,4,5,13692,,,0,"Added function for figure out link for the resource.

Because Kubernetes will stop propagating metadata.selLink field in
release 1.20 and it will be removed in release 1.21, we need to adapt
and calculate selfLink equivalent by ourselves.

In this patch new function is introduced, which will return the path for
provided resource.

Also, we need to deal with list of resources, since for some reason CRs
do have information regarding apiVersion and the kind, while as for core
resources the apiVersion is only on top of the list object, kind is
something like *List, and object within 'items' are without either
apiVersion nor kind.

Implements: blueprint selflink
Change-Id: I721a46ea0379382f7eb2e13c59bd193314f37e7f
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/18/768318/5 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/utils.py', 'kuryr_kubernetes/tests/unit/test_utils.py']",2,e64f3e0890df2d40581e8520ca627c8a0e73a7ac,selflink," def test_get_res_link_core_res(self): res = {'apiVersion': 'v1', 'kind': 'Pod', 'metadata': {'name': 'pod-1', 'namespace': 'default'}} self.assertEqual(utils.get_res_link(res), '/api/v1/namespaces/default/pods/pod-1') def test_get_res_link_no_existent(self): res = {'apiVersion': 'customapi/v1', 'kind': 'ItsATrap!', 'metadata': {'name': 'pod-1', 'namespace': 'default'}} self.assertRaises(KeyError, utils.get_res_link, res) def test_get_res_link_no_namespace(self): res = {'apiVersion': 'v1', 'kind': 'Namespace', 'metadata': {'name': 'ns-1'}} self.assertEqual(utils.get_res_link(res), '/api/v1/namespaces/ns-1') def test_get_res_link_custom_api(self): res = {'apiVersion': 'openstack.org/v1', 'kind': 'KuryrPort', 'metadata': {'name': 'kp-1', 'namespace': 'default'}} self.assertEqual(utils.get_res_link(res), '/apis/openstack.org/v1/namespaces/default/' 'kuryrports/kp-1')",,64,0
openstack%2Fnova~master~I58d82054b41095792f30a23a9e0cef0d9e38a350,openstack/nova,master,I58d82054b41095792f30a23a9e0cef0d9e38a350,Add schema files to compare against after squashing,ABANDONED,2020-12-23 19:15:16.000000000,2021-01-07 13:32:32.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-23 19:15:16.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/schemas/215-mysql.sql', 'nova/db/sqlalchemy/migrate_repo/schemas/215-postgres.sql', 'nova/db/sqlalchemy/migrate_repo/generate-schemas', 'nova/db/sqlalchemy/migrate_repo/schemas/215-sqlite.sql'], 'web_link': 'https://opendev.org/openstack/nova/commit/3c87f4072f960508874937637100ccc7b8cc5fe3', 'message': 'Add schema files to compare against after squashing\n\nThese are generated using the \'generate-schemas\' tool included in this\nchange and then renamed to ""before"" rather than after.\n\nChange-Id: I58d82054b41095792f30a23a9e0cef0d9e38a350\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",1,768364,3c87f4072f960508874937637100ccc7b8cc5fe3,9,1,1,15334,,,0,"Add schema files to compare against after squashing

These are generated using the 'generate-schemas' tool included in this
change and then renamed to ""before"" rather than after.

Change-Id: I58d82054b41095792f30a23a9e0cef0d9e38a350
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/768364/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/schemas/215-mysql.sql', 'nova/db/sqlalchemy/migrate_repo/schemas/215-postgres.sql', 'nova/db/sqlalchemy/migrate_repo/generate-schemas', 'nova/db/sqlalchemy/migrate_repo/schemas/215-sqlite.sql']",4,3c87f4072f960508874937637100ccc7b8cc5fe3,bp/compact-db-migrations-wallaby,"CREATE TABLE migrate_version ( repository_id VARCHAR(250) NOT NULL, repository_path TEXT, version INTEGER, PRIMARY KEY (repository_id) ); CREATE TABLE aggregates ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, name VARCHAR(255), deleted INTEGER, uuid VARCHAR(36), PRIMARY KEY (id) ); CREATE TABLE snapshots ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id VARCHAR(36) NOT NULL, volume_id VARCHAR(36) NOT NULL, user_id VARCHAR(255), project_id VARCHAR(255), status VARCHAR(255), progress VARCHAR(255), volume_size INTEGER, scheduled_at DATETIME, display_name VARCHAR(255), display_description VARCHAR(255), deleted VARCHAR(36), PRIMARY KEY (id) ); CREATE TABLE bw_usage_cache ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, start_period DATETIME NOT NULL, last_refreshed DATETIME, bw_in BIGINT, bw_out BIGINT, mac VARCHAR(255), uuid VARCHAR(36), last_ctr_in BIGINT, last_ctr_out BIGINT, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE certificates ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, user_id VARCHAR(255), project_id VARCHAR(255), file_name VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE consoles ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_name VARCHAR(255), password VARCHAR(255), port INTEGER, pool_id INTEGER, instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id), FOREIGN KEY(pool_id) REFERENCES console_pools (id), CONSTRAINT consoles_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE TABLE dns_domains ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted BOOLEAN, domain VARCHAR(255) NOT NULL, scope VARCHAR(255), availability_zone VARCHAR(255), project_id VARCHAR(255), PRIMARY KEY (domain), CHECK (deleted IN (0, 1)) ); CREATE TABLE instance_id_mappings ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE instance_actions_events ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, event VARCHAR(255), action_id INTEGER, start_time DATETIME, finish_time DATETIME, result VARCHAR(255), traceback TEXT, deleted INTEGER, host VARCHAR(255), details TEXT, PRIMARY KEY (id), FOREIGN KEY(action_id) REFERENCES instance_actions (id) ); CREATE TABLE instance_groups ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, user_id VARCHAR(255), project_id VARCHAR(255), uuid VARCHAR(36) NOT NULL, name VARCHAR(255), PRIMARY KEY (id), CONSTRAINT uniq_instance_groups0uuid0deleted UNIQUE (uuid, deleted) ); CREATE TABLE instance_group_policy ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, policy VARCHAR(255), group_id INTEGER NOT NULL, PRIMARY KEY (id), FOREIGN KEY(group_id) REFERENCES instance_groups (id) ); CREATE TABLE instance_group_member ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, instance_id VARCHAR(255), group_id INTEGER NOT NULL, PRIMARY KEY (id), FOREIGN KEY(group_id) REFERENCES instance_groups (id) ); CREATE TABLE provider_fw_rules ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, protocol VARCHAR(5), from_port INTEGER, to_port INTEGER, cidr VARCHAR(43), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE quota_classes ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, class_name VARCHAR(255), resource VARCHAR(255), hard_limit INTEGER, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE project_user_quotas ( id INTEGER NOT NULL, created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, user_id VARCHAR(255) NOT NULL, project_id VARCHAR(255) NOT NULL, resource VARCHAR(255) NOT NULL, hard_limit INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_project_user_quotas0user_id0project_id0resource0deleted UNIQUE (user_id, project_id, resource, deleted) ); CREATE TABLE s3_images ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE security_group_rules ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, parent_group_id INTEGER, protocol VARCHAR(255), from_port INTEGER, to_port INTEGER, cidr VARCHAR(43), group_id INTEGER, deleted INTEGER, PRIMARY KEY (id), FOREIGN KEY(parent_group_id) REFERENCES security_groups (id), FOREIGN KEY(group_id) REFERENCES security_groups (id) ); CREATE TABLE security_group_default_rules ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, protocol VARCHAR(5), from_port INTEGER, to_port INTEGER, cidr VARCHAR(43), PRIMARY KEY (id) ); CREATE TABLE snapshot_id_mappings ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE volume_id_mappings ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE task_log ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, task_name VARCHAR(255) NOT NULL, state VARCHAR(255) NOT NULL, host VARCHAR(255) NOT NULL, period_beginning DATETIME NOT NULL, period_ending DATETIME NOT NULL, message VARCHAR(255) NOT NULL, task_items INTEGER, errors INTEGER, deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_task_log0task_name0host0period_beginning0period_ending UNIQUE (task_name, host, period_beginning, period_ending) ); CREATE TABLE networks ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, injected BOOLEAN, cidr VARCHAR(43), netmask VARCHAR(39), bridge VARCHAR(255), gateway VARCHAR(39), broadcast VARCHAR(39), dns1 VARCHAR(39), vlan INTEGER, vpn_public_address VARCHAR(39), vpn_public_port INTEGER, vpn_private_address VARCHAR(39), dhcp_start VARCHAR(39), project_id VARCHAR(255), host VARCHAR(255), cidr_v6 VARCHAR(43), gateway_v6 VARCHAR(39), label VARCHAR(255), netmask_v6 VARCHAR(39), bridge_interface VARCHAR(255), multi_host BOOLEAN, dns2 VARCHAR(39), uuid VARCHAR(36), priority INTEGER, rxtx_base INTEGER, deleted INTEGER, mtu INTEGER, dhcp_server VARCHAR(39), enable_dhcp BOOLEAN, share_address BOOLEAN, PRIMARY KEY (id), CHECK (injected IN (0, 1)), CHECK (multi_host IN (0, 1)), CONSTRAINT uniq_networks0vlan0deleted UNIQUE (vlan, deleted) ); CREATE TABLE instance_types ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, name VARCHAR(255), id INTEGER NOT NULL, memory_mb INTEGER NOT NULL, vcpus INTEGER NOT NULL, swap INTEGER NOT NULL, vcpu_weight INTEGER, flavorid VARCHAR(255), rxtx_factor FLOAT, root_gb INTEGER, ephemeral_gb INTEGER, disabled BOOLEAN, is_public BOOLEAN, deleted INTEGER, PRIMARY KEY (id), CHECK (disabled IN (0, 1)), CHECK (is_public IN (0, 1)), CONSTRAINT uniq_instance_types0name0deleted UNIQUE (name, deleted), CONSTRAINT uniq_instance_types0flavorid0deleted UNIQUE (flavorid, deleted) ); CREATE TABLE floating_ips ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(39), fixed_ip_id INTEGER, project_id VARCHAR(255), host VARCHAR(255), auto_assigned BOOLEAN, pool VARCHAR(255), interface VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CHECK (auto_assigned IN (0, 1)), CONSTRAINT uniq_floating_ips0address0deleted UNIQUE (address, deleted) ); CREATE TABLE cells ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, api_url VARCHAR(255), weight_offset FLOAT, weight_scale FLOAT, name VARCHAR(255), is_parent BOOLEAN, deleted INTEGER, transport_url VARCHAR(255) NOT NULL, PRIMARY KEY (id), CHECK (is_parent IN (0, 1)), CONSTRAINT uniq_cells0name0deleted UNIQUE (name, deleted) ); CREATE TABLE security_groups ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, name VARCHAR(255), description VARCHAR(255), user_id VARCHAR(255), project_id VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_security_groups0project_id0name0deleted UNIQUE (project_id, name, deleted) ); CREATE TABLE quotas ( id INTEGER NOT NULL, created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, project_id VARCHAR(255), resource VARCHAR(255) NOT NULL, hard_limit INTEGER, deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_quotas0project_id0resource0deleted UNIQUE (project_id, resource, deleted) ); CREATE TABLE services ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, host VARCHAR(255), binary VARCHAR(255), topic VARCHAR(255), report_count INTEGER NOT NULL, disabled BOOLEAN, deleted INTEGER, disabled_reason VARCHAR(255), last_seen_up DATETIME, forced_down BOOLEAN, version INTEGER, uuid VARCHAR(36), PRIMARY KEY (id), CHECK (disabled IN (0, 1)), CONSTRAINT uniq_services0host0topic0deleted UNIQUE (host, topic, deleted), CONSTRAINT uniq_services0host0binary0deleted UNIQUE (host, binary, deleted) ); CREATE TABLE agent_builds ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, hypervisor VARCHAR(255), os VARCHAR(255), architecture VARCHAR(255), version VARCHAR(255), url VARCHAR(255), md5hash VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_agent_builds0hypervisor0os0architecture0deleted UNIQUE (hypervisor, os, architecture, deleted) ); CREATE TABLE console_pools ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(39), username VARCHAR(255), password VARCHAR(255), console_type VARCHAR(255), public_hostname VARCHAR(255), host VARCHAR(255), compute_host VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_console_pools0host0console_type0compute_host0deleted UNIQUE (host, console_type, compute_host, deleted) ); CREATE TABLE aggregate_hosts ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, host VARCHAR(255), aggregate_id INTEGER NOT NULL, deleted INTEGER, PRIMARY KEY (id), FOREIGN KEY(aggregate_id) REFERENCES aggregates (id), CONSTRAINT uniq_aggregate_hosts0host0aggregate_id0deleted UNIQUE (host, aggregate_id, deleted) ); CREATE TABLE aggregate_metadata ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, aggregate_id INTEGER NOT NULL, ""key"" VARCHAR(255) NOT NULL, value VARCHAR(255) NOT NULL, deleted INTEGER, PRIMARY KEY (id), FOREIGN KEY(aggregate_id) REFERENCES aggregates (id), CONSTRAINT uniq_aggregate_metadata0aggregate_id0key0deleted UNIQUE (aggregate_id, ""key"", deleted) ); CREATE TABLE instance_type_extra_specs ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_type_id INTEGER NOT NULL, ""key"" VARCHAR(255), value VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), FOREIGN KEY(instance_type_id) REFERENCES instance_types (id), CONSTRAINT uniq_instance_type_extra_specs0instance_type_id0key0deleted UNIQUE (instance_type_id, ""key"", deleted) ); CREATE INDEX aggregate_metadata_key_idx ON aggregate_metadata (""key""); CREATE INDEX agent_builds_hypervisor_os_arch_idx ON agent_builds (hypervisor, os, architecture); CREATE INDEX bw_usage_cache_uuid_start_period_idx ON bw_usage_cache (uuid, start_period); CREATE INDEX certificates_project_id_deleted_idx ON certificates (project_id, deleted); CREATE INDEX certificates_user_id_deleted_idx ON certificates (user_id, deleted); CREATE INDEX consoles_instance_uuid_idx ON consoles (instance_uuid); CREATE INDEX dns_domains_domain_deleted_idx ON dns_domains (domain, deleted); CREATE INDEX floating_ips_host_idx ON floating_ips (host); CREATE INDEX floating_ips_project_id_idx ON floating_ips (project_id); CREATE INDEX floating_ips_pool_deleted_fixed_ip_id_project_id_idx ON floating_ips (pool, deleted, fixed_ip_id, project_id); CREATE INDEX instance_group_member_instance_idx ON instance_group_member (instance_id); CREATE INDEX instance_group_policy_policy_idx ON instance_group_policy (policy); CREATE INDEX ix_instance_id_mappings_uuid ON instance_id_mappings (uuid); CREATE INDEX instance_type_extra_specs_instance_type_id_key_idx ON instance_type_extra_specs (instance_type_id, ""key""); CREATE INDEX networks_host_idx ON networks (host); CREATE INDEX networks_cidr_v6_idx ON networks (cidr_v6); CREATE INDEX networks_bridge_deleted_idx ON networks (bridge, deleted); CREATE INDEX networks_project_id_deleted_idx ON networks (project_id, deleted); CREATE INDEX networks_uuid_project_id_deleted_idx ON networks (uuid, project_id, deleted); CREATE INDEX networks_vlan_deleted_idx ON networks (vlan, deleted); CREATE INDEX project_user_quotas_project_id_deleted_idx ON project_user_quotas (project_id, deleted); CREATE INDEX project_user_quotas_user_id_deleted_idx ON project_user_quotas (user_id, deleted); CREATE INDEX ix_task_log_period_beginning ON task_log (period_beginning); CREATE INDEX ix_task_log_host ON task_log (host); CREATE INDEX ix_task_log_period_ending ON task_log (period_ending); CREATE INDEX ix_quota_classes_class_name ON quota_classes (class_name); CREATE TABLE shadow_agent_builds ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, hypervisor VARCHAR(255), os VARCHAR(255), architecture VARCHAR(255), version VARCHAR(255), url VARCHAR(255), md5hash VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_aggregate_hosts ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, host VARCHAR(255), aggregate_id INTEGER NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_aggregates ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, name VARCHAR(255), deleted INTEGER, uuid VARCHAR(36), PRIMARY KEY (id) ); CREATE TABLE shadow_aggregate_metadata ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, aggregate_id INTEGER NOT NULL, ""key"" VARCHAR(255) NOT NULL, value VARCHAR(255) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_block_device_mapping ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, device_name VARCHAR(255), delete_on_termination BOOLEAN, snapshot_id VARCHAR(36), volume_id VARCHAR(36), volume_size INTEGER, no_device BOOLEAN, connection_info TEXT, instance_uuid VARCHAR(36), deleted INTEGER, source_type VARCHAR(255), destination_type VARCHAR(255), guest_format VARCHAR(255), device_type VARCHAR(255), disk_bus VARCHAR(255), boot_index INTEGER, image_id VARCHAR(36), tag VARCHAR(255), attachment_id VARCHAR(36), uuid VARCHAR(36), volume_type VARCHAR(255), PRIMARY KEY (id), CHECK (delete_on_termination IN (0, 1)), CHECK (no_device IN (0, 1)) ); CREATE TABLE shadow_bw_usage_cache ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, start_period DATETIME NOT NULL, last_refreshed DATETIME, bw_in BIGINT, bw_out BIGINT, mac VARCHAR(255), uuid VARCHAR(36), last_ctr_in BIGINT, last_ctr_out BIGINT, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_cells ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, api_url VARCHAR(255), weight_offset FLOAT, weight_scale FLOAT, name VARCHAR(255), is_parent BOOLEAN, deleted INTEGER, transport_url VARCHAR(255) NOT NULL, PRIMARY KEY (id), CHECK (is_parent IN (0, 1)) ); CREATE TABLE shadow_certificates ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, user_id VARCHAR(255), project_id VARCHAR(255), file_name VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_console_pools ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(39), username VARCHAR(255), password VARCHAR(255), console_type VARCHAR(255), public_hostname VARCHAR(255), host VARCHAR(255), compute_host VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_consoles ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_name VARCHAR(255), password VARCHAR(255), port INTEGER, pool_id INTEGER, instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_dns_domains ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted BOOLEAN, domain VARCHAR(255) NOT NULL, scope VARCHAR(255), availability_zone VARCHAR(255), project_id VARCHAR(255), PRIMARY KEY (domain), CHECK (deleted IN (0, 1)) ); CREATE TABLE shadow_fixed_ips ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(39), network_id INTEGER, allocated BOOLEAN, leased BOOLEAN, reserved BOOLEAN, virtual_interface_id INTEGER, host VARCHAR(255), instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id), CHECK (allocated IN (0, 1)), CHECK (leased IN (0, 1)), CHECK (reserved IN (0, 1)) ); CREATE TABLE shadow_floating_ips ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(39), fixed_ip_id INTEGER, project_id VARCHAR(255), host VARCHAR(255), auto_assigned BOOLEAN, pool VARCHAR(255), interface VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CHECK (auto_assigned IN (0, 1)) ); CREATE TABLE shadow_instance_actions ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, action VARCHAR(255), instance_uuid VARCHAR(36), request_id VARCHAR(255), user_id VARCHAR(255), project_id VARCHAR(255), start_time DATETIME, finish_time DATETIME, message VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_actions_events ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, event VARCHAR(255), action_id INTEGER, start_time DATETIME, finish_time DATETIME, result VARCHAR(255), traceback TEXT, deleted INTEGER, host VARCHAR(255), details TEXT, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_faults ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_uuid VARCHAR(36), code INTEGER NOT NULL, message VARCHAR(255), details TEXT, host VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_group_member ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, instance_id VARCHAR(255), group_id INTEGER NOT NULL, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_groups ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, user_id VARCHAR(255), project_id VARCHAR(255), uuid VARCHAR(36) NOT NULL, name VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE shadow_instance_group_policy ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, policy VARCHAR(255), group_id INTEGER NOT NULL, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_id_mappings ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_info_caches ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, network_info TEXT, instance_uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_metadata ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, ""key"" VARCHAR(255), value VARCHAR(255), instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_system_metadata ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_uuid VARCHAR(36) NOT NULL, ""key"" VARCHAR(255) NOT NULL, value VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_type_extra_specs ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_type_id INTEGER NOT NULL, ""key"" VARCHAR(255), value VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_instance_types ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, name VARCHAR(255), id INTEGER NOT NULL, memory_mb INTEGER NOT NULL, vcpus INTEGER NOT NULL, swap INTEGER NOT NULL, vcpu_weight INTEGER, flavorid VARCHAR(255), rxtx_factor FLOAT, root_gb INTEGER, ephemeral_gb INTEGER, disabled BOOLEAN, is_public BOOLEAN, deleted INTEGER, PRIMARY KEY (id), CHECK (disabled IN (0, 1)), CHECK (is_public IN (0, 1)) ); CREATE TABLE shadow_instance_type_projects ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_type_id INTEGER NOT NULL, project_id VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_key_pairs ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, name VARCHAR(255), user_id VARCHAR(255), fingerprint VARCHAR(255), public_key TEXT, deleted INTEGER, type VARCHAR(4) DEFAULT 'ssh' NOT NULL, PRIMARY KEY (id) ); CREATE TABLE shadow_migrate_version ( repository_id VARCHAR(250) NOT NULL, repository_path TEXT, version INTEGER, PRIMARY KEY (repository_id) ); CREATE TABLE shadow_migrations ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, source_compute VARCHAR(255), dest_compute VARCHAR(255), dest_host VARCHAR(255), status VARCHAR(255), instance_uuid VARCHAR(36), old_instance_type_id INTEGER, new_instance_type_id INTEGER, source_node VARCHAR(255), dest_node VARCHAR(255), deleted INTEGER, migration_type VARCHAR(14), hidden BOOLEAN, memory_total BIGINT, memory_processed BIGINT, memory_remaining BIGINT, disk_total BIGINT, disk_processed BIGINT, disk_remaining BIGINT, uuid VARCHAR(36), cross_cell_move BOOLEAN, user_id VARCHAR(255), project_id VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE shadow_networks ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, injected BOOLEAN, cidr VARCHAR(43), netmask VARCHAR(39), bridge VARCHAR(255), gateway VARCHAR(39), broadcast VARCHAR(39), dns1 VARCHAR(39), vlan INTEGER, vpn_public_address VARCHAR(39), vpn_public_port INTEGER, vpn_private_address VARCHAR(39), dhcp_start VARCHAR(39), project_id VARCHAR(255), host VARCHAR(255), cidr_v6 VARCHAR(43), gateway_v6 VARCHAR(39), label VARCHAR(255), netmask_v6 VARCHAR(39), bridge_interface VARCHAR(255), multi_host BOOLEAN, dns2 VARCHAR(39), uuid VARCHAR(36), priority INTEGER, rxtx_base INTEGER, deleted INTEGER, mtu INTEGER, dhcp_server VARCHAR(39), enable_dhcp BOOLEAN, share_address BOOLEAN, PRIMARY KEY (id), CHECK (injected IN (0, 1)), CHECK (multi_host IN (0, 1)) ); CREATE TABLE shadow_pci_devices ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER NOT NULL, id INTEGER NOT NULL, compute_node_id INTEGER NOT NULL, address VARCHAR(12) NOT NULL, product_id VARCHAR(4), vendor_id VARCHAR(4), dev_type VARCHAR(8), dev_id VARCHAR(255), label VARCHAR(255) NOT NULL, status VARCHAR(36) NOT NULL, extra_info TEXT, instance_uuid VARCHAR(36), request_id VARCHAR(36), numa_node INTEGER, parent_addr VARCHAR(12), uuid VARCHAR(36), PRIMARY KEY (id) ); CREATE TABLE shadow_project_user_quotas ( id INTEGER NOT NULL, created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, user_id VARCHAR(255) NOT NULL, project_id VARCHAR(255) NOT NULL, resource VARCHAR(255) NOT NULL, hard_limit INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_provider_fw_rules ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, protocol VARCHAR(5), from_port INTEGER, to_port INTEGER, cidr VARCHAR(43), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_quota_classes ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, class_name VARCHAR(255), resource VARCHAR(255), hard_limit INTEGER, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_quota_usages ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, project_id VARCHAR(255), resource VARCHAR(255), in_use INTEGER NOT NULL, reserved INTEGER NOT NULL, until_refresh INTEGER, deleted INTEGER, user_id VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE shadow_quotas ( id INTEGER NOT NULL, created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, project_id VARCHAR(255), resource VARCHAR(255) NOT NULL, hard_limit INTEGER, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_reservations ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, usage_id INTEGER NOT NULL, project_id VARCHAR(255), resource VARCHAR(255), delta INTEGER NOT NULL, expire DATETIME, deleted INTEGER, user_id VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE shadow_s3_images ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_security_group_default_rules ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, protocol VARCHAR(5), from_port INTEGER, to_port INTEGER, cidr VARCHAR(43), PRIMARY KEY (id) ); CREATE TABLE shadow_security_group_instance_association ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, security_group_id INTEGER, instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_security_group_rules ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, parent_group_id INTEGER, protocol VARCHAR(255), from_port INTEGER, to_port INTEGER, cidr VARCHAR(43), group_id INTEGER, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_security_groups ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, name VARCHAR(255), description VARCHAR(255), user_id VARCHAR(255), project_id VARCHAR(255), deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_services ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, host VARCHAR(255), binary VARCHAR(255), topic VARCHAR(255), report_count INTEGER NOT NULL, disabled BOOLEAN, deleted INTEGER, disabled_reason VARCHAR(255), last_seen_up DATETIME, forced_down BOOLEAN, version INTEGER, uuid VARCHAR(36), PRIMARY KEY (id), CHECK (disabled IN (0, 1)) ); CREATE TABLE shadow_snapshot_id_mappings ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_snapshots ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id VARCHAR(36) NOT NULL, volume_id VARCHAR(36) NOT NULL, user_id VARCHAR(255), project_id VARCHAR(255), status VARCHAR(255), progress VARCHAR(255), volume_size INTEGER, scheduled_at DATETIME, display_name VARCHAR(255), display_description VARCHAR(255), deleted VARCHAR(36), PRIMARY KEY (id) ); CREATE TABLE shadow_task_log ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, task_name VARCHAR(255) NOT NULL, state VARCHAR(255) NOT NULL, host VARCHAR(255) NOT NULL, period_beginning DATETIME NOT NULL, period_ending DATETIME NOT NULL, message VARCHAR(255) NOT NULL, task_items INTEGER, errors INTEGER, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_virtual_interfaces ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(255), network_id INTEGER, uuid VARCHAR(36), instance_uuid VARCHAR(36), deleted INTEGER, tag VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE shadow_volume_id_mappings ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id) ); CREATE TABLE shadow_volume_usage_cache ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, volume_id VARCHAR(36) NOT NULL, tot_last_refreshed DATETIME, tot_reads BIGINT, tot_read_bytes BIGINT, tot_writes BIGINT, tot_write_bytes BIGINT, curr_last_refreshed DATETIME, curr_reads BIGINT, curr_read_bytes BIGINT, curr_writes BIGINT, curr_write_bytes BIGINT, deleted INTEGER, instance_uuid VARCHAR(36), project_id VARCHAR(36), user_id VARCHAR(36), availability_zone VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE volume_usage_cache ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, volume_id VARCHAR(36) NOT NULL, tot_last_refreshed DATETIME, tot_reads BIGINT, tot_read_bytes BIGINT, tot_writes BIGINT, tot_write_bytes BIGINT, curr_last_refreshed DATETIME, curr_reads BIGINT, curr_read_bytes BIGINT, curr_writes BIGINT, curr_write_bytes BIGINT, deleted INTEGER, instance_uuid VARCHAR(36), project_id VARCHAR(36), user_id VARCHAR(64), availability_zone VARCHAR(255), PRIMARY KEY (id) ); CREATE TABLE quota_usages ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, project_id VARCHAR(255), resource VARCHAR(255) NOT NULL, in_use INTEGER NOT NULL, reserved INTEGER NOT NULL, until_refresh INTEGER, deleted INTEGER, user_id VARCHAR(255), PRIMARY KEY (id) ); CREATE INDEX ix_quota_usages_user_id_deleted ON quota_usages (user_id, deleted); CREATE INDEX ix_quota_usages_project_id ON quota_usages (project_id); CREATE TABLE instance_extra ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, instance_uuid VARCHAR(36) NOT NULL, numa_topology TEXT, pci_requests TEXT, flavor TEXT, vcpu_model TEXT, migration_context TEXT, keypairs TEXT, device_metadata TEXT, trusted_certs TEXT, vpmems TEXT, resources TEXT, PRIMARY KEY (id), FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE INDEX instance_extra_idx ON instance_extra (instance_uuid); CREATE TABLE shadow_instance_extra ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, instance_uuid VARCHAR(36) NOT NULL, numa_topology TEXT, pci_requests TEXT, flavor TEXT, vcpu_model TEXT, migration_context TEXT, keypairs TEXT, device_metadata TEXT, trusted_certs TEXT, vpmems TEXT, resources TEXT, PRIMARY KEY (id) ); CREATE INDEX shadow_instance_extra_idx ON shadow_instance_extra (instance_uuid); CREATE TABLE tags ( resource_id VARCHAR(36) NOT NULL, tag VARCHAR(80) NOT NULL, PRIMARY KEY (resource_id, tag) ); CREATE INDEX tags_tag_idx ON tags (tag); CREATE INDEX dns_domains_project_id_idx ON dns_domains (project_id); CREATE INDEX fixed_ip_id ON floating_ips (fixed_ip_id); CREATE TABLE instance_metadata ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, ""key"" VARCHAR(255), value VARCHAR(255), instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT instance_metadata_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE INDEX instance_metadata_instance_uuid_idx ON instance_metadata (instance_uuid); CREATE TABLE instance_system_metadata ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_uuid VARCHAR(36) NOT NULL, ""key"" VARCHAR(255) NOT NULL, value VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT instance_system_metadata_ibfk_1 FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE TABLE reservations ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, usage_id INTEGER NOT NULL, project_id VARCHAR(255), resource VARCHAR(255), delta INTEGER NOT NULL, expire DATETIME, deleted INTEGER, user_id VARCHAR(255), PRIMARY KEY (id), CONSTRAINT reservations_ibfk_1 FOREIGN KEY(usage_id) REFERENCES quota_usages (id) ); CREATE INDEX reservations_deleted_expire_idx ON reservations (deleted, expire); CREATE INDEX reservations_uuid_idx ON reservations (uuid); CREATE INDEX ix_reservations_project_id ON reservations (project_id); CREATE INDEX ix_reservations_user_id_deleted ON reservations (user_id, deleted); CREATE TABLE security_group_instance_association ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, security_group_id INTEGER, instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT security_group_instance_association_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid), CONSTRAINT security_group_instance_association_ibfk_1 FOREIGN KEY(security_group_id) REFERENCES security_groups (id) ); CREATE INDEX security_group_instance_association_instance_uuid_idx ON security_group_instance_association (instance_uuid); CREATE TABLE instance_actions ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, action VARCHAR(255), instance_uuid VARCHAR(36), request_id VARCHAR(255), user_id VARCHAR(255), project_id VARCHAR(255), start_time DATETIME, finish_time DATETIME, message VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT fk_instance_actions_instance_uuid FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE INDEX request_id_idx ON instance_actions (request_id); CREATE INDEX instance_uuid_idx ON instance_actions (instance_uuid); CREATE TABLE instance_faults ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_uuid VARCHAR(36), code INTEGER NOT NULL, message VARCHAR(255), details TEXT, host VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT fk_instance_faults_instance_uuid FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE INDEX instance_faults_instance_uuid_deleted_created_at_idx ON instance_faults (instance_uuid, deleted, created_at); CREATE INDEX instance_faults_host_idx ON instance_faults (host); CREATE TABLE migrations ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, source_compute VARCHAR(255), dest_compute VARCHAR(255), dest_host VARCHAR(255), status VARCHAR(255), instance_uuid VARCHAR(36), old_instance_type_id INTEGER, new_instance_type_id INTEGER, source_node VARCHAR(255), dest_node VARCHAR(255), deleted INTEGER, migration_type VARCHAR(14), hidden BOOLEAN, memory_total BIGINT, memory_processed BIGINT, memory_remaining BIGINT, disk_total BIGINT, disk_processed BIGINT, disk_remaining BIGINT, uuid VARCHAR(36), cross_cell_move BOOLEAN, user_id VARCHAR(255), project_id VARCHAR(255), PRIMARY KEY (id), CONSTRAINT fk_migrations_instance_uuid FOREIGN KEY(instance_uuid) REFERENCES instances (uuid) ); CREATE INDEX migrations_by_host_nodes_and_status_idx ON migrations (deleted, source_compute, dest_compute, source_node, dest_node, status); CREATE INDEX migrations_instance_uuid_and_status_idx ON migrations (deleted, instance_uuid, status); CREATE TABLE fixed_ips ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(39), network_id INTEGER, allocated BOOLEAN, leased BOOLEAN, reserved BOOLEAN, virtual_interface_id INTEGER, host VARCHAR(255), instance_uuid VARCHAR(36), deleted INTEGER, PRIMARY KEY (id), CHECK (allocated IN (0, 1)), CHECK (leased IN (0, 1)), CHECK (reserved IN (0, 1)), CONSTRAINT uniq_fixed_ips0address0deleted UNIQUE (address, deleted), CHECK (allocated IN (0, 1)), CHECK (leased IN (0, 1)), CHECK (reserved IN (0, 1)), CONSTRAINT fixed_ips_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid), CONSTRAINT uniq_fixed_ips0address0deleted UNIQUE (address, deleted) ); CREATE INDEX address ON fixed_ips (address); CREATE INDEX fixed_ips_host_idx ON fixed_ips (host); CREATE INDEX fixed_ips_instance_uuid_fkey ON fixed_ips (instance_uuid); CREATE INDEX network_id ON fixed_ips (network_id); CREATE INDEX fixed_ips_address_reserved_network_id_deleted_idx ON fixed_ips (address, reserved, network_id, deleted); CREATE INDEX fixed_ips_deleted_allocated_idx ON fixed_ips (address, deleted, allocated); CREATE INDEX fixed_ips_network_id_host_deleted_idx ON fixed_ips (network_id, host, deleted); CREATE INDEX fixed_ips_virtual_interface_id_fkey ON fixed_ips (virtual_interface_id); CREATE TABLE instance_info_caches ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, network_info TEXT, instance_uuid VARCHAR(36) NOT NULL, deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_instance_info_caches0instance_uuid UNIQUE (instance_uuid), CONSTRAINT instance_info_caches_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid), CONSTRAINT uniq_instance_info_caches0instance_uuid UNIQUE (instance_uuid) ); CREATE TABLE instance_type_projects ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, instance_type_id INTEGER NOT NULL, project_id VARCHAR(255), deleted INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_instance_type_projects0instance_type_id0project_id0deleted UNIQUE (instance_type_id, project_id, deleted), CONSTRAINT instance_type_projects_ibfk_1 FOREIGN KEY(instance_type_id) REFERENCES instance_types (id), CONSTRAINT uniq_instance_type_projects0instance_type_id0project_id0deleted UNIQUE (instance_type_id, project_id, deleted) ); CREATE TABLE pci_devices ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, deleted INTEGER, id INTEGER NOT NULL, compute_node_id INTEGER NOT NULL, address VARCHAR(12) NOT NULL, vendor_id VARCHAR(4) NOT NULL, product_id VARCHAR(4) NOT NULL, dev_type VARCHAR(8) NOT NULL, dev_id VARCHAR(255), label VARCHAR(255) NOT NULL, status VARCHAR(36) NOT NULL, extra_info TEXT, instance_uuid VARCHAR(36), request_id VARCHAR(36), numa_node INTEGER, parent_addr VARCHAR(12), uuid VARCHAR(36), PRIMARY KEY (id), FOREIGN KEY(compute_node_id) REFERENCES compute_nodes (id), CONSTRAINT uniq_pci_devices0compute_node_id0address0deleted UNIQUE (compute_node_id, address, deleted), CONSTRAINT uniq_pci_devices0compute_node_id0address0deleted UNIQUE (compute_node_id, address, deleted) ); CREATE INDEX ix_pci_devices_instance_uuid_deleted ON pci_devices (instance_uuid, deleted); CREATE INDEX ix_pci_devices_compute_node_id_deleted ON pci_devices (compute_node_id, deleted); CREATE TABLE virtual_interfaces ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, address VARCHAR(255), network_id INTEGER, uuid VARCHAR(36), instance_uuid VARCHAR(36), deleted INTEGER, tag VARCHAR(255), PRIMARY KEY (id), CONSTRAINT uniq_virtual_interfaces0address0deleted UNIQUE (address, deleted), CONSTRAINT virtual_interfaces_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid), CONSTRAINT uniq_virtual_interfaces0address0deleted UNIQUE (address, deleted) ); CREATE INDEX virtual_interfaces_instance_uuid_fkey ON virtual_interfaces (instance_uuid); CREATE INDEX virtual_interfaces_network_id_idx ON virtual_interfaces (network_id); CREATE INDEX fixed_ips_deleted_allocated_updated_at_idx ON fixed_ips (deleted, allocated, updated_at); CREATE TABLE shadow_compute_nodes ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, service_id INTEGER, vcpus INTEGER NOT NULL, memory_mb INTEGER NOT NULL, local_gb INTEGER NOT NULL, vcpus_used INTEGER NOT NULL, memory_mb_used INTEGER NOT NULL, local_gb_used INTEGER NOT NULL, hypervisor_type TEXT NOT NULL, hypervisor_version INTEGER NOT NULL, cpu_info TEXT NOT NULL, disk_available_least INTEGER, free_ram_mb INTEGER, free_disk_gb INTEGER, current_workload INTEGER, running_vms INTEGER, hypervisor_hostname VARCHAR(255), deleted INTEGER, host_ip VARCHAR(39), supported_instances TEXT, pci_stats TEXT, metrics TEXT, extra_resources TEXT, stats TEXT, numa_topology TEXT, host VARCHAR(255), ram_allocation_ratio FLOAT, cpu_allocation_ratio FLOAT, uuid VARCHAR(36), disk_allocation_ratio FLOAT, mapped INTEGER, PRIMARY KEY (id) ); CREATE TABLE compute_nodes ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, service_id INTEGER, vcpus INTEGER NOT NULL, memory_mb INTEGER NOT NULL, local_gb INTEGER NOT NULL, vcpus_used INTEGER NOT NULL, memory_mb_used INTEGER NOT NULL, local_gb_used INTEGER NOT NULL, hypervisor_type TEXT NOT NULL, hypervisor_version INTEGER NOT NULL, cpu_info TEXT NOT NULL, disk_available_least INTEGER, free_ram_mb INTEGER, free_disk_gb INTEGER, current_workload INTEGER, running_vms INTEGER, hypervisor_hostname VARCHAR(255), deleted INTEGER, host_ip VARCHAR(39), supported_instances TEXT, pci_stats TEXT, metrics TEXT, extra_resources TEXT, stats TEXT, numa_topology TEXT, host VARCHAR(255), ram_allocation_ratio FLOAT, cpu_allocation_ratio FLOAT, uuid VARCHAR(36), disk_allocation_ratio FLOAT, mapped INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_compute_nodes0host0hypervisor_hostname0deleted UNIQUE (host, hypervisor_hostname, deleted) ); CREATE TABLE key_pairs ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, name VARCHAR(255) NOT NULL, user_id VARCHAR(255), fingerprint VARCHAR(255), public_key TEXT, deleted INTEGER, type VARCHAR(4) DEFAULT 'ssh' NOT NULL, PRIMARY KEY (id), CONSTRAINT uniq_key_pairs0user_id0name0deleted UNIQUE (user_id, name, deleted) ); CREATE INDEX virtual_interfaces_uuid_idx ON virtual_interfaces (uuid); CREATE INDEX instance_uuid ON instance_system_metadata (instance_uuid); CREATE INDEX ix_pci_devices_compute_node_id_parent_addr_deleted ON pci_devices (compute_node_id, parent_addr, deleted); CREATE TABLE allocations ( id INTEGER NOT NULL, resource_provider_id INTEGER NOT NULL, consumer_id VARCHAR(36) NOT NULL, resource_class_id INTEGER NOT NULL, used INTEGER NOT NULL, PRIMARY KEY (id) ); CREATE INDEX allocations_resource_class_id_idx ON allocations (resource_class_id); CREATE INDEX allocations_consumer_id_idx ON allocations (consumer_id); CREATE INDEX aggregate_uuid_idx ON aggregates (uuid); CREATE TABLE resource_providers ( id INTEGER NOT NULL, uuid VARCHAR(36) NOT NULL, name VARCHAR(200), generation INTEGER, can_host INTEGER, PRIMARY KEY (id), CONSTRAINT uniq_resource_providers0uuid UNIQUE (uuid), CONSTRAINT uniq_resource_providers0name UNIQUE (name) ); CREATE INDEX resource_providers_uuid_idx ON resource_providers (uuid); CREATE INDEX resource_providers_name_idx ON resource_providers (name); CREATE TABLE resource_provider_aggregates ( resource_provider_id INTEGER NOT NULL, aggregate_id INTEGER NOT NULL, PRIMARY KEY (resource_provider_id, aggregate_id) ); CREATE INDEX resource_provider_aggregates_aggregate_id_idx ON resource_provider_aggregates (aggregate_id); CREATE INDEX allocations_resource_provider_class_used_idx ON allocations (resource_provider_id, resource_class_id, used); CREATE TABLE inventories ( id INTEGER NOT NULL, resource_provider_id INTEGER NOT NULL, resource_class_id INTEGER NOT NULL, total INTEGER NOT NULL, reserved INTEGER NOT NULL, min_unit INTEGER NOT NULL, max_unit INTEGER NOT NULL, step_size INTEGER NOT NULL, allocation_ratio FLOAT NOT NULL, PRIMARY KEY (id), CONSTRAINT uniq_inventories0resource_provider_resource_class UNIQUE (resource_provider_id, resource_class_id) ); CREATE INDEX inventories_resource_provider_id_idx ON inventories (resource_provider_id); CREATE INDEX inventories_resource_class_id_idx ON inventories (resource_class_id); CREATE INDEX inventories_resource_provider_resource_class_idx ON inventories (resource_provider_id, resource_class_id); CREATE TABLE console_auth_tokens ( created_at DATETIME, updated_at DATETIME, id INTEGER NOT NULL, token_hash VARCHAR(255) NOT NULL, console_type VARCHAR(255) NOT NULL, host VARCHAR(255) NOT NULL, port INTEGER NOT NULL, internal_access_path VARCHAR(255), instance_uuid VARCHAR(36) NOT NULL, expires INTEGER NOT NULL, access_url_base VARCHAR(255), PRIMARY KEY (id), CONSTRAINT uniq_console_auth_tokens0token_hash UNIQUE (token_hash) ); CREATE INDEX console_auth_tokens_instance_uuid_idx ON console_auth_tokens (instance_uuid); CREATE INDEX console_auth_tokens_token_hash_idx ON console_auth_tokens (token_hash); CREATE INDEX console_auth_tokens_host_expires_idx ON console_auth_tokens (host, expires); CREATE TABLE instances ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, internal_id INTEGER, user_id VARCHAR(255), project_id VARCHAR(255), image_ref VARCHAR(255), kernel_id VARCHAR(255), ramdisk_id VARCHAR(255), launch_index INTEGER, key_name VARCHAR(255), key_data TEXT, power_state INTEGER, vm_state VARCHAR(255), memory_mb INTEGER, vcpus INTEGER, hostname VARCHAR(255), host VARCHAR(255), user_data TEXT, reservation_id VARCHAR(255), launched_at DATETIME, terminated_at DATETIME, display_name VARCHAR(255), display_description VARCHAR(255), availability_zone VARCHAR(255), locked BOOLEAN, os_type VARCHAR(255), launched_on TEXT, instance_type_id INTEGER, vm_mode VARCHAR(255), uuid VARCHAR(36) NOT NULL, architecture VARCHAR(255), root_device_name VARCHAR(255), access_ip_v4 VARCHAR(39), access_ip_v6 VARCHAR(39), config_drive VARCHAR(255), task_state VARCHAR(255), default_ephemeral_device VARCHAR(255), default_swap_device VARCHAR(255), progress INTEGER, auto_disk_config BOOLEAN, shutdown_terminate BOOLEAN, disable_terminate BOOLEAN, root_gb INTEGER, ephemeral_gb INTEGER, cell_name VARCHAR(255), node VARCHAR(255), deleted INTEGER, locked_by VARCHAR(5), cleaned INTEGER, ephemeral_key_uuid VARCHAR(36), hidden BOOLEAN, PRIMARY KEY (id), CHECK (locked IN (0, 1)), CHECK (auto_disk_config IN (0, 1)), CHECK (shutdown_terminate IN (0, 1)), CHECK (disable_terminate IN (0, 1)), CONSTRAINT uniq_instances0uuid UNIQUE (uuid), CHECK (locked IN (0, 1)), CHECK (auto_disk_config IN (0, 1)), CHECK (shutdown_terminate IN (0, 1)), CHECK (disable_terminate IN (0, 1)), CHECK (locked IN (0, 1)), CHECK (auto_disk_config IN (0, 1)), CHECK (shutdown_terminate IN (0, 1)), CHECK (disable_terminate IN (0, 1)), CONSTRAINT instances0locked_by CHECK (locked_by IN ('owner', 'admin')) ); CREATE INDEX instances_host_deleted_cleaned_idx ON instances (host, deleted, cleaned); CREATE INDEX instances_task_state_updated_at_idx ON instances (task_state, updated_at); CREATE INDEX instances_terminated_at_launched_at_idx ON instances (terminated_at, launched_at); CREATE INDEX instances_deleted_created_at_idx ON instances (deleted, created_at); CREATE INDEX instances_project_id_deleted_idx ON instances (project_id, deleted); CREATE INDEX instances_reservation_id_idx ON instances (reservation_id); CREATE INDEX instances_host_node_deleted_idx ON instances (host, node, deleted); CREATE INDEX instances_uuid_deleted_idx ON instances (uuid, deleted); CREATE UNIQUE INDEX uuid ON instances (uuid); CREATE TABLE shadow_instances ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, internal_id INTEGER, user_id VARCHAR(255), project_id VARCHAR(255), image_ref VARCHAR(255), kernel_id VARCHAR(255), ramdisk_id VARCHAR(255), launch_index INTEGER, key_name VARCHAR(255), key_data TEXT, power_state INTEGER, vm_state VARCHAR(255), memory_mb INTEGER, vcpus INTEGER, hostname VARCHAR(255), host VARCHAR(255), user_data TEXT, reservation_id VARCHAR(255), launched_at DATETIME, terminated_at DATETIME, display_name VARCHAR(255), display_description VARCHAR(255), availability_zone VARCHAR(255), locked BOOLEAN, os_type VARCHAR(255), launched_on TEXT, instance_type_id INTEGER, vm_mode VARCHAR(255), uuid VARCHAR(36) NOT NULL, architecture VARCHAR(255), root_device_name VARCHAR(255), access_ip_v4 VARCHAR(39), access_ip_v6 VARCHAR(39), config_drive VARCHAR(255), task_state VARCHAR(255), default_ephemeral_device VARCHAR(255), default_swap_device VARCHAR(255), progress INTEGER, auto_disk_config BOOLEAN, shutdown_terminate BOOLEAN, disable_terminate BOOLEAN, root_gb INTEGER, ephemeral_gb INTEGER, cell_name VARCHAR(255), node VARCHAR(255), deleted INTEGER, locked_by VARCHAR(5), cleaned INTEGER, ephemeral_key_uuid VARCHAR(36), hidden BOOLEAN, PRIMARY KEY (id), CHECK (locked IN (0, 1)), CHECK (auto_disk_config IN (0, 1)), CHECK (shutdown_terminate IN (0, 1)), CHECK (disable_terminate IN (0, 1)), CHECK (locked IN (0, 1)), CHECK (auto_disk_config IN (0, 1)), CHECK (shutdown_terminate IN (0, 1)), CHECK (disable_terminate IN (0, 1)), CHECK (locked IN (0, 1)), CHECK (auto_disk_config IN (0, 1)), CHECK (shutdown_terminate IN (0, 1)), CHECK (disable_terminate IN (0, 1)), CONSTRAINT shadow_instances0locked_by CHECK (locked_by IN ('owner', 'admin')) ); CREATE INDEX instances_project_id_idx ON instances (project_id); CREATE INDEX instances_updated_at_project_id_idx ON instances (updated_at, project_id); CREATE UNIQUE INDEX services_uuid_idx ON services (uuid); CREATE UNIQUE INDEX compute_nodes_uuid_idx ON compute_nodes (uuid); CREATE UNIQUE INDEX migrations_uuid ON migrations (uuid); CREATE UNIQUE INDEX shadow_migrations_uuid ON shadow_migrations (uuid); CREATE TABLE block_device_mapping ( created_at DATETIME, updated_at DATETIME, deleted_at DATETIME, id INTEGER NOT NULL, device_name VARCHAR(255), delete_on_termination BOOLEAN, snapshot_id VARCHAR(36), volume_id VARCHAR(36), volume_size INTEGER, no_device BOOLEAN, connection_info TEXT, instance_uuid VARCHAR(36), deleted INTEGER, source_type VARCHAR(255), destination_type VARCHAR(255), guest_format VARCHAR(255), device_type VARCHAR(255), disk_bus VARCHAR(255), boot_index INTEGER, image_id VARCHAR(36), tag VARCHAR(255), attachment_id VARCHAR(36), uuid VARCHAR(36), volume_type VARCHAR(255), PRIMARY KEY (id), CHECK (delete_on_termination IN (0, 1)), CHECK (no_device IN (0, 1)), CONSTRAINT block_device_mapping_instance_uuid_fkey FOREIGN KEY(instance_uuid) REFERENCES instances (uuid), CHECK (delete_on_termination IN (0, 1)), CHECK (no_device IN (0, 1)), CHECK (delete_on_termination IN (0, 1)), CHECK (no_device IN (0, 1)), CONSTRAINT uniq_block_device_mapping0uuid UNIQUE (uuid) ); CREATE INDEX volume_id ON block_device_mapping (volume_id); CREATE INDEX block_device_mapping_instance_uuid_device_name_idx ON block_device_mapping (instance_uuid, device_name); CREATE INDEX snapshot_id ON block_device_mapping (snapshot_id); CREATE INDEX block_device_mapping_instance_uuid_volume_id_idx ON block_device_mapping (instance_uuid, volume_id); CREATE INDEX block_device_mapping_instance_uuid_idx ON block_device_mapping (instance_uuid); CREATE INDEX console_auth_tokens_token_hash_instance_uuid_idx ON console_auth_tokens (token_hash, instance_uuid); CREATE INDEX migrations_updated_at_idx ON migrations (updated_at); CREATE INDEX instance_actions_instance_uuid_updated_at_idx ON instance_actions (instance_uuid, updated_at); CREATE INDEX aggregate_metadata_value_idx ON aggregate_metadata (value); ",,11625,0
openstack%2Ftripleo-common~master~I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee,openstack/tripleo-common,master,I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee,Enable pylint,MERGED,2020-12-16 14:07:25.000000000,2021-01-07 13:30:02.000000000,2020-12-23 02:18:36.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-16 14:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0264090fa972ccfec9b236c1ef58ef83aea9cc9c', 'message': 'WIP: Enable pylint and fix no-member issue\n\n- enables pylint with most checks temporary disabled, so we have time\n  to address them gradually\n- fix ""no-member"" check which could have prevented regression like the\n  one we had on:\n\nhttps://review.opendev.org/c/openstack/tripleo-common/+/762892/6/tripleo_common/image/builder/buildah.py\n\nNote: there are still some unsolved no-member errors which I was\nnot sure how to address. Feel free to either fix them and upload\nthis CR or add comments on how to address them:\n\n************* Module tripleo_common.utils.locks.processlock\ntripleo_common/utils/locks/processlock.py:29:21: E1101: Instance of \'SyncManager\' has no \'Lock\' member; maybe \'RLock\'? (no-member)\n************* Module tripleo_common.utils.locks.base\ntripleo_common/utils/locks/base.py:18:15: E1101: Instance of \'BaseLock\' has no \'_lock\' member (no-member)\ntripleo_common/utils/locks/base.py:21:15: E1101: Instance of \'BaseLock\' has no \'_objects\' member; maybe \'objects\'? (no-member)\ntripleo_common/utils/locks/base.py:24:15: E1101: Instance of \'BaseLock\' has no \'_sessions\' member; maybe \'sessions\'? (no-member)\n************* Module tripleo_common.image.image_uploader\ntripleo_common/image/image_uploader.py:1242:32: E1101: Class \'BaseImageUploader\' has no \'_global_view_proxy\' member (no-member)\ntripleo_common/image/image_uploader.py:1245:16: E1101: Class \'BaseImageUploader\' has no \'_track_uploaded_layers\' member (no-member)\ntripleo_common/image/image_uploader.py:1258:16: E1101: Class \'BaseImageUploader\' has no \'_global_view_proxy\' member (no-member)\n\nChange-Id: I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee\n'}, {'number': 2, 'created': '2020-12-16 14:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/99dbd10162d2ab3c62070b75436686e46ef22cdf', 'message': 'Enable pylint and fix no-member issue\n\n- enables pylint with most checks temporary disabled, so we have time\n  to address them gradually\n- fix ""no-member"" check which could have prevented regression like the\n  one we had on:\n\nChange-Id: I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee\nFollow-Up: https://review.opendev.org/c/openstack/tripleo-common/+/762892/6/tripleo_common/image/builder/buildah.py\n'}, {'number': 3, 'created': '2020-12-21 14:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dfcbaf9244068b45badbb99af318af4a059a4894', 'message': 'Enable pylint\n\nThis is a follow-up from [1] which underlined that the code lacks even basic coverage as it allow\nus to introduce a costly regression which could have being detected by pylint no-member test.\n\n- enables pylint with most checks temporary disabled, so we have time\n  to address them gradually\n- fixes few minor issues reported by the tool\n- adds skips for some known ""no-member"" errors but avoids adding it to the exclude list, as this\n  in order to prevent further regressions.\n- once landed we can easily address the temporary disabled errors, one by one. In fact this is could\n  prove as a very good learning experience for newer team members. They can start by removing on\n  random exclusion and fixing it. As a hint: leave the missing docstrings for the end, some problems\n  are more important to fix first.\n\n1: https://review.opendev.org/c/openstack/tripleo-common/+/762892/6/tripleo_common/image/builder/buildah.py\n\nChange-Id: I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee\n'}, {'number': 4, 'created': '2020-12-21 14:06:49.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', '.pylintrc', 'tripleo_common/utils/locks/processlock.py', 'tripleo_common/tests/utils/test_template.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/exception.py', 'tripleo_common/utils/locks/base.py', '.pre-commit-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/13ac87ba36be2d8cddb37cd82d242dcb0a8717f5', 'message': 'Enable pylint\n\nThis is a follow-up from [1] which underlined that the code lacks even basic coverage as it allow\nus to introduce a costly regression which could have being detected by pylint no-member test.\n\n- enables pylint with most checks temporary disabled, so we have time\n  to address them gradually\n- fixes few minor issues reported by the tool\n- adds skips for some known ""no-member"" errors but avoids adding it to the exclude list, as this\n  in order to prevent further regressions.\n- once landed we can easily address the temporary disabled errors, one by one. In fact this is could\n  prove as a very good learning experience for newer team members. They can start by removing on\n  random exclusion and fixing it. As a hint: leave the missing docstrings for the end, some problems\n  are more important to fix first.\n\n1: https://review.opendev.org/c/openstack/tripleo-common/+/762892/6/tripleo_common/image/builder/buildah.py\n\nChange-Id: I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee\n'}]",6,767358,13ac87ba36be2d8cddb37cd82d242dcb0a8717f5,22,8,4,24162,,,0,"Enable pylint

This is a follow-up from [1] which underlined that the code lacks even basic coverage as it allow
us to introduce a costly regression which could have being detected by pylint no-member test.

- enables pylint with most checks temporary disabled, so we have time
  to address them gradually
- fixes few minor issues reported by the tool
- adds skips for some known ""no-member"" errors but avoids adding it to the exclude list, as this
  in order to prevent further regressions.
- once landed we can easily address the temporary disabled errors, one by one. In fact this is could
  prove as a very good learning experience for newer team members. They can start by removing on
  random exclusion and fixing it. As a hint: leave the missing docstrings for the end, some problems
  are more important to fix first.

1: https://review.opendev.org/c/openstack/tripleo-common/+/762892/6/tripleo_common/image/builder/buildah.py

Change-Id: I10ab0cbfbaab77b9208e9a5d74d59eb041cb16ee
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/58/767358/4 && git format-patch -1 --stdout FETCH_HEAD,"['.pylintrc', 'tripleo_common/image/image_uploader.py', 'tripleo_common/exception.py', '.pre-commit-config.yaml']",4,0264090fa972ccfec9b236c1ef58ef83aea9cc9c,pylint, rev: v3.4.0 rev: 3.8.4 - repo: https://github.com/PyCQA/pylint rev: pylint-2.6.0 hooks: - id: pylint # additional_dependencies: # - ansible-base # - enrich>=1.2 # - subprocess-tee>=0.1.5 # - testinfra, rev: v2.5.0 rev: 3.8.1,86,3
openstack%2Fdevstack~stable%2Ftrain~I02c692e95d70017eea03d82d75ae6c5e87bde8b1,openstack/devstack,stable/train,I02c692e95d70017eea03d82d75ae6c5e87bde8b1,Install swift keystone extras requirements,MERGED,2020-12-22 18:29:47.000000000,2021-01-07 13:27:14.000000000,2021-01-07 13:25:15.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 28006}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-22 18:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7ae3aa2d361c748b5a18c8a84e1413871ebd50a', 'message': ""Install swift extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n""}, {'number': 2, 'created': '2020-12-22 19:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8b617653dac6150252b651b9bfc06e00c5a1306d', 'message': ""Install swift extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift extra requirements also.\n\nDepends-On: https://review.opendev.org/c/openstack/swift/+/766214\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n""}, {'number': 3, 'created': '2020-12-22 19:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/60c598540832c301f823e9fd69d032a9cf2f1232', 'message': ""Install swift extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n""}, {'number': 4, 'created': '2020-12-23 20:07:01.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a7c4377c17b6ca4a73a786af9cc6b1c502cd8061', 'message': ""Install swift keystone extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift keystone extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)\n(cherry picked from commit 90651cb1a914999afd1dd1e4929c04e62fefb4c8)\n(cherry picked from commit 10fdf258bacf4702917f1bbdffef933e7a89907a)\n""}]",0,768256,a7c4377c17b6ca4a73a786af9cc6b1c502cd8061,25,5,4,8556,,,0,"Install swift keystone extras requirements

Since the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264
s-proxy is no longer able to launch as keystonemiddleware (listed under
test-requirements.txt) has not been installed.

keystonemiddleware is listed as extras requirements in swift
- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79

Let's install swift keystone extra requirements also.

Closes-Bug: #1909018
Change-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1
(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)
(cherry picked from commit 90651cb1a914999afd1dd1e4929c04e62fefb4c8)
(cherry picked from commit 10fdf258bacf4702917f1bbdffef933e7a89907a)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/768256/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,b7ae3aa2d361c748b5a18c8a84e1413871ebd50a,bug/1909018, setup_develop $SWIFT_DIR keystone, setup_develop $SWIFT_DIR,1,1
openstack%2Fpython-openstackclient~master~I7a8349106e211c57c4577b75326b39b88bd9ac1e,openstack/python-openstackclient,master,I7a8349106e211c57c4577b75326b39b88bd9ac1e,compute: Fix 'server * -f yaml' output,MERGED,2020-11-03 17:22:47.000000000,2021-01-07 13:27:02.000000000,2021-01-07 13:24:42.000000000,"[{'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2020-11-03 17:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/57640717ede2ce4d7d63d116cc8e9c6ef260d4b3', 'message': ""compute: Format list of tags for 'server list'\n\nCurrently, the output looks like:\n\n  | tags   | ['bar', 'foo']  |\n\nFix this, so things display correctly:\n\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2020-11-05 12:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fb525c1abb767525c63fd351831499d2bd2e78fe', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2020-11-06 09:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9c8e507d672ba29704b1cbe448cf0474ed853b53', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2020-11-06 11:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b49891ac68c596d2391e026676ae9e7a22214401', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2020-11-17 17:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4462319a34e7245aab04ab28a826c419e4ff8c2d', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 6, 'created': '2020-11-18 10:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fdb0a10a585a1599def100f30af8a63329ded9c1', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 7, 'created': '2020-11-19 14:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/660d10b35cf9de495c98197aad7cfef2214ef866', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 8, 'created': '2020-12-08 16:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/64f089623d1232df08326556da71448ece893566', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 9, 'created': '2020-12-09 15:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/634bac2a10932b38b939d0f88b72afbc84d262ff', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 10, 'created': '2021-01-06 12:03:06.000000000', 'files': ['releasenotes/notes/improved-server-output-6965b664f6abda8d.yaml', 'openstackclient/tests/functional/compute/v2/test_server.py', 'openstackclient/tests/unit/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/03776d82e58622b30b90260ed9c374b0cfc70f2b', 'message': ""compute: Fix 'server * -f yaml' output\n\nMake use of 'FormattableColumn'-derived formatters, which provide better\noutput than what we were using before, particularly for the YAML output\nformat. For example, compare before for the 'server show' command:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',\n    ram='512', swap='0', vcpus='1'\n  ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml\n  ...\n  addresses:\n    private:\n    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n    - 10.0.0.44\n  flavor:\n    disk: 1\n    ephemeral: 0\n    extra_specs:\n      hw_rng:allowed: 'True'\n    original_name: m1.tiny\n    ram: 512\n    swap: 0\n    vcpus: 1\n  ...\n\nSimilarly, compare before for 'server list':\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44\n    Power State: Running\n    Properties: ''\n    ...\n\nTo after:\n\n  $ openstack --os-compute-api-version 2.79 server list -f yaml\n  - ...\n    Networks:\n      private:\n      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944\n      - 10.0.0.44\n    Power State: 1\n    Properties: {}\n    ...\n\nWe also fix the human-readable output for the 'tags' field.\n\nBefore:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | ['bar', 'foo']  |\n\nAfter:\n\n  $ openstack --os-compute-api-version 2.79 server list\n  ...\n  | tags   | bar, foo  |\n\nChange-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,761205,03776d82e58622b30b90260ed9c374b0cfc70f2b,33,4,10,15334,,,0,"compute: Fix 'server * -f yaml' output

Make use of 'FormattableColumn'-derived formatters, which provide better
output than what we were using before, particularly for the YAML output
format. For example, compare before for the 'server show' command:

  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml
  ...
  addresses: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44
  flavor: disk='1', ephemeral='0', extra_specs.hw_rng:allowed='True', original_name='m1.tiny',
    ram='512', swap='0', vcpus='1'
  ...

To after:

  $ openstack --os-compute-api-version 2.79 server show test-server -f yaml
  ...
  addresses:
    private:
    - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944
    - 10.0.0.44
  flavor:
    disk: 1
    ephemeral: 0
    extra_specs:
      hw_rng:allowed: 'True'
    original_name: m1.tiny
    ram: 512
    swap: 0
    vcpus: 1
  ...

Similarly, compare before for 'server list':

  $ openstack --os-compute-api-version 2.79 server list -f yaml
  - ...
    Networks: private=fdff:77e3:9bb4:0:f816:3eff:fe6d:a944, 10.0.0.44
    Power State: Running
    Properties: ''
    ...

To after:

  $ openstack --os-compute-api-version 2.79 server list -f yaml
  - ...
    Networks:
      private:
      - fdff:77e3:9bb4:0:f816:3eff:fe6d:a944
      - 10.0.0.44
    Power State: 1
    Properties: {}
    ...

We also fix the human-readable output for the 'tags' field.

Before:

  $ openstack --os-compute-api-version 2.79 server list
  ...
  | tags   | ['bar', 'foo']  |

After:

  $ openstack --os-compute-api-version 2.79 server list
  ...
  | tags   | bar, foo  |

Change-Id: I7a8349106e211c57c4577b75326b39b88bd9ac1e
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/05/761205/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/server.py'],1,57640717ede2ce4d7d63d116cc8e9c6ef260d4b3,trivial, if 'tags' in info: info.update({'tags': format_columns.ListColumn(info.pop('tags'))}) ,,3,0
openstack%2Fneutron~master~Ifafb327f5b2e2a4b9e46e07cf896e29f9f24f8a4,openstack/neutron,master,Ifafb327f5b2e2a4b9e46e07cf896e29f9f24f8a4,[L3] Document QoS support in Neutron,MERGED,2020-12-24 10:02:13.000000000,2021-01-07 13:26:57.000000000,2021-01-07 13:24:23.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-24 10:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e681507bcc25aded55866ede30e03e9b60a06a71', 'message': '[L3] Document QoS support in Neutron\n\nDocument the existing QoS extensions provided (for L3 router and\nOVN L3) and the QoS rules supported (bandwidth limit).\n\nChange-Id: Ifafb327f5b2e2a4b9e46e07cf896e29f9f24f8a4\n'}, {'number': 2, 'created': '2021-01-04 14:27:42.000000000', 'files': ['doc/source/admin/config-qos.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/74490e09ffcce6d5ef3fa7936dc60cf8c5db845d', 'message': '[L3] Document QoS support in Neutron\n\nDocument the existing QoS extensions provided (for L3 router and\nOVN L3) and the QoS rules supported (bandwidth limit).\n\nChange-Id: Ifafb327f5b2e2a4b9e46e07cf896e29f9f24f8a4\n'}]",2,768459,74490e09ffcce6d5ef3fa7936dc60cf8c5db845d,18,5,2,16688,,,0,"[L3] Document QoS support in Neutron

Document the existing QoS extensions provided (for L3 router and
OVN L3) and the QoS rules supported (bandwidth limit).

Change-Id: Ifafb327f5b2e2a4b9e46e07cf896e29f9f24f8a4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/768459/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/config-qos.rst'],1,e681507bcc25aded55866ede30e03e9b60a06a71,l3_qos_doc,"L3 QoS support ~~~~~~~~~~~~~~ The Neutron L3 services have implemented their own QoS extensions. Currently only bandwidth limit QoS is provided. This is the L3 QoS extension list: * Floating IP bandwidth limit: the rate limit is applied per floating IP address independently (remember that floating IPs can be only IPv4). * Gateway IP bandwidth limit: the rate limit is applied in the router namespace gateway port (or in the SNAT namespace in case of DVR edge router). The rate limit applies to the gateway IP; that means all traffic using this gateway IP will be limited. This rate limit does not apply to the floating IP traffic. L3 services that provide QoS extensions: * L3 router: implements the rate limit using `Linux TC <https://man7.org/linux/man-pages/man8/tc.8.html>`_. * OVN L3: implements the rate limit using the `OVN QoS metering rules <https://man7.org/linux/man-pages/man8/ovn-nbctl.8.html#LOGICAL_SWITCH_QOS_RULE_COMMANDS>`_. The following table shows the L3 service, the QoS supported extension, and traffic directions (from the VM point of view) for **bandwidth limiting**. .. table:: **L3 service, supported extension, and traffic direction** ==================== =================== =================== Rule \\ L3 service L3 router OVN L3 ==================== =================== =================== Floating IP Egress \\ Ingress Egress \\ Ingress Gateway IP Egress \\ Ingress - ==================== =================== =================== ",,37,0
openstack%2Fneutron~stable%2Fvictoria~Ic1d5f893a81b7b841745da82f38b7583e47e468d,openstack/neutron,stable/victoria,Ic1d5f893a81b7b841745da82f38b7583e47e468d,Add locks for methods which sets nat rules in router,MERGED,2020-12-04 11:45:47.000000000,2021-01-07 13:26:54.000000000,2021-01-07 13:24:16.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-12-04 11:45:47.000000000', 'files': ['neutron/agent/l3/router_info.py', 'neutron/agent/l3/extensions/port_forwarding.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3df5a8715b1a6b53d3c3c08aa553950b2c25c95', 'message': ""Add locks for methods which sets nat rules in router\n\nRouter_info class and port_forwarding L3 extensions are using same\ninstance of the iptables manager class and it could happend that\nmethod which sets address scope rules and method which sets\nport forwarding nat rules where run in almost same time and\none of them was adding rules which wasn't expected to be added.\nBecause of that port forwarding rules wasn't configured properly.\n\nThis patch fixed that by adding lock for methods which are changing\nrules in iptables_manager's nat table in both router_info and\nport_forwarding extension.\n\nChange-Id: Ic1d5f893a81b7b841745da82f38b7583e47e468d\nCloses-Bug: #1896735\n(cherry picked from commit 2325ad1950412d3eef0cde848c56bb94fbbb7495)\n""}]",0,765411,d3df5a8715b1a6b53d3c3c08aa553950b2c25c95,18,4,1,11975,,,0,"Add locks for methods which sets nat rules in router

Router_info class and port_forwarding L3 extensions are using same
instance of the iptables manager class and it could happend that
method which sets address scope rules and method which sets
port forwarding nat rules where run in almost same time and
one of them was adding rules which wasn't expected to be added.
Because of that port forwarding rules wasn't configured properly.

This patch fixed that by adding lock for methods which are changing
rules in iptables_manager's nat table in both router_info and
port_forwarding extension.

Change-Id: Ic1d5f893a81b7b841745da82f38b7583e47e468d
Closes-Bug: #1896735
(cherry picked from commit 2325ad1950412d3eef0cde848c56bb94fbbb7495)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/765411/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/router_info.py', 'neutron/agent/l3/extensions/port_forwarding.py']",2,d3df5a8715b1a6b53d3c3c08aa553950b2c25c95,bug/1896735-stable/victoria, @coordination.synchronized('router-lock-ns-{namespace}') @coordination.synchronized('router-lock-ns-{namespace}') @coordination.synchronized('router-lock-ns-{namespace}'), @coordination.synchronized('port-forwarding-{namespace}') @coordination.synchronized('port-forwarding-{namespace}') @coordination.synchronized('port-forwarding-{namespace}'),6,3
openstack%2Fdevstack~stable%2Fussuri~I02c692e95d70017eea03d82d75ae6c5e87bde8b1,openstack/devstack,stable/ussuri,I02c692e95d70017eea03d82d75ae6c5e87bde8b1,Install swift keystone extras requirements,MERGED,2020-12-22 18:29:23.000000000,2021-01-07 13:26:38.000000000,2021-01-07 13:24:56.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-22 18:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a0270d2522e12f3fd5152b837c82f323622f5ee1', 'message': ""Install swift extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n""}, {'number': 2, 'created': '2020-12-23 20:06:16.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/10fdf258bacf4702917f1bbdffef933e7a89907a', 'message': ""Install swift keystone extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift keystone extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)\n(cherry picked from commit 90651cb1a914999afd1dd1e4929c04e62fefb4c8)\n""}]",0,768175,10fdf258bacf4702917f1bbdffef933e7a89907a,21,4,2,8556,,,0,"Install swift keystone extras requirements

Since the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264
s-proxy is no longer able to launch as keystonemiddleware (listed under
test-requirements.txt) has not been installed.

keystonemiddleware is listed as extras requirements in swift
- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79

Let's install swift keystone extra requirements also.

Closes-Bug: #1909018
Change-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1
(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)
(cherry picked from commit 90651cb1a914999afd1dd1e4929c04e62fefb4c8)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/75/768175/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,a0270d2522e12f3fd5152b837c82f323622f5ee1,bug/1909018, setup_develop $SWIFT_DIR keystone, setup_develop $SWIFT_DIR,1,1
openstack%2Fgovernance~master~I07dad33fc1cda89f0a57025b2c62247164e8b583,openstack/governance,master,I07dad33fc1cda89f0a57025b2c62247164e8b583,Deprecate neutron-fwaas and neutron-fwaas-dashboard master branch,MERGED,2020-06-16 09:24:31.000000000,2021-01-07 13:20:36.000000000,2020-06-18 18:14:23.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-06-16 09:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/2c5a6aac1bb4aafcdbccf68ad9892a3b9ab44a53', 'message': 'Retire neutron-fwaas and neutron-fwaas-dashboard from openstack/\n\nThose projects were part of the neutron stadium but during the Shanghai\nPTG we agreed to deprecate them due to lack of maintainers.\nNow, as there is still no maintainers for those projects, lets remove\nthem out of the stadium.\nProject rename patch is proposed at [1]\n\n[1] https://review.opendev.org/#/c/735812/\n\nChange-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583\n'}, {'number': 2, 'created': '2020-06-16 10:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/6bdf50d32d40f2446e22e55dfd84e1c0a4f5080d', 'message': 'Deprecatre neutron-fwaas and neutron-fwaas-dashboard master branch\n\nThose projects were part of the neutron stadium but during the Shanghai\nPTG we agreed to deprecate them due to lack of maintainers.\nNow, as there is still no maintainers for those projects,\nlets deprecate their master branch and stop development there.\n\nStable branches will be still maintained until their EOL.\n\nChange-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583\n'}, {'number': 3, 'created': '2020-06-16 20:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/f7778b1ed84074ad728b27923039a3df3bb970ef', 'message': 'Deprecatre neutron-fwaas and neutron-fwaas-dashboard master branch\n\nThose projects were part of the neutron stadium but during the Shanghai\nPTG we agreed to deprecate them due to lack of maintainers.\nNow, as there is still no maintainers for those projects,\nlets deprecate their master branch and stop development there.\n\nStable branches will be still maintained until their EOL.\n\nChange-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583\n'}, {'number': 4, 'created': '2020-06-17 21:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a7398e28df8059c81930523931fe6133ad922f90', 'message': 'Deprecatre neutron-fwaas and neutron-fwaas-dashboard master branch\n\nThose projects were part of the neutron stadium but during the Shanghai\nPTG we agreed to deprecate them due to lack of maintainers.\nNow, as there is still no maintainers for those projects,\nlets deprecate their master branch and stop development there.\n\nStable branches will be still maintained until their EOL.\n\nDepends-On: https://review.opendev.org/735829\nDepends-On: https://review.opendev.org/735831\nChange-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583\n'}, {'number': 5, 'created': '2020-06-17 21:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/c2a300e690c2e952eb2b6944f63814145380938d', 'message': 'Deprecatre neutron-fwaas and neutron-fwaas-dashboard master branch\n\nThose projects were part of the neutron stadium but during the Shanghai\nPTG we agreed to deprecate them due to lack of maintainers.\nNow, as there is still no maintainers for those projects,\nlets deprecate their master branch and stop development there.\n\nStable branches will be still maintained until their EOL.\n\nChange-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583\n'}, {'number': 6, 'created': '2020-06-18 07:04:02.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/aa1ddd464f6adcaa5406f1eeadac804f62edab88', 'message': 'Deprecate neutron-fwaas and neutron-fwaas-dashboard master branch\n\nThose projects were part of the neutron stadium but during the Shanghai\nPTG we agreed to deprecate them due to lack of maintainers.\nNow, as there is still no maintainers for those projects,\nlets deprecate their master branch and stop development there.\n\nStable branches will be still maintained until their EOL.\n\nDepends-On: https://review.opendev.org/#/c/735850/\n\nChange-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583\n'}]",2,735828,aa1ddd464f6adcaa5406f1eeadac804f62edab88,31,7,6,11975,,,0,"Deprecate neutron-fwaas and neutron-fwaas-dashboard master branch

Those projects were part of the neutron stadium but during the Shanghai
PTG we agreed to deprecate them due to lack of maintainers.
Now, as there is still no maintainers for those projects,
lets deprecate their master branch and stop development there.

Stable branches will be still maintained until their EOL.

Depends-On: https://review.opendev.org/#/c/735850/

Change-Id: I07dad33fc1cda89f0a57025b2c62247164e8b583
",git fetch https://review.opendev.org/openstack/governance refs/changes/28/735828/1 && git format-patch -1 --stdout FETCH_HEAD,"['reference/legacy.yaml', 'reference/projects.yaml']",2,2c5a6aac1bb4aafcdbccf68ad9892a3b9ab44a53,project-update,, neutron-fwaas: repos: - openstack/neutron-fwaas tags: - stable:follows-policy - assert:follows-standard-deprecation neutron-fwaas-dashboard: repos: - openstack/neutron-fwaas-dashboard,8,9
openstack%2Fneutron-vpnaas~master~I30ed6e8d2d7b47234caa32901d6e79ced976e30e,openstack/neutron-vpnaas,master,I30ed6e8d2d7b47234caa32901d6e79ced976e30e,Add doc/requirements,ABANDONED,2021-01-05 15:11:26.000000000,2021-01-07 13:19:44.000000000,,"[{'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 15:11:26.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/ddccda3cb8bf48fb167a590b0fe4a747f1689795', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: I30ed6e8d2d7b47234caa32901d6e79ced976e30e\n'}]",1,769380,ddccda3cb8bf48fb167a590b0fe4a747f1689795,8,2,1,11975,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: I30ed6e8d2d7b47234caa32901d6e79ced976e30e
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/80/769380/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,ddccda3cb8bf48fb167a590b0fe4a747f1689795,fix-relmgt-pip-doc,deps = {[testenv:docs]deps}deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,6,3
openstack%2Ftripleo-quickstart-extras~master~I72e8586acb0bfd7194fa08c08d849a6073373aff,openstack/tripleo-quickstart-extras,master,I72e8586acb0bfd7194fa08c08d849a6073373aff,Switch to python3 venv by default,MERGED,2020-11-25 19:36:25.000000000,2021-01-07 13:19:09.000000000,2021-01-07 13:19:09.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-11-25 19:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/82e9512315ea5c249afdfecbcd4e09fa868a15f7', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 2, 'created': '2020-11-26 14:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/842c9c45c31f8f5815e055df483369321a3a317f', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 3, 'created': '2020-12-01 13:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/852049f25c8aa5d1043bb7d52d3f4c0087c52688', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 4, 'created': '2020-12-08 12:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4f5dec08c278c6998d870cf79a4d463c402f1f05', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 5, 'created': '2020-12-09 11:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5da1bca5edd4cf5ca5876a59e9d47a0f07f7c352', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 6, 'created': '2020-12-09 12:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8f7feaabece2d58edb6f5da120a60e4a65705cea', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 7, 'created': '2020-12-10 20:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6cd33f19105c89a897ccbadd60a09b1f9f5f0c96', 'message': 'Switch to python3 venv by default\n\nUse python3 to create virtualenv. Jobs may enforce py2 by\nsetting python_cmd.\n\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\nRelated-Bug: #1905386\n'}, {'number': 8, 'created': '2021-01-06 11:32:40.000000000', 'files': ['roles/build-test-packages/defaults/main.yml', 'roles/build-test-packages/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8cd2e1dd01b105337e0ef4e3bc6594d108d7ae28', 'message': ""Switch to python3 venv by default\n\nUse python3 to create virtualenv for dlrn, [1][2]\nalready switched quickstart and toci to use python3 venv.\n\nAlso remove contextlib2 hack which was added for python2\nvirtualenv as part of #1863632 and #1867023.\n\nSince using python3 native venv module let's remove\nvirtualenv detection and installation tasks.\n\nRelated-Bug: #1867023\nRelated-Bug: #1905386\nRelated-Bug: #1863632\nChange-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff\n""}]",13,764232,8cd2e1dd01b105337e0ef4e3bc6594d108d7ae28,45,10,8,8175,,,0,"Switch to python3 venv by default

Use python3 to create virtualenv for dlrn, [1][2]
already switched quickstart and toci to use python3 venv.

Also remove contextlib2 hack which was added for python2
virtualenv as part of #1863632 and #1867023.

Since using python3 native venv module let's remove
virtualenv detection and installation tasks.

Related-Bug: #1867023
Related-Bug: #1905386
Related-Bug: #1863632
Change-Id: I72e8586acb0bfd7194fa08c08d849a6073373aff
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/32/764232/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/build-test-packages/defaults/main.yml', 'roles/build-test-packages/tasks/main.yml']",2,82e9512315ea5c249afdfecbcd4e09fa868a15f7,venv-py3," {% if python_cmd == ""python3"" %} {% if python_cmd == ""python3"" %} pip install -r requirements.txt; {{ python_cmd }} setup.py install;", {% if ansible_python.version.major == 3 %} {% if ansible_python.version.major == 3 %} pip{{ ansible_python.version.major }} install -r requirements.txt; python{{ ansible_python.version.major }} setup.py install;,5,4
openstack%2Fneutron-vpnaas~master~Ic0e80b78ba55279a677f808557382656841546ab,openstack/neutron-vpnaas,master,Ic0e80b78ba55279a677f808557382656841546ab,Fix l-c testing for Ubuntu Focal (py38),ABANDONED,2020-09-17 15:53:26.000000000,2021-01-07 13:15:29.000000000,,"[{'_account_id': 841}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-09-17 15:53:26.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/550a820427c195f4eaa5198e694fe1a82dd3822d', 'message': 'Fix l-c testing for Ubuntu Focal (py38)\n\nChange-Id: Ic0e80b78ba55279a677f808557382656841546ab\nStory: 2007865\nTask: 40199\nCloses-Bug: #1886298\n'}]",0,752494,550a820427c195f4eaa5198e694fe1a82dd3822d,14,4,1,32067,,,0,"Fix l-c testing for Ubuntu Focal (py38)

Change-Id: Ic0e80b78ba55279a677f808557382656841546ab
Story: 2007865
Task: 40199
Closes-Bug: #1886298
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/94/752494/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,550a820427c195f4eaa5198e694fe1a82dd3822d,,cffi==1.14.0greenlet==0.4.15MarkupSafe==1.1.1paramiko==2.7.1PyYAML==3.13,cffi==1.7.0greenlet==0.4.10MarkupSafe==1.0paramiko==2.0.0PyYAML==3.12,5,5
openstack%2Fironic~stable%2Fussuri~I32bce7d22d8bfba8ef757b1342faf28f6b89d00c,openstack/ironic,stable/ussuri,I32bce7d22d8bfba8ef757b1342faf28f6b89d00c,Cap version of ipa-builder to 2.2.0,ABANDONED,2020-12-16 17:06:36.000000000,2021-01-07 13:10:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-16 17:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/765278a03724b8e32094c0e6aeb0268c97b70918', 'message': 'Cap version of ipa-builder to 2.2.0\n\nVersions higher than 2.2.0 of ironic-python-agent-builder use\ntinycore 11.x to build tinyipa, and that uses a kernel too recent\nto be built on bionic.\n\nChange-Id: I32bce7d22d8bfba8ef757b1342faf28f6b89d00c\n'}, {'number': 2, 'created': '2021-01-07 13:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3f6d24e8476918379bbd89ded12330766b782dfb', 'message': 'Cap version of ipa-builder to 2.2.0\n\nVersions higher than 2.2.0 of ironic-python-agent-builder use\ntinycore 11.x to build tinyipa, and that uses a kernel too recent\nto be built on bionic.\n\nChange-Id: I32bce7d22d8bfba8ef757b1342faf28f6b89d00c\n'}]",0,767379,3f6d24e8476918379bbd89ded12330766b782dfb,8,1,2,23851,,,0,"Cap version of ipa-builder to 2.2.0

Versions higher than 2.2.0 of ironic-python-agent-builder use
tinycore 11.x to build tinyipa, and that uses a kernel too recent
to be built on bionic.

Change-Id: I32bce7d22d8bfba8ef757b1342faf28f6b89d00c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/79/767379/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,765278a03724b8e32094c0e6aeb0268c97b70918,, - name: openstack/ironic-python-agent-builder override-checkout: 2.2.0 - name: openstack/ironic-python-agent-builder override-checkout: 2.2.0 - name: openstack/ironic-python-agent-builder override-checkout: 2.2.0, - openstack/ironic-python-agent-builder - openstack/ironic-python-agent-builder - openstack/ironic-python-agent-builder,6,3
openstack%2Fneutron~stable%2Fussuri~Ic1d5f893a81b7b841745da82f38b7583e47e468d,openstack/neutron,stable/ussuri,Ic1d5f893a81b7b841745da82f38b7583e47e468d,Add locks for methods which sets nat rules in router,MERGED,2020-12-04 11:46:27.000000000,2021-01-07 12:59:41.000000000,2021-01-07 12:58:12.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-04 11:46:27.000000000', 'files': ['neutron/agent/l3/router_info.py', 'neutron/agent/l3/extensions/port_forwarding.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/941aae1b5671f91be975fdac724c31367ca0605d', 'message': ""Add locks for methods which sets nat rules in router\n\nRouter_info class and port_forwarding L3 extensions are using same\ninstance of the iptables manager class and it could happend that\nmethod which sets address scope rules and method which sets\nport forwarding nat rules where run in almost same time and\none of them was adding rules which wasn't expected to be added.\nBecause of that port forwarding rules wasn't configured properly.\n\nThis patch fixed that by adding lock for methods which are changing\nrules in iptables_manager's nat table in both router_info and\nport_forwarding extension.\n\nChange-Id: Ic1d5f893a81b7b841745da82f38b7583e47e468d\nCloses-Bug: #1896735\n(cherry picked from commit 2325ad1950412d3eef0cde848c56bb94fbbb7495)\n""}]",0,765412,941aae1b5671f91be975fdac724c31367ca0605d,9,3,1,11975,,,0,"Add locks for methods which sets nat rules in router

Router_info class and port_forwarding L3 extensions are using same
instance of the iptables manager class and it could happend that
method which sets address scope rules and method which sets
port forwarding nat rules where run in almost same time and
one of them was adding rules which wasn't expected to be added.
Because of that port forwarding rules wasn't configured properly.

This patch fixed that by adding lock for methods which are changing
rules in iptables_manager's nat table in both router_info and
port_forwarding extension.

Change-Id: Ic1d5f893a81b7b841745da82f38b7583e47e468d
Closes-Bug: #1896735
(cherry picked from commit 2325ad1950412d3eef0cde848c56bb94fbbb7495)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/765412/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/router_info.py', 'neutron/agent/l3/extensions/port_forwarding.py']",2,941aae1b5671f91be975fdac724c31367ca0605d,bug/1896735-stable/victoria-stable/ussuri, @coordination.synchronized('router-lock-ns-{namespace}') @coordination.synchronized('router-lock-ns-{namespace}') @coordination.synchronized('router-lock-ns-{namespace}'), @coordination.synchronized('port-forwarding-{namespace}') @coordination.synchronized('port-forwarding-{namespace}') @coordination.synchronized('port-forwarding-{namespace}'),6,3
openstack%2Fironic-python-agent~stable%2Ftrain~Ide0f6c38a59ae6486fa33cfb19b383d022e57d5a,openstack/ironic-python-agent,stable/train,Ide0f6c38a59ae6486fa33cfb19b383d022e57d5a,"CI: Remove l-c job, set ipa-b to 2.2.0",MERGED,2020-12-17 19:13:44.000000000,2021-01-07 12:55:09.000000000,2021-01-07 12:50:10.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-17 19:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/754485be10bd7326cf1f213a57e9785899e37a94', 'message': 'CI: Remove l-c job, set ipa-b to 2.2.0\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nAlso Cap version of ipa-builder to 2.2.0\n\nVersions higher than 2.2.0 of ironic-python-agent-builder use\ntinycore 11.x to build tinyipa, and that uses a kernel too recent\nto be built on bionic.\n\nChange-Id: Ide0f6c38a59ae6486fa33cfb19b383d022e57d5a\n'}, {'number': 2, 'created': '2021-01-04 18:36:46.000000000', 'files': ['zuul.d/ironic-python-agent-jobs.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/10059c535fe7b77d8d73918ca1316cfcc856b351', 'message': 'CI: Remove l-c job, set ipa-b to 2.2.0\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nAlso Cap version of ipa-builder to 2.2.0\n\nVersions higher than 2.2.0 of ironic-python-agent-builder use\ntinycore 11.x to build tinyipa, and that uses a kernel too recent\nto be built on bionic.\n\nAnd removes explict settings to force python2 use as CI jobs now\npull in some newer version of packages which require python3.\n\nExample: bandit 1.7.0 now requires Python3\n\nChange-Id: Ide0f6c38a59ae6486fa33cfb19b383d022e57d5a\n'}]",0,767622,10059c535fe7b77d8d73918ca1316cfcc856b351,19,2,2,11655,,,0,"CI: Remove l-c job, set ipa-b to 2.2.0

As discussed during the upstream ironic community meeting on
Monday Dec 14 2020, the lower-constraints job is being removed.

Also Cap version of ipa-builder to 2.2.0

Versions higher than 2.2.0 of ironic-python-agent-builder use
tinycore 11.x to build tinyipa, and that uses a kernel too recent
to be built on bionic.

And removes explict settings to force python2 use as CI jobs now
pull in some newer version of packages which require python3.

Example: bandit 1.7.0 now requires Python3

Change-Id: Ide0f6c38a59ae6486fa33cfb19b383d022e57d5a
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/22/767622/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-python-agent-jobs.yaml', 'zuul.d/project.yaml']",2,754485be10bd7326cf1f213a57e9785899e37a94,remove-l-c-job,, - openstack-tox-lower-constraints - openstack-tox-lower-constraints,11,3
openstack%2Fcharm-ceph-rbd-mirror~master~I423eb38f5197879c5f8f7999acb11ece3d26a6a4,openstack/charm-ceph-rbd-mirror,master,I423eb38f5197879c5f8f7999acb11ece3d26a6a4,Handle RBD mirroring mode set in the relation,MERGED,2020-11-19 12:23:29.000000000,2021-01-07 12:53:18.000000000,2021-01-07 12:53:18.000000000,"[{'_account_id': 13178}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-19 12:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/e51384903c9c9cb7498b9e7987c8da3a8b9bf18d', 'message': 'Handle RBD mirroring mode set in the relation\n\nChange-Id: I423eb38f5197879c5f8f7999acb11ece3d26a6a4\nCo-authored-by: Marius Oprin <morpin@cloudbasesolutions.com>\nSigned-off-by: Marius Oprin <moprin@cloudbasesolutions.com>\n'}, {'number': 2, 'created': '2020-12-02 10:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/930245ec3512351239b29a9c22c8a5520c5c5eb4', 'message': 'Handle RBD mirroring mode set in the relation\n\nChange-Id: I423eb38f5197879c5f8f7999acb11ece3d26a6a4\nCo-authored-by: Marius Oprin <morpin@cloudbasesolutions.com>\nSigned-off-by: Marius Oprin <moprin@cloudbasesolutions.com>\n'}, {'number': 3, 'created': '2020-12-15 13:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/8eabb679b72854b54d7e57ee9d5d2e0e3a49d600', 'message': 'Handle RBD mirroring mode set in the relation\n\nChange-Id: I423eb38f5197879c5f8f7999acb11ece3d26a6a4\nCo-authored-by: Marius Oprin <morpin@cloudbasesolutions.com>\nSigned-off-by: Marius Oprin <moprin@cloudbasesolutions.com>\n'}, {'number': 4, 'created': '2020-12-15 13:52:18.000000000', 'files': ['unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/reactive/ceph_rbd_mirror_handlers.py', 'unit_tests/test_ceph_rbd_mirror_handlers.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/3562e11bda8d28e1c8de552fc95fd6544511e66b', 'message': 'Handle RBD mirroring mode set in the relation\n\nChange-Id: I423eb38f5197879c5f8f7999acb11ece3d26a6a4\nCo-authored-by: Marius Oprin <morpin@cloudbasesolutions.com>\nSigned-off-by: Marius Oprin <moprin@cloudbasesolutions.com>\n'}]",1,763363,3562e11bda8d28e1c8de552fc95fd6544511e66b,23,4,4,32431,,,0,"Handle RBD mirroring mode set in the relation

Change-Id: I423eb38f5197879c5f8f7999acb11ece3d26a6a4
Co-authored-by: Marius Oprin <morpin@cloudbasesolutions.com>
Signed-off-by: Marius Oprin <moprin@cloudbasesolutions.com>
",git fetch https://review.opendev.org/openstack/charm-ceph-rbd-mirror refs/changes/63/763363/4 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/reactive/ceph_rbd_mirror_handlers.py', 'unit_tests/test_ceph_rbd_mirror_handlers.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py']",4,e51384903c9c9cb7498b9e7987c8da3a8b9bf18d,cinder-ceph-replication," def mirror_pool_enabled(self, pool, mode='pool'): return self._mirror_pool_info(pool).get('mode', None) == mode def mirror_pool_enable(self, pool, mode='pool'): subprocess.check_call(base_cmd + ['enable', pool, mode]) def pool_mirroring_mode(self, pool, broker_requests=[]): """"""Get the Ceph RBD mirroring mode for the pool. Checks if the pool RBD mirroring mode was explicitly set as part of the 'create-pool' operation into any of the given broker requests. If this is true, its value is returned, otherwise the default 'pool' mirroring mode is used. :param pool: Pool name :type pool: str :param broker_requests: List of broker requests :type broker_requests: List[ch_ceph.CephBrokerRq] :returns: Ceph RBD mirroring mode :rtype: str """""" default_mirroring_mode = 'pool' for rq in broker_requests: if not rq: continue assert rq.api_version == 1 for op in rq.ops: if op['op'] == 'create-pool' and op['name'] == pool: return op.get( 'rbd-mirroring-mode', default_mirroring_mode) return default_mirroring_mode "," def mirror_pool_enabled(self, pool): return self._mirror_pool_info(pool).get('mode', None) == 'pool' def mirror_pool_enable(self, pool): subprocess.check_call(base_cmd + ['enable', pool, 'pool'])",110,12
openstack%2Ftripleo-common~stable%2Ftrain~I8616775584cf0216314109d21dabd32635293a27,openstack/tripleo-common,stable/train,I8616775584cf0216314109d21dabd32635293a27,Fix ImportWarning during importing a module,MERGED,2020-12-25 20:14:10.000000000,2021-01-07 12:38:16.000000000,2021-01-07 12:36:25.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 32240}]","[{'number': 1, 'created': '2020-12-25 20:14:10.000000000', 'files': ['tripleo_common/utils/config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b657dd95d910735dc84310419472c012c76517b4', 'message': 'Fix ImportWarning during importing a module\n\nSet warnings category to filter only DeprecationWarnings\nand UserWarning\n\nCloses-Bug: #1889380\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I8616775584cf0216314109d21dabd32635293a27\n(cherry picked from commit c296d83eaa6edc9d14f76fc2995857f3646dac75)\n'}]",0,768408,b657dd95d910735dc84310419472c012c76517b4,11,6,1,14985,,,0,"Fix ImportWarning during importing a module

Set warnings category to filter only DeprecationWarnings
and UserWarning

Closes-Bug: #1889380
Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: I8616775584cf0216314109d21dabd32635293a27
(cherry picked from commit c296d83eaa6edc9d14f76fc2995857f3646dac75)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/08/768408/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/config.py'],1,b657dd95d910735dc84310419472c012c76517b4,bug/1889380-stable/train,"warnings.filterwarnings('once', category=DeprecationWarning) warnings.filterwarnings('once', category=UserWarning)",warnings.filterwarnings('once'),2,1
openstack%2Fcharms.openstack~master~Id3bb13aff6d0e6df2d5ec144689c992cf09c1b4c,openstack/charms.openstack,master,Id3bb13aff6d0e6df2d5ec144689c992cf09c1b4c,Support upgrades to Trilio 4.1,MERGED,2021-01-06 21:42:43.000000000,2021-01-07 12:37:45.000000000,2021-01-07 12:37:45.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 21:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/c5fcbbd5be040dd57c2ad2f0177f27d4494f6a12', 'message': 'Support upgrades to Trilio 4.1\n\nAdding support for Trilio 4.1 includes the following changes:\n\n* Add Trilio_properties config property to enables templates to distinguish\n  between 4.0 and 4.1 release.\n* Add get_trilio_codename_install_source to attempt to derive the Trilio\n  version supported by an apt repo.\n* Add get_trilio_charm_instance which overrides the default get_charm_instance.\n  This will pick the correct charm class based on both the Trilio release and\n  the OpenStack release.\n* Add select_trilio_release which overrides the default select_release and\n  calculates the target OpenStack and Trilio release.\n* Add a specialist Trilio metaclass BaseTrilioCharmMeta. This registers\n  charm classes using their OpenStack release, Trilio release and package\n  type.\n* Move code shared between TrilioVaultCharm & TrilioVaultSubordinateCharm\n  to TrilioVaultCharmMixin. Add support for Trilio upgrades to\n  TrilioVaultCharmMixina.\n\nChange-Id: Id3bb13aff6d0e6df2d5ec144689c992cf09c1b4c\n'}, {'number': 2, 'created': '2021-01-07 09:57:54.000000000', 'files': ['charms_openstack/plugins/trilio.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/plugins/test_trilio.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/2520764264e10d1ec6077f5472c038ab462df1c2', 'message': 'Support upgrades to Trilio 4.1\n\nAdding support for Trilio 4.1 includes the following changes:\n\n* Add Trilio_properties config property to enables templates to\n  distinguish between 4.0 and 4.1 release.\n* Add get_trilio_codename_install_source to attempt to derive the\n  Trilio version supported by an apt repo.\n* Add get_trilio_charm_instance which overrides the default\n  get_charm_instance.  This will pick the correct charm class based\n  on both the Trilio release and the OpenStack release.\n* Add select_trilio_release which overrides the default\n  select_release and calculates the target OpenStack and Trilio\n  release.\n* Add a specialist Trilio metaclass BaseTrilioCharmMeta. This\n  registers charm classes using their OpenStack release, Trilio\n  release and package type.\n* Move code shared between TrilioVaultCharm &\n  TrilioVaultSubordinateCharm to TrilioVaultCharmMixin. Add support\n  for Trilio upgrades to TrilioVaultCharmMixina.\n\nNOTE: An earlier version of this change\n      (I5a5e5721d9a713b66f8c796896c400481e9733a2) was landed and\n      reverted. It was reverted because get_trilio_charm_instance\n      and select_trilio_release were both registered as handlers\n      irrespective of whether a charm explicitly imported\n      charms_openstack.plugins.trilio This caused reactive charms\n      which used the default handlers to fail as they imported the\n      Trilio functions and the default ones and only one can ever\n      registered. This patch fixes this by wrapping the trilio\n      function definitions inside make_* methods, so the decorator\n      only registers the methods when the make_* methods are\n      explicitly called.\n\nChange-Id: Id3bb13aff6d0e6df2d5ec144689c992cf09c1b4c\n'}]",0,769621,2520764264e10d1ec6077f5472c038ab462df1c2,8,2,2,12549,,,0,"Support upgrades to Trilio 4.1

Adding support for Trilio 4.1 includes the following changes:

* Add Trilio_properties config property to enables templates to
  distinguish between 4.0 and 4.1 release.
* Add get_trilio_codename_install_source to attempt to derive the
  Trilio version supported by an apt repo.
* Add get_trilio_charm_instance which overrides the default
  get_charm_instance.  This will pick the correct charm class based
  on both the Trilio release and the OpenStack release.
* Add select_trilio_release which overrides the default
  select_release and calculates the target OpenStack and Trilio
  release.
* Add a specialist Trilio metaclass BaseTrilioCharmMeta. This
  registers charm classes using their OpenStack release, Trilio
  release and package type.
* Move code shared between TrilioVaultCharm &
  TrilioVaultSubordinateCharm to TrilioVaultCharmMixin. Add support
  for Trilio upgrades to TrilioVaultCharmMixina.

NOTE: An earlier version of this change
      (I5a5e5721d9a713b66f8c796896c400481e9733a2) was landed and
      reverted. It was reverted because get_trilio_charm_instance
      and select_trilio_release were both registered as handlers
      irrespective of whether a charm explicitly imported
      charms_openstack.plugins.trilio This caused reactive charms
      which used the default handlers to fail as they imported the
      Trilio functions and the default ones and only one can ever
      registered. This patch fixes this by wrapping the trilio
      function definitions inside make_* methods, so the decorator
      only registers the methods when the make_* methods are
      explicitly called.

Change-Id: Id3bb13aff6d0e6df2d5ec144689c992cf09c1b4c
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/21/769621/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_openstack/plugins/trilio.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/plugins/test_trilio.py']",3,c5fcbbd5be040dd57c2ad2f0177f27d4494f6a12,trilio-4.1-upgrades-mk2,"from unit_tests.utils import BaseTestCase, patch_open import charms_openstack.charm.core as co_core os_release_pkg = 'nova-common' @classmethod def trilio_version_package(cls): return ""dmapi"" self.patch_object(trilio.fetch.apt_pkg, 'version_compare') def test_trilio_properties(self): cls_mock = mock.MagicMock() cls_mock.charm_instance.release_pkg_version = lambda: '4.0' self.version_compare.return_value = 0 self.assertEqual( trilio.trilio_properties(cls_mock), {'db_type': 'dedicated', 'transport_type': 'dmapi'}) self.version_compare.return_value = -1 self.assertEqual( trilio.trilio_properties(cls_mock), {'db_type': 'legacy', 'transport_type': 'legacy'}) def test_get_trilio_codename_install_source(self): self.assertEqual( trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata-4-0/ /'), '4.0') self.assertEqual( trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata-4-0-0/ /'), '4.0') with self.assertRaises(AssertionError): trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata/ /') def test_get_trilio_charm_instance(self): _safe_gcif = co_core._get_charm_instance_function co_core._get_charm_instance_function = None class BaseClass(): def __init__(self, release, *args, **kwargs): pass class Pike39(BaseClass): release = 'pike' trilio_release = '3.9' class Queens40(BaseClass): release = 'queens' trilio_release = '4.0' class Queens41(BaseClass): release = 'queens' trilio_release = '4.1' class Rocky40(BaseClass): release = 'rocky' trilio_release = '4.0' def _version_compare(ver1, ver2): if float(ver1) > float(ver2): return 1 elif float(ver1) < float(ver2): return -1 else: return 0 save_releases = trilio._trilio_releases self.version_compare.side_effect = _version_compare trilio._trilio_releases = { 'pike': { trilio.AptPkgVersion('3.9'): { 'deb': Pike39}}, 'queens': { trilio.AptPkgVersion('4.0'): { 'deb': Queens40}, trilio.AptPkgVersion('4.1'): { 'deb': Queens41}}, 'rocky': { trilio.AptPkgVersion('4.0'): { 'deb': Rocky40}}} trilio.make_trilio_get_charm_instance_handler() # Check with no release being supplied. Should return the # highest release class. self.assertIsInstance( co_core.get_charm_instance(), Rocky40) self.assertIsInstance( co_core.get_charm_instance(release='queens_4.0'), Queens40) self.assertIsInstance( co_core.get_charm_instance(release='queens_4.1'), Queens41) # Ensure an error is raised if a class satisfying the trilio condition # is not found for the highest matching OpenStack class. with self.assertRaises(RuntimeError): co_core.get_charm_instance(release='rocky_3.9') # Match the openstack release and then the closest trilio releases # within that subset. self.assertIsInstance( co_core.get_charm_instance(release='rocky_4.1'), Rocky40) with self.assertRaises(RuntimeError): co_core.get_charm_instance(release='icehouse_4.1') trilio._trilio_releases = save_releases co_core._get_charm_instance_function = _safe_gcif def test_select_trilio_release(self): def get_charm_class(release_pkg='trilio_pkg', package_version='4.0', os_codename_exception=None, version_package='trilio_pkg', package_version_exception=None, os_release_pkg='nova_pkg', os_codename_pkg='queens', trilio_source='deb https://a.io/trilio-4-2-0/ /'): class _TrilioCharm(): def __init__(self): self.release_pkg = release_pkg self.version_package = version_package self.os_release_pkg = os_release_pkg self.source_config_key = 'openstack-origin' self.package_codenames = {} self.package_version = package_version self.os_codename_exception = os_codename_exception self.os_codename_pkg = os_codename_pkg self.trilio_source = trilio_source @staticmethod def get_os_codename_package(pkg, code_names, apt_cache_sufficient=True): if os_codename_exception: raise os_codename_exception else: return os_codename_pkg @staticmethod def get_package_version(pkg, apt_cache_sufficient=True): if package_version_exception: raise package_version_exception else: return package_version return _TrilioCharm() _safe_rsf = co_core._release_selector_function co_core._release_selector_function = None self.patch_object( trilio.os_utils, ""get_installed_semantic_versioned_packages"") self.patch_object(trilio.os_utils, ""os_release"") self.patch_object(trilio.unitdata, ""kv"") kv_mock = mock.MagicMock() self.kv.return_value = kv_mock kv_mock.get.return_value = None self.patch_object( trilio.charms_openstack.charm.core, ""get_charm_instance"") trilio.make_trilio_get_charm_instance_handler() trilio.make_trilio_select_release_handler() select_trilio_release = co_core._release_selector_function self.get_charm_instance.return_value = get_charm_class() self.assertEqual( select_trilio_release(), 'queens_4.0') # Check RuntimeError is raised if release_pkg is missing from charm # class self.get_charm_instance.return_value = get_charm_class( release_pkg=None) with self.assertRaises(RuntimeError): select_trilio_release() # Test falling back to get_installed_semantic_versioned_packages self.os_release.return_value = 'pike' self.get_installed_semantic_versioned_packages.reset_mock() self.get_installed_semantic_versioned_packages.return_value = ['nova'] self.get_charm_instance.return_value = get_charm_class( os_codename_pkg=None) self.assertEqual( select_trilio_release(), 'pike_4.0') # Check RuntimeError is raised if version_package is missing from charm # class self.get_charm_instance.return_value = get_charm_class( version_package=None) with self.assertRaises(RuntimeError): select_trilio_release() # Test falling back to get_trilio_codename_install_source self.get_charm_instance.return_value = get_charm_class( package_version_exception=ValueError) self.assertEqual( select_trilio_release(), 'queens_4.2') co_core._release_selector_function = _safe_rsf self.patch_object(trilio.ch_core.hookenv, ""log"") self.patch_object(trilio.ch_core.hookenv, ""status_set"") self.patch_object( trilio.charms_openstack.charm.core, ""get_charm_instance"") self.patch_object(trilio.fetch, ""apt_update"") self.patch_object(trilio.fetch, ""apt_install"") self.patch_object(trilio.fetch.apt_pkg, ""version_compare"") self.patch_target('config') self._conf = { 'triliovault-pkg-source': 'deb https://a.io/trilio-4-2-0/ /' } self.config.get.side_effect = lambda x, b=None: self._conf.get(x, b) def test_trilio_source(self): self.assertEqual( self.target.trilio_source, 'deb https://a.io/trilio-4-2-0/ /') def test_do_trilio_pkg_upgrade(self): self.target.do_trilio_pkg_upgrade() self.apt_update.assert_called_once_with() self.apt_install.assert_called_once_with( packages=['foo', 'bar'], options=[ '--option', 'Dpkg::Options::=--force-confnew', '--option', 'Dpkg::Options::=--force-confdef'], fatal=True) def test_run_trilio_upgrade(self): self.patch_target('get_os_codename_package') self.get_os_codename_package.return_value = 'queens' charm_cls = mock.MagicMock() interface_mocks = [mock.MagicMock(), mock.MagicMock()] self.get_charm_instance.return_value = charm_cls self.target.run_trilio_upgrade(interfaces_list=interface_mocks) self._configure_triliovault_source.assert_called_once_with() charm_cls.do_trilio_pkg_upgrade.assert_called_once_with() charm_cls.render_with_interfaces.assert_called_once_with( interface_mocks) charm_cls.do_trilio_upgrade_db_migration.assert_called_once_with() def test_trilio_upgrade_available(self): self.patch_target('get_package_version') self.get_package_version.return_value = '4.1' self.version_compare.return_value = 1 self.assertTrue(self.target.trilio_upgrade_available()) self.version_compare.assert_called_once_with('4.2', '4.1') def test_upgrade_if_available(self): self.patch_target('openstack_upgrade_available') self.patch_target('trilio_upgrade_available') self.patch_target('run_upgrade') self.patch_target('run_trilio_upgrade') interface_mocks = [mock.MagicMock(), mock.MagicMock()] self._conf['action-managed-upgrade'] = False self.openstack_upgrade_available.return_value = True self.trilio_upgrade_available.return_value = True self.target.upgrade_if_available(interface_mocks) self.run_upgrade.assert_called_once_with( interfaces_list=interface_mocks) self.run_trilio_upgrade.assert_called_once_with( interfaces_list=interface_mocks) self.run_upgrade.reset_mock() self.run_trilio_upgrade.reset_mock() self._conf['action-managed-upgrade'] = True self.openstack_upgrade_available.return_value = True self.trilio_upgrade_available.return_value = True self.target.upgrade_if_available(interface_mocks) self.assertFalse(self.run_upgrade.called) self.assertFalse(self.run_trilio_upgrade.called) self.patch_object(trilio.fetch, ""apt_update"") self.apt_update.assert_called_once_with(fatal=True) class TestBaseTrilioCharmMeta(BaseTestCase): def setUp(self): self.save_releases = trilio._trilio_releases super().setUp() self.patch_object(trilio.fetch.apt_pkg, 'version_compare') def _version_compare(ver1, ver2): if float(ver1) > float(ver2): return 1 elif float(ver1) < float(ver2): return -1 else: return 0 self.version_compare.side_effect = _version_compare def tearDown(self): super().tearDown() trilio._trilio_releases = self.save_releases def register_classes(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' class TrilioQueens41(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.1' class TrilioRocky40(metaclass=trilio.BaseTrilioCharmMeta): release = 'rocky' trilio_release = '4.0' return { 'queens_4.0': TrilioQueens40, 'queens_4.1': TrilioQueens41, 'rocky_4.0': TrilioRocky40} def register_classes_missing_key(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' def register_classes_wrong_pkg_type(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.1' package_type = 'up2date' def register_classes_duplicate(self): class TrilioQueens40A(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' class TrilioQueens40B(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' def test_class_register(self): charm_classes = self.register_classes() self.maxDiff = None self.assertEqual( trilio._trilio_releases, { 'queens': { trilio.AptPkgVersion('4.0'): { 'deb': charm_classes['queens_4.0']}, trilio.AptPkgVersion('4.1'): { 'deb': charm_classes['queens_4.1']}}, 'rocky': { trilio.AptPkgVersion('4.0'): { 'deb': charm_classes['rocky_4.0']}}}) def test_class_register_missing_key(self): with self.assertRaises(RuntimeError): self.register_classes_missing_key() def test_class_register_wrong_pkg_type(self): with self.assertRaises(RuntimeError): self.register_classes_wrong_pkg_type() def test_class_register_duplicate(self): with self.assertRaises(RuntimeError): self.register_classes_duplicate()","from unit_tests.utils import patch_open def test_series_upgrade_complete(self): self.patch_object(trilio.charms_openstack.charm.OpenStackCharm, 'series_upgrade_complete') self.patch_target('configure_source') self.target.series_upgrade_complete() self.configure_source.assert_called_once_with() def test_install(self): self.patch_object(trilio.charms_openstack.charm.OpenStackCharm, 'configure_source') self.target.install() self._install_triliovault.assert_called_once_with(self.target)",796,33
openstack%2Fpython-ironicclient~master~I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90,openstack/python-ironicclient,master,I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90,update hacking to new hacking 4.0.0,ABANDONED,2020-12-08 01:04:26.000000000,2021-01-07 12:21:35.000000000,,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-08 01:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/52aded2529adaa2edb70da460df78b497a5552c6', 'message': 'Move python-ironicclient to new hacking 4.0.0\n\nNew rule enforcement has been enabled in the latest hacking code.\nThis patch bumps new version of hacking in test-requirements file,\nfor early detection and to avoid code breakage later when hacking\nchanges are released.\n\nChange-Id: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90\n'}, {'number': 2, 'created': '2020-12-08 01:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/3e70698d342fb48cad4155a1ac11937cb59038ef', 'message': 'Move python-ironicclient to new hacking 4.0.0\n\nNew rule enforcement has been enabled in the latest hacking code.\nThis patch bumps new version of hacking in test-requirements file,\nfor early detection and to avoid code breakage later when hacking\nchanges are released.\n\nChange-Id: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90\n'}, {'number': 3, 'created': '2020-12-08 02:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4722596b87d49f892f1c926b9a399fd468846992', 'message': 'Move python-ironicclient to new hacking 4.0.0\n\nNew rule enforcement has been enabled in the latest hacking code.\nThis patch bumps new version of hacking in test-requirements file,\nfor early detection and to avoid code breakage later when hacking\nchanges are released.\n\nChange-Id: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90\n'}, {'number': 4, 'created': '2020-12-08 03:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/ecce3138d286c1a5cef7f1b401f3dc37b00a90a5', 'message': 'update package\n\nChange-Id: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90\n'}, {'number': 5, 'created': '2020-12-12 07:12:12.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e04f4274e721996b474b27dccc22e4fa18c7ea63', 'message': 'update hacking to new hacking 4.0.0\n\nNew rule enforcement has been enabled in the latest hacking code.\n\nThis patch bumps new version of hacking in test-requirements file,\nfor early detection and to avoid code breakage later when hacking\nchanges are released\n\nChange-Id: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90\n'}]",0,765893,e04f4274e721996b474b27dccc22e4fa18c7ea63,13,2,5,32029,,,0,"update hacking to new hacking 4.0.0

New rule enforcement has been enabled in the latest hacking code.

This patch bumps new version of hacking in test-requirements file,
for early detection and to avoid code breakage later when hacking
changes are released

Change-Id: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/93/765893/5 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,52aded2529adaa2edb70da460df78b497a5552c6,hacking,"hacking>=4.0.0,<4.1.0 # Apache-2.0","hacking>=3.1.0,<4.0.0 # Apache-2.0",1,1
openstack%2Fpython-ironicclient~master~I54b232d860795b16f8b40122a2017dc3591e1d71,openstack/python-ironicclient,master,I54b232d860795b16f8b40122a2017dc3591e1d71,Update doc8 version,ABANDONED,2020-12-20 02:55:33.000000000,2021-01-07 12:21:31.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-20 02:55:33.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/bc5326fe8de726fc6342798ac3b432d8ef944609', 'message': 'Update doc8 version\n\ndoc8 0.6.0 only supports python version less than 3.4\n\n[1] https://pypi.org/project/doc8/0.6.0/\n\nDepends-On: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90\nChange-Id: I54b232d860795b16f8b40122a2017dc3591e1d71\n'}]",0,767998,bc5326fe8de726fc6342798ac3b432d8ef944609,3,1,1,32029,,,0,"Update doc8 version

doc8 0.6.0 only supports python version less than 3.4

[1] https://pypi.org/project/doc8/0.6.0/

Depends-On: I98e2ddb8cbec53e3853c84f85ffd48fc9f8f0f90
Change-Id: I54b232d860795b16f8b40122a2017dc3591e1d71
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/98/767998/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,bc5326fe8de726fc6342798ac3b432d8ef944609,doc8,doc8>=0.8.1 # Apache-2.0,doc8>=0.6.0 # Apache-2.0,1,1
openstack%2Fkuryr-kubernetes~stable%2Ftrain~I98ecd4dc041b271303ccbb4da61e33fa1a95800b,openstack/kuryr-kubernetes,stable/train,I98ecd4dc041b271303ccbb4da61e33fa1a95800b,Fix CI issues,MERGED,2020-12-15 10:05:52.000000000,2021-01-07 11:57:53.000000000,2021-01-07 09:36:26.000000000,"[{'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-12-15 10:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c0da43b7a940e6ce58d5aa5e3d59aa58edcaadc6', 'message': ""Fix CI issues\n\nUpdate the DevStack plugin to query for docker's cgroup driver correctly,\nbecause the old way suddenly stopped working.\n\nChange-Id: I98ecd4dc041b271303ccbb4da61e33fa1a95800b\n""}, {'number': 2, 'created': '2020-12-15 12:30:01.000000000', 'files': ['test-requirements.txt', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/24a1c31b8ba1bc3419ee54f86323886538879355', 'message': ""Fix CI issues\n\nThis fixes several CI problems:\n\n* Update the DevStack plugin to query for docker's cgroup driver\n  correctly, because the old way suddenly stopped working.\n* Cap bandit to 1.6.2 to keep it on version supporting py27.\n\nChange-Id: I98ecd4dc041b271303ccbb4da61e33fa1a95800b\n""}]",0,767110,24a1c31b8ba1bc3419ee54f86323886538879355,19,3,2,11600,,,0,"Fix CI issues

This fixes several CI problems:

* Update the DevStack plugin to query for docker's cgroup driver
  correctly, because the old way suddenly stopped working.
* Cap bandit to 1.6.2 to keep it on version supporting py27.

Change-Id: I98ecd4dc041b271303ccbb4da61e33fa1a95800b
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/10/767110/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,c0da43b7a940e6ce58d5aa5e3d59aa58edcaadc6,," command+="" --cgroup-driver $(docker info -f '{{.CgroupDriver}}')"""," command+="" --cgroup-driver $(docker info|awk '/Cgroup/ {print $NF}')""",1,1
openstack%2Fswift~master~I76cc7cf6a0ba2f20ef7e14e894c69fc8190a2434,openstack/swift,master,I76cc7cf6a0ba2f20ef7e14e894c69fc8190a2434,Add probe test coverage for shard overlap resolution,ABANDONED,2020-12-01 15:14:40.000000000,2021-01-07 11:53:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-01 15:14:40.000000000', 'files': ['bin/swift-container-sharder', 'swift/common/utils.py', 'test/unit/container/test_sharder.py', 'test/probe/test_sharder.py', 'swift/container/sharder.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/24b0d1f49863cc9e3b0d37fea14c480028d1621c', 'message': 'Add probe test coverage for shard overlap resolution\n\nExtends an existing probe test to verify that overlapping shard ranges\nmay be resolved by shrinking a subset of the shard ranges.\n\nAlso:\n - Adds a --auto-shard option to swift-container-sharder to enable the\n   probe tests to disable auto-sharding.\n\n - Improves sharder logging, in particular by decrementing ranges_todo\n   when a shrinking shard is skipped during cleaving.\n\n - Adds a ShardRange.sort_key class method to provide a single definition\n   of ShardRange sort ordering.\n\n - Improves unit test coverage for sharder shard auditing.\n\nRelated-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\nChange-Id: I76cc7cf6a0ba2f20ef7e14e894c69fc8190a2434\n'}]",0,764951,24b0d1f49863cc9e3b0d37fea14c480028d1621c,3,1,1,7847,,,0,"Add probe test coverage for shard overlap resolution

Extends an existing probe test to verify that overlapping shard ranges
may be resolved by shrinking a subset of the shard ranges.

Also:
 - Adds a --auto-shard option to swift-container-sharder to enable the
   probe tests to disable auto-sharding.

 - Improves sharder logging, in particular by decrementing ranges_todo
   when a shrinking shard is skipped during cleaving.

 - Adds a ShardRange.sort_key class method to provide a single definition
   of ShardRange sort ordering.

 - Improves unit test coverage for sharder shard auditing.

Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6
Change-Id: I76cc7cf6a0ba2f20ef7e14e894c69fc8190a2434
",git fetch https://review.opendev.org/openstack/swift refs/changes/51/764951/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-container-sharder', 'swift/common/utils.py', 'test/unit/container/test_sharder.py', 'test/probe/test_sharder.py', 'swift/container/sharder.py', 'swift/container/backend.py']",6,24b0d1f49863cc9e3b0d37fea14c480028d1621c,p-shard-audit-shrinking, shard_ranges.sort(key=ShardRange.sort_key)," # note if this ever changes to *not* sort by upper first then it breaks # a key assumption for bisect, which is used by utils.find_shard_ranges shard_ranges.sort(key=lambda sr: ( sr.upper, sr.state, sr.lower, sr.name))",381,161
openstack%2Fswift~master~Ib913aebc4459530f42ac24de77621113906baba2,openstack/swift,master,Ib913aebc4459530f42ac24de77621113906baba2,Only merge shard ranges from root when SHRINKING or SHRUNK,ABANDONED,2020-11-25 13:10:02.000000000,2021-01-07 11:51:20.000000000,,"[{'_account_id': 1179}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 13:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b09562d0a0dea365bf9f81f1b5d004ec2d9081f', 'message': ""Only merge shard ranges from root when shrinking\n\nDuring shard container audit, overlapping shard ranges discovered from\nroot are merged into the shard's db. This patch restricts that\nbehavior to when the shard is in shrinking state, since this is the\nonly state in which a shard container needs to discover shards from\nthe root.\n\nIn general, a shard is responsible for processing its own sub-shard\nranges (if any) and reporting them to root. Replicas of a shard\ncontainer synchronise their sub-shard ranges via replication, and do\nnot rely on the root to propagate sub-shard ranges between shard\nreplicas. The exception to this is when a third party (or\nauto-sharding) wishes to instigate shrinking by modifying the shard\nand other acceptor shards in the root container, and then have the\nshrinking shard discover its acceptor shards fom the root.\n\nIn other circumstances, the current behavior of shards always merging\noverlapping shard ranges discovered from the root risks shard\ninheriting undesirable shards from the root. For example, if the root\nhas become polluted by split-brain shard range management, a sharding\nshard may have its sub-shards polluted by an undesired shard from the\nroot.\n\nChange-Id: Ib913aebc4459530f42ac24de77621113906baba2\n""}, {'number': 2, 'created': '2020-11-27 21:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e3976a33bafa93f6b238b3da70c756678d94a9ef', 'message': ""Only merge shard ranges from root when shrinking\n\nDuring shard container audit, overlapping shard ranges discovered from\nroot are merged into the shard's db. This patch restricts that\nbehavior to when the shard is in shrinking or sharded state.\n\nThe only time during which a shard container needs to discover shards\nfrom the root is while shrinking.  Ideally we'd only allow merging of\nshard ranges from root in shrinking state, but we need to also allow\nit in the 'sharded' state because one replica of a shrinking shard may\nhave its own shard range already moved to 'sharded' by another\nreplica. This is non-ideal because a shard may also be in sharded\nstate while sharding, not shrinking.\n\nIn general, a shard is responsible for processing its own sub-shard\nranges (if any) and reporting them to root. Replicas of a shard\ncontainer synchronise their sub-shard ranges via replication, and do\nnot rely on the root to propagate sub-shard ranges between shard\nreplicas. The exception to this is when a third party (or\nauto-sharding) wishes to instigate shrinking by modifying the shard\nand other acceptor shards in the root container, and then have the\nshrinking shard discover its acceptor shards fom the root.\n\nIn other circumstances, the current behavior of shards always merging\noverlapping shard ranges discovered from the root risks shard\ninheriting undesirable shards from the root. For example, if the root\nhas become polluted by split-brain shard range management, a sharding\nshard may have its sub-shards polluted by an undesired shard from the\nroot.\n\nChange-Id: Ib913aebc4459530f42ac24de77621113906baba2\n""}, {'number': 3, 'created': '2020-11-30 16:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9064ddc1a6ac74cd3704c19dad7128a982633e44', 'message': ""Only merge shard ranges from root when shrinking\n\nDuring shard container audit, overlapping shard ranges discovered from\nroot are merged into the shard's db. This patch restricts that\nbehavior to when the shard is in shrinking or sharded state.\n\nThe only time during which a shard container needs to discover shards\nfrom the root is while shrinking.  Ideally we'd only allow merging of\nshard ranges from root in shrinking state, but we need to also allow\nit in the 'sharded' state because one replica of a shrinking shard may\nhave its own shard range already moved to 'sharded' by another\nreplica. This is non-ideal because a shard may also be in sharded\nstate while sharding, not shrinking.\n\nIn general, a shard is responsible for processing its own sub-shard\nranges (if any) and reporting them to root. Replicas of a shard\ncontainer synchronise their sub-shard ranges via replication, and do\nnot rely on the root to propagate sub-shard ranges between shard\nreplicas. The exception to this is when a third party (or\nauto-sharding) wishes to instigate shrinking by modifying the shard\nand other acceptor shards in the root container, and then have the\nshrinking shard discover its acceptor shards fom the root.\n\nIn other circumstances, the current behavior of shards always merging\noverlapping shard ranges discovered from the root risks shard\ninheriting undesirable shards from the root. For example, if the root\nhas become polluted by split-brain shard range management, a sharding\nshard may have its sub-shards polluted by an undesired shard from the\nroot.\n\nThis patch also adds a '--auto-shard=[true|false]' option to\nswift-container-sharder so that probe tests can selectively disable\nauto-sharding.\n\nChange-Id: Ib913aebc4459530f42ac24de77621113906baba2\n""}, {'number': 4, 'created': '2020-12-01 15:14:40.000000000', 'files': ['swift/common/utils.py', 'test/unit/container/test_sharder.py', 'test/probe/test_sharder.py', 'swift/container/sharder.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2c3f97cc3c70c58afe5d61ad897a5cd5727c8d4c', 'message': ""Only merge shard ranges from root when SHRINKING or SHRUNK\n\nDuring shard container audit, overlapping shard ranges discovered from\nroot are merged into the shard's db. This patch restricts that\nbehavior to when the shard is in shrinking state or a new shrunk state.\n\nIn general, a shard is responsible for processing its own sub-shard\nranges (if any) and reporting them to root. Replicas of a shard\ncontainer synchronise their sub-shard ranges via replication, and do\nnot rely on the root to propagate sub-shard ranges between shard\nreplicas. The exception to this is when a third party (or\nauto-sharding) wishes to instigate shrinking by modifying the shard\nand other acceptor shards in the root container, and then have the\nshrinking shard discover its acceptor shards fom the root.\n\nIn other circumstances, the current behavior of shards always merging\noverlapping shard ranges discovered from the root is undesirable\nbecause it risks shards inheriting other unrelated shard ranges. For\nexample, if the root has become polluted by split-brain shard range\nmanagement, a sharding shard may have its sub-shards polluted by an\nundesired shard from the root.\n\nDuring the shrinking process a shard range's own shard range state may\nbe either shrinking or, prior to this patch, sharded. The sharded\nstate could occur when one replica of a shrinking shard completed\nshrinking and moved the own shard range state to sharded before other\nreplica(s) had completed shrinking. This makes it impossible to\ndistinguish a shrinking shard (with sharded state), which we do want\nto inherit shard ranges, from a sharding shard (with sharded state),\nwhich we do not want to inherit shard ranges.\n\nThis patch therefore introduces a new shard range state, 'SHRUNK', and\napplies this state to shard ranges that have completed shrinking.\nShards are now restricted to inherit shard ranges from the root only\nwhen their own shard range state is either SHRINKING or SHRUNK.\n\nChange-Id: Ib913aebc4459530f42ac24de77621113906baba2\n""}]",0,764163,2c3f97cc3c70c58afe5d61ad897a5cd5727c8d4c,11,2,4,7847,,,0,"Only merge shard ranges from root when SHRINKING or SHRUNK

During shard container audit, overlapping shard ranges discovered from
root are merged into the shard's db. This patch restricts that
behavior to when the shard is in shrinking state or a new shrunk state.

In general, a shard is responsible for processing its own sub-shard
ranges (if any) and reporting them to root. Replicas of a shard
container synchronise their sub-shard ranges via replication, and do
not rely on the root to propagate sub-shard ranges between shard
replicas. The exception to this is when a third party (or
auto-sharding) wishes to instigate shrinking by modifying the shard
and other acceptor shards in the root container, and then have the
shrinking shard discover its acceptor shards fom the root.

In other circumstances, the current behavior of shards always merging
overlapping shard ranges discovered from the root is undesirable
because it risks shards inheriting other unrelated shard ranges. For
example, if the root has become polluted by split-brain shard range
management, a sharding shard may have its sub-shards polluted by an
undesired shard from the root.

During the shrinking process a shard range's own shard range state may
be either shrinking or, prior to this patch, sharded. The sharded
state could occur when one replica of a shrinking shard completed
shrinking and moved the own shard range state to sharded before other
replica(s) had completed shrinking. This makes it impossible to
distinguish a shrinking shard (with sharded state), which we do want
to inherit shard ranges, from a sharding shard (with sharded state),
which we do not want to inherit shard ranges.

This patch therefore introduces a new shard range state, 'SHRUNK', and
applies this state to shard ranges that have completed shrinking.
Shards are now restricted to inherit shard ranges from the root only
when their own shard range state is either SHRINKING or SHRUNK.

Change-Id: Ib913aebc4459530f42ac24de77621113906baba2
",git fetch https://review.opendev.org/openstack/swift refs/changes/63/764163/4 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/container/test_sharder.py', 'swift/container/sharder.py']",2,9b09562d0a0dea365bf9f81f1b5d004ec2d9081f,p-shard-audit-shrinking," # iff we find our own shard range in the root response, merge it # and reload own shard range (note: own_range_from_root may not # necessarily be 'newer' than the own shard range we already have, # but merging will get us to the 'newest' state) self.logger.debug('Updating own shard range from root') broker.merge_shard_ranges(own_shard_range_from_root) if own_shard_range.state == ShardRange.SHRINKING: # if the up-to-date state is shrinking, save off *all* shards # returned because these may contain shards into which this # shard is to shrink itself; shrinking is the only case when we # want to learn about *other* shard ranges from the root other_shard_ranges = [sr for sr in shard_ranges if sr is not own_shard_range_from_root] self.logger.debug('Updating %s other shard range(s) from root', len(other_shard_ranges)) broker.merge_shard_ranges(other_shard_ranges)"," # iff we find our own shard range in the root response, save off # *all* shards returned (including own_shard_range_from_root) # because, for example, these may contain shards into which this # shard is to shard itself self.logger.debug('Updating %s shard_range(s) from root', len(shard_ranges)) broker.merge_shard_ranges(shard_ranges)",99,129
openstack%2Fkuryr-kubernetes~master~I20bab73f3adcc12cc103ba82d2f2dfda9841efde,openstack/kuryr-kubernetes,master,I20bab73f3adcc12cc103ba82d2f2dfda9841efde,Skip unscheduled pods when handling NP creation,MERGED,2020-12-21 14:44:32.000000000,2021-01-07 11:45:23.000000000,2021-01-07 11:43:51.000000000,"[{'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2020-12-21 14:44:32.000000000', 'files': ['kuryr_kubernetes/controller/handlers/kuryrnetworkpolicy.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/d650962e84d23e8d81fe4e71188159cccce821d6', 'message': 'Skip unscheduled pods when handling NP creation\n\nThis is follow up to dce5939c242d44417b74e00382fd0a08a8c34f7b, as\napparently same problem can happen on NP creation. This patch makes sure\nwe skip unscheduled pods there too.\n\nChange-Id: I20bab73f3adcc12cc103ba82d2f2dfda9841efde\nCloses-Bug: 1904040\n'}]",0,768095,d650962e84d23e8d81fe4e71188159cccce821d6,12,3,1,11600,,,0,"Skip unscheduled pods when handling NP creation

This is follow up to dce5939c242d44417b74e00382fd0a08a8c34f7b, as
apparently same problem can happen on NP creation. This patch makes sure
we skip unscheduled pods there too.

Change-Id: I20bab73f3adcc12cc103ba82d2f2dfda9841efde
Closes-Bug: 1904040
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/95/768095/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/handlers/kuryrnetworkpolicy.py'],1,d650962e84d23e8d81fe4e71188159cccce821d6,bug/1904040, if (driver_utils.is_host_network(pod) or not driver_utils.is_pod_scheduled(pod)):, if driver_utils.is_host_network(pod):,2,1
openstack%2Fneutron-vpnaas~master~I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2,openstack/neutron-vpnaas,master,I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2,Fix inconsistency in requirements,MERGED,2021-01-06 16:18:48.000000000,2021-01-07 11:44:36.000000000,2021-01-07 11:43:19.000000000,"[{'_account_id': 12860}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 16:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/60673de82e41a6a6edc4a865d2c7b3a0115dfd63', 'message': 'Fix inconsistency in requirements\n\nThe latest pip resolver started to check requirements strictly\nand it detects many inconsistencies in neutron-vpnaas requirements.\nAlso applies the practices discussed in the mailing list [1][2].\n\n* Drop pyflakes from requirements.txt as it is not used.\n* Move document dependencies to doc/requirements.txt [1]\n  and drop them from lower-constriants.txt.\n* Bump MarkupSafe lower-constraint to 1.1.1\n  to make it work with newer setuptools.\n* Bump the minimum neutron requirement to 17.0.0 (victoria release)\n  as the previous min version 13.0.0.0b2 is too old.\n  Wallaby and Victoria neutron are not different much, so I think\n  it is no problem to use the latest released version here.\n* Dependenicy related to neutron min version bump are updated\n  in requirements and lower-constraints.\n  Note that eventlet 0.22.0 is used as lower-constraints as 0.21.0\n  (the min requirement in neutron 17.0.0) is blocked in several libs.\n* Move linter dependencies to tox.ini and drop them from\n  lower-constraints.txt (pylint, pyflakes, astroid, isort)\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019362.html\n\nChange-Id: I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2\n'}, {'number': 2, 'created': '2021-01-06 18:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/9c6064921752847c4ea23701d1678e4632dde7d7', 'message': 'Fix inconsistency in requirements\n\nThe latest pip resolver started to check requirements strictly\nand it detects many inconsistencies in neutron-vpnaas requirements.\nAlso applies the practices discussed in the mailing list [1][2].\n\n* Drop pyflakes from requirements.txt as it is not used.\n* Move document dependencies to doc/requirements.txt [1]\n  and drop them from lower-constriants.txt.\n* Bump MarkupSafe lower-constraint to 1.1.1\n  to make it work with newer setuptools.\n* Bump the minimum neutron requirement to 17.0.0 (victoria release)\n  as the previous min version 13.0.0.0b2 is too old.\n  Wallaby and Victoria neutron are not different much, so I think\n  it is no problem to use the latest released version here.\n* Dependenicy related to neutron min version bump are updated\n  in requirements and lower-constraints.\n  Note that eventlet 0.22.0 is used as lower-constraints as 0.21.0\n  (the min requirement in neutron 17.0.0) is blocked in several libs.\n* Move linter dependencies to tox.ini and drop them from\n  lower-constraints.txt (pylint, pyflakes, astroid, isort)\n\nIn addition, hacking version is updated as hacking 0.12.0 is not compatible\nwith python 3.8. W504 and I202 are ignored as we do in the neutron repo.\nOther new flake8 violations are fixed.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019362.html\n\nChange-Id: I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2\n'}, {'number': 3, 'created': '2021-01-06 18:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/dfa1045505cabd234fcd7ff8f8d3eae656017ada', 'message': 'Fix inconsistency in requirements\n\nThe latest pip resolver started to check requirements strictly\nand it detects many inconsistencies in neutron-vpnaas requirements.\nAlso applies the practices discussed in the mailing list [1][2].\n\n* Drop pyflakes from requirements.txt as it is not used.\n* Move document dependencies to doc/requirements.txt [1]\n  and drop them from lower-constriants.txt.\n* Bump MarkupSafe lower-constraint to 1.1.1\n  to make it work with newer setuptools.\n* Bump the minimum neutron requirement to 17.0.0 (victoria release)\n  as the previous min version 13.0.0.0b2 is too old.\n  Wallaby and Victoria neutron are not different much, so I think\n  it is no problem to use the latest released version here.\n* Dependenicy related to neutron min version bump are updated\n  in requirements and lower-constraints.\n  Note that eventlet 0.22.0 is used as lower-constraints as 0.21.0\n  (the min requirement in neutron 17.0.0) is blocked in several libs.\n* Move linter dependencies to tox.ini and drop them from\n  lower-constraints.txt (pylint, pyflakes, astroid, isort)\n\nIn addition, hacking version is updated as hacking 0.12.0 is not compatible\nwith python 3.8. W504 and I202 are ignored as we do in the neutron repo.\nOther new flake8 violations are fixed.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019362.html\n\nChange-Id: I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2\n'}, {'number': 4, 'created': '2021-01-06 20:12:14.000000000', 'files': ['neutron_vpnaas/db/migration/alembic_migrations/versions/victoria/expand/5f884db48ba9_add_aggressive_negotiation_modes.py', 'requirements.txt', 'test-requirements.txt', 'rally-jobs/plugins/vpn_utils.py', 'neutron_vpnaas/services/vpn/common/netns_wrapper.py', 'lower-constraints.txt', 'neutron_vpnaas/extensions/vpnaas.py', 'doc/requirements.txt', 'tox.ini', 'neutron_vpnaas/tests/functional/requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/7c8262cf50daabc9afd3f45137c101a3b1c805c4', 'message': ""Fix inconsistency in requirements\n\nThe latest pip resolver started to check requirements strictly\nand it detects many inconsistencies in neutron-vpnaas requirements.\nAlso applies the practices discussed in the mailing list [1][2].\n\n* Drop pyflakes from requirements.txt as it is not used.\n* Move document dependencies to doc/requirements.txt [1]\n  and drop them from lower-constriants.txt.\n* Bump MarkupSafe lower-constraint to 1.1.1\n  to make it work with newer setuptools.\n* Bump the minimum neutron requirement to 17.0.0 (victoria release)\n  as the previous min version 13.0.0.0b2 is too old.\n  Wallaby and Victoria neutron are not different much, so I think\n  it is no problem to use the latest released version here.\n* Dependenicy related to neutron min version bump are updated\n  in requirements and lower-constraints.\n  Note that eventlet 0.22.0 is used as lower-constraints as 0.21.0\n  (the min requirement in neutron 17.0.0) is blocked in several libs.\n* Move linter dependencies to tox.ini and drop them from\n  lower-constraints.txt (pylint, pyflakes, astroid, isort)\n* Drop psutil from neutron_vpnaas/tests/functional/requirements.txt\n  as the specified version of psutil is too old and psutil is a dependency\n  of neutron so we don't need to install it explicitly here.\n\nIn addition, hacking version is updated as hacking 0.12.0 is not compatible\nwith python 3.8. W504 and I202 are ignored as we do in the neutron repo.\nOther new flake8 violations are fixed.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019362.html\n\nChange-Id: I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2\n""}]",0,769563,7c8262cf50daabc9afd3f45137c101a3b1c805c4,17,3,4,841,,,0,"Fix inconsistency in requirements

The latest pip resolver started to check requirements strictly
and it detects many inconsistencies in neutron-vpnaas requirements.
Also applies the practices discussed in the mailing list [1][2].

* Drop pyflakes from requirements.txt as it is not used.
* Move document dependencies to doc/requirements.txt [1]
  and drop them from lower-constriants.txt.
* Bump MarkupSafe lower-constraint to 1.1.1
  to make it work with newer setuptools.
* Bump the minimum neutron requirement to 17.0.0 (victoria release)
  as the previous min version 13.0.0.0b2 is too old.
  Wallaby and Victoria neutron are not different much, so I think
  it is no problem to use the latest released version here.
* Dependenicy related to neutron min version bump are updated
  in requirements and lower-constraints.
  Note that eventlet 0.22.0 is used as lower-constraints as 0.21.0
  (the min requirement in neutron 17.0.0) is blocked in several libs.
* Move linter dependencies to tox.ini and drop them from
  lower-constraints.txt (pylint, pyflakes, astroid, isort)
* Drop psutil from neutron_vpnaas/tests/functional/requirements.txt
  as the specified version of psutil is too old and psutil is a dependency
  of neutron so we don't need to install it explicitly here.

In addition, hacking version is updated as hacking 0.12.0 is not compatible
with python 3.8. W504 and I202 are ignored as we do in the neutron repo.
Other new flake8 violations are fixed.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019362.html

Change-Id: I47f6d39379b68c4d71fc4d85ebb06d97cb5a6ce2
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/63/769563/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini']",5,60673de82e41a6a6edc4a865d2c7b3a0115dfd63,fix-relmgt-pip-doc,"envdir = {toxworkdir}/docs deps = {[testenv:docs]deps}deps = {[testenv]deps} hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0 flake8-import-order==0.12 # LGPLv3 pylint==2.3.0 # GPLv2 isort==4.3.21 # MITdeps = -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps}",,47,57
openstack%2Fneutron~master~I06a5a1ba0523befbc136920efde3e717ef822856,openstack/neutron,master,I06a5a1ba0523befbc136920efde3e717ef822856,Update major release checklist,MERGED,2020-12-08 10:06:24.000000000,2021-01-07 11:40:35.000000000,2021-01-07 11:35:58.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-08 10:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f443972889f4ce83e33e4abed9d173488b3a1a97', 'message': 'Update major release checklist\n\nAs talked about in the CI meeting, some manual steps were not mentioned\nand could cause some issues later (like running stable stadium CI\nagainst master neutron). All steps should now be listed.\n\nAlso update some release names and URLs in the document\n\nChange-Id: I06a5a1ba0523befbc136920efde3e717ef822856\n'}, {'number': 2, 'created': '2021-01-05 15:28:39.000000000', 'files': ['doc/source/contributor/policies/release-checklist.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c00c060fb8748e593bbff5cf92248b2f44b6026', 'message': 'Update major release checklist\n\nAs talked about in the CI meeting, some manual steps were not mentioned\nand could cause some issues later (like running stable stadium CI\nagainst master neutron). All steps should now be listed.\n\nAlso update some release names and URLs in the document\n\nChange-Id: I06a5a1ba0523befbc136920efde3e717ef822856\n'}]",6,765959,0c00c060fb8748e593bbff5cf92248b2f44b6026,18,4,2,21798,,,0,"Update major release checklist

As talked about in the CI meeting, some manual steps were not mentioned
and could cause some issues later (like running stable stadium CI
against master neutron). All steps should now be listed.

Also update some release names and URLs in the document

Change-Id: I06a5a1ba0523befbc136920efde3e717ef822856
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/765959/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/policies/release-checklist.rst'],1,f443972889f4ce83e33e4abed9d173488b3a1a97,release-checklist-update,"(Victoria, Wallaby, ...) https://review.opendev.org/286413/ #. revise deprecation warnings collected in latest Zuul runs: some of them For example, see: https://review.opendev.org/753039/ see: https://review.opendev.org/755285/#. .gitreview file points to the new branch; https://review.opendev.org/754738/ openstack/requirements repo; https://review.opendev.org/754739/ #. job templates are updated to use versions for that branch; https://review.opendev.org/756585/ and https://review.opendev.org/759856/ #. all CI jobs running against master branch of another project are dropped; https://review.opendev.org/756695/ #. neutron itself is capped in requirements in the new branch; https://review.opendev.org/764022/ Note that some of those steps are covered by the OpenStack release team and its release bot. ","(Liberty, Mitaka, ...) https://review.opendev.org/#/c/286413/ #. revise deprecation warnings collected in latest Jenkins runs: some of them For example, see: https://review.opendev.org/#/c/292445/ see: https://review.opendev.org/#/c/288212/#. .gitreview file points to the new branch; openstack/requirements repo; #. if the branch fetches any other projects as dependencies, e.g. by using tox_install.sh as an install_command in tox.ini, git repository links point to corresponding stable branches of those dependency projects. Note that some of those steps may be covered by the OpenStack release team.",16,11
openstack%2Fswift~master~I03a92168b90508956f367fbb60b7712f95b97f60,openstack/swift,master,I03a92168b90508956f367fbb60b7712f95b97f60,Memcached client TLS support,MERGED,2020-12-04 15:31:04.000000000,2021-01-07 11:40:26.000000000,2021-01-07 11:35:34.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-12-04 15:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8741ed91fd20cd28b980c1d7cc727674ac691c0f', 'message': 'Memcached client TLS support\n\nThis patch specifies a set of configuration options required to build\na TLS context, which is used to wrap the client connection socket.\n\nCloses-Bug: #1906846\nChange-Id: I03a92168b90508956f367fbb60b7712f95b97f60\n'}, {'number': 2, 'created': '2020-12-04 15:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bfa17897478d81dd2e840897dbb029bc4b4b0cbc', 'message': 'Memcached client TLS support\n\nThis patch specifies a set of configuration options required to build\na TLS context, which is used to wrap the client connection socket.\n\nCloses-Bug: #1906846\nChange-Id: I03a92168b90508956f367fbb60b7712f95b97f60\n'}, {'number': 3, 'created': '2020-12-07 10:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/387b7d823924295c0feeed527d1babd22b4ee729', 'message': 'Memcached client TLS support\n\nThis patch specifies a set of configuration options required to build\na TLS context, which is used to wrap the client connection socket.\n\nCloses-Bug: #1906846\nChange-Id: I03a92168b90508956f367fbb60b7712f95b97f60\n'}, {'number': 4, 'created': '2020-12-07 11:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5b61381ce16acdfa28e9e154b54159d53903e6f0', 'message': 'Memcached client TLS support\n\nThis patch specifies a set of configuration options required to build\na TLS context, which is used to wrap the client connection socket.\n\nCloses-Bug: #1906846\nChange-Id: I03a92168b90508956f367fbb60b7712f95b97f60\n'}, {'number': 5, 'created': '2021-01-06 17:49:17.000000000', 'files': ['test/unit/common/middleware/test_memcache.py', 'swift/common/memcached.py', 'etc/proxy-server.conf-sample', 'test/unit/common/test_memcached.py', 'swift/common/middleware/memcache.py', 'etc/memcache.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/6930bc24b2f7613bc56bee3d2c34f7bb4890ec39', 'message': 'Memcached client TLS support\n\nThis patch specifies a set of configuration options required to build\na TLS context, which is used to wrap the client connection socket.\n\nCloses-Bug: #1906846\nChange-Id: I03a92168b90508956f367fbb60b7712f95b97f60\n'}]",8,765552,6930bc24b2f7613bc56bee3d2c34f7bb4890ec39,34,3,5,14250,,,0,"Memcached client TLS support

This patch specifies a set of configuration options required to build
a TLS context, which is used to wrap the client connection socket.

Closes-Bug: #1906846
Change-Id: I03a92168b90508956f367fbb60b7712f95b97f60
",git fetch https://review.opendev.org/openstack/swift refs/changes/52/765552/5 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_memcache.py', 'swift/common/memcached.py', 'etc/proxy-server.conf-sample', 'test/unit/common/test_memcached.py', 'swift/common/middleware/memcache.py', 'etc/memcache.conf-sample']",6,8741ed91fd20cd28b980c1d7cc727674ac691c0f,memcached-cert,"# # (Optional) Global toggle for TLS usage when comunicating with # the caching servers. # tls_enabled = # # (Optional) Path to a file of concatenated CA certificates in PEM # format necessary to establish the caching server's authenticity. # If tls_enabled is False, this option is ignored. # tls_cafile = # # (Optional) Path to a single file in PEM format containing the # client's certificate as well as any number of CA certificates # needed to establish the certificate's authenticity. This file # is only required when client side authentication is necessary. # If tls_enabled is False, this option is ignored. # tls_certfile = # # (Optional) Path to a single file containing the client's private # key in. Otherwhise the private key will be taken from the file # specified in tls_certfile. If tls_enabled is False, this option # is ignored. # tls_keyfile = # # (Optional) Set the available ciphers for sockets created with # the TLS context. It should be a string in the OpenSSL cipher # list format. If not specified, all OpenSSL enabled ciphers will # be available. # tls_allowed_ciphers =",,94,6
openstack%2Fdevstack~stable%2Ftrain~I4fb2372be7d861f09f365e96478b4663847a66a6,openstack/devstack,stable/train,I4fb2372be7d861f09f365e96478b4663847a66a6,Increase swap space size again,MERGED,2020-10-12 09:14:17.000000000,2021-01-07 11:40:15.000000000,2021-01-07 11:35:30.000000000,"[{'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 14250}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 29963}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-10-12 09:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7b6997102c1ad36f58fb7d2b1658c8f584541a95', 'message': 'WIP: Test running with larged swap space size again\n\nChange-Id: I4fb2372be7d861f09f365e96478b4663847a66a6\n'}, {'number': 2, 'created': '2020-11-03 15:43:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc02fb441578179e7cb4eba00563554da3e435ac', 'message': 'Increase swap space size again\n\nInfra changed the default swap size from 8G to 1G, this breaks some\nstable jobs. Revert to 8G for our jobs.\n\nChange-Id: I4fb2372be7d861f09f365e96478b4663847a66a6\n'}]",1,757488,fc02fb441578179e7cb4eba00563554da3e435ac,19,7,2,13252,,,0,"Increase swap space size again

Infra changed the default swap size from 8G to 1G, this breaks some
stable jobs. Revert to 8G for our jobs.

Change-Id: I4fb2372be7d861f09f365e96478b4663847a66a6
",git fetch https://review.opendev.org/openstack/devstack refs/changes/88/757488/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,7b6997102c1ad36f58fb7d2b1658c8f584541a95,bump-swap-train, configure_swap_size: 8192,,1,0
openstack%2Fneutron-specs~master~Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4,openstack/neutron-specs,master,Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4,Extends Floating IP port forwarding API,MERGED,2020-07-06 16:35:34.000000000,2021-01-07 11:20:42.000000000,2021-01-07 11:19:05.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 9531}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 27515}, {'_account_id': 28356}, {'_account_id': 30695}, {'_account_id': 30940}]","[{'number': 1, 'created': '2020-07-06 16:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9a8d68f6f63bd0e400aa7cb15a2360561c65bddc', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 2, 'created': '2020-07-08 13:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/027167535414f93a5afd37c6aaa60df0c5b312de', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 3, 'created': '2020-08-18 12:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/49419308374660e4b20e1928b0da7839b6c707ac', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 4, 'created': '2020-08-27 16:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ff4f8cbdd74e7eafb2b9b6c3afcf3bf1bc92dbb4', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 5, 'created': '2020-11-03 11:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/00bbdebb2412c6b3544818169e347eebd03248b6', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 6, 'created': '2020-11-26 19:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/dfec18599459226f6583d0efa1f6f146ed8fb621', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 7, 'created': '2020-11-26 19:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/aa9217dea9a02f12910838a571484817e9b67e8b', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 8, 'created': '2020-11-27 12:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3be2c9fed4882b11f46307cc42b1ea4605bb2d54', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 9, 'created': '2020-11-27 13:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5dc88f7f8635ed8fada2ffdd1809dbc57873884f', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 10, 'created': '2020-12-02 12:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b45f39858f0d69e1c0aeffaf84fa51e6133edb4d', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 11, 'created': '2020-12-02 12:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4e7995d896aafcef4fa50948fcf95c7f33272a44', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 12, 'created': '2020-12-10 12:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e1a1588aabd1151877d4c4541835d4ae680eba5a', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 13, 'created': '2020-12-18 15:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/83dd340811a8bdd31aeb4d725974c2558368c2c5', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 14, 'created': '2020-12-22 14:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/62032e0f17172e0c53e9d62f78c843f5555dcd24', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}, {'number': 15, 'created': '2020-12-29 13:06:39.000000000', 'files': ['specs/wallaby/index.rst', 'specs/wallaby/port-forwarding-port-ranges.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/40670ccf03d0ccd358b5f9562ed26b5e8c3ac41d', 'message': 'Extends Floating IP port forwarding API\n\nExtend the current floating IP port forwarding API to handle a\nrange of ports instead of a one-to-one mapping.\n\nChange-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4\nImplements: blueprint floatingips-portforwarding-ranges\nCloses-Bug: #1885921\n'}]",33,739549,40670ccf03d0ccd358b5f9562ed26b5e8c3ac41d,71,14,15,30695,,,0,"Extends Floating IP port forwarding API

Extend the current floating IP port forwarding API to handle a
range of ports instead of a one-to-one mapping.

Change-Id: Iee88c2d36eeb600a9b75fc21f4fb5b0a707898f4
Implements: blueprint floatingips-portforwarding-ranges
Closes-Bug: #1885921
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/49/739549/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/victoria/port-forwarding-port-ranges.rst'],1,9a8d68f6f63bd0e400aa7cb15a2360561c65bddc,upstream/feature/fip-pfw-port-range,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Floating IP port forwarding to support port ranges ================================================== https://blueprints.launchpad.net/neutron/+spec/floatingips-portforwarding-ranges The use of port ranges in NAT eases the rules creation process as it replaces the use of many entries in the iptables by just one. Also, some users, when requesting virtual machines that have some ports exposed to the Internet, prefer to request a range of ports to be exposed to avoid doing many requests for operators regarding the networking configurations. Therefore, they usually request a slice of external ports to deploys their applications, so they will be able to choose and change the ports they desire on the fly without needing to contact anyone else or configuring it in OpenStack. Moreover, there are applications such as FTP, video conference systems, streaming, and others that use more than one port (ports in sequence). Therefore, it is easier to enable all of them (the requested/needed port range) in a single configuration. Problem Description =================== * Currently, if a user wants to create NAT rule that cover multiple ports, he/she needs to create them one by one, which is cumbersome in some use cases. * When configuring NAT via iptables [1]_ (and other networking systems/applications), operators can use port ranges while configuring a rule; therefore, it is natural for network engineers to handle/use port ranges in their NAT configurations. Proposed Change =============== Change the Floating IP port forwarding API to allow the use of port ranges to create NAT rules. The changes are presented as follows. Today, when a user is creating a port forwarding rule, he/she create a rule via API, or CLI and send a JSON like: .. code-block:: json { ""port_forwarding"": { ""protocol"": ""tcp"", ""internal_ip_address"": ""172.16.0.7"", ""internal_port"": 80, ""internal_port_id"": ""b67a7746-dc69-45b4-9b84-bb229fe198a0"", ""external_port"": 8080, ""description"": ""desc"" } } The external/internal ports are integers and if the user desires to create a port forwarding in a floating ip for many ports, he/she will need to resend this JSON many times to fit the number of ports he/she desires. The proposal is to change the API/CLI to accept a string in external/internal ports. This will allow users to create a rule with port ranges (instead of executing multiple calls). Therefore, a user would not need anymore to create 100 rules to reach 100 ports forwards in his/her virtual machine, he/she could just send a JSON like that: .. code-block:: json { ""port_forwarding"": { ""protocol"": ""tcp"", ""internal_ip_address"": ""172.16.0.7"", ""internal_port"": ""8000:8100"", ""internal_port_id"": ""b67a7746-dc69-45b4-9b84-bb229fe198a0"", ""external_port"": ""9000:9100"", ""description"": ""desc"" } } New validations will be created to avoid users to enter invalid ranges in ports. Here follows a summary of all of the validations executed by the system: * Only N(external port[s]) to N (internal port[s]) are allowed or N(external port[s]) to 1 (internal port). Therefore, all of the other combinations (1:N, N:M, M:N) are not allowed and will generate an error. * When defining a port(s) range, the ports in this range cannot be already in use by any other port forwarding rule for the same floating IP and protocol. * A valid port is a number between 1 and 65535. All other cases will generate an error. Even though ""0"" is a valid port, we will not allow its use as it is reserved. * The notation to define a port range is the following: <port_range_begin>[:<port_range_end>]; anything that does not match this definition will generate an error. Data Model Impact ----------------- Today, the port_forwarding table schema is something like: +----+---------------+---------------+--------------------------+----------+-----------------+ | id | floatingip_id | external_port | internal_neutron_port_id | protocol | socket | +====+===============+===============+==========================+==========+=================+ | A1 | C2 | 80 | A2 | tcp | 172.16.0.7:8080 | +----+---------------+---------------+--------------------------+----------+-----------------+ | B1 | C2 | 81 | B2 | tcp | 172.16.0.7:8081 | +----+---------------+---------------+--------------------------+----------+-----------------+ To make the port_forwarding table more like the PortForwarding object and the JSON, the port_forwarding table will be updated splitting the socket column into two new columns (internal_ip_address and internal_port), also, the external_port column type will be changed from integer to string. The new table would be like below: +----+---------------+---------------+--------------------------+----------+---------------------+---------------+ | id | floatingip_id | external_port | internal_neutron_port_id | protocol | internal_ip_address | internal_port | +====+===============+===============+==========================+==========+=====================+===============+ | A1 | C2 | 80 | A2 | tcp | 172.16.0.7 | 8080 | +----+---------------+---------------+--------------------------+----------+---------------------+---------------+ | B1 | C2 | 81 | B2 | tcp | 172.16.0.7 | 8081 | +----+---------------+---------------+--------------------------+----------+---------------------+---------------+ The legacy data migration would be done with an alembic migration upgrade script. We have 5 steps in the data migration: 1) Create the ``internal_ip_address`` and ``internal_port`` columns with NULL values; 2) Select id and socket columns for every table entry; 3) For each entry, split the socket value by ':' and put the result in the new ``internal_ip_address`` and ``internal_port`` columns from same id as the socket; 4) Delete the socket column; 5) Change the external_port type from integer to string; Sub Resource Extension ---------------------- It will be created an extension that overrides the parameters (external_port and internal_port) to also accept port ranges in their validations. The attributes map of new sub resource would be like: .. code-block:: python SUB_RESOURCE_ATTRIBUTE_MAP = { 'port_forwarding': { 'parameters': { 'external_port': { 'allow_post': True, 'allow_put': True, 'validate': {'type:port_range': None}, 'is_visible': True, 'is_sort_key': True, 'is_filter': True}, 'internal_port': { 'allow_post': True, 'allow_put': True, 'validate': {'type:port_range': None}, 'is_visible': True}, } } } Implementation ============== Assignee(s) ----------- Primary assignees: * Pedro <phpm13@gmail.com> * Rafael <rafael@apache.org> Other contributors: Work Items ---------- 1) API extension (neutron-lib) 2) DB extension/data migration (neutron) 3) Extend Neutron API with new validations for port ranges (neutron) 4) Extend l3 agent to apply the ranges in the iptable rule (neutron) 5) Tests 6) Documentation Dependencies ============ None References ========== .. [1] https://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-6.html",,201,0
openstack%2Fvenus~master~Ib289acd558389fa7a9832a5af2b353a5240c1e72,openstack/venus,master,Ib289acd558389fa7a9832a5af2b353a5240c1e72,Remove six,ABANDONED,2021-01-07 10:41:06.000000000,2021-01-07 11:10:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-07 10:41:06.000000000', 'files': ['venus/exception.py', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/venus/commit/c149982f1ad7ba261e5febe0ed0ea8c87ce36cfb', 'message': 'Remove six\n\n- six.text_type\n- six.reraise\n\nChange-Id: Ib289acd558389fa7a9832a5af2b353a5240c1e72\n'}]",0,769705,c149982f1ad7ba261e5febe0ed0ea8c87ce36cfb,3,1,1,30092,,,0,"Remove six

- six.text_type
- six.reraise

Change-Id: Ib289acd558389fa7a9832a5af2b353a5240c1e72
",git fetch https://review.opendev.org/openstack/venus refs/changes/05/769705/1 && git format-patch -1 --stdout FETCH_HEAD,"['venus/exception.py', 'requirements.txt']",2,c149982f1ad7ba261e5febe0ed0ea8c87ce36cfb,,,six>=1.9.0,4,7
openstack%2Fdevstack~master~Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8,openstack/devstack,master,Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8,Install systemd-python from distribution package,MERGED,2020-12-11 14:40:46.000000000,2021-01-07 11:03:29.000000000,2021-01-07 11:02:00.000000000,"[{'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 13988}, {'_account_id': 16385}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-11 14:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9dfd295e9e5f17e74bf379455940932f4ddace71', 'message': 'Install systemd-python from RPM on RHEL8/CentOS\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 2, 'created': '2020-12-14 08:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ea38bd6e2af305ee93b2a7cf0a6f0184897171c1', 'message': 'Install systemd-python from RPM to avoid compilation errors\n\nCentOS 8 support start to fail because of errors compiling\nsystemd python binding modules. Let install it from\ndistribution packages as documented by its Web page [1]\n\n[1] https://github.com/systemd/python-systemd\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 3, 'created': '2020-12-14 08:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e4739911f2f03819d32b31c5371b6e00d8b31e2b', 'message': 'Install systemd-python from RPM to avoid compilation errors\n\nCentOS 8 support start to fail because of errors compiling\nsystemd python binding modules. Let install it from\ndistribution packages as documented by its Web page [1]\n\n[1] https://github.com/systemd/python-systemd\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 4, 'created': '2020-12-14 10:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f051ef703d05adeb185a9d456060ba400bea6554', 'message': 'Install systemd-python from RPM to avoid compilation errors\n\nCentOS 8 support start to fail because of errors compiling\nsystemd python binding modules. Let install it from\ndistribution packages as documented by its Web page [1]\n\n[1] https://github.com/systemd/python-systemd\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 5, 'created': '2020-12-14 13:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6dc0283b7dc0289991adcb851b2d5e9ed4c9a2e6', 'message': 'Install systemd-python from RPM to avoid compilation errors\n\nCentOS 8 support start to fail because of errors compiling\nsystemd python binding modules. Let install it from\ndistribution packages as documented by its Web page [1]\n\n[1] https://github.com/systemd/python-systemd\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 6, 'created': '2020-12-16 09:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a1c1dc22c12a1adf3012ae6c7b9db870d254e461', 'message': 'Install systemd-python from RPM to avoid compilation errors\n\nCentOS 8 support start to fail because of an issue [1]\ncompiling systemd python binding modules.\nLet install it from distribution packages as documented by\npython-systemd project Web page [2]\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1862714\n[2] https://github.com/systemd/python-systemd\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 7, 'created': '2020-12-16 09:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/07ff253090cfc196a85c96adf1bdd03d92addd64', 'message': 'Install systemd-python from distribution package\n\nCentOS 8 support start to fail because of an issue [1]\ncompiling systemd python binding modules.\nLet install it from distribution packages as documented by\npython-systemd project Web page [2]\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1862714\n[2] https://github.com/systemd/python-systemd\n\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 8, 'created': '2020-12-16 10:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40820ba02f7ea5d5d9dc598f0c6f54e3cea28911', 'message': 'Install systemd-python from distribution package\n\nCentOS 8 support start to fail because of an issue [1]\ncompiling systemd python binding modules.\nLet install it from distribution packages as documented by\npython-systemd project Web page [2]\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1862714\n[2] https://github.com/systemd/python-systemd\n\nCloses-Bug: #1908386\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 9, 'created': '2020-12-17 14:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/77860b2783dc029c0d311f3ec6f8cd2c954e63d4', 'message': 'Install systemd-python from distribution package\n\nCentOS 8 support start to fail because of an issue [1]\ncompiling systemd python binding modules.\nLet install it from distribution packages as documented by\npython-systemd project Web page [2]\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1862714\n[2] https://github.com/systemd/python-systemd\n\nCloses-Bug: #1908386\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}, {'number': 10, 'created': '2020-12-23 14:22:27.000000000', 'files': ['files/debs/general', 'files/rpms-suse/general', 'files/rpms/general', 'doc/source/systemd.rst', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7e3428b9872d5b4b01ee10f2d29c55e7e2accbbd', 'message': 'Install systemd-python from distribution package\n\nCentOS 8 support start to fail because of an issue [1]\ncompiling systemd python binding modules.\nLet install it from distribution packages as documented by\npython-systemd project Web page [2]\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1862714\n[2] https://github.com/systemd/python-systemd\n\nCloses-Bug: #1908386\nChange-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8\n'}]",0,766740,7e3428b9872d5b4b01ee10f2d29c55e7e2accbbd,40,8,10,27329,,,0,"Install systemd-python from distribution package

CentOS 8 support start to fail because of an issue [1]
compiling systemd python binding modules.
Let install it from distribution packages as documented by
python-systemd project Web page [2]

[1] https://bugzilla.redhat.com/show_bug.cgi?id=1862714
[2] https://github.com/systemd/python-systemd

Closes-Bug: #1908386
Change-Id: Ic7cfd72ce1b875e75b1cdbdd44a902b25d51abb8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/40/766740/10 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,9dfd295e9e5f17e74bf379455940932f4ddace71,centos-8,"if [[ $DISTRO == ""rhel8"" ]]; then install_package python3-systemd else pip_install_gr systemd-python fi",pip_install_gr systemd-python,5,1
openstack%2Fdevstack~stable%2Fstein~I02c692e95d70017eea03d82d75ae6c5e87bde8b1,openstack/devstack,stable/stein,I02c692e95d70017eea03d82d75ae6c5e87bde8b1,Install swift keystone extras requirements,MERGED,2020-12-22 20:41:11.000000000,2021-01-07 10:49:47.000000000,2021-01-07 10:47:28.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-22 20:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fd400a431e7bc649ce1cc5045c7719cfcc0831e8', 'message': ""Install swift extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n""}, {'number': 2, 'created': '2020-12-23 20:07:53.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d3016a20ac7239dfbc27c762b7ba4c08f95abc65', 'message': ""Install swift keystone extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift keystone extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)\n(cherry picked from commit 90651cb1a914999afd1dd1e4929c04e62fefb4c8)\n(cherry picked from commit 10fdf258bacf4702917f1bbdffef933e7a89907a)\n(cherry picked from commit a7c4377c17b6ca4a73a786af9cc6b1c502cd8061)\n""}]",0,768257,d3016a20ac7239dfbc27c762b7ba4c08f95abc65,16,4,2,8556,,,0,"Install swift keystone extras requirements

Since the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264
s-proxy is no longer able to launch as keystonemiddleware (listed under
test-requirements.txt) has not been installed.

keystonemiddleware is listed as extras requirements in swift
- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79

Let's install swift keystone extra requirements also.

Closes-Bug: #1909018
Change-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1
(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)
(cherry picked from commit 90651cb1a914999afd1dd1e4929c04e62fefb4c8)
(cherry picked from commit 10fdf258bacf4702917f1bbdffef933e7a89907a)
(cherry picked from commit a7c4377c17b6ca4a73a786af9cc6b1c502cd8061)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/57/768257/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,fd400a431e7bc649ce1cc5045c7719cfcc0831e8,bug/1909018, setup_develop $SWIFT_DIR keystone, setup_develop $SWIFT_DIR,1,1
openstack%2Fswift~stable%2Fstein~I294d5350e2f418614e54ff7bdd47dff16bfdcdbc,openstack/swift,stable/stein,I294d5350e2f418614e54ff7bdd47dff16bfdcdbc,[stable-only] Cap bandit to 1.6.2,MERGED,2020-12-10 14:58:55.000000000,2021-01-07 10:48:55.000000000,2021-01-07 10:47:32.000000000,"[{'_account_id': 7847}, {'_account_id': 10135}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-10 14:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cac096fcd64213f1e2cfa0848ca9af40a89fc952', 'message': '[stable-only] Cap bandit to 1.6.2\n\nThe 1.6.3 [1] release has dropped support for py2 [2] so cap to 1.6.2\nwhen using py2.\n\n[1] https://github.com/PyCQA/bandit/releases/tag/1.6.3\n[2] https://github.com/PyCQA/bandit/pull/615\n\nCloses-Bug: #1907438\nChange-Id: I294d5350e2f418614e54ff7bdd47dff16bfdcdbc\n(cherry picked from commit 1f2326cd7cf5f8e32a55091f976f917093a0bede)\n'}, {'number': 2, 'created': '2020-12-22 14:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/487585e3d17f3b26a0ada378a9ac064dd5ca4d82', 'message': '[stable-only] Cap bandit to 1.6.2\n\nThe 1.6.3 [1] release has dropped support for py2 [2] so cap to 1.6.2\nwhen using py2.\n\ncheck-requirements is dropped for the time being while we resolve issues\nacross multiple projects uncovered by the 20.3 release of pip.\n\n[1] https://github.com/PyCQA/bandit/releases/tag/1.6.3\n[2] https://github.com/PyCQA/bandit/pull/615\n\nCloses-Bug: #1907438\nChange-Id: I294d5350e2f418614e54ff7bdd47dff16bfdcdbc\n(cherry picked from commit 1f2326cd7cf5f8e32a55091f976f917093a0bede)\n'}, {'number': 3, 'created': '2020-12-23 08:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ef8ef3709a2276bd4806b5409629b5bff29bd6d8', 'message': '[stable-only] Cap bandit to 1.6.2\n\nThe 1.6.3 [1] release has dropped support for py2 [2] so cap to 1.6.2\nwhen using py2.\n\ncheck-requirements is dropped for the time being while we resolve issues\nacross multiple projects uncovered by the 20.3 release of pip.\n\n[1] https://github.com/PyCQA/bandit/releases/tag/1.6.3\n[2] https://github.com/PyCQA/bandit/pull/615\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/768257\n\nCloses-Bug: #1907438\nChange-Id: I294d5350e2f418614e54ff7bdd47dff16bfdcdbc\n(cherry picked from commit 1f2326cd7cf5f8e32a55091f976f917093a0bede)\n'}, {'number': 4, 'created': '2020-12-24 10:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/906fbc31871679dee2846cc40fb554598922e885', 'message': '[stable-only] Cap bandit to 1.6.2\n\nThe 1.6.3 [1] release has dropped support for py2 [2] so cap to 1.6.2\nwhen using py2.\n\nAlso fix sphinx doc requirements to make requirements-check job pass.\n\n[1] https://github.com/PyCQA/bandit/releases/tag/1.6.3\n[2] https://github.com/PyCQA/bandit/pull/615\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/768257\n\nCloses-Bug: #1907438\nChange-Id: I294d5350e2f418614e54ff7bdd47dff16bfdcdbc\n(cherry picked from commit 1f2326cd7cf5f8e32a55091f976f917093a0bede)\n'}, {'number': 5, 'created': '2020-12-29 16:22:58.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/swift/commit/c304f11d0e7b4caf4b705e3a3dfdc0ffe8d78e06', 'message': '[stable-only] Cap bandit to 1.6.2\n\nThe 1.6.3 [1] release has dropped support for py2 [2] so cap to 1.6.2\nwhen using py2.\n\nAlso fix sphinx doc requirements and xattr requirement to make\nrequirements-check job pass.\n\n[1] https://github.com/PyCQA/bandit/releases/tag/1.6.3\n[2] https://github.com/PyCQA/bandit/pull/615\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/768257\n\nCloses-Bug: #1907438\nChange-Id: I294d5350e2f418614e54ff7bdd47dff16bfdcdbc\n(cherry picked from commit 1f2326cd7cf5f8e32a55091f976f917093a0bede)\n'}]",2,766489,c304f11d0e7b4caf4b705e3a3dfdc0ffe8d78e06,27,4,5,17685,,,0,"[stable-only] Cap bandit to 1.6.2

The 1.6.3 [1] release has dropped support for py2 [2] so cap to 1.6.2
when using py2.

Also fix sphinx doc requirements and xattr requirement to make
requirements-check job pass.

[1] https://github.com/PyCQA/bandit/releases/tag/1.6.3
[2] https://github.com/PyCQA/bandit/pull/615

Depends-On: https://review.opendev.org/c/openstack/devstack/+/768257

Closes-Bug: #1907438
Change-Id: I294d5350e2f418614e54ff7bdd47dff16bfdcdbc
(cherry picked from commit 1f2326cd7cf5f8e32a55091f976f917093a0bede)
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/766489/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,cac096fcd64213f1e2cfa0848ca9af40a89fc952,bug/1907438,"bandit>=1.1.0,<=1.6.2 # Apache-2.0",bandit>=1.1.0 # Apache-2.0,1,1
openstack%2Fmasakari~master~Ia6849b67128e6aa635fbfddf463c20f5c71db554,openstack/masakari,master,Ia6849b67128e6aa635fbfddf463c20f5c71db554,update docs,MERGED,2021-01-06 02:18:42.000000000,2021-01-07 10:48:41.000000000,2021-01-07 07:41:01.000000000,"[{'_account_id': 22348}, {'_account_id': 24501}, {'_account_id': 26458}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-06 02:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/3f44005d278f0c6598f5f52679f2cda47eb9c9d8', 'message': 'update docs\n\nChange-Id: Ia6849b67128e6aa635fbfddf463c20f5c71db554\n'}, {'number': 2, 'created': '2021-01-06 02:30:59.000000000', 'files': ['doc/source/install/overview.rst'], 'web_link': 'https://opendev.org/openstack/masakari/commit/27c31cbd9a856e9ab920e09e5b4d94d16b697af4', 'message': 'update docs\n\nChange-Id: Ia6849b67128e6aa635fbfddf463c20f5c71db554\n'}]",0,769444,27c31cbd9a856e9ab920e09e5b4d94d16b697af4,10,4,2,24501,,,0,"update docs

Change-Id: Ia6849b67128e6aa635fbfddf463c20f5c71db554
",git fetch https://review.opendev.org/openstack/masakari refs/changes/44/769444/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/overview.rst'],1,3f44005d278f0c6598f5f52679f2cda47eb9c9d8,,* ``VM process down`` - * ``Provisioning process down`` - * ``nova-compute host failure`` - * ``auto`` - * ``reserved_host`` - * ``auto_priority`` - * ``rh_priority`` - evacuate all the VMs by using ``reserved_host`` recovery method firstly.,* VM process down* Provisioning process down* nova-compute host failure * auto * reserved_host * auto_priority * rh_priority evacuate all the VMs by using ``rh_priority`` recovery method firstly.,8,8
openstack%2Fmasakari~master~I9b9d9a4ccd87f655239f7db2f93e7c38e014f5c1,openstack/masakari,master,I9b9d9a4ccd87f655239f7db2f93e7c38e014f5c1,add host failure reovery method in Masakari doc,MERGED,2020-12-28 03:13:12.000000000,2021-01-07 10:47:51.000000000,2021-01-05 09:32:03.000000000,"[{'_account_id': 22348}, {'_account_id': 24501}, {'_account_id': 26458}, {'_account_id': 32304}]","[{'number': 1, 'created': '2020-12-28 03:13:12.000000000', 'files': ['doc/source/install/overview.rst'], 'web_link': 'https://opendev.org/openstack/masakari/commit/a1d5917f3866a851857b4eeea2eb5016456dcf28', 'message': 'add host failure reovery method in Masakari doc\n\nChange-Id: I9b9d9a4ccd87f655239f7db2f93e7c38e014f5c1\n'}]",0,768591,a1d5917f3866a851857b4eeea2eb5016456dcf28,8,4,1,24501,,,0,"add host failure reovery method in Masakari doc

Change-Id: I9b9d9a4ccd87f655239f7db2f93e7c38e014f5c1
",git fetch https://review.opendev.org/openstack/masakari refs/changes/91/768591/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/overview.rst'],1,a1d5917f3866a851857b4eeea2eb5016456dcf28,,"* VM process down restart vm (use nova stop API, and nova start API). Libvirt events will be also emitted by other failures. * Provisioning process down restarts process, changes nova-compute service status to maintenance mode (use nova service-disable). * nova-compute host failure evacuate all the VMs from failure host according to the following recovery methods (use nova evacuate API). * auto evacuate all the VMs with no destination node for nova scheduler. * reserved_host evacuate all the VMs with reserved hosts as the destination nodes for nova scheduler. * auto_priority evacuate all the VMs by using ``auto`` recovery method firstly. If failed, then using ``reserved_host`` recovery method. * rh_priority evacuate all the VMs by using ``rh_priority`` recovery method firstly. If failed, then using ``auto`` recovery method.","* VM process down - restart vm (use nova stop API, and nova start API). Libvirt events will be also emitted by other failures. * Provisioning process down - restarts process, changes nova-compute service status to maintenance mode (use nova service-disable). * nova-compute host failure - evacuate all the VMs from failure host to reserved host (use nova evacuate API).",21,7
openstack%2Fovn-octavia-provider~stable%2Fvictoria~Ia4460dd0ae22949920f3f304b315e3c3f32f89c0,openstack/ovn-octavia-provider,stable/victoria,Ia4460dd0ae22949920f3f304b315e3c3f32f89c0,Retry status updates to Octavia,MERGED,2020-12-04 18:00:24.000000000,2021-01-07 10:12:55.000000000,2021-01-07 10:11:42.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-04 18:00:24.000000000', 'files': ['ovn_octavia_provider/helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/79c77492be0987cb0948db1fd885b9654826a2b8', 'message': 'Retry status updates to Octavia\n\nWhen the OVN Octavia Provider driver calls into\noctavia-lib to update the status of a loadbalancer,\nit might fail. This can happen if a resource associated\nwith the loadbalancer was not found, for example, if\nit\'s DB transaction was in-flight.\n\nA side-effect is the resource can become ""stuck"":\n\n$ openstack loadbalancer listener delete $ID\nLoad Balancer $ID is immutable and cannot be updated.\n\nThe provider driver needs to retry the operation,\ntypically even the very next call succeeds.\n\nChange-Id: Ia4460dd0ae22949920f3f304b315e3c3f32f89c0\nCloses-bug: #1900763\n(cherry picked from commit 723ca5afeea3fa17e968d9c37220a4ff5a977d45)\n'}]",0,765596,79c77492be0987cb0948db1fd885b9654826a2b8,18,3,1,1131,,,0,"Retry status updates to Octavia

When the OVN Octavia Provider driver calls into
octavia-lib to update the status of a loadbalancer,
it might fail. This can happen if a resource associated
with the loadbalancer was not found, for example, if
it's DB transaction was in-flight.

A side-effect is the resource can become ""stuck"":

$ openstack loadbalancer listener delete $ID
Load Balancer $ID is immutable and cannot be updated.

The provider driver needs to retry the operation,
typically even the very next call succeeds.

Change-Id: Ia4460dd0ae22949920f3f304b315e3c3f32f89c0
Closes-bug: #1900763
(cherry picked from commit 723ca5afeea3fa17e968d9c37220a4ff5a977d45)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/96/765596/1 && git format-patch -1 --stdout FETCH_HEAD,['ovn_octavia_provider/helper.py'],1,79c77492be0987cb0948db1fd885b9654826a2b8,bug/1900763-stable/victoria," request = self.requests.get() request_type = request['type'] if request_type == ovn_const.REQ_TYPE_EXIT: break request_handler = self._lb_request_func_maps.get(request_type) try: except driver_exceptions.UpdateStatusError as e: msg = (""Error while updating the load balancer "" ""status: %s"") % e.fault_string LOG.error(msg) # TODO(haleyb): The resource(s) we were updating status for # should be cleaned-up @tenacity.retry( retry=tenacity.retry_if_exception_type( driver_exceptions.UpdateStatusError), wait=tenacity.wait_exponential(), stop=tenacity.stop_after_delay(10), reraise=True) def _update_status_to_octavia(self, status): status = OvnProviderHelper._delete_disabled_from_status(status) LOG.debug('Updating status to octavia: %s', status) self._octavia_driver_lib.update_loadbalancer_status(status)"," try: request = self.requests.get() request_type = request['type'] if request_type == ovn_const.REQ_TYPE_EXIT: break request_handler = self._lb_request_func_maps.get(request_type) def _update_status_to_octavia(self, status): try: status = OvnProviderHelper._delete_disabled_from_status(status) LOG.debug('Updating status to octavia: %s', status) self._octavia_driver_lib.update_loadbalancer_status(status) except driver_exceptions.UpdateStatusError as e: msg = (""Error while updating the load balancer "" ""status: %s"") % e.fault_string LOG.error(msg) raise driver_exceptions.UpdateStatusError(msg)",21,15
openstack%2Fneutron~master~I5fec22bab6b636e2be97c0e7ae1c73e62082d688,openstack/neutron,master,I5fec22bab6b636e2be97c0e7ae1c73e62082d688,[DNM][WIP] Add standard attributes to the session (network),ABANDONED,2020-12-14 10:04:52.000000000,2021-01-07 10:10:35.000000000,,"[{'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-14 10:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed654adbf491bba501a4b81c5709fe8c86cab0b0', 'message': '[DNM][WIP] Add standard attributes to the session (network)\n\nChange-Id: I5fec22bab6b636e2be97c0e7ae1c73e62082d688\nCloses-Bug: #1903008\n'}, {'number': 2, 'created': '2020-12-14 11:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/334fd56b1269315c23a89d452938ca7b10091338', 'message': '[DNM][WIP] Add standard attributes to the session (network)\n\nChange-Id: I5fec22bab6b636e2be97c0e7ae1c73e62082d688\nCloses-Bug: #1903008\n'}, {'number': 3, 'created': '2020-12-14 13:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b715c4281e60b1ccaf54bc18b8d5e5e9ed407010', 'message': '[DNM][WIP] Add standard attributes to the session (network)\n\nChange-Id: I5fec22bab6b636e2be97c0e7ae1c73e62082d688\nCloses-Bug: #1903008\n'}, {'number': 4, 'created': '2020-12-21 12:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fde54a46baa4396cd8a7ea9503470f54e391aa33', 'message': '[DNM][WIP] Add standard attributes to the session (network)\n\nChange-Id: I5fec22bab6b636e2be97c0e7ae1c73e62082d688\nCloses-Bug: #1903008\n'}, {'number': 5, 'created': '2020-12-22 10:29:48.000000000', 'files': ['neutron/db/db_base_plugin_v2.py', 'zuul.d/base.yaml', 'zuul.d/project.yaml', 'neutron/db/ovn_revision_numbers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/65f7c11477fa73b8ae2b8ced35573490a4e9ba53', 'message': '[DNM][WIP] Add standard attributes to the session (network)\n\nChange-Id: I5fec22bab6b636e2be97c0e7ae1c73e62082d688\nCloses-Bug: #1903008\n'}]",2,766920,65f7c11477fa73b8ae2b8ced35573490a4e9ba53,37,3,5,16688,,,0,"[DNM][WIP] Add standard attributes to the session (network)

Change-Id: I5fec22bab6b636e2be97c0e7ae1c73e62082d688
Closes-Bug: #1903008
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/766920/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/db_base_plugin_v2.py', 'zuul.d/base.yaml', 'zuul.d/project.yaml']",3,ed654adbf491bba501a4b81c5709fe8c86cab0b0,bug/1903008, - neutron-functional-with-uwsgi-1 - neutron-functional-with-uwsgi-2 - neutron-functional-with-uwsgi-3 - neutron-functional-with-uwsgi-4 - neutron-functional-with-uwsgi-5 - neutron-functional-with-uwsgi-6 - neutron-functional-with-uwsgi-7 - neutron-functional-with-uwsgi-8 - neutron-functional-with-uwsgi-9 - neutron-functional-with-uwsgi-10 - neutron-functional-with-uwsgi-11 - neutron-functional-with-uwsgi-12 - neutron-functional-with-uwsgi-13 - neutron-functional-with-uwsgi-14 - neutron-functional-with-uwsgi-15 - neutron-functional-with-uwsgi-16 - neutron-functional-with-uwsgi-17 - neutron-functional-with-uwsgi-18 - neutron-functional-with-uwsgi-19 - neutron-functional-with-uwsgi-20 ," - neutron-functional-with-uwsgi - neutron-fullstack-with-uwsgi - neutron-rally-task - neutron-grenade-multinode - neutron-grenade-dvr-multinode - neutron-grenade-ovn: voting: false - neutron-tempest-multinode-full-py3 - neutron-tempest-dvr-ha-multinode-full - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false # We don't run the job on things like neutron docs-only changes irrelevant-files: &irrelevant-files - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^neutron/locale/.*$ - ^neutron/tests/unit/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ^vagrant/.*$ - ^migration/.*$ - ^devstack/.*\.sample$ - tempest-slow-py3: irrelevant-files: *irrelevant-files - tempest-ipv6-only: irrelevant-files: *irrelevant-files - neutron-tempest-with-neutron-lib-master: voting: false irrelevant-files: *irrelevant-files - neutron-ovn-tempest-ovs-release - neutron-ovn-tempest-ovs-release-ipv6-only - neutron-tempest-with-uwsgi-loki: voting: false # TODO(slaweq): add this job again to the check queue when it will be # working fine on python 3 #- networking-midonet-tempest-aio-ml2-centos-7: # voting: false # irrelevant-files: *irrelevant-files - openstacksdk-functional-devstack-networking: voting: false - tripleo-ci-centos-8-content-provider: voting: false - neutron-centos-8-tripleo-standalone: vars: &consumer_vars consumer_job: true build_container_images: false remove_tags: - build dependencies: &consumer_deps - tripleo-ci-centos-8-content-provider irrelevant-files: &consumer_irrelevant_files # use same list as dependency job # synced from tripleo-ci-base-centos-8 base - ^.*\.md$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^metadata.json$ - ^releasenotes/.*$ # do not put requirements.txt here, as it can have a huge impact - ^test-requirements.txt$ - ^lower-constraints.txt$ - ^spec/.*$ - ^Puppetfile.*$ - tox.ini - ^setup.*$ - ^vars/sova-patterns.yml$ ^.ansible-lint$ - ^.pre-commit-config.yaml$ - ^.yamllint$ - neutron-ovn-rally-task: voting: false # TripleO jobs that deploy OVN. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # In Stein and beyond, fs010 will run using # networking-ovn-tripleo-ci-centos-7-containers-multinode. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. - neutron-ovn-tripleo-ci-centos-8-containers-multinode: voting: false vars: *consumer_vars dependencies: *consumer_deps irrelevant-files: *consumer_irrelevant_files - neutron-ovn-tempest-slow: voting: false - neutron-ovn-tempest-full-multinode-ovs-master: voting: false - openstack-tox-py36: # from openstack-python3-wallaby-jobs template timeout: 3600 - openstack-tox-py38: # from openstack-python3-wallaby-jobs template timeout: 3600 - openstack-tox-lower-constraints: # from openstack-tox-lower-constraints template timeout: 3600 - openstack-tox-cover: # from openstack-cover-jobs template timeout: 4800 - neutron-fullstack-with-uwsgi - neutron-tempest-multinode-full-py3 - neutron-grenade-multinode - neutron-grenade-dvr-multinode - tempest-slow-py3: irrelevant-files: *irrelevant-files - tempest-ipv6-only: irrelevant-files: *irrelevant-files - neutron-ovn-tempest-ovs-release - neutron-ovn-tempest-ovs-release-ipv6-only - openstack-tox-py36: # from openstack-python3-wallaby-jobs template timeout: 3600 - openstack-tox-lower-constraints: # from openstack-tox-lower-constraints template timeout: 3600 #- neutron-ovn-rally-task #- neutron-ovn-tripleo-ci-centos-8-containers-multinode",83,115
openstack%2Fansible-role-python_venv_build~master~I7047760ca281eff9ef9c2a4bce448486d185eb4b,openstack/ansible-role-python_venv_build,master,I7047760ca281eff9ef9c2a4bce448486d185eb4b,Updated from OpenStack Ansible Tests,MERGED,2020-09-24 17:00:00.000000000,2021-01-07 10:04:07.000000000,2021-01-07 10:02:10.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-09-24 17:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/bd2deb7b00c3a9cefd9787654d5e42558c552347', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7047760ca281eff9ef9c2a4bce448486d185eb4b\n'}, {'number': 2, 'created': '2020-10-06 12:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/1156e618356f129b5e506023d13da9edc9d2d1f6', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7047760ca281eff9ef9c2a4bce448486d185eb4b\n'}, {'number': 3, 'created': '2021-01-05 08:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/fd859f3f9bb4b741f873202d02ad365e439ecd00', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7047760ca281eff9ef9c2a4bce448486d185eb4b\n'}, {'number': 4, 'created': '2021-01-06 17:10:41.000000000', 'files': ['run_tests.sh', 'Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/c22b7d7915df28bdf2c22643ec599137c2857875', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7047760ca281eff9ef9c2a4bce448486d185eb4b\n'}]",0,754193,c22b7d7915df28bdf2c22643ec599137c2857875,29,4,4,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I7047760ca281eff9ef9c2a4bce448486d185eb4b
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/93/754193/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'Vagrantfile']",2,bd2deb7b00c3a9cefd9787654d5e42558c552347,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""centos8"" do |centos8| centos8.vm.box = ""centos/8"""," config.vm.define ""centos7"" do |centos7| centos7.vm.box = ""centos/7""",3,6
openstack%2Fvenus~master~If0401a01ccf2755a85fbc03ca31adb8a19962972,openstack/venus,master,If0401a01ccf2755a85fbc03ca31adb8a19962972,remove six,MERGED,2021-01-06 06:51:02.000000000,2021-01-07 09:35:20.000000000,2021-01-07 09:35:20.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 06:51:02.000000000', 'files': ['venus/exception.py', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/venus/commit/39c5e1cecbac9709c6a8562cfe95f9afd9274b09', 'message': 'remove six\n\nremove six in venus/exception.py\nremove six in requirements.txt\n\nChange-Id: If0401a01ccf2755a85fbc03ca31adb8a19962972\n'}]",0,769456,39c5e1cecbac9709c6a8562cfe95f9afd9274b09,6,2,1,31825,,,0,"remove six

remove six in venus/exception.py
remove six in requirements.txt

Change-Id: If0401a01ccf2755a85fbc03ca31adb8a19962972
",git fetch https://review.opendev.org/openstack/venus refs/changes/56/769456/1 && git format-patch -1 --stdout FETCH_HEAD,"['venus/exception.py', 'requirements.txt']",2,39c5e1cecbac9709c6a8562cfe95f9afd9274b09,,,six>=1.9.0,5,9
openstack%2Fpython-venusclient~master~Iddfa30fe626d76d5969719720b52313e69a58129,openstack/python-venusclient,master,Iddfa30fe626d76d5969719720b52313e69a58129,remove six in httpclient.py and requirements.txt,MERGED,2021-01-06 11:50:59.000000000,2021-01-07 09:34:48.000000000,2021-01-07 09:34:48.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 11:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/b0f0c303d4a209d8b147738a4771362d1e9a4387', 'message': 'remove six in httpclient.py and requirements.txt\n\nChange-Id: Iddfa30fe626d76d5969719720b52313e69a58129\n'}, {'number': 2, 'created': '2021-01-06 12:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/f90d87ac4649436f37d3131c078fa077ddc202c1', 'message': 'remove six in httpclient.py and requirements.txt\n\nChange-Id: Iddfa30fe626d76d5969719720b52313e69a58129\n'}, {'number': 3, 'created': '2021-01-07 00:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/2ac5773c7d0c00a7efd1fcdce777762856cb7de2', 'message': 'remove six in httpclient.py and requirements.txt\n\nChange-Id: Iddfa30fe626d76d5969719720b52313e69a58129\n'}, {'number': 4, 'created': '2021-01-07 01:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/27df60972af7103273083d1635e2a06ae6aad21a', 'message': 'remove six in httpclient.py and requirements.txt\n\nChange-Id: Iddfa30fe626d76d5969719720b52313e69a58129\n'}, {'number': 5, 'created': '2021-01-07 01:16:12.000000000', 'files': ['venusclient/common/httpclient.py', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/cc48c5acfcb9ec2a9260bec4f3ff7b5f9c452ccb', 'message': 'remove six in httpclient.py and requirements.txt\n\nChange-Id: Iddfa30fe626d76d5969719720b52313e69a58129\n'}]",2,769533,cc48c5acfcb9ec2a9260bec4f3ff7b5f9c452ccb,13,2,5,31825,,,0,"remove six in httpclient.py and requirements.txt

Change-Id: Iddfa30fe626d76d5969719720b52313e69a58129
",git fetch https://review.opendev.org/openstack/python-venusclient refs/changes/33/769533/5 && git format-patch -1 --stdout FETCH_HEAD,"['venusclient/common/httpclient.py', 'requirements.txt']",2,b0f0c303d4a209d8b147738a4771362d1e9a4387,,,six>=1.10.0 # MIT,7,7
openstack%2Fpython-venusclient~master~I1dfb68c8d9ff01bcc684714b794d5ab06cb4d846,openstack/python-venusclient,master,I1dfb68c8d9ff01bcc684714b794d5ab06cb4d846,remove six in cliutils.py,MERGED,2021-01-06 11:38:59.000000000,2021-01-07 09:34:46.000000000,2021-01-07 09:34:46.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 11:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/7d72af4041544c7255b4d5995dfdc419a047bbdb', 'message': 'remove six in cliutils.py\n\nChange-Id: I1dfb68c8d9ff01bcc684714b794d5ab06cb4d846\n'}, {'number': 2, 'created': '2021-01-06 11:54:44.000000000', 'files': ['venusclient/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/c9c3c0027cb81e245f1ebf8d073d1f78e43892bf', 'message': 'remove six in cliutils.py\n\nChange-Id: I1dfb68c8d9ff01bcc684714b794d5ab06cb4d846\n'}]",2,769529,c9c3c0027cb81e245f1ebf8d073d1f78e43892bf,8,2,2,31825,,,0,"remove six in cliutils.py

Change-Id: I1dfb68c8d9ff01bcc684714b794d5ab06cb4d846
",git fetch https://review.opendev.org/openstack/python-venusclient refs/changes/29/769529/1 && git format-patch -1 --stdout FETCH_HEAD,['venusclient/common/cliutils.py'],1,7d72af4041544c7255b4d5995dfdc419a047bbdb,," print(encodeutils.safe_encode(pt.get_string(**kwargs)).decode()) elif isinstance(k_or_v, str): v = str(keys_and_vals_to_strs(v)) if wrap > 0: v = textwrap.fill(str(v), wrap) if v and isinstance(v, str) and r'\n' in v: print(encodeutils.safe_encode(pt.get_string()).decode()) for __ in range(max_password_prompts):","import six from six import moves if six.PY3: print(encodeutils.safe_encode(pt.get_string(**kwargs)).decode()) else: print(encodeutils.safe_encode(pt.get_string(**kwargs))) elif isinstance(k_or_v, six.text_type): v = six.text_type(keys_and_vals_to_strs(v)) if wrap > 0: v = textwrap.fill(six.text_type(v), wrap) if v and isinstance(v, six.string_types) and r'\n' in v: if six.PY3: print(encodeutils.safe_encode(pt.get_string()).decode()) else: print(encodeutils.safe_encode(pt.get_string())) for __ in moves.range(max_password_prompts):",9,15
openstack%2Fpython-venusclient~master~I926320bd72c098e230509742f647b1024cca0b63,openstack/python-venusclient,master,I926320bd72c098e230509742f647b1024cca0b63,remove six in base.py and http.py,MERGED,2021-01-06 11:32:41.000000000,2021-01-07 09:34:42.000000000,2021-01-07 09:34:42.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 11:32:41.000000000', 'files': ['venusclient/common/base.py', 'venusclient/common/http.py'], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/bf99ac0fcaab07cff2f52b43fcc3080e7c0c5cee', 'message': 'remove six in base.py and http.py\n\nChange-Id: I926320bd72c098e230509742f647b1024cca0b63\n'}]",0,769526,bf99ac0fcaab07cff2f52b43fcc3080e7c0c5cee,6,2,1,31825,,,0,"remove six in base.py and http.py

Change-Id: I926320bd72c098e230509742f647b1024cca0b63
",git fetch https://review.opendev.org/openstack/python-venusclient refs/changes/26/769526/1 && git format-patch -1 --stdout FETCH_HEAD,"['venusclient/common/base.py', 'venusclient/common/http.py']",2,bf99ac0fcaab07cff2f52b43fcc3080e7c0c5cee,,"from urllib import parse if isinstance(content, bytes):","import six from six.moves.urllib import parse if isinstance(content, six.binary_type):",3,4
openstack%2Fvenus~master~I668b1480601234d7ac9d77959793366ea9a4c156,openstack/venus,master,I668b1480601234d7ac9d77959793366ea9a4c156,remove six in HACKING.rst,MERGED,2021-01-07 02:19:24.000000000,2021-01-07 09:33:14.000000000,2021-01-07 09:33:14.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-07 02:19:24.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/venus/commit/e5e455ca8ffd78276e2d76c5b0f39788052eaade', 'message': 'remove six in HACKING.rst\n\nChange-Id: I668b1480601234d7ac9d77959793366ea9a4c156\n'}]",0,769640,e5e455ca8ffd78276e2d76c5b0f39788052eaade,6,2,1,32326,,,0,"remove six in HACKING.rst

Change-Id: I668b1480601234d7ac9d77959793366ea9a4c156
",git fetch https://review.opendev.org/openstack/venus refs/changes/40/769640/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,e5e455ca8ffd78276e2d76c5b0f39788052eaade,,,- [N325] str() and unicode() cannot be used on an exception. Remove or use six.text_type().- [C302] six.text_type should be used instead of unicode.,0,2
openstack%2Fpython-venusclient~master~Ibfd1d99979a8e5aae4b265358d92d073f7a0dc08,openstack/python-venusclient,master,Ibfd1d99979a8e5aae4b265358d92d073f7a0dc08,remove six in exceptions.py,MERGED,2021-01-06 11:26:05.000000000,2021-01-07 09:32:16.000000000,2021-01-07 09:32:16.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 11:26:05.000000000', 'files': ['venusclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/31fd85e0326affdfebdb7276d91ba64958ed298a', 'message': 'remove six in exceptions.py\n\nChange-Id: Ibfd1d99979a8e5aae4b265358d92d073f7a0dc08\n'}]",0,769522,31fd85e0326affdfebdb7276d91ba64958ed298a,6,2,1,31825,,,0,"remove six in exceptions.py

Change-Id: Ibfd1d99979a8e5aae4b265358d92d073f7a0dc08
",git fetch https://review.opendev.org/openstack/python-venusclient refs/changes/22/769522/1 && git format-patch -1 --stdout FETCH_HEAD,['venusclient/exceptions.py'],1,31fd85e0326affdfebdb7276d91ba64958ed298a,," if isinstance(error, str): str(body))","import six if isinstance(error, six.string_types): six.text_type(body))",2,3
openstack%2Fdevstack~stable%2Fvictoria~I02c692e95d70017eea03d82d75ae6c5e87bde8b1,openstack/devstack,stable/victoria,I02c692e95d70017eea03d82d75ae6c5e87bde8b1,Install swift keystone extras requirements,MERGED,2020-12-22 18:29:07.000000000,2021-01-07 09:32:02.000000000,2021-01-07 09:30:12.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-22 18:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/07278f2072c8e9d81a3d67b67538a6c74bb0b6fd', 'message': ""Install swift extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n""}, {'number': 2, 'created': '2020-12-23 20:05:08.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/90651cb1a914999afd1dd1e4929c04e62fefb4c8', 'message': ""Install swift keystone extras requirements\n\nSince the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264\ns-proxy is no longer able to launch as keystonemiddleware (listed under\ntest-requirements.txt) has not been installed.\n\nkeystonemiddleware is listed as extras requirements in swift\n- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79\n\nLet's install swift keystone extra requirements also.\n\nCloses-Bug: #1909018\nChange-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1\n(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)\n""}]",0,768174,90651cb1a914999afd1dd1e4929c04e62fefb4c8,15,4,2,8556,,,0,"Install swift keystone extras requirements

Since the introduction of I8f24b839bf42e2fb9803dc7df3a30ae20cf264
s-proxy is no longer able to launch as keystonemiddleware (listed under
test-requirements.txt) has not been installed.

keystonemiddleware is listed as extras requirements in swift
- https://github.com/openstack/swift/blob/e0d46d77fa740768f1dd5b989a63be85ff1fec20/setup.cfg#L79

Let's install swift keystone extra requirements also.

Closes-Bug: #1909018
Change-Id: I02c692e95d70017eea03d82d75ae6c5e87bde8b1
(cherry picked from commit 04b0b61557f7dad6c32b566255c21a36e4b0aefa)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/74/768174/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,07278f2072c8e9d81a3d67b67538a6c74bb0b6fd,bug/1909018, setup_develop $SWIFT_DIR keystone, setup_develop $SWIFT_DIR,1,1
openstack%2Fironic~stable%2Fvictoria~Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c,openstack/ironic,stable/victoria,Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c,Document using ramdisks with the ramdisk deploy interface,MERGED,2021-01-06 13:14:35.000000000,2021-01-07 09:32:01.000000000,2021-01-07 09:30:39.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-01-06 13:14:35.000000000', 'files': ['doc/source/admin/ramdisk-boot.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c0b6044133cdd1afdd7f9b87131934fd0b58385d', 'message': 'Document using ramdisks with the ramdisk deploy interface\n\nChange-Id: Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c\nDepends-On: https://review.opendev.org/c/openstack/ironic-python-agent-builder/+/767376\n(cherry picked from commit 20f25068c627974ae8c38ca249fcd96ec6924ed0)\n'}]",0,769508,c0b6044133cdd1afdd7f9b87131934fd0b58385d,7,2,1,10239,,,0,"Document using ramdisks with the ramdisk deploy interface

Change-Id: Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c
Depends-On: https://review.opendev.org/c/openstack/ironic-python-agent-builder/+/767376
(cherry picked from commit 20f25068c627974ae8c38ca249fcd96ec6924ed0)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/08/769508/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/ramdisk-boot.rst'],1,c0b6044133cdd1afdd7f9b87131934fd0b58385d,ramdisk-stable/victoria,"Creating a ramdisk ------------------ A ramdisk can be created using the ``ironic-ramdisk-base`` element from ironic-python-agent-builder_, e.g. with Debian: .. code-block:: shell export ELEMENTS_PATH=/opt/stack/ironic-python-agent-builder/dib disk-image-create -o /output/ramdisk \ debian-minimal ironic-ramdisk-base openssh-server dhcp-all-interfaces You should consider using the following elements: * openssh-server_ to install the SSH server since it's not provided by default by some minimal images. * devuser_ or dynamic-login_ to provide SSH access. * dhcp-all-interfaces_ or simple-init_ to configure networking. The resulting files (``/output/ramdisk.kernel`` and ``/output/ramdisk.initramfs`` in this case) can then be used when `Booting a ramdisk`_. Booting a ramdisk ----------------- Pass the kernel and ramdisk as normally, also providing the ramdisk as an image source, for example, .. code-block:: shell baremetal node set <NODE> \ --instance-info kernel=http://path/to/ramdisk.kernel \ --instance-info ramdisk=http://path/to/ramdisk.initramfs \ --instance-info image_source=http://path/to/ramdisk.initramfs baremetal node deploy <NODE> .. note:: The requirement to pass ``image_source`` is artificial and will be fixed in a future version of the Bare Metal service. .. _ironic-python-agent-builder: https://opendev.org/openstack/ironic-python-agent-builder .. _openssh-server: https://docs.openstack.org/diskimage-builder/latest/elements/openssh-server/README.html .. _devuser: https://docs.openstack.org/diskimage-builder/latest/elements/devuser/README.html .. _dynamic-login: https://docs.openstack.org/diskimage-builder/latest/elements/dynamic-login/README.html .. _dhcp-all-interfaces: https://docs.openstack.org/diskimage-builder/latest/elements/dhcp-all-interfaces/README.html .. _simple-init: https://docs.openstack.org/diskimage-builder/latest/elements/simple-init/README.html",.. TODO(dtantsur): document how exactly to create and boot a ramdisk,47,1
openstack%2Fpython-venusclient~master~I414642b34e2b8c33553cdb3e2b523a6e6cda98f9,openstack/python-venusclient,master,I414642b34e2b8c33553cdb3e2b523a6e6cda98f9,remove six in venusclient/common/apiclient/exceptions.py,MERGED,2021-01-06 06:58:12.000000000,2021-01-07 09:31:40.000000000,2021-01-07 09:31:40.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 06:58:12.000000000', 'files': ['venusclient/common/apiclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/29a5aa0880649139d232148339f84c2b37f38173', 'message': 'remove six in venusclient/common/apiclient/exceptions.py\n\nChange-Id: I414642b34e2b8c33553cdb3e2b523a6e6cda98f9\n'}]",0,769460,29a5aa0880649139d232148339f84c2b37f38173,6,2,1,31825,,,0,"remove six in venusclient/common/apiclient/exceptions.py

Change-Id: I414642b34e2b8c33553cdb3e2b523a6e6cda98f9
",git fetch https://review.opendev.org/openstack/python-venusclient refs/changes/60/769460/1 && git format-patch -1 --stdout FETCH_HEAD,['venusclient/common/apiclient/exceptions.py'],1,29a5aa0880649139d232148339f84c2b37f38173,, str(body)),import six six.text_type(body)),1,2
openstack%2Fpython-venusclient~master~Id4e91d581b46c9b93860d6b9431352be4642f605,openstack/python-venusclient,master,Id4e91d581b46c9b93860d6b9431352be4642f605,remove six in venusclient/shell.py,MERGED,2021-01-06 06:56:09.000000000,2021-01-07 09:31:37.000000000,2021-01-07 09:31:37.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-06 06:56:09.000000000', 'files': ['venusclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-venusclient/commit/50dd8a94f0e5b56f45929230a63dd5e9a23fd2f0', 'message': 'remove six in venusclient/shell.py\n\nChange-Id: Id4e91d581b46c9b93860d6b9431352be4642f605\n'}]",0,769459,50dd8a94f0e5b56f45929230a63dd5e9a23fd2f0,6,2,1,31825,,,0,"remove six in venusclient/shell.py

Change-Id: Id4e91d581b46c9b93860d6b9431352be4642f605
",git fetch https://review.opendev.org/openstack/python-venusclient refs/changes/59/769459/1 && git format-patch -1 --stdout FETCH_HEAD,['venusclient/shell.py'],1,50dd8a94f0e5b56f45929230a63dd5e9a23fd2f0,," print(""ERROR: %s"" % encodeutils.safe_encode(str(e)),","import six print(""ERROR: %s"" % encodeutils.safe_encode(six.text_type(e)),",1,2
openstack%2Fnetworking-generic-switch~master~I08b44ed592cbe0a8b60b8afffb3db24e0faadc3f,openstack/networking-generic-switch,master,I08b44ed592cbe0a8b60b8afffb3db24e0faadc3f,Use TOX_CONSTRAINTS_FILE,MERGED,2021-01-07 02:06:41.000000000,2021-01-07 09:18:26.000000000,2021-01-07 09:17:10.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-01-07 02:06:41.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/dd50b6fe28f5547ed3a13f38763f75845a51209b', 'message': 'Use TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I08b44ed592cbe0a8b60b8afffb3db24e0faadc3f\n'}]",0,769636,dd50b6fe28f5547ed3a13f38763f75845a51209b,8,3,1,32238,,,0,"Use TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I08b44ed592cbe0a8b60b8afffb3db24e0faadc3f
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/36/769636/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dd50b6fe28f5547ed3a13f38763f75845a51209b,, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},4,4
openstack%2Fmagnum~master~I491eaad57285159c43f77df08b5163170fa6220b,openstack/magnum,master,I491eaad57285159c43f77df08b5163170fa6220b,DNM fix ca-bundle,ABANDONED,2020-11-12 12:24:08.000000000,2021-01-07 09:17:51.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-12 12:24:08.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fcct-config.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/67c23ccf1535d3d40b5755d297c854ead2eab745', 'message': 'DNM fix ca-bundle\n\nChange-Id: I491eaad57285159c43f77df08b5163170fa6220b\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",0,762510,67c23ccf1535d3d40b5755d297c854ead2eab745,3,1,1,20498,,,0,"DNM fix ca-bundle

Change-Id: I491eaad57285159c43f77df08b5163170fa6220b
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/10/762510/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fcct-config.yaml']",2,67c23ccf1535d3d40b5755d297c854ead2eab745,drop-hyperkube, mkdir -p /etc/kubernetes/ cp /etc/pki/tls/certs/ca-bundle.crt /etc/kubernetes/ca-bundle.crt , ,12,25
openstack%2Fmagnum~master~Ie91ec7195c46790aea1c0b001688be7cf36e1f48,openstack/magnum,master,Ie91ec7195c46790aea1c0b001688be7cf36e1f48,ci: Bump bashate version,ABANDONED,2020-12-08 11:47:39.000000000,2021-01-07 09:17:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-08 11:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6723b444d2a65f783a6e354c2cbffea3ff5339b4', 'message': 'ci: Bump bashate version\n\nChange-Id: Ie91ec7195c46790aea1c0b001688be7cf36e1f48\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 2, 'created': '2020-12-15 21:31:18.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/11f6e3700b204365ffdd96fe46a05e4fb1a9692c', 'message': 'ci: Bump bashate version\n\nChange-Id: Ie91ec7195c46790aea1c0b001688be7cf36e1f48\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",0,765979,11f6e3700b204365ffdd96fe46a05e4fb1a9692c,5,1,2,20498,,,0,"ci: Bump bashate version

Change-Id: Ie91ec7195c46790aea1c0b001688be7cf36e1f48
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/79/765979/2 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,6723b444d2a65f783a6e354c2cbffea3ff5339b4,fix-bashate,bashate==2.0.0,bashate==0.5.1,1,1
openstack%2Fpanko~master~Ia145ab8a4758169cbbdd6c8d7fd067e979a1a66f,openstack/panko,master,Ia145ab8a4758169cbbdd6c8d7fd067e979a1a66f,Update the README to point to storyboard,MERGED,2020-12-01 09:59:22.000000000,2021-01-07 09:13:17.000000000,2021-01-07 09:12:08.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-01 09:59:22.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/panko/commit/d51de0091417b3a10c4aee7846337895187aad35', 'message': 'Update the README to point to storyboard\n\nChange-Id: Ia145ab8a4758169cbbdd6c8d7fd067e979a1a66f\n'}]",0,764918,d51de0091417b3a10c4aee7846337895187aad35,7,2,1,4264,,,0,"Update the README to point to storyboard

Change-Id: Ia145ab8a4758169cbbdd6c8d7fd067e979a1a66f
",git fetch https://review.opendev.org/openstack/panko refs/changes/18/764918/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d51de0091417b3a10c4aee7846337895187aad35,readme,The Panko project is an event storage service that provides the ability to store and querying event data generated by Ceilometer with potentially other sources. Panko is a component of the OpenStack Telemetry project.- Bugs: https://storyboard.openstack.org/#!/project/openstack/panko,- Bugs: https://bugs.launchpad.net/panko,6,1
openstack%2Fcharm-ceph-radosgw~stable%2F20.10~I6a55e46422a19ea27193518a41a48b768b980212,openstack/charm-ceph-radosgw,stable/20.10,I6a55e46422a19ea27193518a41a48b768b980212,Ensure valid configuration before zone creation,ABANDONED,2020-12-08 05:03:23.000000000,2021-01-07 09:00:25.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-08 05:03:23.000000000', 'files': ['hooks/hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/b5d8b09e600a34b283020afbbb8c17202233d788', 'message': ""Ensure valid configuration before zone creation\n\nCheck that the 'mon' context was listed as complete prior to\nattempting to undertake any type of zone configuration.\n\nThis should ensure that the ceph.conf file is complete.\n\nChange-Id: I6a55e46422a19ea27193518a41a48b768b980212\nCloses-Bug: 1905985\n""}]",0,765907,b5d8b09e600a34b283020afbbb8c17202233d788,5,2,1,935,,,0,"Ensure valid configuration before zone creation

Check that the 'mon' context was listed as complete prior to
attempting to undertake any type of zone configuration.

This should ensure that the ceph.conf file is complete.

Change-Id: I6a55e46422a19ea27193518a41a48b768b980212
Closes-Bug: 1905985
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/07/765907/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/hooks.py'],1,b5d8b09e600a34b283020afbbb8c17202233d788,bug/1905985, elif is_leader() and 'mon' in CONFIGS.complete_contexts():, elif is_leader():,1,1
openstack%2Fceilometer~master~I491b25ea97ee97426d314ff72d9b11fe3682444b,openstack/ceilometer,master,I491b25ea97ee97426d314ff72d9b11fe3682444b,Imported Translations from Zanata,MERGED,2020-12-20 06:20:17.000000000,2021-01-07 08:53:16.000000000,2021-01-07 08:51:52.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-20 06:20:17.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8c1e6926799f47ffb7fceb3cef2ab1d1c1dd5e90', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I491b25ea97ee97426d314ff72d9b11fe3682444b\n'}]",0,768001,8c1e6926799f47ffb7fceb3cef2ab1d1c1dd5e90,8,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I491b25ea97ee97426d314ff72d9b11fe3682444b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/01/768001/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,8c1e6926799f47ffb7fceb3cef2ab1d1c1dd5e90,zanata/translations,"""POT-Creation-Date: 2020-12-14 07:20+0000\n""""PO-Revision-Date: 2020-12-19 01:24+0000\n""msgid ""15.0.0-24"" msgstr ""15.0.0-24""","""POT-Creation-Date: 2020-12-11 09:42+0000\n""""PO-Revision-Date: 2020-12-13 12:33+0000\n""msgid ""15.0.0-23"" msgstr ""15.0.0-23""",4,4
openstack%2Fcharm-ceph-radosgw~master~I241b83f748b36aad645d0296acb73d9b654ca60a,openstack/charm-ceph-radosgw,master,I241b83f748b36aad645d0296acb73d9b654ca60a,Fix race condition in default zone creation,MERGED,2020-11-30 11:36:25.000000000,2021-01-07 08:46:47.000000000,2021-01-07 08:46:47.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-30 11:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/1e879960523ee98298a21a37b346d7f8457d3531', 'message': 'Fix race condition in default zone creation\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 2, 'created': '2020-11-30 14:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/71f4de1171c66f2d26a4636db3da1d665d65225f', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to bump simplejson to work\naround a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 3, 'created': '2020-11-30 14:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/db1e5a3c02d45c246404c0d951a5202fcc7634a6', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 4, 'created': '2020-11-30 15:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/b16aee20bef231b16dfbdfe3d9b5b1c78b5910bc', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 5, 'created': '2020-11-30 16:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/57221e2a6dc3ff697d86955389909bde60d813d6', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 6, 'created': '2020-11-30 22:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/5bd083f811479c2a9d7aee87d6d2e0f7d0fcaea0', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 7, 'created': '2020-12-01 07:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/6d2da998703ad826ec1ecbc1c0adbe064e02e93c', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 8, 'created': '2020-12-01 12:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/954a42656d0878ed0d65d5625268142596e189a5', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 9, 'created': '2020-12-01 12:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/13d5bc0758c15d8258ba32e7d3426ed8cdf90318', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 10, 'created': '2020-12-01 13:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/672a3ef2fdfafe5d899c67a07b79a9f696c42bc3', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge because: attempting to pin packages in order\nto work around a ""pip install"" failure on python 3.5\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 11, 'created': '2020-12-01 16:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/6e4a18306b3e52137271458962ad64a5ed378a22', 'message': 'Fix race condition in default zone creation\n\nAlso pulled latest (test-)requirements.txt containing\nhttps://github.com/openstack-charmers/release-tools/pull/124\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 12, 'created': '2020-12-03 14:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/19d294ae4ac67fcd4cd69e94dfe8f978c6400e20', 'message': 'Fix race condition in default zone creation\n\nAlso pulled latest (test-)requirements.txt containing\nhttps://github.com/openstack-charmers/release-tools/pull/125\nin order to pin pip < 20.3\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 13, 'created': '2020-12-03 14:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/88c3a84b64e03c9ab6811fc1dbda24ca8ffec230', 'message': '[DO NOT MERGE] Fix race condition in default zone creation\n\nDO NOT MERGE: validating fix for zuul cover job. To be\ncopied back to release-tools#125 if it works.\n\nAlso pulled latest (test-)requirements.txt containing\nhttps://github.com/openstack-charmers/release-tools/pull/125\nin order to pin pip < 20.3\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 14, 'created': '2020-12-03 15:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/75f140ec873297071007d3af01157274531ac1e8', 'message': 'Fix race condition in default zone creation\n\nAlso pulled latest (test-)requirements.txt containing\nhttps://github.com/openstack-charmers/release-tools/pull/125\nin order to pin pip < 20.3\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 15, 'created': '2020-12-03 15:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/e6d31d8709a04134697c4123b9c8b10441699600', 'message': 'Fix race condition in default zone creation\n\nAlso pulled latest (test-)requirements.txt containing\nhttps://github.com/openstack-charmers/release-tools/pull/125\nin order to pin pip < 20.3\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 16, 'created': '2020-12-04 09:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/18e499c80c7d12b411afa11109fb170e71cde618', 'message': 'Fix race condition in default zone creation\n\nAlso pulled latest (test-)requirements.txt containing\nhttps://github.com/openstack-charmers/release-tools/pull/125\nin order to pin pip < 20.3\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 17, 'created': '2020-12-08 13:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/67a03bdd051b5353a59da50f61291bca1da3adce', 'message': ""[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge: jamespage's comments to be addressed. For now\nmisusing this review to validate the linked release-tools\nchanges.\n\nAlso pulled latest (test-)requirements.txt containing the\nfollowing changes in order to pin pip < 20.3:\nhttps://github.com/openstack-charmers/release-tools/pull/125\nhttps://github.com/openstack-charmers/release-tools/pull/126\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n""}, {'number': 18, 'created': '2020-12-10 09:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/b5661acb5c0550e724444dd4cf27f3bde5248a41', 'message': ""[DO NOT MERGE] Fix race condition in default zone creation\n\nDo not merge: jamespage's comments to be addressed. For now\nmisusing this review to validate the linked release-tools\nchanges.\n\nAlso pulled latest (test-)requirements.txt containing the\nfollowing changes in order to pin pip < 20.3:\nhttps://github.com/openstack-charmers/release-tools/pull/125\nhttps://github.com/openstack-charmers/release-tools/pull/126\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n""}, {'number': 19, 'created': '2020-12-15 21:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/631fa4460087f11f8025711030e9f0f0025abd56', 'message': 'Fix race condition in default zone creation\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}, {'number': 20, 'created': '2020-12-18 14:41:43.000000000', 'files': ['hooks/hooks.py', 'unit_tests/test_hooks.py', 'unit_tests/test_multisite.py', 'hooks/multisite.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/f35f3e0392e6b841d3899d522d38bd6b3621277b', 'message': 'Fix race condition in default zone creation\n\nChange-Id: I241b83f748b36aad645d0296acb73d9b654ca60a\nCloses-Bug: #1905985\n'}]",2,764641,f35f3e0392e6b841d3899d522d38bd6b3621277b,106,4,20,31289,,,0,"Fix race condition in default zone creation

Change-Id: I241b83f748b36aad645d0296acb73d9b654ca60a
Closes-Bug: #1905985
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/41/764641/9 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/hooks.py', 'unit_tests/test_hooks.py', 'unit_tests/test_multisite.py', 'hooks/multisite.py']",4,1e879960523ee98298a21a37b346d7f8457d3531,bug/1905985," return subprocess.check_output(cmd, stderr=subprocess.PIPE).decode('UTF-8')", return subprocess.check_output(cmd).decode('UTF-8'),45,21
openstack%2Fopenstack-helm~master~I63521ff9609ad89485a843bc0fbddb00e38dccc8,openstack/openstack-helm,master,I63521ff9609ad89485a843bc0fbddb00e38dccc8,Cinder: Enable iscsi to work correctly in cinder volume,MERGED,2021-01-06 17:51:36.000000000,2021-01-07 08:45:00.000000000,2021-01-07 08:43:54.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18236}, {'_account_id': 18250}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 24780}, {'_account_id': 28719}, {'_account_id': 30495}, {'_account_id': 30746}]","[{'number': 1, 'created': '2021-01-06 17:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/df3e75dccfb1661854a4656c8defd5a2d4a3e2b0', 'message': 'Signed-off-by: intlabs <pete@port.direct>\nChange-Id: I63521ff9609ad89485a843bc0fbddb00e38dccc8\n'}, {'number': 2, 'created': '2021-01-06 18:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5ea95e9b832d41a1dfa39b91734daea242a12133', 'message': 'Signed-off-by: intlabs <pete@port.direct>\nChange-Id: I63521ff9609ad89485a843bc0fbddb00e38dccc8\n'}, {'number': 3, 'created': '2021-01-06 20:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ad3148eb902c0334bee9d12f8a3e8d293ef48df1', 'message': 'Signed-off-by: intlabs <pete@port.direct>\nChange-Id: I63521ff9609ad89485a843bc0fbddb00e38dccc8\n'}, {'number': 4, 'created': '2021-01-06 20:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/893b74c10b2e70301218d1af85dcbf7894f6f6ca', 'message': 'Cinder: Enable iscsi to work correctly in cinder volume\n\nThis PS enables iscsi actions to work correctly in cinder\nvolume - enabling things like conversion of glance images\nto cinder volumes (required for nova-boot-from-volume)\n\nSigned-off-by: intlabs <pete@port.direct>\nChange-Id: I63521ff9609ad89485a843bc0fbddb00e38dccc8\n'}, {'number': 5, 'created': '2021-01-06 20:15:37.000000000', 'files': ['cinder/templates/deployment-volume.yaml', 'cinder/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/97187997e47057bd2049a5f4e351807bbc4257e0', 'message': 'Cinder: Enable iscsi to work correctly in cinder volume\n\nThis PS enables iscsi actions to work correctly in cinder\nvolume - enabling things like conversion of glance images\nto cinder volumes (required for nova-boot-from-volume)\n\nChange-Id: I63521ff9609ad89485a843bc0fbddb00e38dccc8\nSigned-off-by: Pete Birley <pete@port.direct>\n'}]",2,769575,97187997e47057bd2049a5f4e351807bbc4257e0,34,11,5,23928,,,0,"Cinder: Enable iscsi to work correctly in cinder volume

This PS enables iscsi actions to work correctly in cinder
volume - enabling things like conversion of glance images
to cinder volumes (required for nova-boot-from-volume)

Change-Id: I63521ff9609ad89485a843bc0fbddb00e38dccc8
Signed-off-by: Pete Birley <pete@port.direct>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/75/769575/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/templates/deployment-volume.yaml', 'cinder/values.yaml']",2,df3e75dccfb1661854a4656c8defd5a2d4a3e2b0,, volume: requiredDuringSchedulingIgnoredDuringExecution useHostPID: volume: true useHostIPC: volume: true enable_iscsi: true configmap_bin: false configmap_etc: false cron_volume_usage_audit: false deployment_api: false deployment_backup: false deployment_scheduler: false ingress_api: false job_backup_storage_init: false job_bootstrap: false job_clean: false job_create_internal_tenant: false job_db_init: false job_image_repo_sync: false job_rabbit_init: false job_db_sync: false job_ks_endpoints: false job_ks_service: false job_ks_user: false job_storage_init: false pdb_api: false pod_rally_test: false pvc_backup: false secret_db: false secret_ingress_tls: false secret_keystone: false secret_rabbitmq: false service_api: false service_ingress_api: false, enable_iscsi: false configmap_bin: true configmap_etc: true cron_volume_usage_audit: true deployment_api: true deployment_backup: true deployment_scheduler: true ingress_api: true job_backup_storage_init: true job_bootstrap: true job_clean: true job_create_internal_tenant: true job_db_init: true job_image_repo_sync: true job_rabbit_init: true job_db_sync: true job_ks_endpoints: true job_ks_service: true job_ks_user: true job_storage_init: true pdb_api: true pod_rally_test: true pvc_backup: true secret_db: true secret_ingress_tls: true secret_keystone: true secret_rabbitmq: true service_api: true service_ingress_api: true,48,29
openstack%2Fcharm-ceph-iscsi~master~I6d28291ea111978b26567836c1608e65391c199c,openstack/charm-ceph-iscsi,master,I6d28291ea111978b26567836c1608e65391c199c,More tolerant ceph client relation unit test,MERGED,2020-12-15 18:34:35.000000000,2021-01-07 08:35:37.000000000,2021-01-07 08:35:37.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-12-15 18:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/0dd275d1acbc8778a568c92d36bd9f086db44496', 'message': 'Fix VMware links in README\n\nChange-Id: I6d28291ea111978b26567836c1608e65391c199c\n'}, {'number': 2, 'created': '2020-12-17 10:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/7ce13bc4c67d78ef90bd13e4e338f18f9afb61f8', 'message': 'Fix VMware links in README\n\nAlso made unit tests more tolerant. After recent work\non the cinder-ceph replication, a new\nrbd-mirroring-mode attribute has been added to the\ncreate-pool broker requests.\n\nChange-Id: I6d28291ea111978b26567836c1608e65391c199c\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 3, 'created': '2020-12-18 11:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/d89508d349d636484d59e4e1c458a77615658d1d', 'message': 'Fix VMware links in README\n\nAlso made unit tests more tolerant. After recent work\non the cinder-ceph replication, a new\nrbd-mirroring-mode attribute has been added to the\ncreate-pool broker requests.\n\nChange-Id: I6d28291ea111978b26567836c1608e65391c199c\nFunc-Test-Pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/475\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 4, 'created': '2020-12-18 21:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/aabfdd20d79a8eb7721e62f2af7c150738a762ce', 'message': 'Fix VMware links in README\n\nActually reverted README to its original state.\n\nAlso made unit tests more tolerant. After recent work\non the cinder-ceph replication, a new\nrbd-mirroring-mode attribute has been added to the\ncreate-pool broker requests.\n\nChange-Id: I6d28291ea111978b26567836c1608e65391c199c\nFunc-Test-Pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/475\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 5, 'created': '2020-12-18 21:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/f55ca384f858fcc4cf38cc059d3eefc02cb2bc90', 'message': 'More tolerant ceph client relation unit test\n\nMade unit tests more tolerant. After recent work\non the cinder-ceph replication, a new\nrbd-mirroring-mode attribute has been added to the\ncreate-pool broker requests.\n\nChange-Id: I6d28291ea111978b26567836c1608e65391c199c\nFunc-Test-Pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/475\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 6, 'created': '2021-01-06 13:10:46.000000000', 'files': ['unit_tests/test_ceph_iscsi_charm.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-iscsi/commit/cd09ecfd0495e70af9f4034212d83451f6068314', 'message': 'More tolerant ceph client relation unit test\n\nMade unit tests more tolerant. After recent work\non the cinder-ceph replication, a new\nrbd-mirroring-mode attribute has been added to the\ncreate-pool broker requests.\n\nChange-Id: I6d28291ea111978b26567836c1608e65391c199c\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}]",0,767198,cd09ecfd0495e70af9f4034212d83451f6068314,36,5,6,30561,,,0,"More tolerant ceph client relation unit test

Made unit tests more tolerant. After recent work
on the cinder-ceph replication, a new
rbd-mirroring-mode attribute has been added to the
create-pool broker requests.

Change-Id: I6d28291ea111978b26567836c1608e65391c199c
Co-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-ceph-iscsi refs/changes/98/767198/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,0dd275d1acbc8778a568c92d36bd9f086db44496,fix-vmware-link-in-readme,documented under [VMware integration][ceph-docs-vmware-integration] in the [Charmed Ceph documentation][ceph-docs].[ceph-docs-vmware-integration]: https://ubuntu.com/ceph/docs/integration-vmware [ceph-docs]: https://ubuntu.com/ceph/docs,documented under [Ceph iSCSI][cdg-ceph-iscsi] in the [OpenStack Charms Deployment Guide][cdg].[cg-preview-charms]: https://docs.openstack.org/charm-guide/latest/openstack-charms.html#tech-preview-charms-beta [cdg-ceph-iscsi]: https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-ceph-iscsi.html,4,4
openstack%2Fcyborg-tempest-plugin~master~I071c334fe9338b3c1fd414ded54d3413685fddce,openstack/cyborg-tempest-plugin,master,I071c334fe9338b3c1fd414ded54d3413685fddce,add list deployables method and api test,ABANDONED,2020-12-21 01:26:40.000000000,2021-01-07 08:26:08.000000000,,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-12-21 01:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/9f92cb456db74f3f434f1dc7348e5c32797a9628', 'message': 'add list deployables method and api test\n\nadd list deployables method and basic api testcase\nChange-Id: I071c334fe9338b3c1fd414ded54d3413685fddce\n'}, {'number': 2, 'created': '2020-12-21 01:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/373f4b4f316251b85244ba818b60dc2c5436124d', 'message': 'add list deployables method and api test\n\nadd list deployables method and basic api testcase\nChange-Id: I071c334fe9338b3c1fd414ded54d3413685fddce\n'}, {'number': 3, 'created': '2020-12-21 02:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/9988a626f5cbee39077c8d81b061960fcc7eadde', 'message': 'add list deployables method and api test\n\nadd list deployables method and basic api testcase\nChange-Id: I071c334fe9338b3c1fd414ded54d3413685fddce\n'}, {'number': 4, 'created': '2021-01-07 06:27:19.000000000', 'files': ['cyborg_tempest_plugin/tests/api/test_deployable.py', 'cyborg_tempest_plugin/services/cyborg_rest_client.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/ef556956025d60f21fcc0fa04fe2eb5c447623ec', 'message': 'add list deployables method and api test\n\nadd list deployables method and basic api testcase\nChange-Id: I071c334fe9338b3c1fd414ded54d3413685fddce\n'}]",3,768031,ef556956025d60f21fcc0fa04fe2eb5c447623ec,12,3,4,30409,,,0,"add list deployables method and api test

add list deployables method and basic api testcase
Change-Id: I071c334fe9338b3c1fd414ded54d3413685fddce
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/31/768031/4 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg_tempest_plugin/tests/api/test_deployable.py', 'cyborg_tempest_plugin/services/cyborg_rest_client.py']",2,9f92cb456db74f3f434f1dc7348e5c32797a9628,master5," def list_deployables(self): resp, body = self.get(""/deployables"") return self._response_helper(resp, body) ",,33,0
openstack%2Fcloudkitty-dashboard~master~Ie3092d5b403e75fe75d09f5c1db0f14a7a6e1b77,openstack/cloudkitty-dashboard,master,Ie3092d5b403e75fe75d09f5c1db0f14a7a6e1b77,remove unicode from code,ABANDONED,2021-01-07 01:23:25.000000000,2021-01-07 08:10:22.000000000,,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-07 01:23:25.000000000', 'files': ['cloudkittydashboard/tests/test_predictive_pricing.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/7406dfccea6fd9033b9342a02e20cfdbb4bd48e5', 'message': 'remove unicode from code\n\nChange-Id: Ie3092d5b403e75fe75d09f5c1db0f14a7a6e1b77\n'}]",0,769631,7406dfccea6fd9033b9342a02e20cfdbb4bd48e5,4,2,1,32921,,,0,"remove unicode from code

Change-Id: Ie3092d5b403e75fe75d09f5c1db0f14a7a6e1b77
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/31/769631/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkittydashboard/tests/test_predictive_pricing.py'],1,7406dfccea6fd9033b9342a02e20cfdbb4bd48e5,," expected_body = [{'service': 'test_service'}, {'other_key': None, 'service': 'test_service'}]"," expected_body = [{u'service': 'test_service'}, {u'other_key': None, 'service': 'test_service'}]",2,2
openstack%2Fcloudkitty-dashboard~master~Ibb32b752d02ee0105fb598608e46d920f1e042dc,openstack/cloudkitty-dashboard,master,Ibb32b752d02ee0105fb598608e46d920f1e042dc,remove unicode from code,ABANDONED,2021-01-07 01:22:11.000000000,2021-01-07 08:09:53.000000000,,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-07 01:22:11.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/6b75285ea6f2201a22316bad539dc0e25b201267', 'message': 'remove unicode from code\n\nChange-Id: Ibb32b752d02ee0105fb598608e46d920f1e042dc\n'}]",0,769630,6b75285ea6f2201a22316bad539dc0e25b201267,4,2,1,32921,,,0,"remove unicode from code

Change-Id: Ibb32b752d02ee0105fb598608e46d920f1e042dc
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/30/769630/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,6b75285ea6f2201a22316bad539dc0e25b201267,,"project = 'Cloudkitty Dashboard Release Notes' copyright = '2016, Cloudkitty developers' ('index', 'PythonCloudkitty.tex', 'Cloudkitty Release Notes Documentation', 'Cloudkitty developers', 'manual'), 'Cloudkitty Dashboard Release Notes Documentation', ['Cloudkitty developers'], 1) 'Cloudkitty Dashboard Release Notes Documentation', 'Cloudkitty Dashboard developers', 'CloudkittyDashboard',","project = u'Cloudkitty Dashboard Release Notes' copyright = u'2016, Cloudkitty developers' ('index', 'PythonCloudkitty.tex', u'Cloudkitty Release Notes Documentation', u'Cloudkitty developers', 'manual'), u'Cloudkitty Dashboard Release Notes Documentation', [u'Cloudkitty developers'], 1) u'Cloudkitty Dashboard Release Notes Documentation', u'Cloudkitty Dashboard developers', 'CloudkittyDashboard',",8,8
openstack%2Fcloudkitty-dashboard~master~If724393df178491a7300c3717ca63572d73f0a4a,openstack/cloudkitty-dashboard,master,If724393df178491a7300c3717ca63572d73f0a4a,remove unicode from code,ABANDONED,2021-01-07 01:17:05.000000000,2021-01-07 08:09:19.000000000,,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-07 01:17:05.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/6070ad7385fa6e1a753e974f9abb06aa64eb67ba', 'message': 'remove unicode from code\n\nChange-Id: If724393df178491a7300c3717ca63572d73f0a4a\n'}]",0,769628,6070ad7385fa6e1a753e974f9abb06aa64eb67ba,5,2,1,32921,,,0,"remove unicode from code

Change-Id: If724393df178491a7300c3717ca63572d73f0a4a
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/28/769628/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,6070ad7385fa6e1a753e974f9abb06aa64eb67ba,,"project = 'cloudkitty-dashboard' copyright = '2014, Objectif Libre' 'Cloudkitty-Dashboard Documentation', 'OpenStack Foundation', 'howto', True '%s Documentation' % project, ['Objectif Libre'], '%s Documentation' % project, 'Objectif Libre',","project = u'cloudkitty-dashboard' copyright = u'2014, Objectif Libre' u'Cloudkitty-Dashboard Documentation', u'OpenStack Foundation', 'howto', True u'%s Documentation' % project, [u'Objectif Libre'], u'%s Documentation' % project, u'Objectif Libre',",8,8
openstack%2Fkuryr-kubernetes~master~Ia8374173075d14a0487ee2bca22c2480efd005ef,openstack/kuryr-kubernetes,master,Ia8374173075d14a0487ee2bca22c2480efd005ef,CNI docs: Fix return code,MERGED,2021-01-05 14:38:08.000000000,2021-01-07 07:55:07.000000000,2021-01-07 07:53:56.000000000,"[{'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2021-01-05 14:38:08.000000000', 'files': ['doc/source/devref/kuryr_kubernetes_design.rst'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/478257afc6091d11be737eace3a6d7bb70a6ca33', 'message': 'CNI docs: Fix return code\n\nChange-Id: Ia8374173075d14a0487ee2bca22c2480efd005ef\nCloses-Bug: 1909113\n'}]",0,769354,478257afc6091d11be737eace3a6d7bb70a6ca33,8,4,1,11600,,,0,"CNI docs: Fix return code

Change-Id: Ia8374173075d14a0487ee2bca22c2480efd005ef
Closes-Bug: 1909113
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/54/769354/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/kuryr_kubernetes_design.rst'],1,478257afc6091d11be737eace3a6d7bb70a6ca33,bug/1909113,**Return code:** 202 Accepted,**Return code:** 201 Created,1,1
openstack%2Fopenstack-virtual-baremetal~master~I363cec4d81b6cc45d77b9c6651d71a6669b8dc4f,openstack/openstack-virtual-baremetal,master,I363cec4d81b6cc45d77b9c6651d71a6669b8dc4f,[DNM]Just checking if CI is working,ABANDONED,2020-12-18 06:53:42.000000000,2021-01-07 07:36:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-18 06:53:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/2c9f04173ac7ea023b7d28279a74af12f202c696', 'message': '[DNM]\xa0Just checking if CI is working\n\nChange-Id: I363cec4d81b6cc45d77b9c6651d71a6669b8dc4f\n'}]",0,767670,2c9f04173ac7ea023b7d28279a74af12f202c696,4,2,1,24245,,,0,"[DNM]Just checking if CI is working

Change-Id: I363cec4d81b6cc45d77b9c6651d71a6669b8dc4f
",git fetch https://review.opendev.org/openstack/openstack-virtual-baremetal refs/changes/70/767670/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2c9f04173ac7ea023b7d28279a74af12f202c696,dnm-test-ci,# Do not merge,,1,0
openstack%2Ftripleo-heat-templates~master~I3a35c4b46536fa2916d9fa387278077884adaf68,openstack/tripleo-heat-templates,master,I3a35c4b46536fa2916d9fa387278077884adaf68,Concatenate host_routes and default route in overcloud.yaml,MERGED,2020-10-02 07:25:46.000000000,2021-01-07 07:35:16.000000000,2020-10-09 13:09:42.000000000,"[{'_account_id': 3153}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-10-02 07:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/523f9668c9566be3f0238bbbf272ba80c6739557', 'message': 'Concatenate host_routes and default route in overcloud.yaml\n\nPrevioously the default route was concatenated with the\nhost_routes in the NetworkConfig. This change moves that\nconcatenation to overcloud.yaml.\n\nGroupVars {{network.name_lower}}_host_routes and\nctlplane_host_routes will have the default route appended\nbased on role.default_route_networks setting.\n\nFor heat base NetworkConfig the parameters\nControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes\nwill have the default route appropriately appended.\n\nDoing the concatenation in overcloud.yaml enable simplified\nuser-facing NetwrokConfig templates.\n\nChange-Id: I3a35c4b46536fa2916d9fa387278077884adaf68\n'}, {'number': 2, 'created': '2020-10-02 09:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55dbc2aa57733515c82a19d9dc2a8114a0123ea4', 'message': 'Concatenate host_routes and default route in overcloud.yaml\n\nPrevioously the default route was concatenated with the\nhost_routes in the NetworkConfig. This change moves that\nconcatenation to overcloud.yaml.\n\nGroupVars {{network.name_lower}}_host_routes and\nctlplane_host_routes will have the default route appended\nbased on role.default_route_networks setting.\n\nFor heat base NetworkConfig the parameters\nControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes\nwill have the default route appropriately appended.\n\nDoing the concatenation in overcloud.yaml enable simplified\nuser-facing NetwrokConfig templates.\n\nChange-Id: I3a35c4b46536fa2916d9fa387278077884adaf68\n'}, {'number': 3, 'created': '2020-10-03 18:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d2b4db26b4f74701dcfa594ce67fd895be3a02e2', 'message': 'Concatenate host_routes and default route in overcloud.yaml\n\nPrevioously the default route was concatenated with the\nhost_routes in the NetworkConfig. This change moves that\nconcatenation to overcloud.yaml.\n\nGroupVars {{network.name_lower}}_host_routes and\nctlplane_host_routes will have the default route appended\nbased on role.default_route_networks setting.\n\nFor heat base NetworkConfig the parameters\nControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes\nwill have the default route appropriately appended.\n\nDoing the concatenation in overcloud.yaml enable simplified\nuser-facing NetwrokConfig templates.\n\nChange-Id: I3a35c4b46536fa2916d9fa387278077884adaf68\n'}, {'number': 4, 'created': '2020-10-03 23:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2d907a9d4ffee2a072a7316b8d63de04b0abbd04', 'message': 'Concatenate host_routes and default route in overcloud.yaml\n\nPrevioously the default route was concatenated with the\nhost_routes in the NetworkConfig. This change moves that\nconcatenation to overcloud.yaml.\n\nGroupVars {{network.name_lower}}_host_routes and\nctlplane_host_routes will have the default route appended\nbased on role.default_route_networks setting.\n\nFor heat base NetworkConfig the parameters\nControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes\nwill have the default route appropriately appended.\n\nDoing the concatenation in overcloud.yaml enable simplified\nuser-facing NetwrokConfig templates.\n\nChange-Id: I3a35c4b46536fa2916d9fa387278077884adaf68\n'}, {'number': 5, 'created': '2020-10-04 05:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8e4b6001af2160cc43b8657b16bcfceb536e9396', 'message': ""Concatenate host_routes and default route in overcloud.yaml\n\nPrevioously the default route was concatenated with the\nhost_routes in the NetworkConfig. This change moves that\nconcatenation to overcloud.yaml.\n\nGroupVars {{network.name_lower}}_host_routes and\nctlplane_host_routes will have the default route appended\nbased on role.default_route_networks setting.\n\nFor heat base NetworkConfig the parameters\nControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes\nwill have the default route appropriately appended.\n\nDoing the concatenation in overcloud.yaml enable simplified\nuser-facing NetwrokConfig templates.\n\nFor standalone and undercloud define the default_route_networks\nwith an empty list. Cannot leave it undefined as this will\ndefault the default route to the ctlplane's gateway. Undercloud\nand Standalone uses the management interface as the gateway by\ndefault, so we should not set a default gateway for these roles.\n\nChange-Id: I3a35c4b46536fa2916d9fa387278077884adaf68\n""}, {'number': 6, 'created': '2020-10-04 10:29:00.000000000', 'files': ['roles/Standalone.yaml', 'network/config/single-nic-vlans/controller-no-external.j2.yaml', 'network/config/single-nic-linux-bridge-vlans/role.role.j2.yaml', 'network/config/multiple-nics-vlans/compute-dvr.j2.yaml', 'overcloud.j2.yaml', 'roles/UndercloudMinion.yaml', 'network/config/single-nic-vlans/role.role.j2.yaml', 'network/config/bond-with-vlans/controller-no-external.j2.yaml', 'network/config/multiple-nics/compute-dvr.j2.yaml', 'network/config/multiple-nics-vlans/role.role.j2.yaml', 'network/config/bond-with-vlans/role.role.j2.yaml', 'network/config/multiple-nics/role.role.j2.yaml', 'roles_data_undercloud.yaml', 'roles/Undercloud.yaml', 'network/config/2-linux-bonds-vlans/role.role.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/34fae762aab364559bfcc29510b1c69957dd21f4', 'message': ""Concatenate host_routes and default route in overcloud.yaml\n\nPrevioously the default route was concatenated with the\nhost_routes in the NetworkConfig. This change moves that\nconcatenation to overcloud.yaml.\n\nGroupVars {{network.name_lower}}_host_routes and\nctlplane_host_routes will have the default route appended\nbased on role.default_route_networks setting.\n\nFor heat base NetworkConfig the parameters\nControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes\nwill have the default route appropriately appended.\n\nDoing the concatenation in overcloud.yaml enable simplified\nuser-facing NetworkConfig templates.\n\nFor standalone and undercloud define the default_route_networks\nwith an empty list. Cannot leave it undefined as this will\ndefault the default route to the ctlplane's gateway. Undercloud\nand Standalone uses the management interface as the gateway by\ndefault, so we should not set a default gateway for these roles.\n\nChange-Id: I3a35c4b46536fa2916d9fa387278077884adaf68\n""}]",5,755715,34fae762aab364559bfcc29510b1c69957dd21f4,32,5,6,24245,,,0,"Concatenate host_routes and default route in overcloud.yaml

Previoously the default route was concatenated with the
host_routes in the NetworkConfig. This change moves that
concatenation to overcloud.yaml.

GroupVars {{network.name_lower}}_host_routes and
ctlplane_host_routes will have the default route appended
based on role.default_route_networks setting.

For heat base NetworkConfig the parameters
ControlPlaneStaticRoutes and {{network.name}}InterfaceRoutes
will have the default route appropriately appended.

Doing the concatenation in overcloud.yaml enable simplified
user-facing NetworkConfig templates.

For standalone and undercloud define the default_route_networks
with an empty list. Cannot leave it undefined as this will
default the default route to the ctlplane's gateway. Undercloud
and Standalone uses the management interface as the gateway by
default, so we should not set a default gateway for these roles.

Change-Id: I3a35c4b46536fa2916d9fa387278077884adaf68
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/755715/3 && git format-patch -1 --stdout FETCH_HEAD,"['network/config/bond-with-vlans/controller-no-external.j2.yaml', 'network/config/multiple-nics/compute-dvr.j2.yaml', 'network/config/single-nic-vlans/controller-no-external.j2.yaml', 'network/config/multiple-nics-vlans/role.role.j2.yaml', 'network/config/single-nic-linux-bridge-vlans/role.role.j2.yaml', 'network/config/multiple-nics-vlans/compute-dvr.j2.yaml', 'overcloud.j2.yaml', 'network/config/bond-with-vlans/role.role.j2.yaml', 'network/config/multiple-nics/role.role.j2.yaml', 'network/config/single-nic-vlans/role.role.j2.yaml', 'network/config/2-linux-bonds-vlans/role.role.j2.yaml']",11,523f9668c9566be3f0238bbbf272ba80c6739557,os_net_config, get_param: ControlPlaneStaticRoutes get_param: {{network.name}}InterfaceRoutes get_param: {{network.name}}InterfaceRoutes get_param: {{network.name}}InterfaceRoutes, list_concat_unique: - get_param: ControlPlaneStaticRoutes {%- if role.default_route_networks is not defined or 'ControlPlane' in role.default_route_networks %} - - default: true next_hop: get_param: ControlPlaneDefaultRoute {%- endif %} list_concat_unique: - get_param: {{network.name}}InterfaceRoutes {%- if network.name in role.default_route_networks %} - - default: true next_hop: get_param: {{network.name}}InterfaceDefaultRoute {%- endif %} list_concat_unique: - get_param: {{network.name}}InterfaceRoutes {%- if network.name in role.default_route_networks %} - - default: true next_hop: get_param: {{network.name}}InterfaceDefaultRoute {%- endif %} list_concat_unique: - get_param: {{network.name}}InterfaceRoutes {%- if network.name in role.default_route_networks %} - - default: true next_hop: get_param: {{network.name}}InterfaceDefaultRoute {%- endif %},48,142
openstack%2Fsushy~master~Ie401218013438b9de07d8dc9daa24485608b29a5,openstack/sushy,master,Ie401218013438b9de07d8dc9daa24485608b29a5,Add doc/requirements,MERGED,2021-01-04 17:36:24.000000000,2021-01-07 07:05:04.000000000,2021-01-07 07:02:48.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 17:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/49053883548b5f722a0712c298e53f4d7bb2ccde', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ie401218013438b9de07d8dc9daa24485608b29a5\n'}, {'number': 2, 'created': '2021-01-06 17:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/fff7b154aa5e9b514d4106abac17031373962967', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ie401218013438b9de07d8dc9daa24485608b29a5\n'}, {'number': 3, 'created': '2021-01-06 17:09:37.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sushy/commit/e4a3e18de079968f23aa6473750ed017ff43fa4c', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ie401218013438b9de07d8dc9daa24485608b29a5\n'}]",3,769174,e4a3e18de079968f23aa6473750ed017ff43fa4c,14,3,3,15519,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: Ie401218013438b9de07d8dc9daa24485608b29a5
",git fetch https://review.opendev.org/openstack/sushy refs/changes/74/769174/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,49053883548b5f722a0712c298e53f4d7bb2ccde,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps}deps = {[testenv:docs]deps},,8,8
openstack%2Ftripleo-quickstart~master~I5355d0027e831d34d840a95e3705064001be3a93,openstack/tripleo-quickstart,master,I5355d0027e831d34d840a95e3705064001be3a93,Only use repo_config for dependency if file exists,MERGED,2021-01-06 14:03:24.000000000,2021-01-07 06:31:31.000000000,2021-01-07 06:27:36.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-06 14:03:24.000000000', 'files': ['roles/repo-setup/tasks/set-dependency-repo-vars.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4d9be8400705315536c26298ad98607d34e7594e', 'message': 'Only use repo_config for dependency if file exists\n\nNot all dependency jobs require a repo_config file.\nThis review makes including the vars from that file\nan option - executed only if the file exists.\n\nChange-Id: I5355d0027e831d34d840a95e3705064001be3a93\n'}]",0,769545,4d9be8400705315536c26298ad98607d34e7594e,10,7,1,9976,,,0,"Only use repo_config for dependency if file exists

Not all dependency jobs require a repo_config file.
This review makes including the vars from that file
an option - executed only if the file exists.

Change-Id: I5355d0027e831d34d840a95e3705064001be3a93
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/45/769545/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/repo-setup/tasks/set-dependency-repo-vars.yml'],1,4d9be8400705315536c26298ad98607d34e7594e,conditional_dep-file,"- name: set_fact for the repo_config path set_fact: repo_config_path: ""{{ working_dir }}/workspace/.quickstart/config/release/dependency_ci/{{ job.dependency|default(dependency) }}/repo_config.yaml"" - name: check if we have a depednecy repo_config file stat: path: ""{{ repo_config_path }}"" register: repo_config_path_check include_vars: ""{{ repo_config_path }}"" when: repo_config_path_check.stat.exists"," include_vars: ""{{ working_dir }}/workspace/.quickstart/config/release/dependency_ci/{{ job.dependency|default(dependency) }}/repo_config.yaml""",11,2
openstack%2Ftripleo-quickstart~master~Ie5e1e44179227828fce498ed27589f38f80feb69,openstack/tripleo-quickstart,master,Ie5e1e44179227828fce498ed27589f38f80feb69,Enable QoS related L3 agent extensions in featureset020,MERGED,2020-10-27 09:01:32.000000000,2021-01-07 06:30:05.000000000,2021-01-07 06:27:27.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 11975}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-27 09:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3523e94ef67f45f6c0c63fe1d749506972b2d023', 'message': 'Enable QoS related L3 agent extensions in featureset020\n\nDepends-On: https://review.opendev.org/759829\n\nChange-Id: Ie5e1e44179227828fce498ed27589f38f80feb69\nRelated-Bug: #1900357\n'}, {'number': 2, 'created': '2020-11-30 11:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b1b72cfa0b774ff38dd4c5294cbc879755fb67a4', 'message': 'Enable QoS related L3 agent extensions in featureset020\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/764095\n\nChange-Id: Ie5e1e44179227828fce498ed27589f38f80feb69\nRelated-Bug: #1900357\n'}, {'number': 3, 'created': '2020-12-03 08:14:49.000000000', 'files': ['config/general_config/featureset020.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6eaf394e0a7f4defd6a45e0083e4855f8e358913', 'message': 'Enable QoS related L3 agent extensions in featureset020\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/764095\n\nChange-Id: Ie5e1e44179227828fce498ed27589f38f80feb69\nRelated-Bug: #1900357\n'}]",9,759832,6eaf394e0a7f4defd6a45e0083e4855f8e358913,52,9,3,11975,,,0,"Enable QoS related L3 agent extensions in featureset020

Depends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/764095

Change-Id: Ie5e1e44179227828fce498ed27589f38f80feb69
Related-Bug: #1900357
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/32/759832/2 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset020.yml'],1,3523e94ef67f45f6c0c63fe1d749506972b2d023,bug/1900357,"extra_args: >- {% if release not in ['newton','ocata','pike'] -%} -e {{ overcloud_templates_path }}/ci/environments/neutron_l3_qos.yaml {% endif %}",extra_args: '',4,1
openstack%2Fcinder~master~I7875d365bb73dd80ecbe30c4801599b6f781cc39,openstack/cinder,master,I7875d365bb73dd80ecbe30c4801599b6f781cc39,Correct group:reset_group_snapshot_status policy,MERGED,2020-12-15 22:36:50.000000000,2021-01-07 06:06:25.000000000,2021-01-06 16:43:56.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 8846}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-15 22:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9441726dd32147352428d5c0028cac5fb7e62ea4', 'message': 'Correct group:reset_group_snapshot_status policy\n\nThe default value for the group:reset_group_snapshot_status policy\nis supposed to be admin-only (as advertised in the api-ref) [0].  It was\nchanged to admin-or-owner during refactoring for the policy-in-code\ninitiative in Queens [1].  Consensus at the Wallaby R-18 mid-cycle was\nthat this change was a mistake that should be corrected [2].\n\n[0] https://docs.openstack.org/api-ref/block-storage/v3/#snapshot-actions-snapshots-action\n[1] https://review.opendev.org/c/openstack/cinder/+/507812\n[2] https://wiki.openstack.org/wiki/CinderWallabyMidCycleSummary#consistent_and_secure_policies\n\nChange-Id: I7875d365bb73dd80ecbe30c4801599b6f781cc39\nCloses-bug: #1908315\n'}, {'number': 2, 'created': '2020-12-17 02:41:47.000000000', 'files': ['releasenotes/notes/bug-1908315-020fea3e244d49bb.yaml', 'cinder/policies/group_snapshot_actions.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1631742f43a2d1f60cf5ccee26dced1d542f2bf6', 'message': 'Correct group:reset_group_snapshot_status policy\n\nThe default value for the group:reset_group_snapshot_status policy, which\ngoverns the Block Storage API call ""Reset group snapshot status"" [0],\nwas changed to admin-or-owner during refactoring for the policy-in-code\ninitiative in Queens [1].  Consensus at the Wallaby R-18 mid-cycle was\nthat this change was a mistake that should be corrected [2].\n\n[0] https://docs.openstack.org/api-ref/block-storage/v3/#reset-group-snapshot-status\n[1] https://review.opendev.org/c/openstack/cinder/+/507812\n[2] https://wiki.openstack.org/wiki/CinderWallabyMidCycleSummary#consistent_and_secure_policies\n\nChange-Id: I7875d365bb73dd80ecbe30c4801599b6f781cc39\nCloses-bug: #1908315\n'}]",0,767226,1631742f43a2d1f60cf5ccee26dced1d542f2bf6,127,7,2,5314,,,0,"Correct group:reset_group_snapshot_status policy

The default value for the group:reset_group_snapshot_status policy, which
governs the Block Storage API call ""Reset group snapshot status"" [0],
was changed to admin-or-owner during refactoring for the policy-in-code
initiative in Queens [1].  Consensus at the Wallaby R-18 mid-cycle was
that this change was a mistake that should be corrected [2].

[0] https://docs.openstack.org/api-ref/block-storage/v3/#reset-group-snapshot-status
[1] https://review.opendev.org/c/openstack/cinder/+/507812
[2] https://wiki.openstack.org/wiki/CinderWallabyMidCycleSummary#consistent_and_secure_policies

Change-Id: I7875d365bb73dd80ecbe30c4801599b6f781cc39
Closes-bug: #1908315
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/767226/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1908315-020fea3e244d49bb.yaml', 'cinder/policies/group_snapshot_actions.py']",2,9441726dd32147352428d5c0028cac5fb7e62ea4,bug/1908315," check_str=base.RULE_ADMIN_API,"," check_str=base.RULE_ADMIN_OR_OWNER,",41,1
openstack%2Fpuppet-neutron~master~I4cdc70ef2e0544db30b4ed7c24816accf074f860,openstack/puppet-neutron,master,I4cdc70ef2e0544db30b4ed7c24816accf074f860,Deprecate neutron::plugins::cisco,MERGED,2021-01-02 09:27:09.000000000,2021-01-07 05:50:45.000000000,2021-01-07 05:43:50.000000000,"[{'_account_id': 6681}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-02 09:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/cd98c4b23c8d7a59eae63586c99974a824395312', 'message': 'Deprecate neutron::plugins::cisco\n\nThis class was initially introduced to support Neutron Cisco plugin\nbut this plugin was migrated to networking-cisco and the neutron-cisco\npackage is no longer provided in any distros.\n\nChange-Id: I4cdc70ef2e0544db30b4ed7c24816accf074f860\n'}, {'number': 2, 'created': '2021-01-02 09:38:08.000000000', 'files': ['spec/classes/neutron_config_spec.rb', 'releasenotes/notes/deprecate-neutron-plugin-cisco-539f6c165734589c.yaml', 'manifests/plugins/cisco.pp', 'manifests/params.pp', 'spec/classes/neutron_plugins_cisco_spec.rb', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/bc50622a2db80e7759f7fe4caaf58f4ce5b8567a', 'message': 'Deprecate neutron::plugins::cisco\n\nThis class was initially introduced to support Cisco monolithic plugins\nbut these plugins were removed and replaced by ml2 plugins.\n\nChange-Id: I4cdc70ef2e0544db30b4ed7c24816accf074f860\n'}]",0,768879,bc50622a2db80e7759f7fe4caaf58f4ce5b8567a,14,4,2,9816,,,0,"Deprecate neutron::plugins::cisco

This class was initially introduced to support Cisco monolithic plugins
but these plugins were removed and replaced by ml2 plugins.

Change-Id: I4cdc70ef2e0544db30b4ed7c24816accf074f860
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/79/768879/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_config_spec.rb', 'releasenotes/notes/deprecate-neutron-plugin-cisco-539f6c165734589c.yaml', 'manifests/plugins/cisco.pp', 'manifests/params.pp', 'spec/classes/neutron_plugins_cisco_spec.rb', 'manifests/config.pp']",6,cd98c4b23c8d7a59eae63586c99974a824395312,cisco-monolithic-plugins,"# [*plugin_cisco_db_conn_config*] # (optional) Manage configuration of plugins/cisco/db_conn.ini # # [*plugin_cisco_l2network_config*] # (optional) Manage configuration of plugins/cisco/l2network_plugin.ini # # [*plugin_cisco_config*] # (optional) Manage configuration of cisco_plugins.ini # $plugin_cisco_db_conn_config = undef, $plugin_cisco_l2network_config = undef, $plugin_cisco_config = undef, $cisco_plugin_param_names = [ 'plugin_cisco_db_conn_config', 'plugin_cisco_l2network_config', 'plugin_cisco_config', ] $cisco_plugin_param_names.each |$param_name| { $param = getvar($param_name) if $param != undef{ warning(""The ${param_name} parameter is deprecated and has no effect."") } } ","# [*plugin_cisco_db_conn_config*] # (optional) Manage configuration of plugins/cisco/db_conn.ini # # [*plugin_cisco_l2network_config*] # (optional) Manage configuration of plugins/cisco/l2network_plugin.ini # # [*plugin_cisco_config*] # (optional) Manage configuration of cisco_plugins.ini # $plugin_cisco_db_conn_config = {}, $plugin_cisco_l2network_config = {}, $plugin_cisco_config = {}, validate_legacy(Hash, 'validate_hash', $plugin_cisco_db_conn_config) validate_legacy(Hash, 'validate_hash', $plugin_cisco_l2network_config) validate_legacy(Hash, 'validate_hash', $plugin_cisco_config) create_resources('neutron_plugin_cisco_db_conn', $plugin_cisco_db_conn_config) create_resources('neutron_plugin_cisco_l2network', $plugin_cisco_l2network_config) create_resources('neutron_plugin_cisco', $plugin_cisco_config)",32,333
openstack%2Fpuppet-neutron~master~I3ff88e3192254e04cfa577c3bff5e154885ca1a8,openstack/puppet-neutron,master,I3ff88e3192254e04cfa577c3bff5e154885ca1a8,Deprecate support of Nexus 1000v driver,MERGED,2021-01-02 02:52:54.000000000,2021-01-07 05:48:57.000000000,2021-01-07 05:43:46.000000000,"[{'_account_id': 6681}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-02 02:52:54.000000000', 'files': ['releasenotes/notes/deprecate-n1kv-driver-b851f8fbfcef8a48.yaml', 'spec/classes/neutron_agents_n1kv_vem_spec.rb', 'manifests/agents/n1kv_vem.pp', 'manifests/plugins/ml2/cisco/nexus1000v.pp', 'templates/n1kv.conf.erb', 'spec/classes/neutron_plugins_ml2_cisco_nexus1000v_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/320da88fea0b2de15859a6371ff7ea63ec190009', 'message': 'Deprecate support of Nexus 1000v driver\n\n... because it was already removed from networking-cisco[1].\n\n[1] https://opendev.org/x/networking-cisco/commit/0730ec9e6b76b3c1e75082e9dd1af55c9faeb34c\n\nChange-Id: I3ff88e3192254e04cfa577c3bff5e154885ca1a8\n'}]",0,768845,320da88fea0b2de15859a6371ff7ea63ec190009,15,4,1,9816,,,0,"Deprecate support of Nexus 1000v driver

... because it was already removed from networking-cisco[1].

[1] https://opendev.org/x/networking-cisco/commit/0730ec9e6b76b3c1e75082e9dd1af55c9faeb34c

Change-Id: I3ff88e3192254e04cfa577c3bff5e154885ca1a8
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/45/768845/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-n1kv-driver-b851f8fbfcef8a48.yaml', 'spec/classes/neutron_agents_n1kv_vem_spec.rb', 'manifests/agents/n1kv_vem.pp', 'manifests/plugins/ml2/cisco/nexus1000v.pp', 'templates/n1kv.conf.erb', 'spec/classes/neutron_plugins_ml2_cisco_nexus1000v_spec.rb']",6,320da88fea0b2de15859a6371ff7ea63ec190009,n1kv,,"require 'spec_helper' describe 'neutron::plugins::ml2::cisco::nexus1000v' do let :pre_condition do ""class { 'neutron::keystone::authtoken': password => 'passw0rd', } class { 'neutron::server': } class { 'neutron': core_plugin => 'ml2' }"" end let :default_params do { :n1kv_vsm_ip => '10.10.10.10', :n1kv_vsm_username => 'admin', :n1kv_vsm_password => 'password', :default_policy_profile => 'default-pp', :default_vlan_network_profile => 'default-vlan-np', :default_vxlan_network_profile => 'default-vxlan-np', :poll_duration => '60', :http_pool_size => '4', :http_timeout => '15', :sync_interval => '300', :max_vsm_retries => '2', :restrict_policy_profiles => 'False', :enable_vif_type_n1kv => 'False', } end let :params do {} end shared_examples 'neutron cisco ml2 nexus1000v plugin' do before do params.merge!(default_params) end it { should contain_class('neutron::params') } it do should contain_neutron_plugin_ml2('ml2_cisco_n1kv/n1kv_vsm_ips').with_value(params[:n1kv_vsm_ip]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/username').with_value(params[:n1kv_vsm_username]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/password').with_value(params[:n1kv_vsm_password]).with_secret(true) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/default_policy_profile').with_value(params[:default_policy_profile]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/default_vlan_network_profile').with_value(params[:default_vlan_network_profile]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/default_vxlan_network_profile').with_value(params[:default_vxlan_network_profile]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/poll_duration').with_value(params[:poll_duration]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/http_pool_size').with_value(params[:http_pool_size]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/http_timeout').with_value(params[:http_timeout]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/sync_interval').with_value(params[:sync_interval]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/max_vsm_retries').with_value(params[:max_vsm_retries]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/restrict_policy_profiles').with_value(params[:restrict_policy_profiles]) should contain_neutron_plugin_ml2('ml2_cisco_n1kv/enable_vif_type_n1kv').with_value(params[:enable_vif_type_n1kv]) end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts()) end if facts[:osfamily] == 'RedHat' it_behaves_like 'neutron cisco ml2 nexus1000v plugin' end end end end ",9,667
openstack%2Fpuppet-neutron~master~Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf,openstack/puppet-neutron,master,Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf,Ensure service user passwords are secret,MERGED,2021-01-03 09:07:15.000000000,2021-01-07 05:00:11.000000000,2021-01-07 05:00:11.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 09:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c10eafae799770bdedb140fa34e8b28d1f07b72d', 'message': 'Ensure service user passwords are secret\n\nChange-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf\n'}, {'number': 2, 'created': '2021-01-03 09:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/abab25a2b95715833ec132f1364c9c820e2df01d', 'message': 'Ensure service user passwords are secret\n\nChange-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf\n'}, {'number': 3, 'created': '2021-01-03 22:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/acdcd09bfbbc3e3fa8351015895f2c5348b1c5fe', 'message': 'Ensure service user passwords are secret\n\nChange-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf\n'}, {'number': 4, 'created': '2021-01-04 06:15:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/569fadb3e8250480276e6c7d37037ce467e4e66b', 'message': 'Ensure service user passwords are secret\n\nChange-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf\n'}, {'number': 5, 'created': '2021-01-04 06:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8b8d7eb8cc209c71c329bd05a03d194b93f6ffa6', 'message': 'Ensure service user passwords are secret\n\nChange-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf\n'}, {'number': 6, 'created': '2021-01-04 13:41:44.000000000', 'files': ['manifests/designate.pp', 'spec/classes/neutron_designate_spec.rb', 'manifests/agents/ml2/networking_baremetal.pp', 'spec/classes/neutron_agents_ml2_networking_baremetal_spec.rb', 'lib/puppet/type/ironic_neutron_agent_config.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8d2662c2ba9f70a5a9098821006f28d7e1ea9d7e', 'message': 'Ensure service user passwords are secret\n\nChange-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf\n'}]",0,769049,8d2662c2ba9f70a5a9098821006f28d7e1ea9d7e,23,3,6,9816,,,0,"Ensure service user passwords are secret

Change-Id: Ia4aabf358e4e0ef0e7913940b70ba79b1eaa1acf
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/49/769049/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/designate.pp', 'spec/classes/neutron_designate_spec.rb', 'manifests/agents/ml2/networking_baremetal.pp', 'spec/classes/neutron_agents_ml2_networking_baremetal_spec.rb']",4,c10eafae799770bdedb140fa34e8b28d1f07b72d,service-password, should contain_ironic_neutron_agent_config('ironic/password').with_value(p[:password]).with_secret(true), should contain_ironic_neutron_agent_config('ironic/password').with_value(p[:password]),5,5
openstack%2Fpuppet-horizon~master~I72a025697e41ba0a4fe1605c0cfd6f317fb7d803,openstack/puppet-horizon,master,I72a025697e41ba0a4fe1605c0cfd6f317fb7d803,Remove the profile_support setting from OPENSTACK_NEUTRON_NETWORK,MERGED,2021-01-02 03:25:39.000000000,2021-01-07 04:57:21.000000000,2021-01-07 04:57:21.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-02 03:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/291f439bd18f34e35e903a78779e817f1fd0d5a3', 'message': 'Remove the profile_support setting from OPENSTACK_NEUTRON_NETWORK\n\n... because the setting no longer exists in Horizon[1].\n\n[1] a8f17150bfed4d30a0e5b06069ce85c8c3049bcb\n\nChange-Id: I72a025697e41ba0a4fe1605c0cfd6f317fb7d803\n'}, {'number': 2, 'created': '2021-01-05 23:06:00.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/b5d76caebaa2c78320dd69de2bc9515c4dcc43ab', 'message': 'Remove the profile_support setting from OPENSTACK_NEUTRON_NETWORK\n\n... because the setting no longer exists in Horizon[1].\n\n[1] a8f17150bfed4d30a0e5b06069ce85c8c3049bcb\n\nChange-Id: I72a025697e41ba0a4fe1605c0cfd6f317fb7d803\n'}]",0,768850,b5d76caebaa2c78320dd69de2bc9515c4dcc43ab,12,4,2,9816,,,0,"Remove the profile_support setting from OPENSTACK_NEUTRON_NETWORK

... because the setting no longer exists in Horizon[1].

[1] a8f17150bfed4d30a0e5b06069ce85c8c3049bcb

Change-Id: I72a025697e41ba0a4fe1605c0cfd6f317fb7d803
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/50/768850/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,291f439bd18f34e35e903a78779e817f1fd0d5a3,profile_support," 'enable_distributed_router' => false, 'enable_ha_router' => false,"," 'enable_distributed_router' => false, 'enable_ha_router' => false, 'profile_support' => 'cisco', "" 'profile_support': 'cisco',"",",1,12
openstack%2Fpuppet-neutron~master~I90a205df7817a28574e494ec7e1d497ee320a493,openstack/puppet-neutron,master,I90a205df7817a28574e494ec7e1d497ee320a493,Deprecate parameters for XenAPI support,MERGED,2021-01-03 12:10:26.000000000,2021-01-07 04:36:02.000000000,2021-01-07 04:34:49.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 12:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/aa31e6808b22b40a3e50e266771c914c99737925', 'message': 'Deprecate parameters for XenAPI support\n\n... because it was already deprecated in neutron[1].\n\n[1] a6dbf97242caa3be646e8eb6b1502b5e59e123fd\n\nChange-Id: I90a205df7817a28574e494ec7e1d497ee320a493\n'}, {'number': 2, 'created': '2021-01-03 22:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/dff146379e4bb8523c2c67b71e0cf75458d1258d', 'message': 'Deprecate parameters for XenAPI support\n\n... because it was already deprecated in neutron[1].\n\n[1] a6dbf97242caa3be646e8eb6b1502b5e59e123fd\n\nChange-Id: I90a205df7817a28574e494ec7e1d497ee320a493\n'}, {'number': 3, 'created': '2021-01-04 13:41:07.000000000', 'files': ['spec/classes/neutron_rootwrap_spec.rb', 'releasenotes/notes/deprecate-xenapi-d97bb062fe508fbc.yaml', 'manifests/rootwrap.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1e01fb86bc0d1fd9ba792a2cf1917c973cc35558', 'message': 'Deprecate parameters for XenAPI support\n\n... because it was already deprecated in neutron[1].\n\n[1] a6dbf97242caa3be646e8eb6b1502b5e59e123fd\n\nChange-Id: I90a205df7817a28574e494ec7e1d497ee320a493\n'}]",0,769065,1e01fb86bc0d1fd9ba792a2cf1917c973cc35558,18,3,3,9816,,,0,"Deprecate parameters for XenAPI support

... because it was already deprecated in neutron[1].

[1] a6dbf97242caa3be646e8eb6b1502b5e59e123fd

Change-Id: I90a205df7817a28574e494ec7e1d497ee320a493
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/65/769065/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_rootwrap_spec.rb', 'releasenotes/notes/deprecate-xenapi-d97bb062fe508fbc.yaml', 'manifests/rootwrap.pp']",3,aa31e6808b22b40a3e50e266771c914c99737925,xenapi,"# DEPRECATED PARAMETERS ## Defaults to undef.# Defaults to undef.# Defaults to undef. # DEPRECATED PARAMETERS $xenapi_connection_url = undef, $xenapi_connection_username = undef, $xenapi_connection_password = undef, $deprecated_xenapi_param_names = [ 'xenapi_connection_url', 'xenapi_connection_username', 'xenapi_connection_password', ] $deprecated_xenapi_param_names.each |$param_name| { $param = getvar($param_name) if $param != undef { warning(""The ${param_name} parameter is deprecated and has no effect."") }","# Defaults to $::os_service_default.# Defaults to $::os_service_default.# Defaults to $::os_service_default. $xenapi_connection_url = $::os_service_default, $xenapi_connection_username = $::os_service_default, $xenapi_connection_password = $::os_service_default, neutron_rootwrap_config { 'xenapi/xenapi_connection_url': value => $xenapi_connection_url; 'xenapi/xenapi_connection_username': value => $xenapi_connection_username; 'xenapi/xenapi_connection_password': value => $xenapi_connection_password;",30,23
openstack%2Frequirements~master~Ie80e45571efafe73a553ddd89c5be90fe97bea4d,openstack/requirements,master,Ie80e45571efafe73a553ddd89c5be90fe97bea4d,Blacklist sphinx 3.4.2 because of Flask regressions,MERGED,2021-01-06 17:22:25.000000000,2021-01-07 04:27:37.000000000,2021-01-07 04:26:22.000000000,"[{'_account_id': 14288}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-06 17:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ebc6d3d570cc40ef5c0cc711330cf827d7a72cfd', 'message': 'Blacklist sphinx 3.4.2 because of Flask regressions\n\nUsing sphinx version 3.4.2 with Flask and documentation builds results\nin an error:\n\n  Exception occurred:\n    File ""/opt/stack/keystone/.tox/docs/lib/python3.8/site-packages/flask/globals.py"", line 38, in _lookup_req_object\n      raise RuntimeError(_request_ctx_err_msg)\n  RuntimeError: Working outside of request context.\n\nThis issue has occured a few times with sphinx in the past and has been\nreported upstream [0][1].\n\nThis commit blacklists sphinx 3.4.2 until we get a newer release with a fix.\n\n[0] https://github.com/sphinx-doc/sphinx/issues/8655\n[1] https://github.com/sphinx-doc/sphinx/issues/2796\n\nChange-Id: Ie80e45571efafe73a553ddd89c5be90fe97bea4d\n'}, {'number': 2, 'created': '2021-01-06 17:23:04.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/8b7a53cac1cc1fdcd4ab94aad9a7b7d24362fdc3', 'message': 'Blacklist sphinx 3.4.2 because of Flask regressions\n\nUsing sphinx version 3.4.2 with Flask and documentation builds results\nin an error:\n\n  Exception occurred:\n    File ""/opt/stack/keystone/.tox/docs/lib/python3.8/site-packages/flask/globals.py"", line 38, in _lookup_req_object\n      raise RuntimeError(_request_ctx_err_msg)\n  RuntimeError: Working outside of request context.\n\nThis issue has occured a few times with sphinx in the past and has been\nreported upstream [0][1].\n\nThis commit blacklists sphinx 3.4.2 until we get a newer release with a fix.\n\n[0] https://github.com/sphinx-doc/sphinx/issues/8655\n[1] https://github.com/sphinx-doc/sphinx/issues/2796\n\nPartial-Bug: 1910419\n\nChange-Id: Ie80e45571efafe73a553ddd89c5be90fe97bea4d\n'}]",0,769571,8b7a53cac1cc1fdcd4ab94aad9a7b7d24362fdc3,17,4,2,5046,,,0,"Blacklist sphinx 3.4.2 because of Flask regressions

Using sphinx version 3.4.2 with Flask and documentation builds results
in an error:

  Exception occurred:
    File ""/opt/stack/keystone/.tox/docs/lib/python3.8/site-packages/flask/globals.py"", line 38, in _lookup_req_object
      raise RuntimeError(_request_ctx_err_msg)
  RuntimeError: Working outside of request context.

This issue has occured a few times with sphinx in the past and has been
reported upstream [0][1].

This commit blacklists sphinx 3.4.2 until we get a newer release with a fix.

[0] https://github.com/sphinx-doc/sphinx/issues/8655
[1] https://github.com/sphinx-doc/sphinx/issues/2796

Partial-Bug: 1910419

Change-Id: Ie80e45571efafe73a553ddd89c5be90fe97bea4d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/71/769571/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,ebc6d3d570cc40ef5c0cc711330cf827d7a72cfd,,"sphinx!=1.6.6,!=1.6.7,!=2.1.0,!=3.0.0,!=3.4.2 # BSD","sphinx!=1.6.6,!=1.6.7,!=2.1.0,!=3.0.0 # BSD",1,1
openstack%2Fneutron~stable%2Fvictoria~Iadc1671c862f8c01e5761e92b82a04849d4bb411,openstack/neutron,stable/victoria,Iadc1671c862f8c01e5761e92b82a04849d4bb411,Fix removal of dvr-src mac flows when non-gateway port on router is deleted,MERGED,2020-12-17 02:26:54.000000000,2021-01-07 03:31:35.000000000,2021-01-07 03:30:15.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 02:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31107f2b6515e4e44916a7323ac8e4195de22213', 'message': 'Fix removal of dvr-src mac flows when non-gateway port on router is deleted\n\nRemoval of non-gateway port on DVR router deletes all the DVR to\nSRC mac flows for the instances of same subnet on that compute node.\nThe instances are not reachable from any other network.\n\nThis patch checks if the DVR router port is gateway for the subnet\nor not. And deletes the DVR-SRC mac flows only if it is gateway port.\nThe DVR-SRC mac flows are deleted if the gateway is not set for the subnet.\n\nChange-Id: Iadc1671c862f8c01e5761e92b82a04849d4bb411\nCloses-Bug: #1892405\n(cherry picked from commit 329ea19f8b881421b9b5ae2fcc855f96af72a9f5)\n'}, {'number': 2, 'created': '2020-12-18 02:32:47.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc3ea9dd051aebbf2d9e93f99dd5fd84bd8e416c', 'message': 'Fix removal of dvr-src mac flows when non-gateway port on router is deleted\n\nRemoval of non-gateway port on DVR router deletes all the DVR to\nSRC mac flows for the instances of same subnet on that compute node.\nThe instances are not reachable from any other network.\n\nThis patch checks if the DVR router port is gateway for the subnet\nor not. And deletes the DVR-SRC mac flows only if it is gateway port.\nThe DVR-SRC mac flows are deleted if the gateway is not set for the subnet.\n\nChange-Id: Iadc1671c862f8c01e5761e92b82a04849d4bb411\nCloses-Bug: #1892405\n(cherry picked from commit 329ea19f8b881421b9b5ae2fcc855f96af72a9f5)\n'}]",0,767331,bc3ea9dd051aebbf2d9e93f99dd5fd84bd8e416c,32,6,2,10366,,,0,"Fix removal of dvr-src mac flows when non-gateway port on router is deleted

Removal of non-gateway port on DVR router deletes all the DVR to
SRC mac flows for the instances of same subnet on that compute node.
The instances are not reachable from any other network.

This patch checks if the DVR router port is gateway for the subnet
or not. And deletes the DVR-SRC mac flows only if it is gateway port.
The DVR-SRC mac flows are deleted if the gateway is not set for the subnet.

Change-Id: Iadc1671c862f8c01e5761e92b82a04849d4bb411
Closes-Bug: #1892405
(cherry picked from commit 329ea19f8b881421b9b5ae2fcc855f96af72a9f5)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/767331/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",2,31107f2b6515e4e44916a7323ac8e4195de22213,bug/1892405-stable/victoria," def _setup_extra_port_for_dvr(self): self._port_nongateway = mock.Mock() self._port_nongateway.ofport = 11 self._port_nongateway.vif_id = ""1234-5678-99"" self._port_nongateway.vif_mac = 'aa:bb:cc:11:22:44' self._port_nongateway.dvr_mac = self.agent.dvr_agent.dvr_mac_address self._fixed_ips_nongateway = [{'subnet_id': 'my-subnet-uuid', 'ip_address': '1.1.1.11'}] def _test_port_unbound_dvr_router_port_on_vxlan_network( self, port_type='gateway', ip_version=n_const.IP_VERSION_4): """"""Test DVR ovs flows when router port is unbound. Setup 2 ports from same subnet to a DVR router. Add an instance port. Remove one of the router ports based on port_type passed to the function. port_type='gateway' removes the gateway port, port_type nongateway removes the non-gateway port. port_type='all' removes both the ports. Verify if the corresponding ovs flows are updated. """""" self._setup_for_dvr_test() self._setup_extra_port_for_dvr() if ip_version == n_const.IP_VERSION_4: gateway_ip = '1.1.1.1' cidr = '1.1.1.0/24' else: gateway_ip = '2001:db8:100::1' cidr = '2001:db8:100::0/64' self._fixed_ips = [{'subnet_id': 'my-subnet-uuid', 'ip_address': '2001:db8:100::1'}] self._fixed_ips_nongateway = [{'subnet_id': 'my-subnet-uuid', 'ip_address': '2001:db8:100::10'}] network_type = n_const.TYPE_VXLAN self._port.vif_mac = gateway_mac = 'aa:bb:cc:11:22:33' self._port.dvr_mac = self.agent.dvr_agent.dvr_mac_address self._compute_port.vif_mac = '77:88:99:00:11:22' physical_network = self._physical_network segmentation_id = self._segmentation_id int_br = mock.create_autospec(self.agent.int_br) tun_br = mock.create_autospec(self.agent.tun_br) phys_br = mock.create_autospec(self.br_phys_cls('br-phys')) int_br.set_db_attribute.return_value = True int_br.db_get_val.return_value = {} with mock.patch.object(self.agent.dvr_agent.plugin_rpc, 'get_subnet_for_dvr', return_value={'gateway_ip': gateway_ip, 'cidr': cidr, 'ip_version': ip_version, 'gateway_mac': gateway_mac}),\ mock.patch.object(self.agent.dvr_agent.plugin_rpc, 'get_ports_on_host_by_subnet', return_value=[]),\ mock.patch.object(self.agent.dvr_agent.int_br, 'get_vif_port_by_id', return_value=self._port),\ mock.patch.object(self.agent, 'int_br', new=int_br),\ mock.patch.object(self.agent, 'tun_br', new=tun_br),\ mock.patch.dict(self.agent.phys_brs, {physical_network: phys_br}),\ mock.patch.object(self.agent.dvr_agent, 'int_br', new=int_br),\ mock.patch.object(self.agent.dvr_agent, 'tun_br', new=tun_br),\ mock.patch.dict(self.agent.dvr_agent.phys_brs, {physical_network: phys_br}): self.agent.port_bound( self._port, self._net_uuid, network_type, physical_network, segmentation_id, self._fixed_ips, n_const.DEVICE_OWNER_DVR_INTERFACE, False) lvid = self.agent.vlan_manager.get(self._net_uuid).vlan # Bound non-gateway port self.agent.port_bound( self._port_nongateway, self._net_uuid, network_type, physical_network, segmentation_id, self._fixed_ips_nongateway, n_const.DEVICE_OWNER_DVR_INTERFACE, False) # Bound compute port self.agent.port_bound(self._compute_port, self._net_uuid, network_type, physical_network, segmentation_id, self._compute_fixed_ips, DEVICE_OWNER_COMPUTE, False) int_br.reset_mock() tun_br.reset_mock() phys_br.reset_mock() ports_to_unbind = {} expected_br_int_mock_calls_gateway_port = 2 expected_br_int_mock_calls_nongateway_port = 1 if port_type == 'gateway': ports_to_unbind = { self._port: expected_br_int_mock_calls_gateway_port } elif port_type == 'nongateway': ports_to_unbind = { self._port_nongateway: expected_br_int_mock_calls_nongateway_port } else: ports_to_unbind = { self._port: expected_br_int_mock_calls_gateway_port, self._port_nongateway: expected_br_int_mock_calls_nongateway_port } for port_to_unbind, br_int_mock_calls in ports_to_unbind.items(): self.agent.port_unbound(port_to_unbind.vif_id) expected_on_int_br = self._expected_port_unbound( port_to_unbind, lvid, True, network_type) if ip_version == n_const.IP_VERSION_4: expected_on_tun_br = [ mock.call.delete_dvr_process_ipv4( vlan_tag=lvid, gateway_ip=gateway_ip), ] else: expected_on_tun_br = [ mock.call.delete_dvr_process_ipv6( vlan_tag=lvid, gateway_mac=gateway_mac), ] expected_on_tun_br.extend([ mock.call.delete_dvr_process( vlan_tag=lvid, vif_mac=port_to_unbind.vif_mac), ]) int_br.assert_has_calls(expected_on_int_br) self.assertEqual(br_int_mock_calls, len(int_br.mock_calls)) tun_br.assert_has_calls(expected_on_tun_br) int_br.reset_mock() tun_br.reset_mock() phys_br.assert_not_called() phys_br.reset_mock() def test_port_unbound_dvr_router_port(self): self._test_port_unbound_dvr_router_port_on_vxlan_network( port_type='gateway') self._test_port_unbound_dvr_router_port_on_vxlan_network( port_type='nongateway') # Unbound all the dvr router ports self._test_port_unbound_dvr_router_port_on_vxlan_network( port_type='all') self._test_port_unbound_dvr_router_port_on_vxlan_network( port_type='gateway', ip_version=n_const.IP_VERSION_6) self._test_port_unbound_dvr_router_port_on_vxlan_network( port_type='nongateway', ip_version=n_const.IP_VERSION_6) # Unbound all the dvr router ports self._test_port_unbound_dvr_router_port_on_vxlan_network( port_type='all', ip_version=n_const.IP_VERSION_6) ",,219,19
openstack%2Ftripleo-image-elements~master~I29d632814577db0b720b07d4497983e267d46a4e,openstack/tripleo-image-elements,master,I29d632814577db0b720b07d4497983e267d46a4e,ensure any ens3 interface is nuked during image build,MERGED,2021-01-04 19:41:18.000000000,2021-01-07 03:25:01.000000000,2021-01-07 03:25:01.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-04 19:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b1e2101239cde96fbf3a2a690fe29797aeda267d', 'message': ""ensure any ens3 interface is nuked during image build\n\nIt seems as though w/ CentOS-8.3 ens3 has crept\nback into play.  Ensure it's not in the overcloud\nimages.  See bug for details.\n\nCloses-Bug: #1910107\nChange-Id: I29d632814577db0b720b07d4497983e267d46a4e\n""}, {'number': 2, 'created': '2021-01-04 21:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9cd6d44d7c2c02f0e5c304ae06930fb7d60f7f63', 'message': ""ensure any ens3 interface is nuked during image build\n\nIt seems as though w/ CentOS-8.3 ens3 has crept\nback into play.  Ensure it's not in the overcloud\nimages.  See bug for details.\n\nCloses-Bug: #1910107\nChange-Id: I29d632814577db0b720b07d4497983e267d46a4e\n""}, {'number': 3, 'created': '2021-01-05 16:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c49e5521b8b314eef37e3b6bbd6f91b4e1e0328e', 'message': ""ensure any ens3 interface is nuked during image build\n\nIt seems as though w/ CentOS-8.3 ens3 has crept\nback into play.  Ensure it's not in the overcloud\nimages.  See bug for details.\n\nCloses-Bug: #1910107\nChange-Id: I29d632814577db0b720b07d4497983e267d46a4e\n""}, {'number': 4, 'created': '2021-01-06 16:05:28.000000000', 'files': ['elements/interface-names/install.d/71-clean-stale-interface'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d072a79acf52a87333fa663059eb769009b8fb4e', 'message': ""ensure any ens3 interface is nuked during image build\n\nIt seems as though w/ CentOS-8.3 ens3 has crept\nback into play.  Ensure it's not in the overcloud\nimages.  See bug for details.\n\nCloses-Bug: #1910107\nChange-Id: I29d632814577db0b720b07d4497983e267d46a4e\n""}]",2,769209,d072a79acf52a87333fa663059eb769009b8fb4e,23,7,4,9592,,,0,"ensure any ens3 interface is nuked during image build

It seems as though w/ CentOS-8.3 ens3 has crept
back into play.  Ensure it's not in the overcloud
images.  See bug for details.

Closes-Bug: #1910107
Change-Id: I29d632814577db0b720b07d4497983e267d46a4e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/09/769209/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/interface-names/install.d/71-clean-stale-interface'],1,b1e2101239cde96fbf3a2a690fe29797aeda267d,, rm -f /etc/sysconfig/network-scripts/ifcfg-ens3*, rm -f /etc/sysconfig/network-scripts/ifcfg-ens3,1,1
openstack%2Fpuppet-cinder~master~I26a8d679d31a929234b6ebc73035b18f3d65161c,openstack/puppet-cinder,master,I26a8d679d31a929234b6ebc73035b18f3d65161c,Deprecate support for v2 API,MERGED,2020-11-13 06:44:05.000000000,2021-01-07 03:21:36.000000000,2021-01-07 03:20:29.000000000,"[{'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-13 06:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/18557bcdc2fa3500d0a3a6929cd58252072e7de0', 'message': 'Deprecate support for v2 API\n\nCinder v2 API was deprected a while ago[1], and only v3 API should be\nused now. This patch deprecates support for v2 API and disabled\nkeystone resources for it by default.\n\n[1] f6d3454f608ec40570deb62997ccda8048f6e2dc\n\nChange-Id: I26a8d679d31a929234b6ebc73035b18f3d65161c\n'}, {'number': 2, 'created': '2020-11-16 13:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/213032bd58903c5906cff3f2f34423c4a83537ea', 'message': 'Deprecate support for v2 API\n\nCinder v2 API was deprected a while ago[1], and only v3 API should be\nused now. This patch deprecates support for v2 API and disabled\nkeystone resources for it by default.\n\n[1] f6d3454f608ec40570deb62997ccda8048f6e2dc\n\nChange-Id: I26a8d679d31a929234b6ebc73035b18f3d65161c\n'}, {'number': 3, 'created': '2020-11-17 13:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/21ddbfe1121f1e5b5fa768604fda16119902a04b', 'message': ""Deprecate support for v2 API\n\nThis patch deprecates support for v2 API and makes the keystone\nresources for v2 API no longer managed by puppet-cinder, because v2 API\nwas deprected a while ago[1] and is supposed to be removed in this\nW-cycle[2].\n\nNote that this change doesn't implement cleanup for v2 API resources,\nand all existing keystone resources like endpoints, service and so on\nshould be manually deleted during upgrade.\n\n[1] f6d3454f608ec40570deb62997ccda8048f6e2dc\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018531.html\n\nChange-Id: I26a8d679d31a929234b6ebc73035b18f3d65161c\n""}, {'number': 4, 'created': '2020-12-21 15:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/b3f12e991ff3677ac5dcf876be9dfa2cc7c9fbc9', 'message': ""Deprecate support for v2 API\n\nThis patch deprecates support for v2 API and makes the keystone\nresources for v2 API no longer managed by puppet-cinder, because v2 API\nwas deprected a while ago[1] and is supposed to be removed in this\nW-cycle[2].\n\nNote that this change doesn't implement cleanup for v2 API resources,\nand all existing keystone resources like endpoints, service and so on\nshould be manually deleted during upgrade.\n\n[1] f6d3454f608ec40570deb62997ccda8048f6e2dc\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018531.html\n\nChange-Id: I26a8d679d31a929234b6ebc73035b18f3d65161c\n""}, {'number': 5, 'created': '2020-12-22 10:55:23.000000000', 'files': ['spec/classes/cinder_keystone_auth_spec.rb', 'releasenotes/notes/deprecate-v2-api-a6fd143635d2f3a5.yaml', 'manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/3cb961733b212773145ba93aa955c196d8dc6ed1', 'message': ""Deprecate support for v2 API\n\nThis patch deprecates support for v2 API and makes the keystone\nresources for v2 API no longer managed by puppet-cinder, because v2 API\nwas deprected a while ago[1] and is supposed to be removed in this\nW-cycle[2].\n\nNote that this change doesn't implement cleanup for v2 API resources,\nand all existing keystone resources like endpoints, service and so on\nshould be manually deleted during upgrade.\n\n[1] f6d3454f608ec40570deb62997ccda8048f6e2dc\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018531.html\n\nDepends-on: https://review.opendev.org/768178/\nChange-Id: I26a8d679d31a929234b6ebc73035b18f3d65161c\n""}]",4,762618,3cb961733b212773145ba93aa955c196d8dc6ed1,38,6,5,9816,,,0,"Deprecate support for v2 API

This patch deprecates support for v2 API and makes the keystone
resources for v2 API no longer managed by puppet-cinder, because v2 API
was deprected a while ago[1] and is supposed to be removed in this
W-cycle[2].

Note that this change doesn't implement cleanup for v2 API resources,
and all existing keystone resources like endpoints, service and so on
should be manually deleted during upgrade.

[1] f6d3454f608ec40570deb62997ccda8048f6e2dc
[2] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018531.html

Depends-on: https://review.opendev.org/768178/
Change-Id: I26a8d679d31a929234b6ebc73035b18f3d65161c
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/18/762618/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_keystone_auth_spec.rb', 'releasenotes/notes/deprecate-v2-api-a6fd143635d2f3a5.yaml', 'manifests/keystone/auth.pp']",3,18557bcdc2fa3500d0a3a6929cd58252072e7de0,deprecate-v2-api,"# [*public_url_v3*] # (0ptional) The v3 endpoint's public url. # This url should *not* contain any trailing '/'. # Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s' # # [*internal_url_v3*] # (Optional) The v3 endpoint's internal url. # This url should *not* contain any trailing '/'. # Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s' # # [*admin_url_v3*] # (Optional) The v3 endpoint's admin url. # This url should *not* contain any trailing '/'. # Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s' # # DEPRECATED PARAMETRS # # [*password_user_v2*] # (Optional) Password for Cinder v2 user. # Defaults to undef. # # [*email_user_v2*] # (Optional) Email for Cinder v2 user. # Defaults to 'cinderv2@localhost'. # # [*auth_name_v2*] # (Optional) Username for Cinder v2 service. # Defaults to 'cinderv2'. # # [*configure_endpoint_v2*] # (Optional) Should Cinder v2 endpoint be configured? # Defaults to false # # [*configure_user_v2*] # (Optional) Should the service user be configured for cinder v2? # Defaults to false # # [*configure_user_role_v2*] # (Optional) Should the admin role be configured for the service user for cinder v2? # Defaults to false # # [*service_name_v2*] # (Optional) Name of the v2 service. # Defaults to 'cinderv2'. # # [*service_type_v2*] # (Optional) Type of API v2 service. # Defaults to 'volumev2'. # # [*service_description_v2*] # (Optional) Description for keystone v2 service. # Defaults to 'Cinder Service v2'. # # [*tenant_user_v2*] # (Optional) Tenant for Cinder v2 user. # Defaults to 'services'. # # [*roles_v2*] # (Optional) List of roles assigned to Cinder v2 user # Defaults to ['admin'] # # DEPRECATED PARAMETERS $password_user_v2 = undef, $auth_name_v2 = 'cinderv2', $tenant_user_v2 = 'services', $roles_v2 = ['admin'], $email_user_v2 = 'cinderv2@localhost', $public_url_v2 = 'http://127.0.0.1:8776/v2/%(tenant_id)s', $internal_url_v2 = 'http://127.0.0.1:8776/v2/%(tenant_id)s', $admin_url_v2 = 'http://127.0.0.1:8776/v2/%(tenant_id)s', $configure_endpoint_v2 = false, $configure_user_v2 = false, $configure_user_role_v2 = false, $service_name_v2 = 'cinderv2', $service_type_v2 = 'volumev2', $service_description_v2 = 'Cinder Service v2', warning('The support for v2 API has been deprecated') if $configure_user_v2 { warning('The support for v2 API has been deprecated') } ","# [*password_user_v2*] # (Optional) Password for Cinder v2 user. # Defaults to undef. # # [*email_user_v2*] # (Optional) Email for Cinder v2 user. # Defaults to 'cinderv2@localhost'. ## [*auth_name_v2*] # (Optional) Username for Cinder v2 service. # Defaults to 'cinderv2'. ## [*configure_endpoint_v2*] # (Optional) Should Cinder v2 endpoint be configured? # Defaults to true ## [*configure_user_v2*] # (Optional) Should the service user be configured for cinder v2? # Defaults to false ## [*configure_user_role_v2*] # (Optional) Should the admin role be configured for the service user for cinder v2? # Defaults to false ## [*service_name_v2*] # (Optional) Name of the v2 service. # Defaults to 'cinderv2'. ## [*service_type_v2*] # (Optional) Type of API v2 service. # Defaults to 'volumev2'. ## [*service_description_v2*] # (Optional) Description for keystone v2 service. # Defaults to 'Cinder Service v2'. ## [*tenant_user_v2*] # (Optional) Tenant for Cinder v2 user. # Defaults to 'services'. ## [*roles_v2*] # (Optional) List of roles assigned to Cinder v2 user # Defaults to ['admin'] ## [*public_url_v3*] # (0ptional) The v3 endpoint's public url. # This url should *not* contain any trailing '/'. # Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s' # # [*internal_url_v3*] # (Optional) The v3 endpoint's internal url. # This url should *not* contain any trailing '/'. # Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s' # # [*admin_url_v3*] # (Optional) The v3 endpoint's admin url. # This url should *not* contain any trailing '/'. # Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s' # $password_user_v2 = undef, $auth_name_v2 = 'cinderv2', $tenant_user_v2 = 'services', $roles_v2 = ['admin'], $email_user_v2 = 'cinderv2@localhost', $public_url_v2 = 'http://127.0.0.1:8776/v2/%(tenant_id)s', $internal_url_v2 = 'http://127.0.0.1:8776/v2/%(tenant_id)s', $admin_url_v2 = 'http://127.0.0.1:8776/v2/%(tenant_id)s', $configure_endpoint_v2 = true, $configure_user_v2 = false, $configure_user_role_v2 = false, $service_name_v2 = 'cinderv2', $service_type_v2 = 'volumev2', $service_description_v2 = 'Cinder Service v2',",127,91
openstack%2Fneutron~stable%2Fussuri~I74916acf8311989dca267f23261ec4cf449a6abf,openstack/neutron,stable/ussuri,I74916acf8311989dca267f23261ec4cf449a6abf,Fix OVS conjunctive IP flows cleanup,MERGED,2020-12-18 08:52:47.000000000,2021-01-07 03:03:09.000000000,2021-01-07 03:00:55.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28159}]","[{'number': 1, 'created': '2020-12-18 08:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c388f6d3e08c9f751aed43cc95ffcd12d0cdc7f2', 'message': ""Fix OVS conjunctive IP flows cleanup\n\n Currently when deleting a remote-group's member IPs, the deleted IPs'\n conjunctive flows are not cleaned up in OF tables. This is because\n the conjunctive flows' cookies don't match with the OVSBridge default\n cookie used by the delete flow method. This patch fixed the issue by\n using an ANY cookie that can always match with the cookies of the\n conjunctive flows.\n\nChange-Id: I74916acf8311989dca267f23261ec4cf449a6abf\nCloses-Bug: 1907491\n(cherry picked from commit f4b64e519cdb9fd9c5046f21bc9f325341fd367f)\n""}, {'number': 2, 'created': '2020-12-21 10:08:12.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c720f26b6afeaea61c61bb2f0b1b2825c6c58859', 'message': ""Fix OVS conjunctive IP flows cleanup\n\n Currently when deleting a remote-group's member IPs, the deleted IPs'\n conjunctive flows are not cleaned up in OF tables. This is because\n the conjunctive flows' cookies don't match with the OVSBridge default\n cookie used by the delete flow method. This patch fixed the issue by\n using an ANY cookie that can always match with the cookies of the\n conjunctive flows.\n\nChange-Id: I74916acf8311989dca267f23261ec4cf449a6abf\nCloses-Bug: 1907491\n(cherry picked from commit f4b64e519cdb9fd9c5046f21bc9f325341fd367f)\n""}]",0,767677,c720f26b6afeaea61c61bb2f0b1b2825c6c58859,25,4,2,16688,,,0,"Fix OVS conjunctive IP flows cleanup

 Currently when deleting a remote-group's member IPs, the deleted IPs'
 conjunctive flows are not cleaned up in OF tables. This is because
 the conjunctive flows' cookies don't match with the OVSBridge default
 cookie used by the delete flow method. This patch fixed the issue by
 using an ANY cookie that can always match with the cookies of the
 conjunctive flows.

Change-Id: I74916acf8311989dca267f23261ec4cf449a6abf
Closes-Bug: 1907491
(cherry picked from commit f4b64e519cdb9fd9c5046f21bc9f325341fd367f)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/767677/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py']",2,c388f6d3e08c9f751aed43cc95ffcd12d0cdc7f2,bug/1907491," def test_delete_flow_for_ip_using_cookie_any(self): with mock.patch.object(self.firewall, '_delete_flows') as \ mock_delete_flows: self.firewall.delete_flow_for_ip(('10.1.2.3', None), constants.INGRESS_DIRECTION, constants.IPv4, 100, [0]) _, kwargs = mock_delete_flows.call_args self.assertIn('cookie', kwargs) self.assertIs(ovs_lib.COOKIE_ANY, kwargs['cookie']) ",,15,0
openstack%2Fpuppet-openstacklib~master~I2b7763eaebb4ad28ff94585dcb4c7846182f45b5,openstack/puppet-openstacklib,master,I2b7763eaebb4ad28ff94585dcb4c7846182f45b5,Use stdlib functions to manage policy files,ABANDONED,2020-07-08 13:30:24.000000000,2021-01-07 02:54:02.000000000,,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-07-08 13:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/07fceffc70745fc31eece91718ac5b9d9ece8c7d', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 2, 'created': '2020-07-08 13:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/02ab194778acae415e18e70e76297d4f339982e9', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 3, 'created': '2020-07-08 13:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/5f6d30a2de48c34f43a6af3395ee9d09f8de0de5', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 4, 'created': '2020-07-08 13:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/ce0e9449fd4ddae8c2d2e8526506471618ff1b69', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 5, 'created': '2020-07-08 13:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/0fd0f2376d5c5f4673cba2e3dfce3959cff35297', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 6, 'created': '2020-07-08 14:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/4c12d604bd4fd6ed6f531bf5481d0f3cd9a2452f', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 7, 'created': '2020-07-08 23:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/9354a9559a793de428e0f771bda406f302e8f6a7', 'message': 'WIP: Use stdlib functions to manage json\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 8, 'created': '2020-07-09 05:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/58cf2a70285168a99758dbd171f6c99e797db25f', 'message': 'WIP: Use stdlib functions to manage json\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 9, 'created': '2020-07-09 05:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/9c85c99ee403e75adf681b5c93fa38fb337e84a0', 'message': 'WIP: Use stdlib functions to manage json\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 10, 'created': '2020-07-09 05:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/00e598e42d2000c1c4f909a87e560c70eb6689b1', 'message': 'Use stdlib functions to manage json\n\nThis pathc replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 11, 'created': '2020-07-15 22:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/4780c6f3b658368a5a90544e92098240cdb8cc7f', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 12, 'created': '2020-07-16 00:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f5d36879f1c5a25e38a58aa039dba894c11760b5', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 13, 'created': '2020-07-16 02:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/10caf1a3545eb00cecf9ee5ed6e4b9023a0ca396', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 14, 'created': '2020-07-16 02:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/d34e91c583a1a7ee40a8cf4b81f7201d467f4d5e', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 15, 'created': '2020-07-16 05:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/90772c92d008343e24000745e089f41b18cc03be', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 16, 'created': '2020-07-16 05:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/51a6ba892b17a6c7c93fbba3dd9139a49a1c6be0', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 17, 'created': '2020-07-16 05:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/1f96848b0b819406b2f8f78eacdf56a0b727878b', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 18, 'created': '2020-07-16 06:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/412f164541ae4c7efcfb61d5342ed839c659c022', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 19, 'created': '2020-07-16 06:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f66d5b5f440b9d938d63efc6d47c6f5665def22a', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 20, 'created': '2020-07-16 06:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f8b81297648aa2da624f9af869e917ed02aabe5a', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 21, 'created': '2020-07-16 07:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/084fd4a078e8f8102aeaaaa2fb09ab76b63dbdce', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 22, 'created': '2020-07-16 07:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/61e556e2e0f717852af158f507676518e17224f9', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 23, 'created': '2020-07-16 10:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/4b8b2de292a77aa66b7439c5361ec18bbe89ab4a', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 24, 'created': '2020-07-16 10:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/64b73abe4cd38e101c21fceb6275e8ad68bb255b', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 25, 'created': '2020-07-16 11:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/65956f6868af43a9d314684fceb110a2b09597d8', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 26, 'created': '2020-07-16 12:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/5cd98b20befd2589ec3a44191cd2944b4cf3b9c4', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 27, 'created': '2020-07-16 13:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c49003462b3f1a7b6d7fa780bfb9de99c422b353', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 28, 'created': '2020-07-21 14:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f9cddbc7b0a6e17e2a58de8180b42590b2469ab4', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 29, 'created': '2020-07-21 14:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/e6dc70051e7b37cbbd89c1612d03a87e682a48b1', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 30, 'created': '2020-07-22 02:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/7c8aff7c070181e6a9f4d7ee701bcd034c0bf957', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 31, 'created': '2020-07-28 00:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/b9e24d84d431a062d3c1529723486a42ff48469b', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 32, 'created': '2020-08-30 12:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/740518faf97fc2b32b2be96fde0ed80c7aaba21f', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\nAlso, this introduces automatical detection of policy file format\nfrom policy file path, so that we can switch to yaml format by updating\nonly file path parameter.\n\nDepends-on: https://review.opendev.org/#/c/740154/\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 33, 'created': '2021-01-05 07:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/0ce3d9f4368ee5f1837af3806cd15d37362ecb23', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 34, 'created': '2021-01-05 07:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/273b5085d33372065a0faa99921931b33000d51f', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 35, 'created': '2021-01-05 08:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/505b5185bf7a80fa1947adcc93bb594c60696c3d', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 36, 'created': '2021-01-05 08:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/d5f31747992190a4f50619367fe9d38e4497022b', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 37, 'created': '2021-01-05 08:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/7700bf6a74f8d56b8fcc9eaf936471678466d60c', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 38, 'created': '2021-01-05 08:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/7309549ed2f4289c839010ae23c17063a7e1c42f', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 39, 'created': '2021-01-05 11:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/37efcc19879dde06a63f6a1a2bf56e9f8bcd50d4', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 40, 'created': '2021-01-06 05:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/34741b4ce95b256ed10fedbe98a0b0866d17999f', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 41, 'created': '2021-01-06 08:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/20641eb4299a3af5759bd4d6bd94f40772626f21', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}, {'number': 42, 'created': '2021-01-07 01:58:50.000000000', 'files': ['spec/defines/openstacklib_policy_base_spec.rb', 'spec/acceptance/openstacklib_policy_base_spec.rb', 'manifests/policy/base.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/4b4412def1b12bfd937eb42c3a9ba4821fd464a0', 'message': 'Use stdlib functions to manage policy files\n\nThis patch replaces the augeas resource in policy generation by native\nfunctions in puppet, to simplify the implementation to manage policy\ncontent.\n\nChange-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5\n'}]",0,739984,4b4412def1b12bfd937eb42c3a9ba4821fd464a0,62,2,42,9816,,,0,"Use stdlib functions to manage policy files

This patch replaces the augeas resource in policy generation by native
functions in puppet, to simplify the implementation to manage policy
content.

Change-Id: I2b7763eaebb4ad28ff94585dcb4c7846182f45b5
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/84/739984/41 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/openstacklib_policy_base_spec.rb', 'manifests/policy/base.pp']",2,07fceffc70745fc31eece91718ac5b9d9ece8c7d,policy," $value = '', $policy_content = loadjson($file_path, {}) if $policy_content == undef { fail('Failed to parse policy json') } $new_policy_content = $policy_content $new_content = $to_json_pretty($new_policy_content) ensure_resource('file' $file_path, { content => $new_content,"," $value = '', ensure_resource('file', $file_path, { replace => false, # augeas will manage the content, we just need to make sure it exists content => '{}' # Add entry if it doesn't exists augeas { ""${file_path}-${key}-${value}-add"": lens => 'Json.lns', incl => $file_path, changes => [ ""set dict/entry[last()+1] \""${key}\"""", ""set dict/entry[last()]/string \""${value}\"""", ], onlyif => ""match dict/entry[*][.=\""${key}\""] size == 0"", } # Requires that the entry is added before this call or it will fail. augeas { ""${file_path}-${key}-${value}"" : lens => 'Json.lns', incl => $file_path, changes => ""set dict/entry[*][.=\""${key}\""]/string \""${value}\"""", } File<| title == $file_path |> -> Augeas<| title == ""${file_path}-${key}-${value}-add"" |> ~> Augeas<| title == ""${file_path}-${key}-${value}"" |> ",26,47
openstack%2Fpuppet-openstacklib~master~I9acdf9983873f5cadad991cf37a6fdd1025dfa5f,openstack/puppet-openstacklib,master,I9acdf9983873f5cadad991cf37a6fdd1025dfa5f,DNM: Try stubs(:call),ABANDONED,2021-01-05 12:27:29.000000000,2021-01-07 02:53:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-05 12:27:29.000000000', 'files': ['spec/defines/openstacklib_policy_base_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/2581b13ba28384f6bfa765648b8d2044a78b4960', 'message': 'DNM: Try stubs(:call)\n\nChange-Id: I9acdf9983873f5cadad991cf37a6fdd1025dfa5f\n'}]",0,769342,2581b13ba28384f6bfa765648b8d2044a78b4960,3,1,1,9816,,,0,"DNM: Try stubs(:call)

Change-Id: I9acdf9983873f5cadad991cf37a6fdd1025dfa5f
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/42/769342/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/defines/openstacklib_policy_base_spec.rb'],1,2581b13ba28384f6bfa765648b8d2044a78b4960,policy, f.stubs(:call).with('/etc/nova/policy.json').returns({'default' => 'rule:admin_or_owner'}) f.stubs(:call).with({ f.stubs(:call).with('/etc/nova/policy.yaml').returns({'default' => 'rule:admin_or_owner'}) f.stubs(:call).with({, f.stubbed.with('/etc/nova/policy.json').returns({'default' => 'rule:admin_or_owner'}) f.stubbed.with({ f.stubbed.with('/etc/nova/policy.yaml').returns({'default' => 'rule:admin_or_owner'}) f.stubbed.with({,4,4
openstack%2Fpuppet-openstacklib~master~I1d50f4dd2177bdb3419b99f059b4c20e769aa422,openstack/puppet-openstacklib,master,I1d50f4dd2177bdb3419b99f059b4c20e769aa422,DNM: Debugging policy content,ABANDONED,2021-01-06 23:11:49.000000000,2021-01-07 02:53:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-06 23:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/5156bcefa86d50edfeb899cbba59165f8ca0c0c4', 'message': 'DNM: Debugging policy content\n\nChange-Id: I1d50f4dd2177bdb3419b99f059b4c20e769aa422\n'}, {'number': 2, 'created': '2021-01-07 00:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/465183e91b2d3b259714e0a31fcde37498d06620', 'message': 'DNM: Debugging policy content\n\nChange-Id: I1d50f4dd2177bdb3419b99f059b4c20e769aa422\n'}, {'number': 3, 'created': '2021-01-07 00:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c79bd62da04261be934e334d608932bacfe44b2e', 'message': 'DNM: Debugging policy content\n\nChange-Id: I1d50f4dd2177bdb3419b99f059b4c20e769aa422\n'}, {'number': 4, 'created': '2021-01-07 01:58:50.000000000', 'files': ['spec/acceptance/openstacklib_policy_base_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f19a1757feaaaf8d4945c065c5865c5499f6c9e2', 'message': 'DNM: Debugging policy content\n\nChange-Id: I1d50f4dd2177bdb3419b99f059b4c20e769aa422\n'}]",0,769623,f19a1757feaaaf8d4945c065c5865c5499f6c9e2,9,1,4,9816,,,0,"DNM: Debugging policy content

Change-Id: I1d50f4dd2177bdb3419b99f059b4c20e769aa422
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/23/769623/3 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/openstacklib_policy_base_spec.rb'],1,5156bcefa86d50edfeb899cbba59165f8ca0c0c4,policy, it { should matche /foo/ } it { should matche /foo/ },,2,0
openstack%2Fcharm-ceilometer~master~I89bab84de2fe82d20e92407b2aec9a594c208b7a,openstack/charm-ceilometer,master,I89bab84de2fe82d20e92407b2aec9a594c208b7a,Charm-helpers sync for Bug #1893847,MERGED,2021-01-05 22:03:21.000000000,2021-01-07 02:38:17.000000000,2021-01-07 02:38:17.000000000,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 22:03:21.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apache.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/hahelpers/apache.py'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/79dd41247e41dcccd623f032ee71d8ed8b5b441f', 'message': 'Charm-helpers sync for Bug #1893847\n\nChange-Id: I89bab84de2fe82d20e92407b2aec9a594c208b7a\nCloses-Bug: #1893847\n'}]",0,769426,79dd41247e41dcccd623f032ee71d8ed8b5b441f,11,3,1,20805,,,0,"Charm-helpers sync for Bug #1893847

Change-Id: I89bab84de2fe82d20e92407b2aec9a594c208b7a
Closes-Bug: #1893847
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/26/769426/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apache.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/hahelpers/apache.py']",14,79dd41247e41dcccd623f032ee71d8ed8b5b441f,bug/1893847,"# This file contains the CA cert from the charms ssl_ca configuration # option, in future the file name should be updated reflect that. CONFIG_CA_CERT_FILE = 'keystone_juju_ca_cert' host.install_ca_cert(ca_cert, CONFIG_CA_CERT_FILE)"," host.install_ca_cert(ca_cert, 'keystone_juju_ca_cert')",338,51
openstack%2Fcharm-glance~master~I5efe8e98c23f8660cb5d90286e685a4b5dde8aba,openstack/charm-glance,master,I5efe8e98c23f8660cb5d90286e685a4b5dde8aba,Charm-helpers sync for Bug #1893847,MERGED,2021-01-05 22:24:28.000000000,2021-01-07 02:37:34.000000000,2021-01-07 02:37:34.000000000,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 22:24:28.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apache.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/hahelpers/apache.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/4a1aa147d128d123b34f2b045255d7b7cb4e663d', 'message': 'Charm-helpers sync for Bug #1893847\n\nChange-Id: I5efe8e98c23f8660cb5d90286e685a4b5dde8aba\nCloses-Bug: #1893847\n'}]",0,769429,4a1aa147d128d123b34f2b045255d7b7cb4e663d,11,3,1,20805,,,0,"Charm-helpers sync for Bug #1893847

Change-Id: I5efe8e98c23f8660cb5d90286e685a4b5dde8aba
Closes-Bug: #1893847
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/29/769429/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apache.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/hahelpers/apache.py']",14,4a1aa147d128d123b34f2b045255d7b7cb4e663d,bug/1893847,"# This file contains the CA cert from the charms ssl_ca configuration # option, in future the file name should be updated reflect that. CONFIG_CA_CERT_FILE = 'keystone_juju_ca_cert' host.install_ca_cert(ca_cert, CONFIG_CA_CERT_FILE)"," host.install_ca_cert(ca_cert, 'keystone_juju_ca_cert')",339,52
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65,openstack/tripleo-heat-templates,stable/victoria,Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65,Adding key_size option on the certificate creation,MERGED,2021-01-06 13:18:20.000000000,2021-01-07 01:48:52.000000000,2021-01-07 01:48:52.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 8866}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2021-01-06 13:18:20.000000000', 'files': ['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/database/redis-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/haproxy/haproxy-public-tls-certmonger.yaml', 'deployment/database/mysql-base.yaml', 'deployment/haproxy/haproxy-internal-tls-certmonger.j2.yaml', 'deployment/ceph-ansible/ceph-rgw.yaml', 'deployment/ceph-ansible/ceph-grafana.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/ceph-ansible/ceph-mgr.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/octavia/providers/ovn-provider-config.yaml', 'deployment/metrics/qdr-container-puppet.yaml', 'deployment/memcached/memcached-container-puppet.yaml', 'deployment/apache/apache-baremetal-puppet.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cff6378fb1f09cae95710cbc53706ac86bcc2b95', 'message': ""Adding key_size option on the certificate creation\n\nAdding the ability to specifies the private key size\nused when creating the certificate. We have defined the\ndefault value the same as we have before 2048 bits.\nAlso, it'll be able to override the key_size value\nper service.\n\nDepends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\nChange-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65\n(cherry picked from commit 97609775297417620ede0436c80156456a6c41da)\n""}]",0,769509,cff6378fb1f09cae95710cbc53706ac86bcc2b95,8,7,1,9914,,,0,"Adding key_size option on the certificate creation

Adding the ability to specifies the private key size
used when creating the certificate. We have defined the
default value the same as we have before 2048 bits.
Also, it'll be able to override the key_size value
per service.

Depends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b
Change-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65
(cherry picked from commit 97609775297417620ede0436c80156456a6c41da)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/09/769509/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/database/redis-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/haproxy/haproxy-public-tls-certmonger.yaml', 'deployment/database/mysql-base.yaml', 'deployment/haproxy/haproxy-internal-tls-certmonger.j2.yaml', 'deployment/ceph-ansible/ceph-rgw.yaml', 'deployment/ceph-ansible/ceph-grafana.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/ceph-ansible/ceph-mgr.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/octavia/providers/ovn-provider-config.yaml', 'deployment/metrics/qdr-container-puppet.yaml', 'deployment/memcached/memcached-container-puppet.yaml', 'deployment/apache/apache-baremetal-puppet.j2.yaml']",22,cff6378fb1f09cae95710cbc53706ac86bcc2b95,key_size_cert-stable/victoria," CertificateKeySize: type: string default: '2048' description: Specifies the private key size used when creating the certificate. ApacheCertificateKeySize: type: string default: '' description: Override the private key size used when creating the certificate for this service key_size_override_unset: {equals: [{get_param: ApacheCertificateKeySize}, '']} key_size: if: - key_size_override_unset - {get_param: CertificateKeySize} - {get_param: ApacheCertificateKeySize}",,404,0
openstack%2Fpython-tripleoclient~master~I30b448930f53aef108d9bdb544a6d02b18658b0d,openstack/python-tripleoclient,master,I30b448930f53aef108d9bdb544a6d02b18658b0d,Add --disable-container-prepare flag,MERGED,2020-09-22 20:08:04.000000000,2021-01-07 00:58:06.000000000,2021-01-07 00:56:54.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8297}, {'_account_id': 9592}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-09-22 20:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f6ad439e031241fa1bedf055a6c0b3cf2582f513', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to overcloud deploy (and updates) and\nthe overcloud plan actions which should skip the preparation actions.\n\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}, {'number': 2, 'created': '2020-09-23 13:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/47e2b7bbaf33378c3f6d8aeb6028730ae873deff', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}, {'number': 3, 'created': '2020-09-23 13:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/7184399749beba68fce49a21e2e4f74feaa4d7fb', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}, {'number': 4, 'created': '2020-09-23 13:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bcd722d111f5df4341d1a243c5be717496ee56ff', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}, {'number': 5, 'created': '2020-09-30 14:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b6b500ee8cb44eb4b99950d52f4f3885adde5dca', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}, {'number': 6, 'created': '2020-10-02 15:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a89cc193a4d1d74f5442d2759ad28126da5e91eb', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}, {'number': 7, 'created': '2020-10-30 15:29:10.000000000', 'files': ['tripleoclient/v1/tripleo_deploy.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/workflows/plan_management.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/v1/undercloud.py', 'tripleoclient/v1/overcloud_plan.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0d84ac9234bf93ca4d1471d5860739bc31a6be80', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/#/c/737522/\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n""}]",3,753443,0d84ac9234bf93ca4d1471d5860739bc31a6be80,55,9,7,14985,,,0,"Add --disable-container-prepare flag

Users may want to skip the container prepare process to ensure they
don't update their containers. This change adds a
--disable-container-prepare flag to the following actions which should
skip the preparation actions.
 - overcloud deploy (and updates)
 - overcloud plan actions
 - undercloud deploy (and upgrades)
 - tripleo deploy (and standalone deploy)

Closes-Bug: #1896757
Depends-On: https://review.opendev.org/#/c/737522/
Change-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/43/753443/7 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/workflows/plan_management.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/v1/overcloud_plan.py', 'tripleoclient/v1/overcloud_deploy.py']",5,f6ad439e031241fa1bedf055a6c0b3cf2582f513,disable-image-prepare," verbosity_level=utils.playbook_verbosity(self=self), container_prepare=(not parsed_args.disable_container_prepare) ""ssh_user_name"": parsed_args.overcloud_ssh_user parser.add_argument( '--disable-container-prepare', action='store_true', default=False, help=_('Disable the container preparation actions to prevent ' 'container tags from being updated and new containers ' 'from being fetched. If you skip this but do not have ' 'the container parameters configured, the deployment ' 'action may fail.') )"," verbosity_level=utils.playbook_verbosity(self=self) ""ssh_user_name"": parsed_args.overcloud_ssh_user,",66,15
openstack%2Ftripleo-image-elements~master~Id7ed00333ba9571ef9e0d8f300714835ba63551b,openstack/tripleo-image-elements,master,Id7ed00333ba9571ef9e0d8f300714835ba63551b,Add doc/requirements,MERGED,2021-01-05 09:34:36.000000000,2021-01-07 00:23:52.000000000,2021-01-07 00:22:48.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-05 09:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5954c5530e665c48595858e699d5f80b3da5e37a', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto\npull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug and it already faced\nit previously [1].\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: Id7ed00333ba9571ef9e0d8f300714835ba63551b\n""}, {'number': 2, 'created': '2021-01-05 16:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2124254719d9f81c3c852890a90b4934d7800db6', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto\npull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug and it already faced\nit previously [1].\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nNOTE: Also clear pbr constraints to fix CI.\n\nChange-Id: Id7ed00333ba9571ef9e0d8f300714835ba63551b\n""}, {'number': 3, 'created': '2021-01-06 11:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fd93c9c9f50531233d04b89c5d58194eaa711df5', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto\npull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug and it already faced\nit previously [1].\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nNOTE: Also fix CI clear pbr constraints, relax hacking contraints\n\nChange-Id: Id7ed00333ba9571ef9e0d8f300714835ba63551b\n""}, {'number': 4, 'created': '2021-01-06 14:22:45.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'doc/requirements.txt', 'tests/test_no_dup_filenames.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3ce55b5039c257068abb3dcb78286b02c0f360ed', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto\npull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug and it already faced\nit previously [1].\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nNOTE: Also fix CI clear pbr constraints, relax hacking contraints,\nfix H214 Use assertIn/NotIn(A, B) rather than assertTrue/False\n\nChange-Id: Id7ed00333ba9571ef9e0d8f300714835ba63551b\n""}]",4,769298,3ce55b5039c257068abb3dcb78286b02c0f360ed,23,5,4,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to
pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug and it already faced
it previously [1].

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

NOTE: Also fix CI clear pbr constraints, relax hacking contraints,
fix H214 Use assertIn/NotIn(A, B) rather than assertTrue/False

Change-Id: Id7ed00333ba9571ef9e0d8f300714835ba63551b
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/98/769298/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,5954c5530e665c48595858e699d5f80b3da5e37a,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,5,3
openstack%2Ftripleo-validations~stable%2Fvictoria~I69f3400568d865c1f3505913077ecd7fe36d7d43,openstack/tripleo-validations,stable/victoria,I69f3400568d865c1f3505913077ecd7fe36d7d43,Use the UBI8 image for testing,MERGED,2021-01-04 08:41:19.000000000,2021-01-07 00:12:20.000000000,2021-01-07 00:08:40.000000000,"[{'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 26343}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2021-01-04 08:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/1585e48a3cccbef9f999a52542fbda4664294a5f', 'message': 'Use the UBI8 image for testing\n\nThis change converts our use of CentOS7/88 to UBI8, which should\nprovide a better test environment which will match that of\nproduction for future releases of TripleO. While this image change\nwill better match production clouds thanks in large part to TCIB,\nit will also remove our use of docker.io (dockerhub) which fraught\nwith peril due to the ongoing API rate limits saga.\n\nChange-Id: I69f3400568d865c1f3505913077ecd7fe36d7d43\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n(cherry picked from commit 5bf1427b43132259cd8e37d4b9c4479af9ece958)\n'}, {'number': 2, 'created': '2021-01-05 08:36:33.000000000', 'files': ['roles/undercloud_disk_space/molecule/default/Dockerfile', 'roles/neutron_sanity_check/molecule/default/Dockerfile', 'roles/dhcp_validations/molecule/default/molecule.yml', 'roles/switch_vlans/molecule/default/molecule.yml', 'roles/node_health/molecule/default/molecule.yml', 'roles/openshift_on_openstack/molecule/default/Dockerfile', 'ansible-test-env.rc', 'roles/pacemaker_status/molecule/default/molecule.yml', 'roles/nova_event_callback/molecule/default/Dockerfile', 'roles/undercloud_debug/molecule/default/Dockerfile', 'roles/node_disks/molecule/default/Dockerfile', 'ci/playbooks/pre.yml', 'roles/check_kernel_version/molecule/default/molecule.yml', 'roles/openshift_on_openstack/molecule/default/molecule.yml', 'roles/system_encoding/molecule/default/molecule.yml', 'roles/nova_svirt/molecule/default/prepare.yml', 'roles/check_rhsm_version/molecule/default/molecule.yml', 'roles/stonith_exists/molecule/default/Dockerfile', 'roles/dhcp_validations/molecule/default/Dockerfile', 'roles/ironic_boot_configuration/molecule/default/Dockerfile', 'roles/nova_status/molecule/default/Dockerfile', 'roles/nova_event_callback/molecule/default/molecule.yml', 'roles/collect_flavors_and_verify_profiles/molecule/default/molecule.yml', 'roles/pacemaker_status/molecule/default/Dockerfile', 'roles/network_environment/molecule/default/molecule.yml', '_skeleton_role_/molecule/default/Dockerfile', 'roles/undercloud_debug/molecule/default/molecule.yml', 'roles/ceilometerdb_size/molecule/default/molecule.yml', 'roles/healthcheck_service_status/molecule/default/Dockerfile', '_skeleton_role_/molecule/default/molecule.yml', 'roles/repos/molecule/default/molecule.yml', 'roles/ceph/molecule/ceph-ansible-installed/prepare.yml', 'roles/stack_health/molecule/default/Dockerfile', 'roles/ctlplane_ip_range/molecule/default/prepare.yml', 'roles/nova_status/molecule/default/molecule.yml', 'roles/openstack_endpoints/molecule/default/Dockerfile', 'roles/tls_everywhere/molecule/default/Dockerfile', 'roles/package_version/molecule/default/Dockerfile', 'roles/package_version/molecule/default/molecule.yml', 'roles/container_status/molecule/default/Dockerfile', 'roles/stonith_exists/molecule/default/molecule.yml', 'roles/ovs_dpdk_pmd/molecule/default/Dockerfile', 'roles/ceph/molecule/default/molecule.yml', 'roles/controller_token/molecule/default/Dockerfile', 'roles/controller_token/molecule/default/molecule.yml', 'roles/node_disks/molecule/default/molecule.yml', 'roles/undercloud_tokenflush/molecule/non-persistent-token-format/Dockerfile', 'roles/undercloud_heat_purge_deleted/molecule/default/molecule.yml', 'roles/undercloud_disk_space/molecule/default/molecule.yml', 'roles/switch_vlans/molecule/default/Dockerfile', 'roles/ceph/molecule/ceph-ansible-installed/molecule.yml', 'roles/image_serve/molecule/default/Dockerfile', 'roles/mysql_open_files_limit/molecule/default/molecule.yml', '_skeleton_role_/molecule/default/verify.yml', 'roles/ctlplane_ip_range/molecule/default/molecule.yml', 'roles/undercloud_process_count/molecule/default/Dockerfile', 'roles/repos/molecule/default/verify.yml', 'roles/container_status/molecule/default/molecule.yml', 'roles/check_network_gateway/molecule/default/Dockerfile', 'roles/collect_flavors_and_verify_profiles/molecule/default/Dockerfile', 'roles/nova_svirt/molecule/default/molecule.yml', 'bindep.txt', 'roles/network_environment/molecule/default/Dockerfile', 'roles/controller_ulimits/molecule/default/Dockerfile', 'roles/rabbitmq_limits/molecule/default/molecule.yml', 'roles/ceilometerdb_size/molecule/default/Dockerfile', 'roles/healthcheck_service_status/molecule/default/molecule.yml', 'roles/undercloud_process_count/molecule/default/molecule.yml', 'roles/check_rhsm_version/molecule/rhsm_mismatch/molecule.yml', 'roles/ovs_dpdk_pmd/molecule/default/molecule.yml', 'roles/tls_everywhere/molecule/default/molecule.yml', 'roles/undercloud_heat_purge_deleted/molecule/default/Dockerfile', 'roles/controller_ulimits/molecule/default/molecule.yml', '.zuul.yaml', 'roles/stack_health/molecule/default/molecule.yml', 'roles/neutron_sanity_check/molecule/default/molecule.yml', 'roles/undercloud_tokenflush/molecule/default/molecule.yml', 'roles/check_kernel_version/molecule/default/Dockerfile', 'roles/undercloud_tokenflush/molecule/default/Dockerfile', 'roles/rabbitmq_limits/molecule/default/Dockerfile', 'roles/image_serve/molecule/default/molecule.yml', 'roles/openstack_endpoints/molecule/default/molecule.yml', 'roles/check_network_gateway/molecule/default/molecule.yml', 'roles/ctlplane_ip_range/molecule/default/Dockerfile', 'ci/playbooks/run-local.yml', 'roles/mysql_open_files_limit/molecule/default/Dockerfile', 'scripts/run-local-test', 'roles/undercloud_tokenflush/molecule/non-persistent-token-format/molecule.yml', 'roles/ironic_boot_configuration/molecule/default/molecule.yml', 'doc/source/readme.rst', 'roles/repos/molecule/default/Dockerfile', 'roles/node_health/molecule/default/Dockerfile'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/ca884424f4b6b25f8d46ecd192f7555007884f56', 'message': 'Use the UBI8 image for testing\n\nThis change converts our use of CentOS7/88 to UBI8, which should\nprovide a better test environment which will match that of\nproduction for future releases of TripleO. While this image change\nwill better match production clouds thanks in large part to TCIB,\nit will also remove our use of docker.io (dockerhub) which fraught\nwith peril due to the ongoing API rate limits saga.\n\nChange-Id: I69f3400568d865c1f3505913077ecd7fe36d7d43\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n(cherry picked from commit 5bf1427b43132259cd8e37d4b9c4479af9ece958)\n'}]",0,769108,ca884424f4b6b25f8d46ecd192f7555007884f56,11,7,2,11491,,,0,"Use the UBI8 image for testing

This change converts our use of CentOS7/88 to UBI8, which should
provide a better test environment which will match that of
production for future releases of TripleO. While this image change
will better match production clouds thanks in large part to TCIB,
it will also remove our use of docker.io (dockerhub) which fraught
with peril due to the ongoing API rate limits saga.

Change-Id: I69f3400568d865c1f3505913077ecd7fe36d7d43
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
(cherry picked from commit 5bf1427b43132259cd8e37d4b9c4479af9ece958)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/08/769108/2 && git format-patch -1 --stdout FETCH_HEAD,"['roles/undercloud_disk_space/molecule/default/Dockerfile', 'roles/neutron_sanity_check/molecule/default/Dockerfile', 'roles/dhcp_validations/molecule/default/molecule.yml', 'roles/switch_vlans/molecule/default/molecule.yml', 'roles/node_health/molecule/default/molecule.yml', 'roles/openshift_on_openstack/molecule/default/Dockerfile', 'ansible-test-env.rc', 'roles/pacemaker_status/molecule/default/molecule.yml', 'roles/nova_event_callback/molecule/default/Dockerfile', 'roles/undercloud_debug/molecule/default/Dockerfile', 'roles/node_disks/molecule/default/Dockerfile', 'ci/playbooks/pre.yml', 'roles/check_kernel_version/molecule/default/molecule.yml', 'roles/openshift_on_openstack/molecule/default/molecule.yml', 'roles/system_encoding/molecule/default/molecule.yml', 'roles/nova_svirt/molecule/default/prepare.yml', 'roles/check_rhsm_version/molecule/default/molecule.yml', 'roles/stonith_exists/molecule/default/Dockerfile', 'roles/dhcp_validations/molecule/default/Dockerfile', 'roles/ironic_boot_configuration/molecule/default/Dockerfile', 'roles/nova_status/molecule/default/Dockerfile', 'roles/nova_event_callback/molecule/default/molecule.yml', 'roles/collect_flavors_and_verify_profiles/molecule/default/molecule.yml', 'roles/pacemaker_status/molecule/default/Dockerfile', 'roles/network_environment/molecule/default/molecule.yml', '_skeleton_role_/molecule/default/Dockerfile', 'roles/undercloud_debug/molecule/default/molecule.yml', 'roles/ceilometerdb_size/molecule/default/molecule.yml', 'roles/healthcheck_service_status/molecule/default/Dockerfile', '_skeleton_role_/molecule/default/molecule.yml', 'roles/repos/molecule/default/molecule.yml', 'roles/ceph/molecule/ceph-ansible-installed/prepare.yml', 'roles/stack_health/molecule/default/Dockerfile', 'roles/ctlplane_ip_range/molecule/default/prepare.yml', 'roles/nova_status/molecule/default/molecule.yml', 'roles/openstack_endpoints/molecule/default/Dockerfile', 'roles/tls_everywhere/molecule/default/Dockerfile', 'roles/package_version/molecule/default/Dockerfile', 'roles/package_version/molecule/default/molecule.yml', 'roles/container_status/molecule/default/Dockerfile', 'roles/stonith_exists/molecule/default/molecule.yml', 'roles/ovs_dpdk_pmd/molecule/default/Dockerfile', 'roles/ceph/molecule/default/molecule.yml', 'roles/controller_token/molecule/default/Dockerfile', 'roles/controller_token/molecule/default/molecule.yml', 'roles/node_disks/molecule/default/molecule.yml', 'roles/undercloud_tokenflush/molecule/non-persistent-token-format/Dockerfile', 'roles/undercloud_heat_purge_deleted/molecule/default/molecule.yml', 'roles/undercloud_disk_space/molecule/default/molecule.yml', 'roles/switch_vlans/molecule/default/Dockerfile', 'roles/ceph/molecule/ceph-ansible-installed/molecule.yml', 'roles/image_serve/molecule/default/Dockerfile', 'roles/mysql_open_files_limit/molecule/default/molecule.yml', '_skeleton_role_/molecule/default/verify.yml', 'roles/ctlplane_ip_range/molecule/default/molecule.yml', 'roles/undercloud_process_count/molecule/default/Dockerfile', 'roles/repos/molecule/default/verify.yml', 'roles/container_status/molecule/default/molecule.yml', 'roles/check_network_gateway/molecule/default/Dockerfile', 'roles/collect_flavors_and_verify_profiles/molecule/default/Dockerfile', 'roles/nova_svirt/molecule/default/molecule.yml', 'bindep.txt', 'roles/network_environment/molecule/default/Dockerfile', 'roles/controller_ulimits/molecule/default/Dockerfile', 'roles/rabbitmq_limits/molecule/default/molecule.yml', 'roles/ceilometerdb_size/molecule/default/Dockerfile', 'roles/healthcheck_service_status/molecule/default/molecule.yml', 'roles/undercloud_process_count/molecule/default/molecule.yml', 'roles/check_rhsm_version/molecule/rhsm_mismatch/molecule.yml', 'roles/ovs_dpdk_pmd/molecule/default/molecule.yml', 'roles/tls_everywhere/molecule/default/molecule.yml', 'roles/undercloud_heat_purge_deleted/molecule/default/Dockerfile', 'roles/controller_ulimits/molecule/default/molecule.yml', 'roles/stack_health/molecule/default/molecule.yml', 'roles/neutron_sanity_check/molecule/default/molecule.yml', 'roles/undercloud_tokenflush/molecule/default/molecule.yml', 'roles/check_kernel_version/molecule/default/Dockerfile', 'roles/undercloud_tokenflush/molecule/default/Dockerfile', 'roles/rabbitmq_limits/molecule/default/Dockerfile', 'roles/image_serve/molecule/default/molecule.yml', 'roles/openstack_endpoints/molecule/default/molecule.yml', 'roles/check_network_gateway/molecule/default/molecule.yml', 'roles/ctlplane_ip_range/molecule/default/Dockerfile', 'ci/playbooks/run-local.yml', 'roles/mysql_open_files_limit/molecule/default/Dockerfile', 'scripts/run-local-test', 'roles/undercloud_tokenflush/molecule/non-persistent-token-format/molecule.yml', 'roles/ironic_boot_configuration/molecule/default/molecule.yml', 'doc/source/readme.rst', 'roles/repos/molecule/default/Dockerfile', 'roles/node_health/molecule/default/Dockerfile']",91,1585e48a3cccbef9f999a52542fbda4664294a5f,victoria,,,941,755
openstack%2Fansible-role-collect-logs~master~I2d4d076ee20525bb425086801d59e2e020bffe96,openstack/ansible-role-collect-logs,master,I2d4d076ee20525bb425086801d59e2e020bffe96,Changing bash executable,MERGED,2020-12-15 19:33:08.000000000,2021-01-07 00:08:48.000000000,2021-01-07 00:08:48.000000000,"[{'_account_id': 7144}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-15 19:33:08.000000000', 'files': ['tasks/collect.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/0d3e085fbd8d6515052f6715c8ca80b1be504531', 'message': 'Changing bash executable\n\n/usr/bin/bash is not available on all distros. /bin/bash is more widely\navailable.\n\nChange-Id: I2d4d076ee20525bb425086801d59e2e020bffe96\n'}]",0,767208,0d3e085fbd8d6515052f6715c8ca80b1be504531,20,5,1,27419,,,0,"Changing bash executable

/usr/bin/bash is not available on all distros. /bin/bash is more widely
available.

Change-Id: I2d4d076ee20525bb425086801d59e2e020bffe96
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/08/767208/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/collect.yml'],1,0d3e085fbd8d6515052f6715c8ca80b1be504531,, executable: /bin/bash, executable: /usr/bin/bash,1,1
openstack%2Fansible-role-collect-logs~master~I4100d1712a92cd797d1d4525798745b2c3ddfe33,openstack/ansible-role-collect-logs,master,I4100d1712a92cd797d1d4525798745b2c3ddfe33,Add conflict packages pattern,MERGED,2021-01-06 09:08:37.000000000,2021-01-07 00:08:45.000000000,2021-01-07 00:08:45.000000000,"[{'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-06 09:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/aedfaf979cfea1ffdd556fab2b35185123e3536d', 'message': 'Add conflict packates pattern\n\nChange-Id: I4100d1712a92cd797d1d4525798745b2c3ddfe33\n'}, {'number': 2, 'created': '2021-01-06 09:09:49.000000000', 'files': ['vars/sova-patterns.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/be7cd38a7bc5e2c84db8664c8e41812ea96249ae', 'message': 'Add conflict packages pattern\n\nChange-Id: I4100d1712a92cd797d1d4525798745b2c3ddfe33\n'}]",0,769476,be7cd38a7bc5e2c84db8664c8e41812ea96249ae,8,4,2,10969,,,0,"Add conflict packages pattern

Change-Id: I4100d1712a92cd797d1d4525798745b2c3ddfe33
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/76/769476/2 && git format-patch -1 --stdout FETCH_HEAD,['vars/sova-patterns.yml'],1,aedfaf979cfea1ffdd556fab2b35185123e3536d,addpatterns," - id: 538 logstash: 'conflicts with file from package' msg: ""Packages conflict."" pattern: 'conflicts with file from package' tag: ""code""",,5,0
openstack%2Fopenstack-ansible~stable%2Fvictoria~I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f,openstack/openstack-ansible,stable/victoria,I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f,Set force option to false by default,MERGED,2021-01-06 18:52:52.000000000,2021-01-07 00:06:36.000000000,2021-01-07 00:05:17.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2021-01-06 18:52:52.000000000', 'files': ['scripts/get-ansible-role-requirements.yml', 'playbooks/library/git_requirements.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f8f4c9b4166076899bde587831d08fcce6d72269', 'message': ""Set force option to false by default\n\nNow git-reset does not have force option [1]. So we're setting it\nto False by default but enable to distros except Ubuntu Focal since\nit has pretty modern git, while others don't\n\nWe also add rescue block not to hard fail in case parallel clone\nexperience issues.\n\n[1] https://git-scm.com/docs/git-reset\n\nChange-Id: I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f\n(cherry picked from commit 273d84be94333c686fecf7210555ec439941e283)\n""}]",0,769588,f8f4c9b4166076899bde587831d08fcce6d72269,8,3,1,25023,,,0,"Set force option to false by default

Now git-reset does not have force option [1]. So we're setting it
to False by default but enable to distros except Ubuntu Focal since
it has pretty modern git, while others don't

We also add rescue block not to hard fail in case parallel clone
experience issues.

[1] https://git-scm.com/docs/git-reset

Change-Id: I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f
(cherry picked from commit 273d84be94333c686fecf7210555ec439941e283)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/88/769588/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/library/git_requirements.py', 'scripts/get-ansible-role-requirements.yml']",2,f8f4c9b4166076899bde587831d08fcce6d72269,," - name: Clone git repos block: - name: Clone git repos (parallel) git_requirements: default_path: ""{{ role_path_default }}"" default_depth: 10 default_version: ""master"" repo_info: ""{{ clone_roles }}"" retries: ""{{ git_clone_retries }}"" delay: ""{{ git_clone_retry_delay }}"" force: ""{{ not (ansible_distribution | lower == 'ubuntu' and ansible_distribution_version is version('20.04', '>=')) }}"" core_multiplier: 4 rescue: - name: Clone git repos (with git) git: repo: ""{{ item.src }}"" dest: ""{{ item.path | default(role_path_default) }}/{{ item.name | default(item.src | basename) }}"" version: ""{{ item.version | default('master') }}"" refspec: ""{{ item.refspec | default(omit) }}"" depth: ""{{ item.depth | default('10') }}"" update: true force: true with_items: ""{{ clone_roles }}"" register: git_clone until: git_clone is success retries: ""{{ git_clone_retries }}"" delay: ""{{ git_clone_retry_delay }}"""," - name: Clone git repos (parallel) git_requirements: default_path: ""{{ role_path_default }}"" default_depth: 10 default_version: ""master"" repo_info: ""{{ clone_roles }}"" retries: ""{{ git_clone_retries }}"" delay: ""{{ git_clone_retry_delay }}"" force: true core_multiplier: 4",29,12
openstack%2Ftripleo-validations~stable%2Ftrain~Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc,openstack/tripleo-validations,stable/train,Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc,Add tripleo-validation.py as script in setup.cfg,MERGED,2020-10-07 11:06:12.000000000,2021-01-06 23:52:12.000000000,2021-01-06 23:48:52.000000000,"[{'_account_id': 9592}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-10-07 11:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/4de0127d585b9a3655dfc4d0c0edd3a98969fb2b', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 2, 'created': '2020-10-30 21:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/2461082aea1661fca32b031be8c34280edfe3da2', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 3, 'created': '2020-10-30 22:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/9549491efd53f2572c01d647b97f99cd87274bc1', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nDepends-On: https://review.opendev.org/#/c/760437\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 4, 'created': '2020-10-30 22:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/11a4d0f821673d8b629701f1efcf4a6660c134b1', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nDepends-On: https://review.opendev.org/#/c/760437\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 5, 'created': '2020-11-18 08:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/56c52840e05d164afe0b624ca86bcfa339033bd9', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 6, 'created': '2020-11-24 12:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/3f120e78bb185aaf2a687e125f822cced25a6405', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 7, 'created': '2020-11-24 12:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/40598716375e65115bf694a4b7ee51e3997507ab', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 8, 'created': '2021-01-05 16:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/2fbd05a3382b7069f1132fc1231aa97eeeb8a681', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}, {'number': 9, 'created': '2021-01-06 08:18:38.000000000', 'files': ['lower-constraints.txt', 'zuul.d/layout.yaml', 'setup.cfg', 'zuul.d/layout.yaml.bak', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/937fb3a27f0b24ecea799ad673656445616c2c94', 'message': 'Add tripleo-validation.py as script in setup.cfg\n\nChange-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc\n(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)\n(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)\n'}]",0,756493,937fb3a27f0b24ecea799ad673656445616c2c94,51,6,9,11491,,,0,"Add tripleo-validation.py as script in setup.cfg

Change-Id: Ic3ce56eb98f8e04048c9a871aa01fa290ec5e7dc
(cherry picked from commit 0f7389fd93ac3a1a8ba6bd0373dcf27521e43d4e)
(cherry picked from commit c472b46aec92852af87baf6ca048aae7cfc8684c)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/93/756493/6 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,4de0127d585b9a3655dfc4d0c0edd3a98969fb2b,rhbz#1877688-train-bp, scripts/tripleo-validation.py,,1,0
openstack%2Fopenstack-helm-infra~master~I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d,openstack/openstack-helm-infra,master,I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d,Fix spacing inconsistencies with flags,MERGED,2021-01-05 21:48:25.000000000,2021-01-06 20:45:50.000000000,2021-01-06 20:44:41.000000000,"[{'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 24780}, {'_account_id': 28849}, {'_account_id': 30582}, {'_account_id': 30777}, {'_account_id': 31713}]","[{'number': 1, 'created': '2021-01-05 21:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0cb53430c4bdccf96acf732d233cb12b56f6eb06', 'message': 'Fix spacing inconsistencies with flags\n\nChange-Id: I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d\n'}, {'number': 2, 'created': '2021-01-05 22:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/64aaaa4b72185c8e8958d593ea8018ffbd7ed663', 'message': 'Fix spacing inconsistencies with flags\n\nChange-Id: I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d\n'}, {'number': 3, 'created': '2021-01-05 22:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9418c55fcc8ccac4e01fd1ea2a53dea84561f869', 'message': 'Fix spacing inconsistencies with flags\n\nChange-Id: I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d\n'}, {'number': 4, 'created': '2021-01-06 00:16:28.000000000', 'files': ['prometheus/Chart.yaml', 'prometheus/templates/utils/_command_line_flags.tpl', 'prometheus/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1934d32cdd110686d82e2e9352829ffefcb27508', 'message': 'Fix spacing inconsistencies with flags\n\nChange-Id: I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d\n'}]",0,769423,1934d32cdd110686d82e2e9352829ffefcb27508,27,10,4,27499,,,0,"Fix spacing inconsistencies with flags

Change-Id: I83676f62a4cfc7d8e20145a72f28eeab5ef4cc8d
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/23/769423/4 && git format-patch -1 --stdout FETCH_HEAD,['prometheus/templates/utils/_command_line_flags.tpl'],1,0cb53430c4bdccf96acf732d233cb12b56f6eb06,,"{{- printf "" --%s"" $flag -}}{{- printf "" --%s=%s"" $flag $value }}","{{- printf ""--%s "" $flag -}}{{- printf ""--%s=%s "" $flag $value }}",2,2
openstack%2Fpython-tripleoclient~master~I265b77de4b8f9b611f6bc908e90d8f69a26439ab,openstack/python-tripleoclient,master,I265b77de4b8f9b611f6bc908e90d8f69a26439ab,[Validator Run] Add return code management,MERGED,2020-10-13 10:49:45.000000000,2021-01-06 20:45:34.000000000,2021-01-06 20:43:51.000000000,"[{'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-10-13 10:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3117bb7d6169727dd2b22e8d140779281faa13f0', 'message': '[Validator Run] Aligning PrettyTable to left\n\nThis patch is aligning the result table to left in order to be compliant\nwith other table output.\n\nChange-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2020-10-13 15:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2f811a4d4c11c6427f82eb16051a02af489d6525', 'message': '[Validator Run] Add return code management\n\nThe validator run command will now raise a CommandError exception if one\nor more validations have failed.\n\nThis patch is also aligning the result table to left in order to be\ncompliant with other table output.\n\nChange-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 3, 'created': '2020-10-21 13:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3b628694b54a910fd8259aaba2fd9f5f684df82a', 'message': '[Validator Run] Add return code management\n\nThe validator run command will now raise a CommandError exception if one\nor more validations have failed.\n\nThis patch is also aligning the result table to left in order to be\ncompliant with other table output.\n\nChange-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 4, 'created': '2020-10-30 12:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/55042999e9c4472bc1cd50c0b870285c13ca7330', 'message': '[Validator Run] Add return code management\n\nThe validator run command will now raise a CommandError exception if one\nor more validations have failed.\n\nThis patch is also aligning the result table to left in order to be\ncompliant with other table output.\n\nChange-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 5, 'created': '2021-01-05 08:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0f870be97608082a8f530b46d1dca7f9a9be236f', 'message': '[Validator Run] Add return code management\n\nThe validator run command will now raise a CommandError exception if one\nor more validations have failed.\n\nThis patch is also aligning the result table to left in order to be\ncompliant with other table output.\n\nChange-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 6, 'created': '2021-01-05 16:31:50.000000000', 'files': ['tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/be3f43ff81e24a0262d8f02495cca9a876731f7c', 'message': '[Validator Run] Add return code management\n\nThe validator run command will now raise a CommandError exception if one\nor more validations have failed.\n\nThis patch is also aligning the result table to left in order to be\ncompliant with other table output.\n\nChange-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",0,757820,be3f43ff81e24a0262d8f02495cca9a876731f7c,27,6,6,11491,,,0,"[Validator Run] Add return code management

The validator run command will now raise a CommandError exception if one
or more validations have failed.

This patch is also aligning the result table to left in order to be
compliant with other table output.

Change-Id: I265b77de4b8f9b611f6bc908e90d8f69a26439ab
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/20/757820/6 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_validator.py'],1,3117bb7d6169727dd2b22e8d140779281faa13f0,," t.align = ""l""",,1,0
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I35c7c1610af08b33497f43090761aaa55d3a9efc,openstack/tripleo-heat-templates,stable/victoria,I35c7c1610af08b33497f43090761aaa55d3a9efc,Ensure cloud-init has finished before puppet run,MERGED,2020-12-07 02:59:53.000000000,2021-01-06 20:43:59.000000000,2021-01-06 20:43:59.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-07 02:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d96ae303128746c0ecfdd16b4d9a38e5650cd28', 'message': 'Ensure cloud-init has finished before puppet run\n\nSometimes cloud-init does not finish before we start applying\nconfigs with ansible/puppet and can lead to issues. This would\nensure that cloud-init has finished before ansible/puppet\nconfigs.\n\nWith os-collect-config we used to ensure that with:\n\n$ sudo cat /usr/lib/systemd/system/os-collect-config.service\n[Unit]\nDescription=Collect metadata and run hook commands.\nAfter=cloud-final.service\nBefore=crond.service\n\nWith baremetal provisioning after config-drive support, this\nwould also be useful when firstboot config is used.\n\nChange-Id: I35c7c1610af08b33497f43090761aaa55d3a9efc\n(cherry picked from commit 1879441b3c3e771a5754ed9689f64dde2a927efb)\n'}, {'number': 2, 'created': '2020-12-07 19:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/afc7f768361140da9b228cc365f1e720961a8557', 'message': 'Ensure cloud-init has finished before puppet run\n\nSometimes cloud-init does not finish before we start applying\nconfigs with ansible/puppet and can lead to issues. This would\nensure that cloud-init has finished before ansible/puppet\nconfigs.\n\nWith os-collect-config we used to ensure that with:\n\n$ sudo cat /usr/lib/systemd/system/os-collect-config.service\n[Unit]\nDescription=Collect metadata and run hook commands.\nAfter=cloud-final.service\nBefore=crond.service\n\nWith baremetal provisioning after config-drive support, this\nwould also be useful when firstboot config is used.\n\nDepends-On: https://review.opendev.org/c/765835\nChange-Id: I35c7c1610af08b33497f43090761aaa55d3a9efc\n(cherry picked from commit 1879441b3c3e771a5754ed9689f64dde2a927efb)\n'}, {'number': 3, 'created': '2020-12-09 09:54:04.000000000', 'files': ['common/deploy-steps-tasks-step-0.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1bda7f47c5d9422dc638d74cd7866cae868a9e6', 'message': 'Ensure cloud-init has finished before puppet run\n\nSometimes cloud-init does not finish before we start applying\nconfigs with ansible/puppet and can lead to issues. This would\nensure that cloud-init has finished before ansible/puppet\nconfigs.\n\nWith os-collect-config we used to ensure that with:\n\n$ sudo cat /usr/lib/systemd/system/os-collect-config.service\n[Unit]\nDescription=Collect metadata and run hook commands.\nAfter=cloud-final.service\nBefore=crond.service\n\nWith baremetal provisioning after config-drive support, this\nwould also be useful when firstboot config is used.\n\nChange-Id: I35c7c1610af08b33497f43090761aaa55d3a9efc\n(cherry picked from commit 1879441b3c3e771a5754ed9689f64dde2a927efb)\n'}]",0,765736,b1bda7f47c5d9422dc638d74cd7866cae868a9e6,32,4,3,8833,,,0,"Ensure cloud-init has finished before puppet run

Sometimes cloud-init does not finish before we start applying
configs with ansible/puppet and can lead to issues. This would
ensure that cloud-init has finished before ansible/puppet
configs.

With os-collect-config we used to ensure that with:

$ sudo cat /usr/lib/systemd/system/os-collect-config.service
[Unit]
Description=Collect metadata and run hook commands.
After=cloud-final.service
Before=crond.service

With baremetal provisioning after config-drive support, this
would also be useful when firstboot config is used.

Change-Id: I35c7c1610af08b33497f43090761aaa55d3a9efc
(cherry picked from commit 1879441b3c3e771a5754ed9689f64dde2a927efb)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/765736/3 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps-tasks-step-0.j2.yaml'],1,4d96ae303128746c0ecfdd16b4d9a38e5650cd28,,"- name: Populate service facts service_facts: - name: Wait for cloud-init to finish, if enabled cloud_init_data_facts: filter: status register: res until: > res.cloud_init_data_facts.status.v1.stage is defined and not res.cloud_init_data_facts.status.v1.stage retries: 50 delay: 5 when: > 'cloud-init.service' in ansible_facts.services and ansible_facts.services['cloud-init.service']['status'] == 'enabled'",,14,0
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79,openstack/tripleo-heat-templates,stable/victoria,I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79,Don't pass empty values for ipaclient_servers to ipaclient role,MERGED,2020-12-24 11:17:08.000000000,2021-01-06 20:43:45.000000000,2021-01-06 20:43:45.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-24 11:17:08.000000000', 'files': ['deployment/ipa/ipaservices-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5c5f008df935e4b8aba3f65653d8a6e6a0cc0013', 'message': ""Don't pass empty values for ipaclient_servers to ipaclient role\n\nThis avoids passing an empty value to the --server and --domain options\nof ipa-client-install. These are then auto-detected, as described in\nthe IdMServer and IdMDomain parameters descriptions.\n\nChange-Id: I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79\nCloses-Bug: #1904856\nResolves: rhbz#1874936\n(cherry picked from commit 39ee7e23dadedcd6de2ab3f30b322954379b8214)\n""}]",0,768398,5c5f008df935e4b8aba3f65653d8a6e6a0cc0013,10,3,1,14250,,,0,"Don't pass empty values for ipaclient_servers to ipaclient role

This avoids passing an empty value to the --server and --domain options
of ipa-client-install. These are then auto-detected, as described in
the IdMServer and IdMDomain parameters descriptions.

Change-Id: I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79
Closes-Bug: #1904856
Resolves: rhbz#1874936
(cherry picked from commit 39ee7e23dadedcd6de2ab3f30b322954379b8214)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/98/768398/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ipa/ipaservices-baremetal-ansible.yaml'],1,5c5f008df935e4b8aba3f65653d8a6e6a0cc0013,fix_providing_server_domain_args-stable/victoria," map_merge: - state: present ipaclient_otp: ""{{ ipa_host_otp }}"" idm_enroll_base_server: {get_param: IdMEnrollBaseServer} ipaclient_mkhomedir: {get_param: MakeHomeDir} ipaclient_no_ntp: {get_param: IdMNoNtpSetup} ipaclient_force: yes ipaclient_hostname: ""{{ fqdn_canonical }}"" ipaclient_install_packages: {get_param: IdMInstallClientPackages} ipaclients: - ""{{ inventory_hostname }}"" - if: - idm_server_provided - ipaclient_servers: {get_param: IdMServer} ipaclient_domain: {get_param: IdMDomain} - {}"," state: present ipaclient_otp: ""{{ ipa_host_otp }}"" idm_enroll_base_server: {get_param: IdMEnrollBaseServer} ipaclient_mkhomedir: {get_param: MakeHomeDir} ipaclient_domain: {get_param: IdMDomain} ipaclient_no_ntp: {get_param: IdMNoNtpSetup} ipaclient_force: yes ipaclient_servers: {get_param: IdMServer} ipaclient_hostname: ""{{ fqdn_canonical }}"" ipaclient_install_packages: {get_param: IdMInstallClientPackages} ipaclients: - ""{{ inventory_hostname }}""",18,12
openstack%2Ftripleo-ci~master~I1b4ce4f95b7a5bdd92de41735d1cd2b1b63f4047,openstack/tripleo-ci,master,I1b4ce4f95b7a5bdd92de41735d1cd2b1b63f4047,Add victoria multinode job to periodic,MERGED,2020-12-16 13:27:46.000000000,2021-01-06 20:32:29.000000000,2021-01-06 20:32:29.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-16 13:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0d83c1dfdacf51364d39bec13eae05f28736a5b8', 'message': 'Add victoria multinode job to periodic\n\nClean up old-style periodic job\nChange-Id: I1b4ce4f95b7a5bdd92de41735d1cd2b1b63f4047\n'}, {'number': 2, 'created': '2020-12-21 22:39:15.000000000', 'files': ['zuul.d/periodic.yaml', 'zuul.d/multinode-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fd4b8c949f74d9faaf0d96ab1d185819200c2b46', 'message': 'Add victoria multinode job to periodic\n\nClean up old-style periodic job\nChange-Id: I1b4ce4f95b7a5bdd92de41735d1cd2b1b63f4047\n'}]",0,767350,fd4b8c949f74d9faaf0d96ab1d185819200c2b46,27,5,2,10969,,,0,"Add victoria multinode job to periodic

Clean up old-style periodic job
Change-Id: I1b4ce4f95b7a5bdd92de41735d1cd2b1b63f4047
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/50/767350/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/periodic.yaml', 'zuul.d/multinode-jobs.yaml']",2,0d83c1dfdacf51364d39bec13eae05f28736a5b8,,, periodic: jobs: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-content-provider-train - tripleo-ci-centos-7-content-provider-queens - tripleo-ci-centos-8-containers-multinode-victoria: vars: force_non_periodic: true - tripleo-ci-centos-8-containers-multinode-ussuri: vars: force_non_periodic: true - tripleo-ci-centos-8-containers-multinode-train: vars: force_non_periodic: true - tripleo-ci-centos-7-containers-multinode-train: vars: force_non_periodic: true - tripleo-ci-centos-7-containers-multinode-stein: vars: force_non_periodic: true - tripleo-ci-centos-7-containers-multinode-rocky: vars: force_non_periodic: true - tripleo-ci-centos-7-containers-multinode-queens: vars: force_non_periodic: true,7,27
openstack%2Fossa~master~Id450757b2a6a026839be26cf9e8f243f76594348,openstack/ossa,master,Id450757b2a6a026839be26cf9e8f243f76594348,Add missing releases for the CVE,MERGED,2021-01-06 15:45:44.000000000,2021-01-06 20:16:30.000000000,2021-01-06 20:15:11.000000000,"[{'_account_id': 5263}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 15:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/e175f6a43d6a3d995e1aaf42ff8c69db8587b777', 'message': 'Add missing releases for the CVE\n\nChange-Id: Id450757b2a6a026839be26cf9e8f243f76594348\n'}, {'number': 2, 'created': '2021-01-06 19:57:26.000000000', 'files': ['ossa/OSSA-2020-008.yaml'], 'web_link': 'https://opendev.org/openstack/ossa/commit/fc1a66d398a78b44512e7a35c0faa20146199924', 'message': 'Add missing releases for the CVE\n\nChange-Id: Id450757b2a6a026839be26cf9e8f243f76594348\n'}]",2,769558,fc1a66d398a78b44512e7a35c0faa20146199924,12,3,2,13095,,,0,"Add missing releases for the CVE

Change-Id: Id450757b2a6a026839be26cf9e8f243f76594348
",git fetch https://review.opendev.org/openstack/ossa refs/changes/58/769558/1 && git format-patch -1 --stdout FETCH_HEAD,['ossa/OSSA-2020-008.yaml'],1,e175f6a43d6a3d995e1aaf42ff8c69db8587b777,, rocky: - https://review.opendev.org/765945 queens: - https://review.opendev.org/765950 pike: - https://review.opendev.org/765951,,6,0
openstack%2Fpatrole~master~I948c6ee0e2b1b021eae1393caa2cc91fdb477e06,openstack/patrole,master,I948c6ee0e2b1b021eae1393caa2cc91fdb477e06,"Add skip for Nova policy ""os_compute_api:os-admin-actions:reset_network""",ABANDONED,2021-01-05 10:22:11.000000000,2021-01-06 20:09:56.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-05 10:22:11.000000000', 'files': ['patrole_tempest_plugin/tests/api/compute/test_server_misc_policy_actions_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/fc0939f70da2b0e83b9450fe79873ac183f3ff61', 'message': 'Add skip for Nova policy ""os_compute_api:os-admin-actions:reset_network""\n\nThe policy has been removed in\nhttps://review.opendev.org/c/openstack/nova/+/749315\n\nChange-Id: I948c6ee0e2b1b021eae1393caa2cc91fdb477e06\n'}]",0,769309,fc0939f70da2b0e83b9450fe79873ac183f3ff61,3,1,1,6732,,,0,"Add skip for Nova policy ""os_compute_api:os-admin-actions:reset_network""

The policy has been removed in
https://review.opendev.org/c/openstack/nova/+/749315

Change-Id: I948c6ee0e2b1b021eae1393caa2cc91fdb477e06
",git fetch https://review.opendev.org/openstack/patrole refs/changes/09/769309/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/compute/test_server_misc_policy_actions_rbac.py'],1,fc0939f70da2b0e83b9450fe79873ac183f3ff61,remove-policy," @testtools.skipIf( CONF.policy_feature_enabled.removed_nova_policies_wallaby, ""This API extension policy was removed in Wallaby"")",,3,0
openstack%2Fnova~master~Ie824b972c9f63af7c38d63ade1d293c3acc7538b,openstack/nova,master,Ie824b972c9f63af7c38d63ade1d293c3acc7538b,tests: Remove 'test_extended_hypervisors',MERGED,2021-01-06 11:16:10.000000000,2021-01-06 19:47:49.000000000,2021-01-06 19:46:08.000000000,"[{'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 11:16:10.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_extended_hypervisors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f86bf703e5367dfce21a2819b926b2f32d0c72e4', 'message': ""tests: Remove 'test_extended_hypervisors'\n\nThis is a hangover from the days of API extensions. Everything that's\ncovered here is covered in 'test_hypervisors' now.\n\nChange-Id: Ie824b972c9f63af7c38d63ade1d293c3acc7538b\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,769519,f86bf703e5367dfce21a2819b926b2f32d0c72e4,10,3,1,15334,,,0,"tests: Remove 'test_extended_hypervisors'

This is a hangover from the days of API extensions. Everything that's
covered here is covered in 'test_hypervisors' now.

Change-Id: Ie824b972c9f63af7c38d63ade1d293c3acc7538b
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/769519/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/test_extended_hypervisors.py'],1,f86bf703e5367dfce21a2819b926b2f32d0c72e4,bp/modernize-os-hypervisors-api,,"# Copyright 2014 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import mock from nova.api.openstack.compute import hypervisors \ as hypervisors_v21 from nova import exception from nova import objects from nova import test from nova.tests.unit.api.openstack.compute import test_hypervisors from nova.tests.unit.api.openstack import fakes def fake_compute_node_get(context, compute_id): for hyper in test_hypervisors.TEST_HYPERS_OBJ: if hyper.id == int(compute_id): return hyper raise exception.ComputeHostNotFound(host=compute_id) def fake_compute_node_get_all(context, limit=None, marker=None): return test_hypervisors.TEST_HYPERS_OBJ def fake_service_get_by_compute_host(context, host): for service in test_hypervisors.TEST_SERVICES: if service.host == host: return service class ExtendedHypervisorsTestV21(test.NoDBTestCase): DETAIL_HYPERS_DICTS = copy.deepcopy(test_hypervisors.TEST_HYPERS) del DETAIL_HYPERS_DICTS[0]['service_id'] del DETAIL_HYPERS_DICTS[1]['service_id'] del DETAIL_HYPERS_DICTS[0]['host'] del DETAIL_HYPERS_DICTS[1]['host'] del DETAIL_HYPERS_DICTS[0]['uuid'] del DETAIL_HYPERS_DICTS[1]['uuid'] DETAIL_HYPERS_DICTS[0].update({'state': 'up', 'status': 'enabled', 'service': dict(id=1, host='compute1', disabled_reason=None)}) DETAIL_HYPERS_DICTS[1].update({'state': 'up', 'status': 'enabled', 'service': dict(id=2, host='compute2', disabled_reason=None)}) def _set_up_controller(self): self.controller = hypervisors_v21.HypervisorsController() def _get_request(self): return fakes.HTTPRequest.blank( '/v2/%s/os-hypervisors/detail' % fakes.FAKE_PROJECT_ID, use_admin_context=True) def setUp(self): super(ExtendedHypervisorsTestV21, self).setUp() self._set_up_controller() def test_view_hypervisor_detail_noservers(self): with mock.patch.object(self.controller.servicegroup_api, 'service_is_up', return_value=True) as mock_service_is_up: req = self._get_request() result = self.controller._view_hypervisor( test_hypervisors.TEST_HYPERS_OBJ[0], test_hypervisors.TEST_SERVICES[0], True, req) self.assertEqual(self.DETAIL_HYPERS_DICTS[0], result) self.assertTrue(mock_service_is_up.called) @mock.patch.object(objects.Service, 'get_by_compute_host', side_effect=fake_service_get_by_compute_host) def test_detail(self, mock_get_by_host): with test.nested( mock.patch.object(self.controller.host_api, 'compute_node_get_all', side_effect=fake_compute_node_get_all), mock.patch.object(self.controller.servicegroup_api, 'service_is_up', return_value=True), ) as (mock_node_get_all, mock_service_is_up): req = self._get_request() result = self.controller.detail(req) self.assertEqual(dict(hypervisors=self.DETAIL_HYPERS_DICTS), result) self.assertTrue(mock_service_is_up.called) self.assertTrue(mock_get_by_host.called) self.assertTrue(mock_node_get_all.called) @mock.patch.object(objects.Service, 'get_by_compute_host', side_effect=fake_service_get_by_compute_host) def test_show_withid(self, mock_get_by_host): with test.nested( mock.patch.object(self.controller.host_api, 'compute_node_get', side_effect=fake_compute_node_get), mock.patch.object(self.controller.servicegroup_api, 'service_is_up', return_value=True), ) as (mock_node_get, mock_service_is_up): req = self._get_request() result = self.controller.show(req, '1') self.assertEqual(dict(hypervisor=self.DETAIL_HYPERS_DICTS[0]), result) self.assertTrue(mock_service_is_up.called) self.assertTrue(mock_get_by_host.called) self.assertTrue(mock_node_get.called) ",0,120
openstack%2Fopenstack-ansible-os_zun~master~Ib2395c317c34cfbd4b72b1d19932a236bcff7a30,openstack/openstack-ansible-os_zun,master,Ib2395c317c34cfbd4b72b1d19932a236bcff7a30,defaults: start kuryr service before docker,MERGED,2021-01-06 08:59:43.000000000,2021-01-06 19:29:59.000000000,2021-01-06 19:28:39.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2021-01-06 08:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/e0ec5592be8baedd42f679dc1b270a2c25778c55', 'message': 'defaults: start kuryr service before docker\n\nIf Docker starts first, it gets stuck in a starting state waiting\nfor the kuryr service to become available. This change swaps the\norder to start kuryr first instead.\n\nChange-Id: Ib2395c317c34cfbd4b72b1d19932a236bcff7a30\n'}, {'number': 2, 'created': '2021-01-06 09:11:56.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/1a75a7dfbe9345fa795965fea947237d2e8bec80', 'message': 'defaults: start kuryr service before docker\n\nIf Docker starts first, it gets stuck in a starting state waiting\nfor the kuryr service to become available. This change swaps the\norder to start kuryr first instead.\n\nChange-Id: Ib2395c317c34cfbd4b72b1d19932a236bcff7a30\n'}]",5,769474,1a75a7dfbe9345fa795965fea947237d2e8bec80,14,3,2,31542,,,0,"defaults: start kuryr service before docker

If Docker starts first, it gets stuck in a starting state waiting
for the kuryr service to become available. This change swaps the
order to start kuryr first instead.

Change-Id: Ib2395c317c34cfbd4b72b1d19932a236bcff7a30
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/74/769474/2 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,e0ec5592be8baedd42f679dc1b270a2c25778c55,zun-bootorder, Before: docker.service After: network-online.target,# NOTE(cloudnull): These options are used to ensure that kuryr is always # started after docker and has the proper capabilities. After: ? network-online.target ? docker.service PartOf: docker.service,2,6
openstack%2Frpm-packaging~master~I483988e6fe64a5ebbf798a3bdfc6d058ea19036a,openstack/rpm-packaging,master,I483988e6fe64a5ebbf798a3bdfc6d058ea19036a,Update python-tripleoclient to 14.1.0,MERGED,2021-01-05 08:05:29.000000000,2021-01-06 19:18:19.000000000,2021-01-06 19:18:19.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-05 08:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/38bd55bfa8d076059584202a23ed64029fc5bab0', 'message': 'Update python-tripleoclient to 14.1.0\n\nChange-Id: I483988e6fe64a5ebbf798a3bdfc6d058ea19036a\n'}, {'number': 2, 'created': '2021-01-06 16:47:05.000000000', 'files': ['openstack/python-tripleoclient/python-tripleoclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/984cb8543d4d85a0af98eb4e7c25d3370c0f45cc', 'message': 'Update python-tripleoclient to 14.1.0\n\nChange-Id: I483988e6fe64a5ebbf798a3bdfc6d058ea19036a\n'}]",0,769257,984cb8543d4d85a0af98eb4e7c25d3370c0f45cc,14,5,2,27380,,,0,"Update python-tripleoclient to 14.1.0

Change-Id: I483988e6fe64a5ebbf798a3bdfc6d058ea19036a
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/57/769257/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-tripleoclient/python-tripleoclient.spec.j2'],1,38bd55bfa8d076059584202a23ed64029fc5bab0,update_python-tripleoclient,{% set upstream_version = upstream_version('14.1.0') %},{% set upstream_version = upstream_version('14.0.0') %},1,1
openstack%2Fopenstack-ansible-os_keystone~stable%2Fvictoria~Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486,openstack/openstack-ansible-os_keystone,stable/victoria,Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486,Add no_log to LDAP domain config,MERGED,2021-01-04 21:13:53.000000000,2021-01-06 19:11:49.000000000,2021-01-06 19:07:21.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-04 21:13:53.000000000', 'files': ['tasks/keystone_ldap_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/3420f29a5557af0aa09b5aefe73b20de60f22cc7', 'message': 'Add no_log to LDAP domain config\n\nThe data contains credentials which should not appear in logs.\n\nChange-Id: Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486\n(cherry picked from commit 27f3306713982df7685384c24c1880c2b8ae797c)\n'}]",0,769185,3420f29a5557af0aa09b5aefe73b20de60f22cc7,16,3,1,25023,,,0,"Add no_log to LDAP domain config

The data contains credentials which should not appear in logs.

Change-Id: Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486
(cherry picked from commit 27f3306713982df7685384c24c1880c2b8ae797c)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/85/769185/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/keystone_ldap_setup.yml'],1,3420f29a5557af0aa09b5aefe73b20de60f22cc7,, no_log: true no_log: true,,2,0
openstack%2Fpatrole~master~Id73342c24342637edc37104f2112235a2edcac39,openstack/patrole,master,Id73342c24342637edc37104f2112235a2edcac39,Remove stable/stein testing jobs,MERGED,2020-12-21 18:44:53.000000000,2021-01-06 18:40:36.000000000,2021-01-06 18:36:04.000000000,"[{'_account_id': 6732}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2020-12-21 18:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/df0dcf529aff0adbc7835697fd125271b2dfa15e', 'message': ""Remove stable/stein testing jobs\n\nstable/stein is not suported in Patrole now, so\nlet's remove their jobs from master gate.\n\nChange-Id: Id73342c24342637edc37104f2112235a2edcac39\n""}, {'number': 2, 'created': '2021-01-05 21:55:12.000000000', 'files': ['patrole_tempest_plugin/tests/api/compute/test_server_misc_policy_actions_rbac.py', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/patrole/commit/700c1db070bd6a5ac331dc5a6b6fc59bb2c43105', 'message': 'Remove stable/stein testing jobs\n\nstable/stein is not suported in Patrole now, so\nlet\'s remove their jobs from master gate.\n\nIn order to pass the CI, the following changes are also made:\n* Added skip for Nova policy\n  ""os_compute_api:os-admin-actions:reset_network"", which was removed in\n  https://review.opendev.org/c/openstack/nova/+/749315\n* Removed openstack-tox-lower-constraints job for now until we have a\n  solution.\n\nChange-Id: Id73342c24342637edc37104f2112235a2edcac39\n'}]",0,768119,700c1db070bd6a5ac331dc5a6b6fc59bb2c43105,10,4,2,8556,,,0,"Remove stable/stein testing jobs

stable/stein is not suported in Patrole now, so
let's remove their jobs from master gate.

In order to pass the CI, the following changes are also made:
* Added skip for Nova policy
  ""os_compute_api:os-admin-actions:reset_network"", which was removed in
  https://review.opendev.org/c/openstack/nova/+/749315
* Removed openstack-tox-lower-constraints job for now until we have a
  solution.

Change-Id: Id73342c24342637edc37104f2112235a2edcac39
",git fetch https://review.opendev.org/openstack/patrole refs/changes/19/768119/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,df0dcf529aff0adbc7835697fd125271b2dfa15e,,, name: patrole-member-stein parent: patrole-member nodeset: openstack-single-node-bionic override-checkout: stable/stein vars: devstack_localrc: USE_PYTHON3: True - job: - patrole-member-stein - patrole-member-stein,0,11
openstack%2Fopenstack-helm-infra~master~I0439272587a2afbccc4d7c49ef6ad053c8b305e7,openstack/openstack-helm-infra,master,I0439272587a2afbccc4d7c49ef6ad053c8b305e7,Update default Kubernetes API for use with Helm v3,MERGED,2020-12-21 18:54:54.000000000,2021-01-06 18:40:32.000000000,2021-01-06 18:39:13.000000000,"[{'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 24780}, {'_account_id': 30495}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-12-21 18:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4fd2111cb2bd4afb3e6aa9fe2ceb20ed50ed68d7', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 2, 'created': '2020-12-21 19:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/679f232098cbc9fc2f239d3f96adba2297ba0afc', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 3, 'created': '2020-12-21 20:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9a03086a111c058d3e739ca04c8bd33fdaa601fd', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 4, 'created': '2020-12-22 21:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/effb52a5fedfa9c3e0d921d3a8502d0558f8aaf1', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 5, 'created': '2020-12-22 21:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/625bb874039240980505eac7a237de683444d7b2', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 6, 'created': '2020-12-22 22:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1042c83b0733b9a4a78a40e04d46dfbba605eeba', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 7, 'created': '2020-12-23 00:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b5db0544e3daa81f987743fc500ef5f4f2f5cd7f', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 8, 'created': '2021-01-05 15:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ea71d24f3025bca387179b008dca72562858106b', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 9, 'created': '2021-01-05 15:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/227c7af2264dde7d9a4faef1c4af392fb0bda3f2', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 10, 'created': '2021-01-05 15:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d3f6e70584e0408cc81142a5ff6c23744ebede1b', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}, {'number': 11, 'created': '2021-01-05 16:43:38.000000000', 'files': ['ingress/Chart.yaml', 'ingress/templates/ingress.yaml', 'helm-toolkit/Chart.yaml', 'helm-toolkit/templates/manifests/_ingress.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/67618474ce5f0adbbbe30b2d7b22b88127ef5070', 'message': 'Update default Kubernetes API for use with Helm v3\n\nUpdated Kubernetes api from extensions/v1beta1 to\nnetworking.k8s.io/v1beta1 per docs[0] for kubernetes\n1.16 deprecations as helm v3 linting will fail\nwhen it parses extensions/v1beta1 seen here[1]\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e\n\nChange-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7\n'}]",4,768120,67618474ce5f0adbbbe30b2d7b22b88127ef5070,42,8,11,29585,,,0,"Update default Kubernetes API for use with Helm v3

Updated Kubernetes api from extensions/v1beta1 to
networking.k8s.io/v1beta1 per docs[0] for kubernetes
1.16 deprecations as helm v3 linting will fail
when it parses extensions/v1beta1 seen here[1]

[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/
[1] https://zuul.opendev.org/t/openstack/build/82f92508fb31418aa377f91d62e0d42e

Change-Id: I0439272587a2afbccc4d7c49ef6ad053c8b305e7
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/20/768120/1 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/manifests/_ingress.tpl'],1,4fd2111cb2bd4afb3e6aa9fe2ceb20ed50ed68d7,ready-for-review,apiVersion: networking.k8s.io/v1beta1 ,apiVersion: extensions/v1beta1,1,1
openstack%2Foslo.messaging~master~I01a38754a31c891f2b3b9c7f8135690693df5d13,openstack/oslo.messaging,master,I01a38754a31c891f2b3b9c7f8135690693df5d13,Fix type of direct_mandatory_flag opt,MERGED,2020-12-22 19:36:34.000000000,2021-01-06 18:31:29.000000000,2021-01-06 18:30:08.000000000,"[{'_account_id': 8770}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-22 19:36:34.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b8f8b17030e93f6fe64e986ebae1de4011f007d5', 'message': ""Fix type of direct_mandatory_flag opt\n\nAn IntOpt with a default of True is invalid. I'm a little surprised\nthis doesn't fail a defaults check somewhere, but it needs to be\nfixed regardless.\n\nLooking at where it is used, it appears the boolean type is correct.\nThis just changes the opt type to BoolOpt to match.\n\nChange-Id: I01a38754a31c891f2b3b9c7f8135690693df5d13\nCloses-Bug: 1909036\n""}]",0,768252,b8f8b17030e93f6fe64e986ebae1de4011f007d5,11,3,1,6928,,,0,"Fix type of direct_mandatory_flag opt

An IntOpt with a default of True is invalid. I'm a little surprised
this doesn't fail a defaults check somewhere, but it needs to be
fixed regardless.

Looking at where it is used, it appears the boolean type is correct.
This just changes the opt type to BoolOpt to match.

Change-Id: I01a38754a31c891f2b3b9c7f8135690693df5d13
Closes-Bug: 1909036
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/52/768252/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,b8f8b17030e93f6fe64e986ebae1de4011f007d5,bug/1909036," cfg.BoolOpt('direct_mandatory_flag', default=True, help='Enable/Disable the RabbitMQ mandatory flag ' 'for direct send. The direct send is used as reply, ' 'so the MessageUndeliverable exception is raised ' 'in case the client queue does not exist.'),"," cfg.IntOpt('direct_mandatory_flag', default=True, help='Enable/Disable the RabbitMQ mandatory flag ' 'for direct send. The direct send is used as reply, ' 'so the MessageUndeliverable exception is raised ' 'in case the client queue does not exist.'),",6,6
openstack%2Fopenstacksdk~stable%2Fvictoria~Ia615288da30426c2f689daa3e5f88376aead1d3f,openstack/openstacksdk,stable/victoria,Ia615288da30426c2f689daa3e5f88376aead1d3f,Support roles 'name' in list_roles call,MERGED,2021-01-06 09:16:49.000000000,2021-01-06 18:28:54.000000000,2021-01-06 18:27:12.000000000,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-01-06 09:16:49.000000000', 'files': ['openstack/cloud/_identity.py', 'openstack/tests/unit/cloud/test_identity_roles.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4b594833e65e4a8d52b9217b36adfef900328365', 'message': ""Support roles 'name' in list_roles call\n\nChange-Id: Ia615288da30426c2f689daa3e5f88376aead1d3f\n""}]",0,769374,4b594833e65e4a8d52b9217b36adfef900328365,7,3,1,10969,,,0,"Support roles 'name' in list_roles call

Change-Id: Ia615288da30426c2f689daa3e5f88376aead1d3f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/74/769374/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cloud/_identity.py', 'openstack/tests/unit/cloud/test_identity_roles.py']",2,4b594833e65e4a8d52b9217b36adfef900328365,name_roles-stable/victoria," def test_list_role_by_name(self): role_data = self._get_role_data() self.register_uris([ dict(method='GET', uri=self.get_mock_url( qs_elements=['name={0}'.format(role_data.role_name)]), status_code=200, json={'roles': [role_data.json_response['role']]}) ]) role = self.cloud.list_roles(name=role_data.role_name)[0] self.assertIsNotNone(role) self.assertThat(role.id, matchers.Equals(role_data.role_id)) self.assertThat(role.name, matchers.Equals(role_data.role_name)) self.assert_calls() ",,17,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Ia9942297eabb524c8644a7ba155b728ec6bb71c5,openstack/tripleo-heat-templates,stable/queens,Ia9942297eabb524c8644a7ba155b728ec6bb71c5,DNM: Testing restart of ceph service.,ABANDONED,2021-01-05 16:10:34.000000000,2021-01-06 18:05:21.000000000,,"[{'_account_id': 6796}, {'_account_id': 14270}, {'_account_id': 15205}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2021-01-05 16:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/815142692fc5cd8f6dace287a53dbe21cd05e965', 'message': 'DNM: Testing restart of ceph service.\n\nrelated to bz#1846830 and bz#1910842\n\nChange-Id: Ia9942297eabb524c8644a7ba155b728ec6bb71c5\n'}, {'number': 2, 'created': '2021-01-05 17:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ecf7735ea41b493233f95ea7e9abd868185179a9', 'message': 'DNM: Testing restart of ceph service.\n\nrelated to bz#1846830 and bz#1910842\n\nChange-Id: Ia9942297eabb524c8644a7ba155b728ec6bb71c5\n'}, {'number': 3, 'created': '2021-01-05 22:11:01.000000000', 'files': ['puppet/services/docker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7d9b71abbd48d611320e650c67d60fd10fe66a5b', 'message': 'DNM: Testing restart of ceph service.\n\nrelated to bz#1846830 and bz#1910842\n\nChange-Id: Ia9942297eabb524c8644a7ba155b728ec6bb71c5\n'}]",4,769393,7d9b71abbd48d611320e650c67d60fd10fe66a5b,12,7,3,8297,,,0,"DNM: Testing restart of ceph service.

related to bz#1846830 and bz#1910842

Change-Id: Ia9942297eabb524c8644a7ba155b728ec6bb71c5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/93/769393/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/docker.yaml'],1,815142692fc5cd8f6dace287a53dbe21cd05e965,ceph_docker_update, - name: Ensure all ceph services are started shell: | systemctl start ceph-* ignore_errors: true when: docker_rpm_needs_update,,5,0
openstack%2Fcharm-layer-openstack~master~Idd2a7c436f5448505bdfe5a53738a8e2071ed272,openstack/charm-layer-openstack,master,Idd2a7c436f5448505bdfe5a53738a8e2071ed272,Use the project_name from the identity_service,MERGED,2020-12-23 17:27:25.000000000,2021-01-06 17:52:52.000000000,2021-01-06 17:27:38.000000000,"[{'_account_id': 8992}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-23 17:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-layer-openstack/commit/6f1c0ebbe38cdb156899364e30df29481460a7d6', 'message': 'Use the project_name from the identity_service\n\nCurrently the template hardcodes the `project_name` to `services`\nwhich is not necessarily correct. Instead the template should use the\n`identity_service.service_tenant`.\n\nCloses: #1908945\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\nChange-Id: Idd2a7c436f5448505bdfe5a53738a8e2071ed272\n'}, {'number': 2, 'created': '2020-12-23 17:28:29.000000000', 'files': ['templates/parts/section-keystone-authtoken'], 'web_link': 'https://opendev.org/openstack/charm-layer-openstack/commit/91e6caf3be764d117d07be5dbf5927b847284e49', 'message': 'Use the project_name from the identity_service\n\nCurrently the template hardcodes the `project_name` to `services`\nwhich is not necessarily correct. Instead the template should use the\n`identity_service.service_tenant`.\n\nCloses-Bug: #1908945\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\nChange-Id: Idd2a7c436f5448505bdfe5a53738a8e2071ed272\n'}]",4,768360,91e6caf3be764d117d07be5dbf5927b847284e49,17,5,2,19298,,,0,"Use the project_name from the identity_service

Currently the template hardcodes the `project_name` to `services`
which is not necessarily correct. Instead the template should use the
`identity_service.service_tenant`.

Closes-Bug: #1908945
Signed-off-by: Nicolas Bock <nicolas.bock@canonical.com>
Change-Id: Idd2a7c436f5448505bdfe5a53738a8e2071ed272
",git fetch https://review.opendev.org/openstack/charm-layer-openstack refs/changes/60/768360/2 && git format-patch -1 --stdout FETCH_HEAD,['templates/parts/section-keystone-authtoken'],1,6f1c0ebbe38cdb156899364e30df29481460a7d6,project_name,project_name = {{ identity_service.service_tenant }},project_name = services,1,1
openstack%2Fopenstack-ansible~master~I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f,openstack/openstack-ansible,master,I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f,Set force option to false by default,MERGED,2020-12-29 15:34:56.000000000,2021-01-06 17:52:12.000000000,2021-01-06 17:50:39.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-29 15:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9d7232194971f6e3502528e2fd7d105206e5e3ae', 'message': ""Set force option to false by default\n\nNow git-reset does not have force option [1]. So we're setting it\nto False by default but enable to distros except Ubuntu Focal since\nit has pretty modern git, while others don't\n\nWe also add rescue block not to hard fail in case parallel clone\nexperience issues.\n\n[1] https://git-scm.com/docs/git-reset\n\nChange-Id: I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f\n""}, {'number': 2, 'created': '2020-12-29 15:47:10.000000000', 'files': ['scripts/get-ansible-role-requirements.yml', 'playbooks/library/git_requirements.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/273d84be94333c686fecf7210555ec439941e283', 'message': ""Set force option to false by default\n\nNow git-reset does not have force option [1]. So we're setting it\nto False by default but enable to distros except Ubuntu Focal since\nit has pretty modern git, while others don't\n\nWe also add rescue block not to hard fail in case parallel clone\nexperience issues.\n\n[1] https://git-scm.com/docs/git-reset\n\nChange-Id: I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f\n""}]",0,768729,273d84be94333c686fecf7210555ec439941e283,10,4,2,28619,,,0,"Set force option to false by default

Now git-reset does not have force option [1]. So we're setting it
to False by default but enable to distros except Ubuntu Focal since
it has pretty modern git, while others don't

We also add rescue block not to hard fail in case parallel clone
experience issues.

[1] https://git-scm.com/docs/git-reset

Change-Id: I6e7f35b2aedfd5552f1f451a2b18182ae623ec0f
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/29/768729/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/library/git_requirements.py', 'scripts/get-ansible-role-requirements.yml']",2,9d7232194971f6e3502528e2fd7d105206e5e3ae,," - name: Clone git repos block: - name: Clone git repos (parallel) git_requirements: default_path: ""{{ role_path_default }}"" default_depth: 10 default_version: ""master"" repo_info: ""{{ clone_roles }}"" retries: ""{{ git_clone_retries }}"" delay: ""{{ git_clone_retry_delay }}"" force: ""{{ not (ansible_distribution | lower == 'ubuntu' and ansible_distribution_version is version('20.04', '>=') }}"" core_multiplier: 4 rescue: - name: Clone git repos (with git) git: repo: ""{{ item.src }}"" dest: ""{{ item.path | default(role_path_default) }}/{{ item.name | default(item.src | basename) }}"" version: ""{{ item.version | default('master') }}"" refspec: ""{{ item.refspec | default(omit) }}"" depth: ""{{ item.depth | default('10') }}"" update: true force: true with_items: ""{{ clone_roles }}"" register: git_clone until: git_clone is success retries: ""{{ git_clone_retries }}"" delay: ""{{ git_clone_retry_delay }}"""," - name: Clone git repos (parallel) git_requirements: default_path: ""{{ role_path_default }}"" default_depth: 10 default_version: ""master"" repo_info: ""{{ clone_roles }}"" retries: ""{{ git_clone_retries }}"" delay: ""{{ git_clone_retry_delay }}"" force: true core_multiplier: 4",29,12
openstack%2Fneutron~master~I9ae9d193b885364d5a4d90538880d8e9fbc8df74,openstack/neutron,master,I9ae9d193b885364d5a4d90538880d8e9fbc8df74,Floating IP for routed networks: network:routed API,MERGED,2019-07-05 16:45:47.000000000,2021-01-06 17:35:27.000000000,2021-01-06 17:32:23.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 4187}, {'_account_id': 4694}, {'_account_id': 6476}, {'_account_id': 7016}, {'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 10962}, {'_account_id': 11583}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 32029}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2019-07-05 16:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d069054b32adbf0f20da602ae5678e41448dec26', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 2, 'created': '2020-07-17 09:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c6cea30fc7156d7d02e4634206358ca21c3782f', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 3, 'created': '2020-07-17 09:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/53706dc5b4dc16ad0637f88fe181f548013fec95', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 4, 'created': '2020-07-17 09:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8b9526601bee47fa2a9048083df6845b7e4548b', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 5, 'created': '2020-07-17 11:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b32401c9c80e24bacf966d73752b0711624264b1', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 6, 'created': '2020-07-18 16:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e203942c946b3951bb67dbc8505f471f46480e94', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 7, 'created': '2020-07-20 14:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2567f15d31240e6e25bf3d11b9380d19a9917d16', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 8, 'created': '2020-07-27 11:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eaaf9641f8d547bdce6a7120dee015f7c221a6ff', 'message': ""[WIP][POC] Floating IP's for routed networks\n\nThis change is a proof-of-concept for enabling floating IP's on routed\nnetworks. To be able to create a subnet that spans all segments of a\nrouted network, a special subnet service type of 'network:routed' is\nused to denote a network that can span all segments of a routed network.\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 9, 'created': '2020-07-28 12:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd295222350465945fe085480a38c7a8ce4062b3', 'message': ""Floating IP's for routed networks\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 10, 'created': '2020-07-29 06:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef45532f99146433ba8117323e93b17a974e7b25', 'message': ""Floating IP's for routed networks\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 11, 'created': '2020-07-29 22:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9b5f6b97e36f971799c9a8ea591d2303e5fadfc', 'message': ""[WIP] [PoC] Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 12, 'created': '2020-07-30 07:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb7719d2746ddbb1c73258c0fc8140a80ec50254', 'message': ""[WIP] [PoC] Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 13, 'created': '2020-07-30 12:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/746a7e51973d6e451393c3e270475aa46e3a1e1c', 'message': ""[WIP] [PoC] Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 14, 'created': '2020-07-31 07:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e228ff8f20c148d3f648fbdd28accf387b1a5e8', 'message': ""[WIP] [PoC] Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 15, 'created': '2020-08-03 10:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da40111ff6a7d70627fd8384b21d7d4908eabde4', 'message': ""[WIP] [PoC] Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 16, 'created': '2020-08-03 10:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d03f6b1b432893de9251e87eaf4d8a6c527d1aa', 'message': ""Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nPartial-Bug: #1667329\n""}, {'number': 17, 'created': '2020-08-03 15:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/119d4bac8c99c67b08d55606090d84cc29432925', 'message': ""Floating IP's for routed networks\n\nPatch to check value of action in _validate_segment\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 18, 'created': '2020-08-05 12:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f003b34a86b5595d4a1a17e76ee7c43ce136f021', 'message': ""Floating IP's for routed networks\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 19, 'created': '2020-08-05 12:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74b79f39e428addb98bfee9a67a38defc3f3a825', 'message': ""Floating IP's for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 20, 'created': '2020-08-05 16:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/491afdd621f6162ab601342b3564ede8439c1592', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 21, 'created': '2020-08-06 07:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef70ba6a2800fdf70e1591c0b9c22cb4f85d1c66', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 22, 'created': '2020-08-15 12:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/84a6f8eb0f1906b424dd046311bb52cc446849d2', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 23, 'created': '2020-08-15 12:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/345ed8154466720f81c89e5b5c053bf61ab9ee76', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 24, 'created': '2020-08-15 19:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38ef23590a5b6834cc62b8eeaa603736036f9f4e', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 25, 'created': '2020-08-17 20:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9c5a3ec74619f2def68e142ed063372eaee8624', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 26, 'created': '2020-08-27 11:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4efa46411fac8ccc84f96ba4b4de41e98214ddf', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 27, 'created': '2020-08-31 07:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1876c2de70811ee28b545aa8e494b6c3e0d43517', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 28, 'created': '2020-08-31 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74ee297d005c6a493690868257d3e51e6de46231', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 29, 'created': '2020-09-01 07:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e472d205f5b54fcd847015c5117cbc07adeb82d', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 30, 'created': '2020-12-15 12:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d92ac5315c7e3813c6dba5474c45b3536cca415c', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 31, 'created': '2020-12-16 13:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c4d2f6d7735b5cb558db45ec9f3ce845eea1213', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 32, 'created': '2020-12-16 20:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01bba25351d85acc383254a738fbdfea7483bbdd', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 33, 'created': '2020-12-17 09:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/59c86d56246e23edb4083244d3bed096ac36d37a', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}, {'number': 34, 'created': '2020-12-17 13:22:22.000000000', 'files': ['neutron/tests/unit/db/test_ipam_backend_mixin.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/objects/subnet.py', 'doc/source/admin/figures/bgp-floating-ip-over-l2-segmented-network.png', 'doc/source/admin/config.rst', 'doc/source/admin/config-bgp-floating-ip-over-l2-segmented-network.rst', 'releasenotes/notes/network-routed-subnets-cf4874d97ddacd77.yaml', 'neutron/tests/unit/extensions/test_segment.py', 'doc/source/admin/figures/bgp-floating-ip-over-l2-segmented-network.svg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c613ede9fa79eeabeb23002a6eb9ba9a9b2ac15f', 'message': ""Floating IP for routed networks: network:routed API\n\nThis change is needed for enabling floating IP's on routed networks.\nTo be able to create a subnet that spans all segments of a routed network,\na special subnet service type of 'network:routed' is used to denote a\nnetwork that can span all segments of a routed network.\n\nTo create floating IP's on a routed network, the subnet must be created\nwith a service_type of 'network:routed'. After the subnet has been\ncreated, floating IP's can be allocated and associated as before.\nSee the design spec https://review.opendev.org/#/c/486450/ for\nreference.\n\nOne caveat for this approach is that it requires the underlying\ninfrastructure to be aware of and able to route /32 host routes\nfor the floating IP. This implies that in practice, use of the\n'network:routed' service type should be done in conjunction with\none or both of the following:\n\n1. Third-party SDN backend that handles this service type in its\n   own way\n2. neutron-dynamic-routing and the BGP service plugin for announcing\n   the appropriate next-hops for floating IP's. This is compatible\n   with DVR and non-DVR environments.\n\nDepends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454\nChange-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74\nCo-Author: Thomas Goirand <zigo@debian.org>\nPartial-Bug: #1667329\n""}]",136,669395,c613ede9fa79eeabeb23002a6eb9ba9a9b2ac15f,227,20,34,4187,,,0,"Floating IP for routed networks: network:routed API

This change is needed for enabling floating IP's on routed networks.
To be able to create a subnet that spans all segments of a routed network,
a special subnet service type of 'network:routed' is used to denote a
network that can span all segments of a routed network.

To create floating IP's on a routed network, the subnet must be created
with a service_type of 'network:routed'. After the subnet has been
created, floating IP's can be allocated and associated as before.
See the design spec https://review.opendev.org/#/c/486450/ for
reference.

One caveat for this approach is that it requires the underlying
infrastructure to be aware of and able to route /32 host routes
for the floating IP. This implies that in practice, use of the
'network:routed' service type should be done in conjunction with
one or both of the following:

1. Third-party SDN backend that handles this service type in its
   own way
2. neutron-dynamic-routing and the BGP service plugin for announcing
   the appropriate next-hops for floating IP's. This is compatible
   with DVR and non-DVR environments.

Depends-On: Ibde33bdacba6bd1e9c41cc69d0054bf55e1e6454
Change-Id: I9ae9d193b885364d5a4d90538880d8e9fbc8df74
Co-Author: Thomas Goirand <zigo@debian.org>
Partial-Bug: #1667329
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/669395/18 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_ipam_backend_mixin.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/objects/subnet.py']",3,d069054b32adbf0f20da602ae5678e41448dec26,bug/1667329," @classmethod def get_subnet_segment_ids(cls, context, network_id, filtered_service_type=None): query = context.session.query(cls.db_model.segment_id) query = query.filter(cls.db_model.network_id == network_id) if filtered_service_type: service_type_model = SubnetServiceType.db_model filter_subquery = context.session.query( service_type_model.subnet_id) filter_subquery = filter_subquery.filter( cls.db_model.network_id == network_id) filter_subquery = filter_subquery.filter( service_type_model.subnet_id == cls.db_model.id) filter_subquery = filter_subquery.filter( service_type_model.service_type == filtered_service_type) query = query.filter(cls.db_model.id.notin_(filter_subquery)) return [segment_id for (segment_id,) in query.all()]",,25,3
openstack%2Ftripleo-ansible~stable%2Fussuri~I29f94783637264b6938c1f03925ed700bd8acafc,openstack/tripleo-ansible,stable/ussuri,I29f94783637264b6938c1f03925ed700bd8acafc,Update for a podman_container from collection,MERGED,2021-01-05 22:10:53.000000000,2021-01-06 17:28:41.000000000,2021-01-06 17:28:41.000000000,"[{'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-05 22:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ab9f2f01bc03f35278785fb36917102812c7377d', 'message': 'Update for a podman_container from collection\n\nAnd removing docker.io from podman container tests.\n\nChange-Id: I29f94783637264b6938c1f03925ed700bd8acafc\n(cherry picked from commit b6ca89d194aeb428e58f680a43c4bef700b96831)\n'}, {'number': 2, 'created': '2021-01-05 22:33:57.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/podman_container.py', 'tripleo_ansible/ansible_plugins/module_utils/podman/common.py', 'tripleo_ansible/ansible_plugins/module_utils/podman/podman_container_lib.py', 'tripleo_ansible/ansible_plugins/tests/molecule/podman_container/converge.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/83b78caaba28037148d33c35ed92ded2594536bd', 'message': 'Update for a podman_container from collection\n\nAnd removing docker.io from podman container tests.\n\nChange-Id: I29f94783637264b6938c1f03925ed700bd8acafc\n(cherry picked from commit b6ca89d194aeb428e58f680a43c4bef700b96831)\n'}]",0,769363,83b78caaba28037148d33c35ed92ded2594536bd,10,6,2,10969,,,0,"Update for a podman_container from collection

And removing docker.io from podman container tests.

Change-Id: I29f94783637264b6938c1f03925ed700bd8acafc
(cherry picked from commit b6ca89d194aeb428e58f680a43c4bef700b96831)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/63/769363/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/podman_container.py', 'tripleo_ansible/ansible_plugins/module_utils/podman/common.py', 'tripleo_ansible/ansible_plugins/module_utils/podman/podman_container_lib.py', 'tripleo_ansible/ansible_plugins/tests/molecule/podman_container/converge.yml']",4,ab9f2f01bc03f35278785fb36917102812c7377d,next_p-stable/ussuri," - ""ubi-minimal"" name: registry.access.redhat.com/ubi8/ubi-minimal image: registry.access.redhat.com/ubi8/ubi-minimal image: registry.access.redhat.com/ubi8/ubi-minimal - ""'pulled image registry.access.redhat.com/ubi8/ubi-minimal' in image.actions"" - ""'pulled image registry.access.redhat.com/ubi8/ubi-minimal' not in image2.actions"" image: registry.access.redhat.com/ubi8/ubi-minimal image: registry.access.redhat.com/ubi8/ubi-minimal image: registry.access.redhat.com/ubi8/ubi-minimal - ""'pulled image registry.access.redhat.com/ubi8/ubi-minimal' not in started.actions"" image: registry.access.redhat.com/ubi8/ubi-minimal - test.container['Config']['Labels'] | length >= 2 image: registry.access.redhat.com/ubi8/ubi-minimal image: ubi-minimal:latest image: ubi-minimal image: ubi-minimal image: registry.access.redhat.com/ubi8/ubi-minimal image: ubi-minimal:latest image: ubi-minimal<<<<<<< HEAD (3559d1 Merge ""Run LVM filter tasks when enabled, regardless of allo) ======= - ""ubi-minimal"" - ""web"" - ""test"" - ""testidem"" >>>>>>> CHANGE (b6ca89 Update for a podman_container from collection)"," - ""alpine:3.7"" name: alpine:3.7 image: alpine:3.7 image: alpine:3.7 - ""'pulled image alpine:3.7' in image.actions"" - ""'pulled image alpine:3.7' not in image2.actions"" image: alpine image: alpine:3.7 image: alpine:3.7 - ""'pulled image alpine:3.7' not in started.actions"" image: docker.io/alpine:3.7 - test.container['Config']['Labels'] | length == 2 image: docker.io/alpine image: alpine:latest image: alpine image: alpine image: docker.io/alpine image: alpine:latest image: alpine - ""alpine:3.7""",1552,1319
openstack%2Fbifrost~bugfix%2F10.0~Ie5e6a655b103dd7edb447f56bff8da870193deba,openstack/bifrost,bugfix/10.0,Ie5e6a655b103dd7edb447f56bff8da870193deba,Remove lower-constraints job,MERGED,2021-01-06 10:50:40.000000000,2021-01-06 17:18:55.000000000,2021-01-06 17:13:46.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 10:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/779d66976b6e43cbc4acb1439f9f74b9312b5377', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nChange-Id: Ie5e6a655b103dd7edb447f56bff8da870193deba\n(cherry picked from commit 986427ce8eaa96e820f3cb8cda4cc1954c449994)\n'}, {'number': 2, 'created': '2021-01-06 10:51:06.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/48165b2d7f0dfe0f908a97ada7ab1d4994ef2e95', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nChange-Id: Ie5e6a655b103dd7edb447f56bff8da870193deba\n(cherry picked from commit 986427ce8eaa96e820f3cb8cda4cc1954c449994)\n'}]",0,769502,48165b2d7f0dfe0f908a97ada7ab1d4994ef2e95,10,2,2,23851,,,0,"Remove lower-constraints job

As discussed during the upstream ironic community meeting on
Monday Dec 14 2020, the lower-constraints job is being removed.

Change-Id: Ie5e6a655b103dd7edb447f56bff8da870193deba
(cherry picked from commit 986427ce8eaa96e820f3cb8cda4cc1954c449994)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/02/769502/1 && git format-patch -1 --stdout FETCH_HEAD,"['lower-constraints.txt', 'zuul.d/project.yaml']",2,779d66976b6e43cbc4acb1439f9f74b9312b5377,remove-l-c-job,, - openstack-lower-constraints-jobs,0,64
openstack%2Fansible-role-python_venv_build~master~Iec2fd7839605075af1c3b3ab952513b6004c19a6,openstack/ansible-role-python_venv_build,master,Iec2fd7839605075af1c3b3ab952513b6004c19a6,Fix tests for Centos8 EPEL repo paths,MERGED,2020-12-31 18:57:25.000000000,2021-01-06 17:12:06.000000000,2021-01-06 17:06:16.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-31 18:57:25.000000000', 'files': ['tests/test.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/036795aa9f72fac4bc31c1f84e2ea17812aeea78', 'message': 'Fix tests for Centos8 EPEL repo paths\n\nChange-Id: Iec2fd7839605075af1c3b3ab952513b6004c19a6\n'}]",0,768808,036795aa9f72fac4bc31c1f84e2ea17812aeea78,8,3,1,25023,,,0,"Fix tests for Centos8 EPEL repo paths

Change-Id: Iec2fd7839605075af1c3b3ab952513b6004c19a6
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/08/768808/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test.yml'],1,036795aa9f72fac4bc31c1f84e2ea17812aeea78,," baseurl: ""{{ (centos_epel_mirror | default ('http://download.fedoraproject.org/pub/epel')) ~ '/' ~ ansible_distribution_major_version ~ ((ansible_distribution_major_version is version('8', '<')) | ternary('/', '/Everything/')) ~ ansible_architecture }}"" description: 'Extra Packages for Enterprise Linux - $basearch'"," baseurl: ""{{ (centos_epel_mirror | default ('http://download.fedoraproject.org/pub/epel')) ~ '/' ~ ansible_distribution_major_version ~ '/' ~ ansible_architecture }}"" description: 'Extra Packages for Enterprise Linux 7 - $basearch'",2,2
openstack%2Fironic-inspector~bugfix%2F10.5~I943b63b9c6a980011b35bb028c64bee18d772750,openstack/ironic-inspector,bugfix/10.5,I943b63b9c6a980011b35bb028c64bee18d772750,Remove lower-constraints job,MERGED,2021-01-06 10:57:51.000000000,2021-01-06 17:12:00.000000000,2021-01-06 17:02:39.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 10:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/df99ae1478cbdb5e895a4355645a79a4290ec0ce', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nChange-Id: I943b63b9c6a980011b35bb028c64bee18d772750\n(cherry picked from commit c6fdf2511697305e2f00ec444081ab3353074b22)\n'}, {'number': 2, 'created': '2021-01-06 10:58:21.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/2fff24dabf6cf95d05153dc0478f0982ec931345', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nChange-Id: I943b63b9c6a980011b35bb028c64bee18d772750\n(cherry picked from commit c6fdf2511697305e2f00ec444081ab3353074b22)\n'}]",0,769505,2fff24dabf6cf95d05153dc0478f0982ec931345,10,2,2,23851,,,0,"Remove lower-constraints job

As discussed during the upstream ironic community meeting on
Monday Dec 14 2020, the lower-constraints job is being removed.

Change-Id: I943b63b9c6a980011b35bb028c64bee18d772750
(cherry picked from commit c6fdf2511697305e2f00ec444081ab3353074b22)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/05/769505/2 && git format-patch -1 --stdout FETCH_HEAD,"['lower-constraints.txt', 'zuul.d/project.yaml']",2,df99ae1478cbdb5e895a4355645a79a4290ec0ce,remove-l-c-job,, - openstack-lower-constraints-jobs,0,144
openstack%2Fironic~bugfix%2F15.2~I116d99014a7bf77ca77b796ea3b759800dd808ce,openstack/ironic,bugfix/15.2,I116d99014a7bf77ca77b796ea3b759800dd808ce,Remove lower-constraints job,MERGED,2021-01-06 10:54:27.000000000,2021-01-06 17:11:59.000000000,2021-01-06 17:02:34.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 10:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/478049b6b001a78a7bf0298a4b089cf496dcdcd4', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nChange-Id: I116d99014a7bf77ca77b796ea3b759800dd808ce\n(cherry picked from commit 840488e5951a360bb0f61ce36d33b5253ed19655)\n'}, {'number': 2, 'created': '2021-01-06 10:55:00.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4bdf00daacf1ff8d9074a09c1898b966eb8b8377', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nChange-Id: I116d99014a7bf77ca77b796ea3b759800dd808ce\n(cherry picked from commit 840488e5951a360bb0f61ce36d33b5253ed19655)\n'}]",0,769503,4bdf00daacf1ff8d9074a09c1898b966eb8b8377,12,2,2,23851,,,0,"Remove lower-constraints job

As discussed during the upstream ironic community meeting on
Monday Dec 14 2020, the lower-constraints job is being removed.

Change-Id: I116d99014a7bf77ca77b796ea3b759800dd808ce
(cherry picked from commit 840488e5951a360bb0f61ce36d33b5253ed19655)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/03/769503/2 && git format-patch -1 --stdout FETCH_HEAD,"['lower-constraints.txt', 'zuul.d/project.yaml']",2,478049b6b001a78a7bf0298a4b089cf496dcdcd4,remove-l-c-job,<<<<<<< HEAD (01de66 CI: Patch to fix CI jobs in bugfix/stable branches)======= - openstack-python3-wallaby-jobs >>>>>>> CHANGE (840488 Remove lower-constraints job),,7,0
openstack%2Fproject-config~master~I894df2e26c6927eac25dbfe596a93f4209ff92ee,openstack/project-config,master,I894df2e26c6927eac25dbfe596a93f4209ff92ee,Enable tripleo core members to change WIP flag,MERGED,2020-12-07 15:41:27.000000000,2021-01-06 17:06:42.000000000,2021-01-06 16:55:21.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 8833}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-12-07 15:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ed51faf7280c29e03d6b4f59cec1f5854916deca', 'message': 'Enable tripleo core members to change WIP flag\n\nThis change enables people that already had permission to abandon\nother changes to also toggle the WIP flag on them.\n\nChange-Id: I894df2e26c6927eac25dbfe596a93f4209ff92ee\n'}, {'number': 2, 'created': '2020-12-07 15:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4dca03f7ebcb7838259f5fd3f6d346710b93c030', 'message': 'Enable tripleo core members to change WIP flag\n\nThis change enables people that already had permission to abandon\nother changes to also toggle the WIP flag on them.\n\nChange-Id: I894df2e26c6927eac25dbfe596a93f4209ff92ee\nReference: https://gerrit-review.googlesource.com/c/gerrit/+/212571/3/java/com/google/gerrit/common/data/Permission.java#49\n'}, {'number': 3, 'created': '2020-12-07 15:59:46.000000000', 'files': ['gerrit/acls/openstack/tripleo-ha-utils.config', 'gerrit/acls/openstack/tripleo-ci-shared-core.config', 'gerrit/acls/openstack/tripleo-ansible.config', 'tools/check_valid_gerrit_config.sh', 'tools/check_projects_yaml_alphabetized.sh', 'tools/normalize_acl.py', 'gerrit/acls/openstack/tripleo-quickstart.config', 'gerrit/acls/openstack/tripleo-upgrade.config', 'gerrit/acls/openstack/tripleo-specs.config', 'gerrit/acls/openstack/tripleo-ci.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/97cacc26cc1f380456c6705c08d41c88502d3ddd', 'message': 'Enable tripleo core members to change WIP flag\n\nThis change enables people that already had permission to abandon\nother changes to also toggle the WIP flag on them.\n\nChange-Id: I894df2e26c6927eac25dbfe596a93f4209ff92ee\nReference: https://gerrit-review.googlesource.com/c/gerrit/+/212571/3/java/com/google/gerrit/common/data/Permission.java#49\n'}]",0,765821,97cacc26cc1f380456c6705c08d41c88502d3ddd,21,7,3,24162,,,0,"Enable tripleo core members to change WIP flag

This change enables people that already had permission to abandon
other changes to also toggle the WIP flag on them.

Change-Id: I894df2e26c6927eac25dbfe596a93f4209ff92ee
Reference: https://gerrit-review.googlesource.com/c/gerrit/+/212571/3/java/com/google/gerrit/common/data/Permission.java#49
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/765821/3 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/tripleo-ci-shared-core.config', 'gerrit/acls/openstack/tripleo-ha-utils.config', 'gerrit/acls/openstack/tripleo-ansible.config', 'gerrit/acls/openstack/tripleo-quickstart.config', 'gerrit/acls/openstack/tripleo-upgrade.config', 'gerrit/acls/openstack/tripleo-specs.config', 'gerrit/acls/openstack/tripleo-ci.config']",7,ed51faf7280c29e03d6b4f59cec1f5854916deca,,toggleWipState = group tripleo-ci-core,,7,0
openstack%2Ffreezer-api~master~I233f7fe332a6f6c14ffb98081e3a9efc6a516722,openstack/freezer-api,master,I233f7fe332a6f6c14ffb98081e3a9efc6a516722,Add doc/requirements,NEW,2021-01-06 16:22:58.000000000,2021-01-06 17:06:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-06 16:22:58.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/fa23daca422b5d20ae1bad15283051754bff5f53', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I233f7fe332a6f6c14ffb98081e3a9efc6a516722\n""}]",0,769564,fa23daca422b5d20ae1bad15283051754bff5f53,2,1,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.
The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I233f7fe332a6f6c14ffb98081e3a9efc6a516722
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/64/769564/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,fa23daca422b5d20ae1bad15283051754bff5f53,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps}deps = {[testenv:docs]deps},,8,4
openstack%2Ffreezer-dr~master~I010d3ce9ce69a62222e0a4d96339aed055bcef1b,openstack/freezer-dr,master,I010d3ce9ce69a62222e0a4d96339aed055bcef1b,Add doc/requirements,NEW,2021-01-06 16:53:57.000000000,2021-01-06 17:05:55.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-06 16:53:57.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/cf253889f550ee88702b33a3be407a9e26c2f475', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I010d3ce9ce69a62222e0a4d96339aed055bcef1b\n""}]",0,769567,cf253889f550ee88702b33a3be407a9e26c2f475,2,1,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I010d3ce9ce69a62222e0a4d96339aed055bcef1b
",git fetch https://review.opendev.org/openstack/freezer-dr refs/changes/67/769567/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,cf253889f550ee88702b33a3be407a9e26c2f475,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,5,3
openstack%2Frpm-packaging~master~I8b052656a681672a3a56fe9aa0eacc9a2f872f5b,openstack/rpm-packaging,master,I8b052656a681672a3a56fe9aa0eacc9a2f872f5b,Update keystonemiddleware to 9.2.0,MERGED,2020-12-05 15:22:45.000000000,2021-01-06 16:54:12.000000000,2021-01-06 16:54:12.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-12-05 15:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f34059612c4779d67d297e5529f145ec6a3a9bce', 'message': 'Update keystonemiddleware to 9.2.0\n\nChange-Id: I8b052656a681672a3a56fe9aa0eacc9a2f872f5b\n'}, {'number': 2, 'created': '2020-12-07 13:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2fb8c7467cf711f111db13a70f95f95f634267b4', 'message': 'Update keystonemiddleware to 9.2.0\n\nChange-Id: I8b052656a681672a3a56fe9aa0eacc9a2f872f5b\n'}, {'number': 3, 'created': '2020-12-08 19:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/192c7bb8e5cdc8c7c3d90148b1631d13bb3f3f9f', 'message': 'Update keystonemiddleware to 9.2.0\n\nChange-Id: I8b052656a681672a3a56fe9aa0eacc9a2f872f5b\n'}, {'number': 4, 'created': '2020-12-21 18:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c0e0c854112ecd9774aadc19b8a935ffdcc5b6fc', 'message': 'Update keystonemiddleware to 9.2.0\n\nChange-Id: I8b052656a681672a3a56fe9aa0eacc9a2f872f5b\n'}, {'number': 5, 'created': '2021-01-04 21:15:28.000000000', 'files': ['openstack/keystonemiddleware/keystonemiddleware.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3e10f56490b0500e9f57c51f4f9761965e114b54', 'message': 'Update keystonemiddleware to 9.2.0\n\nChange-Id: I8b052656a681672a3a56fe9aa0eacc9a2f872f5b\n'}]",0,765665,3e10f56490b0500e9f57c51f4f9761965e114b54,39,7,5,26584,,,0,"Update keystonemiddleware to 9.2.0

Change-Id: I8b052656a681672a3a56fe9aa0eacc9a2f872f5b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/65/765665/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/keystonemiddleware/keystonemiddleware.spec.j2'],1,f34059612c4779d67d297e5529f145ec6a3a9bce,keystonemiddleware,{% set upstream_version = upstream_version('9.2.0') %},{% set upstream_version = upstream_version('9.1.0') %},1,1
openstack%2Frpm-packaging~master~I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b,openstack/rpm-packaging,master,I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b,Update python-keystoneclient to 4.2.0,MERGED,2020-12-05 14:46:33.000000000,2021-01-06 16:53:13.000000000,2021-01-06 16:53:13.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-05 14:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/08c9d02f75256e01a13958c12bc7171ad600a421', 'message': 'Update python-keystoneclient to 4.2.0\n\nChange-Id: I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b\n'}, {'number': 2, 'created': '2020-12-07 13:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a29fa9bbf58eaf4c9cd1748a71d2457c03899352', 'message': 'Update python-keystoneclient to 4.2.0\n\nChange-Id: I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b\n'}, {'number': 3, 'created': '2020-12-08 19:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8889c09093b2aa7297f04a46a79d265e9968d9e0', 'message': 'Update python-keystoneclient to 4.2.0\n\nChange-Id: I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b\n'}, {'number': 4, 'created': '2020-12-19 10:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a3f60e4e3addd731bbc2681cb35b0d2dd9908a93', 'message': 'Update python-keystoneclient to 4.2.0\n\nChange-Id: I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b\n'}, {'number': 5, 'created': '2021-01-04 19:57:11.000000000', 'files': ['openstack/python-keystoneclient/python-keystoneclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/af674b51fefcf6bdf7720ddb6826e6d1bf82d743', 'message': 'Update python-keystoneclient to 4.2.0\n\nChange-Id: I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b\n'}]",0,765654,af674b51fefcf6bdf7720ddb6826e6d1bf82d743,37,5,5,26118,,,0,"Update python-keystoneclient to 4.2.0

Change-Id: I8c90291cdd6ef7a2cf73665728b7f46268f8ea4b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/54/765654/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-keystoneclient/python-keystoneclient.spec.j2'],1,08c9d02f75256e01a13958c12bc7171ad600a421,pykesclient,{% set upstream_version = upstream_version('4.2.0') %},{% set upstream_version = upstream_version('4.1.1') %},1,1
openstack%2Fironic-python-agent-builder~master~Ibeb6253046787a7a0768879067facaaeb0137cdb,openstack/ironic-python-agent-builder,master,Ibeb6253046787a7a0768879067facaaeb0137cdb,Add doc/requirements,MERGED,2021-01-04 17:43:56.000000000,2021-01-06 16:52:04.000000000,2021-01-06 16:50:37.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-01-04 17:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/ceb76f5c59e4f960de2d5c9212f0aff0663ce96b', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ibeb6253046787a7a0768879067facaaeb0137cdb\n'}, {'number': 2, 'created': '2021-01-06 14:46:16.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/dc090b273a74092b0cd20d24a90c8d04ade4294a', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ibeb6253046787a7a0768879067facaaeb0137cdb\n'}]",2,769196,dc090b273a74092b0cd20d24a90c8d04ade4294a,13,3,2,15519,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: Ibeb6253046787a7a0768879067facaaeb0137cdb
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/96/769196/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,ceb76f5c59e4f960de2d5c9212f0aff0663ce96b,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps}deps = {[testenv:docs]deps},,7,5
openstack%2Fos-brick~master~I8e433ad5d11873b39f578c98278e5d3b34cf7012,openstack/os-brick,master,I8e433ad5d11873b39f578c98278e5d3b34cf7012,opencas: Use BrickException instead of Exception,MERGED,2020-11-23 13:56:37.000000000,2021-01-06 16:49:46.000000000,2021-01-06 16:48:35.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 22348}, {'_account_id': 23601}]","[{'number': 1, 'created': '2020-11-23 13:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/fdbf595d9d9a0bbef155ede267aba549434399a5', 'message': 'opencas: Use BrickException instead of Exception\n\nRaise BrickException instead of Exception for\nerrors here.  This makes it easier for callers\nto handle failures correctly.\n\nChange-Id: I8e433ad5d11873b39f578c98278e5d3b34cf7012\n'}, {'number': 2, 'created': '2020-12-17 15:21:37.000000000', 'files': ['os_brick/caches/opencas.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/8577096e19af4ad2efd55a58c8861941960c3ee5', 'message': 'opencas: Use BrickException instead of Exception\n\nRaise BrickException instead of Exception for\nerrors here.  This makes it easier for callers\nto handle failures correctly.\n\nChange-Id: I8e433ad5d11873b39f578c98278e5d3b34cf7012\n'}]",0,763784,8577096e19af4ad2efd55a58c8861941960c3ee5,49,4,2,4523,,,0,"opencas: Use BrickException instead of Exception

Raise BrickException instead of Exception for
errors here.  This makes it easier for callers
to handle failures correctly.

Change-Id: I8e433ad5d11873b39f578c98278e5d3b34cf7012
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/84/763784/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/caches/opencas.py'],1,fdbf595d9d9a0bbef155ede267aba549434399a5,, raise exception.BrickException('Cannot find emulated device.') raise exception.BrickException('Cannot find core device.'), raise Exception('Cannot find emulated device.') raise Exception('Cannot find core device.'),2,2
openstack%2Frpm-packaging~master~I1a5f078a8830c38435796f282a9196a2baa8908c,openstack/rpm-packaging,master,I1a5f078a8830c38435796f282a9196a2baa8908c,Update os-apply-config to 12.0.0,MERGED,2021-01-05 08:04:55.000000000,2021-01-06 16:46:03.000000000,2021-01-06 16:46:03.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}, {'_account_id': 32324}]","[{'number': 1, 'created': '2021-01-05 08:04:55.000000000', 'files': ['openstack/os-apply-config/os-apply-config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/48377cb73f5ebe15902b06cb9b65636ae45e58d5', 'message': 'Update os-apply-config to 12.0.0\n\nChange-Id: I1a5f078a8830c38435796f282a9196a2baa8908c\n'}]",0,769256,48377cb73f5ebe15902b06cb9b65636ae45e58d5,11,6,1,27380,,,0,"Update os-apply-config to 12.0.0

Change-Id: I1a5f078a8830c38435796f282a9196a2baa8908c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/56/769256/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-apply-config/os-apply-config.spec.j2'],1,48377cb73f5ebe15902b06cb9b65636ae45e58d5,update_os-apply-config,{% set upstream_version = upstream_version('12.0.0') %},{% set upstream_version = upstream_version('11.3.0') %},1,1
openstack%2Ftripleo-ci~master~I728b56e98b376051dc350b0779e656cd12a80c77,openstack/tripleo-ci,master,I728b56e98b376051dc350b0779e656cd12a80c77,Adds new per-branch zuul-templates for upgrades jobs,MERGED,2020-11-03 16:05:57.000000000,2021-01-06 16:38:30.000000000,2021-01-06 16:38:30.000000000,"[{'_account_id': 6816}, {'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 11090}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-11-03 16:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5d3fefa9620d4078d707cf75d9be2814cdd1d7a9', 'message': ""WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to prevent us running redundant content providers. This\ndoes mean more management from us - because we'll have to include\nthe templates in the right branches of the tripleo repos.\n\nJust an idea not sure if it works yet WIP\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n""}, {'number': 2, 'created': '2020-11-03 16:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ff526ccc678776366d6f02cedb445323860ad4e0', 'message': ""WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to prevent us running redundant content providers. This\ndoes mean more management from us - because we'll have to include\nthe templates in the right branches of the tripleo repos.\n\nJust an idea not sure if it works yet WIP\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n""}, {'number': 3, 'created': '2020-11-03 16:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e033809578e9adf27b301aa817c1a0daafb8ccba', 'message': ""WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to prevent us running redundant content providers. This\ndoes mean more management from us - because we'll have to include\nthe templates in the right branches of the tripleo repos.\n\nJust an idea not sure if it works yet WIP\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n""}, {'number': 4, 'created': '2020-11-04 10:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/91181d58cab6b86092a13aa389f55775119588f1', 'message': ""WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to prevent us running redundant content providers. This\ndoes mean more management from us - because we'll have to include\nthe templates in the right branches of the tripleo repos.\n\nJust an idea not sure if it works yet WIP\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n""}, {'number': 5, 'created': '2020-11-04 10:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d2fa775ddb60642e489ce272bd05979d30e9731a', 'message': ""WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to prevent us running redundant content providers. This\ndoes mean more management from us - because we'll have to include\nthe templates in the right branches of the tripleo repos.\n\nJust an idea not sure if it works yet WIP\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n""}, {'number': 6, 'created': '2020-11-04 13:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b0040a0a3ba80a5d2c38a39fe7aa68d773a28b7c', 'message': ""WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to prevent us running redundant content providers. This\ndoes mean more management from us - because we'll have to include\nthe templates in the right branches of the tripleo repos.\n\nJust an idea not sure if it works yet WIP\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n""}, {'number': 7, 'created': '2020-11-24 11:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6d75048cd93e0cb0f8f1550d8b6fd7c77af660ac', 'message': 'WIP - moving multi parent upgrade jobs to branch templates\n\nTrying to reduce redundant content providers. The cost is we\nhave to wire up the new upgrade templates per branch across\nthe tripleo repos.\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n'}, {'number': 8, 'created': '2020-12-22 16:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a48b4393c325c6c04a96e6876ca27ca7c432d8d0', 'message': 'WIP Moving multi parent upgrade jobs to branch templates\n\nTrying to reduce redundant content providers. The cost is we\nhave to wire up the new upgrade templates per branch across\nthe tripleo repos.\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n'}, {'number': 9, 'created': '2021-01-04 12:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8a335739d8862dc387d8c24b6a9cc3515a9430b0', 'message': 'Adds new per-branch zuul-templates for upgrades jobs\n\nThis adds a new upgrades-jobs-templates.yaml with all the upgrades\njob layouts. There are four templates introduced one for each\nbranch.\n\nOnce we wire up this new template across tripleo we will remove the\nexcess content providers and all the upgrades jobs from the existing\nlayouts (e.g. tripleo-standalone-scenarios-pipeline).\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n'}, {'number': 10, 'created': '2021-01-05 15:49:09.000000000', 'files': ['zuul.d/upgrades-jobs-templates.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f3c0e8000a8e1dfb20e8d5b04a9a6c689b1d89f9', 'message': 'Adds new per-branch zuul-templates for upgrades jobs\n\nThis adds a new upgrades-jobs-templates.yaml with all the upgrades\njob layouts. There are four templates introduced one for each\nbranch.\n\nOnce we wire up this new template across tripleo we will remove the\nexcess content providers and all the upgrades jobs from the existing\nlayouts (e.g. tripleo-standalone-scenarios-pipeline).\n\nChange-Id: I728b56e98b376051dc350b0779e656cd12a80c77\n'}]",14,761188,f3c0e8000a8e1dfb20e8d5b04a9a6c689b1d89f9,59,13,10,8449,,,0,"Adds new per-branch zuul-templates for upgrades jobs

This adds a new upgrades-jobs-templates.yaml with all the upgrades
job layouts. There are four templates introduced one for each
branch.

Once we wire up this new template across tripleo we will remove the
excess content providers and all the upgrades jobs from the existing
layouts (e.g. tripleo-standalone-scenarios-pipeline).

Change-Id: I728b56e98b376051dc350b0779e656cd12a80c77
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/88/761188/5 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,5d3fefa9620d4078d707cf75d9be2814cdd1d7a9,reduce-content-providers, name: tripleo-standalone-upgrades-master-pipeline check: jobs: - tripleo-ci-centos-8-content-provider - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-standalone-upgrade: vars: &consumer_vars consumer_job: true build_container_images: false remove_tags: - build dependencies: - tripleo-ci-centos-8-content-provider - tripleo-ci-centos-8-content-provider-victoria gate: queue: tripleo - project-template: name: tripleo-standalone-upgrades-victoria-pipeline check: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-standalone-upgrade-victoria: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri gate: queue: tripleo jobs: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-standalone-upgrade-victoria: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri - project-template: name: tripleo-standalone-upgrades-ussuri-pipeline check: - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-content-provider-train - tripleo-ci-centos-8-standalone-upgrade-ussuri: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-content-provider-train gate: queue: tripleo jobs: - tripleo-ci-centos-8-standalone-upgrade-ussuri: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-content-provider-train - project-template: vars: *consumer_vars, vars: &consumer_vars consumer_job: true build_container_images: false remove_tags: - build - tripleo-ci-centos-8-standalone-upgrade: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-standalone-upgrade-victoria: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-standalone-upgrade-ussuri: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-content-provider-train - tripleo-ci-centos-8-standalone-upgrade-victoria: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-standalone-upgrade-ussuri: vars: *consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-ussuri - tripleo-ci-centos-8-content-provider-train,59,30
openstack%2Fopenstack-helm-images~master~I36f54077be65741c0677d77cbbf4795db919703f,openstack/openstack-helm-images,master,I36f54077be65741c0677d77cbbf4795db919703f,[CEPH] Build Octopus based ceph images,MERGED,2021-01-04 17:47:08.000000000,2021-01-06 16:22:15.000000000,2021-01-06 16:20:09.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 17119}, {'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 18511}, {'_account_id': 21040}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 24780}, {'_account_id': 29974}, {'_account_id': 30495}, {'_account_id': 30746}, {'_account_id': 31728}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-01-04 17:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8e189f433119e691b1cf5a7af8904b5d91ff350e', 'message': '[CEPH] Build Octopus based images .\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 2, 'created': '2021-01-04 17:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/c1ac1da2b76a4ec21083b5bd5f0ca8945160055d', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 3, 'created': '2021-01-04 18:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/adfdff40c468a416ae2ffe4b11620f9294c03cc4', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 4, 'created': '2021-01-04 18:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/5c21eb647a81f641958c3c1e207130a408edbf45', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 5, 'created': '2021-01-04 19:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/7eb424fe91c1270cb3a17e45b0ff2b87ff285b39', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 6, 'created': '2021-01-04 20:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/936db36f55168c30ed056720f76f4f83a03cc049', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 7, 'created': '2021-01-04 21:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d84eca38963f6cc84a4382cf09b7a5706ce8dc64', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 8, 'created': '2021-01-05 17:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/98d5ff4a07e9172fdcbf9bffed16e7fd15e43a52', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 9, 'created': '2021-01-05 17:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/5cfd6911f2ceb9bda714d1de00742598986915a3', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 10, 'created': '2021-01-05 18:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/57be9cc3cb5ce62b69a6751f88a777107fb6b9b5', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 11, 'created': '2021-01-05 18:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8026f69b902f32052dfedb99ddff6e9b12e3f3d8', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 12, 'created': '2021-01-05 19:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/fa6d2ebe89bd729c350483280de413af4cfb04cc', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 13, 'created': '2021-01-05 21:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/6afdd4986d3e75c6858c7ea78e8d9c612b52d384', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 14, 'created': '2021-01-05 21:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/10883501a6419a7c014fd1943b29ef1a7946ecc0', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}, {'number': 15, 'created': '2021-01-06 15:06:38.000000000', 'files': ['ceph-config-helper/Dockerfile.ubuntu_bionic', 'ceph-rbd-provisioner/Dockerfile.ubuntu_bionic', 'ceph-cephfs-provisioner/Dockerfile.ubuntu_bionic', 'ceph-daemon/Dockerfile.ubuntu_bionic'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/b379c3a27252a1d087a452213adfa11849a14586', 'message': '[CEPH] Build Octopus based ceph images\n\nThis is to uplift ceph release from Nautilus to Octopus.\n\nChange-Id: I36f54077be65741c0677d77cbbf4795db919703f\n'}]",6,769198,b379c3a27252a1d087a452213adfa11849a14586,59,16,15,28372,,,0,"[CEPH] Build Octopus based ceph images

This is to uplift ceph release from Nautilus to Octopus.

Change-Id: I36f54077be65741c0677d77cbbf4795db919703f
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/98/769198/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-config-helper/Dockerfile.ubuntu_bionic', 'ceph-rbd-provisioner/Dockerfile.ubuntu_bionic', 'ceph-cephfs-provisioner/Dockerfile.ubuntu_bionic', 'ceph-daemon/Dockerfile.ubuntu_bionic']",4,8e189f433119e691b1cf5a7af8904b5d91ff350e,,# Octopus 15.2.7 ARG CEPH_RELEASE=octopus ARG CEPH_RELEASE_TAG=15.2.7-1bionicARG CEPH_REPO=https://mirror.mirantis.com/att/ceph-octopus/ ARG CEPH_KEY= https://mirror.mirantis.com/att/ceph-octopus/release.asc,# Nautilus 14.2.9 ARG CEPH_RELEASE=nautilus ARG CEPH_RELEASE_TAG=14.2.9-1.0~bionicARG CEPH_REPO=https://mirror.mirantis.com/testing/ceph-nautilus/bionic/ ARG CEPH_KEY=https://mirror.mirantis.com/testing/ceph-nautilus/bionic/archive-ceph-nautilus.key,22,20
openstack%2Foctavia~master~If75ab984313660e435d9820d9dc777e5bdd78546,openstack/octavia,master,If75ab984313660e435d9820d9dc777e5bdd78546,Use keystone Session for neutron user client,NEW,2020-12-18 01:39:02.000000000,2021-01-06 16:11:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-18 01:39:02.000000000', 'files': ['octavia/common/keystone.py', 'octavia/common/clients.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/57743f8a714b1d55bdaa90026c8dbc5d5076674f', 'message': 'Use keystone Session for neutron user client\n\nNot using one has the side effect of skipping usage of various config\noptions for connections, including things like client certificate auth.\n\nChange-Id: If75ab984313660e435d9820d9dc777e5bdd78546\n'}]",3,767648,57743f8a714b1d55bdaa90026c8dbc5d5076674f,4,1,1,10273,,,0,"Use keystone Session for neutron user client

Not using one has the side effect of skipping usage of various config
options for connections, including things like client certificate auth.

Change-Id: If75ab984313660e435d9820d9dc777e5bdd78546
",git fetch https://review.opendev.org/openstack/octavia refs/changes/48/767648/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/keystone.py', 'octavia/common/clients.py']",2,57743f8a714b1d55bdaa90026c8dbc5d5076674f,,"from octavia.common import constants ksession = keystone.KeystoneSession() kwargs = { 'region_name': CONF.neutron.region_name, 'session': ksession.get_session(token=context.auth_token), 'endpoint_type': CONF.neutron.endpoint_type, } if CONF.neutron.endpoint: kwargs['endpoint_override'] = CONF.neutron.endpoint if CONF.neutron.ca_certificates_file: kwargs['ca_cert'] = CONF.neutron.ca_certificates_file try: return neutron_client.Client(NEUTRON_VERSION, **kwargs) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(""Error creating user Neutron client."")"," neutron_endpoint = CONF.neutron.endpoint if not neutron_endpoint: session = keystone.KeystoneSession().get_session() endpoint_data = session.get_endpoint_data( service_type='network', interface=CONF.neutron.endpoint_type, region_name=CONF.neutron.region_name) neutron_endpoint = endpoint_data.catalog_url kwargs = { 'token': context.auth_token, 'endpoint_url': neutron_endpoint, 'ca_cert': CONF.neutron.ca_certificates_file } return neutron_client.Client(NEUTRON_VERSION, **kwargs)",24,14
openstack%2Fopenstack-tempest-skiplist~master~Ib738c65544ea997a3f0b3881609461b0a8725050,openstack/openstack-tempest-skiplist,master,Ib738c65544ea997a3f0b3881609461b0a8725050,un skip neutron tests for queens,MERGED,2020-12-09 16:01:09.000000000,2021-01-06 15:57:49.000000000,2021-01-06 15:56:29.000000000,"[{'_account_id': 9592}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-09 16:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/d0300d6427739bbbe1f043eac11e78de440b6cc6', 'message': '[DNM] un skip neutron tests for queens\n\nChange-Id: Ib738c65544ea997a3f0b3881609461b0a8725050\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 2, 'created': '2021-01-05 15:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/c9369188f73b7841c47c6d654087125f5c67b106', 'message': ""un skip neutron tests for queens\n\nBug #1900357 is fixed now. Proper L3 agent extensions\nare loaded in the neutron-l3-agent's config file and\nthat test should works fine.\n\nRelated-Bug: #1900357\n\nChange-Id: Ib738c65544ea997a3f0b3881609461b0a8725050\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}, {'number': 3, 'created': '2021-01-06 08:29:40.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/7c20c337accb5728752188e14615646a3ed7cacf', 'message': ""un skip neutron tests for queens\n\nBug #1900357 is fixed now. Proper L3 agent extensions\nare loaded in the neutron-l3-agent's config file and\nthat test should works fine.\n\nCloses-Bug: #1900357\n\nChange-Id: Ib738c65544ea997a3f0b3881609461b0a8725050\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}]",0,766252,7c20c337accb5728752188e14615646a3ed7cacf,11,2,3,12393,,,0,"un skip neutron tests for queens

Bug #1900357 is fixed now. Proper L3 agent extensions
are loaded in the neutron-l3-agent's config file and
that test should works fine.

Closes-Bug: #1900357

Change-Id: Ib738c65544ea997a3f0b3881609461b0a8725050
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/52/766252/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,d0300d6427739bbbe1f043eac11e78de440b6cc6,,, - test: 'neutron_tempest_plugin.scenario' deployment: - 'overcloud' releases: - name: 'queens' reason: 'Neutron Tempest plugin scenario tests are not yet stable.' lp: 'https://launchpad.net/bugs/1737940' jobs: [],0,8
openstack%2Ftripleo-common~master~I005027441229469e4d4b4c90506ccf41f486d174,openstack/tripleo-common,master,I005027441229469e4d4b4c90506ccf41f486d174,"Revert ""Fix a couple of Swift healthchecks""",MERGED,2020-12-23 10:16:41.000000000,2021-01-06 15:46:53.000000000,2020-12-23 23:31:07.000000000,"[{'_account_id': 5241}, {'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 6968}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-12-23 10:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/44b64839124006e47db609a4e874f0c8494213f6', 'message': '[DNM] Revert ""Fix a couple of Swift healthchecks""\n\nThis reverts commit 4cd3bd8fdce54c4b9a75b382773ad49f11125c01.\n\nReason for revert: <INSERT REASONING HERE>\n\nChange-Id: I005027441229469e4d4b4c90506ccf41f486d174\n'}, {'number': 2, 'created': '2020-12-23 11:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b1a7cdc4cb370d9ba51cba57b4f3e517a4b2402a', 'message': '[DNM] Revert ""Fix a couple of Swift healthchecks""\n\nThis reverts commit 4cd3bd8fdce54c4b9a75b382773ad49f11125c01.\n\nCloses-Bug: #1909105\nChange-Id: I005027441229469e4d4b4c90506ccf41f486d174\n'}, {'number': 3, 'created': '2020-12-23 12:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8b7c65908a18e2a381e15ee961de0d76bd1a3b69', 'message': '[DNM] Revert ""Fix a couple of Swift healthchecks""\n\nThis reverts commit 4cd3bd8fdce54c4b9a75b382773ad49f11125c01.\n\nCloses-Bug: #1909105\nChange-Id: I005027441229469e4d4b4c90506ccf41f486d174\nTested here: https://review.rdoproject.org/r/#/c/31424/\n'}, {'number': 4, 'created': '2020-12-23 13:35:51.000000000', 'files': ['container-images/tcib/base/os/swift-base/swift-container/swift-container.yaml', 'healthcheck/swift-account-server', 'healthcheck/releasenotes/notes/swift-fix-healthchecks-b3a02139230f4258.yaml', 'healthcheck/swift-object-replicator', 'container-images/tcib/base/os/swift-base/swift-object/swift-object.yaml', 'healthcheck/swift-account-replicator', 'healthcheck/swift-object', 'healthcheck/swift-container-replicator', 'healthcheck/common.sh', 'healthcheck/swift-object-server', 'container-images/tcib/base/os/swift-base/swift-account/swift-account.yaml', 'healthcheck/swift-container-server', 'healthcheck/swift-proxy'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/750b562521b507aab555862f01b74e56f8119861', 'message': 'Revert ""Fix a couple of Swift healthchecks""\n\nThis reverts commit 4cd3bd8fdce54c4b9a75b382773ad49f11125c01.\n\nCloses-Bug: #1909105\nChange-Id: I005027441229469e4d4b4c90506ccf41f486d174\nTested here: https://review.rdoproject.org/r/#/c/31424/\n'}]",0,768264,750b562521b507aab555862f01b74e56f8119861,16,16,4,20182,,,0,"Revert ""Fix a couple of Swift healthchecks""

This reverts commit 4cd3bd8fdce54c4b9a75b382773ad49f11125c01.

Closes-Bug: #1909105
Change-Id: I005027441229469e4d4b4c90506ccf41f486d174
Tested here: https://review.rdoproject.org/r/#/c/31424/
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/64/768264/4 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/tcib/base/os/swift-base/swift-container/swift-container.yaml', 'healthcheck/swift-account-server', 'healthcheck/releasenotes/notes/swift-fix-healthchecks-b3a02139230f4258.yaml', 'healthcheck/swift-object-replicator', 'container-images/tcib/base/os/swift-base/swift-object/swift-object.yaml', 'healthcheck/swift-account-replicator', 'healthcheck/swift-object', 'healthcheck/swift-container-replicator', 'healthcheck/common.sh', 'healthcheck/swift-object-server', 'container-images/tcib/base/os/swift-base/swift-account/swift-account.yaml', 'healthcheck/swift-container-server', 'healthcheck/swift-proxy']",13,44b64839124006e47db609a4e874f0c8494213f6,,if pgrep -f swift-proxy-server; then,if ps -ef | grep --quiet [s]wift-proxy-server; then,49,48
openstack%2Fopenstack-ansible-os_nova~master~Ida1df164f50b93f470e5ab014b26fc5808e26e89,openstack/openstack-ansible-os_nova,master,Ida1df164f50b93f470e5ab014b26fc5808e26e89,Use systemd sockets for libvirt,ABANDONED,2020-11-18 16:58:41.000000000,2021-01-06 15:32:46.000000000,,"[{'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-11-18 16:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/15d1f568d9481ba67ed22a5d4a15206676c6797a', 'message': ""Use systemd sockets for libvirt\n\nSince libvirt 5.7 you can't use traditional mode with systemd systems\nby default. You need either to switch back to the traditional mode or\nenable appropriate sockets. Since we want more control on the sockets\nconfig (ie listen address or other options) we leverage our\nsystemd_service role to create alterantive systemd services to the\npackaged ones.\n\nDepends-On: https://review.opendev.org/763211\nDepends-On: https://review.opendev.org/763194\nChange-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89\nCloses-Bug: #1903846\n""}, {'number': 2, 'created': '2020-11-18 17:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/0ee2993b7d74be6bb2040de77940136041174fe3', 'message': ""Use systemd sockets for libvirt\n\nSince libvirt 5.7 you can't use traditional mode with systemd systems\nby default. You need either to switch back to the traditional mode or\nenable appropriate sockets. Since we want more control on the sockets\nconfig (ie listen address or other options) we leverage our\nsystemd_service role to create alterantive systemd services to the\npackaged ones.\n\nDepends-On: https://review.opendev.org/763211\nDepends-On: https://review.opendev.org/763194\nChange-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89\nCloses-Bug: #1903846\n""}, {'number': 3, 'created': '2021-01-05 15:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/85a4966597c115a1d1968eb3b684b82f19824945', 'message': ""Use systemd sockets for libvirt\n\nSince libvirt 5.7 you can't use traditional mode with systemd systems\nby default. You need either to switch back to the traditional mode or\nenable appropriate sockets. Since we want more control on the sockets\nconfig (ie listen address or other options) we leverage our\nsystemd_service role to create alterantive systemd services to the\npackaged ones.\n\nDepends-On: https://review.opendev.org/765815\nChange-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89\nCloses-Bug: #1903846\n""}, {'number': 4, 'created': '2021-01-06 11:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/ff534b52fe5c9d2a9539618b4ffe2e8f10ba6f99', 'message': ""Use systemd sockets for libvirt\n\nSince libvirt 5.7 you can't use traditional mode with systemd systems\nby default. You need either to switch back to the traditional mode or\nenable appropriate sockets. Since we want more control on the sockets\nconfig (ie listen address or other options) we leverage our\nsystemd_service role to create alterantive systemd services to the\npackaged ones.\n\nDepends-On: https://review.opendev.org/765815\nChange-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89\nCloses-Bug: #1903846\n""}, {'number': 5, 'created': '2021-01-06 11:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/996ccc401cd431dfb1422aa1c6c8b758fdb09aac', 'message': ""Use systemd sockets for libvirt\n\nSince libvirt 5.7 you can't use traditional mode with systemd systems\nby default. You need either to switch back to the traditional mode or\nenable appropriate sockets. Since we want more control on the sockets\nconfig (ie listen address or other options) we leverage our\nsystemd_service role to create alterantive systemd services to the\npackaged ones.\n\nDepends-On: https://review.opendev.org/765815\nChange-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89\nCloses-Bug: #1903846\n""}, {'number': 6, 'created': '2021-01-06 12:30:27.000000000', 'files': ['tasks/main.yml', 'tasks/nova_compute.yml', 'templates/libvirtd.conf.j2', 'defaults/main.yml', 'vars/main.yml', 'tasks/drivers/kvm/nova_compute_kvm.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/cb4fb791f93ecf3ddf9e5d3b7c6e75e86e90cc46', 'message': ""Use systemd sockets for libvirt\n\nSince libvirt 5.7 you can't use traditional mode with systemd systems\nby default. You need either to switch back to the traditional mode or\nenable appropriate sockets. Since we want more control on the sockets\nconfig (ie listen address or other options) we leverage our\nsystemd_service role to create alterantive systemd services to the\npackaged ones.\n\nDepends-On: https://review.opendev.org/765815\nChange-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89\nCloses-Bug: #1903846\n""}]",0,763216,cb4fb791f93ecf3ddf9e5d3b7c6e75e86e90cc46,18,2,6,28619,,,0,"Use systemd sockets for libvirt

Since libvirt 5.7 you can't use traditional mode with systemd systems
by default. You need either to switch back to the traditional mode or
enable appropriate sockets. Since we want more control on the sockets
config (ie listen address or other options) we leverage our
systemd_service role to create alterantive systemd services to the
packaged ones.

Depends-On: https://review.opendev.org/765815
Change-Id: Ida1df164f50b93f470e5ab014b26fc5808e26e89
Closes-Bug: #1903846
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/16/763216/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/nova_compute.yml', 'templates/libvirtd.conf.j2', 'defaults/main.yml', 'vars/main.yml']",5,15d1f568d9481ba67ed22a5d4a15206676c6797a,bug/1903846," _nova_libvirtd_tls_socket: socket_name: libvirtd-tls after_targets: - libvirtd.socket bind_targets: - libvirtd.socket options: ListenStream: ""{{ nova_libvirtd_listen_tls_address }}"" _nova_libvirtd_tcp_socket: socket_name: libvirtd-tcp after_targets: - libvirtd.socket bind_targets: - libvirtd.socket options: ListenStream: ""{{ nova_libvirtd_listen_tcp_address }}"" _nova_libvirtd_service: - service_name: libvirtd enabled: yes state: started execstarts: /usr/sbin/libvirtd $libvirtd_opts execreloads: /bin/kill -HUP $MAINPID service_type: notify environment_file: ""-/etc/default/libvirtd"" systemd_unit_docs: - ""man:libvirtd(8)"" - ""https://libvirt.org"" program_accounting: {} after_targets: - network.target - dbus.service - iscsid.service - local-fs.target - remote-fs.target - systemd-logind.service - systemd-machined.service - xencommons.service before_targets: - libvirt-guests.service requires_targets: - virtlogd.socket - virtlockd.socket conflicts_targets: - xendomains.service wants_targets: |- {% set wants = [ 'systemd-machined.service', 'libvirtd.socket', 'libvirtd-ro.socket', 'libvirtd-admin.socket', ]%} {% if nova_libvirtd_listen_tls | bool %} {% set _ = wants.append('libvirtd-tls.socket') %} {% endif %} {% if nova_libvirtd_listen_tcp | bool %} {% set _ = wants.append('libvirtd-tcp.socket') %} {% endif %} {{ wants }} also_targets: |- {% set also = [ 'virtlockd.socket', 'virtlogd.socket', 'libvirtd.socket', 'libvirtd-ro.socket', 'libvirtd-admin.socket', ]%} {% if nova_libvirtd_listen_tls | bool %} {% set _ = also.append('libvirtd-tls.socket') %} {% endif %} {% if nova_libvirtd_listen_tcp | bool %} {% set _ = also.append('libvirtd-tcp.socket') %} {% endif %} {{ also }} sockets: |- {% set socket_list = [] %} {% if nova_libvirtd_listen_tls | bool %} {% set _ = socket_list.append(_nova_libvirtd_tls_socket) %} {% endif %} {% if nova_libvirtd_listen_tcp | bool %} {% set _ = socket_list.append(_nova_libvirtd_tcp_socket) %} {% endif %} {{ socket_list }} config_overrides: Service: LimitNOFILE: 8192 TasksMax: 32768 LimitMEMLOCK: 64M",,105,1
openstack%2Ftripleo-ci~master~Ib90d5c064d6b22e027f2a6f26bb84bcb021b702a,openstack/tripleo-ci,master,Ib90d5c064d6b22e027f2a6f26bb84bcb021b702a,Allow to override extra_args & bm provisioning,ABANDONED,2021-01-06 15:23:49.000000000,2021-01-06 15:32:20.000000000,,[],"[{'number': 1, 'created': '2021-01-06 15:23:49.000000000', 'files': ['roles/run-test/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/967f021caf78eee1913b4de628d84e41d4fca0ff', 'message': 'Allow to override extra_args & bm provisioning\n\nWe are adding extra_args & baremetal_provision to allowed_override to\nmake them overridable which enables us to test ""provisioning via\nmetalsmith"" feature in older branches and in downstream reusing fs001\nand not maintain an entirely new featureset for these few settings.\n\nbaremetal_provision allows provisioning of node using metalsmith\nworkflow instead of heat/nova, This is true by default for ussuri+\nbranches.[1]\n\nAlso, we need to pass --disable-validations in deployment command when\nwe provision nodes via metalsmith which is set by default in\nussuri+[2]. This can be set using extra_args.\n\n[1] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L231-L236\n[2] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L72-L78\nChange-Id: Ied37aa4ed8592142704446d20a3665345e46bddc\n\nChange-Id: Ib90d5c064d6b22e027f2a6f26bb84bcb021b702a\n'}]",0,769553,967f021caf78eee1913b4de628d84e41d4fca0ff,2,0,1,29775,,,0,"Allow to override extra_args & bm provisioning

We are adding extra_args & baremetal_provision to allowed_override to
make them overridable which enables us to test ""provisioning via
metalsmith"" feature in older branches and in downstream reusing fs001
and not maintain an entirely new featureset for these few settings.

baremetal_provision allows provisioning of node using metalsmith
workflow instead of heat/nova, This is true by default for ussuri+
branches.[1]

Also, we need to pass --disable-validations in deployment command when
we provision nodes via metalsmith which is set by default in
ussuri+[2]. This can be set using extra_args.

[1] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L231-L236
[2] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L72-L78
Change-Id: Ied37aa4ed8592142704446d20a3665345e46bddc

Change-Id: Ib90d5c064d6b22e027f2a6f26bb84bcb021b702a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/53/769553/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/run-test/tasks/main.yaml'],1,967f021caf78eee1913b4de628d84e41d4fca0ff,, - 'baremetal_provision' - 'extra_args',,2,0
openstack%2Fpython-ironicclient~stable%2Fvictoria~Iafad733ac813da65ceb1864cb24af65e924732b7,openstack/python-ironicclient,stable/victoria,Iafad733ac813da65ceb1864cb24af65e924732b7,Remove lower-constraints job,MERGED,2020-12-18 15:14:30.000000000,2021-01-06 15:24:58.000000000,2021-01-06 15:18:54.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 15:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4d39d2b56b12f3e3ff98c968bf1a80b744268c62', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nAlso fix functional tests.\n\nChange-Id: Iafad733ac813da65ceb1864cb24af65e924732b7\n(cherry picked from commit 7fb95d341cf11c902a5ab231bab4201cb3ab169b)\n'}, {'number': 2, 'created': '2020-12-18 15:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f48cb57bddd93a3fd170371cb9170391a4f95230', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nAlso fix functional tests.\n\nChange-Id: Iafad733ac813da65ceb1864cb24af65e924732b7\n(cherry picked from commit 7fb95d341cf11c902a5ab231bab4201cb3ab169b)\n'}, {'number': 3, 'created': '2020-12-19 14:31:55.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8ae1c79c287b7ad6d252dd9e86dca1df12d6fdf8', 'message': 'Remove lower-constraints job\n\nAs discussed during the upstream ironic community meeting on\nMonday Dec 14 2020, the lower-constraints job is being removed.\n\nAlso fix functional tests.\n\nChange-Id: Iafad733ac813da65ceb1864cb24af65e924732b7\n(cherry picked from commit 7fb95d341cf11c902a5ab231bab4201cb3ab169b)\n'}]",1,767776,8ae1c79c287b7ad6d252dd9e86dca1df12d6fdf8,16,2,3,23851,,,0,"Remove lower-constraints job

As discussed during the upstream ironic community meeting on
Monday Dec 14 2020, the lower-constraints job is being removed.

Also fix functional tests.

Change-Id: Iafad733ac813da65ceb1864cb24af65e924732b7
(cherry picked from commit 7fb95d341cf11c902a5ab231bab4201cb3ab169b)
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/76/767776/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/functional/osc/v1/test_baremetal_node_create_negative.py', 'lower-constraints.txt', 'zuul.d/project.yaml', 'ironicclient/tests/functional/osc/v1/test_baremetal_allocation.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_deploy_template_basic.py']",5,4d39d2b56b12f3e3ff98c968bf1a80b744268c62,remove-l-c-job," ('--uuid', '!@#$^*&%^', 'Expected UUID for uuid'), ('', 'not/a/name', 'does not match'), ('', 'foo', 'does not match'), ('--steps', '[]', 'is too short'))"," ('--uuid', '!@#$^*&%^', 'Expected a UUID'), ('', 'not/a/name', 'Deploy template name must be a valid trait'), ('', 'foo', 'Deploy template name must be a valid trait'), ('--steps', '[]', 'No deploy steps specified'))",15,10
openstack%2Fkeystone~stable%2Ftrain~I120ef1c0c8259c85b6030f2db0a649c71b990879,openstack/keystone,stable/train,I120ef1c0c8259c85b6030f2db0a649c71b990879,fix link in release note of bug/1794527,MERGED,2020-05-12 18:22:55.000000000,2021-01-06 15:08:14.000000000,2021-01-06 15:06:14.000000000,"[{'_account_id': 1736}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 9373}, {'_account_id': 18816}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2020-05-12 18:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a30f2b1a9b703927e81d504ef151f569e45b5d36', 'message': 'fix link in release note of bug/1794527\n\nChange-Id: I120ef1c0c8259c85b6030f2db0a649c71b990879\ncloses-bug: 1877393\n'}, {'number': 2, 'created': '2020-05-26 15:12:56.000000000', 'files': ['releasenotes/notes/bug-1794527-866b1caff67977f3.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/13f965e1f19822cd54ef496c9b8c3f4fdec2ac58', 'message': 'fix link in release note of bug/1794527\n\nChange-Id: I120ef1c0c8259c85b6030f2db0a649c71b990879\ncloses-bug: 1877393\n'}]",0,727357,13f965e1f19822cd54ef496c9b8c3f4fdec2ac58,15,8,2,18816,,,0,"fix link in release note of bug/1794527

Change-Id: I120ef1c0c8259c85b6030f2db0a649c71b990879
closes-bug: 1877393
",git fetch https://review.opendev.org/openstack/keystone refs/changes/57/727357/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/bug-1794527-866b1caff67977f3.yaml'],1,a30f2b1a9b703927e81d504ef151f569e45b5d36,bug/1877393-stable/train, https://specs.openstack.org/openstack/keystone-specs/specs/keystone/train/explicit-domains-ids.html , https://specs.openstack.org/openstack/keystone-specs/specs/keystone/stein/explicit-domains-ids.html,1,1
openstack%2Fneutron~stable%2Fvictoria~I12857794f7b8219e90db547e77d835bdaa6cfa6f,openstack/neutron,stable/victoria,I12857794f7b8219e90db547e77d835bdaa6cfa6f,Fix imports order in neutron.services.ovn_l3_plugin module,MERGED,2020-12-18 15:39:27.000000000,2021-01-06 14:43:51.000000000,2021-01-06 14:42:20.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 15:39:27.000000000', 'files': ['neutron/services/ovn_l3/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dffe4eb3b2258930b03e4297845a8e0c60a06ddb', 'message': 'Fix imports order in neutron.services.ovn_l3_plugin module\n\nTrivialFix\n\nConflicts:\n    neutron/services/ovn_l3/plugin.py\n\nChange-Id: I12857794f7b8219e90db547e77d835bdaa6cfa6f\n(cherry picked from commit c8f88f2ab6d3daaf85387e930140d2eda5d73fa5)\n'}]",0,767774,dffe4eb3b2258930b03e4297845a8e0c60a06ddb,24,5,1,11975,,,0,"Fix imports order in neutron.services.ovn_l3_plugin module

TrivialFix

Conflicts:
    neutron/services/ovn_l3/plugin.py

Change-Id: I12857794f7b8219e90db547e77d835bdaa6cfa6f
(cherry picked from commit c8f88f2ab6d3daaf85387e930140d2eda5d73fa5)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/767774/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/ovn_l3/plugin.py'],1,dffe4eb3b2258930b03e4297845a8e0c60a06ddb,bug/1906311-stable/victoria,from neutron.db import dns_db from neutron.db import extraroute_dbfrom neutron.db import l3_gwmode_db from neutron.db.models import l3 as l3_modelsfrom neutron.quota import resource_registryfrom neutron.services.ovn_l3 import exceptions as ovn_l3_exc,from neutron.db import dns_db from neutron.db import extraroute_db from neutron.db import l3_gwmode_db from neutron.db.models import l3 as l3_models from neutron.quota import resource_registryfrom neutron.services.ovn_l3 import exceptions as ovn_l3_exc ,6,7
openstack%2Fopenstacksdk~master~I1cede0c2d2fc3b7d8fa87bc981b0f4016e5d3592,openstack/openstacksdk,master,I1cede0c2d2fc3b7d8fa87bc981b0f4016e5d3592,"New volume availability zone resource, new functional and unit tests",ABANDONED,2021-01-06 13:55:40.000000000,2021-01-06 14:16:14.000000000,,[],"[{'number': 1, 'created': '2021-01-06 13:55:40.000000000', 'files': ['openstack/block_storage/v3/availability_zone.py', 'openstack/tests/unit/block_storage/v3/test_availability_zone.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6c504f0dd42b1f024ceb5cb4c2ba39800061803b', 'message': 'New volume availability zone resource, new functional and unit tests\n\nChange-Id: I1cede0c2d2fc3b7d8fa87bc981b0f4016e5d3592\n'}]",0,769543,6c504f0dd42b1f024ceb5cb4c2ba39800061803b,2,0,1,32677,,,0,"New volume availability zone resource, new functional and unit tests

Change-Id: I1cede0c2d2fc3b7d8fa87bc981b0f4016e5d3592
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/43/769543/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/block_storage/v3/availability_zone.py', 'openstack/tests/unit/block_storage/v3/test_availability_zone.py']",2,6c504f0dd42b1f024ceb5cb4c2ba39800061803b,volume-availability-zone-support,"from openstack.block_storage.v3 import availability_zone as azIDENTIFIER = ""IDENTIFIER"" EXAMPLE = { ""id"": IDENTIFIER, ""zoneState"": { ""available"": True }, ""zoneName"": ""zone1"" self.assertEqual(EXAMPLE['zoneName'], sot.name) ","from openstack.block_storage.v3 import availability_zone as azIDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'id': IDENTIFIER, 'zoneState': 'available', 'zoneName': 'zone1' self.assertEqual(EXAMPLE['zoneName'], sot.name)",11,14
openstack%2Fironic-python-agent-builder~master~I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24,openstack/ironic-python-agent-builder,master,I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24,Make the debian job voting and start publishing debian images,MERGED,2020-12-15 14:13:47.000000000,2021-01-06 14:16:12.000000000,2021-01-06 14:09:57.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-12-15 14:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/6507f5955ba7658cb7fa6de2b6e0ab42e2a3516d', 'message': 'Make the debian job voting and start publishing debian images\n\nWith only 270MiB in size, the Debian images are likely candidates\nfor our future default images. Given that CentOS Stream 8 images\nare nearly 500MiB in size, Debian may be our only path forward.\n\nChange-Id: I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24\n'}, {'number': 2, 'created': '2020-12-15 15:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/358528e07ada0a47712f2c08be326745d6cbb5a5', 'message': 'Make the debian job voting and start publishing debian images\n\nWith only 270MiB in size, the Debian images are likely candidates\nfor our future default images. Given that CentOS Stream 8 images\nare nearly 500MiB in size, Debian may be our only path forward.\n\nEnable installing firmware on Debian images to make them suitable\nfor bare metal installations.\n\nChange-Id: I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24\n'}, {'number': 3, 'created': '2020-12-15 19:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/1c20fd705381905e451941455b1e3e609159bad4', 'message': 'Make the debian job voting and start publishing debian images\n\nWith only 270MiB in size, the Debian images are likely candidates\nfor our future default images. Given that CentOS Stream 8 images\nare nearly 500MiB in size, Debian may be our only path forward.\n\nEnable installing firmware on Debian images to make them suitable\nfor bare metal installations.\n\nDo not try to install biosdevname on non-RH systems.\n\nChange-Id: I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24\n'}, {'number': 4, 'created': '2020-12-16 10:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/7dd573ac861face1a412ff314759b5760220a590', 'message': 'Make the debian job voting and start publishing debian images\n\nWith only 270MiB in size, the Debian images are likely candidates\nfor our future default images. Given that CentOS Stream 8 images\nare nearly 500MiB in size, Debian may be our only path forward.\n\nEnable installing firmware on Debian images to make them suitable\nfor bare metal installations.\n\nDo not try to install biosdevname on non-RH systems.\n\nChange-Id: I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24\n'}, {'number': 5, 'created': '2020-12-16 18:49:17.000000000', 'files': ['roles/ipa-build-dib-image/tasks/main.yaml', 'releasenotes/notes/debian-firmware-1927601ebb779bc4.yaml', 'dib/ironic-python-agent-ramdisk/package-installs.yaml', 'zuul.d/ironic-python-agent-builder-jobs.yaml', 'dib/ironic-python-agent-ramdisk/environment.d/01-debian-ipa.bash', 'zuul.d/project.yaml', 'dib/extra-hardware/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/db238b9c9950d956bec920034638ab14b6a5e4dc', 'message': 'Make the debian job voting and start publishing debian images\n\nWith only 270MiB in size, the Debian images are likely candidates\nfor our future default images. Given that CentOS Stream 8 images\nare nearly 500MiB in size, Debian may be our only path forward.\n\nEnable installing firmware on Debian images to make them suitable\nfor bare metal installations.\n\nDo not try to install biosdevname on non-RH systems.\n\nChange-Id: I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24\n'}]",0,767158,db238b9c9950d956bec920034638ab14b6a5e4dc,18,4,5,10239,,,0,"Make the debian job voting and start publishing debian images

With only 270MiB in size, the Debian images are likely candidates
for our future default images. Given that CentOS Stream 8 images
are nearly 500MiB in size, Debian may be our only path forward.

Enable installing firmware on Debian images to make them suitable
for bare metal installations.

Do not try to install biosdevname on non-RH systems.

Change-Id: I2c2a71c4afd0cd534961317b7fe9d3fb5d007d24
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/58/767158/3 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-python-agent-builder-jobs.yaml', 'zuul.d/project.yaml']",2,6507f5955ba7658cb7fa6de2b6e0ab42e2a3516d,debian, - ironic-python-agent-check-image-dib-debian - ironic-python-agent-check-image-dib-debian-extra - ironic-python-agent-check-image-dib-debian - ironic-python-agent-check-image-dib-debian-extra - ironic-python-agent-build-image-dib-debian, - ironic-python-agent-check-image-dib-debian: voting: false,20,2
openstack%2Fswift~master~I677a726081d924e3fe122e6b551ed26c90de7981,openstack/swift,master,I677a726081d924e3fe122e6b551ed26c90de7981,wip: failing shard loop test,NEW,2021-01-05 21:34:09.000000000,2021-01-06 14:14:39.000000000,,"[{'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 21:34:09.000000000', 'files': ['test/unit/proxy/controllers/test_container.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/71b653ddb821b5ca5c78b764a9c8a1d2c8fc21e2', 'message': 'wip: failing shard loop test\n\nChange-Id: I677a726081d924e3fe122e6b551ed26c90de7981\n'}]",2,769421,71b653ddb821b5ca5c78b764a9c8a1d2c8fc21e2,4,3,1,1179,,,0,"wip: failing shard loop test

Change-Id: I677a726081d924e3fe122e6b551ed26c90de7981
",git fetch https://review.opendev.org/openstack/swift refs/changes/21/769421/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/proxy/controllers/test_container.py'],1,71b653ddb821b5ca5c78b764a9c8a1d2c8fc21e2,p-shard-listings-loop," def test_GET_out_of_date_root_shrunk_shard(self): # check that if root sends us to a shrinking shard that redirects to # it's acceptor ... we'll go back to it? shard_bounds = ('', 'a', 'b', '') shard_ranges = [ ShardRange('.shards_a/c_%s' % upper, Timestamp.now(), lower, upper) for lower, upper in zip(shard_bounds[:-1], shard_bounds[1:])] self.assertEqual([ '.shards_a/c_a', '.shards_a/c_b', '.shards_a/c_', ], [sr.name for sr in shard_ranges]) sr_dicts = [dict(sr) for sr in shard_ranges] sr_objs = [self._make_shard_objects(sr) for sr in shard_ranges] all_objects = [] for objects in sr_objs: all_objects.extend(objects) size_all_objects = sum([obj['bytes'] for obj in all_objects]) num_all_objects = len(all_objects) root_resp_hdrs = {'X-Backend-Sharding-State': 'sharded', 'X-Backend-Timestamp': '99', 'X-Container-Object-Count': num_all_objects, 'X-Container-Bytes-Used': size_all_objects, 'X-Backend-Storage-Policy-Index': 0, 'X-Backend-Record-Type': 'shard', } shard_resp_hdrs = {'X-Backend-Sharding-State': 'unsharded', 'X-Container-Object-Count': 2, 'X-Container-Bytes-Used': 4, 'X-Backend-Storage-Policy-Index': 0} shrinking_resp_headers = { 'X-Backend-Sharding-State': 'sharded', 'X-Backend-Record-Type': 'shard', } limit = CONTAINER_LISTING_LIMIT mock_responses = [ # status, body, headers (200, sr_dicts, root_resp_hdrs), (200, sr_objs[0], shard_resp_hdrs), (200, sr_objs[1], shard_resp_hdrs), # the last shard shrinks to the previous one (200, [sr_dicts[-2]], shrinking_resp_headers), (200, sr_objs[2], shard_resp_hdrs), ] expected_requests = [ # path, headers, params ('a/c', {'X-Backend-Record-Type': 'auto'}, dict(states='listing')), # 200 ('.shards_a/c_a', {'X-Backend-Record-Type': 'auto'}, dict(marker='', end_marker='a\x00', states='listing', limit=str(limit))), # 200 ('.shards_a/c_b', {'X-Backend-Record-Type': 'auto'}, dict(marker='a', end_marker='b\x00', states='listing', limit=str(limit - len(sr_objs[0])))), # 200 ('.shards_a/c_', {'X-Backend-Record-Type': 'auto'}, dict(marker='b', end_marker='', states='listing', limit=str( limit - len(sr_objs[0]) - len(sr_objs[1])))), # 200 ('.shards_a/c_b', {'X-Backend-Record-Type': 'object'}, dict(marker='b', end_marker='b\x00', states='listing', limit=str( limit - len(sr_objs[0]) - len(sr_objs[1])))), # 200 ] resp = self._check_GET_shard_listing( mock_responses, all_objects, expected_requests) self.check_response(resp, root_resp_hdrs, expected_objects=all_objects) ",,70,0
openstack%2Fkeystone~master~Icd3a00d9a78f1516a0080f065679aa59ac699a98,openstack/keystone,master,Icd3a00d9a78f1516a0080f065679aa59ac699a98,Remove unused policy rule,NEW,2020-10-28 15:30:23.000000000,2021-01-06 14:12:01.000000000,,"[{'_account_id': 5046}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-28 15:30:23.000000000', 'files': ['keystone/common/policies/user.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f4ba73bef9dc1940e3a45350a1e0505b6fcfe1b', 'message': 'Remove unused policy rule\n\nIn the ""/v3/auth/project"" API, the ""identity:get_auth_projects"" rule has\nbeen used to check permissions. In the similar ""/v3/auth/domains"" API,\nthe ""identity:get_auth_domains"" rule has been used to check.\n\nUnused rules ""identity:list_projects_for_user"" and\n""identity:list_domains_for_user"" should be removed.\n\nChange-Id: Icd3a00d9a78f1516a0080f065679aa59ac699a98\n'}]",1,760166,0f4ba73bef9dc1940e3a45350a1e0505b6fcfe1b,3,2,1,27809,,,0,"Remove unused policy rule

In the ""/v3/auth/project"" API, the ""identity:get_auth_projects"" rule has
been used to check permissions. In the similar ""/v3/auth/domains"" API,
the ""identity:get_auth_domains"" rule has been used to check.

Unused rules ""identity:list_projects_for_user"" and
""identity:list_domains_for_user"" should be removed.

Change-Id: Icd3a00d9a78f1516a0080f065679aa59ac699a98
",git fetch https://review.opendev.org/openstack/keystone refs/changes/66/760166/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/policies/user.py'],1,0f4ba73bef9dc1940e3a45350a1e0505b6fcfe1b,,," name=base.IDENTITY % 'list_projects_for_user', check_str='', # NOTE(lbragstad): We explicitly omit scope_types from this policy # because it's meant to be called with an unscoped token, which doesn't # apply to scope_types or its purpose. So long as the user is in the # system and has a valid token, they should be able to generate a list # of projects they have access to. description=('List all projects a user has access to via role ' 'assignments.'), operations=[{'path': ' /v3/auth/projects', 'method': 'GET'}]), policy.DocumentedRuleDefault( name=base.IDENTITY % 'list_domains_for_user', check_str='', # NOTE(lbragstad): We explicitly omit scope_types from this policy # because it's meant to be called with an unscoped token, which doesn't # apply to scope_types or its purpose. So long as the user is in the # system and has a valid token, they should be able to generate a list # of domains they have access to. description=('List all domains a user has access to via role ' 'assignments.'), operations=[{'path': '/v3/auth/domains', 'method': 'GET'}]), policy.DocumentedRuleDefault(",0,24
openstack%2Fcharms.openstack~master~I5a4b8f8602c2a46b340765a8a22fdc218560dfc6,openstack/charms.openstack,master,I5a4b8f8602c2a46b340765a8a22fdc218560dfc6,"Revert ""Support upgrades to Trilio 4.1""",MERGED,2021-01-06 13:43:58.000000000,2021-01-06 14:03:14.000000000,2021-01-06 14:03:14.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 13:43:58.000000000', 'files': ['charms_openstack/plugins/trilio.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/plugins/test_trilio.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/390a426d31cb35b0f3c7066b605cf0d52e005486', 'message': 'Revert ""Support upgrades to Trilio 4.1""\n\nThis reverts commit 3b72a8ba2f4f2981ee6b84fb0346858390d6c8ef.\n\nReason for revert: Registering a second release_selector_function is breaking non-trilio charms\n\nChange-Id: I5a4b8f8602c2a46b340765a8a22fdc218560dfc6\n'}]",0,769511,390a426d31cb35b0f3c7066b605cf0d52e005486,6,3,1,12549,,,0,"Revert ""Support upgrades to Trilio 4.1""

This reverts commit 3b72a8ba2f4f2981ee6b84fb0346858390d6c8ef.

Reason for revert: Registering a second release_selector_function is breaking non-trilio charms

Change-Id: I5a4b8f8602c2a46b340765a8a22fdc218560dfc6
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/11/769511/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_openstack/plugins/trilio.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/plugins/test_trilio.py']",3,390a426d31cb35b0f3c7066b605cf0d52e005486,trilio-4.1-upgrades,"from unit_tests.utils import patch_open def test_series_upgrade_complete(self): self.patch_object(trilio.charms_openstack.charm.OpenStackCharm, 'series_upgrade_complete') self.patch_target('configure_source') self.target.series_upgrade_complete() self.configure_source.assert_called_once_with() def test_install(self): self.patch_object(trilio.charms_openstack.charm.OpenStackCharm, 'configure_source') self.target.install() self._install_triliovault.assert_called_once_with(self.target)","from unit_tests.utils import BaseTestCase, patch_open os_release_pkg = 'nova-common' @classmethod def trilio_version_package(cls): return ""dmapi"" self.patch_object(trilio.fetch.apt_pkg, 'version_compare') def test_trilio_properties(self): cls_mock = mock.MagicMock() cls_mock.charm_instance.release_pkg_version = lambda: '4.0' self.version_compare.return_value = 0 self.assertEqual( trilio.trilio_properties(cls_mock), {'db_type': 'dedicated', 'transport_type': 'dmapi'}) self.version_compare.return_value = -1 self.assertEqual( trilio.trilio_properties(cls_mock), {'db_type': 'legacy', 'transport_type': 'legacy'}) def test_get_trilio_codename_install_source(self): self.assertEqual( trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata-4-0/ /'), '4.0') self.assertEqual( trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata-4-0-0/ /'), '4.0') with self.assertRaises(AssertionError): trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata/ /') def test_get_trilio_charm_instance(self): class BaseClass(): def __init__(self, release, *args, **kwargs): pass class Pike39(BaseClass): release = 'pike' trilio_release = '3.9' class Queens40(BaseClass): release = 'queens' trilio_release = '4.0' class Queens41(BaseClass): release = 'queens' trilio_release = '4.1' class Rocky40(BaseClass): release = 'rocky' trilio_release = '4.0' def _version_compare(ver1, ver2): if float(ver1) > float(ver2): return 1 elif float(ver1) < float(ver2): return -1 else: return 0 save_releases = trilio._trilio_releases self.version_compare.side_effect = _version_compare trilio._trilio_releases = { 'pike': { trilio.AptPkgVersion('3.9'): { 'deb': Pike39}}, 'queens': { trilio.AptPkgVersion('4.0'): { 'deb': Queens40}, trilio.AptPkgVersion('4.1'): { 'deb': Queens41}}, 'rocky': { trilio.AptPkgVersion('4.0'): { 'deb': Rocky40}}} # Check with no release being supplied. Should return the # highest release class. self.assertIsInstance( trilio.get_trilio_charm_instance(), Rocky40) self.assertIsInstance( trilio.get_trilio_charm_instance(release='queens_4.0'), Queens40) self.assertIsInstance( trilio.get_trilio_charm_instance(release='queens_4.1'), Queens41) # Ensure an error is raised if a class satisfying the trilio condition # is not found for the highest matching OpenStack class. with self.assertRaises(RuntimeError): trilio.get_trilio_charm_instance(release='rocky_3.9') # Match the openstack release and then the closest trilio releases # within that subset. self.assertIsInstance( trilio.get_trilio_charm_instance(release='rocky_4.1'), Rocky40) with self.assertRaises(RuntimeError): trilio.get_trilio_charm_instance(release='icehouse_4.1') trilio._trilio_releases = save_releases def test_select_trilio_release(self): def get_charm_class(release_pkg='trilio_pkg', package_version='4.0', os_codename_exception=None, version_package='trilio_pkg', package_version_exception=None, os_release_pkg='nova_pkg', os_codename_pkg='queens', trilio_source='deb https://a.io/trilio-4-2-0/ /'): class _TrilioCharm(): def __init__(self): self.release_pkg = release_pkg self.version_package = version_package self.os_release_pkg = os_release_pkg self.source_config_key = 'openstack-origin' self.package_codenames = {} self.package_version = package_version self.os_codename_exception = os_codename_exception self.os_codename_pkg = os_codename_pkg self.trilio_source = trilio_source @staticmethod def get_os_codename_package(pkg, code_names, apt_cache_sufficient=True): if os_codename_exception: raise os_codename_exception else: return os_codename_pkg @staticmethod def get_package_version(pkg, apt_cache_sufficient=True): if package_version_exception: raise package_version_exception else: return package_version return _TrilioCharm() self.patch_object( trilio.os_utils, ""get_installed_semantic_versioned_packages"") self.patch_object(trilio.os_utils, ""os_release"") self.patch_object(trilio.unitdata, ""kv"") kv_mock = mock.MagicMock() self.kv.return_value = kv_mock kv_mock.get.return_value = None self.patch_object(trilio, ""get_trilio_charm_instance"") self.get_trilio_charm_instance.return_value = get_charm_class() self.assertEqual( trilio.select_trilio_release(), 'queens_4.0') # Check RuntimeError is raised if release_pkg is missing from charm # class self.get_trilio_charm_instance.return_value = get_charm_class( release_pkg=None) with self.assertRaises(RuntimeError): trilio.select_trilio_release() # Test falling back to get_installed_semantic_versioned_packages self.os_release.return_value = 'pike' self.get_installed_semantic_versioned_packages.reset_mock() self.get_installed_semantic_versioned_packages.return_value = ['nova'] self.get_trilio_charm_instance.return_value = get_charm_class( os_codename_pkg=None) self.assertEqual( trilio.select_trilio_release(), 'pike_4.0') # Check RuntimeError is raised if version_package is missing from charm # class self.get_trilio_charm_instance.return_value = get_charm_class( version_package=None) with self.assertRaises(RuntimeError): trilio.select_trilio_release() # Test falling back to get_trilio_codename_install_source self.get_trilio_charm_instance.return_value = get_charm_class( package_version_exception=ValueError) self.assertEqual( trilio.select_trilio_release(), 'queens_4.2') self.patch_object(trilio.ch_core.hookenv, ""log"") self.patch_object(trilio.ch_core.hookenv, ""status_set"") self.patch_object(trilio, ""get_trilio_charm_instance"") self.patch_object(trilio.fetch, ""apt_update"") self.patch_object(trilio.fetch, ""apt_install"") self.patch_object(trilio.fetch.apt_pkg, ""version_compare"") self.patch_target('config') self._conf = { 'triliovault-pkg-source': 'deb https://a.io/trilio-4-2-0/ /' } self.config.get.side_effect = lambda x, b=None: self._conf.get(x, b) def test_trilio_source(self): self.assertEqual( self.target.trilio_source, 'deb https://a.io/trilio-4-2-0/ /') def test_do_trilio_pkg_upgrade(self): self.target.do_trilio_pkg_upgrade() self.apt_update.assert_called_once_with() self.apt_install.assert_called_once_with( packages=['foo', 'bar'], options=[ '--option', 'Dpkg::Options::=--force-confnew', '--option', 'Dpkg::Options::=--force-confdef'], fatal=True) def test_run_trilio_upgrade(self): self.patch_target('get_os_codename_package') self.get_os_codename_package.return_value = 'queens' charm_cls = mock.MagicMock() interface_mocks = [mock.MagicMock(), mock.MagicMock()] self.get_trilio_charm_instance.return_value = charm_cls self.target.run_trilio_upgrade(interfaces_list=interface_mocks) self._configure_triliovault_source.assert_called_once_with() charm_cls.do_trilio_pkg_upgrade.assert_called_once_with() charm_cls.render_with_interfaces.assert_called_once_with( interface_mocks) charm_cls.do_trilio_upgrade_db_migration.assert_called_once_with() def test_trilio_upgrade_available(self): self.patch_target('get_package_version') self.get_package_version.return_value = '4.1' self.version_compare.return_value = 1 self.assertTrue(self.target.trilio_upgrade_available()) self.version_compare.assert_called_once_with('4.2', '4.1') def test_upgrade_if_available(self): self.patch_target('openstack_upgrade_available') self.patch_target('trilio_upgrade_available') self.patch_target('run_upgrade') self.patch_target('run_trilio_upgrade') interface_mocks = [mock.MagicMock(), mock.MagicMock()] self._conf['action-managed-upgrade'] = False self.openstack_upgrade_available.return_value = True self.trilio_upgrade_available.return_value = True self.target.upgrade_if_available(interface_mocks) self.run_upgrade.assert_called_once_with( interfaces_list=interface_mocks) self.run_trilio_upgrade.assert_called_once_with( interfaces_list=interface_mocks) self.run_upgrade.reset_mock() self.run_trilio_upgrade.reset_mock() self._conf['action-managed-upgrade'] = True self.openstack_upgrade_available.return_value = True self.trilio_upgrade_available.return_value = True self.target.upgrade_if_available(interface_mocks) self.assertFalse(self.run_upgrade.called) self.assertFalse(self.run_trilio_upgrade.called) self.patch_object(trilio.fetch, ""apt_update"") self.apt_update.assert_called_once_with(fatal=True) class TestBaseTrilioCharmMeta(BaseTestCase): def setUp(self): self.save_releases = trilio._trilio_releases super().setUp() self.patch_object(trilio.fetch.apt_pkg, 'version_compare') def _version_compare(ver1, ver2): if float(ver1) > float(ver2): return 1 elif float(ver1) < float(ver2): return -1 else: return 0 self.version_compare.side_effect = _version_compare def tearDown(self): super().tearDown() trilio._trilio_releases = self.save_releases def register_classes(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' class TrilioQueens41(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.1' class TrilioRocky40(metaclass=trilio.BaseTrilioCharmMeta): release = 'rocky' trilio_release = '4.0' return { 'queens_4.0': TrilioQueens40, 'queens_4.1': TrilioQueens41, 'rocky_4.0': TrilioRocky40} def register_classes_missing_key(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' def register_classes_wrong_pkg_type(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.1' package_type = 'up2date' def register_classes_duplicate(self): class TrilioQueens40A(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' class TrilioQueens40B(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' def test_class_register(self): charm_classes = self.register_classes() self.maxDiff = None self.assertEqual( trilio._trilio_releases, { 'queens': { trilio.AptPkgVersion('4.0'): { 'deb': charm_classes['queens_4.0']}, trilio.AptPkgVersion('4.1'): { 'deb': charm_classes['queens_4.1']}}, 'rocky': { trilio.AptPkgVersion('4.0'): { 'deb': charm_classes['rocky_4.0']}}}) def test_class_register_missing_key(self): with self.assertRaises(RuntimeError): self.register_classes_missing_key() def test_class_register_wrong_pkg_type(self): with self.assertRaises(RuntimeError): self.register_classes_wrong_pkg_type() def test_class_register_duplicate(self): with self.assertRaises(RuntimeError): self.register_classes_duplicate()",33,760
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a,openstack/tripleo-heat-templates,stable/train,I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a,Ensure cinder LVM volumes work after system restart,MERGED,2021-01-05 03:16:03.000000000,2021-01-06 13:54:24.000000000,2021-01-06 10:22:29.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-05 03:16:03.000000000', 'files': ['deployment/iscsid/iscsid-container-puppet.yaml', 'deployment/cinder/cinder-common-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/98377d0200138c97655fdd7dd55c63dca5a1bd00', 'message': ""Ensure cinder LVM volumes work after system restart\n\nUpdate the cinder-lvm-losetup systemd service to wait until the local\n/var directory is mounted and the lvm2-monitor service has started\nprior to creating the loopback device used by cinder's LVM backend.\n\nMake LIO SCSI target data persistent by adding container volume mounts\nfor the /etc/target directory so that the data is stored on the host.\n\nNOTE(stable/train): The setype for persistent directories is set to\nsvirt_sandbox_file_t, whereas later releases use container_file_t.\n\nCloses-Bug: #1905617\nChange-Id: I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a\n(cherry picked from commit 63b2a989ba4a79c204c6d2a4b1512e3a924ec434)\n(cherry picked from commit 27678af1ab36ac531b8dd694ca92a461df43ec7b)\n(cherry picked from commit 833e812bafd8e34919e301537ca655826e393e74)\n""}]",0,769239,98377d0200138c97655fdd7dd55c63dca5a1bd00,14,3,1,21129,,,0,"Ensure cinder LVM volumes work after system restart

Update the cinder-lvm-losetup systemd service to wait until the local
/var directory is mounted and the lvm2-monitor service has started
prior to creating the loopback device used by cinder's LVM backend.

Make LIO SCSI target data persistent by adding container volume mounts
for the /etc/target directory so that the data is stored on the host.

NOTE(stable/train): The setype for persistent directories is set to
svirt_sandbox_file_t, whereas later releases use container_file_t.

Closes-Bug: #1905617
Change-Id: I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a
(cherry picked from commit 63b2a989ba4a79c204c6d2a4b1512e3a924ec434)
(cherry picked from commit 27678af1ab36ac531b8dd694ca92a461df43ec7b)
(cherry picked from commit 833e812bafd8e34919e301537ca655826e393e74)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/769239/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/iscsid/iscsid-container-puppet.yaml', 'deployment/cinder/cinder-common-container-puppet.yaml']",2,98377d0200138c97655fdd7dd55c63dca5a1bd00,bug/1905617," cinder_iscsi_backend_enabled: {equals: [{get_param: CinderEnableIscsiBackend}, true]} cinder_enable_iscsi_backend: {if: [cinder_iscsi_backend_enabled, true, false]} Requires=lvm2-monitor.service systemd-udev-settle.service After=var.mount lvm2-monitor.service systemd-udev-settle.service - cinder_iscsi_backend_enabled - - /etc/target:/etc/target:z - [] - if:", cinder_enable_iscsi_backend: {get_param: CinderEnableIscsiBackend} Requires=lvm2-lvmetad.service systemd-udev-settle.service After=lvm2-lvmetad.service systemd-udev-settle.service,17,11
openstack%2Fcharms.openstack~master~I5a5e5721d9a713b66f8c796896c400481e9733a2,openstack/charms.openstack,master,I5a5e5721d9a713b66f8c796896c400481e9733a2,Support upgrades to Trilio 4.1,MERGED,2020-12-17 11:49:25.000000000,2021-01-06 13:43:58.000000000,2021-01-06 11:20:53.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 11:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/e61997eabddeff8ee5abb2254375269e763ebe36', 'message': 'Support trilio upgrades\n\nChange-Id: I5a5e5721d9a713b66f8c796896c400481e9733a2\n'}, {'number': 2, 'created': '2020-12-17 11:58:28.000000000', 'files': ['charms_openstack/plugins/trilio.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/plugins/test_trilio.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/3b72a8ba2f4f2981ee6b84fb0346858390d6c8ef', 'message': 'Support upgrades to Trilio 4.1\n\nAdding support for Trilio 4.1 includes the following changes:\n\n* Add Trilio_properties config property to enables templates to distinguish\n  between 4.0 and 4.1 release.\n* Add get_trilio_codename_install_source to attempt to derive the Trilio\n  version supported by an apt repo.\n* Add get_trilio_charm_instance which overrides the default get_charm_instance.\n  This will pick the correct charm class based on both the Trilio release and\n  the OpenStack release.\n* Add select_trilio_release which overrides the default select_release and\n  calculates the target OpenStack and Trilio release.\n* Add a specialist Trilio metaclass BaseTrilioCharmMeta. This registers\n  charm classes using their OpenStack release, Trilio release and package\n  type.\n* Move code shared between TrilioVaultCharm & TrilioVaultSubordinateCharm\n  to TrilioVaultCharmMixin. Add support for Trilio upgrades to\n  TrilioVaultCharmMixina.\n\nChange-Id: I5a5e5721d9a713b66f8c796896c400481e9733a2\n'}]",0,767517,3b72a8ba2f4f2981ee6b84fb0346858390d6c8ef,8,2,2,12549,,,0,"Support upgrades to Trilio 4.1

Adding support for Trilio 4.1 includes the following changes:

* Add Trilio_properties config property to enables templates to distinguish
  between 4.0 and 4.1 release.
* Add get_trilio_codename_install_source to attempt to derive the Trilio
  version supported by an apt repo.
* Add get_trilio_charm_instance which overrides the default get_charm_instance.
  This will pick the correct charm class based on both the Trilio release and
  the OpenStack release.
* Add select_trilio_release which overrides the default select_release and
  calculates the target OpenStack and Trilio release.
* Add a specialist Trilio metaclass BaseTrilioCharmMeta. This registers
  charm classes using their OpenStack release, Trilio release and package
  type.
* Move code shared between TrilioVaultCharm & TrilioVaultSubordinateCharm
  to TrilioVaultCharmMixin. Add support for Trilio upgrades to
  TrilioVaultCharmMixina.

Change-Id: I5a5e5721d9a713b66f8c796896c400481e9733a2
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/17/767517/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_openstack/plugins/trilio.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/plugins/test_trilio.py']",3,e61997eabddeff8ee5abb2254375269e763ebe36,trilio-4.1-upgrades,"from unit_tests.utils import BaseTestCase, patch_open os_release_pkg = 'nova-common' @classmethod def trilio_version_package(cls): return ""dmapi"" self.patch_object(trilio.fetch.apt_pkg, 'version_compare') def test_trilio_properties(self): cls_mock = mock.MagicMock() cls_mock.charm_instance.release_pkg_version = lambda: '4.0' self.version_compare.return_value = 0 self.assertEqual( trilio.trilio_properties(cls_mock), {'db_type': 'dedicated', 'transport_type': 'dmapi'}) self.version_compare.return_value = -1 self.assertEqual( trilio.trilio_properties(cls_mock), {'db_type': 'legacy', 'transport_type': 'legacy'}) def test_get_trilio_codename_install_source(self): self.assertEqual( trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata-4-0/ /'), '4.0') self.assertEqual( trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata-4-0-0/ /'), '4.0') with self.assertRaises(AssertionError): trilio.get_trilio_codename_install_source( 'deb [trusted=yes] https://apt.fury.io/triliodata/ /') def test_get_trilio_charm_instance(self): class BaseClass(): def __init__(self, release, *args, **kwargs): pass class Pike39(BaseClass): release = 'pike' trilio_release = '3.9' class Queens40(BaseClass): release = 'queens' trilio_release = '4.0' class Queens41(BaseClass): release = 'queens' trilio_release = '4.1' class Rocky40(BaseClass): release = 'rocky' trilio_release = '4.0' def _version_compare(ver1, ver2): if float(ver1) > float(ver2): return 1 elif float(ver1) < float(ver2): return -1 else: return 0 save_releases = trilio._trilio_releases self.version_compare.side_effect = _version_compare trilio._trilio_releases = { 'pike': { trilio.AptPkgVersion('3.9'): { 'deb': Pike39}}, 'queens': { trilio.AptPkgVersion('4.0'): { 'deb': Queens40}, trilio.AptPkgVersion('4.1'): { 'deb': Queens41}}, 'rocky': { trilio.AptPkgVersion('4.0'): { 'deb': Rocky40}}} # Check with no release being supplied. Should return the # highest release class. self.assertIsInstance( trilio.get_trilio_charm_instance(), Rocky40) self.assertIsInstance( trilio.get_trilio_charm_instance(release='queens_4.0'), Queens40) self.assertIsInstance( trilio.get_trilio_charm_instance(release='queens_4.1'), Queens41) # Ensure an error is raised if a class satisfying the trilio condition # is not found for the highest matching OpenStack class. with self.assertRaises(RuntimeError): trilio.get_trilio_charm_instance(release='rocky_3.9') # Match the openstack release and then the closest trilio releases # within that subset. self.assertIsInstance( trilio.get_trilio_charm_instance(release='rocky_4.1'), Rocky40) with self.assertRaises(RuntimeError): trilio.get_trilio_charm_instance(release='icehouse_4.1') trilio._trilio_releases = save_releases def test_select_trilio_release(self): def get_charm_class(release_pkg='trilio_pkg', package_version='4.0', os_codename_exception=None, version_package='trilio_pkg', package_version_exception=None, os_release_pkg='nova_pkg', os_codename_pkg='queens', trilio_source='deb https://a.io/trilio-4-2-0/ /'): class _TrilioCharm(): def __init__(self): self.release_pkg = release_pkg self.version_package = version_package self.os_release_pkg = os_release_pkg self.source_config_key = 'openstack-origin' self.package_codenames = {} self.package_version = package_version self.os_codename_exception = os_codename_exception self.os_codename_pkg = os_codename_pkg self.trilio_source = trilio_source @staticmethod def get_os_codename_package(pkg, code_names, apt_cache_sufficient=True): if os_codename_exception: raise os_codename_exception else: return os_codename_pkg @staticmethod def get_package_version(pkg, apt_cache_sufficient=True): if package_version_exception: raise package_version_exception else: return package_version return _TrilioCharm() self.patch_object( trilio.os_utils, ""get_installed_semantic_versioned_packages"") self.patch_object(trilio.os_utils, ""os_release"") self.patch_object(trilio.unitdata, ""kv"") kv_mock = mock.MagicMock() self.kv.return_value = kv_mock kv_mock.get.return_value = None self.patch_object(trilio, ""get_trilio_charm_instance"") self.get_trilio_charm_instance.return_value = get_charm_class() self.assertEqual( trilio.select_trilio_release(), 'queens_4.0') # Check RuntimeError is raised if release_pkg is missing from charm # class self.get_trilio_charm_instance.return_value = get_charm_class( release_pkg=None) with self.assertRaises(RuntimeError): trilio.select_trilio_release() # Test falling back to get_installed_semantic_versioned_packages self.os_release.return_value = 'pike' self.get_installed_semantic_versioned_packages.reset_mock() self.get_installed_semantic_versioned_packages.return_value = ['nova'] self.get_trilio_charm_instance.return_value = get_charm_class( os_codename_pkg=None) self.assertEqual( trilio.select_trilio_release(), 'pike_4.0') # Check RuntimeError is raised if version_package is missing from charm # class self.get_trilio_charm_instance.return_value = get_charm_class( version_package=None) with self.assertRaises(RuntimeError): trilio.select_trilio_release() # Test falling back to get_trilio_codename_install_source self.get_trilio_charm_instance.return_value = get_charm_class( package_version_exception=ValueError) self.assertEqual( trilio.select_trilio_release(), 'queens_4.2') self.patch_object(trilio.ch_core.hookenv, ""log"") self.patch_object(trilio.ch_core.hookenv, ""status_set"") self.patch_object(trilio, ""get_trilio_charm_instance"") self.patch_object(trilio.fetch, ""apt_update"") self.patch_object(trilio.fetch, ""apt_install"") self.patch_object(trilio.fetch.apt_pkg, ""version_compare"") self.patch_target('config') self._conf = { 'triliovault-pkg-source': 'deb https://a.io/trilio-4-2-0/ /' } self.config.get.side_effect = lambda x, b=None: self._conf.get(x, b) def test_trilio_source(self): self.assertEqual( self.target.trilio_source, 'deb https://a.io/trilio-4-2-0/ /') def test_do_trilio_pkg_upgrade(self): self.target.do_trilio_pkg_upgrade() self.apt_update.assert_called_once_with() self.apt_install.assert_called_once_with( packages=['foo', 'bar'], options=[ '--option', 'Dpkg::Options::=--force-confnew', '--option', 'Dpkg::Options::=--force-confdef'], fatal=True) def test_run_trilio_upgrade(self): self.patch_target('get_os_codename_package') self.get_os_codename_package.return_value = 'queens' charm_cls = mock.MagicMock() interface_mocks = [mock.MagicMock(), mock.MagicMock()] self.get_trilio_charm_instance.return_value = charm_cls self.target.run_trilio_upgrade(interfaces_list=interface_mocks) self._configure_triliovault_source.assert_called_once_with() charm_cls.do_trilio_pkg_upgrade.assert_called_once_with() charm_cls.render_with_interfaces.assert_called_once_with( interface_mocks) charm_cls.do_trilio_upgrade_db_migration.assert_called_once_with() def test_trilio_upgrade_available(self): self.patch_target('get_package_version') self.get_package_version.return_value = '4.1' self.version_compare.return_value = 1 self.assertTrue(self.target.trilio_upgrade_available()) self.version_compare.assert_called_once_with('4.2', '4.1') def test_upgrade_if_available(self): self.patch_target('openstack_upgrade_available') self.patch_target('trilio_upgrade_available') self.patch_target('run_upgrade') self.patch_target('run_trilio_upgrade') interface_mocks = [mock.MagicMock(), mock.MagicMock()] self._conf['action-managed-upgrade'] = False self.openstack_upgrade_available.return_value = True self.trilio_upgrade_available.return_value = True self.target.upgrade_if_available(interface_mocks) self.run_upgrade.assert_called_once_with( interfaces_list=interface_mocks) self.run_trilio_upgrade.assert_called_once_with( interfaces_list=interface_mocks) self.run_upgrade.reset_mock() self.run_trilio_upgrade.reset_mock() self._conf['action-managed-upgrade'] = True self.openstack_upgrade_available.return_value = True self.trilio_upgrade_available.return_value = True self.target.upgrade_if_available(interface_mocks) self.assertFalse(self.run_upgrade.called) self.assertFalse(self.run_trilio_upgrade.called) self.patch_object(trilio.fetch, ""apt_update"") self.apt_update.assert_called_once_with(fatal=True) class TestBaseTrilioCharmMeta(BaseTestCase): def setUp(self): self.save_releases = trilio._trilio_releases super().setUp() self.patch_object(trilio.fetch.apt_pkg, 'version_compare') def _version_compare(ver1, ver2): if float(ver1) > float(ver2): return 1 elif float(ver1) < float(ver2): return -1 else: return 0 self.version_compare.side_effect = _version_compare def tearDown(self): super().tearDown() trilio._trilio_releases = self.save_releases def register_classes(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' class TrilioQueens41(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.1' class TrilioRocky40(metaclass=trilio.BaseTrilioCharmMeta): release = 'rocky' trilio_release = '4.0' return { 'queens_4.0': TrilioQueens40, 'queens_4.1': TrilioQueens41, 'rocky_4.0': TrilioRocky40} def register_classes_missing_key(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' def register_classes_wrong_pkg_type(self): class TrilioQueens40(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.1' package_type = 'up2date' def register_classes_duplicate(self): class TrilioQueens40A(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' class TrilioQueens40B(metaclass=trilio.BaseTrilioCharmMeta): release = 'queens' trilio_release = '4.0' def test_class_register(self): charm_classes = self.register_classes() self.maxDiff = None self.assertEqual( trilio._trilio_releases, { 'queens': { trilio.AptPkgVersion('4.0'): { 'deb': charm_classes['queens_4.0']}, trilio.AptPkgVersion('4.1'): { 'deb': charm_classes['queens_4.1']}}, 'rocky': { trilio.AptPkgVersion('4.0'): { 'deb': charm_classes['rocky_4.0']}}}) def test_class_register_missing_key(self): with self.assertRaises(RuntimeError): self.register_classes_missing_key() def test_class_register_wrong_pkg_type(self): with self.assertRaises(RuntimeError): self.register_classes_wrong_pkg_type() def test_class_register_duplicate(self): with self.assertRaises(RuntimeError): self.register_classes_duplicate()","from unit_tests.utils import patch_open def test_series_upgrade_complete(self): self.patch_object(trilio.charms_openstack.charm.OpenStackCharm, 'series_upgrade_complete') self.patch_target('configure_source') self.target.series_upgrade_complete() self.configure_source.assert_called_once_with() def test_install(self): self.patch_object(trilio.charms_openstack.charm.OpenStackCharm, 'configure_source') self.target.install() self._install_triliovault.assert_called_once_with(self.target)",760,33
openstack%2Fopenstack-ansible~stable%2Fussuri~I4dc900a103d675cb0739f25c6c063d18e63191b8,openstack/openstack-ansible,stable/ussuri,I4dc900a103d675cb0739f25c6c063d18e63191b8,Bump SHAs for stable/ussuri,MERGED,2020-12-27 17:09:47.000000000,2021-01-06 13:30:13.000000000,2021-01-06 13:28:14.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-27 17:09:47.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/315f4d25a19906af958de9401b93cb0c06122a70', 'message': 'Bump SHAs for stable/ussuri\n\nChange-Id: I4dc900a103d675cb0739f25c6c063d18e63191b8\n'}]",0,768581,315f4d25a19906af958de9401b93cb0c06122a70,29,3,1,28619,,,0,"Bump SHAs for stable/ussuri

Change-Id: I4dc900a103d675cb0739f25c6c063d18e63191b8
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/768581/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,315f4d25a19906af958de9401b93cb0c06122a70,bump_osa, version: f3d96876dfd71c03283a3db58ece76c527347b3e version: 987199f132764153d7b976cb27bd5cd8f869b2b9, version: cf475a9b779d508841d066c8e73b1f45988be2bf version: ffa823d4f6714e17c7532a86d10af129c7032e98,52,52
openstack%2Ftripleo-validations~master~Iefc9cf7e5a0d366f8cc3dd27aef3bc545226fe35,openstack/tripleo-validations,master,Iefc9cf7e5a0d366f8cc3dd27aef3bc545226fe35,POC: Make linters voting only on master,ABANDONED,2020-12-15 15:22:11.000000000,2021-01-06 13:24:20.000000000,,"[{'_account_id': 11491}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-15 15:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/3f81fc76a01530383947d8c8bac4c64d4d77228b', 'message': 'POC: Make linters voting only on master\n\nChange-Id: Iefc9cf7e5a0d366f8cc3dd27aef3bc545226fe35\n'}, {'number': 2, 'created': '2020-12-15 15:24:28.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/79efbe3f0004e6729bc8e018298b83a9d1141ee7', 'message': 'POC: Make linters voting only on master\n\nChange-Id: Iefc9cf7e5a0d366f8cc3dd27aef3bc545226fe35\n'}]",0,767175,79efbe3f0004e6729bc8e018298b83a9d1141ee7,5,2,2,24162,,,0,"POC: Make linters voting only on master

Change-Id: Iefc9cf7e5a0d366f8cc3dd27aef3bc545226fe35
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/75/767175/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3f81fc76a01530383947d8c8bac4c64d4d77228b,,- job: name: tripleo-validations-tox-linters parent: openstack-tox-linters branches: - master voting: true - job: name: tripleo-validations-tox-linters parent: openstack-tox-linters branches: ^(?!master).*$ voting: false - tripleo-validations-tox-linters: &tripleo-linters - tripleo-validations-tox-linters, - openstack-tox-linters: &tripleo-linters - openstack-tox-linters,15,2
openstack%2Fopenstacksdk~master~Ia615288da30426c2f689daa3e5f88376aead1d3f,openstack/openstacksdk,master,Ia615288da30426c2f689daa3e5f88376aead1d3f,Support roles 'name' in list_roles call,MERGED,2021-01-05 14:18:13.000000000,2021-01-06 13:13:10.000000000,2021-01-06 13:11:40.000000000,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-01-05 14:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/57e98903aa5f79804eb33a6ec91bb96cf8c693dd', 'message': ""Support roles 'name' in list_roles call\n\nChange-Id: Ia615288da30426c2f689daa3e5f88376aead1d3f\n""}, {'number': 2, 'created': '2021-01-05 18:50:37.000000000', 'files': ['openstack/cloud/_identity.py', 'openstack/tests/unit/cloud/test_identity_roles.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/658b5805be92892581fb0029107f7fc47af271e8', 'message': ""Support roles 'name' in list_roles call\n\nChange-Id: Ia615288da30426c2f689daa3e5f88376aead1d3f\n""}]",0,769350,658b5805be92892581fb0029107f7fc47af271e8,17,3,2,10969,,,0,"Support roles 'name' in list_roles call

Change-Id: Ia615288da30426c2f689daa3e5f88376aead1d3f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/50/769350/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cloud/_identity.py', 'openstack/tests/unit/cloud/test_identity_roles.py']",2,57e98903aa5f79804eb33a6ec91bb96cf8c693dd,name_roles," def test_list_role_by_name(self): role_data = self._get_role_data() self.register_uris([ dict(method='GET', uri=self.get_mock_url(), status_code=200, json={'roles': [role_data.json_response['role']]}) ]) role = self.cloud.list_roles(name=role_data.role_name)[0] self.assertIsNotNone(role) self.assertThat(role.id, matchers.Equals(role_data.role_id)) self.assertThat(role.name, matchers.Equals(role_data.role_name)) self.assert_calls() ",,16,1
openstack%2Fkuryr-libnetwork~master~I2ee7ff82855e7e528808ecbb60fee598b740d83c,openstack/kuryr-libnetwork,master,I2ee7ff82855e7e528808ecbb60fee598b740d83c,Fix docs requirements for new pip,ABANDONED,2021-01-04 19:49:13.000000000,2021-01-06 13:08:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-04 19:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/e110b1ca43624bed3fc1a81a603a08fb53d48d4d', 'message': 'Fix docs requirements for new pip\n\nDocs requirements could fail because of\nusing test-requirements instead of doc/requirements\nas announced on openstack list[1]. This commit\navoids that by creating a doc/requirements.\n\n[1] [1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c\n'}, {'number': 2, 'created': '2021-01-05 18:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/ee688b35f6b483893d11bbcbeb72967d31131812', 'message': 'Fix docs requirements for new pip\n\nDocs requirements could fail because of\nusing test-requirements instead of doc/requirements\nas announced on openstack list[1]. This commit\navoids that by creating a doc/requirements.\n\n[1] [1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c\n'}, {'number': 3, 'created': '2021-01-05 20:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/ed319d646c085d1aec823acba973aadc12095762', 'message': 'Fix docs requirements for new pip\n\nDocs requirements could fail because of\nusing test-requirements instead of doc/requirements\nas announced on openstack list[1]. This commit\navoids that by creating a doc/requirements.\n\n[1] [1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c\n'}, {'number': 4, 'created': '2021-01-05 22:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/9381d04e68f7ad10279e3fdb0df1e4c954772211', 'message': 'Fix docs requirements for new pip\n\nDocs requirements could fail because of\nusing test-requirements instead of doc/requirements\nas announced on openstack list[1]. This commit\navoids that by creating a doc/requirements.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c\n'}, {'number': 5, 'created': '2021-01-06 00:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/94e681b5da91345b7270c94532c720ac9b9d5c59', 'message': 'Fix docs requirements for new pip\n\nDocs requirements could fail because of\nusing test-requirements instead of doc/requirements\nas announced on openstack list[1]. This commit\navoids that by creating a doc/requirements.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c\n'}, {'number': 6, 'created': '2021-01-06 00:30:58.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/411a68bc654391817865724f8a99b72a0e51dd73', 'message': 'Fix docs requirements for new pip\n\nDocs requirements could fail because of\nusing test-requirements instead of doc/requirements\nas announced on openstack list[1]. This commit\navoids that by creating a doc/requirements.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c\n'}]",0,769210,411a68bc654391817865724f8a99b72a0e51dd73,13,1,6,27032,,,0,"Fix docs requirements for new pip

Docs requirements could fail because of
using test-requirements instead of doc/requirements
as announced on openstack list[1]. This commit
avoids that by creating a doc/requirements.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html

Change-Id: I2ee7ff82855e7e528808ecbb60fee598b740d83c
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/10/769210/6 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,e110b1ca43624bed3fc1a81a603a08fb53d48d4d,fix-docs-dep,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,6,3
openstack%2Fcloudkitty-tempest-plugin~master~I18fdf133b6c3ea9b60e784c0e1dfb7ce1217eda5,openstack/cloudkitty-tempest-plugin,master,I18fdf133b6c3ea9b60e784c0e1dfb7ce1217eda5,Add doc/requirements,MERGED,2021-01-05 13:08:05.000000000,2021-01-06 12:55:20.000000000,2021-01-06 12:55:20.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28356}]","[{'number': 1, 'created': '2021-01-05 13:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/b454f9bc16aee723e891b16941e889040f26f066', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug however it doesn't\nproduce any doc or releasenotes, but uniformization can't hurt and help\nus in the future.\n\n/!\\/!\\/!\\\nNotice that I voluntarily added the doc directory even if no docs\nare generated here because zuul will try to pull this requirements from\nthere first and the contained requirements are needed for reno but AFAIK\nthe releasenotes dir is ignored by zuul. c.f [4] for further details.\n/!\\/!\\/!\\\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I18fdf133b6c3ea9b60e784c0e1dfb7ce1217eda5\n""}, {'number': 2, 'created': '2021-01-05 16:40:03.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/72752c4cdbdb937ce8daddb2b43d551922b2e1c0', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug however it doesn't\nproduce any doc or releasenotes, but uniformization can't hurt and help\nus in the future.\n\n/!\\/!\\/!\\\nNotice that I voluntarily added the doc directory even if no docs\nare generated here because zuul will try to pull this requirements from\nthere first and the contained requirements are needed for reno but AFAIK\nthe releasenotes dir is ignored by zuul. c.f [4] for further details.\n/!\\/!\\/!\\\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I18fdf133b6c3ea9b60e784c0e1dfb7ce1217eda5\n""}]",0,769345,72752c4cdbdb937ce8daddb2b43d551922b2e1c0,11,3,2,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug however it doesn't
produce any doc or releasenotes, but uniformization can't hurt and help
us in the future.

/!\/!\/!\
Notice that I voluntarily added the doc directory even if no docs
are generated here because zuul will try to pull this requirements from
there first and the contained requirements are needed for reno but AFAIK
the releasenotes dir is ignored by zuul. c.f [4] for further details.
/!\/!\/!\

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I18fdf133b6c3ea9b60e784c0e1dfb7ce1217eda5
",git fetch https://review.opendev.org/openstack/cloudkitty-tempest-plugin refs/changes/45/769345/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt']",2,b454f9bc16aee723e891b16941e889040f26f066,fix-relmgt-pip-doc,"sphinx!=1.6.6,!=1.6.7,>=1.6.2 # BSD openstackdocstheme>=1.11.0 # Apache-2.0 reno>=1.8.0 # Apache-2.0 ",,3,4
openstack%2Ftripleo-quickstart-extras~master~I62768e9eaa9c2d483d5784a6e48d5346e56fb67e,openstack/tripleo-quickstart-extras,master,I62768e9eaa9c2d483d5784a6e48d5346e56fb67e,[WIP] Test --reverse-zone,ABANDONED,2020-09-29 11:38:57.000000000,2021-01-06 12:10:19.000000000,,"[{'_account_id': 9592}, {'_account_id': 9914}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29775}]","[{'number': 1, 'created': '2020-09-29 11:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9e7544ab35d91f04eba75b4881255f3dcd6a8282', 'message': '[WIP] Remove auto-reverse option from IPA server setup\n\nThe inclusion of --auto-reverse in the IPA server\ndeploy command is causing errors on certains clouds where\nthe zone being created already exists and is owned by\nsome other dns server.\n\nThis review removes the --auto-reverse to prevent\nerrors on these clouds.\n\nChange-Id: I62768e9eaa9c2d483d5784a6e48d5346e56fb67e\n'}, {'number': 2, 'created': '2020-09-29 13:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/17457f7dcb4082c4200503f263ec6e800fd41921', 'message': '[WIP] Test add allow-zone-overlap\n\nThe inclusion of --auto-reverse in the IPA server\ndeploy command is causing errors on certains clouds where\nthe zone being created already exists and is owned by\nsome other dns server.\n\nwe tried removal of --auto-reverse but because of this removal the reverse DNS lookup\nwon\'t work properly and undercloud install failed on TASK [Enroll to FreeIPA]\nwith below error:-\n\n~~~\nstderr_lines"": [""Unable to discover domain, not provided on command line"",\n~~~\n\nThis review add --allow-zone-overlap which should skip\nthe check for already existing reverse zones and create it.\n\nChange-Id: I62768e9eaa9c2d483d5784a6e48d5346e56fb67e\n'}, {'number': 3, 'created': '2020-10-06 09:23:47.000000000', 'files': ['zuul.d/layout.yaml', 'roles/freeipa-setup/templates/deploy_freeipa.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e8823f23205c48154cc538b37ed4de06d5f1a2a8', 'message': ""[WIP] Test --reverse-zone\n\nThe inclusion of --auto-reverse in the IPA server\ndeploy command is causing errors on certains clouds where\nthe zone being created already exists and is owned by\nsome other dns server.\n\nwe tried removal of --auto-reverse but because of this removal the reverse DNS lookup\nwon't work properly and undercloud install failed on TASK [Enroll to FreeIPA]\nwith below error:-\n\nChange-Id: I62768e9eaa9c2d483d5784a6e48d5346e56fb67e\n""}]",0,754979,e8823f23205c48154cc538b37ed4de06d5f1a2a8,14,6,3,29775,,,0,"[WIP] Test --reverse-zone

The inclusion of --auto-reverse in the IPA server
deploy command is causing errors on certains clouds where
the zone being created already exists and is owned by
some other dns server.

we tried removal of --auto-reverse but because of this removal the reverse DNS lookup
won't work properly and undercloud install failed on TASK [Enroll to FreeIPA]
with below error:-

Change-Id: I62768e9eaa9c2d483d5784a6e48d5346e56fb67e
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/79/754979/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/layout.yaml', 'roles/freeipa-setup/templates/deploy_freeipa.sh.j2']",2,9e7544ab35d91f04eba75b4881255f3dcd6a8282,,, --auto-reverse {{ ipa_server_install_params|default('') }},0,21
openstack%2Ftripleo-quickstart-extras~master~Iafcfe3725b5f639925bd171f46e7ac570855bcbb,openstack/tripleo-quickstart-extras,master,Iafcfe3725b5f639925bd171f46e7ac570855bcbb,DNM Multinode increased checks for debugging,ABANDONED,2020-06-04 16:39:51.000000000,2021-01-06 12:09:21.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-06-04 16:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/62e90f4073ff9936860e4d89ab6030571841fbd6', 'message': 'DNM Test patch\n\nChange-Id: Iafcfe3725b5f639925bd171f46e7ac570855bcbb\n'}, {'number': 2, 'created': '2020-06-09 01:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0fd117c9483cdb987a5d701f8fbac6eb3eae6209', 'message': 'DNM Multinode include_vars against undercloud\n\nChange-Id: Iafcfe3725b5f639925bd171f46e7ac570855bcbb\n'}, {'number': 3, 'created': '2020-06-15 09:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d1ef7b2d69d537807115fc739c01b91716f2b32b', 'message': 'DNM Multinode include_vars against undercloud\n\nChange-Id: Iafcfe3725b5f639925bd171f46e7ac570855bcbb\n'}, {'number': 4, 'created': '2020-06-17 13:13:18.000000000', 'files': ['playbooks/multinode-overcloud.yml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9404d51a7fb7b297c5e98a9090425411fafa8c20', 'message': 'DNM Multinode increased checks for debugging\n\nChange-Id: Iafcfe3725b5f639925bd171f46e7ac570855bcbb\n'}]",0,733658,9404d51a7fb7b297c5e98a9090425411fafa8c20,13,2,4,29775,,,0,"DNM Multinode increased checks for debugging

Change-Id: Iafcfe3725b5f639925bd171f46e7ac570855bcbb
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/58/733658/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/multinode-overcloud.yml', 'zuul.d/layout.yaml']",2,62e90f4073ff9936860e4d89ab6030571841fbd6,,, templates: - tripleo-undercloud-jobs - tripleo-multinode-container-full - tripleo-multinode-experimental - tripleo-multinode-branchful - release-notes-jobs-python3 - tripleo-standalone-scenarios-full - openstack-tox-molecule: required-projects: - openstack/tripleo-quickstart - tripleo-ci-centos-8-containers-undercloud-minion: files: - ^roles/.*minion.*$ - ^playbooks/.*minion.*$ - tripleo-ci-centos-8-standalone-on-multinode-ipa: files: - ^roles/.*multinode-ipa.*$ - ^roles/standalone.*$ - ^playbooks/multinode-standalone-ipa.yml.*$,11,20
openstack%2Ftripleo-ansible~master~I69c74c1869aa0f54c1695fd53098df7e78f64247,openstack/tripleo-ansible,master,I69c74c1869aa0f54c1695fd53098df7e78f64247,Add distribute_private_key boolean for tripleo_create_admin,MERGED,2020-12-23 19:22:00.000000000,2021-01-06 12:09:13.000000000,2021-01-06 12:09:13.000000000,"[{'_account_id': 6796}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2020-12-23 19:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/52be4d01589f81887fc6465164ed840f076959f6', 'message': ""Add distribute_private_key boolean for tripleo_create_admin\n\nAdd boolean option to distribute the private key which is\ncreated by the cli-enable-ssh-admin.yaml playbook and update\nthe tripleo_create_admin role to distribute the private key\nwhen it is true.\n\nThis option defaults to false as we normally don't want to\ndo this. However, cephadm needs a private key on all nodes\nwith the OS::TripleO::Services::CephMgr service in order to\nmanage a Ceph cluster. This option will likely only be used\nfor the ceph-admin user which is similar to but not the same\nas the tripleo-admin user.\n\nAlso, remove old reference to Mistral in task name.\n\nImplements: blueprint tripleo-ceph\nChange-Id: I69c74c1869aa0f54c1695fd53098df7e78f64247\n""}, {'number': 2, 'created': '2020-12-23 20:13:44.000000000', 'files': ['tripleo_ansible/roles/tripleo_create_admin/molecule/addkey/tests/test_keyadd.py', 'tripleo_ansible/roles/tripleo_create_admin/tasks/authorize_user.yml', 'tripleo_ansible/roles/tripleo_create_admin/defaults/main.yml', 'tripleo_ansible/roles/tripleo_create_admin/tasks/distribute_key_files.yml', 'tripleo_ansible/roles/tripleo_create_admin/tasks/main.yml', 'tripleo_ansible/playbooks/cli-enable-ssh-admin.yaml', 'tripleo_ansible/roles/tripleo_create_admin/molecule/addkey/converge.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/3d65bce9b3efdbadacee85b0593f4bdcf917528c', 'message': ""Add distribute_private_key boolean for tripleo_create_admin\n\nAdd boolean option to distribute the private key which is\ncreated by the cli-enable-ssh-admin.yaml playbook and update\nthe tripleo_create_admin role to distribute the private key\nwhen it is true.\n\nThis option defaults to false as we normally don't want to\ndo this. However, cephadm needs a private key on all nodes\nwith the OS::TripleO::Services::CephMgr service in order to\nmanage a Ceph cluster. This option will likely only be used\nfor the ceph-admin user which is similar to but not the same\nas the tripleo-admin user.\n\nAlso, remove old reference to Mistral in task name.\n\nImplements: blueprint tripleo-ceph\nChange-Id: I69c74c1869aa0f54c1695fd53098df7e78f64247\n""}]",1,768365,3d65bce9b3efdbadacee85b0593f4bdcf917528c,10,7,2,18002,,,0,"Add distribute_private_key boolean for tripleo_create_admin

Add boolean option to distribute the private key which is
created by the cli-enable-ssh-admin.yaml playbook and update
the tripleo_create_admin role to distribute the private key
when it is true.

This option defaults to false as we normally don't want to
do this. However, cephadm needs a private key on all nodes
with the OS::TripleO::Services::CephMgr service in order to
manage a Ceph cluster. This option will likely only be used
for the ceph-admin user which is similar to but not the same
as the tripleo-admin user.

Also, remove old reference to Mistral in task name.

Implements: blueprint tripleo-ceph
Change-Id: I69c74c1869aa0f54c1695fd53098df7e78f64247
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/65/768365/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_create_admin/molecule/addkey/tests/test_keyadd.py', 'tripleo_ansible/roles/tripleo_create_admin/tasks/authorize_user.yml', 'tripleo_ansible/roles/tripleo_create_admin/defaults/main.yml', 'tripleo_ansible/roles/tripleo_create_admin/tasks/main.yml', 'tripleo_ansible/roles/tripleo_create_admin/tasks/private_key.yml', 'tripleo_ansible/playbooks/cli-enable-ssh-admin.yaml', 'tripleo_ansible/roles/tripleo_create_admin/molecule/addkey/converge.yml']",7,52be4d01589f81887fc6465164ed840f076959f6,private_key, - import_role: name: tripleo_create_admin tasks_from: private_key.yml vars: tripleo_admin_user: tripleo-admin distribute_private_key: true tripleo_admin_prikey: '-----BEGIN OPENSSH PRIVATE KEY-----',,50,2
openstack%2Ftripleo-quickstart-extras~master~Ia9616b9c14d59ff382509086fcbf00f56a0701ea,openstack/tripleo-quickstart-extras,master,Ia9616b9c14d59ff382509086fcbf00f56a0701ea,Add doc/requirements,MERGED,2021-01-05 09:59:24.000000000,2021-01-06 12:08:36.000000000,2021-01-06 12:02:35.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 09:59:24.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/792f6216f659acd21a02a84ceb2c5d2972620b33', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: Ia9616b9c14d59ff382509086fcbf00f56a0701ea\n""}]",0,769303,792f6216f659acd21a02a84ceb2c5d2972620b33,9,2,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.
The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: Ia9616b9c14d59ff382509086fcbf00f56a0701ea
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/03/769303/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,792f6216f659acd21a02a84ceb2c5d2972620b33,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,6,4
openstack%2Ftripleo-common~stable%2Fussuri~I8616775584cf0216314109d21dabd32635293a27,openstack/tripleo-common,stable/ussuri,I8616775584cf0216314109d21dabd32635293a27,Fix ImportWarning during importing a module,MERGED,2020-12-25 20:13:54.000000000,2021-01-06 12:08:24.000000000,2021-01-06 12:02:30.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 32240}]","[{'number': 1, 'created': '2020-12-25 20:13:54.000000000', 'files': ['tripleo_common/utils/config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dd2d6fac24edc775c7031b2d6ff2e8f9b52f90bb', 'message': 'Fix ImportWarning during importing a module\n\nSet warnings category to filter only DeprecationWarnings\nand UserWarning\n\nCloses-Bug: #1889380\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I8616775584cf0216314109d21dabd32635293a27\n(cherry picked from commit c296d83eaa6edc9d14f76fc2995857f3646dac75)\n'}]",0,768407,dd2d6fac24edc775c7031b2d6ff2e8f9b52f90bb,11,6,1,14985,,,0,"Fix ImportWarning during importing a module

Set warnings category to filter only DeprecationWarnings
and UserWarning

Closes-Bug: #1889380
Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: I8616775584cf0216314109d21dabd32635293a27
(cherry picked from commit c296d83eaa6edc9d14f76fc2995857f3646dac75)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/07/768407/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/config.py'],1,dd2d6fac24edc775c7031b2d6ff2e8f9b52f90bb,bug/1889380-stable/ussuri,"warnings.filterwarnings('once', category=DeprecationWarning) warnings.filterwarnings('once', category=UserWarning)",warnings.filterwarnings('once'),2,1
openstack%2Ftripleo-heat-templates~master~Ic43c7ed464e1fde595790f2882cd36adfc7a38d1,openstack/tripleo-heat-templates,master,Ic43c7ed464e1fde595790f2882cd36adfc7a38d1,DNM Test https://review.opendev.org/#/c/724103,ABANDONED,2020-04-28 18:33:31.000000000,2021-01-06 12:08:24.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29775}]","[{'number': 1, 'created': '2020-04-28 18:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2b3d189494b59bdb54ed015e24586eba0e2d8bb9', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724103\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 2, 'created': '2020-04-28 18:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3bd3c3a172a1d5ee6d25e58bc8fff6b2588d85e9', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724103\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 3, 'created': '2020-04-29 08:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/166513cc8081247115f5f78a8153a80efb88c4ba', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724071/\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 4, 'created': '2020-04-29 11:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cd512ccc1f4be834694cdfbc35785365a76ef179', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724071/\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 5, 'created': '2020-04-29 11:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/846412897c39f1f833bea08ea7172814f124083d', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724071/\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 6, 'created': '2020-04-30 07:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f12d5d8a9459cff9f2b4e7099e9c585f3aee5ef3', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724071/\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 7, 'created': '2020-05-04 11:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/98da695892daed49051833facc2a5e2fd74da047', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724103\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}, {'number': 8, 'created': '2020-05-05 17:48:36.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/20a54a431f391e7b6576c267388d7795e81e7c32', 'message': 'DNM Test https://review.opendev.org/#/c/724103\n\nDepends-On: https://review.opendev.org/#/c/724103\nDepends-On: https://review.opendev.org/#/c/725659/\nChange-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1\n'}]",2,724119,20a54a431f391e7b6576c267388d7795e81e7c32,25,3,8,29775,,,0,"DNM Test https://review.opendev.org/#/c/724103

Depends-On: https://review.opendev.org/#/c/724103
Depends-On: https://review.opendev.org/#/c/725659/
Change-Id: Ic43c7ed464e1fde595790f2882cd36adfc7a38d1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/19/724119/8 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,2b3d189494b59bdb54ed015e24586eba0e2d8bb9,bug/1875681, - tripleo-ci-centos-8-scenario012-standalone:," templates: - tripleo-undercloud-jobs - tripleo-multinode-container-minimal - check-requirements - release-notes-jobs-python3 - tripleo-standalone-scenarios-full - openstack-python3-ussuri-jobs - openstack-tox-pep8 - openstack-tox-lower-constraints - tripleo-ci-centos-8-containers-multinode: dependencies: &deps_unit_lint - openstack-tox-pep8 - openstack-tox-tht - tripleo-ci-centos-7-undercloud-containers: dependencies: *deps_unit_lint - tripleo-ci-centos-8-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-7-standalone-upgrade-stein: dependencies: *deps_unit_lint - tripleo-ci-centos-7-scenario000-multinode-oooq-container-upgrades: dependencies: *deps_unit_lint - tripleo-ci-centos-7-scenario000-multinode-oooq-container-updates: dependencies: *deps_unit_lint files: - common/.*$ - ci/environments/scenario000-multinode-containers.yaml - ^ci/common/.*$ - ^deployed-server/.*$ - ^deployment/container-image-prepare/.*$ - ^(deployment|docker|puppet)/.*ca-certs.*$ - ^(deployment|docker|puppet)/.*clustercheck.*$ - ^(deployment|docker|puppet)/.*docker.*$ - ^(deployment|docker|puppet)/.*haproxy.*$ - ^(deployment|docker|puppet)/.*kernel.*$ - ^(deployment|docker|puppet)/.*keystone.*$ - ^(deployment|docker|puppet)/.*memcached.*$ - ^(deployment|docker|puppet)/.*mysql.*$ - ^(deployment|docker|puppet)/.*ntp.*$ - ^(deployment|docker|puppet)/.*pacemaker.*$ - ^(deployment|docker|puppet)/.*rabbitmq.*$ - ^(deployment|docker|puppet)/.*snmp.*$ - ^(deployment|docker|puppet)/.*timezone.*$ - ^(deployment|docker|puppet)/.*tripleo-packages.*$ - ^(deployment|docker|puppet)/.*tripleo-firewall.*$ - ^(deployment|docker|puppet)/.*sshd.*$ - ^environments\/.*.yaml - ^network/endpoints/.*$ - zuul.d/* - tripleo-ci-centos-7-scenario007-multinode-oooq-container: dependencies: *deps_unit_lint files: - ci/environments/scenario007-multinode-containers.yaml - ^(deployment|docker|puppet)/neutron-plugin-ml2.yaml #LP1765975 - ^(deployment|docker|puppet)/.*.*ovn.*$ - ^ci/common/.*$ - ^environments\/.*.yaml - ^deployed-server/.*$ - ^common/.*$ - zuul.d/* - tripleo-ci-centos-7-scenario010-multinode-oooq-container: dependencies: *deps_unit_lint files: - ^(deployment|docker|puppet)/.*octavia.*$ - ^deployment/ceph-ansible.*$ - ^deployment/octavia/*$ - ci/environments/scenario010-multinode-containers.yaml - ^ci/common/.*$ - ^environments\/.*.yaml - ^deployed-server/.*$ - ^network/endpoints/.*$ - ^common/.*$ - zuul.d/* - tripleo-ci-centos-8-scenario001-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario002-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario003-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario004-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario012-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-7-containerized-undercloud-upgrades: dependencies: *deps_unit_lint - tripleo-ci-centos-8-containers-undercloud-minion: dependencies: *deps_unit_lint - openstack-tox-tht gate: queue: tripleo jobs: - openstack-tox-lower-constraints - openstack-tox-pep8 - tripleo-ci-centos-7-scenario000-multinode-oooq-container-updates: files: - common/.*$ - ci/environments/scenario000-multinode-containers.yaml - ^ci/common/.*$ - ^deployed-server/.*$ - ^deployment/container-image-prepare/.*$ - ^(deployment|docker|puppet)/.*ca-certs.*$ - ^(deployment|docker|puppet)/.*clustercheck.*$ - ^(deployment|docker|puppet)/.*docker.*$ - ^(deployment|docker|puppet)/.*haproxy.*$ - ^(deployment|docker|puppet)/.*kernel.*$ - ^(deployment|docker|puppet)/.*keystone.*$ - ^(deployment|docker|puppet)/.*memcached.*$ - ^(deployment|docker|puppet)/.*mysql.*$ - ^(deployment|docker|puppet)/.*ntp.*$ - ^(deployment|docker|puppet)/.*pacemaker.*$ - ^(deployment|docker|puppet)/.*rabbitmq.*$ - ^(deployment|docker|puppet)/.*snmp.*$ - ^(deployment|docker|puppet)/.*timezone.*$ - ^(deployment|docker|puppet)/.*tripleo-packages.*$ - ^(deployment|docker|puppet)/.*tripleo-firewall.*$ - ^(deployment|docker|puppet)/.*sshd.*$ - ^environments\/.*.yaml - ^network/endpoints/.*$ - zuul.d/* experimental: jobs: - tripleo-ci-centos-7-scenario011-multinode-oooq-container: files: - ci/environments/scenario011-multinode-containers.yaml - ^(deployment|docker|puppet)/.*ironic.*$ - ^environments\/.*ironic.*$ - job: name: openstack-tox-tht parent: openstack-tox description: Runs syntax tht tests. Uses tox with the ``tht`` environment. success-url: ""reports.html"" failure-url: ""reports.html"" voting: true vars: tox_envlist: tht bindep_profile: test tht test_setup_skip: true",0,135
openstack%2Ftripleo-quickstart-extras~master~Ie64ce994d8985838a6677b84a1f07c1bc7e7876b,openstack/tripleo-quickstart-extras,master,Ie64ce994d8985838a6677b84a1f07c1bc7e7876b,[dnm] tripleo_deploy_control_virtual_ip testing,ABANDONED,2020-07-28 06:31:09.000000000,2021-01-06 12:07:17.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-07-28 06:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/eff4f685288a3f64993114de0b9baf1e4272a75b', 'message': '[dnm] Patch to test container build locally\n\nChange-Id: Ie64ce994d8985838a6677b84a1f07c1bc7e7876b\n'}, {'number': 2, 'created': '2020-08-19 03:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f7cd0a1387288350883aa378ace8f5f1b41388e3', 'message': '[dnm] tripleo_deploy_control_virtual_ip testing\n\nChange-Id: Ie64ce994d8985838a6677b84a1f07c1bc7e7876b\n'}, {'number': 3, 'created': '2020-08-19 03:11:42.000000000', 'files': ['roles/standalone/tasks/main.yml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7b0b83d1abf899dfe6b67e731c443e7ef6518c68', 'message': '[dnm] tripleo_deploy_control_virtual_ip testing\n\nChange-Id: Ie64ce994d8985838a6677b84a1f07c1bc7e7876b\n'}]",1,743464,7b0b83d1abf899dfe6b67e731c443e7ef6518c68,11,3,3,29775,,,0,"[dnm] tripleo_deploy_control_virtual_ip testing

Change-Id: Ie64ce994d8985838a6677b84a1f07c1bc7e7876b
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/64/743464/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/standalone/tasks/main.yml'],1,eff4f685288a3f64993114de0b9baf1e4272a75b,,, when: - job.build_container_images|default(false)|bool,0,2
openstack%2Ftripleo-quickstart-extras~master~I7ec6cce0f6e3a79ad2b5dd3ba22e819448b00fa6,openstack/tripleo-quickstart-extras,master,I7ec6cce0f6e3a79ad2b5dd3ba22e819448b00fa6,[wip] Create /usr/share/rhn/ if it don't exists,ABANDONED,2020-12-14 17:24:39.000000000,2021-01-06 12:04:57.000000000,,"[{'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-14 17:24:39.000000000', 'files': ['roles/build-test-packages/tasks/dlrn-build.yml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e11d65697db3db805d111848bd95eb3a1328f30c', 'message': ""[wip] Create /usr/share/rhn/ if it don't exists\n\nbuild-test-packages in downstream is failing with below error:-\n~~~\ntouch: cannot touch '/usr/share/rhn/RHN-ORG-TRUSTED-SSL-CERT': No such file or directory\n~~~\n\nWith this patch, Creating /usr/share/rhn/ dir if it don't exists\n\nChange-Id: I7ec6cce0f6e3a79ad2b5dd3ba22e819448b00fa6\n""}]",0,766998,e11d65697db3db805d111848bd95eb3a1328f30c,6,3,1,29775,,,0,"[wip] Create /usr/share/rhn/ if it don't exists

build-test-packages in downstream is failing with below error:-
~~~
touch: cannot touch '/usr/share/rhn/RHN-ORG-TRUSTED-SSL-CERT': No such file or directory
~~~

With this patch, Creating /usr/share/rhn/ dir if it don't exists

Change-Id: I7ec6cce0f6e3a79ad2b5dd3ba22e819448b00fa6
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/98/766998/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/build-test-packages/tasks/dlrn-build.yml', 'zuul.d/layout.yaml']",2,e11d65697db3db805d111848bd95eb3a1328f30c,,, templates: - tripleo-undercloud-jobs-pipeline - tripleo-multinode-container-full-pipeline - tripleo-multinode-branchful - release-notes-jobs-python3 - tripleo-standalone-scenarios-pipeline - tripleo-standalone-multinode-ipa-pipeline - openstack-tox-molecule: required-projects: - openstack/tripleo-quickstart - tripleo-ci-centos-8-containers-undercloud-minion: vars: consumer_job: true remove_tags: - build dependencies: - tripleo-ci-centos-8-content-provider files: - ^roles/.*minion.*$ - ^playbooks/.*minion.*$ - tripleo-ci-centos-8-standalone-on-multinode-ipa: vars: consumer_job: true build_container_images: false remove_tags: - build dependencies: - tripleo-ci-centos-8-content-provider files: - ^roles/ipa-multinode.*$ - ^roles/standalone.*$ - ^playbooks/multinode-standalone-ipa.yml.*$,1,32
openstack%2Ftripleo-ci~master~I49c783d4bcf03181f23d8ccc72d8f8ca3d0ceb47,openstack/tripleo-ci,master,I49c783d4bcf03181f23d8ccc72d8f8ca3d0ceb47,Remove train from the multinode-ipa job,MERGED,2020-12-31 19:57:41.000000000,2021-01-06 12:02:39.000000000,2021-01-06 12:02:39.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9914}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-31 19:57:41.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e660bd9f7f6606daaed613c5c530419085f1bf60', 'message': 'Remove train from the multinode-ipa job\n\nTrain has never passed on this job. Remove\nthe branch from where this job runs.\n\nChange-Id: I49c783d4bcf03181f23d8ccc72d8f8ca3d0ceb47\n'}]",0,768809,e660bd9f7f6606daaed613c5c530419085f1bf60,26,6,1,9976,,,0,"Remove train from the multinode-ipa job

Train has never passed on this job. Remove
the branch from where this job runs.

Change-Id: I49c783d4bcf03181f23d8ccc72d8f8ca3d0ceb47
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/09/768809/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,e660bd9f7f6606daaed613c5c530419085f1bf60,remove-train-multiode-ipa, branches: ^(?!stable/(newton|ocata|pike|queens|rocky|stein|train)).*$, branches: ^(?!stable/(newton|ocata|pike|queens|rocky|stein)).*$,1,1
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I69fa208d160f1ae2cb2cc252d9b7852ada9e96f0,openstack/tripleo-heat-templates,stable/victoria,I69fa208d160f1ae2cb2cc252d9b7852ada9e96f0,Add 'networks_all' ansible group_var,MERGED,2020-12-16 22:41:31.000000000,2021-01-06 12:00:25.000000000,2021-01-06 12:00:25.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-16 22:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/afbdfb6e2d52ef2e4296eafecdc47b5e00249533', 'message': ""Add 'networks_all' ansible group_var\n\nAdd a group_var carrying all enabled overcloud\nnetworks. The multi-nic templates should iterate\nover all the networks in the order they apper in\nnetwork_data.yaml to allow maintaining the\nnetwork to nicX contract that existed in the Heat\nmulit-nic config templates.\n\nChange-Id: I69fa208d160f1ae2cb2cc252d9b7852ada9e96f0\nRelated-Bug: #1904894\n(cherry picked from commit fe275dd918169eb6090da0cf4a9a2c17da3227c7)\n""}, {'number': 2, 'created': '2020-12-18 05:26:14.000000000', 'files': ['overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dd1cba373c252b4170f646c7bf66952341d6bad7', 'message': ""Add 'networks_all' ansible group_var\n\nAdd a group_var carrying all enabled overcloud\nnetworks. The multi-nic templates should iterate\nover all the networks in the order they apper in\nnetwork_data.yaml to allow maintaining the\nnetwork to nicX contract that existed in the Heat\nmulit-nic config templates.\n\nChange-Id: I69fa208d160f1ae2cb2cc252d9b7852ada9e96f0\nRelated-Bug: #1904894\n(cherry picked from commit fe275dd918169eb6090da0cf4a9a2c17da3227c7)\n""}]",0,767330,dd1cba373c252b4170f646c7bf66952341d6bad7,13,3,2,24245,,,0,"Add 'networks_all' ansible group_var

Add a group_var carrying all enabled overcloud
networks. The multi-nic templates should iterate
over all the networks in the order they apper in
network_data.yaml to allow maintaining the
network to nicX contract that existed in the Heat
mulit-nic config templates.

Change-Id: I69fa208d160f1ae2cb2cc252d9b7852ada9e96f0
Related-Bug: #1904894
(cherry picked from commit fe275dd918169eb6090da0cf4a9a2c17da3227c7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/767330/2 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.j2.yaml'],1,afbdfb6e2d52ef2e4296eafecdc47b5e00249533,bug/1904894-stable/victoria, networks_all: {%- for network in networks if network.enabled|default(true) %} - {{network.name}} {%- endfor %},,4,0
openstack%2Fopenstack-ansible~stable%2Fvictoria~I05512c5aa5dd32993405f91523e0e5f90a870b27,openstack/openstack-ansible,stable/victoria,I05512c5aa5dd32993405f91523e0e5f90a870b27,Bump ansible version to 2.10.4,MERGED,2021-01-04 21:13:01.000000000,2021-01-06 11:43:58.000000000,2021-01-06 11:42:00.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-04 21:13:01.000000000', 'files': ['scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/adac359d40b6b6e2c989df5ad396f39b597f3d1c', 'message': 'Bump ansible version to 2.10.4\n\nChange-Id: I05512c5aa5dd32993405f91523e0e5f90a870b27\n(cherry picked from commit 1d7e892b07ee7d0c3719e11c352f1bddef985309)\n'}]",0,769183,adac359d40b6b6e2c989df5ad396f39b597f3d1c,12,3,1,25023,,,0,"Bump ansible version to 2.10.4

Change-Id: I05512c5aa5dd32993405f91523e0e5f90a870b27
(cherry picked from commit 1d7e892b07ee7d0c3719e11c352f1bddef985309)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/83/769183/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/bootstrap-ansible.sh'],1,adac359d40b6b6e2c989df5ad396f39b597f3d1c,,"export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible-base==2.10.4""}","export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible-base==2.10.3""}",1,1
openstack%2Fpython-openstackclient~master~I2f2033a8d49ee42eb21696a9cd28e63ad9712fad,openstack/python-openstackclient,master,I2f2033a8d49ee42eb21696a9cd28e63ad9712fad,trivial: Cleanup docs for 'server list',MERGED,2020-12-03 18:12:39.000000000,2021-01-06 11:43:40.000000000,2021-01-06 11:41:12.000000000,"[{'_account_id': 9708}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2020-12-03 18:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/88d016ea30bb76a678ce61e5c7fb8f8039293e97', 'message': ""trivial: Cleanup docs for 'server list'\n\nChange-Id: I2f2033a8d49ee42eb21696a9cd28e63ad9712fad\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2020-12-07 18:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/903fa027d7d1971849a2793b6aee64e45d80e4d2', 'message': ""trivial: Cleanup docs for 'server list'\n\nChange-Id: I2f2033a8d49ee42eb21696a9cd28e63ad9712fad\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2020-12-08 16:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7182fa94daaf4fd3bdecb5eb045a5bf8e65221a7', 'message': ""trivial: Cleanup docs for 'server list'\n\nChange-Id: I2f2033a8d49ee42eb21696a9cd28e63ad9712fad\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2020-12-09 18:39:23.000000000', 'files': ['openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/054562238d31757b023da9a6a566f7970527ca4c', 'message': ""trivial: Cleanup docs for 'server list'\n\nChange-Id: I2f2033a8d49ee42eb21696a9cd28e63ad9712fad\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,765361,054562238d31757b023da9a6a566f7970527ca4c,22,3,4,15334,,,0,"trivial: Cleanup docs for 'server list'

Change-Id: I2f2033a8d49ee42eb21696a9cd28e63ad9712fad
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/61/765361/4 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/server.py'],1,88d016ea30bb76a678ce61e5c7fb8f8039293e97,osc-first," help=_( 'Regular expression to match IPv6 addresses. Note ' 'that this option only applies for non-admin users ' 'when using ``--os-compute-api-version`` 2.5 or greater.' ), '--deleted', action='store_true', default=False, help=_('Only display deleted servers (admin only)'), ) parser.add_argument( help=_( 'Skip flavor and image name lookup. ' 'Mutually exclusive with ""--name-lookup-one-by-one"" option.' ), help=_( 'When looking up flavor and image names, look them up' 'one by one as needed instead of all together (default). ' 'Mutually exclusive with ""--no-name-lookup|-n"" option.' ), help=_( 'The last server of the previous page. Display ' 'list of servers after marker. Display all servers if not ' 'specified. When used with ``--deleted``, the marker must ' 'be an ID, otherwise a name or ID can be used.' ), help=_( ""Maximum number of servers to display. If limit equals -1, "" ""all servers will be displayed. If limit is greater than "" ""'osapi_max_limit' option of Nova API, "" ""'osapi_max_limit' will be used instead."" ), help=_( ""List only servers changed before a certain point of time. "" ""The provided time should be an ISO 8061 formatted time "" ""(e.g., 2016-03-05T06:27:59Z). "" '(supported by --os-compute-api-version 2.66 or above)' ), help=_( ""List only servers changed after a certain point of time. "" ""The provided time should be an ISO 8061 formatted time "" ""(e.g., 2016-03-04T06:27:59Z)."" ), help=_( 'Only display locked servers ' '(supported by --os-compute-api-version 2.73 or above)' ), help=_( 'Only display unlocked servers ' '(supported by --os-compute-api-version 2.73 or above)' ), if parsed_args.locked: if compute_client.api_version < api_versions.APIVersion('2.73'): msg = _( '--os-compute-api-version 2.73 or greater is required to ' 'support the --locked option' ) raise exceptions.CommandError(msg) search_opts['locked'] = True elif parsed_args.unlocked: if compute_client.api_version < api_versions.APIVersion('2.73'): msg = _( '--os-compute-api-version 2.73 or greater is required to ' 'support the --unlocked option' ) raise exceptions.CommandError(msg) search_opts['locked'] = False table = ( column_headers, ( utils.get_item_properties( s, columns, mixed_case_fields=mixed_case_fields, formatters={ 'OS-EXT-STS:power_state': _format_servers_list_power_state, 'Networks': _format_servers_list_networks, 'Metadata': utils.format_dict, }, ) for s in data ), )"," help=_('Regular expression to match IPv6 addresses. Note ' 'that this option only applies for non-admin users ' 'when using ``--os-compute-api-version`` 2.5 or greater.'), help=_('Skip flavor and image name lookup.' 'Mutually exclusive with ""--name-lookup-one-by-one""' ' option.'), help=_('When looking up flavor and image names, look them up' 'one by one as needed instead of all together (default). ' 'Mutually exclusive with ""--no-name-lookup|-n"" option.'), help=_('The last server of the previous page. Display ' 'list of servers after marker. Display all servers if not ' 'specified. When used with ``--deleted``, the marker must ' 'be an ID, otherwise a name or ID can be used.'), help=_(""Maximum number of servers to display. If limit equals -1, "" ""all servers will be displayed. If limit is greater than "" ""'osapi_max_limit' option of Nova API, "" ""'osapi_max_limit' will be used instead.""), ) parser.add_argument( '--deleted', action=""store_true"", default=False, help=_('Only display deleted servers (Admin only).') help=_(""List only servers changed before a certain point of time. "" ""The provided time should be an ISO 8061 formatted time "" ""(e.g., 2016-03-05T06:27:59Z). "" ""(Supported by API versions '2.66' - '2.latest')"") help=_(""List only servers changed after a certain point of time."" "" The provided time should be an ISO 8061 formatted time"" "" (e.g., 2016-03-04T06:27:59Z)."") help=_('Only display locked servers. ' 'Requires ``--os-compute-api-version`` 2.73 or greater.'), help=_('Only display unlocked servers. ' 'Requires ``--os-compute-api-version`` 2.73 or greater.'), support_locked = (compute_client.api_version >= api_versions.APIVersion('2.73')) if not support_locked and (parsed_args.locked or parsed_args.unlocked): msg = _('--os-compute-api-version 2.73 or greater is required to ' 'use the (un)locked filter option.') raise exceptions.CommandError(msg) elif support_locked: # Only from 2.73. if parsed_args.locked: search_opts['locked'] = True if parsed_args.unlocked: search_opts['locked'] = False table = (column_headers, (utils.get_item_properties( s, columns, mixed_case_fields=mixed_case_fields, formatters={ 'OS-EXT-STS:power_state': _format_servers_list_power_state, 'Networks': _format_servers_list_networks, 'Metadata': utils.format_dict, }, ) for s in data))",85,57
openstack%2Fpython-tripleoclient~stable%2Fvictoria~Id94132d23d272d383b65a839a75b08f855fb6be3,openstack/python-tripleoclient,stable/victoria,Id94132d23d272d383b65a839a75b08f855fb6be3,[Validator Show Run] Display simplified results by default,MERGED,2020-11-02 14:55:33.000000000,2021-01-06 11:43:29.000000000,2021-01-06 11:40:24.000000000,"[{'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-11-02 14:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3a03fc6ea2c40bb537695317c617b34e2fbb4d33', 'message': '[Validator Show Run] Display simplified results by default\n\nThis patch is displaying the content of the validation_output dictionary\nwhich is a simplified output content (the former validation_output)\ninstead of dumping the entire log file in the stdout.\n\nIt also fixes the --full argument which was True forever!\n\nChange-Id: Id94132d23d272d383b65a839a75b08f855fb6be3\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n(cherry picked from commit 4229bee94016ad5a78dd8455f282a8e7f4a3d28e)\n'}, {'number': 2, 'created': '2021-01-05 16:49:39.000000000', 'files': ['tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/7873e6d800d75119730c7cd8ff1152fe08aa1c49', 'message': '[Validator Show Run] Display simplified results by default\n\nThis patch is displaying the content of the validation_output dictionary\nwhich is a simplified output content (the former validation_output)\ninstead of dumping the entire log file in the stdout.\n\nIt also fixes the --full argument which was True forever!\n\nChange-Id: Id94132d23d272d383b65a839a75b08f855fb6be3\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n(cherry picked from commit 4229bee94016ad5a78dd8455f282a8e7f4a3d28e)\n'}]",0,760935,7873e6d800d75119730c7cd8ff1152fe08aa1c49,22,5,2,11491,,,0,"[Validator Show Run] Display simplified results by default

This patch is displaying the content of the validation_output dictionary
which is a simplified output content (the former validation_output)
instead of dumping the entire log file in the stdout.

It also fixes the --full argument which was True forever!

Change-Id: Id94132d23d272d383b65a839a75b08f855fb6be3
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
(cherry picked from commit 4229bee94016ad5a78dd8455f282a8e7f4a3d28e)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/35/760935/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_validator.py'],1,3a03fc6ea2c40bb537695317c617b34e2fbb4d33,validator_show_run/validation_output-stable/victoria," for p in d.get('validation_output', []): print(json.dumps(p['tasks'], indent=4, sort_keys=True))"," default=True, for p in d['plays']: print(json.dumps(p['tasks'], indent=4, sort_keys=True))",4,3
openstack%2Fcloudkitty~master~I6bdfa9830a32ecf36e1931e1bb0afa366f1dfeb9,openstack/cloudkitty,master,I6bdfa9830a32ecf36e1931e1bb0afa366f1dfeb9,Add doc/requirements,MERGED,2021-01-05 13:00:11.000000000,2021-01-06 11:43:28.000000000,2021-01-06 11:40:02.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28356}, {'_account_id': 32238}]","[{'number': 1, 'created': '2021-01-05 13:00:11.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b0d5e455fc71028388908c64d80ae36a4d153030', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I6bdfa9830a32ecf36e1931e1bb0afa366f1dfeb9\n""}]",0,769344,b0d5e455fc71028388908c64d80ae36a4d153030,9,4,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I6bdfa9830a32ecf36e1931e1bb0afa366f1dfeb9
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/44/769344/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,b0d5e455fc71028388908c64d80ae36a4d153030,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,10,7
openstack%2Fpython-openstackclient~master~I61c46e18bef1f086b62a015ebdc56be91071b826,openstack/python-openstackclient,master,I61c46e18bef1f086b62a015ebdc56be91071b826,compute: Add missing options for 'server rebuild',MERGED,2020-12-03 18:12:39.000000000,2021-01-06 11:32:34.000000000,2021-01-06 11:30:53.000000000,"[{'_account_id': 9708}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2020-12-03 18:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8899ead560b996087029d72ad7e528b75e747d65', 'message': ""compute: Add missing options for 'server rebuild'\n\nThis accepts a large number of options that we weren't exposing. Add the\nfollowing options: '--name', '--preserve-ephemeral', '--user-data',\n'--no-user-data', '--trusted-image-cert' and '--no-trusted-image-certs'.\nIn addition, rename the '--key-unset' parameter to '--no-key-name', to\nmimic e.g. '--no-property' on other commands.\n\nChange-Id: I61c46e18bef1f086b62a015ebdc56be91071b826\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2020-12-07 18:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2f6c9280b75e4f5d4be2cfe576812f4e3cb0dd29', 'message': ""compute: Add missing options for 'server rebuild'\n\nThis accepts a large number of options that we weren't exposing. Add the\nfollowing options: '--name', '--preserve-ephemeral', '--user-data',\n'--no-user-data', '--trusted-image-cert' and '--no-trusted-image-certs'.\nIn addition, rename the '--key-unset' parameter to '--no-key-name', to\nmimic e.g. '--no-property' on other commands.\n\nChange-Id: I61c46e18bef1f086b62a015ebdc56be91071b826\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2020-12-08 16:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/859f6dae199c68ea78ae9e83257801dd8390c2dd', 'message': ""compute: Add missing options for 'server rebuild'\n\nThis accepts a large number of options that we weren't exposing. Add the\nfollowing options: '--name', '--preserve-ephemeral', '--user-data',\n'--no-user-data', '--trusted-image-cert' and '--no-trusted-image-certs'.\nIn addition, rename the '--key-unset' parameter to '--no-key-name', to\nmimic e.g. '--no-property' on other commands.\n\nChange-Id: I61c46e18bef1f086b62a015ebdc56be91071b826\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2020-12-09 18:39:23.000000000', 'files': ['releasenotes/notes/add-missing-server-rebuild-opts-5c75e838d8f0487d.yaml', 'openstackclient/tests/unit/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f9fd3642f8e8c59cd5a819e260d0575f884ae174', 'message': ""compute: Add missing options for 'server rebuild'\n\nThis accepts a large number of options that we weren't exposing. Add the\nfollowing options: '--name', '--preserve-ephemeral', '--user-data',\n'--no-user-data', '--trusted-image-cert' and '--no-trusted-image-certs'.\nIn addition, rename the '--key-unset' parameter to '--no-key-name', to\nmimic e.g. '--no-property' on other commands.\n\nChange-Id: I61c46e18bef1f086b62a015ebdc56be91071b826\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",2,765360,f9fd3642f8e8c59cd5a819e260d0575f884ae174,20,3,4,15334,,,0,"compute: Add missing options for 'server rebuild'

This accepts a large number of options that we weren't exposing. Add the
following options: '--name', '--preserve-ephemeral', '--user-data',
'--no-user-data', '--trusted-image-cert' and '--no-trusted-image-certs'.
In addition, rename the '--key-unset' parameter to '--no-key-name', to
mimic e.g. '--no-property' on other commands.

Change-Id: I61c46e18bef1f086b62a015ebdc56be91071b826
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/60/765360/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-missing-server-rebuild-opts-5c75e838d8f0487d.yaml', 'openstackclient/tests/unit/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py']",3,8899ead560b996087029d72ad7e528b75e747d65,osc-first," '--name', metavar='<name>', help=_('Set the new name of the rebuilt server'), ) parser.add_argument( help=_('Set the password on the rebuilt server'), preserve_ephemeral_group = parser.add_mutually_exclusive_group() preserve_ephemeral_group.add_argument( '--preserve-ephemeral', action='store_true', default=None, help=_( 'Preserve the default ephemeral storage partition on rebuild.' ), ) preserve_ephemeral_group.add_argument( '--no-preserve-ephemeral', action='store_false', dest='preserve_ephemeral', help=_( 'Do not preserve the default ephemeral storage partition on ' 'rebuild.' ), ) '--no-key-name', dest='no_key_name', # TODO(stephenfin): Remove this in a future major version bump key_group.add_argument( '--key-unset', action='store_true', dest='no_key_name', help=argparse.SUPPRESS, ) user_data_group = parser.add_mutually_exclusive_group() user_data_group.add_argument( '--user-data', metavar='<user-data>', help=_( 'Add a new user data file to the rebuilt server. ' 'Cannot be specified with the --no-user-data option. ' '(supported by --os-compute-api-version 2.57 or above)' ), ) user_data_group.add_argument( '--no-user-data', action='store_true', default=False, help=_( 'Remove existing user data when rebuilding server. ' 'Cannot be specified with the --user-data option. ' '(supported by --os-compute-api-version 2.57 or above)' ), ) trusted_certs_group = parser.add_mutually_exclusive_group() trusted_certs_group.add_argument( '--trusted-image-cert', metavar='<trusted-cert-id>', action='append', dest='trusted_image_certs', help=_( 'Trusted image certificate IDs used to validate certificates ' 'during the image signature verification process. ' 'Defaults to env[OS_TRUSTED_IMAGE_CERTIFICATE_IDS]. ' 'May be specified multiple times to pass multiple trusted ' 'image certificate IDs. ' 'Cannot be specified with the --no-trusted-certs option. ' '(supported by --os-compute-api-version 2.63 or above)' ), ) trusted_certs_group.add_argument( '--no-trusted-image-certs', action='store_true', default=False, help=_( 'Remove any existing trusted image certificates from the ' 'server. ' 'Cannot be specified with the --trusted-certs option. ' '(supported by --os-compute-api-version 2.63 or above)' ), ) if parsed_args.name is not None: kwargs['name'] = parsed_args.name if parsed_args.preserve_ephemeral is not None: kwargs['preserve_ephemeral'] = parsed_args.preserve_ephemeral if compute_client.api_version < api_versions.APIVersion('2.19'): elif parsed_args.no_key_name: userdata = None if parsed_args.user_data: if compute_client.api_version < api_versions.APIVersion('2.54'): msg = _( '--os-compute-api-version 2.54 or greater is required to ' 'support the --user-data option' ) raise exceptions.CommandError(msg) try: userdata = io.open(parsed_args.user_data) except IOError as e: msg = _(""Can't open '%(data)s': %(exception)s"") raise exceptions.CommandError( msg % {'data': parsed_args.user_data, 'exception': e} ) kwargs['userdata'] = userdata elif parsed_args.no_user_data: if compute_client.api_version < api_versions.APIVersion('2.54'): msg = _( '--os-compute-api-version 2.54 or greater is required to ' 'support the --no-user-data option' ) raise exceptions.CommandError(msg) kwargs['userdata'] = None # TODO(stephenfin): Handle OS_TRUSTED_IMAGE_CERTIFICATE_IDS if parsed_args.trusted_image_certs: if compute_client.api_version < api_versions.APIVersion('2.63'): msg = _( '--os-compute-api-version 2.63 or greater is required to ' 'support the --trusted-certs option' ) raise exceptions.CommandError(msg) certs = parsed_args.trusted_image_certs kwargs['trusted_image_certificates'] = certs elif parsed_args.no_trusted_image_certs: if compute_client.api_version < api_versions.APIVersion('2.63'): msg = _( '--os-compute-api-version 2.63 or greater is required to ' 'support the --no-trusted-certs option' ) raise exceptions.CommandError(msg) kwargs['trusted_image_certificates'] = None try: server = server.rebuild(image, parsed_args.password, **kwargs) finally: if userdata and hasattr(userdata, 'close'): userdata.close() "," help=_('Set a password on the rebuilt server'), '--key-unset', default=False, if server.api_version < api_versions.APIVersion(""2.19""): elif parsed_args.key_unset: server = server.rebuild(image, parsed_args.password, **kwargs)",455,83
openstack%2Fopenstack-manuals~master~I2c1d22274436c5902145c60de2fec9146f313c43,openstack/openstack-manuals,master,I2c1d22274436c5902145c60de2fec9146f313c43,Add Victoria version installation for Ubuntu 20.04,MERGED,2020-12-24 20:06:58.000000000,2021-01-06 11:28:37.000000000,2021-01-06 11:13:07.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-24 20:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cbd5701b2812fecbba98d129e3773ac848ebfbb7', 'message': 'Add Victoria version installation for Ubuntu 20.04\n\nAs the official Ubuntu wiki[1], victoria cloud-archive is available\nfor Ubuntu 20.04LTS and the wiki shows how to use it.\nIn addition, I confirmed it works locally.\nThis adds the description for the installation guide.\n\n[1]: https://wiki.ubuntu.com/OpenStack/CloudArchive\n\nChange-Id: I2c1d22274436c5902145c60de2fec9146f313c43\n'}, {'number': 2, 'created': '2021-01-04 17:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/376ccb7147557380ac3cf1d457ac129e39e25055', 'message': 'Add Victoria version installation for Ubuntu 20.04\n\nAs the official Ubuntu wiki[1], victoria cloud-archive is available\nfor Ubuntu 20.04LTS and the wiki shows how to use it.\nIn addition, I confirmed it works locally.\nThis adds the description for the installation guide.\n\n[1]: https://wiki.ubuntu.com/OpenStack/CloudArchive\n\nChange-Id: I2c1d22274436c5902145c60de2fec9146f313c43\n'}, {'number': 3, 'created': '2021-01-04 23:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b262badd5761c3e1c5f461ba30812d6752f69562', 'message': 'Add Victoria version installation for Ubuntu 20.04\n\nAs the official Ubuntu wiki[1], victoria cloud-archive is available\nfor Ubuntu 20.04LTS and the wiki shows how to use it.\nIn addition, I confirmed it works locally.\nThis adds the description for the installation guide.\n\n[1]: https://wiki.ubuntu.com/OpenStack/CloudArchive\n\nChange-Id: I2c1d22274436c5902145c60de2fec9146f313c43\n'}, {'number': 4, 'created': '2021-01-06 00:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f8483fb2a224e9f59a65d239eddc82fcdc0139ce', 'message': 'Add Victoria version installation for Ubuntu 20.04\n\nAs the official Ubuntu wiki[1], victoria cloud-archive is available\nfor Ubuntu 20.04LTS and the wiki shows how to use it.\nIn addition, I confirmed it works locally.\nThis adds the description for the installation guide.\n\n[1]: https://wiki.ubuntu.com/OpenStack/CloudArchive\n\nChange-Id: I2c1d22274436c5902145c60de2fec9146f313c43\n'}, {'number': 5, 'created': '2021-01-06 10:33:35.000000000', 'files': ['doc/install-guide/source/preface.rst', 'doc/install-guide/source/environment-packages-ubuntu.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e8f20aad7a0618a766e8c17ec30d7e4d96019b64', 'message': 'Add Victoria version installation for Ubuntu 20.04\n\nAs the official Ubuntu wiki[1], victoria cloud-archive is available\nfor Ubuntu 20.04LTS and the wiki shows how to use it.\nIn addition, I confirmed it works locally.\nThis adds the description for the installation guide.\n\n[1]: https://wiki.ubuntu.com/OpenStack/CloudArchive\n\nChange-Id: I2c1d22274436c5902145c60de2fec9146f313c43\n'}]",4,768484,e8f20aad7a0618a766e8c17ec30d7e4d96019b64,19,2,5,6167,,,0,"Add Victoria version installation for Ubuntu 20.04

As the official Ubuntu wiki[1], victoria cloud-archive is available
for Ubuntu 20.04LTS and the wiki shows how to use it.
In addition, I confirmed it works locally.
This adds the description for the installation guide.

[1]: https://wiki.ubuntu.com/OpenStack/CloudArchive

Change-Id: I2c1d22274436c5902145c60de2fec9146f313c43
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/768484/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/environment-packages-ubuntu.rst'],1,cbd5701b2812fecbba98d129e3773ac848ebfbb7,ubuntu2004,**OpenStack Victoria for Ubuntu 20.04 LTS:** .. code-block:: console # add-apt-repository cloud-archive:victoria **OpenStack Victoria/Stein for Ubuntu 20.04/18.04 LTS:**, **OpenStack Stein for Ubuntu 18.04 LTS:**,7,1
openstack%2Fpython-openstackclient~master~Ib3f0bdf419675e1c35c3406fbac8a4c18ac56a33,openstack/python-openstackclient,master,Ib3f0bdf419675e1c35c3406fbac8a4c18ac56a33,"Add 'flavor list --min-disk', '--min-ram' options",MERGED,2020-10-14 09:51:24.000000000,2021-01-06 11:20:02.000000000,2021-01-06 11:16:49.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2020-10-14 09:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cc0a9dcab91a7089f4080e2c01d9a9139953a37d', 'message': ""Add 'flavor list --min-disk', '--min-ram' options\n\nAllow us to filter on minimum disk and RAM, and close another gap with\nnovaclient.\n\nChange-Id: Ib3f0bdf419675e1c35c3406fbac8a4c18ac56a33\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2020-12-09 15:29:02.000000000', 'files': ['openstackclient/compute/v2/flavor.py', 'openstackclient/tests/unit/compute/v2/test_flavor.py', 'releasenotes/notes/flavor-list-min-disk-min-ram-65ba35e7acc24134.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/da03bd80e3b83faf465f1446c4553c5d97b5bad5', 'message': ""Add 'flavor list --min-disk', '--min-ram' options\n\nAllow us to filter on minimum disk and RAM, and close another gap with\nnovaclient.\n\nChange-Id: Ib3f0bdf419675e1c35c3406fbac8a4c18ac56a33\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,758062,da03bd80e3b83faf465f1446c4553c5d97b5bad5,16,3,2,15334,,,0,"Add 'flavor list --min-disk', '--min-ram' options

Allow us to filter on minimum disk and RAM, and close another gap with
novaclient.

Change-Id: Ib3f0bdf419675e1c35c3406fbac8a4c18ac56a33
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/62/758062/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/compute/v2/flavor.py', 'openstackclient/tests/unit/compute/v2/test_flavor.py', 'releasenotes/notes/flavor-list-min-disk-min-ram-65ba35e7acc24134.yaml']",3,cc0a9dcab91a7089f4080e2c01d9a9139953a37d,osc-first,"--- features: - | The ``openstack flavor list`` command now accepts two additional options, ``--min-disk`` and ``--min-ram``, to filter flavor by minimum disk and minimum RAM, respectively. ",,78,6
openstack%2Fpython-ironicclient~master~I2d9dee3dc2299656f305559145f7801b25ef30f3,openstack/python-ironicclient,master,I2d9dee3dc2299656f305559145f7801b25ef30f3,Move pep8 dependencies from test-requirements to tox.ini,MERGED,2020-12-14 09:37:04.000000000,2021-01-06 11:11:39.000000000,2021-01-06 11:10:12.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-14 09:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/00af84b26a263cd402e2f431aef46b8d7cc0cbca', 'message': ""Fix lower-constraints with the new pip resolver\n\n* move pep8 dependencies from test-requirements to tox.ini,\n  they're not needed there and are hard to constraint properly.\n\n* adapt test-requirements and lower-constraints as needed\n\nChange-Id: I2d9dee3dc2299656f305559145f7801b25ef30f3\n""}, {'number': 2, 'created': '2020-12-14 14:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c08c8eee37a337d3a56684c1db3416695d042553', 'message': ""Fix lower-constraints with the new pip resolver\n\n* move pep8 dependencies from test-requirements to tox.ini,\n  they're not needed there and are hard to constraint properly.\n\n* adapt test-requirements and lower-constraints as needed\n\nChange-Id: I2d9dee3dc2299656f305559145f7801b25ef30f3\n""}, {'number': 3, 'created': '2020-12-15 17:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/ac1dfa1162fd3814c13efb192e9b8005582a7ab5', 'message': ""Fix lower-constraints with the new pip resolver\n\n* move pep8 dependencies from test-requirements to tox.ini,\n  they're not needed there and are hard to constraint properly.\n\n* adapt test-requirements and lower-constraints as needed\n\nChange-Id: I2d9dee3dc2299656f305559145f7801b25ef30f3\n""}, {'number': 4, 'created': '2020-12-23 12:13:56.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/1db6aef7079982cbfd7d0a6464380f5734b575e8', 'message': ""Move pep8 dependencies from test-requirements to tox.ini\n\nThey're not needed there and are hard to constraint properly.\n\nChange-Id: I2d9dee3dc2299656f305559145f7801b25ef30f3\n""}]",4,766908,1db6aef7079982cbfd7d0a6464380f5734b575e8,21,3,4,23851,,,0,"Move pep8 dependencies from test-requirements to tox.ini

They're not needed there and are hard to constraint properly.

Change-Id: I2d9dee3dc2299656f305559145f7801b25ef30f3
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/08/766908/4 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt', 'tox.ini']",3,00af84b26a263cd402e2f431aef46b8d7cc0cbca,pip-resolver,"deps = hacking>=3.1.0,<4.0.0 # Apache-2.0 doc8>=0.6.0 # Apache-2.0 flake8-import-order>=0.17.1 # LGPLv3 pycodestyle>=2.0.0,<2.7.0 # MIT Pygments>=2.2.0 # BSD",,12,16
openstack%2Fcharm-trilio-data-mover~master~I11d7a35c83f7689a1eb6c897b21a6f1bb866a525,openstack/charm-trilio-data-mover,master,I11d7a35c83f7689a1eb6c897b21a6f1bb866a525,Fix libvirt permissions for snapshots,ABANDONED,2020-07-28 09:45:36.000000000,2021-01-06 11:06:44.000000000,,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-07-28 09:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-trilio-data-mover/commit/a5a668f51ed36a6b8dffd3d878f0390772d5917d', 'message': 'Fix libvirt permissions for snapshots\n\nEnsure that the libvirt-qemu user is a member of the nova group,\nsupporting access to snapshots managed by TrilioVault.\n\nChange-Id: I11d7a35c83f7689a1eb6c897b21a6f1bb866a525\nCloses-Bug: 1888389\n'}, {'number': 2, 'created': '2020-09-29 09:32:06.000000000', 'files': ['src/lib/charm/openstack/trilio_dm.py'], 'web_link': 'https://opendev.org/openstack/charm-trilio-data-mover/commit/659f20020d62f59fb59c453ff02896dce8f668b5', 'message': 'Fix libvirt permissions for snapshots\n\nEnsure that the libvirt-qemu user is a member of the nova group,\nsupporting access to snapshots managed by TrilioVault.\n\nChange-Id: I11d7a35c83f7689a1eb6c897b21a6f1bb866a525\nCloses-Bug: 1888389\n'}]",0,743496,659f20020d62f59fb59c453ff02896dce8f668b5,15,3,2,935,,,0,"Fix libvirt permissions for snapshots

Ensure that the libvirt-qemu user is a member of the nova group,
supporting access to snapshots managed by TrilioVault.

Change-Id: I11d7a35c83f7689a1eb6c897b21a6f1bb866a525
Closes-Bug: 1888389
",git fetch https://review.opendev.org/openstack/charm-trilio-data-mover refs/changes/96/743496/2 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/trilio_dm.py'],1,a5a668f51ed36a6b8dffd3d878f0390772d5917d,bug/1888389,"import charmhelpers.core.host as ch_host def install(self): """"""Install charm including any trilio-dm specific operations"""""" super().install() self._configure_libvirt_group() def upgrade_charm(self): """"""Upgrade charm including any trilio-dm specifif operations"""""" super().upgrade_charm() self._configure_libvirt_group() def _configure_libvirt_group(self): """"""Add libvirt-qemu user to nova group for snapshot permissions"""""" # NOTE: see https://pad.lv/1888389 ch_host.add_user_to_group(username='libvirt-qemu', group='nova') ",,16,0
openstack%2Fironic-inspector-specs~master~Ic843e1edc22c29213957b67081345e1715ee0e34,openstack/ironic-inspector-specs,master,Ic843e1edc22c29213957b67081345e1715ee0e34,remove unicode from code,MERGED,2021-01-05 09:28:16.000000000,2021-01-06 10:57:06.000000000,2021-01-06 10:55:46.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 09:28:16.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector-specs/commit/034bdae33e1ea32fa9e14b9e4d19c0ca65f4b7a4', 'message': 'remove unicode from code\n\nChange-Id: Ic843e1edc22c29213957b67081345e1715ee0e34\n'}]",0,769293,034bdae33e1ea32fa9e14b9e4d19c0ca65f4b7a4,7,2,1,32020,,,0,"remove unicode from code

Change-Id: Ic843e1edc22c29213957b67081345e1715ee0e34
",git fetch https://review.opendev.org/openstack/ironic-inspector-specs refs/changes/93/769293/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,034bdae33e1ea32fa9e14b9e4d19c0ca65f4b7a4,,"project = 'Ironic Inspector Specs' copyright = '%s, OpenStack Ironic Inspector Team' % datetime.date.today().year 'OpenStack Ironic Inspector Team', 'manual'),","project = u'Ironic Inspector Specs' copyright = u'%s, OpenStack Ironic Inspector Team' % datetime.date.today().year u'OpenStack Ironic Inspector Team', 'manual'),",3,3
openstack%2Fopenstack-helm-images~master~If0d3205bbf94d27543f0e4f7be30dacf8ce61b2e,openstack/openstack-helm-images,master,If0d3205bbf94d27543f0e4f7be30dacf8ce61b2e,Remove unused test jobs for mariadb and ovs in periodic pipeline,MERGED,2021-01-05 20:38:12.000000000,2021-01-06 10:50:27.000000000,2021-01-06 10:40:36.000000000,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 20:38:12.000000000', 'files': ['zuul.d/openstack-loci.yaml', 'zuul.d/mariadb.yaml', 'zuul.d/openvswitch.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/46bf884d16f22302a432b5574856d94e556d8494', 'message': 'Remove unused test jobs for mariadb and ovs in periodic pipeline\n\nAlso adds periodic promotion for ussuri loci images.\n\nChange-Id: If0d3205bbf94d27543f0e4f7be30dacf8ce61b2e\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}]",0,769417,46bf884d16f22302a432b5574856d94e556d8494,17,3,1,8863,,,0,"Remove unused test jobs for mariadb and ovs in periodic pipeline

Also adds periodic promotion for ussuri loci images.

Change-Id: If0d3205bbf94d27543f0e4f7be30dacf8ce61b2e
Signed-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/17/769417/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/openstack-loci.yaml', 'zuul.d/mariadb.yaml', 'zuul.d/openvswitch.yaml']",3,46bf884d16f22302a432b5574856d94e556d8494,,, - name: openstack-helm-images-cinder-stein-ubuntu_bionic - name: openstack-helm-images-cinder-train-ubuntu_bionic,3,4
openstack%2Fblazar-tempest-plugin~master~I7de0f99a4b15cd4c21a815f6d6bdeac99bb657ba,openstack/blazar-tempest-plugin,master,I7de0f99a4b15cd4c21a815f6d6bdeac99bb657ba,Bump py37 to py38 in tox.ini,MERGED,2020-10-14 07:55:53.000000000,2021-01-06 10:35:00.000000000,2021-01-06 10:33:31.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-14 07:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/1008c0dbe7f355b4ff751fee8573083df5ae8c1c', 'message': ""bump py37 to py38 in tox.ini\n\nin 'victoria' cycle, we should test py38 by default.\n\nref:\n  https://governance.openstack.org/tc/reference/runtimes/victoria.html\n\nChange-Id: I7de0f99a4b15cd4c21a815f6d6bdeac99bb657ba\n""}, {'number': 2, 'created': '2021-01-05 22:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/de98cc1b4aab382d6de4ce96275c763b42c2e4cb', 'message': ""bump py37 to py38 in tox.ini\n\nin 'victoria' cycle, we should test py38 by default.\n\nref:\n  https://governance.openstack.org/tc/reference/runtimes/victoria.html\n\nChange-Id: I7de0f99a4b15cd4c21a815f6d6bdeac99bb657ba\n""}, {'number': 3, 'created': '2021-01-05 22:26:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/b979560d888c223a0c68fcc88d0a31bb7480a0b3', 'message': ""Bump py37 to py38 in tox.ini\n\nIn 'wallaby' cycle, we should test py38 by default.\n\nref:\n  https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I7de0f99a4b15cd4c21a815f6d6bdeac99bb657ba\n""}]",0,758027,b979560d888c223a0c68fcc88d0a31bb7480a0b3,10,2,3,32291,,,0,"Bump py37 to py38 in tox.ini

In 'wallaby' cycle, we should test py38 by default.

ref:
  https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I7de0f99a4b15cd4c21a815f6d6bdeac99bb657ba
",git fetch https://review.opendev.org/openstack/blazar-tempest-plugin refs/changes/27/758027/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1008c0dbe7f355b4ff751fee8573083df5ae8c1c,,"envlist = py36,py38,docs,pep8","envlist = py36,py37,docs,pep8",1,1
openstack%2Fsushy-tools~master~I0eee22a18dde54e887e2a5d3ed1db141fec163f7,openstack/sushy-tools,master,I0eee22a18dde54e887e2a5d3ed1db141fec163f7,Adding basic support for processors schema,MERGED,2020-11-09 12:24:50.000000000,2021-01-06 10:30:39.000000000,2021-01-06 10:29:17.000000000,"[{'_account_id': 10239}, {'_account_id': 11292}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-11-09 12:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/70733b59b9e01204b3fbc39d858ac7a1ec159ac2', 'message': '[WIP] Support processors schema\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 2, 'created': '2020-11-09 12:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/106d962fd33e91ef166350d3c1041bf3b8d3b15a', 'message': '[WIP] Support processors schema\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 3, 'created': '2020-11-20 09:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/41e54ca638bc721d01d71f693fcad0d61cebb90e', 'message': '[WIP] Support processors schema\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 4, 'created': '2020-11-20 13:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/76062bdada1925d5e7c19925c164e08d60384bb7', 'message': '[WIP] Support processors schema\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 5, 'created': '2020-11-23 14:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/1cb8fbf606662e8c8b0683ae4c93565cb0f8e2c4', 'message': '[WIP] Support processors schema\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 6, 'created': '2020-11-25 13:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/e4f930f4d2d34146ddbdc1a588a146600d062db7', 'message': 'Adding basic support for processors schema\n\nAdds logic to provide basic support for Redfish Processor schema [1]\n\n[1] https://redfish.dmtf.org/schemas/v1/Processor.v1_10_0.json\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 7, 'created': '2020-11-25 13:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/81f4be13a79e934905cf2a24b9f3a9874bb3aa98', 'message': 'Adding basic support for processors schema\n\nAdds logic to provide basic support for Redfish Processor schema [1]\n\n[1] https://redfish.dmtf.org/schemas/v1/Processor.v1_10_0.json\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 8, 'created': '2020-12-15 14:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/944ccc549625632cf3505c299ede560702e14fe5', 'message': 'Adding basic support for processors schema\n\nAdds logic to provide basic support for Redfish Processor schema [1]\n\n[1] https://redfish.dmtf.org/schemas/v1/Processor.v1_10_0.json\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 9, 'created': '2020-12-16 08:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/4fbaa22c5e06b100524dc7227b896a69a0a782b9', 'message': 'Adding basic support for processors schema\n\nAdds logic to provide basic support for Redfish Processor schema [1]\n\n[1] https://redfish.dmtf.org/schemas/v1/Processor.v1_10_0.json\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}, {'number': 10, 'created': '2020-12-16 09:01:55.000000000', 'files': ['sushy_tools/emulator/main.py', 'sushy_tools/tests/unit/emulator/domain_processors.xml', 'sushy_tools/emulator/resources/systems/libvirtdriver.py', 'releasenotes/notes/add-processor-schema-f23195a923f5830f.yaml', 'doc/source/admin/emulator.conf', 'sushy_tools/tests/unit/emulator/resources/systems/test_libvirt.py', 'sushy_tools/emulator/templates/processors_collection.json', 'sushy_tools/emulator/templates/processor.json'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/ef0baa721582c2fbb4a60d8c5dcb6117493fdd41', 'message': 'Adding basic support for processors schema\n\nAdds logic to provide basic support for Redfish Processor schema [1]\n\n[1] https://redfish.dmtf.org/schemas/v1/Processor.v1_10_0.json\n\nStory: 2007454\nTask: 39128\n\nChange-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7\n'}]",1,761909,ef0baa721582c2fbb4a60d8c5dcb6117493fdd41,27,4,10,23851,,,0,"Adding basic support for processors schema

Adds logic to provide basic support for Redfish Processor schema [1]

[1] https://redfish.dmtf.org/schemas/v1/Processor.v1_10_0.json

Story: 2007454
Task: 39128

Change-Id: I0eee22a18dde54e887e2a5d3ed1db141fec163f7
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/09/761909/8 && git format-patch -1 --stdout FETCH_HEAD,"['sushy_tools/emulator/templates/processor_collection.json', 'sushy_tools/tests/unit/emulator/resources/test_processors.py', 'doc/source/admin/emulator.conf', 'sushy_tools/emulator/resources/processors.py', 'sushy_tools/emulator/templates/processor.json']",5,70733b59b9e01204b3fbc39d858ac7a1ec159ac2,processors,"{ ""@odata.type"": ""#Processor.v1_7_0.Processor"", ""Id"": {{ processor['Id']|string|tojson }}, ""Name"": {{ processor['Name']|string|tojson }}, ""Socket"": {{ processor['Socket']|string|tojson }}, ""ProcessorType"": ""CPU"", ""ProcessorArchitecture"": ""x86"", ""InstructionSet"": ""x86-64"", ""Manufacturer"": ""Intel(R) Corporation"", ""Model"": ""Multi-Core Intel(R) Xeon(R) processor 7xxx Series"", ""ProcessorId"": { ""VendorID"": ""GenuineIntel"", ""IdentificationRegisters"": ""GenuineIntel"", ""EffectiveFamily"": ""0x42"", ""EffectiveModel"": ""0x61"", ""Step"": ""0x1"", ""MicrocodeInfo"": ""0x429943"" }, ""MaxSpeedMHz"": 3700, ""TotalCores"": 8, ""TotalThreads"": 16, ""Status"": { ""@odata.type"": ""#Resource.Status"", ""State"": ""Enabled"", ""Health"": ""OK"" }, ""@odata.context"": ""/redfish/v1/$metadata#Processor.Processor"", ""@odata.id"": {{ ""/redfish/v1/Systems/%s/Storage/%s/Drives/%s""|format(identity, processor['Id'])|tojson }}, ""@Redfish.Copyright"": ""Copyright 2014-2019 DMTF. For the full DMTF copyright policy, see http://www.dmtf.org/about/policies/copyright"" } ",,166,0
openstack%2Fsushy-tools~master~I16369eda04fbd0ed18da524eae5cf792c1b31155,openstack/sushy-tools,master,I16369eda04fbd0ed18da524eae5cf792c1b31155,Provide correct libvirt name/bus for virtual floppy,MERGED,2020-12-23 17:32:05.000000000,2021-01-06 10:26:29.000000000,2021-01-06 10:23:46.000000000,"[{'_account_id': 11292}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-23 17:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/6ccd0205cb2bd09478e6824114580f1133dbf283', 'message': 'Provide correct libvirt name/bus for virtual floppy\n\nChange-Id: I16369eda04fbd0ed18da524eae5cf792c1b31155\n'}, {'number': 2, 'created': '2020-12-23 17:32:42.000000000', 'files': ['sushy_tools/emulator/resources/systems/libvirtdriver.py', 'releasenotes/notes/floppy-1be04ed78708caf1.yaml'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/80b40b5a84adba2a76d0a76b3d21a06ad8711521', 'message': 'Provide correct libvirt name/bus for virtual floppy\n\nChange-Id: I16369eda04fbd0ed18da524eae5cf792c1b31155\n'}]",0,768361,80b40b5a84adba2a76d0a76b3d21a06ad8711521,9,3,2,10239,,,0,"Provide correct libvirt name/bus for virtual floppy

Change-Id: I16369eda04fbd0ed18da524eae5cf792c1b31155
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/61/768361/2 && git format-patch -1 --stdout FETCH_HEAD,['sushy_tools/emulator/resources/systems/libvirtdriver.py'],1,6ccd0205cb2bd09478e6824114580f1133dbf283,floopy," elif lv_device == 'floppy': tgt_dev, tgt_bus = ('fda', 'fdc')",,2,0
openstack%2Fsushy-tools~master~I8595eeadcbfd9c45949c676312fc4079795f9953,openstack/sushy-tools,master,I8595eeadcbfd9c45949c676312fc4079795f9953,Add doc/requirements,MERGED,2021-01-04 17:39:44.000000000,2021-01-06 10:25:04.000000000,2021-01-06 10:23:42.000000000,"[{'_account_id': 11292}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-04 17:39:44.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/2cb8ca719a38a1eea87877ff290c612c065b3276', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: I8595eeadcbfd9c45949c676312fc4079795f9953\n'}]",0,769175,2cb8ca719a38a1eea87877ff290c612c065b3276,9,4,1,15519,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: I8595eeadcbfd9c45949c676312fc4079795f9953
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/75/769175/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,2cb8ca719a38a1eea87877ff290c612c065b3276,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps}deps = {[testenv:docs]deps},,7,3
openstack%2Ftripleo-heat-templates~master~If46a83e5f476ab8ed553b67b624c780a21ee50a5,openstack/tripleo-heat-templates,master,If46a83e5f476ab8ed553b67b624c780a21ee50a5,Add SwiftHashPrefix parameter,MERGED,2020-12-03 05:40:18.000000000,2021-01-06 10:24:11.000000000,2021-01-06 10:22:40.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30073}, {'_account_id': 30095}]","[{'number': 1, 'created': '2020-12-03 05:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6c93d81648078950edf5822c91ddcaa8b3cbdb81', 'message': ""Add SwiftHashPrefix parameter\n\nAdds a new parameter 'SwiftHashPrefix' to allow swift\nto have its hash_prefix parameter set.\n\nChange-Id: If46a83e5f476ab8ed553b67b624c780a21ee50a5\nCloses-bug: 2008411\n""}, {'number': 2, 'created': '2020-12-03 12:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/126e7296a82f56e835fe202855d75ffeb7221194', 'message': ""Add SwiftHashPrefix parameter\n\nAdds a new parameter 'SwiftHashPrefix' to allow swift\nto have its hash_prefix parameter set.\n\nChange-Id: If46a83e5f476ab8ed553b67b624c780a21ee50a5\nStory: 2008411\n""}, {'number': 3, 'created': '2020-12-03 13:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/573a2ebf4ba33beb88692bf9c92c634d7f62eb2d', 'message': ""Add SwiftHashPrefix parameter\n\nAdds a new parameter 'SwiftHashPrefix' to allow swift\nto have its hash_prefix parameter set.\n\nChange-Id: If46a83e5f476ab8ed553b67b624c780a21ee50a5\nStory: 2008411\n""}, {'number': 4, 'created': '2020-12-03 13:41:56.000000000', 'files': ['releasenotes/notes/swift_hash_path_prefix-5ecc32ed5d78158b.yaml', 'deployment/swift/swift-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e1c9618b98a0780362ab6761c3aab058dadc7d1', 'message': ""Add SwiftHashPrefix parameter\n\nAdds a new parameter 'SwiftHashPrefix' to allow swift\nto have its hash_prefix parameter set.\n\nChange-Id: If46a83e5f476ab8ed553b67b624c780a21ee50a5\nStory: 2008411\nRelated-RHBZ: #1903901\n""}]",5,765238,0e1c9618b98a0780362ab6761c3aab058dadc7d1,48,7,4,30095,,,0,"Add SwiftHashPrefix parameter

Adds a new parameter 'SwiftHashPrefix' to allow swift
to have its hash_prefix parameter set.

Change-Id: If46a83e5f476ab8ed553b67b624c780a21ee50a5
Story: 2008411
Related-RHBZ: #1903901
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/765238/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/swift/swift-base.yaml'],1,6c93d81648078950edf5822c91ddcaa8b3cbdb81,, SwiftHashPrefix: default: '' description: A random string to be used as an extra salt when hashing to determine mappings in the ring. hidden: true type: string swift::swift_hash_path_prefix: {get_param: SwiftHashPrefix},,7,0
openstack%2Ftripleo-heat-templates~master~Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65,openstack/tripleo-heat-templates,master,Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65,Adding key_size option on the certificate creation,MERGED,2020-12-01 17:11:18.000000000,2021-01-06 10:22:15.000000000,2021-01-06 10:22:15.000000000,"[{'_account_id': 7353}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28182}]","[{'number': 1, 'created': '2020-12-01 17:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f5c2760950432692ba8e28c674167e4fb807b5d', 'message': '[WIP]Adding key_size option on the certificate creation\n\nDepends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\nChange-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65\n'}, {'number': 2, 'created': '2020-12-03 14:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f9ec93898efe67828951696d229a9e22f33330e3', 'message': ""Adding key_size option on the certificate creation\n\nAdding the ability to specifies the private key size\nused when creating the certificate. We have defined the\ndefault value the same as we have before 2048 bits.\nAlso, it'll be able to override the key_size value\nper service.\n\nDepends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\nChange-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65\n""}, {'number': 3, 'created': '2020-12-17 21:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b91655c26fb48dfd071389f9b7bb7ca56fea089', 'message': ""Adding key_size option on the certificate creation\n\nAdding the ability to specifies the private key size\nused when creating the certificate. We have defined the\ndefault value the same as we have before 2048 bits.\nAlso, it'll be able to override the key_size value\nper service.\n\nDepends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\nChange-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65\n""}, {'number': 4, 'created': '2020-12-17 21:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ac1b74de057b41c3846a5d52977ed29a28958285', 'message': ""Adding key_size option on the certificate creation\n\nAdding the ability to specifies the private key size\nused when creating the certificate. We have defined the\ndefault value the same as we have before 2048 bits.\nAlso, it'll be able to override the key_size value\nper service.\n\nDepends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\nChange-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65\n""}, {'number': 5, 'created': '2020-12-17 23:23:03.000000000', 'files': ['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/database/redis-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/haproxy/haproxy-public-tls-certmonger.yaml', 'deployment/database/mysql-base.yaml', 'deployment/haproxy/haproxy-internal-tls-certmonger.j2.yaml', 'deployment/ceph-ansible/ceph-rgw.yaml', 'deployment/ceph-ansible/ceph-grafana.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/ceph-ansible/ceph-mgr.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/octavia/providers/ovn-provider-config.yaml', 'deployment/metrics/qdr-container-puppet.yaml', 'deployment/memcached/memcached-container-puppet.yaml', 'deployment/apache/apache-baremetal-puppet.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/97609775297417620ede0436c80156456a6c41da', 'message': ""Adding key_size option on the certificate creation\n\nAdding the ability to specifies the private key size\nused when creating the certificate. We have defined the\ndefault value the same as we have before 2048 bits.\nAlso, it'll be able to override the key_size value\nper service.\n\nDepends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\nChange-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65\n""}]",0,764988,97609775297417620ede0436c80156456a6c41da,29,6,5,8866,,,0,"Adding key_size option on the certificate creation

Adding the ability to specifies the private key size
used when creating the certificate. We have defined the
default value the same as we have before 2048 bits.
Also, it'll be able to override the key_size value
per service.

Depends-on: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b
Change-Id: Ic2edabb7f1bd0caf4a5550d03f60fab7c8354d65
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/88/764988/5 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/haproxy/haproxy-public-tls-certmonger.yaml', 'deployment/haproxy/haproxy-internal-tls-certmonger.j2.yaml', 'deployment/ceph-ansible/ceph-grafana.yaml', 'deployment/ceph-ansible/ceph-mgr.yaml', 'deployment/apache/apache-baremetal-puppet.j2.yaml']",7,5f5c2760950432692ba8e28c674167e4fb807b5d,key_size_cert," key_size: ""%{hiera('key_size')}""",,28,0
openstack%2Fpuppet-tripleo~stable%2Ftrain~I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,openstack/puppet-tripleo,stable/train,I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,Adding key_size option on the certmonger_certificate function,MERGED,2021-01-05 15:47:09.000000000,2021-01-06 10:22:11.000000000,2021-01-06 10:22:11.000000000,"[{'_account_id': 7353}, {'_account_id': 8866}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-05 15:47:09.000000000', 'files': ['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5b0ca71c0a98d19fc9b6452aaac91a1b52be517f', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)\n'}]",0,769360,5b0ca71c0a98d19fc9b6452aaac91a1b52be517f,8,5,1,9914,,,0,"Adding key_size option on the certmonger_certificate function

certmonger_certificate function currently does not support
creating certificates with private keys stronger than 2048bits.
Adding a key_size option.

key_size option were added on puppet_certmonger on the v2.6.0
upstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0

Change-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b
(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/60/769360/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp']",22,5b0ca71c0a98d19fc9b6452aaac91a1b52be517f,key_size_cert-stable/victoria-stable/ussuri-stable/train,"# [*key_size*] # (Optional) Specifies the private key size used when creating the certificate. # Defaults to 2048bits. # $key_size = 2048, key_size => $key_size,",,126,1
openstack%2Fvalidations-common~master~I344ace76feeea1b7f26eaa4f6e6d66a6d01c3b3c,openstack/validations-common,master,I344ace76feeea1b7f26eaa4f6e6d66a6d01c3b3c,new line in readme.,ABANDONED,2021-01-05 15:52:56.000000000,2021-01-06 10:16:13.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-05 15:52:56.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/b165b8441a75d17a322b15cad7f97c95af186f17', 'message': ' new line in readme.\n\nChange-Id: I344ace76feeea1b7f26eaa4f6e6d66a6d01c3b3c\n'}]",0,769388,b165b8441a75d17a322b15cad7f97c95af186f17,3,1,1,32926,,,0," new line in readme.

Change-Id: I344ace76feeea1b7f26eaa4f6e6d66a6d01c3b3c
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/88/769388/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b165b8441a75d17a322b15cad7f97c95af186f17,jptestbranch, ,,2,0
openstack%2Fsushy-tools~master~Ie0d0b7ccf55685c46de2163baeda4e40ed845eaa,openstack/sushy-tools,master,Ie0d0b7ccf55685c46de2163baeda4e40ed845eaa,Adding status to ethernet interface template,MERGED,2020-11-26 12:51:57.000000000,2021-01-06 10:14:01.000000000,2021-01-06 10:12:46.000000000,"[{'_account_id': 10239}, {'_account_id': 11292}, {'_account_id': 22348}, {'_account_id': 32177}]","[{'number': 1, 'created': '2020-11-26 12:51:57.000000000', 'files': ['sushy_tools/emulator/templates/ethernet_interface.json'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/e0d510608dace56abb481af35e096ea47e8c309b', 'message': ""Adding status to ethernet interface template\n\nThe status of a resource should be always reported by redfish, let's\nadd a static one for the ethernet interface too for completeness.\n\nChange-Id: Ie0d0b7ccf55685c46de2163baeda4e40ed845eaa\n""}]",0,764341,e0d510608dace56abb481af35e096ea47e8c309b,9,4,1,23851,,,0,"Adding status to ethernet interface template

The status of a resource should be always reported by redfish, let's
add a static one for the ethernet interface too for completeness.

Change-Id: Ie0d0b7ccf55685c46de2163baeda4e40ed845eaa
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/41/764341/1 && git format-patch -1 --stdout FETCH_HEAD,['sushy_tools/emulator/templates/ethernet_interface.json'],1,e0d510608dace56abb481af35e096ea47e8c309b,eth-int-status," ""Status"": { ""State"": ""Enabled"", ""Health"": ""OK"" },",,4,0
openstack%2Fmonasca-statsd~master~Ib8ee8b50f6e823cf543e8c6e3b5f271691785b87,openstack/monasca-statsd,master,Ib8ee8b50f6e823cf543e8c6e3b5f271691785b87,update lower-constraints,NEW,2021-01-06 09:21:14.000000000,2021-01-06 10:11:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-06 09:21:14.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/monasca-statsd/commit/299a1a8d9c9c0d95b87197a2abd960c6a5eb861d', 'message': 'update lower-constraints\n\nChange-Id: Ib8ee8b50f6e823cf543e8c6e3b5f271691785b87\n'}]",0,769479,299a1a8d9c9c0d95b87197a2abd960c6a5eb861d,2,1,1,32238,,,0,"update lower-constraints

Change-Id: Ib8ee8b50f6e823cf543e8c6e3b5f271691785b87
",git fetch https://review.opendev.org/openstack/monasca-statsd refs/changes/79/769479/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,299a1a8d9c9c0d95b87197a2abd960c6a5eb861d,,mccabe==0.6.0,mccabe==0.2.1,1,1
openstack%2Frequirements~master~I88deb79c47ae9ec91b038539780a38e9262a4185,openstack/requirements,master,I88deb79c47ae9ec91b038539780a38e9262a4185,Updated from generate-constraints,MERGED,2021-01-06 06:29:09.000000000,2021-01-06 10:07:14.000000000,2021-01-06 10:05:27.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-06 06:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/bfe65b31c9f440efda46c23c9160933e5beb7130', 'message': 'Updated from generate-constraints\n\nChange-Id: I88deb79c47ae9ec91b038539780a38e9262a4185\n'}, {'number': 2, 'created': '2021-01-06 06:34:24.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ff08aee41973835d07a43c1b57363ef2e5e1f7ce', 'message': 'Updated from generate-constraints\n\nChange-Id: I88deb79c47ae9ec91b038539780a38e9262a4185\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,769455,ff08aee41973835d07a43c1b57363ef2e5e1f7ce,10,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: I88deb79c47ae9ec91b038539780a38e9262a4185
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/55/769455/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,bfe65b31c9f440efda46c23c9160933e5beb7130,openstack/requirements/constraints/noclob,tripleo-common===13.1.0mock===4.0.3os-net-config===13.1.0os-apply-config===12.0.0docutils===0.16boto3===1.16.49numpy===1.19.5botocore===1.19.49oslo.db===8.5.0pkg-resources===0.0.0fasteners===0.16virtualenv===20.2.2,tripleo-common===13.0.0mock===3.0.5os-net-config===13.0.0os-apply-config===11.3.0docutils===0.15.2boto3===1.16.48numpy===1.19.4botocore===1.19.48oslo.db===8.4.0fasteners===0.14.1virtualenv===20.2.1setuptools===51.1.1,12,12
openstack%2Fpuppet-tripleo~stable%2Fussuri~I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,openstack/puppet-tripleo,stable/ussuri,I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,Adding key_size option on the certmonger_certificate function,MERGED,2021-01-05 14:38:35.000000000,2021-01-06 10:05:19.000000000,2021-01-06 10:05:19.000000000,"[{'_account_id': 7353}, {'_account_id': 8866}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-05 14:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/65baf2fab486f708fefdaafea379d89bf3e8d6e1', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)\n'}, {'number': 2, 'created': '2021-01-05 15:45:41.000000000', 'files': ['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/963b47338008f16039a815b03f00ad6e387b6ca0', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)\n'}]",0,769356,963b47338008f16039a815b03f00ad6e387b6ca0,10,5,2,9914,,,0,"Adding key_size option on the certmonger_certificate function

certmonger_certificate function currently does not support
creating certificates with private keys stronger than 2048bits.
Adding a key_size option.

key_size option were added on puppet_certmonger on the v2.6.0
upstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0

Change-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b
(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/56/769356/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp', 'manifests/certmonger/memcached.pp']",23,65baf2fab486f708fefdaafea379d89bf3e8d6e1,key_size_cert-stable/victoria-stable/ussuri,"<<<<<<< HEAD (d63284 Allow to specify a nic for the VIPs + Fix nic selection when) ======= # Copyright 2020 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # == Class: tripleo::certmonger::memcached # # Request a certificate for Memcached and do the necessary setup. # # === Parameters # # [*hostname*] # The hostname of the node. this will be set in the CN of the certificate. # # [*service_certificate*] # The path to the certificate that will be used for TLS in this service. # # [*service_key*] # The path to the key that will be used for TLS in this service. # # [*certmonger_ca*] # (Optional) The CA that certmonger will use to generate the certificates. # Defaults to hiera('certmonger_ca', 'local'). # # [*postsave_cmd*] # (Optional) Specifies the command to execute after requesting a certificate. # If nothing is given, it will default to: ""systemctl restart ${service name}"" # Defaults to undef. # # [*principal*] # (Optional) The service principal that is set for the service in kerberos. # Defaults to undef # # [*key_size*] # (Optional) Specifies the private key size used when creating the certificate. # Defaults to 2048bits. # class tripleo::certmonger::memcached ( $hostname, $service_certificate, $service_key, $certmonger_ca = hiera('certmonger_ca', 'local'), $postsave_cmd = '/usr/bin/certmonger-memcached-refresh.sh', $principal = undef, $key_size = 2048, ) { include certmonger ensure_resource('file', '/usr/bin/certmonger-memcached-refresh.sh', { source => 'puppet:///modules/tripleo/certmonger-memcached-refresh.sh', mode => '0700', seltype => 'bin_t', notify => Service['certmonger'] }) certmonger_certificate { 'memcached' : ensure => 'present', certfile => $service_certificate, keyfile => $service_key, hostname => $hostname, dnsname => $hostname, principal => $principal, postsave_cmd => $postsave_cmd, ca => $certmonger_ca, key_size => $key_size, wait => true, require => Class['::certmonger'], } file { $service_certificate : require => Certmonger_certificate['memcached'], } file { $service_key : require => Certmonger_certificate['memcached'], } } >>>>>>> CHANGE (51ff42 Adding key_size option on the certmonger_certificate functio) ",,214,1
openstack%2Fpuppet-tripleo~stable%2Fvictoria~I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,openstack/puppet-tripleo,stable/victoria,I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,Adding key_size option on the certmonger_certificate function,MERGED,2021-01-05 14:35:47.000000000,2021-01-06 10:05:14.000000000,2021-01-06 10:05:14.000000000,"[{'_account_id': 8866}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-05 14:35:47.000000000', 'files': ['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp', 'manifests/certmonger/memcached.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/51ff421cf3f86878818162396fc6489cb3148843', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)\n'}]",0,769195,51ff421cf3f86878818162396fc6489cb3148843,8,4,1,9914,,,0,"Adding key_size option on the certmonger_certificate function

certmonger_certificate function currently does not support
creating certificates with private keys stronger than 2048bits.
Adding a key_size option.

key_size option were added on puppet_certmonger on the v2.6.0
upstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0

Change-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b
(cherry picked from commit 190aebca609e8ec68586cfa4ced9f2efa65758d1)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/95/769195/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp', 'manifests/certmonger/memcached.pp']",23,51ff421cf3f86878818162396fc6489cb3148843,key_size_cert-stable/victoria,"# [*key_size*] # (Optional) Specifies the private key size used when creating the certificate. # Defaults to 2048bits. # $key_size = 2048, key_size => $key_size,",,132,1
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~Id05acb6516daa62279c9aade41256bcec7c5fce7,openstack/tripleo-heat-templates,stable/victoria,Id05acb6516daa62279c9aade41256bcec7c5fce7,Identify HSMs using labels instead of Slot ID,MERGED,2020-12-01 21:07:52.000000000,2021-01-06 10:05:06.000000000,2021-01-06 10:05:06.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 21:07:52.000000000', 'files': ['deployment/barbican/barbican-backend-pkcs11-crypto-puppet.yaml', 'environments/barbican-backend-pkcs11-lunasa.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b269eec7b1afa154d306e0160aed82906b489994', 'message': 'Identify HSMs using labels instead of Slot ID\n\nThis patch adds support for two new options in barbican.conf for the\nPKCS#11 backend plugin:  [p11_crypto]token_label and\n[p11_crypto]token_serial_number by adding two new parameters\nto the Barbican deployment BarbicanPkcs11CryptoTokenSerialNumber\nand BarbicanPkcs11CryptoTokenLabel.\n\nThis patch also simplifies the use of barbican-manage to generate\nthe MKEK and PKEK in the HSM backend by using the values provided\nin barbican.conf instead of duplicating them on the command line.\n\nFor the Thales Luna Network device, this patch uses the label\nparameters to identify the partition to be used.  Because we are\nusing labels we no longer need to write the runtime generated\nSlot ID of the HA group into hieradata.\n\nDepends-On: I4e86e73bbdef0e16d3699cec1cc8f7e17dfb643b\nChange-Id: Id05acb6516daa62279c9aade41256bcec7c5fce7\n(cherry picked from commit 04b4ec3866446df45dab628782702cd1444c3575)\n'}]",0,765006,b269eec7b1afa154d306e0160aed82906b489994,10,3,1,7973,,,0,"Identify HSMs using labels instead of Slot ID

This patch adds support for two new options in barbican.conf for the
PKCS#11 backend plugin:  [p11_crypto]token_label and
[p11_crypto]token_serial_number by adding two new parameters
to the Barbican deployment BarbicanPkcs11CryptoTokenSerialNumber
and BarbicanPkcs11CryptoTokenLabel.

This patch also simplifies the use of barbican-manage to generate
the MKEK and PKEK in the HSM backend by using the values provided
in barbican.conf instead of duplicating them on the command line.

For the Thales Luna Network device, this patch uses the label
parameters to identify the partition to be used.  Because we are
using labels we no longer need to write the runtime generated
Slot ID of the HA group into hieradata.

Depends-On: I4e86e73bbdef0e16d3699cec1cc8f7e17dfb643b
Change-Id: Id05acb6516daa62279c9aade41256bcec7c5fce7
(cherry picked from commit 04b4ec3866446df45dab628782702cd1444c3575)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/765006/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/barbican/barbican-backend-pkcs11-crypto-puppet.yaml', 'environments/barbican-backend-pkcs11-lunasa.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml']",3,b269eec7b1afa154d306e0160aed82906b489994,," description: Password (PIN) to login to PKCS#11 session description: Slot Id for the PKCS#11 token to be used BarbicanPkcs11CryptoTokenSerialNumber: description: Serial number for PKCS#11 token to be used type: string default: '' BarbicanPkcs11CryptoTokenLabel: description: Label for PKCS#11 token to be used type: string default: '' hsm_enabled: - hsm_enabled - lunasa_ha_label: {get_param: BarbicanPkcs11CryptoTokenLabel} - lunasa_ha_label: {get_param: BarbicanPkcs11CryptoTokenLabel} - ""hsm check_mkek --label"" - ""hsm gen_mkek --label"" - ""hsm check_hmac --label"" - ""|| /usr/bin/barbican-manage hsm gen_hmac --label"""," description: Password to login to PKCS11 session description: Slot Id for the HSM thales_or_atos_or_lunasa_hsm_enabled: - thales_or_atos_or_lunasa_hsm_enabled - name: set the slot id in hieradata include_role: name: tripleo_hieradata tasks_from: ansible_hieradata.yml vars: hieradata_ansible_data: barbican::plugins::p11_crypto::p11_crypto_plugin_slot_id: ""{{ lunasa_ha_slot }}"" when: lunasa_ha_slot is defined - ""hsm check_mkek --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""hsm gen_mkek --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""hsm check_hmac --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""--key-type"" - {get_param: [BarbicanPkcs11CryptoHMACKeyType]} - ""|| /usr/bin/barbican-manage hsm gen_hmac --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""--key-type"" - {get_param: [BarbicanPkcs11CryptoHMACKeyType]} - ""--mechanism"" - {get_param: [BarbicanPkcs11CryptoHMACKeygenMechanism]}",43,60
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Id05acb6516daa62279c9aade41256bcec7c5fce7,openstack/tripleo-heat-templates,stable/ussuri,Id05acb6516daa62279c9aade41256bcec7c5fce7,Identify HSMs using labels instead of Slot ID,MERGED,2020-12-01 21:27:33.000000000,2021-01-06 10:04:58.000000000,2021-01-06 10:04:58.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 21:27:33.000000000', 'files': ['deployment/barbican/barbican-backend-pkcs11-crypto-puppet.yaml', 'environments/barbican-backend-pkcs11-lunasa.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2de50cc3ca31c094b2ab646ee178627c55a39e04', 'message': 'Identify HSMs using labels instead of Slot ID\n\nThis patch adds support for two new options in barbican.conf for the\nPKCS#11 backend plugin:  [p11_crypto]token_label and\n[p11_crypto]token_serial_number by adding two new parameters\nto the Barbican deployment BarbicanPkcs11CryptoTokenSerialNumber\nand BarbicanPkcs11CryptoTokenLabel.\n\nThis patch also simplifies the use of barbican-manage to generate\nthe MKEK and PKEK in the HSM backend by using the values provided\nin barbican.conf instead of duplicating them on the command line.\n\nFor the Thales Luna Network device, this patch uses the label\nparameters to identify the partition to be used.  Because we are\nusing labels we no longer need to write the runtime generated\nSlot ID of the HA group into hieradata.\n\nDepends-On: I4e86e73bbdef0e16d3699cec1cc8f7e17dfb643b\nChange-Id: Id05acb6516daa62279c9aade41256bcec7c5fce7\n(cherry picked from commit 04b4ec3866446df45dab628782702cd1444c3575)\n'}]",0,765007,2de50cc3ca31c094b2ab646ee178627c55a39e04,10,3,1,7973,,,0,"Identify HSMs using labels instead of Slot ID

This patch adds support for two new options in barbican.conf for the
PKCS#11 backend plugin:  [p11_crypto]token_label and
[p11_crypto]token_serial_number by adding two new parameters
to the Barbican deployment BarbicanPkcs11CryptoTokenSerialNumber
and BarbicanPkcs11CryptoTokenLabel.

This patch also simplifies the use of barbican-manage to generate
the MKEK and PKEK in the HSM backend by using the values provided
in barbican.conf instead of duplicating them on the command line.

For the Thales Luna Network device, this patch uses the label
parameters to identify the partition to be used.  Because we are
using labels we no longer need to write the runtime generated
Slot ID of the HA group into hieradata.

Depends-On: I4e86e73bbdef0e16d3699cec1cc8f7e17dfb643b
Change-Id: Id05acb6516daa62279c9aade41256bcec7c5fce7
(cherry picked from commit 04b4ec3866446df45dab628782702cd1444c3575)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/07/765007/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/barbican/barbican-backend-pkcs11-crypto-puppet.yaml', 'environments/barbican-backend-pkcs11-lunasa.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml']",3,2de50cc3ca31c094b2ab646ee178627c55a39e04,," description: Password (PIN) to login to PKCS#11 session description: Slot Id for the PKCS#11 token to be used BarbicanPkcs11CryptoTokenSerialNumber: description: Serial number for PKCS#11 token to be used type: string default: '' BarbicanPkcs11CryptoTokenLabel: description: Label for PKCS#11 token to be used type: string default: '' hsm_enabled: - hsm_enabled - lunasa_ha_label: {get_param: BarbicanPkcs11CryptoTokenLabel} - lunasa_ha_label: {get_param: BarbicanPkcs11CryptoTokenLabel} - ""hsm check_mkek --label"" - ""hsm gen_mkek --label"" - ""hsm check_hmac --label"" - ""|| /usr/bin/barbican-manage hsm gen_hmac --label"""," description: Password to login to PKCS11 session description: Slot Id for the HSM thales_or_atos_or_lunasa_hsm_enabled: - thales_or_atos_or_lunasa_hsm_enabled - name: set the slot id in hieradata include_role: name: tripleo_hieradata tasks_from: ansible_hieradata.yml vars: hieradata_ansible_data: barbican::plugins::p11_crypto::p11_crypto_plugin_slot_id: ""{{ lunasa_ha_slot }}"" when: lunasa_ha_slot is defined - ""hsm check_mkek --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""hsm gen_mkek --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""hsm check_hmac --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""--key-type"" - {get_param: [BarbicanPkcs11CryptoHMACKeyType]} - ""|| /usr/bin/barbican-manage hsm gen_hmac --library-path"" - {get_param: [BarbicanPkcs11CryptoLibraryPath]} - ""--slot-id"" - {get_param: [BarbicanPkcs11CryptoSlotId]} - ""--passphrase"" - {get_param: [BarbicanPkcs11CryptoLogin]} - ""--label"" - ""--key-type"" - {get_param: [BarbicanPkcs11CryptoHMACKeyType]} - ""--mechanism"" - {get_param: [BarbicanPkcs11CryptoHMACKeygenMechanism]}",43,60
openstack%2Fblazar-tempest-plugin~master~I23bbefb2549afdb7e54c9b0c245a338cae4e81e9,openstack/blazar-tempest-plugin,master,I23bbefb2549afdb7e54c9b0c245a338cae4e81e9,Add doc/requirements,MERGED,2021-01-05 10:36:49.000000000,2021-01-06 09:37:47.000000000,2021-01-06 09:36:25.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 10:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/2619d850a3a60aadb8bda996a5610fe5701c2c41', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I23bbefb2549afdb7e54c9b0c245a338cae4e81e9\n""}, {'number': 2, 'created': '2021-01-05 22:24:24.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/f6b619e8e8e883703f6e4731fe1e7aee99acdc5d', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I23bbefb2549afdb7e54c9b0c245a338cae4e81e9\n""}]",0,769314,f6b619e8e8e883703f6e4731fe1e7aee99acdc5d,9,2,2,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I23bbefb2549afdb7e54c9b0c245a338cae4e81e9
",git fetch https://review.opendev.org/openstack/blazar-tempest-plugin refs/changes/14/769314/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,2619d850a3a60aadb8bda996a5610fe5701c2c41,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps}deps = {[testenv:docs]deps},,7,6
openstack%2Fsenlin-tempest-plugin~master~Ia4f5b1a1ba7e3f0bd0553e70b26a79e67401865b,openstack/senlin-tempest-plugin,master,Ia4f5b1a1ba7e3f0bd0553e70b26a79e67401865b,update status of an action,ABANDONED,2020-11-30 07:49:34.000000000,2021-01-06 09:30:27.000000000,,"[{'_account_id': 22348}, {'_account_id': 22998}, {'_account_id': 27224}]","[{'number': 1, 'created': '2020-11-30 07:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/8d1112db7a2f23c395d05a17bf5d60c5e90e6d49', 'message': 'update status of an action\n\nChange-Id: Ia4f5b1a1ba7e3f0bd0553e70b26a79e67401865b\n'}, {'number': 2, 'created': '2020-11-30 07:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/a942d767a39b9af832717995bdefb561240b6ca2', 'message': 'update status of an action\n\ntest update status of an action\n\nChange-Id: Ia4f5b1a1ba7e3f0bd0553e70b26a79e67401865b\n'}, {'number': 3, 'created': '2020-11-30 08:11:21.000000000', 'files': ['senlin_tempest_plugin/tests/api/actions/test_action_update.py'], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/4bba869afaa69873629603d17d63c89ece40c15a', 'message': 'update status of an action\n\ntest update status of an action\n\nChange-Id: Ia4f5b1a1ba7e3f0bd0553e70b26a79e67401865b\n'}]",1,764607,4bba869afaa69873629603d17d63c89ece40c15a,7,3,3,31280,,,0,"update status of an action

test update status of an action

Change-Id: Ia4f5b1a1ba7e3f0bd0553e70b26a79e67401865b
",git fetch https://review.opendev.org/openstack/senlin-tempest-plugin refs/changes/07/764607/2 && git format-patch -1 --stdout FETCH_HEAD,['senlin_tempest_plugin/tests/api/actions/test_action_update.py'],1,8d1112db7a2f23c395d05a17bf5d60c5e90e6d49,senlin03,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import time from tempest.lib import decorators from senlin_tempest_plugin.common import utils from senlin_tempest_plugin.tests.api import base class TestActionUpdate(base.BaseSenlinAPITest): def setUp(self): super(TestActionUpdate, self).setUp() profile_id = utils.create_a_profile(self) self.addCleanup(utils.delete_a_profile, self, profile_id) self.lower_time_bound = time.time() params = { 'cluster': { 'profile_id': profile_id, 'desired_capacity': 0, 'min_size': 0, 'max_size': -1, 'timeout': None, 'metadata': {}, 'name': 'test-cluster-action-show' } } res = self.client.create_obj('clusters', params) self.action_id = res['location'].split('/actions/')[1] self.addCleanup(utils.delete_a_cluster, self, res['body']['id']) @decorators.idempotent_id('c6376f60-8f52-4384-8b6d-57df264f2e23') def test_action_update(self): # Update status of action params = { ""action"": { ""status"": ""CANCELLED"", } } res = self.client.update_obj('actions', self.action_id, params) # check status of action self.assertEqual(202, res['status']) self.client.wait_for_status('actions', self.action_id, 'SUCCEEDED') ",,56,0
openstack%2Fdevstack~master~I636e003d30455d15480c92a9e8dcf455ecf5254c,openstack/devstack,master,I636e003d30455d15480c92a9e8dcf455ecf5254c,DO NOT REVIEW: Test jobs,ABANDONED,2021-01-05 09:46:30.000000000,2021-01-06 09:30:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-05 09:46:30.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e3b4c88861fc7fc373cb84c564f2880d1c67201d', 'message': 'DO NOT REVIEW: Test jobs\n\nChange-Id: I636e003d30455d15480c92a9e8dcf455ecf5254c\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",0,769300,e3b4c88861fc7fc373cb84c564f2880d1c67201d,3,1,1,6773,,,0,"DO NOT REVIEW: Test jobs

Change-Id: I636e003d30455d15480c92a9e8dcf455ecf5254c
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/00/769300/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e3b4c88861fc7fc373cb84c564f2880d1c67201d,test, test ,,2,0
openstack%2Fneutron-tempest-plugin~master~If3d8c7fbf5065620d7dbff1895fa4da1e5d439ab,openstack/neutron-tempest-plugin,master,If3d8c7fbf5065620d7dbff1895fa4da1e5d439ab,New test: test_soft_hard_vm_reboot,ABANDONED,2020-10-29 12:01:17.000000000,2021-01-06 09:22:25.000000000,,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 18894}, {'_account_id': 19118}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28609}, {'_account_id': 29088}, {'_account_id': 29350}, {'_account_id': 31450}]","[{'number': 1, 'created': '2020-10-29 12:01:17.000000000', 'files': ['neutron_tempest_plugin/scenario/test_basic.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/247a6bb1e6ef8dbe5911c04d18300e638b8ac690', 'message': 'New test: test_soft_hard_vm_reboot\n\nTest scenario:\n1) Create a VM and check connectivity\n2) Reboot (HARD) VM and check connectivity\n3) Rebbot (SOFT) VM and ccheck connectivity\nPolarion ID: RHOSP7-3677\n\nChange-Id: If3d8c7fbf5065620d7dbff1895fa4da1e5d439ab\n'}]",1,760346,247a6bb1e6ef8dbe5911c04d18300e638b8ac690,24,10,1,28609,,,0,"New test: test_soft_hard_vm_reboot

Test scenario:
1) Create a VM and check connectivity
2) Reboot (HARD) VM and check connectivity
3) Rebbot (SOFT) VM and ccheck connectivity
Polarion ID: RHOSP7-3677

Change-Id: If3d8c7fbf5065620d7dbff1895fa4da1e5d439ab
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/46/760346/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/test_basic.py'],1,247a6bb1e6ef8dbe5911c04d18300e638b8ac690,vm_reboot," @decorators.idempotent_id('af0295a0-19d0-11eb-b02e-74e5f9e2a801') def test_soft_hard_vm_reboot(self): self.setup_network_and_server() self.check_connectivity(self.fip['floating_ip_address'], CONF.validation.image_ssh_user, self.keypair['private_key']) reboot_types = ['HARD', 'SOFT'] for reboot_type in reboot_types: self.os_primary.servers_client.reboot_server( self.server['server']['id'], type=reboot_type) self.wait_for_server_active(self.server['server']) self.check_connectivity( self.fip['floating_ip_address'], CONF.validation.image_ssh_user, self.keypair['private_key'])",,16,0
openstack%2Fneutron-tempest-plugin~master~I1c3f142ffe5a49551582ad2664c48de564df9b4a,openstack/neutron-tempest-plugin,master,I1c3f142ffe5a49551582ad2664c48de564df9b4a,"New test case: ""test_remove_security_group_negative"" 1) Remove non existing security group from instance 2) Remove not associated security group from instance Expected result: ""404 NotFound"" Error for both cases. Polarion IDs: RHOSP7-3461, RHOSP7-3460",ABANDONED,2020-10-28 17:22:44.000000000,2021-01-06 09:22:10.000000000,,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 18894}, {'_account_id': 19118}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28609}, {'_account_id': 29088}, {'_account_id': 29350}, {'_account_id': 31450}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-10-28 17:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/8bd767085a554d9aec546f2a873513a9ddef9c86', 'message': 'New test case: ""test_remove_security_group_negative""\n1) Remove non existing security group from instance\n2) Remove not associated security group from instance\nExpected result: ""404 NotFound"" Error for both cases.\nPolarion IDs: RHOSP7-3461, RHOSP7-3460\n\nChange-Id: I1c3f142ffe5a49551582ad2664c48de564df9b4a\n'}, {'number': 2, 'created': '2020-10-29 07:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/02209a24724df297afe7eeee78521b843024e249', 'message': 'New test case: ""test_remove_security_group_negative""\n1) Remove non existing security group from instance\n2) Remove not associated security group from instance\nExpected result: ""404 NotFound"" Error for both cases.\nPolarion IDs: RHOSP7-3461, RHOSP7-3460\n\nChange-Id: I1c3f142ffe5a49551582ad2664c48de564df9b4a\n'}, {'number': 3, 'created': '2020-10-29 16:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/8a2d7e60e8fb0cf16319e8dafdf1f6981301fdde', 'message': 'New test case: ""test_remove_security_group_negative""\n1) Remove non existing security group from instance\n2) Remove not associated security group from instance\nExpected result: ""404 NotFound"" Error for both cases.\nPolarion IDs: RHOSP7-3461, RHOSP7-3460\n\nChange-Id: I1c3f142ffe5a49551582ad2664c48de564df9b4a\n'}, {'number': 4, 'created': '2020-10-30 05:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/a230685f1a779dd0aac7b199504c021f52bb3a70', 'message': 'New test case: ""test_remove_security_group_negative""\n1) Remove non existing security group from instance\n2) Remove not associated security group from instance\nExpected result: ""404 NotFound"" Error for both cases.\nPolarion IDs: RHOSP7-3461, RHOSP7-3460\n\nChange-Id: I1c3f142ffe5a49551582ad2664c48de564df9b4a\n'}, {'number': 5, 'created': '2020-11-02 14:20:32.000000000', 'files': ['neutron_tempest_plugin/scenario/test_security_groups.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/89bf84021ccbf46ea8878bfb9db730b6fc9db55b', 'message': 'New test case: ""test_remove_security_group_negative""\n1) Remove non existing security group from instance\n2) Remove not associated security group from instance\nExpected result: ""404 NotFound"" Error for both cases.\nPolarion IDs: RHOSP7-3461, RHOSP7-3460\n\nChange-Id: I1c3f142ffe5a49551582ad2664c48de564df9b4a\n'}]",16,760191,89bf84021ccbf46ea8878bfb9db730b6fc9db55b,31,12,5,28609,,,0,"New test case: ""test_remove_security_group_negative""
1) Remove non existing security group from instance
2) Remove not associated security group from instance
Expected result: ""404 NotFound"" Error for both cases.
Polarion IDs: RHOSP7-3461, RHOSP7-3460

Change-Id: I1c3f142ffe5a49551582ad2664c48de564df9b4a
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/91/760191/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/test_security_groups.py'],1,8bd767085a554d9aec546f2a873513a9ddef9c86,sec_group_negative,"from tempest.lib import exceptions as lib_excfrom oslo_log import log LOG = log.getLogger(__name__) @decorators.idempotent_id('5ca2fb8a-185c-11eb-a46e-74e5f9e2a801') def test_remove_security_group_negative(self): # Create ""existing security group"" existing_sg = self.os_primary.network_client.create_security_group( name=data_utils.rand_name('test_sg')) self.security_groups.append(existing_sg['security_group']) # Create ""not existing security group"" not_existing_sg = self.os_primary.network_client.create_security_group( name=data_utils.rand_name('test_sg')) self.delete_security_group(not_existing_sg['security_group']) # Create network and subnet network = self.create_network( network_name=data_utils.rand_name('test_net')) LOG.info('test_negative network: {}'.format(network)) subnet = self.create_subnet(network) LOG.info('test_negative subnet: {}'.format(subnet)) # Create the VM server_args = { 'flavor_ref': CONF.compute.flavor_ref, 'image_ref': CONF.compute.image_ref, 'key_name': self.keypair['name'], 'networks': [{'uuid': network['id']}] } server = self.create_server(**server_args) waiters.wait_for_server_status( self.os_primary.servers_client, server['server']['id'], const.SERVER_STATUS_ACTIVE) LOG.info('test_negative server: {}'.format(server['server'])) # Try to remove ""Existing SG ID"" that is not associated to VM Network # from VM. self.assertRaises( lib_exc.NotFound, self.os_primary.servers_client.remove_security_group, server_id=server['server']['id'], name=existing_sg['security_group']['id']) # Try to remove ""Not Existing SG ID"" from VM. self.assertRaises( lib_exc.NotFound, self.os_primary.servers_client.remove_security_group, server_id=server['server']['id'], name=not_existing_sg['security_group']['id'])",,51,0
openstack%2Ftempest~master~I2fc2aa14abe8a90a9d298378640440c1d4c975c6,openstack/tempest,master,I2fc2aa14abe8a90a9d298378640440c1d4c975c6,"Adding 'HARD' type reboot into ""test_minimum_basic_scenario""",ABANDONED,2020-11-09 13:21:06.000000000,2021-01-06 09:21:38.000000000,,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 8556}, {'_account_id': 10459}, {'_account_id': 11075}, {'_account_id': 11975}, {'_account_id': 19118}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 28609}, {'_account_id': 31450}]","[{'number': 1, 'created': '2020-11-09 13:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/681a3df24ae19e882d8085a957025a9f84a11727', 'message': 'Adding \'HARD\' type reboot into ""test_minimum_basic_scenario""\n\nChange-Id: I2fc2aa14abe8a90a9d298378640440c1d4c975c6\n'}, {'number': 2, 'created': '2020-11-09 20:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/228bce53258b29ba894d558f535146e55b25d45e', 'message': 'Adding \'HARD\' type reboot into ""test_minimum_basic_scenario""\n\nChange-Id: I2fc2aa14abe8a90a9d298378640440c1d4c975c6\n'}, {'number': 3, 'created': '2020-11-10 14:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c4735e23b353f8b2ca07cfc50a6d36f27ec8d346', 'message': 'Adding \'HARD\' type reboot into ""test_minimum_basic_scenario""\n\nIt\'s important to chech SSH and Disk access after VM reboot\nThere are two types to reboot VM: SOFT and HARD (power off)\nand reboot test scenario needs to cover both types.\nThe original test contains SOFT type only.\n\nChange-Id: I2fc2aa14abe8a90a9d298378640440c1d4c975c6\n'}, {'number': 4, 'created': '2020-11-29 11:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1581e01e0a776bf056ad7dc20b7e562713ab6b40', 'message': 'Adding \'HARD\' type reboot into ""test_minimum_basic_scenario""\n\nIt\'s important to chech SSH and Disk access after VM reboot\nThere are two types to reboot VM: SOFT and HARD (power off)\nand reboot test scenario needs to cover both types.\nThe original test contains SOFT type only.\n\nChange-Id: I2fc2aa14abe8a90a9d298378640440c1d4c975c6\n'}, {'number': 5, 'created': '2020-12-02 14:24:58.000000000', 'files': ['tempest/scenario/test_minimum_basic.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6ee8f0c46f371ecb1233c228e34811e8d6eae57b', 'message': 'Adding \'HARD\' type reboot into ""test_minimum_basic_scenario""\n\nIt\'s important to chech SSH and Disk access after VM reboot\nThere are two types to reboot VM: SOFT and HARD (power off)\nand reboot test scenario needs to cover both types.\nThe original test contains SOFT type only.\n\nChange-Id: I2fc2aa14abe8a90a9d298378640440c1d4c975c6\n'}]",5,761917,6ee8f0c46f371ecb1233c228e34811e8d6eae57b,30,12,5,28609,,,0,"Adding 'HARD' type reboot into ""test_minimum_basic_scenario""

It's important to chech SSH and Disk access after VM reboot
There are two types to reboot VM: SOFT and HARD (power off)
and reboot test scenario needs to cover both types.
The original test contains SOFT type only.

Change-Id: I2fc2aa14abe8a90a9d298378640440c1d4c975c6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/17/761917/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_minimum_basic.py'],1,681a3df24ae19e882d8085a957025a9f84a11727,reboot_vm," def nova_reboot(self, server, reboot_type='SOFT'): self.servers_client.reboot_server(server['id'], type=reboot_type) # check that we can SSH to the server after SOFT or HARD reboot reboot_types=['SOFT', 'HARD'] for reboot_type in reboot_types: self.nova_reboot(server, reboot_type) self.linux_client = self.get_remote_client( ssh_ip, private_key=keypair['private_key'], server=server)"," def nova_reboot(self, server): self.servers_client.reboot_server(server['id'], type='SOFT') self.nova_reboot(server) # check that we can SSH to the server after reboot self.linux_client = self.get_remote_client( ssh_ip, private_key=keypair['private_key'], server=server)",9,8
openstack%2Ftempest~master~I49208d31f4e2296b5551d6e60d10c3c36122c7d3,openstack/tempest,master,I49208d31f4e2296b5551d6e60d10c3c36122c7d3,"New test case: ""test_remove_security_group""",ABANDONED,2020-11-09 18:58:02.000000000,2021-01-06 09:21:18.000000000,,"[{'_account_id': 1131}, {'_account_id': 5690}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 8556}, {'_account_id': 10459}, {'_account_id': 11075}, {'_account_id': 11975}, {'_account_id': 19118}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 28609}, {'_account_id': 31450}]","[{'number': 1, 'created': '2020-11-09 18:58:02.000000000', 'files': ['tempest/scenario/test_security_groups_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c86800cb754afd0d6c7cce11122bf63805203c19', 'message': 'New test case: ""test_remove_security_group""\n\n1) Remove non existing security group from instance\n2) Remove not associated security group from instance\nExpected result: ""404 NotFound"" Error for both cases.\n\nChange-Id: I49208d31f4e2296b5551d6e60d10c3c36122c7d3\n'}]",6,761981,c86800cb754afd0d6c7cce11122bf63805203c19,20,13,1,28609,,,0,"New test case: ""test_remove_security_group""

1) Remove non existing security group from instance
2) Remove not associated security group from instance
Expected result: ""404 NotFound"" Error for both cases.

Change-Id: I49208d31f4e2296b5551d6e60d10c3c36122c7d3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/81/761981/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_security_groups_basic_ops.py'],1,c86800cb754afd0d6c7cce11122bf63805203c19,remove_sec_group,"from tempest.lib import exceptions as lib_exc @decorators.idempotent_id('5ca2fb8a-185c-11eb-a46e-74e5f9e2a801') @decorators.attr(type=['negative']) @utils.services('compute', 'network') def test_remove_security_group(self): """"""Test Scenario: 1) Create security group (existing_sg) 2) Create and delete security group (not_existing_sg) 3) Create VM with default security group (#1 and #2 are not in use) 4) Try to remove ""existing_sg"" from VM, expected NotFound Error 5) Try to remove ""not_existing_sg"" from VM, expected NotFound Error """""" tenant = self.primary_tenant existing_sg = self.security_groups_client.create_security_group( name=data_utils.rand_name('test_sg')) not_existing_sg = self.security_groups_client.create_security_group( name=data_utils.rand_name('test_sg')) self.security_groups_client.delete_security_group( not_existing_sg['security_group']['id']) self._create_tenant_network(tenant) name = data_utils.rand_name('test_vm') server = self._create_server( name, tenant, [tenant.security_groups['default']]) self.assertRaises( lib_exc.NotFound, self.os_primary.servers_client.remove_security_group, server_id=server['id'], name=existing_sg['security_group']['id']) self.assertRaises( lib_exc.NotFound, self.os_primary.servers_client.remove_security_group, server_id=server['id'], name=not_existing_sg['security_group']['id'])",,35,0
openstack%2Fadjutant-ui~master~Ifa46f9f0b7dca27c9e8a305932141da78b85cd50,openstack/adjutant-ui,master,Ifa46f9f0b7dca27c9e8a305932141da78b85cd50,Add doc/requirements,MERGED,2021-01-05 10:18:44.000000000,2021-01-06 08:50:53.000000000,2021-01-06 08:50:53.000000000,"[{'_account_id': 10420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 10:18:44.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/adjutant-ui/commit/d46e9e267dbeecbb81c53d2e011e580354e5a465', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: Ifa46f9f0b7dca27c9e8a305932141da78b85cd50\n""}]",0,769308,d46e9e267dbeecbb81c53d2e011e580354e5a465,6,2,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: Ifa46f9f0b7dca27c9e8a305932141da78b85cd50
",git fetch https://review.opendev.org/openstack/adjutant-ui refs/changes/08/769308/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,d46e9e267dbeecbb81c53d2e011e580354e5a465,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,5,3
openstack%2Fadjutant~master~I0b4f89cd89fd0645e27291b6613fd231d6a69feb,openstack/adjutant,master,I0b4f89cd89fd0645e27291b6613fd231d6a69feb,Add Victoria release info,MERGED,2021-01-03 01:28:16.000000000,2021-01-06 08:48:34.000000000,2021-01-06 08:47:13.000000000,"[{'_account_id': 10420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 01:28:16.000000000', 'files': ['releasenotes/source/victoria.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/adjutant/commit/eda6558b89608dc25a217cbb5625f63755989818', 'message': 'Add Victoria release info\n\nAdd the lack of release information for Victoria, this patch added it.\n\nChange-Id: I0b4f89cd89fd0645e27291b6613fd231d6a69feb\n'}]",0,768892,eda6558b89608dc25a217cbb5625f63755989818,7,2,1,30384,,,0,"Add Victoria release info

Add the lack of release information for Victoria, this patch added it.

Change-Id: I0b4f89cd89fd0645e27291b6613fd231d6a69feb
",git fetch https://review.opendev.org/openstack/adjutant refs/changes/92/768892/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/victoria.rst', 'releasenotes/source/index.rst']",2,eda6558b89608dc25a217cbb5625f63755989818,, victoria,,7,0
openstack%2Fironic-inspector~master~I1acd3f12acbaf413e0752155c1e78e84824034af,openstack/ironic-inspector,master,I1acd3f12acbaf413e0752155c1e78e84824034af,Update version of doc8,MERGED,2020-12-14 09:04:36.000000000,2021-01-06 08:39:44.000000000,2021-01-06 08:37:39.000000000,"[{'_account_id': 11076}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-12-14 09:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/1f839471667aa293bcfa8045b0d5fd645e5480a9', 'message': ""Update version of doc8\n\nThe doc8 lib supports Python 3.6 starting from version 0.8.1\nAlso removing it from test-requirements and lower-constraints as\nit's already present in tox.ini\n\nChange-Id: I1acd3f12acbaf413e0752155c1e78e84824034af\n""}, {'number': 2, 'created': '2021-01-05 08:00:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/fb5955bccef367af58c972718643fe5fdb18ffa5', 'message': 'Update version of doc8\n\nThe doc8 lib supports Python 3.6 starting from version 0.8.1\n\nChange-Id: I1acd3f12acbaf413e0752155c1e78e84824034af\n'}]",0,766896,fb5955bccef367af58c972718643fe5fdb18ffa5,12,3,2,23851,,,0,"Update version of doc8

The doc8 lib supports Python 3.6 starting from version 0.8.1

Change-Id: I1acd3f12acbaf413e0752155c1e78e84824034af
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/96/766896/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt', 'tox.ini']",3,1f839471667aa293bcfa8045b0d5fd645e5480a9,doc8-tox, doc8>=0.8.1 # Apache-2.0, doc8>=0.6.0 # Apache-2.0,1,3
openstack%2Fmagnum~master~I2dffb9e717c2fa2754a077880ab43541bff6d94e,openstack/magnum,master,I2dffb9e717c2fa2754a077880ab43541bff6d94e,requirements: Drop os-testr,ABANDONED,2020-09-08 02:13:19.000000000,2021-01-06 08:28:32.000000000,,"[{'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-09-08 02:13:19.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6c524b47be9ea9cf4c1724637d18d1fe0dc4a2d6', 'message': 'requirements: Drop os-testr\n\nDrop os-testr switched to stestr\n\nChange-Id: I2dffb9e717c2fa2754a077880ab43541bff6d94e\n'}]",0,750267,6c524b47be9ea9cf4c1724637d18d1fe0dc4a2d6,5,3,1,32238,,,0,"requirements: Drop os-testr

Drop os-testr switched to stestr

Change-Id: I2dffb9e717c2fa2754a077880ab43541bff6d94e
",git fetch https://review.opendev.org/openstack/magnum refs/changes/67/750267/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt']",2,6c524b47be9ea9cf4c1724637d18d1fe0dc4a2d6,,,os-testr==1.0.0,0,2
openstack%2Fpuppet-openstacklib~master~I260f883caa95c580566dd09092b370016de64180,openstack/puppet-openstacklib,master,I260f883caa95c580566dd09092b370016de64180,Add acceptance tests for policy file management,ABANDONED,2021-01-05 23:33:11.000000000,2021-01-06 08:14:08.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-05 23:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/ad8c7b13e9ee81297103d1467b8d120419df0c67', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 2, 'created': '2021-01-05 23:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f678c828984f09972996e12637c5b0b9553cda3b', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 3, 'created': '2021-01-06 01:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/072d10aa4ca21fe0ac0b67081af9fe5314d8cf35', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 4, 'created': '2021-01-06 02:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/afbbebd42603ab5cda39c9f19a0a8c3d7405a646', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 5, 'created': '2021-01-06 02:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f622740d1225c3009f2e84814a256765281b43ea', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 6, 'created': '2021-01-06 04:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c64e1994d7da58ef7378734c1d54535080383545', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 7, 'created': '2021-01-06 04:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/6c6369c24a344944d2cf1bd87b92760990e992e7', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 8, 'created': '2021-01-06 05:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/9a24e58ddffb4674544316ec6ccf7a2369e25722', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 9, 'created': '2021-01-06 05:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/3554c66191ca4e4062f1ce793f370f25366ed4a0', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 10, 'created': '2021-01-06 08:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/7cabf190f3a2ae9ef10f4d7c2d86295595116a4b', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}, {'number': 11, 'created': '2021-01-06 08:13:38.000000000', 'files': ['spec/defines/openstacklib_policy_base_spec.rb', 'spec/acceptance/openstacklib_policy_base_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/2cf2972360f37b279a5148630ecd7bea5c851907', 'message': 'Add acceptance tests for policy file management\n\nChange-Id: I260f883caa95c580566dd09092b370016de64180\n'}]",0,769438,2cf2972360f37b279a5148630ecd7bea5c851907,20,1,11,9816,,,0,"Add acceptance tests for policy file management

Change-Id: I260f883caa95c580566dd09092b370016de64180
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/38/769438/9 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/openstacklib_policy_base_spec.rb'],1,ad8c7b13e9ee81297103d1467b8d120419df0c67,policy,"require 'spec_helper_acceptance' describe 'policy file management' do context 'with policy.json' do it 'should work with no errors' do pp= <<-EOS Exec { logoutput => 'on_failure' } # We create the file manually here because we only want to test # the logic of the provider hence installing the whole stack would # result in some overhead that is already tested in puppet-keystone File <||> -> Keystone_config <||> file { '/tmp/openstacklib_policy.json' : ensure => file, replace => false, content => '{""key0"": ""value0""}' } class { 'openstacklib::policy::base': $file_path => '/tmp/openstacklib_policy.json', $key => 'key1', $value => 'value1', $file_format => 'json', } EOS # Run it twice and test for idempotency apply_manifest(pp, :catch_failures => true) apply_manifest(pp, :catch_changes => true) end describe file('/tmp/openstacklib_policy.json') do it { should exist } it { should contain('""key0"": ""value0""') } it { should contain('""key1"": ""value1""') } end end context 'with policy.yaml' do it 'should work with no errors' do pp= <<-EOS Exec { logoutput => 'on_failure' } # We create the file manually here because we only want to test # the logic of the provider hence installing the whole stack would # result in some overhead that is already tested in puppet-keystone File <||> -> Keystone_config <||> file { '/tmp/openstacklib_policy.json' : ensure => file, replace => false, content => 'key0: ""value0""' } class { 'openstacklib::policy::base': $file_path => '/tmp/openstacklib_policy.yaml', $key => 'key1', $value => 'value1', $file_format => 'yaml', } EOS # Run it twice and test for idempotency apply_manifest(pp, :catch_failures => true) apply_manifest(pp, :catch_changes => true) end describe file('/tmp/openstacklib_policy.yaml') do it { should exist } it { should contain('key0: \'value0\'') } it { should contain('key1: \'value1\'') } end end end ",,81,0
openstack%2Fmagnum~master~I49bb332064557f7b83512e157535857d5c7460b1,openstack/magnum,master,I49bb332064557f7b83512e157535857d5c7460b1,Make the /healthcheck publicly accessible,NEW,2020-06-16 12:40:45.000000000,2021-01-06 06:41:34.000000000,,"[{'_account_id': 6484}, {'_account_id': 8064}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-06-16 12:40:45.000000000', 'files': ['etc/magnum/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/magnum/commit/09b8f5c9a9f74047dbfb6e0311521aeb5fdf1e4f', 'message': ""Make the /healthcheck publicly accessible\n\nThere's no reason to have /healthcheck requiring auth: it's not more\ndangerous than / or /v1, and all other services have it publicly\naccessible.\n\nChange-Id: I49bb332064557f7b83512e157535857d5c7460b1\n""}]",4,735898,09b8f5c9a9f74047dbfb6e0311521aeb5fdf1e4f,16,5,1,6476,,,0,"Make the /healthcheck publicly accessible

There's no reason to have /healthcheck requiring auth: it's not more
dangerous than / or /v1, and all other services have it publicly
accessible.

Change-Id: I49bb332064557f7b83512e157535857d5c7460b1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/98/735898/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/magnum/api-paste.ini'],1,09b8f5c9a9f74047dbfb6e0311521aeb5fdf1e4f,healtcheck-public,"acl_public_routes = /, /v1, /healthcheck","acl_public_routes = /, /v1",1,1
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I7fe5404144f7a75a5a1c257ceef9593719ac5dbc,openstack/tripleo-heat-templates,stable/ussuri,I7fe5404144f7a75a5a1c257ceef9593719ac5dbc,Add package install for openssl-perl,MERGED,2020-10-26 15:28:00.000000000,2021-01-06 05:09:14.000000000,2021-01-06 05:09:14.000000000,"[{'_account_id': 7353}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}, {'_account_id': 28182}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-10-26 15:28:00.000000000', 'files': ['deployment/ipa/ipaservices-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf50c743a3bf9d126185d1044d3ad3f7b139ac5d', 'message': ""Add package install for openssl-perl\n\nopenssl-perl is used to get the directory /etc/pki/CA, which\nis needed for cert requests during the deployment.  In OVB\ndeployments, this package is part of the image and so does not need\nto be installed.\n\nIn pre-provisioned node environments, we need to document that this\npackage needs to be installed.  By adding this patch, we ensure that\nit is there before we need it for certs.\n\nThis of course assumes we're not in some kind of airgapped environment\n(which is why its dependent on IdMInstallClientPackages).  In that case,\nwe need to continue to doc what must be there.\n\nChange-Id: I7fe5404144f7a75a5a1c257ceef9593719ac5dbc\n(cherry picked from commit bc0ab07c5941194178c08ec2924474a2ae15f2b1)\n""}]",0,759721,bf50c743a3bf9d126185d1044d3ad3f7b139ac5d,39,8,1,9914,,,0,"Add package install for openssl-perl

openssl-perl is used to get the directory /etc/pki/CA, which
is needed for cert requests during the deployment.  In OVB
deployments, this package is part of the image and so does not need
to be installed.

In pre-provisioned node environments, we need to document that this
package needs to be installed.  By adding this patch, we ensure that
it is there before we need it for certs.

This of course assumes we're not in some kind of airgapped environment
(which is why its dependent on IdMInstallClientPackages).  In that case,
we need to continue to doc what must be there.

Change-Id: I7fe5404144f7a75a5a1c257ceef9593719ac5dbc
(cherry picked from commit bc0ab07c5941194178c08ec2924474a2ae15f2b1)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/759721/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ipa/ipaservices-baremetal-ansible.yaml'],1,bf50c743a3bf9d126185d1044d3ad3f7b139ac5d,add_openssl_perl_to_template-stable/ussuri, - name: install openssl-perl package: name: openssl-perl state: present when: - ipaclient_install_packages|bool,,6,0
openstack%2Fpuppet-nova~master~If545538c53677d4979e6f260a1f84caeea565c68,openstack/puppet-nova,master,If545538c53677d4979e6f260a1f84caeea565c68,Remove redundant spaces from cron commands,MERGED,2021-01-03 07:15:12.000000000,2021-01-06 05:02:14.000000000,2021-01-06 05:02:14.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-01-03 07:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f4787c8064bacdad449c333f1dd304035ee1711c', 'message': 'Remove redundant spaces from cron commands\n\nChange-Id: If545538c53677d4979e6f260a1f84caeea565c68\n'}, {'number': 2, 'created': '2021-01-03 10:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/2bca39dcb6f6f6ab3024c67045eb88c2c34c2c35', 'message': 'Remove redundant spaces from cron commands\n\nChange-Id: If545538c53677d4979e6f260a1f84caeea565c68\n'}, {'number': 3, 'created': '2021-01-03 21:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/335b2bd52aabb6bc7d9f42a7cf6254c1d749bb64', 'message': 'Remove redundant spaces from cron commands\n\nChange-Id: If545538c53677d4979e6f260a1f84caeea565c68\n'}, {'number': 4, 'created': '2021-01-03 22:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d851ad77e46a64dd13166774a5d7f99508669c19', 'message': 'Remove redundant spaces from cron commands\n\nChange-Id: If545538c53677d4979e6f260a1f84caeea565c68\n'}, {'number': 5, 'created': '2021-01-04 01:04:42.000000000', 'files': ['manifests/cron/purge_shadow_tables.pp', 'spec/classes/nova_cron_purge_shadow_tables_spec.rb', 'spec/acceptance/nova_wsgi_apache_spec.rb', 'manifests/cron/archive_deleted_rows.pp', 'spec/classes/nova_cron_archive_deleted_rows_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/508b9f7fe50076a012ad0a3337bf332a7dd7040f', 'message': 'Remove redundant spaces from cron commands\n\nChange-Id: If545538c53677d4979e6f260a1f84caeea565c68\n'}]",0,768971,508b9f7fe50076a012ad0a3337bf332a7dd7040f,21,4,5,9816,,,0,"Remove redundant spaces from cron commands

Change-Id: If545538c53677d4979e6f260a1f84caeea565c68
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/71/768971/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/cron/purge_shadow_tables.pp', 'spec/classes/nova_cron_purge_shadow_tables_spec.rb', 'manifests/cron/archive_deleted_rows.pp', 'spec/classes/nova_cron_archive_deleted_rows_spec.rb']",4,f4787c8064bacdad449c333f1dd304035ee1711c,cron-cmd-spaces," :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} --until-complete >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} --all-cells >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --purge --max_rows #{params[:max_rows]} >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --purge --max_rows #{params[:max_rows]} --until-complete >>#{params[:destination]} 2>&1"", :command => ""sleep `expr ${RANDOM} \\% #{params[:maxdelay]}`; nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} --before `date --date='today - #{params[:age]} days' +\\%F` >>#{params[:destination]} 2>&1"","," :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} --until-complete >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} --all-cells >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --purge --max_rows #{params[:max_rows]} >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --purge --max_rows #{params[:max_rows]} --until-complete >>#{params[:destination]} 2>&1"", :command => ""sleep `expr ${RANDOM} \\% #{params[:maxdelay]}`; nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} >>#{params[:destination]} 2>&1"", :command => ""nova-manage db archive_deleted_rows --max_rows #{params[:max_rows]} --before `date --date='today - #{params[:age]} days' +\\%F` >>#{params[:destination]} 2>&1"",",18,18
openstack%2Ftripleo-heat-templates~stable%2Fstein~Ia3c62668b0c1469e31aa8cd2c984b460eb06d970,openstack/tripleo-heat-templates,stable/stein,Ia3c62668b0c1469e31aa8cd2c984b460eb06d970,Add new role parameters for cpu/ram/disk allocation ratio,MERGED,2020-01-25 05:35:01.000000000,2021-01-06 04:49:38.000000000,2021-01-06 04:48:20.000000000,"[{'_account_id': 11444}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-01-25 05:35:01.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'deployment/nova/nova-base-puppet.yaml', 'releasenotes/notes/allocation_ratio-4a8ecf4cdf5fb7e2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a881043b22f025efb0186ceb0f534e3da2704439', 'message': 'Add new role parameters for cpu/ram/disk allocation ratio\n\nThis change adds three new role parameters `NovaCPUAllocationRatio`,\n`NovaRAMAllocationRatio` and `NovaDiskAllocationRatio` for\nconfiguring cpu_allocation_ratio, ram_allocation_ratio and\ndisk_allocation_ratio.\nThe default values for CPU and Disk allocation ratio are taken\nas 0.0 as it will be updated by update_available_resource method\nas mentioned in [1].\n[1]\nhttps://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/initial-allocation-ratios.html\n\nChange-Id: Ia3c62668b0c1469e31aa8cd2c984b460eb06d970\n(cherry picked from commit 5066737451035de19383bf1f7a2afa5334d7d361)\n'}]",0,704212,a881043b22f025efb0186ceb0f534e3da2704439,20,5,1,11444,,,0,"Add new role parameters for cpu/ram/disk allocation ratio

This change adds three new role parameters `NovaCPUAllocationRatio`,
`NovaRAMAllocationRatio` and `NovaDiskAllocationRatio` for
configuring cpu_allocation_ratio, ram_allocation_ratio and
disk_allocation_ratio.
The default values for CPU and Disk allocation ratio are taken
as 0.0 as it will be updated by update_available_resource method
as mentioned in [1].
[1]
https://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/initial-allocation-ratios.html

Change-Id: Ia3c62668b0c1469e31aa8cd2c984b460eb06d970
(cherry picked from commit 5066737451035de19383bf1f7a2afa5334d7d361)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/704212/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'deployment/nova/nova-base-puppet.yaml', 'releasenotes/notes/allocation_ratio-4a8ecf4cdf5fb7e2.yaml']",3,a881043b22f025efb0186ceb0f534e3da2704439,feature/cpu-ram-allocation-ratio,"--- features: - | Add new role parameters `NovaCPUAllocationRatio`, `NovaRAMAllocationRatio` and `NovaDiskAllocationRatio` which allows to configure `cpu_allocation_ratio`, `ram_allocation_ratio` and `disk_allocation_ratio`. Default value for NovaCPUAllocationRatio is 0.0 Default value for NovaRAMAllocationRatio is 1.0 Default value for NovaDiskAllocationRatio is 0.0 The default values for CPU and Disk allocation ratio are taken 0.0 as mentioned in [1]. [1] https://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/initial-allocation-ratios.html ",,38,2
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79,openstack/tripleo-heat-templates,stable/ussuri,I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79,Don't pass empty values for ipaclient_servers to ipaclient role,MERGED,2020-12-24 11:17:30.000000000,2021-01-06 04:48:15.000000000,2021-01-06 04:48:15.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-24 11:17:30.000000000', 'files': ['deployment/ipa/ipaservices-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dcab52658a9de95edd8bd9b1d0be7a09fecdf788', 'message': ""Don't pass empty values for ipaclient_servers to ipaclient role\n\nThis avoids passing an empty value to the --server and --domain options\nof ipa-client-install. These are then auto-detected, as described in\nthe IdMServer and IdMDomain parameters descriptions.\n\nChange-Id: I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79\nCloses-Bug: #1904856\nResolves: rhbz#1874936\n(cherry picked from commit 39ee7e23dadedcd6de2ab3f30b322954379b8214)\n""}]",0,768399,dcab52658a9de95edd8bd9b1d0be7a09fecdf788,8,4,1,14250,,,0,"Don't pass empty values for ipaclient_servers to ipaclient role

This avoids passing an empty value to the --server and --domain options
of ipa-client-install. These are then auto-detected, as described in
the IdMServer and IdMDomain parameters descriptions.

Change-Id: I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79
Closes-Bug: #1904856
Resolves: rhbz#1874936
(cherry picked from commit 39ee7e23dadedcd6de2ab3f30b322954379b8214)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/768399/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ipa/ipaservices-baremetal-ansible.yaml'],1,dcab52658a9de95edd8bd9b1d0be7a09fecdf788,fix_providing_server_domain_args-stable/ussuri," map_merge: - state: present ipaclient_otp: ""{{ ipa_host_otp }}"" idm_enroll_base_server: {get_param: IdMEnrollBaseServer} ipaclient_mkhomedir: {get_param: MakeHomeDir} ipaclient_no_ntp: {get_param: IdMNoNtpSetup} ipaclient_force: yes ipaclient_hostname: ""{{ fqdn_canonical }}"" ipaclient_install_packages: {get_param: IdMInstallClientPackages} ipaclients: - ""{{ inventory_hostname }}"" - if: - idm_server_provided - ipaclient_servers: {get_param: IdMServer} ipaclient_domain: {get_param: IdMDomain} - {}"," state: present ipaclient_otp: ""{{ ipa_host_otp }}"" idm_enroll_base_server: {get_param: IdMEnrollBaseServer} ipaclient_mkhomedir: {get_param: MakeHomeDir} ipaclient_domain: {get_param: IdMDomain} ipaclient_no_ntp: {get_param: IdMNoNtpSetup} ipaclient_force: yes ipaclient_servers: {get_param: IdMServer} ipaclient_hostname: ""{{ fqdn_canonical }}"" ipaclient_install_packages: {get_param: IdMInstallClientPackages} ipaclients: - ""{{ inventory_hostname }}""",18,12
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79,openstack/tripleo-heat-templates,stable/train,I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79,Don't pass empty values for ipaclient_servers to ipaclient role,MERGED,2020-12-24 11:17:49.000000000,2021-01-06 04:45:37.000000000,2021-01-06 04:45:37.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-24 11:17:49.000000000', 'files': ['deployment/ipa/ipaservices-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4b392af30cad3f9c79f7f457741882e70773a939', 'message': ""Don't pass empty values for ipaclient_servers to ipaclient role\n\nThis avoids passing an empty value to the --server and --domain options\nof ipa-client-install. These are then auto-detected, as described in\nthe IdMServer and IdMDomain parameters descriptions.\n\nChange-Id: I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79\nCloses-Bug: #1904856\nResolves: rhbz#1874936\n(cherry picked from commit 39ee7e23dadedcd6de2ab3f30b322954379b8214)\n""}]",0,768400,4b392af30cad3f9c79f7f457741882e70773a939,7,3,1,14250,,,0,"Don't pass empty values for ipaclient_servers to ipaclient role

This avoids passing an empty value to the --server and --domain options
of ipa-client-install. These are then auto-detected, as described in
the IdMServer and IdMDomain parameters descriptions.

Change-Id: I3a8725f0b64caf9fa50c90bf49634dffe0ad9b79
Closes-Bug: #1904856
Resolves: rhbz#1874936
(cherry picked from commit 39ee7e23dadedcd6de2ab3f30b322954379b8214)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/00/768400/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ipa/ipaservices-baremetal-ansible.yaml'],1,4b392af30cad3f9c79f7f457741882e70773a939,fix_providing_server_domain_args-stable/train," map_merge: - state: present ipaclient_otp: ""{{ ipa_host_otp }}"" idm_enroll_base_server: {get_param: IdMEnrollBaseServer} ipaclient_mkhomedir: {get_param: MakeHomeDir} ipaclient_no_ntp: {get_param: IdMNoNtpSetup} ipaclient_force: yes ipaclient_hostname: ""{{ fqdn_canonical }}"" ipaclient_install_packages: {get_param: IdMInstallClientPackages} ipaclients: - ""{{ inventory_hostname }}"" - if: - idm_server_provided - ipaclient_servers: {get_param: IdMServer} ipaclient_domain: {get_param: IdMDomain} - {}"," state: present ipaclient_otp: ""{{ ipa_host_otp }}"" idm_enroll_base_server: {get_param: IdMEnrollBaseServer} ipaclient_mkhomedir: {get_param: MakeHomeDir} ipaclient_domain: {get_param: IdMDomain} ipaclient_no_ntp: {get_param: IdMNoNtpSetup} ipaclient_force: yes ipaclient_servers: {get_param: IdMServer} ipaclient_hostname: ""{{ fqdn_canonical }}"" ipaclient_install_packages: {get_param: IdMInstallClientPackages} ipaclients: - ""{{ inventory_hostname }}""",18,12
openstack%2Fovn-octavia-provider~stable%2Fvictoria~Ic6b1dca1c58f982562333a5ae762b1b596355ede,openstack/ovn-octavia-provider,stable/victoria,Ic6b1dca1c58f982562333a5ae762b1b596355ede,Fix gate failure,MERGED,2020-12-14 16:10:54.000000000,2021-01-06 04:11:38.000000000,2021-01-06 04:10:24.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-14 16:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/99ca367c67cb7ff0d865f2654f55ec6abeee025b', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update. Required\nmoving minimum neutron version to Ussuri (16.0.0).\nFix associated new warnings.\n\nChange-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede\n(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)\n'}, {'number': 2, 'created': '2020-12-14 19:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/d7b0302d33c43ac2dfa09ef3bf4f101b19e5713e', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update. Required\nmoving minimum neutron version to Ussuri (16.0.0).\nFix associated new warnings.\n\nConflicts:\n    lower-constraints.txt\n    requirements.txt\n    test-requirements.txt\n\nChange-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede\n(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)\n'}, {'number': 3, 'created': '2020-12-14 20:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/96e84d853c2188a2b4cd558469ef5f385d286fda', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update. Required\nmoving minimum neutron version to Ussuri (16.0.0).\nFix associated new warnings.\n\nConflicts:\n    lower-constraints.txt\n    requirements.txt\n    test-requirements.txt\n\nChange-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede\n(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)\n'}, {'number': 4, 'created': '2020-12-15 19:32:54.000000000', 'files': ['requirements.txt', 'ovn_octavia_provider/event.py', 'test-requirements.txt', 'ovn_octavia_provider/tests/functional/requirements.txt', 'lower-constraints.txt', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/c2bb58ba8925258c349583eade1bf135cb8886e9', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update. Required\nmoving minimum neutron version to Ussuri (16.0.0).\nFix associated new warnings.\n\nConflicts:\n    lower-constraints.txt\n    requirements.txt\n    test-requirements.txt\n\nChange-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede\n(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)\n'}]",1,766813,c2bb58ba8925258c349583eade1bf135cb8886e9,32,3,4,1131,,,0,"Fix gate failure

Bumped a bunch of constraints and requirements to fix
a gate failure with recent pip update. Required
moving minimum neutron version to Ussuri (16.0.0).
Fix associated new warnings.

Conflicts:
    lower-constraints.txt
    requirements.txt
    test-requirements.txt

Change-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede
(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/13/766813/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'ovn_octavia_provider/event.py', 'test-requirements.txt', 'ovn_octavia_provider/tests/functional/requirements.txt', 'lower-constraints.txt', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py']",7,99ca367c67cb7ff0d865f2654f55ec6abeee025b,gate-failure-stable/victoria, super().__init__()," super(OvnProviderDriver, self).__init__()",66,52
openstack%2Fpuppet-neutron~master~I87dba40544a76991f5fa16705ab1af00f75e5dc9,openstack/puppet-neutron,master,I87dba40544a76991f5fa16705ab1af00f75e5dc9,Support arbitrary configurations for ovs agent and sriov agent,MERGED,2020-12-07 13:20:42.000000000,2021-01-06 03:50:13.000000000,2021-01-06 03:48:46.000000000,"[{'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-07 13:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f0b5d3603ee0abbad3e9239d7a59554ba36c3133', 'message': 'Support arbitrary configurations for ovs agent and sriov agent\n\nThis patch introduces new parameters to the neutron::config class,\nto allow us to add arbitary configurations into openvswitch_agent.ini\nand sriov_agent.ini .\n\nChange-Id: I87dba40544a76991f5fa16705ab1af00f75e5dc9\n'}, {'number': 2, 'created': '2020-12-21 12:13:00.000000000', 'files': ['spec/classes/neutron_config_spec.rb', 'releasenotes/notes/agent-arbitrary-configs-8036223e87f32c2a.yaml', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/34eef40377f32d44838ea1a3d7471f07c0fe6528', 'message': 'Support arbitrary configurations for ovs agent and sriov agent\n\nThis patch introduces new parameters to the neutron::config class,\nto allow us to add arbitary configurations into openvswitch_agent.ini\nand sriov_agent.ini .\n\nChange-Id: I87dba40544a76991f5fa16705ab1af00f75e5dc9\n'}]",0,765805,34eef40377f32d44838ea1a3d7471f07c0fe6528,11,4,2,9816,,,0,"Support arbitrary configurations for ovs agent and sriov agent

This patch introduces new parameters to the neutron::config class,
to allow us to add arbitary configurations into openvswitch_agent.ini
and sriov_agent.ini .

Change-Id: I87dba40544a76991f5fa16705ab1af00f75e5dc9
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/05/765805/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_config_spec.rb', 'releasenotes/notes/agent-arbitrary-configs-8036223e87f32c2a.yaml', 'manifests/config.pp']",3,f0b5d3603ee0abbad3e9239d7a59554ba36c3133,agent_config,"# [*ovs_agent_config*] # (optional) Manage configuration of openvswitch_agent.ini # # [*sriov_agent_config*] # (optional) Manage configuration of sriov_agent.ini # $ovs_agent_config = {}, $sriov_agent_config = {}, validate_legacy(Hash, 'validate_hash', $ovs_agent_config) validate_legacy(Hash, 'validate_hash', $sriov_agent_config) create_resources('neutron_agent_ovs', $ovs_agent_config) create_resources('neutron_sriov_agent_config', $sriov_agent_config)",,44,0
openstack%2Fpuppet-neutron~master~Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7,openstack/puppet-neutron,master,Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7,Ensure vnic_type_blacklist is unset by default,MERGED,2021-01-01 08:40:05.000000000,2021-01-06 03:48:53.000000000,2021-01-06 03:48:53.000000000,"[{'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-01 08:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/6e59660f1993e5325084e6abe2af767f0f93c015', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 2, 'created': '2021-01-01 08:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/57367804146e5b68bb8b60037bbdbcd7b8e52382', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 3, 'created': '2021-01-01 14:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2e5b562a62a5affedc931a84e8e4475623969799', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 4, 'created': '2021-01-02 00:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d23fd036d864eff0a2403c127f2a90bc25034a09', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 5, 'created': '2021-01-02 00:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/016168d9ade85c82cbe61c3780b0f8acf373f3b5', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 6, 'created': '2021-01-02 02:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/cabe205ac29c804fab5b640934d0c95ad458f40e', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 7, 'created': '2021-01-02 02:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d8b65c34dc64f81c02750fa87127af9b8a4d56a3', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 8, 'created': '2021-01-02 05:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/708bafde5758ed733c7c3c916209cff81ba75008', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}, {'number': 9, 'created': '2021-01-03 05:50:05.000000000', 'files': ['spec/classes/neutron_plugins_ml2_ovs_driver_spec.rb', 'spec/classes/neutron_plugins_ml2_sriov_driver_spec.rb', 'manifests/plugins/ml2/ovs_driver.pp', 'manifests/plugins/ml2/sriov_driver.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c1a3259fde02a5a06dda87538eb0a10162a902da', 'message': 'Ensure vnic_type_blacklist is unset by default\n\n... and fix some ineffective unit test cases.\n\nChange-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7\n'}]",0,768818,c1a3259fde02a5a06dda87538eb0a10162a902da,24,4,9,9816,,,0,"Ensure vnic_type_blacklist is unset by default

... and fix some ineffective unit test cases.

Change-Id: Ibc6c12c39d9a924f22c499d33856cb0c7fdf8cd7
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/18/768818/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_ovs_driver_spec.rb', 'spec/classes/neutron_plugins_ml2_sriov_driver_spec.rb', 'manifests/plugins/ml2/ovs_driver.pp', 'manifests/plugins/ml2/sriov_driver.pp']",4,6e59660f1993e5325084e6abe2af767f0f93c015,plugins-ml2," validate_legacy(Array, 'validate_array', $vnic_type_blacklist) } else { neutron_plugin_ml2 { 'sriov_driver/vnic_type_blacklist': value => $::os_service_default; }",,34,12
openstack%2Fpuppet-neutron~master~Ibb0b7bcc268752802f3413648e6828fd4999cc9b,openstack/puppet-neutron,master,Ibb0b7bcc268752802f3413648e6828fd4999cc9b,Fix ignored unit test cases,MERGED,2021-01-01 08:40:05.000000000,2021-01-06 03:48:49.000000000,2021-01-06 03:48:49.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-01 08:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a7d534d9acc870a49c599646dc1f6088f3a83570', 'message': 'Fix ignored unit test cases\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 2, 'created': '2021-01-01 08:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/07736607cc62fbdb292e045e589878370b9cb77b', 'message': 'Fix ignored unit test cases\n\nThis change ensures that unit test cases for the following two classes\nare properly executed in gate tests.\n - neutron::plugins::ml2::ovs_driver\n - neutron::plugins::ml2::sriov_driver\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 3, 'created': '2021-01-01 14:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/3f709c10a082497c31cba56ea0a250cfda9f99a3', 'message': 'Fix ignored unit test cases\n\nThis change ensures that unit test cases for the following two classes\nare properly executed in gate tests.\n - neutron::plugins::ml2::ovs_driver\n - neutron::plugins::ml2::sriov_driver\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 4, 'created': '2021-01-02 00:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f6b524ad1c0154878d7c31c69d043caeb61ebcce', 'message': 'Fix ignored unit test cases\n\nThis change ensures that unit test cases for the following two classes\nare properly executed in gate tests.\n - neutron::plugins::ml2::ovs_driver\n - neutron::plugins::ml2::sriov_driver\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 5, 'created': '2021-01-02 00:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/980bcac2386f6e7f3bd52b592ce8f976f0da1a94', 'message': 'Fix ignored unit test cases\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 6, 'created': '2021-01-02 02:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ca14a5ed81f6abcad00d84f48b03c81e535fad88', 'message': 'Fix ignored unit test cases\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 7, 'created': '2021-01-02 02:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d2627568207666be9d5ba576656e05fa85bc9ed6', 'message': 'Fix ignored unit test cases\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 8, 'created': '2021-01-02 05:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/96c4a929b3c44d7b29f4c3f9dcfff844044b129e', 'message': 'Fix ignored unit test cases\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}, {'number': 9, 'created': '2021-01-03 05:50:05.000000000', 'files': ['spec/classes/neutron_plugins_ml2_ovs_driver_spec.rb', 'spec/classes/neutron_plugins_ml2_sriov_driver_spec.rb', 'spec/unit/type/neutron_subnet_spec.rb', 'spec/classes/neutron_plugins_ml2_ovs_driver.rb', 'spec/classes/neutron_agents_bigswitch_spec.rb', 'spec/classes/neutron_plugins_ml2_sriov_driver.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ce4c032d1722e288c2468fd279fdb113dceb23f8', 'message': 'Fix ignored unit test cases\n\nChange-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b\n'}]",0,768817,ce4c032d1722e288c2468fd279fdb113dceb23f8,20,3,9,9816,,,0,"Fix ignored unit test cases

Change-Id: Ibb0b7bcc268752802f3413648e6828fd4999cc9b
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/17/768817/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_ovs_driver_spec.rb', 'spec/classes/neutron_plugins_ml2_sriov_driver_spec.rb']",2,a7d534d9acc870a49c599646dc1f6088f3a83570,plugins-ml2," on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts()) end it_behaves_like 'neutron::plugins::ml2::sriov_driver' end end",,24,0
openstack%2Fswift~master~I8db90ce8198aad720a644186d6a122df6f0058ae,openstack/swift,master,I8db90ce8198aad720a644186d6a122df6f0058ae,Run linters on py3,MERGED,2020-12-17 17:30:40.000000000,2021-01-06 01:43:37.000000000,2021-01-06 01:41:52.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 17:30:40.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/6058b1c4ea9368ba02a25a7b56f6ff16994a13f5', 'message': 'Run linters on py3\n\nChange-Id: I8db90ce8198aad720a644186d6a122df6f0058ae\n'}]",0,767596,6058b1c4ea9368ba02a25a7b56f6ff16994a13f5,9,2,1,15343,,,0,"Run linters on py3

Change-Id: I8db90ce8198aad720a644186d6a122df6f0058ae
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/767596/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6058b1c4ea9368ba02a25a7b56f6ff16994a13f5,,,basepython = python2.7 deps = {[testenv:py27]deps}[testenv:py3pep8] basepython = python3 commands = {[testenv:pep8]commands} ,0,6
openstack%2Fopenstack-helm-images~master~Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2,openstack/openstack-helm-images,master,Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2,[test],ABANDONED,2021-01-05 22:02:07.000000000,2021-01-06 01:41:27.000000000,,[],"[{'number': 1, 'created': '2021-01-05 22:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/2c61d56ca93c6c1dd6573a12f517bcd84c7dd4b9', 'message': '[test]\n\nChange-Id: Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}, {'number': 2, 'created': '2021-01-05 22:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/7a605ca86820caa01bbaccbb20b38cb4f803d323', 'message': '[test]\n\nChange-Id: Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}, {'number': 3, 'created': '2021-01-05 23:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d559edb4d67dd71dcf48978302b23db5b10403d9', 'message': '[test]\n\nChange-Id: Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}, {'number': 4, 'created': '2021-01-05 23:31:44.000000000', 'files': ['zuul.d/mariadb.yaml', 'zuul.d/openvswitch.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/92b06e1f315d0f8855672c35d32b50850f8fa4cf', 'message': '[test]\n\nChange-Id: Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}]",0,769425,92b06e1f315d0f8855672c35d32b50850f8fa4cf,5,0,4,8863,,,0,"[test]

Change-Id: Ifa0da38113425763c09aeb4dff5159d4c4c2e3c2
Signed-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/25/769425/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/openvswitch.yaml'],1,2c61d56ca93c6c1dd6573a12f517bcd84c7dd4b9,, - openstack-helm-images-cinder-stein-ubuntu_bionic: dependencies: - name: openstack-helm-images-compute-kit-stein-ubuntu_bionic - name: openstack-helm-images-compute-kit-train-ubuntu_bionic,,4,0
openstack%2Fzaqar~master~I97fb088bc36540ea74fdd2da24a2e46114665d3a,openstack/zaqar,master,I97fb088bc36540ea74fdd2da24a2e46114665d3a,Update the requirement of doc8,ABANDONED,2021-01-04 07:42:04.000000000,2021-01-06 01:00:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-04 07:42:04.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/988ef4385b6d324b571a022ac48e095634a170e2', 'message': 'Update the requirement of doc8\n\nUpdate the requirement and lower-constraints in\nW release.\n\nChange-Id: I97fb088bc36540ea74fdd2da24a2e46114665d3a\n'}]",0,769093,988ef4385b6d324b571a022ac48e095634a170e2,3,1,1,8846,,,0,"Update the requirement of doc8

Update the requirement and lower-constraints in
W release.

Change-Id: I97fb088bc36540ea74fdd2da24a2e46114665d3a
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/93/769093/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt']",2,988ef4385b6d324b571a022ac48e095634a170e2,update-requiement,doc8==0.8.1 docutils==0.15.2,doc8==0.6.0,3,2
openstack%2Fpython-swiftclient~master~I791cc993aef832b30c08fdb5bdd7165a074d263f,openstack/python-swiftclient,master,I791cc993aef832b30c08fdb5bdd7165a074d263f,remove unicode from code,MERGED,2021-01-03 08:44:38.000000000,2021-01-06 00:46:54.000000000,2021-01-06 00:45:46.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 08:44:38.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e6876361f079e9ccd526958e005258bdc68273e9', 'message': 'remove unicode from code\n\nChange-Id: I791cc993aef832b30c08fdb5bdd7165a074d263f\n'}]",0,769036,e6876361f079e9ccd526958e005258bdc68273e9,7,2,1,30384,,,0,"remove unicode from code

Change-Id: I791cc993aef832b30c08fdb5bdd7165a074d263f
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/36/769036/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,e6876361f079e9ccd526958e005258bdc68273e9,,"copyright = '%d, OpenStack Foundation' % datetime.datetime.now().year# html_title = 'swift v2.10.0'# (master_doc, 'swift.tex', 'swift Documentation', # 'swift', 'manual'),# (master_doc, 'swift', 'swift Documentation',# (master_doc, 'swift', 'swift Documentation',","copyright = u'%d, OpenStack Foundation' % datetime.datetime.now().year# html_title = u'swift v2.10.0'# (master_doc, 'swift.tex', u'swift Documentation', # u'swift', 'manual'),# (master_doc, 'swift', u'swift Documentation',# (master_doc, 'swift', u'swift Documentation',",9,9
openstack%2Fopenstack-helm~master~Ic43f7b3113942d296728b06f1fcb82bd9fbd3e44,openstack/openstack-helm,master,Ic43f7b3113942d296728b06f1fcb82bd9fbd3e44,Swap SSH key names to reflect the correct key,MERGED,2021-01-04 19:33:48.000000000,2021-01-06 00:40:22.000000000,2021-01-06 00:36:48.000000000,"[{'_account_id': 18250}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 24780}, {'_account_id': 31746}]","[{'number': 1, 'created': '2021-01-04 19:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/efd42208d6ad995db6db40793e1b1411e492c5e7', 'message': 'Swap SSH key names to reflect the correct key\n\nChange-Id: Ic43f7b3113942d296728b06f1fcb82bd9fbd3e44\n'}, {'number': 2, 'created': '2021-01-04 21:16:10.000000000', 'files': ['nova/values_overrides/ssh.yaml', 'nova/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/35f55106c04ffb63764615ca73ea74ef84c2a391', 'message': 'Swap SSH key names to reflect the correct key\n\nChange-Id: Ic43f7b3113942d296728b06f1fcb82bd9fbd3e44\n'}]",0,769207,35f55106c04ffb63764615ca73ea74ef84c2a391,23,6,2,18256,,,0,"Swap SSH key names to reflect the correct key

Change-Id: Ic43f7b3113942d296728b06f1fcb82bd9fbd3e44
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/07/769207/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/values_overrides/ssh.yaml'],1,efd42208d6ad995db6db40793e1b1411e492c5e7,, ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDfgGkoPxu6jVqyBTGDlhGqoFFaTymMOH3pDRzrzXCVodqrtv1heBAyi7L63+MZ+m/facDDo43hWzhFLmmMgD00AS7L+VH+oeEwKVCfq0HN3asKLadpweBQVAkGX7PzjRKF25qj6J7iVpKAf1NcnJCsWL3b+wC9mwK7TmupOmWra8BrfP7Fvek1RLx3lwk+ZZ9lUlm6o+jwXn/9rCEFa7ywkGpdrPRBNHQshGjDlJPi15boXIKxOmoZ/DszkJq7iLYQnwa4Kdb0dJ9OE/l2LLBiEpkMlTnwXA7QCS5jEHXwW78b4BOZvqrFflga+YldhDmkyRRfnhcF5Ok2zQmx9Q+t root@openstack-helm private_key: |, private_key: | ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDfgGkoPxu6jVqyBTGDlhGqoFFaTymMOH3pDRzrzXCVodqrtv1heBAyi7L63+MZ+m/facDDo43hWzhFLmmMgD00AS7L+VH+oeEwKVCfq0HN3asKLadpweBQVAkGX7PzjRKF25qj6J7iVpKAf1NcnJCsWL3b+wC9mwK7TmupOmWra8BrfP7Fvek1RLx3lwk+ZZ9lUlm6o+jwXn/9rCEFa7ywkGpdrPRBNHQshGjDlJPi15boXIKxOmoZ/DszkJq7iLYQnwa4Kdb0dJ9OE/l2LLBiEpkMlTnwXA7QCS5jEHXwW78b4BOZvqrFflga+YldhDmkyRRfnhcF5Ok2zQmx9Q+t root@openstack-helm,2,2
openstack%2Fpuppet-openstacklib~stable%2Fussuri~I45b80ad1e1b1c0f6d91ec32e1d4e6d02489bf548,openstack/puppet-openstacklib,stable/ussuri,I45b80ad1e1b1c0f6d91ec32e1d4e6d02489bf548,Fix up rabbitmq dependency,MERGED,2021-01-05 05:03:38.000000000,2021-01-06 00:38:34.000000000,2021-01-05 16:01:47.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 05:03:38.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/49ed85acd4e1a5f541895ef9de2fb346a8ad20b6', 'message': 'Fix up rabbitmq dependency\n\nOther openstack modules in the ussuri branch has puppet/rabbitmq\ndependency version at "">=8.4.0 <9.0.0"" [1]. Having openstacklib\'s rabbitmq\ndependency at "">=2.0.2 <6.0.0"" means the modules can never be installed\nby a tool that enforces metadata.json (e.g. puppet-librarian)\n\n[1]: https://opendev.org/openstack/puppet-nova/src/branch/stable/ussuri/metadata.json#L33-L34\n\nChange-Id: I45b80ad1e1b1c0f6d91ec32e1d4e6d02489bf548\n'}]",0,769244,49ed85acd4e1a5f541895ef9de2fb346a8ad20b6,9,3,1,8064,,,0,"Fix up rabbitmq dependency

Other openstack modules in the ussuri branch has puppet/rabbitmq
dependency version at "">=8.4.0 <9.0.0"" [1]. Having openstacklib's rabbitmq
dependency at "">=2.0.2 <6.0.0"" means the modules can never be installed
by a tool that enforces metadata.json (e.g. puppet-librarian)

[1]: https://opendev.org/openstack/puppet-nova/src/branch/stable/ussuri/metadata.json#L33-L34

Change-Id: I45b80ad1e1b1c0f6d91ec32e1d4e6d02489bf548
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/44/769244/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,49ed85acd4e1a5f541895ef9de2fb346a8ad20b6,," ""version_requirement"": "">=8.4.0 <9.0.0"""," ""version_requirement"": "">=2.0.2 <6.0.0""",1,1
openstack%2Fswift~master~Ifd4aea2b9f97a94dd73bede8918e40b6a4bc2f11,openstack/swift,master,Ifd4aea2b9f97a94dd73bede8918e40b6a4bc2f11,Improve test_utils.TestCloseableChain,MERGED,2020-12-30 10:45:21.000000000,2021-01-06 00:31:30.000000000,2021-01-06 00:29:47.000000000,"[{'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-30 10:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/552ce4b3259c23b6bc1e1aca661fbfedf3b9c360', 'message': 'Improve test_utils.TestCloseableChain\n\nAdd assertions with a generator in the CloseableChain.\n\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nChange-Id: Ifd4aea2b9f97a94dd73bede8918e40b6a4bc2f11\n'}, {'number': 2, 'created': '2020-12-30 11:40:42.000000000', 'files': ['test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d64522a68fedf9841f49c668633a37e4c182765f', 'message': 'Improve test_utils.TestCloseableChain\n\nAdd assertions with a generator in the CloseableChain.\n\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nChange-Id: Ifd4aea2b9f97a94dd73bede8918e40b6a4bc2f11\n'}]",1,768774,d64522a68fedf9841f49c668633a37e4c182765f,14,3,2,7847,,,0,"Improve test_utils.TestCloseableChain

Add assertions with a generator in the CloseableChain.

Co-Authored-By: Tim Burke <tim.burke@gmail.com>
Change-Id: Ifd4aea2b9f97a94dd73bede8918e40b6a4bc2f11
",git fetch https://review.opendev.org/openstack/swift refs/changes/74/768774/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/test_utils.py'],1,552ce4b3259c23b6bc1e1aca661fbfedf3b9c360,p-slo-close-iter-test," # check with generator in the chain generator_closed = [False] def gen(): try: yield 2 yield 3 except GeneratorExit: generator_closed[0] = True raise test_iter1 = FakeIterable([1]) chain = utils.CloseableChain(test_iter1, gen()) self.assertEqual(0, test_iter1.close_call_count) self.assertFalse(generator_closed[0]) chain.close() self.assertEqual(1, test_iter1.close_call_count) # Generator never kicked off, so there's no GeneratorExit self.assertFalse(generator_closed[0]) test_iter1 = FakeIterable([1]) chain = utils.CloseableChain(gen(), test_iter1) self.assertEqual(2, next(chain)) # Kick off the generator self.assertEqual(0, test_iter1.close_call_count) self.assertFalse(generator_closed[0]) chain.close() self.assertEqual(1, test_iter1.close_call_count) self.assertTrue(generator_closed[0])",,29,0
openstack%2Fopenstack-ansible~stable%2Fvictoria~I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3,openstack/openstack-ansible,stable/victoria,I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3,Update deploy guide to reflect the current status of OSA,MERGED,2021-01-04 21:10:19.000000000,2021-01-06 00:17:12.000000000,2021-01-06 00:14:24.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 25600}]","[{'number': 1, 'created': '2021-01-04 21:10:19.000000000', 'files': ['deploy-guide/source/app-aboutosa.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e2eaac58b8657bc8784fc05536a9622632f65bc3', 'message': 'Update deploy guide to reflect the current status of OSA\n\nChange-Id: I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3\n(cherry picked from commit 6614e27a1139afc748d44f967b560bd845ee04b4)\n'}]",0,769178,e2eaac58b8657bc8784fc05536a9622632f65bc3,8,3,1,25023,,,0,"Update deploy guide to reflect the current status of OSA

Change-Id: I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3
(cherry picked from commit 6614e27a1139afc748d44f967b560bd845ee04b4)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/78/769178/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-aboutosa.rst'],1,e2eaac58b8657bc8784fc05536a9622632f65bc3,,"For isolation and ease of maintenance, all OpenStack services are installed by default from source code into python virtual environments. The services are further isolated via the use of LXC containers, but these are optional and a bare metal based installation is also possible. We currently support LXC containers, if you want to go 100% Docker,* You want to deploy OpenStack services from distribution packages (deb or rpm). Whilst there is some support for this, coverage of the services is incomplete and a lot of operator flexibility is lost when using this approach.","For isolation and ease of maintenance, you can install OpenStack components into machine containers.* Supports the major CPU architectures x86, ppc64, s390x (WIP). We currently support machine containers, with lxc and we will support *systemd-nspawn* in the future (WIP). If you want to go 100% Docker,",10,5
openstack%2Fopenstack-ansible~stable%2Fvictoria~I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5,openstack/openstack-ansible,stable/victoria,I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5,Fix keystone IDP setup,MERGED,2021-01-04 21:12:10.000000000,2021-01-06 00:15:50.000000000,2021-01-06 00:14:20.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27915}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-04 21:12:10.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7a0ca0b569353efffe6d57dea9f7f95b6ff51b48', 'message': 'Fix keystone IDP setup\n\nThe current version does not include the os_keystone role correctly,\nas it runs the whole os_keystone role again and ignores the\ntasks_from: parameter.\n\nThis fix has been tested and now it correctly configures the SP/IDP\nconfiguration.\n\nChange-Id: I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5\nCloses-Bug: 1908510\n(cherry picked from commit 2bb60193028fc848e87cdc7f416019482b8cf2cb)\n'}]",0,769181,7a0ca0b569353efffe6d57dea9f7f95b6ff51b48,9,4,1,25023,,,0,"Fix keystone IDP setup

The current version does not include the os_keystone role correctly,
as it runs the whole os_keystone role again and ignores the
tasks_from: parameter.

This fix has been tested and now it correctly configures the SP/IDP
configuration.

Change-Id: I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5
Closes-Bug: 1908510
(cherry picked from commit 2bb60193028fc848e87cdc7f416019482b8cf2cb)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/769181/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-keystone-install.yml'],1,7a0ca0b569353efffe6d57dea9f7f95b6ff51b48,1908510-stable/victoria," tasks: - name: ""Post configure SP/IDP"" include_role: name: os_keystone tasks_from: main_keystone_federation_sp_idp_setup.yml", roles: - role: os_keystone tasks_from: main_keystone_federation_sp_idp_setup.yml,5,3
openstack%2Fnova~master~I66c209baf11c37ffebca52764263daae9e1dd50b,openstack/nova,master,I66c209baf11c37ffebca52764263daae9e1dd50b,Improving the description for unshelve request body,MERGED,2020-12-16 01:50:49.000000000,2021-01-06 00:01:11.000000000,2021-01-05 23:59:15.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28182}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-16 01:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/361137647688cb77ca7e7db343bad44520b34df7', 'message': ""Improving the description for az of unshleve API\n\nThe 'availability_zone' description in unshleve api-ref is confusing,\nadding NOTE for it:\n\nSince microversion 2.77, allowed request body schema are {'unshelve':\nnull} or {'unshelve': {'availability_zone': <string>}}, and {'unshelve':\n{}} request body is not allowed.\n\nCloses-Bug: #1908336\nChange-Id: I66c209baf11c37ffebca52764263daae9e1dd50b\n""}, {'number': 2, 'created': '2020-12-24 13:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ee8db454a36185a2a2d45923a5af6ad0acdd095', 'message': ""Improving the description for az of unshleve API\n\nThe 'availability_zone' description in unshleve api-ref is confusing,\nadding NOTE for it:\n\nSince microversion 2.77, allowed request body schema are {'unshelve':\nnull} or {'unshelve': {'availability_zone': <string>}}, and {'unshelve':\n{}} request body is not allowed.\n\nCloses-Bug: #1908336\nChange-Id: I66c209baf11c37ffebca52764263daae9e1dd50b\n""}, {'number': 3, 'created': '2020-12-25 00:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9918ede0d056edcca03c9c6dd0f1a390376c4c18', 'message': ""Improving the description for az of unshleve API\n\nThe 'availability_zone' description in unshleve api-ref is confusing,\nadding NOTE for it:\n\nSince microversion 2.77, allowed request body schema are {'unshelve':\nnull} or {'unshelve': {'availability_zone': <string>}}, and {'unshelve':\n{}} request body is not allowed.\n\nCloses-Bug: #1908336\nChange-Id: I66c209baf11c37ffebca52764263daae9e1dd50b\n""}, {'number': 4, 'created': '2020-12-25 01:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/945fd6e13399372bcdcd46a835177e51cd5897ab', 'message': ""Improving the description for unshleve request body\n\nThe 'availability_zone' description in unshleve api-ref is confusing,\nadding NOTE for it:\n\nSince microversion 2.77, allowed request body schema are {'unshelve':\nnull} or {'unshelve': {'availability_zone': <string>}}, and {'unshelve':\n{}} request body is not allowed.\n\nCloses-Bug: #1908336\nChange-Id: I66c209baf11c37ffebca52764263daae9e1dd50b\n""}, {'number': 5, 'created': '2020-12-25 01:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb66f1e1f49216c724c672d04bcfb74f07922886', 'message': ""Improving the description for unshleve request body\n\nThe 'availability_zone' description in unshleve api-ref is confusing,\nadding NOTE for unshelve request body:\n\nSince microversion 2.77, allowed request body schema are {'unshelve':\nnull} or {'unshelve': {'availability_zone': <string>}}. A request body\nof {'unshelve':{}} is not allowed.\n\nCloses-Bug: #1908336\nChange-Id: I66c209baf11c37ffebca52764263daae9e1dd50b\n""}, {'number': 6, 'created': '2021-01-05 12:21:10.000000000', 'files': ['api-ref/source/servers-action-shelve.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/b4f560d4e193f457d2cd5724c62d2b6adcaf332b', 'message': 'Improving the description for unshelve request body\n\nThe \'availability_zone\' description in unshelve api-ref is confusing,\nadding NOTE for unshelve request body:\n\nSince microversion 2.77, allowed request body schema are {""unshelve"":\nnull} or {""unshelve"": {""availability_zone"": <string>}}. A request body\nof {""unshelve"":{}} is not allowed.\n\nCloses-Bug: #1908336\nChange-Id: I66c209baf11c37ffebca52764263daae9e1dd50b\n'}]",13,767251,b4f560d4e193f457d2cd5724c62d2b6adcaf332b,47,11,6,26458,,,0,"Improving the description for unshelve request body

The 'availability_zone' description in unshelve api-ref is confusing,
adding NOTE for unshelve request body:

Since microversion 2.77, allowed request body schema are {""unshelve"":
null} or {""unshelve"": {""availability_zone"": <string>}}. A request body
of {""unshelve"":{}} is not allowed.

Closes-Bug: #1908336
Change-Id: I66c209baf11c37ffebca52764263daae9e1dd50b
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/767251/5 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/parameters.yaml'],1,361137647688cb77ca7e7db343bad44520b34df7,bug/1908336," .. note:: Since microversion 2.77, allowed request body schema are {'unshelve': null} or {'unshelve': {'availability_zone': <string>}}, and {'unshelve': {}} request body is not allowed.",,4,0
openstack%2Fovn-octavia-provider~stable%2Fussuri~Ic6b1dca1c58f982562333a5ae762b1b596355ede,openstack/ovn-octavia-provider,stable/ussuri,Ic6b1dca1c58f982562333a5ae762b1b596355ede,Fix gate failure,MERGED,2020-12-15 22:17:53.000000000,2021-01-05 23:40:06.000000000,2021-01-05 23:38:38.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-15 22:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/a873340a385fc284717f7f762226480fbfbf6488', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update. Required\nmoving minimum neutron version to Ussuri (16.0.0).\nFix associated new warnings.\n\nConflicts:\n    lower-constraints.txt\n    requirements.txt\n    test-requirements.txt\n\nChange-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede\n(partially cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)\n'}, {'number': 2, 'created': '2020-12-16 02:28:32.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'ovn_octavia_provider/tests/unit/hacking/test_checks.py', 'ovn_octavia_provider/tests/functional/requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/3204fcfa7d0d2189977d2195ef27d58e39fe67aa', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update. Required\nmoving minimum neutron version to Ussuri (16.0.0).\nFix associated new warnings.\n\nConflicts:\n    lower-constraints.txt\n    requirements.txt\n    test-requirements.txt\n\nChange-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede\n(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)\n'}]",0,767224,3204fcfa7d0d2189977d2195ef27d58e39fe67aa,13,3,2,1131,,,0,"Fix gate failure

Bumped a bunch of constraints and requirements to fix
a gate failure with recent pip update. Required
moving minimum neutron version to Ussuri (16.0.0).
Fix associated new warnings.

Conflicts:
    lower-constraints.txt
    requirements.txt
    test-requirements.txt

Change-Id: Ic6b1dca1c58f982562333a5ae762b1b596355ede
(cherry picked from commit b882a7f69def632b862c969af0e4fc4bfcec9d03)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/24/767224/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'ovn_octavia_provider/tests/unit/hacking/test_checks.py', 'lower-constraints.txt', 'tox.ini']",5,a873340a385fc284717f7f762226480fbfbf6488,gate-failure-stable/ussuri,local-check-factory = ovn_octavia_provider.hacking.checks.factory,local-check-factory = neutron_lib.hacking.checks.factory,47,38
openstack%2Fpython-manilaclient~master~I39919d38854387af21da410849905698ad261e9f,openstack/python-manilaclient,master,I39919d38854387af21da410849905698ad261e9f,[OSC] Implement Share Adopt & Abandon Commands,MERGED,2020-11-15 11:43:52.000000000,2021-01-05 23:35:53.000000000,2021-01-05 23:34:28.000000000,"[{'_account_id': 6413}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 32531}]","[{'number': 1, 'created': '2020-11-15 11:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/67b4c9cd0527530bcf9293029be5667ad659f140', 'message': ""[OSC] Implement Share Adopt & Abandon Commands\n\nThis commit adds 'openstack share adopt' and 'openstack share abandon'\ncommands, that implement the same functionality as 'manila manage' and\n'manila unmanage' commands\n\nUsage:\nopenstack share adopt <service-host> <protocol> <export-path>\nopenstack share abandon <share>\n\nPartially-implements bp openstack-client-support\nChange-Id: I39919d38854387af21da410849905698ad261e9f\n""}, {'number': 2, 'created': '2020-11-18 19:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/752d71c807ef97f955ed5008b4b55297e38642eb', 'message': ""[OSC] Implement Share Adopt & Abandon Commands\n\nThis commit adds 'openstack share adopt' and 'openstack share abandon'\ncommands, that implement the same functionality as 'manila manage' and\n'manila unmanage' commands\n\nUsage:\nopenstack share adopt <service-host> <protocol> <export-path>\nopenstack share abandon <share>\n\nPartially-implements bp openstack-client-support\nChange-Id: I39919d38854387af21da410849905698ad261e9f\n""}, {'number': 3, 'created': '2020-12-19 15:31:21.000000000', 'files': ['manilaclient/osc/v2/share.py', 'manilaclient/tests/unit/osc/v2/test_share.py', 'doc/source/cli/osc/v2/index.rst', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/bf3e7cb7161dc3f48dbba36e6619f2b924b2795b', 'message': ""[OSC] Implement Share Adopt & Abandon Commands\n\nThis commit adds 'openstack share adopt' and 'openstack share abandon'\ncommands, that implement the same functionality as 'manila manage' and\n'manila unmanage' commands\n\nUsage:\nopenstack share adopt <service-host> <protocol> <export-path>\nopenstack share abandon <share>\n\nPartially-implements bp openstack-client-support\nChange-Id: I39919d38854387af21da410849905698ad261e9f\n""}]",7,762754,bf3e7cb7161dc3f48dbba36e6619f2b924b2795b,17,4,3,31213,,,0,"[OSC] Implement Share Adopt & Abandon Commands

This commit adds 'openstack share adopt' and 'openstack share abandon'
commands, that implement the same functionality as 'manila manage' and
'manila unmanage' commands

Usage:
openstack share adopt <service-host> <protocol> <export-path>
openstack share abandon <share>

Partially-implements bp openstack-client-support
Change-Id: I39919d38854387af21da410849905698ad261e9f
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/54/762754/3 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/osc/v2/share.py', 'manilaclient/tests/unit/osc/v2/test_share.py', 'doc/source/cli/osc/v2/index.rst', 'setup.cfg']",4,67b4c9cd0527530bcf9293029be5667ad659f140,bp/openstack-client-support, share_adopt = manilaclient.osc.v2.share:AdoptShare share_abandon = manilaclient.osc.v2.share:AbandonShare,,439,0
openstack%2Fopenstack-ansible~master~I051539fc3bbd3bfcddc30048348c571dd6a5c7e1,openstack/openstack-ansible,master,I051539fc3bbd3bfcddc30048348c571dd6a5c7e1,Add haproxy_*_service variables,MERGED,2021-01-05 11:45:58.000000000,2021-01-05 23:28:56.000000000,2021-01-05 23:26:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-05 11:45:58.000000000', 'files': ['releasenotes/notes/haproxy_service_variables-ffd7958b20dfe92c.yaml', 'inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/65a8c2413e1e8f91fd6d712cb84af2ab01784299', 'message': 'Add haproxy_*_service variables\n\nThis aims to ease override of the specific service listen port or other\nhaproxy frontend/backend setting without override of all backends.\n\nChange-Id: I051539fc3bbd3bfcddc30048348c571dd6a5c7e1\n'}]",0,769326,65a8c2413e1e8f91fd6d712cb84af2ab01784299,8,3,1,28619,,,0,"Add haproxy_*_service variables

This aims to ease override of the specific service listen port or other
haproxy frontend/backend setting without override of all backends.

Change-Id: I051539fc3bbd3bfcddc30048348c571dd6a5c7e1
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/26/769326/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/haproxy_service_variables-ffd7958b20dfe92c.yaml', 'inventory/group_vars/haproxy/haproxy.yml']",2,65a8c2413e1e8f91fd6d712cb84af2ab01784299,,"haproxy_adjutant_api_service: haproxy_service_name: adjutant_api haproxy_backend_nodes: ""{{ groups['adjutant_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['adjutant_api'] is defined and groups['adjutant_api'] | length > 0 }}"" haproxy_aodh_api_service: haproxy_service_name: aodh_api haproxy_backend_nodes: ""{{ groups['aodh_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8042 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['aodh_api'] is defined and groups['aodh_api'] | length > 0 }}"" haproxy_barbican_service: haproxy_service_name: barbican haproxy_backend_nodes: ""{{ groups['barbican_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9311 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['barbican_api'] is defined and groups['barbican_api'] | length > 0 }}"" haproxy_ceph_rgw_service: haproxy_service_name: ceph-rgw haproxy_backend_nodes: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) | ternary(groups['ceph-rgw'], ceph_rgws) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: ""{{ radosgw_service_port | default(7980) }}"" haproxy_balance_type: http haproxy_backend_options: - httpchk HEAD / haproxy_backend_httpcheck_options: - expect rstatus 200|405 haproxy_service_enabled: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0) }}"" haproxy_cinder_api_service: haproxy_service_name: cinder_api haproxy_backend_nodes: ""{{ groups['cinder_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8776 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['cinder_api'] is defined and groups['cinder_api'] | length > 0 }}"" haproxy_designate_api_service: haproxy_service_name: designate_api haproxy_backend_nodes: ""{{ groups['designate_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9001 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['designate_api'] is defined and groups['designate_api'] | length > 0 }}"" haproxy_galera_service: haproxy_service_name: galera haproxy_backend_nodes: ""{{ (groups['galera_all'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['galera_all'] | default([]))[1:] }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 3306 haproxy_check_port: 9200 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_galera_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['galera_all'] is defined and groups['galera_all'] | length > 0 }}"" haproxy_glance_api_service: haproxy_service_name: glance_api haproxy_backend_nodes: ""{{ groups['glance_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9292 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['glance_api'] is defined and groups['glance_api'] | length > 0 }}"" haproxy_gnocchi_service: haproxy_service_name: gnocchi haproxy_backend_nodes: ""{{ groups['gnocchi_all'] | default([]) }}"" haproxy_port: 8041 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"" haproxy_heat_api_cfn_service: haproxy_service_name: heat_api_cfn haproxy_backend_nodes: ""{{ groups['heat_api_cfn'] | default([]) }}"" haproxy_port: 8000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api_cfn'] is defined and groups['heat_api_cfn'] | length > 0 }}"" haproxy_heat_api_service: haproxy_service_name: heat_api haproxy_backend_nodes: ""{{ groups['heat_api'] | default([]) }}"" haproxy_port: 8004 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api'] is defined and groups['heat_api'] | length > 0 }}"" haproxy_horizon_service: haproxy_service_name: horizon haproxy_backend_nodes: ""{{ groups['horizon_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: true haproxy_port: ""{{ haproxy_ssl | ternary(443,80) }}"" haproxy_backend_port: 80 haproxy_redirect_http_port: 80 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['horizon_all'] is defined and groups['horizon_all'] | length > 0 }}"" haproxy_redirect_scheme: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary('https if !{ ssl_fc } !{ path_beg /.well-known/acme-challenge/ }', 'https if !{ ssl_fc }') }}"" haproxy_frontend_acls: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary(haproxy_ssl_letsencrypt_acl, {}) }}"" haproxy_acls: ""{{ keystone_security_txt_content is defined | ternary(haproxy_security_txt_acl, {}) }}"" haproxy_ironic_api_service: haproxy_service_name: ironic_api haproxy_backend_nodes: ""{{ groups['ironic_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 6385 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_api'] is defined and groups['ironic_api'] | length > 0 }}"" haproxy_ironic_inspector_service: haproxy_service_name: ironic_inspector haproxy_backend_nodes: ""{{ groups['ironic_inspector'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_inspector'] is defined and groups['ironic_inspector'] | length > 0 }}"" haproxy_keystone_service: haproxy_service_name: keystone_service haproxy_backend_nodes: ""{{ groups['keystone_all'] | default([]) }}"" haproxy_port: 5000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: ""http"" haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['keystone_all'] is defined and groups['keystone_all'] | length > 0 }}"" haproxy_letsencrypt_service: haproxy_service_name: letsencrypt haproxy_backend_nodes: ""{{ groups['haproxy_all'] }}"" backend_rise: 1 backend_fall: 2 haproxy_bind: - 127.0.0.1 haproxy_port: ""{{ haproxy_ssl_letsencrypt_certbot_backend_port }}"" haproxy_balance_type: http haproxy_service_enabled: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) }}"" haproxy_magnum_service: haproxy_service_name: magnum haproxy_backend_nodes: ""{{ groups['magnum_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9511 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['magnum_all'] is defined and groups['magnum_all'] | length > 0 }}"" haproxy_manila_service: haproxy_service_name: manila haproxy_backend_nodes: ""{{ groups['manila_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8786 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['manila_api'] is defined and groups['manila_api'] | length > 0 }}"" haproxy_masakari_api_service: haproxy_service_name: masakari_api haproxy_backend_nodes: ""{{ groups['masakari_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 15868 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['masakari_api'] is defined and groups['masakari_api'] | length > 0 }}"" haproxy_mistral_service: haproxy_service_name: mistral haproxy_backend_nodes: ""{{ groups['mistral_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8989 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['mistral_all'] is defined and groups['mistral_all'] | length > 0 }}"" haproxy_murano_service: haproxy_service_name: murano haproxy_backend_nodes: ""{{ groups['murano_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8082 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 401"" haproxy_service_enabled: ""{{ groups['murano_all'] is defined and groups['murano_all'] | length > 0 }}"" haproxy_neutron_server_service: haproxy_service_name: neutron_server haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_port: 9696 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['neutron_server'] is defined and groups['neutron_server'] | length > 0 }}"" haproxy_nova_api_metadata_service: haproxy_service_name: nova_api_metadata haproxy_backend_nodes: ""{{ groups['nova_api_metadata'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8775 haproxy_ssl: ""{{ haproxy_ssl_all_vips }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_nova_metadata_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['nova_api_metadata'] is defined and groups['nova_api_metadata'] | length > 0 }}"" haproxy_nova_api_compute_service: haproxy_service_name: nova_api_os_compute haproxy_backend_nodes: ""{{ groups['nova_api_os_compute'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8774 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['nova_api_os_compute'] is defined and groups['nova_api_os_compute'] | length > 0 }}"" haproxy_nova_console_service: haproxy_service_name: nova_console haproxy_backend_nodes: ""{{ groups['nova_console'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: ""{{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_port'] | default(6082) }}"" haproxy_balance_type: http haproxy_timeout_client: 60m haproxy_timeout_server: 60m haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD {{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_path'] | default('/spice_auto.html') }} HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['nova_console'] is defined and groups['nova_console'] | length > 0 }}"" haproxy_octavia_service: haproxy_service_name: octavia haproxy_backend_nodes: ""{{ groups['octavia_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9876 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['octavia_all'] is defined and groups['octavia_all'] | length > 0 }}"" haproxy_opendaylight_neutron_service: haproxy_service_name: opendaylight-neutron haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8180 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" haproxy_opendaylight_websocket_service: haproxy_service_name: opendaylight-websocket haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8185 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" haproxy_ovn_northbound_service: haproxy_service_name: neutron_ovn_northd_northbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6641 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" haproxy_ovn_southbound_service: haproxy_service_name: neutron_ovn_northd_southbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6642 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" haproxy_ovn_ovsdb_service: haproxy_service_name: neutron_ovn_ovsdb_server haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6640 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" haproxy_panko_api_service: haproxy_service_name: panko_api haproxy_backend_nodes: ""{{ groups['panko_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8777 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['panko_all'] is defined and groups['panko_all'] | length > 0 }}"" haproxy_placement_service: haproxy_service_name: placement haproxy_backend_nodes: ""{{ groups['placement_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8780 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['placement_all'] is defined and groups['placement_all'] | length > 0 }}"" haproxy_rabbitmq_service: haproxy_service_name: rabbitmq_mgmt haproxy_backend_nodes: ""{{ groups['rabbitmq'] | default([]) }}"" haproxy_ssl: False haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 15672 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_rabbitmq_management_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['rabbitmq'] is defined and groups['rabbitmq'] | length > 0 }}"" haproxy_repo_service: haproxy_service_name: repo_all haproxy_backend_nodes: ""{{ groups['repo_all'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8181 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /repo_sync_complete HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"" haproxy_sahara_api_service: haproxy_service_name: sahara_api haproxy_backend_nodes: ""{{ groups['sahara_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8386 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['sahara_api'] is defined and groups['sahara_api'] | length > 0 }}"" haproxy_senlin_api_service: haproxy_service_name: senlin_api haproxy_backend_nodes: ""{{ groups['senlin_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8778 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['senlin_api'] is defined and groups['senlin_api'] | length > 0 }}"" haproxy_swift_proxy_service: haproxy_service_name: swift_proxy haproxy_backend_nodes: ""{{ groups['swift_proxy'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8080 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['swift_proxy'] is defined and groups['swift_proxy'] | length > 0 }}"" haproxy_tacker_service: haproxy_service_name: tacker haproxy_backend_nodes: ""{{ groups['tacker_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9890 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['tacker_all'] is defined and groups['tacker_all'] | length > 0 }}"" haproxy_trove_service: haproxy_service_name: trove haproxy_backend_nodes: ""{{ groups['trove_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8779 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['trove_api'] is defined and groups['trove_api'] | length > 0 }}"" haproxy_zun_api_service: haproxy_service_name: zun_api haproxy_backend_nodes: ""{{ groups['zun_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9517 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['zun_api'] is defined and groups['zun_api'] | length > 0 }}"" haproxy_default_services: - service: ""{{ haproxy_adjutant_api_service }}"" - service: ""{{ haproxy_aodh_api_service }}"" - service: ""{{ haproxy_barbican_service }}"" - service: ""{{ haproxy_ceph_rgw_service }}"" - service: ""{{ haproxy_cinder_api_service }}"" - service: ""{{ haproxy_designate_api_service }}"" - service: ""{{ haproxy_galera_service }}"" - service: ""{{ haproxy_glance_api_service }}"" - service: ""{{ haproxy_gnocchi_service }}"" - service: ""{{ haproxy_heat_api_cfn_service }}"" - service: ""{{ haproxy_heat_api_service }}"" - service: ""{{ haproxy_horizon_service }}"" - service: ""{{ haproxy_ironic_api_service }}"" - service: ""{{ haproxy_ironic_inspector_service }}"" - service: ""{{ haproxy_keystone_service }}"" - service: ""{{ haproxy_letsencrypt_service }}"" - service: ""{{ haproxy_magnum_service }}"" - service: ""{{ haproxy_manila_service }}"" - service: ""{{ haproxy_masakari_api_service }}"" - service: ""{{ haproxy_mistral_service }}"" - service: ""{{ haproxy_murano_service }}"" - service: ""{{ haproxy_neutron_server_service }}"" - service: ""{{ haproxy_nova_api_metadata_service }}"" - service: ""{{ haproxy_nova_api_compute_service }}"" - service: ""{{ haproxy_nova_console_service }}"" - service: ""{{ haproxy_octavia_service }}"" - service: ""{{ haproxy_opendaylight_neutron_service }}"" - service: ""{{ haproxy_opendaylight_websocket_service }}"" - service: ""{{ haproxy_ovn_northbound_service }}"" - service: ""{{ haproxy_ovn_southbound_service }}"" - service: ""{{ haproxy_ovn_ovsdb_service }}"" - service: ""{{ haproxy_panko_api_service }}"" - service: ""{{ haproxy_placement_service }}"" - service: ""{{ haproxy_rabbitmq_service }}"" - service: ""{{ haproxy_repo_service }}"" - service: ""{{ haproxy_sahara_api_service }}"" - service: ""{{ haproxy_senlin_api_service }}"" - service: ""{{ haproxy_swift_proxy_service }}"" - service: ""{{ haproxy_tacker_service }}"" - service: ""{{ haproxy_trove_service }}"" - service: ""{{ haproxy_zun_api_service }}""","haproxy_default_services: - service: haproxy_service_name: galera haproxy_backend_nodes: ""{{ (groups['galera_all'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['galera_all'] | default([]))[1:] }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 3306 haproxy_check_port: 9200 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_galera_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['galera_all'] is defined and groups['galera_all'] | length > 0 }}"" - service: haproxy_service_name: repo_git haproxy_backend_nodes: ""{{ groups['repo_all'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 9418 haproxy_balance_type: tcp haproxy_backend_options: - tcp-check haproxy_whitelist_networks: ""{{ haproxy_repo_git_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"" state: absent - service: haproxy_service_name: repo_all haproxy_backend_nodes: ""{{ groups['repo_all'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8181 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /repo_sync_complete HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"" - service: haproxy_service_name: glance_api haproxy_backend_nodes: ""{{ groups['glance_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9292 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['glance_api'] is defined and groups['glance_api'] | length > 0 }}"" - service: haproxy_service_name: gnocchi haproxy_backend_nodes: ""{{ groups['gnocchi_all'] | default([]) }}"" haproxy_port: 8041 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"" - service: haproxy_service_name: heat_api_cfn haproxy_backend_nodes: ""{{ groups['heat_api_cfn'] | default([]) }}"" haproxy_port: 8000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api_cfn'] is defined and groups['heat_api_cfn'] | length > 0 }}"" - service: haproxy_service_name: heat_api haproxy_backend_nodes: ""{{ groups['heat_api'] | default([]) }}"" haproxy_port: 8004 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api'] is defined and groups['heat_api'] | length > 0 }}"" - service: haproxy_service_name: keystone_service haproxy_backend_nodes: ""{{ groups['keystone_all'] | default([]) }}"" haproxy_port: 5000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: ""http"" haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['keystone_all'] is defined and groups['keystone_all'] | length > 0 }}"" - service: haproxy_service_name: neutron_server haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_port: 9696 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['neutron_server'] is defined and groups['neutron_server'] | length > 0 }}"" - service: haproxy_service_name: nova_api_metadata haproxy_backend_nodes: ""{{ groups['nova_api_metadata'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8775 haproxy_ssl: ""{{ haproxy_ssl_all_vips }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_nova_metadata_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['nova_api_metadata'] is defined and groups['nova_api_metadata'] | length > 0 }}"" - service: haproxy_service_name: nova_api_os_compute haproxy_backend_nodes: ""{{ groups['nova_api_os_compute'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8774 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['nova_api_os_compute'] is defined and groups['nova_api_os_compute'] | length > 0 }}"" - service: haproxy_service_name: placement haproxy_backend_nodes: ""{{ groups['placement_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8780 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['placement_all'] is defined and groups['placement_all'] | length > 0 }}"" - service: haproxy_service_name: nova_console haproxy_backend_nodes: ""{{ groups['nova_console'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: ""{{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_port'] | default(6082) }}"" haproxy_balance_type: http haproxy_timeout_client: 60m haproxy_timeout_server: 60m haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD {{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_path'] | default('/spice_auto.html') }} HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['nova_console'] is defined and groups['nova_console'] | length > 0 }}"" - service: haproxy_service_name: cinder_api haproxy_backend_nodes: ""{{ groups['cinder_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8776 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['cinder_api'] is defined and groups['cinder_api'] | length > 0 }}"" - service: haproxy_service_name: horizon haproxy_backend_nodes: ""{{ groups['horizon_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: true haproxy_port: ""{{ haproxy_ssl | ternary(443,80) }}"" haproxy_backend_port: 80 haproxy_redirect_http_port: 80 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['horizon_all'] is defined and groups['horizon_all'] | length > 0 }}"" haproxy_redirect_scheme: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary('https if !{ ssl_fc } !{ path_beg /.well-known/acme-challenge/ }', 'https if !{ ssl_fc }') }}"" haproxy_frontend_acls: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary(haproxy_ssl_letsencrypt_acl, {}) }}"" haproxy_acls: ""{{ keystone_security_txt_content is defined | ternary(haproxy_security_txt_acl, {}) }}"" - service: haproxy_service_name: letsencrypt haproxy_backend_nodes: ""{{ groups['haproxy_all'] }}"" backend_rise: 1 backend_fall: 2 haproxy_bind: - 127.0.0.1 haproxy_port: ""{{ haproxy_ssl_letsencrypt_certbot_backend_port }}"" haproxy_balance_type: http haproxy_service_enabled: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) }}"" - service: haproxy_service_name: sahara_api haproxy_backend_nodes: ""{{ groups['sahara_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8386 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['sahara_api'] is defined and groups['sahara_api'] | length > 0 }}"" - service: haproxy_service_name: senlin_api haproxy_backend_nodes: ""{{ groups['senlin_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8778 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['senlin_api'] is defined and groups['senlin_api'] | length > 0 }}"" - service: haproxy_service_name: swift_proxy haproxy_backend_nodes: ""{{ groups['swift_proxy'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8080 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['swift_proxy'] is defined and groups['swift_proxy'] | length > 0 }}"" - service: haproxy_service_name: adjutant_api haproxy_backend_nodes: ""{{ groups['adjutant_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['adjutant_api'] is defined and groups['adjutant_api'] | length > 0 }}"" - service: haproxy_service_name: aodh_api haproxy_backend_nodes: ""{{ groups['aodh_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8042 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['aodh_api'] is defined and groups['aodh_api'] | length > 0 }}"" - service: haproxy_service_name: ironic_api haproxy_backend_nodes: ""{{ groups['ironic_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 6385 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_api'] is defined and groups['ironic_api'] | length > 0 }}"" - service: haproxy_service_name: ironic_inspector haproxy_backend_nodes: ""{{ groups['ironic_inspector'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_inspector'] is defined and groups['ironic_inspector'] | length > 0 }}"" - service: haproxy_service_name: rabbitmq_mgmt haproxy_backend_nodes: ""{{ groups['rabbitmq'] | default([]) }}"" haproxy_ssl: False haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 15672 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_rabbitmq_management_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['rabbitmq'] is defined and groups['rabbitmq'] | length > 0 }}"" - service: haproxy_service_name: magnum haproxy_backend_nodes: ""{{ groups['magnum_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9511 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['magnum_all'] is defined and groups['magnum_all'] | length > 0 }}"" - service: haproxy_service_name: manila haproxy_backend_nodes: ""{{ groups['manila_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8786 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['manila_api'] is defined and groups['manila_api'] | length > 0 }}"" - service: haproxy_service_name: masakari_api haproxy_backend_nodes: ""{{ groups['masakari_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 15868 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['masakari_api'] is defined and groups['masakari_api'] | length > 0 }}"" - service: haproxy_service_name: mistral haproxy_backend_nodes: ""{{ groups['mistral_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8989 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['mistral_all'] is defined and groups['mistral_all'] | length > 0 }}"" - service: haproxy_service_name: murano haproxy_backend_nodes: ""{{ groups['murano_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8082 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 401"" haproxy_service_enabled: ""{{ groups['murano_all'] is defined and groups['murano_all'] | length > 0 }}"" - service: haproxy_service_name: trove haproxy_backend_nodes: ""{{ groups['trove_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8779 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['trove_api'] is defined and groups['trove_api'] | length > 0 }}"" - service: haproxy_service_name: barbican haproxy_backend_nodes: ""{{ groups['barbican_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9311 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['barbican_api'] is defined and groups['barbican_api'] | length > 0 }}"" - service: haproxy_service_name: designate_api haproxy_backend_nodes: ""{{ groups['designate_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9001 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['designate_api'] is defined and groups['designate_api'] | length > 0 }}"" - service: haproxy_service_name: octavia haproxy_backend_nodes: ""{{ groups['octavia_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9876 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['octavia_all'] is defined and groups['octavia_all'] | length > 0 }}"" - service: haproxy_service_name: tacker haproxy_backend_nodes: ""{{ groups['tacker_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9890 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['tacker_all'] is defined and groups['tacker_all'] | length > 0 }}"" - service: haproxy_service_name: opendaylight-neutron haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8180 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" - service: haproxy_service_name: opendaylight-websocket haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8185 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" - service: haproxy_service_name: ceph-rgw haproxy_backend_nodes: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) | ternary(groups['ceph-rgw'], ceph_rgws) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: ""{{ radosgw_service_port | default(7980) }}"" haproxy_balance_type: http haproxy_backend_options: - httpchk HEAD / haproxy_backend_httpcheck_options: - expect rstatus 200|405 haproxy_service_enabled: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0) }}"" - service: haproxy_service_name: neutron_ovn_northd_northbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6641 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" - service: haproxy_service_name: neutron_ovn_northd_southbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6642 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" - service: haproxy_service_name: neutron_ovn_ovsdb_server haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6640 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" - service: haproxy_service_name: panko_api haproxy_backend_nodes: ""{{ groups['panko_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8777 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['panko_all'] is defined and groups['panko_all'] | length > 0 }}"" - service: haproxy_service_name: zun_api haproxy_backend_nodes: ""{{ groups['zun_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9517 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['zun_api'] is defined and groups['zun_api'] | length > 0 }}""",539,461
openstack%2Fopenstack-ansible-galera_server~stable%2Fvictoria~I4a4e958c98b67203774e0c8aa0d208aede0673c7,openstack/openstack-ansible-galera_server,stable/victoria,I4a4e958c98b67203774e0c8aa0d208aede0673c7,Bump mariadb version to 10.5.8,MERGED,2021-01-04 21:12:45.000000000,2021-01-05 23:06:02.000000000,2021-01-05 23:04:49.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 25600}]","[{'number': 1, 'created': '2021-01-04 21:12:45.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/892a5bfac0947d0b2871191ce098ef3b00607024', 'message': 'Bump mariadb version to 10.5.8\n\nIncorporate latest bug fixes in the 10.5 release\n\nChange-Id: I4a4e958c98b67203774e0c8aa0d208aede0673c7\n(cherry picked from commit b0e4cb8953d280906503e8b6ddfabb73aece27e0)\n'}]",0,769182,892a5bfac0947d0b2871191ce098ef3b00607024,8,3,1,25023,,,0,"Bump mariadb version to 10.5.8

Incorporate latest bug fixes in the 10.5 release

Change-Id: I4a4e958c98b67203774e0c8aa0d208aede0673c7
(cherry picked from commit b0e4cb8953d280906503e8b6ddfabb73aece27e0)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/82/769182/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,892a5bfac0947d0b2871191ce098ef3b00607024,,galera_minor_version: 8,galera_minor_version: 6,1,1
openstack%2Fopenstack-ansible-openstack_hosts~master~I2f0ea659824588b338bead67d77080fc2d9a3726,openstack/openstack-ansible-openstack_hosts,master,I2f0ea659824588b338bead67d77080fc2d9a3726,Updated from OpenStack Ansible Tests,MERGED,2020-11-10 12:56:15.000000000,2021-01-05 22:39:50.000000000,2021-01-05 22:38:32.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2020-11-10 12:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/0a85fb371a4660febac3e04092173c7073d88019', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I2f0ea659824588b338bead67d77080fc2d9a3726\n'}, {'number': 2, 'created': '2021-01-05 08:36:31.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/fe97de3d825a93aa225d83e27c4d539e434125da', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I2f0ea659824588b338bead67d77080fc2d9a3726\n'}]",0,762133,fe97de3d825a93aa225d83e27c4d539e434125da,14,2,2,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I2f0ea659824588b338bead67d77080fc2d9a3726
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/33/762133/2 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,0a85fb371a4660febac3e04092173c7073d88019,openstack/openstack-ansible-tests/sync-tests,git-core [platform:dpkg platform:suse]git [platform:rpm !platform:suse]# Base requirements for Gentoo git [platform:gentoo] ,git-core [platform:dpkg]git [platform:rpm],5,2
openstack%2Fpython-blazarclient~master~Ib9f1cb5a77947cfb1ab28a7f26e97edba007466c,openstack/python-blazarclient,master,Ib9f1cb5a77947cfb1ab28a7f26e97edba007466c,Bump hacking max version to 3.0.1 and fix pep8,MERGED,2021-01-03 11:24:54.000000000,2021-01-05 22:33:50.000000000,2021-01-05 22:31:58.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 11:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/ad5c5b7d04487c3b61b55619d2f1b2630303f2e7', 'message': 'Bump hacking max version to 3.0.1\n\npep8 job is failing because the version of flake8\n(flake8<2.7.0,>=2.6.0) requested by hacking<1.2.0 is not\ncompatible with pyflakes>=2.1.1. Therefore the patch increases\nthe max version of hacking.\n\nChange-Id: Ib9f1cb5a77947cfb1ab28a7f26e97edba007466c\n'}, {'number': 2, 'created': '2021-01-03 11:55:46.000000000', 'files': ['blazarclient/utils.py', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/e875b753921b995388abf3ead158f1775f3904be', 'message': 'Bump hacking max version to 3.0.1 and fix pep8\n\npep8 job is failing because the version of flake8\n(flake8<2.7.0,>=2.6.0) requested by hacking<1.2.0 is not\ncompatible with pyflakes>=2.1.1. Therefore the patch increases\nthe max version of hacking.\nAlso the patch fixes a few pep8 errors.\n\nChange-Id: Ib9f1cb5a77947cfb1ab28a7f26e97edba007466c\n'}]",0,769063,e875b753921b995388abf3ead158f1775f3904be,9,2,2,22873,,,0,"Bump hacking max version to 3.0.1 and fix pep8

pep8 job is failing because the version of flake8
(flake8<2.7.0,>=2.6.0) requested by hacking<1.2.0 is not
compatible with pyflakes>=2.1.1. Therefore the patch increases
the max version of hacking.
Also the patch fixes a few pep8 errors.

Change-Id: Ib9f1cb5a77947cfb1ab28a7f26e97edba007466c
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/63/769063/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ad5c5b7d04487c3b61b55619d2f1b2630303f2e7,,"hacking>=1.1.0,<3.0.1 # Apache-2.0","hacking>=1.1.0,<1.2.0 # Apache-2.0",1,1
openstack%2Ftripleo-puppet-elements~master~I9b10cd04a98d4ec2899962c53bda16ec860b2c4d,openstack/tripleo-puppet-elements,master,I9b10cd04a98d4ec2899962c53bda16ec860b2c4d,Add doc/requirements,MERGED,2021-01-05 09:53:21.000000000,2021-01-05 22:27:51.000000000,2021-01-05 22:25:49.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 09:53:21.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/ad31a402117851eddb288f43c39e7944127376bd', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I9b10cd04a98d4ec2899962c53bda16ec860b2c4d\n""}]",0,769302,ad31a402117851eddb288f43c39e7944127376bd,9,3,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.
The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I9b10cd04a98d4ec2899962c53bda16ec860b2c4d
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/02/769302/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,ad31a402117851eddb288f43c39e7944127376bd,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,7,5
openstack%2Fvalidations-common~master~I526608180ad3cf15337cde422414cf2fbae21499,openstack/validations-common,master,I526608180ad3cf15337cde422414cf2fbae21499,Remove useless python import,MERGED,2020-12-01 11:08:29.000000000,2021-01-05 22:26:12.000000000,2021-01-05 22:26:12.000000000,"[{'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2020-12-01 11:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-common/commit/6a9e48545f2ce050f3d6ffca7a3039fcf8af5e50', 'message': 'Remove useless python import\n\nChange-Id: I526608180ad3cf15337cde422414cf2fbae21499\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2020-12-15 14:06:22.000000000', 'files': ['validations_common/callback_plugins/validation_stdout.py'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/4df9a808a9f242af50022d3304793335047f5370', 'message': 'Remove useless python import\n\nChange-Id: I526608180ad3cf15337cde422414cf2fbae21499\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",0,764930,4df9a808a9f242af50022d3304793335047f5370,12,6,2,11491,,,0,"Remove useless python import

Change-Id: I526608180ad3cf15337cde422414cf2fbae21499
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/30/764930/2 && git format-patch -1 --stdout FETCH_HEAD,['validations_common/callback_plugins/validation_stdout.py'],1,6a9e48545f2ce050f3d6ffca7a3039fcf8af5e50,,,import json import timefrom functools import partial from ansible.parsing.ajson import AnsibleJSONEncoder,0,5
openstack%2Fvalidations-common~master~I1004a7b56409e6eb5fefa6868314cbb4f4647543,openstack/validations-common,master,I1004a7b56409e6eb5fefa6868314cbb4f4647543,Update TOX_CONSTRAINTS_FILE,MERGED,2020-12-18 09:23:29.000000000,2021-01-05 22:26:07.000000000,2021-01-05 22:26:07.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 09:23:29.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/0a5c58af8dd9cd0df984141d499ec776beb39330', 'message': 'Update TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I1004a7b56409e6eb5fefa6868314cbb4f4647543\n'}]",0,767681,0a5c58af8dd9cd0df984141d499ec776beb39330,6,2,1,32291,,,0,"Update TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I1004a7b56409e6eb5fefa6868314cbb4f4647543
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/81/767681/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0a5c58af8dd9cd0df984141d499ec776beb39330,, -c {env:TOX_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt}, -c {env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},1,1
openstack%2Ftripleo-upgrade~master~I5cd2351ae4c813fac9a1909d518f8fa637807aaa,openstack/tripleo-upgrade,master,I5cd2351ae4c813fac9a1909d518f8fa637807aaa,Add doc/requirements,MERGED,2021-01-05 10:06:37.000000000,2021-01-05 22:26:03.000000000,2021-01-05 22:26:03.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 10:06:37.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/95cec68a9622e2d9f6c3858b72878c3e48fbe361', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n/!\\/!\\/!\\\nNotice that I voluntarily added the doc directory even if no docs\nare generated here because zuul will try to pull this requirements from\nthere first and the contained requirements are needed for reno but AFAIK\nthe releasenotes dir is ignored by zuul. c.f [4] for further details.\n/!\\/!\\/!\\\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I5cd2351ae4c813fac9a1909d518f8fa637807aaa\n""}]",0,769305,95cec68a9622e2d9f6c3858b72878c3e48fbe361,7,3,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.
The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

/!\/!\/!\
Notice that I voluntarily added the doc directory even if no docs
are generated here because zuul will try to pull this requirements from
there first and the contained requirements are needed for reno but AFAIK
the releasenotes dir is ignored by zuul. c.f [4] for further details.
/!\/!\/!\

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I5cd2351ae4c813fac9a1909d518f8fa637807aaa
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/05/769305/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,95cec68a9622e2d9f6c3858b72878c3e48fbe361,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,5,3
openstack%2Fopenstack-ansible-tests~stable%2Fvictoria~I892c3673a167fff17a720101b301b48485fb2bd5,openstack/openstack-ansible-tests,stable/victoria,I892c3673a167fff17a720101b301b48485fb2bd5,Bump ansible version to 2.10.4,MERGED,2021-01-04 21:11:31.000000000,2021-01-05 22:09:14.000000000,2021-01-05 22:07:23.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 25600}]","[{'number': 1, 'created': '2021-01-04 21:11:31.000000000', 'files': ['test-ansible-deps.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/d93aad4b86b5e9f2229cabbc1dc9bd388abd29f5', 'message': 'Bump ansible version to 2.10.4\n\nChange-Id: I892c3673a167fff17a720101b301b48485fb2bd5\n(cherry picked from commit 2f89be9cbeb1507545f5de1ddabca36c0fa8cabf)\n'}]",0,769180,d93aad4b86b5e9f2229cabbc1dc9bd388abd29f5,8,3,1,25023,,,0,"Bump ansible version to 2.10.4

Change-Id: I892c3673a167fff17a720101b301b48485fb2bd5
(cherry picked from commit 2f89be9cbeb1507545f5de1ddabca36c0fa8cabf)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/80/769180/1 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-deps.txt'],1,d93aad4b86b5e9f2229cabbc1dc9bd388abd29f5,,ansible-base==2.10.4,ansible-base==2.10.3,1,1
openstack%2Fswift~master~I8dfdbd5dc6dec420efd8892cba58f4761c5bbd15,openstack/swift,master,I8dfdbd5dc6dec420efd8892cba58f4761c5bbd15,watchers: Add a policy-stat watcher,NEW,2020-12-11 00:03:49.000000000,2021-01-05 21:50:23.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-11 00:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/78b4d002404328f0dfe353e22c319774d980df62', 'message': 'watchers: Add a policy-stat watcher\n\nCollect object- and byte-count statistics per policy as part of the ZBF\naudit. Output gets dropped to recon like\n\n  ""policy_stats"": {\n    ""0"": {\n      ""disk_bytes"": {\n        ""-1"": 0,\n        ""0"": 10632,\n        ""1024"": 400058,\n        ""10240"": 357416,\n        ""102400"": 0\n      },\n      ""disk_objects"": {\n        ""-1"": 3,\n        ""0"": 24,\n        ""1024"": 78,\n        ""10240"": 16,\n        ""102400"": 0\n      },\n      ""user_bytes"": { ... },\n      ""user_objects"": { ... }\n    },\n    ""1"": {\n      ""disk_bytes"": { ... },\n      ""disk_objects"": { ... },\n      ""user_bytes"": { ... },\n      ""user_objects"": { ... }\n    },\n    ...\n    ""reported"": 1607640216.18415\n  }\n\nThis means, for example, that the server has\n\n * 3 zero-byte data files on disk for policy 0\n * 24 data files on disk for policy 0 where\n      0 < data file size <= 1024\n * 400058 total bytes on disk for policy 0 where\n   1024 < data file size <= 10240, and\n * no data files for policy 0 where data file size > 102400\n\nThe cutoffs used are operator-defined; by default, all data files go in\na ""-1"" bucket.\n\nThe disk_* and user_* stats will be identical for replicated policies;\nfor erasure-coded policies, the client-facing sizes are used when\nassigning buckets and counting bytes for the user_* stats, while the\nfragment-archive sizes are used for the disk_* stats.\n\nChange-Id: I8dfdbd5dc6dec420efd8892cba58f4761c5bbd15\n'}, {'number': 2, 'created': '2020-12-11 00:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/72af5242a9ee2f57a532ee977510bc80c0ac1e28', 'message': 'watchers: Add a policy-stat watcher\n\nCollect object- and byte-count statistics per policy as part of the ZBF\naudit. Output gets dropped to recon like\n\n  ""policy_stats"": {\n    ""0"": {\n      ""disk_bytes"": {\n        ""-1"": 0,\n        ""0"": 10632,\n        ""1024"": 400058,\n        ""10240"": 357416,\n        ""102400"": 0\n      },\n      ""disk_objects"": {\n        ""-1"": 3,\n        ""0"": 24,\n        ""1024"": 78,\n        ""10240"": 16,\n        ""102400"": 0\n      },\n      ""user_bytes"": { ... },\n      ""user_objects"": { ... }\n    },\n    ""1"": {\n      ""disk_bytes"": { ... },\n      ""disk_objects"": { ... },\n      ""user_bytes"": { ... },\n      ""user_objects"": { ... }\n    },\n    ...\n    ""reported"": 1607640216.18415\n  }\n\nThis means, for example, that the server has\n\n * 3 zero-byte data files on disk for policy 0\n * 24 data files on disk for policy 0 where\n      0 < data file size <= 1024\n * 400058 total bytes on disk for policy 0 where\n   1024 < data file size <= 10240, and\n * no data files for policy 0 where data file size > 102400\n\nThe cutoffs used are operator-defined; by default, all data files go in\na ""-1"" bucket.\n\nThe disk_* and user_* stats will be identical for replicated policies;\nfor erasure-coded policies, the client-facing sizes are used when\nassigning buckets and counting bytes for the user_* stats, while the\nfragment-archive sizes are used for the disk_* stats.\n\nChange-Id: I8dfdbd5dc6dec420efd8892cba58f4761c5bbd15\n'}, {'number': 3, 'created': '2021-01-05 19:06:45.000000000', 'files': ['setup.cfg', 'swift/obj/watchers/policy_stats.py', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/7b9c7f1d48f950f72c0b889a1738dfad19d89fe0', 'message': 'watchers: Add a policy-stat watcher\n\nCollect object- and byte-count statistics per policy as part of the ZBF\naudit. Output gets dropped to recon like\n\n  ""policy_stats"": {\n    ""0"": {\n      ""disk_bytes"": {\n        ""-1"": 0,\n        ""0"": 10632,\n        ""1024"": 400058,\n        ""10240"": 357416,\n        ""102400"": 0\n      },\n      ""disk_objects"": {\n        ""-1"": 3,\n        ""0"": 24,\n        ""1024"": 78,\n        ""10240"": 16,\n        ""102400"": 0\n      },\n      ""user_bytes"": { ... },\n      ""user_objects"": { ... }\n    },\n    ""1"": {\n      ""disk_bytes"": { ... },\n      ""disk_objects"": { ... },\n      ""user_bytes"": { ... },\n      ""user_objects"": { ... }\n    },\n    ...\n    ""reported"": 1607640216.18415\n  }\n\nThis means, for example, that the server has\n\n * 3 zero-byte data files on disk for policy 0\n * 24 data files on disk for policy 0 where\n      0 < data file size <= 1024\n * 400058 total bytes on disk for policy 0 where\n   1024 < data file size <= 10240, and\n * no data files for policy 0 where data file size > 102400\n\nThe cutoffs used are operator-defined; by default, all data files go in\na ""-1"" bucket.\n\nThe disk_* and user_* stats will be identical for replicated policies;\nfor erasure-coded policies, the client-facing sizes are used when\nassigning buckets and counting bytes for the user_* stats, while the\nfragment-archive sizes are used for the disk_* stats.\n\nChange-Id: I8dfdbd5dc6dec420efd8892cba58f4761c5bbd15\n'}]",0,766640,7b9c7f1d48f950f72c0b889a1738dfad19d89fe0,6,1,3,15343,,,0,"watchers: Add a policy-stat watcher

Collect object- and byte-count statistics per policy as part of the ZBF
audit. Output gets dropped to recon like

  ""policy_stats"": {
    ""0"": {
      ""disk_bytes"": {
        ""-1"": 0,
        ""0"": 10632,
        ""1024"": 400058,
        ""10240"": 357416,
        ""102400"": 0
      },
      ""disk_objects"": {
        ""-1"": 3,
        ""0"": 24,
        ""1024"": 78,
        ""10240"": 16,
        ""102400"": 0
      },
      ""user_bytes"": { ... },
      ""user_objects"": { ... }
    },
    ""1"": {
      ""disk_bytes"": { ... },
      ""disk_objects"": { ... },
      ""user_bytes"": { ... },
      ""user_objects"": { ... }
    },
    ...
    ""reported"": 1607640216.18415
  }

This means, for example, that the server has

 * 3 zero-byte data files on disk for policy 0
 * 24 data files on disk for policy 0 where
      0 < data file size <= 1024
 * 400058 total bytes on disk for policy 0 where
   1024 < data file size <= 10240, and
 * no data files for policy 0 where data file size > 102400

The cutoffs used are operator-defined; by default, all data files go in
a ""-1"" bucket.

The disk_* and user_* stats will be identical for replicated policies;
for erasure-coded policies, the client-facing sizes are used when
assigning buckets and counting bytes for the user_* stats, while the
fragment-archive sizes are used for the disk_* stats.

Change-Id: I8dfdbd5dc6dec420efd8892cba58f4761c5bbd15
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/766640/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'swift/obj/watchers/policy_stats.py', 'etc/object-server.conf-sample']",3,78b4d002404328f0dfe353e22c319774d980df62,policy-stats,"# Watcher-specific parameters can be added after ""object-auditor:watcher:""# # [object-auditor:watcher:swift#policy_stats] # buckets = 0 1024 1048576 33554432 1073741824","# Watcher-specific parameters can he added after ""object-auditor:watcher:""",83,1
openstack%2Ftripleo-operator-ansible~master~Ide774f65a5facfad1097344f82e6e65f467a0d89,openstack/tripleo-operator-ansible,master,Ide774f65a5facfad1097344f82e6e65f467a0d89,Bump molecule,MERGED,2020-10-23 12:28:30.000000000,2021-01-05 21:48:34.000000000,2021-01-05 21:43:46.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-10-23 12:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/b5217ba7d7d9bbad568f5dc82ae7074932d53f32', 'message': 'WIP: Bump molecule\n\nThis change switches to newer version of molecule and uses its\nextras for installing test requirements. This should make\nmuch easier to upgrade in the future.\n\nChange-Id: Ide774f65a5facfad1097344f82e6e65f467a0d89\n'}, {'number': 2, 'created': '2020-10-23 13:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/7de5f3ea4d80eec251cb79943f233da49ed183b4', 'message': 'WIP: Bump molecule\n\nThis change switches to newer version of molecule and uses its\nextras for installing test requirements. This should make\nmuch easier to upgrade in the future.\n\nChange-Id: Ide774f65a5facfad1097344f82e6e65f467a0d89\n'}, {'number': 3, 'created': '2020-11-25 12:10:40.000000000', 'files': ['zuul.d/molecule.yaml', 'molecule-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/fc6cf86f1f6f2165d8d23c0d8574e8123754f6df', 'message': 'Bump molecule\n\nThis change switches to newer version of molecule and uses its\nextras for installing test requirements. This should make\nmuch easier to upgrade in the future.\n\nChange-Id: Ide774f65a5facfad1097344f82e6e65f467a0d89\n'}]",0,759413,fc6cf86f1f6f2165d8d23c0d8574e8123754f6df,32,5,3,24162,,,0,"Bump molecule

This change switches to newer version of molecule and uses its
extras for installing test requirements. This should make
much easier to upgrade in the future.

Change-Id: Ide774f65a5facfad1097344f82e6e65f467a0d89
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/13/759413/2 && git format-patch -1 --stdout FETCH_HEAD,['molecule-requirements.txt'],1,b5217ba7d7d9bbad568f5dc82ae7074932d53f32,,"# molecule also has optional extras: docker, podman molecule[test]>=3.1,<3.2 # MIT","ansi2htmldocker>=4.0.1 paramiko>=2.5.0 # LGPL (soft-dependency of docker that enables ssh protocol) pytest pytest-cov pytest-html<=2.0.1 # MPL 2.0 pytest-molecule<1.3.0 pytest-xdist mock molecule>=3.0,<3.1 # MIT selinux>=0.2.1 # MIT",2,11
openstack%2Ftripleo-heat-templates~master~I519ef389448acb3dde328a0e61c074e48d7e0466,openstack/tripleo-heat-templates,master,I519ef389448acb3dde328a0e61c074e48d7e0466,Add doc/requirements,MERGED,2021-01-05 08:51:35.000000000,2021-01-05 21:48:32.000000000,2021-01-05 21:43:16.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 08:51:35.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fea7fa2d9cc7a583083e00ccaaffbdcdea1fe385', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto\npull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n/!\\/!\\/!\\\nNotice that I voluntarily added the doc directory even if no docs\nare generated here because zuul will try to pull this requirements from\nthere first and the contained requirements are needed for reno but AFAIK\nthe releasenotes dir is ignored by zuul. c.f [4] for further details.\n/!\\/!\\/!\\\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I519ef389448acb3dde328a0e61c074e48d7e0466\n""}]",0,769263,fea7fa2d9cc7a583083e00ccaaffbdcdea1fe385,9,3,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to
pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

/!\/!\/!\
Notice that I voluntarily added the doc directory even if no docs
are generated here because zuul will try to pull this requirements from
there first and the contained requirements are needed for reno but AFAIK
the releasenotes dir is ignored by zuul. c.f [4] for further details.
/!\/!\/!\

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I519ef389448acb3dde328a0e61c074e48d7e0466
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/769263/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,fea7fa2d9cc7a583083e00ccaaffbdcdea1fe385,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,5,3
openstack%2Fblazar-tempest-plugin~master~I87c6d037fbbc24ef795ddbe26b5e297fb1bbc7a9,openstack/blazar-tempest-plugin,master,I87c6d037fbbc24ef795ddbe26b5e297fb1bbc7a9,Fix multiple CI failures,MERGED,2021-01-05 14:48:40.000000000,2021-01-05 21:47:17.000000000,2021-01-05 21:39:58.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 14:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/8955ba121732e0f544ab2b503527bb6cd8fb8735', 'message': 'Update hacking to 4.0.0 to fix dependency resolution issues\n\nFix or ignore new code style failures.\n\nChange-Id: I87c6d037fbbc24ef795ddbe26b5e297fb1bbc7a9\n'}, {'number': 2, 'created': '2021-01-05 15:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/fbe6e41ab1f9dafb6ad142983b1fc48ade7cfda1', 'message': 'Fix multiple CI failures\n\n1) Update hacking to 4.0.0 to fix dependency resolution issues. Fix or\n   ignore new code style failures.\n\n2) Disable swift-proxy service which fails to start on stein. Disabled\n   other unneeded services while here.\n\nChange-Id: I87c6d037fbbc24ef795ddbe26b5e297fb1bbc7a9\n'}, {'number': 3, 'created': '2021-01-05 16:19:09.000000000', 'files': ['test-requirements.txt', 'blazar_tempest_plugin/tests/scenario/test_host_reservation.py', '.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/10ef8b76dddbd6c4f0ba917a67ee61188f998571', 'message': 'Fix multiple CI failures\n\n1) Bump hacking max version to 3.0.1 and fix code style failures.\n\npep8 job is failing because the version of flake8 (flake8<2.7.0,>=2.6.0)\nrequested by hacking<1.2.0 is not compatible with pyflakes>=2.1.1.\nTherefore the patch increases the max version of hacking.\n\n2) Disable swift-proxy service which fails to start on stein. Disabled\n   other unneeded services while here.\n\nChange-Id: I87c6d037fbbc24ef795ddbe26b5e297fb1bbc7a9\n'}]",0,769376,10ef8b76dddbd6c4f0ba917a67ee61188f998571,9,2,3,15197,,,0,"Fix multiple CI failures

1) Bump hacking max version to 3.0.1 and fix code style failures.

pep8 job is failing because the version of flake8 (flake8<2.7.0,>=2.6.0)
requested by hacking<1.2.0 is not compatible with pyflakes>=2.1.1.
Therefore the patch increases the max version of hacking.

2) Disable swift-proxy service which fails to start on stein. Disabled
   other unneeded services while here.

Change-Id: I87c6d037fbbc24ef795ddbe26b5e297fb1bbc7a9
",git fetch https://review.opendev.org/openstack/blazar-tempest-plugin refs/changes/76/769376/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'blazar_tempest_plugin/tests/scenario/test_host_reservation.py', 'tox.ini']",3,8955ba121732e0f544ab2b503527bb6cd8fb8735,,"ignore = E123,E125,W503,W504","ignore = E123,E125",7,12
openstack%2Fswift~master~Id11c391da545bc3851a5b687f4b06e0d9239bdcd,openstack/swift,master,Id11c391da545bc3851a5b687f4b06e0d9239bdcd,Let developers/operators add watchers to object audit,ABANDONED,2015-08-13 22:38:03.000000000,2021-01-05 21:35:01.000000000,,"[{'_account_id': 330}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}, {'_account_id': 13852}, {'_account_id': 14766}, {'_account_id': 15343}, {'_account_id': 16896}, {'_account_id': 18142}, {'_account_id': 18978}, {'_account_id': 22348}]","[{'number': 1, 'created': '2015-08-13 22:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/898e93955f43794f8c7784a9687061092da3e3d5', 'message': ""Let operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(metadata) for each object audited, and\nwatcher.end() at the end of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 2, 'created': '2015-09-18 21:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/09fed1336ef10030d46dab6c5e2ba3ff4456b52f', 'message': ""Let operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(metadata) for each object audited, and\nwatcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 3, 'created': '2015-10-28 02:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ee3b582e0e10e0dccdea4f385c7a97191262dc76', 'message': ""Let operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, policy_index, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(policy_index, metadata) for each object\naudited, and watcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 4, 'created': '2015-11-19 23:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3e81d50ff594e7ee4f89769abadfe9cad00ad377', 'message': ""Let operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, policy_index, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(policy_index, metadata) for each object\naudited, and watcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 5, 'created': '2015-12-22 00:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3b1ce108e9c8b12d7669460e3c8b4f25ee79d956', 'message': ""Let operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, policy_index, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(policy_index, metadata) for each object\naudited, and watcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 6, 'created': '2016-01-14 22:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e5703fecb4f821e06d5264d27b484710e8b07072', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, policy_index, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(policy_index, metadata) for each object\naudited, and watcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 7, 'created': '2016-01-19 22:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2adc20b68047cd33abe82f58f6eb8aaf4591cd6e', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger)\n   start(self, audit_type)\n   see_object(self, policy_index, object_metadata)\n   end(self)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(policy_index, metadata) for each object\naudited, and watcher.end() at the end of an audit pass.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 8, 'created': '2016-02-25 19:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d621e09b6f495aeff6820a56d19cd843c6af8784', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, *args, **kwargs)\n\n   start(self, audit_type, *args, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, *args, **kwargs)\n\n   end(self, *args, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 9, 'created': '2016-02-26 07:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/14e05a9c28d8cddedd2c8c63180982ff5e426fa2', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, *args, **kwargs)\n\n   start(self, audit_type, *args, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, *args, **kwargs)\n\n   end(self, *args, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 10, 'created': '2018-07-30 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/716d9c17705cb68597d0d28014686354e26ba584', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, *args, **kwargs)\n\n   start(self, audit_type, *args, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, *args, **kwargs)\n\n   end(self, *args, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 11, 'created': '2019-01-03 22:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/65f8dc0aeefc9abae86bfecd8fdf14f0696e754b', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 12, 'created': '2019-01-04 01:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/33d91e413a35bdae14b5fa1cfcd880225fb5b704', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. If Swift gets\nencryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nDocImpact\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 13, 'created': '2019-11-05 08:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/61e87f77b1cd9132b42aeedd3473ebe920ba5634', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 14, 'created': '2019-11-05 09:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/57b58c57bd1136ae7a3f05ee75957d9cd296f179', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 15, 'created': '2019-11-05 14:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/683a3508a966dbf26c4d49bcd2abf394b93bff42', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 16, 'created': '2019-11-05 23:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/add840a1e5dcd8148db4bf4975f00ed9b58d2cf6', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 17, 'created': '2019-12-13 17:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/87d48b77492ecd6de867c61c70b64b6da41ef5a6', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 18, 'created': '2019-12-13 19:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/088da06bd465f50f0619acbee71039f95d4291ba', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 19, 'created': '2020-01-06 06:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/70385420121b2bf9a41e895c06a6989b533bbe56', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 20, 'created': '2020-01-07 00:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b69116b5c552f1edd477c6afa838874fceedaae', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}, {'number': 21, 'created': '2020-01-16 16:02:35.000000000', 'files': ['test/unit/obj/test_auditor.py', 'swift/obj/auditor.py', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/4a166b91a3d4ced48173de44c865dad48e118de5', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThe user-supplied watcher code runs entirely in a child process of the\nauditor process (of which there may be many, if parallel audits are in\nuse). This lets the auditor continue working even if the watcher\ncrashes or hangs. These subprocesses are automatically killed (after a\nshort delay) upon completion of an audit pass.\n\nChange-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd\n""}]",40,212824,4a166b91a3d4ced48173de44c865dad48e118de5,91,15,21,2622,,,0,"Let developers/operators add watchers to object audit

Swift operators may find it useful to operate on each object in their
cluster in some way. This commit provides them a way to hook into the
object auditor with a simple, clearly-defined boundary so that they
can iterate over their objects without additional disk IO.

For example, a cluster operator may want to scan for objects with
particular MD5 checksums and take actions based on that (e.g. pirated
movies). Other operators may want to locate old DLO manifests and
convert them to SLO manifests. This can be used after a cluster fills
up to locate objects that aren't in container listings. Now that Swift
has encryption support, this could be used to locate unencrypted
objects. The list goes on.

This commit makes the auditor locate, via entry points, the watchers
named in its config file.

A watcher is a class with at least these four methods:

   __init__(self, conf, logger, **kwargs)

   start(self, audit_type, **kwargs)

   see_object(self, sequence_number, policy_index, object_metadata,
              partition, **kwargs)

   end(self, final_sequence_number, **kwargs)

The auditor will call watcher.start(audit_type) at the start of an
audit pass, watcher.see_object(...) for each object audited, and
watcher.end() at the end of an audit pass. All method arguments are
passed as keyword args.

The user-supplied watcher code runs entirely in a child process of the
auditor process (of which there may be many, if parallel audits are in
use). This lets the auditor continue working even if the watcher
crashes or hangs. These subprocesses are automatically killed (after a
short delay) upon completion of an audit pass.

Change-Id: Id11c391da545bc3851a5b687f4b06e0d9239bdcd
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/212824/20 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/obj/auditor.py', 'etc/object-server.conf-sample']",3,898e93955f43794f8c7784a9687061092da3e3d5,dark_data_03,# A comma-separated list of watcher entry points. This lets operators # programmatically see audited objects. # watchers = ,,363,3
openstack%2Ftripleo-common~master~I737a7d7f6781abb84bd5213d0723bb14a48eb89f,openstack/tripleo-common,master,I737a7d7f6781abb84bd5213d0723bb14a48eb89f,Add doc/requirements,MERGED,2021-01-05 08:32:43.000000000,2021-01-05 21:33:39.000000000,2021-01-05 21:31:38.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 08:32:43.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8e57c59eb59dd2ec54726909f1789efc81ef41ee', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file to\npull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I737a7d7f6781abb84bd5213d0723bb14a48eb89f\n""}]",0,769259,8e57c59eb59dd2ec54726909f1789efc81ef41ee,9,3,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file to
pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I737a7d7f6781abb84bd5213d0723bb14a48eb89f
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/59/769259/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,8e57c59eb59dd2ec54726909f1789efc81ef41ee,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,7,5
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I47b95ad46e2d4e5b1f370a2f840826e87da2d703,openstack/tripleo-heat-templates,stable/victoria,I47b95ad46e2d4e5b1f370a2f840826e87da2d703,Move cell_v2 discovery off compute hosts,MERGED,2021-01-04 12:42:55.000000000,2021-01-05 21:33:36.000000000,2021-01-05 21:31:53.000000000,"[{'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2021-01-04 12:42:55.000000000', 'files': ['roles/NovaManager.yaml', 'releasenotes/notes/cell_v2_discovery_off_computes-2b977c6b9a01cde2.yaml', 'ci/environments/multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'tools/yaml-validate.py', 'deployment/nova/nova-manager-container-puppet.yaml', 'deployment/nova/nova-compute-common-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03697234fd2e8c8d052c331485d304bcb77b1b8b', 'message': 'Move cell_v2 discovery off compute hosts\n\nIn I12a02f636f31985bc1b71bff5b744d346286a95f cell_v2 discovery was\noriginally moved from the nova-api container to the\nnova-compute|nova-ironic containers in order to run cell\ndiscovery during a scale up where the controllers are omitted\n(e.g to exclude the controllers from a maintenance window).\n\nThis requires api database credentials on the compute node, which is\nforbidden, so it must move back to a nova-api host as a pre-requisite\nfor removing these credentials in a follow-up patch.\n\nScale-up while omitting the controllers will no longer work out of the\nbox. Either a manual cell_v2 discovery can be run after scale up, or an\nadditional node can be deployed using the NovaManager tripleo role.\n\nRelated-bug: #1786961\nRelated-bug: #1871482\nChange-Id: I47b95ad46e2d4e5b1f370a2f840826e87da2d703\n(cherry picked from commit 629485dde5d6b96d38688f362362fac45392ece9)\n'}]",0,769138,03697234fd2e8c8d052c331485d304bcb77b1b8b,9,6,1,27419,,,0,"Move cell_v2 discovery off compute hosts

In I12a02f636f31985bc1b71bff5b744d346286a95f cell_v2 discovery was
originally moved from the nova-api container to the
nova-compute|nova-ironic containers in order to run cell
discovery during a scale up where the controllers are omitted
(e.g to exclude the controllers from a maintenance window).

This requires api database credentials on the compute node, which is
forbidden, so it must move back to a nova-api host as a pre-requisite
for removing these credentials in a follow-up patch.

Scale-up while omitting the controllers will no longer work out of the
box. Either a manual cell_v2 discovery can be run after scale up, or an
additional node can be deployed using the NovaManager tripleo role.

Related-bug: #1786961
Related-bug: #1871482
Change-Id: I47b95ad46e2d4e5b1f370a2f840826e87da2d703
(cherry picked from commit 629485dde5d6b96d38688f362362fac45392ece9)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/769138/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/NovaManager.yaml', 'releasenotes/notes/cell_v2_discovery_off_computes-2b977c6b9a01cde2.yaml', 'ci/environments/multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'tools/yaml-validate.py', 'deployment/nova/nova-manager-container-puppet.yaml', 'deployment/nova/nova-compute-common-container-puppet.yaml']",7,03697234fd2e8c8d052c331485d304bcb77b1b8b,refactor_nova_db_config," - name: discover via nova_manager? set_fact: nova_cellv2_discovery_delegate_host: ""{{ groups['nova_manager'][0] }}"" nova_cellv2_discovery_container: nova_manager when: - groups['nova_manager'] is defined and (groups['nova_manager']|length>0) - name: discover via nova_api? set_fact: nova_cellv2_discovery_delegate_host: ""{{ groups['nova_api'][0] }}"" nova_cellv2_discovery_container: nova_api - groups['nova_api'] is defined and (groups['nova_api']|length>0) - name: Warn if no discovery host available fail: msg: 'No hosts available to run nova cell_v2 host discovery.' ignore_errors: yes when: - nova_cellv2_discovery_delegate_host is not defined command: ""{{ container_cli }} exec {{ nova_cellv2_discovery_container }} nova-manage cell_v2 discover_hosts --by-service"""," - name: discover via nova_compute? set_fact: nova_cellv2_discovery_delegate_host: ""{{ groups['nova_compute'][0] }}"" when: - groups['nova_compute'] is defined and (groups['nova_compute']|length>0) - name: discover via nova_ironic? set_fact: nova_cellv2_discovery_delegate_host: ""{{ groups['nova_ironic'][0] }}"" - groups['nova_ironic'] is defined and (groups['nova_ironic']|length>0) command: ""{{ container_cli }} exec nova_compute nova-manage cell_v2 discover_hosts --by-service""",178,8
openstack%2Fironic~stable%2Fvictoria~Ib05a952260d027f9f1307a9948ac5691b57e96d3,openstack/ironic,stable/victoria,Ib05a952260d027f9f1307a9948ac5691b57e96d3,Convert last bionic jobs to focal,MERGED,2020-12-21 08:29:00.000000000,2021-01-05 21:33:28.000000000,2021-01-05 21:24:05.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-21 08:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e07e16c10fccd917c8e07a141873c3366c0830e5', 'message': 'Convert last bionic jobs to focal\n\nAnd disable dstat in ironic-base for the time being.\n\nChange-Id: Ib05a952260d027f9f1307a9948ac5691b57e96d3\n(cherry picked from commit 1ab192beca8b3e10cefeef6c3d2343200d7bca32)\n'}, {'number': 2, 'created': '2021-01-05 13:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/96939e855a0e9e2d4977c856a6c3506f2d3465ad', 'message': 'Convert last bionic jobs to focal\n\nAnd disable dstat in ironic-base for the time being.\n\nAlso temporary making ironic-tempest-partition-uefi-redfish-vmedia\nnon-voting to prevent chicken-egg effect.\nShould be fixed by https://review.opendev.org/c/openstack/ironic/+/769194\n\nChange-Id: Ib05a952260d027f9f1307a9948ac5691b57e96d3\n(cherry picked from commit 1ab192beca8b3e10cefeef6c3d2343200d7bca32)\n'}, {'number': 3, 'created': '2021-01-05 13:57:18.000000000', 'files': ['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c6c1525f6f2799ee781425bf4c36326f44d4bd1f', 'message': 'Convert last bionic jobs to focal\n\nAnd disable dstat in ironic-base for the time being.\n\nAlso temporary making ironic-tempest-partition-uefi-redfish-vmedia\nnon-voting to prevent chicken-egg effect.\nShould be fixed by https://review.opendev.org/c/openstack/ironic/+/769194\n\nChange-Id: Ib05a952260d027f9f1307a9948ac5691b57e96d3\n(cherry picked from commit 1ab192beca8b3e10cefeef6c3d2343200d7bca32)\n'}]",1,767989,c6c1525f6f2799ee781425bf4c36326f44d4bd1f,18,3,3,23851,,,0,"Convert last bionic jobs to focal

And disable dstat in ironic-base for the time being.

Also temporary making ironic-tempest-partition-uefi-redfish-vmedia
non-voting to prevent chicken-egg effect.
Should be fixed by https://review.opendev.org/c/openstack/ironic/+/769194

Change-Id: Ib05a952260d027f9f1307a9948ac5691b57e96d3
(cherry picked from commit 1ab192beca8b3e10cefeef6c3d2343200d7bca32)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/89/767989/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,e07e16c10fccd917c8e07a141873c3366c0830e5,migrate-to-focal-stable/victoria, # TODO: re-enable dstat once https://storyboard.openstack.org/#!/story/2008185 # is resolved dstat: false, # TODO: Remove the below nodeset setting to Bionic once # https://storyboard.openstack.org/#!/story/2008185 is fixed # Once nodeset is removed form here then devstack base jobs # will automatically run this job on Ubuntu Focal nodeset from # Victoria gate onwards. nodeset: openstack-single-node-bionic # TODO: Remove the below nodeset setting to Bionic once # https://storyboard.openstack.org/#!/story/2008185 is fixed # Once nodeset is removed form here then devstack base jobs # will automatically run this job on Ubuntu Focal nodeset from # Victoria gate onwards. nodeset: openstack-single-node-bionic # TODO: Remove the below nodeset setting to Bionic once # https://storyboard.openstack.org/#!/story/2008185 is fixed # Once nodeset is removed form here then devstack base jobs # will automatically run this job on Ubuntu Focal nodeset from # Victoria gate onwards. nodeset: openstack-single-node-bionic,3,22
openstack%2Fpython-tripleoclient~stable%2Ftrain~I32c1e006d10ceb541aadb486befd8aa8fc6aa045,openstack/python-tripleoclient,stable/train,I32c1e006d10ceb541aadb486befd8aa8fc6aa045,Do not require authentication for the validator CLI,MERGED,2020-11-02 12:26:17.000000000,2021-01-05 21:33:25.000000000,2021-01-05 21:31:35.000000000,"[{'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-11-02 12:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ace0aa641fc027dc80116dcbadac4f7039e75d61', 'message': 'Do not require authentication for the validator CLI\n\nSince most of the actions of the validator is based on the filesystem,\nwe really don\'t need to require auth.\nThe only subcommand that might require it is the ""run"", since it might\ngo through the inventory generation.\n\nAlso, pass the ""--os-cloud"" parameter down to the\ntripleo-ansible-inventory script. Value is hardcoded, since it is an\nentry name we can\'t set (yet). It allows to authenticate only for the\nrelevant part of the validation run.\n\nResolves: rhbz#1892323\nCloses-Bug: #1902052\n\nChange-Id: I32c1e006d10ceb541aadb486befd8aa8fc6aa045\n(cherry picked from commit aafd981948b28b7786c9c8d5f9b0e7e1b3f9371f)\n'}, {'number': 2, 'created': '2020-11-12 11:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c75fc24b0ab7a3318aff2184eb91514773833813', 'message': 'Do not require authentication for the validator CLI\n\nSince most of the actions of the validator is based on the filesystem,\nwe really don\'t need to require auth.\nThe only subcommand that might require it is the ""run"", since it might\ngo through the inventory generation.\n\nAlso, pass the ""--os-cloud"" parameter down to the\ntripleo-ansible-inventory script. Value is hardcoded, since it is an\nentry name we can\'t set (yet). It allows to authenticate only for the\nrelevant part of the validation run.\n\nResolves: rhbz#1892323\nCloses-Bug: #1902052\n\nChange-Id: I32c1e006d10ceb541aadb486befd8aa8fc6aa045\n(cherry picked from commit aafd981948b28b7786c9c8d5f9b0e7e1b3f9371f)\n'}, {'number': 3, 'created': '2020-11-18 15:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b6c7efcebaf70e98059560e00856baa821be92b2', 'message': 'Do not require authentication for the validator CLI\n\nSince most of the actions of the validator is based on the filesystem,\nwe really don\'t need to require auth.\nThe only subcommand that might require it is the ""run"", since it might\ngo through the inventory generation.\n\nAlso, pass the ""--os-cloud"" parameter down to the\ntripleo-ansible-inventory script. Value is hardcoded, since it is an\nentry name we can\'t set (yet). It allows to authenticate only for the\nrelevant part of the validation run.\n\nResolves: rhbz#1892323\nCloses-Bug: #1902052\n\nChange-Id: I32c1e006d10ceb541aadb486befd8aa8fc6aa045\n(cherry picked from commit aafd981948b28b7786c9c8d5f9b0e7e1b3f9371f)\n'}, {'number': 4, 'created': '2020-12-18 12:22:03.000000000', 'files': ['tripleoclient/utils.py', 'tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/dfa329425c26d8414e38d77082ddddbf8c9fe855', 'message': 'Do not require authentication for the validator CLI\n\nSince most of the actions of the validator is based on the filesystem,\nwe really don\'t need to require auth.\nThe only subcommand that might require it is the ""run"", since it might\ngo through the inventory generation.\n\nAlso, pass the ""--os-cloud"" parameter down to the\ntripleo-ansible-inventory script. Value is hardcoded, since it is an\nentry name we can\'t set (yet). It allows to authenticate only for the\nrelevant part of the validation run.\n\nResolves: rhbz#1892323\nCloses-Bug: #1902052\n\nChange-Id: I32c1e006d10ceb541aadb486befd8aa8fc6aa045\n(cherry picked from commit aafd981948b28b7786c9c8d5f9b0e7e1b3f9371f)\n'}]",0,760905,dfa329425c26d8414e38d77082ddddbf8c9fe855,38,7,4,28223,,,0,"Do not require authentication for the validator CLI

Since most of the actions of the validator is based on the filesystem,
we really don't need to require auth.
The only subcommand that might require it is the ""run"", since it might
go through the inventory generation.

Also, pass the ""--os-cloud"" parameter down to the
tripleo-ansible-inventory script. Value is hardcoded, since it is an
entry name we can't set (yet). It allows to authenticate only for the
relevant part of the validation run.

Resolves: rhbz#1892323
Closes-Bug: #1902052

Change-Id: I32c1e006d10ceb541aadb486befd8aa8fc6aa045
(cherry picked from commit aafd981948b28b7786c9c8d5f9b0e7e1b3f9371f)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/05/760905/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/utils.py', 'tripleoclient/v1/tripleo_validator.py']",2,ace0aa641fc027dc80116dcbadac4f7039e75d61,train/validator/no-auth, auth_required = False auth_required = False auth_required = False auth_required = False auth_required = False auth_required = False auth_required = False ,,15,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ia8698702c9494d4303ede4fd2955c5975ab07af9,openstack/tripleo-heat-templates,stable/train,Ia8698702c9494d4303ede4fd2955c5975ab07af9,Remove Luna HSM clients on scaledown,MERGED,2020-12-18 18:54:27.000000000,2021-01-05 21:31:29.000000000,2021-01-05 21:31:29.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-18 18:54:27.000000000', 'files': ['deployment/barbican/barbican-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a1a3cc1ea710aaf6bda4be6c824ec2c795f0fe5', 'message': 'Remove Luna HSM clients on scaledown\n\nThis patch adds a scaledown task to remove the HSM\nclient when a Controller node is being removed.\n\nDepends-On: I87f7cb2435f77814169fbad3bd0814d370a546a1\nChange-Id: Ia8698702c9494d4303ede4fd2955c5975ab07af9\n(cherry picked from commit 144eb67ca5590c842a687285b278d1a892e9fe69)\n'}]",0,767933,5a1a3cc1ea710aaf6bda4be6c824ec2c795f0fe5,10,3,1,7973,,,0,"Remove Luna HSM clients on scaledown

This patch adds a scaledown task to remove the HSM
client when a Controller node is being removed.

Depends-On: I87f7cb2435f77814169fbad3bd0814d370a546a1
Change-Id: Ia8698702c9494d4303ede4fd2955c5975ab07af9
(cherry picked from commit 144eb67ca5590c842a687285b278d1a892e9fe69)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/33/767933/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/barbican/barbican-api-container-puppet.yaml'],1,5a1a3cc1ea710aaf6bda4be6c824ec2c795f0fe5,," scale_tasks: if: - lunasa_hsm_enabled - - name: Remove HSM clients when: step|int == 1 tags: down block: - name: Remove client from HSM import_role: name: lunasa_hsm tasks_from: unregister_client delegate_to: undercloud vars: - map_merge: - {get_param: LunasaVars} - lunasa_client_pin: {get_param: BarbicanPkcs11CryptoLogin} - client_name: ""{{ fqdn_canonical }}"" - null",,19,0
openstack%2Fblazar-nova~master~Icba57c52c613611311e8ef1838cd94b062b4705b,openstack/blazar-nova,master,Icba57c52c613611311e8ef1838cd94b062b4705b,Fix lower-constraints job,MERGED,2021-01-05 10:25:50.000000000,2021-01-05 20:59:52.000000000,2021-01-05 20:59:52.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 10:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/e74b4302d456aa42f94ac1b7650f395212aea6fa', 'message': ""Fix lower-constraints job\n\n* Move upper constraints from install_command to testenv deps, so it\n  doesn't get inherited by the lower-constraints job. This was causing\n  the wrong set of constraints to be used.\n* Update MarkupSafe to 1.1.1 because of an incompatibility with recent\n  setuptools: https://github.com/pallets/markupsafe/issues/116\n* Update PyYAML to 5.1 to fix build on some platforms such as macOS\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n""}, {'number': 2, 'created': '2021-01-05 12:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/5b31c5a8b5a4c2ce0b9ec13ce540a1edd9b64543', 'message': ""Fix lower-constraints job\n\n* Move upper constraints from install_command to testenv deps, so it\n  doesn't get inherited by the lower-constraints job. This was causing\n  the wrong set of constraints to be used.\n* Update MarkupSafe to 1.1.1 because of an incompatibility with recent\n  setuptools: https://github.com/pallets/markupsafe/issues/116\n* Update PyYAML to 5.1 to fix build on some platforms such as macOS\n* Require hacking 4.0.0+ to fix issues with pyflakes dependencies\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n""}, {'number': 3, 'created': '2021-01-05 17:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/518e0cac99211a0aa60d25f95ab0f3079f2539ed', 'message': 'Fix lower-constraints job\n\n* Require hacking 4.0.0+ to fix issues with pyflakes dependencies\n* Add install_command for the lower-constraints env which uses\n  lower-constraints.txt instead of the upper constraints file.\n* Update lower constraints to match nova\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n'}, {'number': 4, 'created': '2021-01-05 18:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/c98c726ef6f8bbfeebd776bda806da68167b3f4b', 'message': 'Fix lower-constraints job\n\n* Require hacking 4.0.0+ to fix issues with pyflakes dependencies\n* Add install_command for the lower-constraints env which uses\n  lower-constraints.txt instead of the upper constraints file.\n* Update lower constraints and test requirements to match nova\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n'}, {'number': 5, 'created': '2021-01-05 18:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/d406f2fbb7544c769fd5a7f7f70a2951d868a0c0', 'message': 'Fix lower-constraints job\n\n* Require hacking 4.0.0+ to fix issues with pyflakes dependencies\n* Add install_command for the lower-constraints env which uses\n  lower-constraints.txt instead of the upper constraints file.\n* Update lower constraints and requirements to match nova\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n'}, {'number': 6, 'created': '2021-01-05 19:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/6de509b8e2b2e57966d735e0a6180fa199015846', 'message': 'Fix lower-constraints job\n\n* Require hacking 4.0.0+ to fix issues with pyflakes dependencies\n* Add install_command for the lower-constraints env which uses\n  lower-constraints.txt instead of the upper constraints file.\n* Update lower constraints and requirements to match nova\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n'}, {'number': 7, 'created': '2021-01-05 20:36:00.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/6434f21c68f431f00784349ff1f8636b5fa044f3', 'message': 'Fix lower-constraints job\n\n* Require hacking 4.0.0+ to fix issues with pyflakes dependencies\n* Add install_command for the lower-constraints env which uses\n  lower-constraints.txt instead of the upper constraints file.\n* Update lower constraints and requirements to match nova\n\nChange-Id: Icba57c52c613611311e8ef1838cd94b062b4705b\n'}]",0,769311,6434f21c68f431f00784349ff1f8636b5fa044f3,17,2,7,15197,,,0,"Fix lower-constraints job

* Require hacking 4.0.0+ to fix issues with pyflakes dependencies
* Add install_command for the lower-constraints env which uses
  lower-constraints.txt instead of the upper constraints file.
* Update lower constraints and requirements to match nova

Change-Id: Icba57c52c613611311e8ef1838cd94b062b4705b
",git fetch https://review.opendev.org/openstack/blazar-nova refs/changes/11/769311/1 && git format-patch -1 --stdout FETCH_HEAD,"['lower-constraints.txt', 'tox.ini']",2,e74b4302d456aa42f94ac1b7650f395212aea6fa,fix-lower-constraints,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt -r{toxinidir}/test-requirements.txt,install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages} deps = -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt,7,6
openstack%2Fpython-tripleoclient~stable%2Fussuri~I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e,openstack/python-tripleoclient,stable/ussuri,I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e,Raise if no validation has been executed,MERGED,2020-10-26 13:45:16.000000000,2021-01-05 20:44:16.000000000,2021-01-05 20:42:33.000000000,"[{'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-10-26 13:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1ea9d8205e06367eabaf70ebf52f0be4261be69d', 'message': 'Raise if no validation has been executed\n\nIf no validations has been run, the CLI should raise\na exceptions.CommandError  instead of trying to build the prettytable\nfrom results.\n\nChange-Id: I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e\n(cherry picked from commit efcf2d98be109c919d627f3148522a559d13667a)\n'}, {'number': 2, 'created': '2020-10-26 13:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4ee65b0132facaa422408f9e50a0407e9fb21bfa', 'message': 'Raise if no validation has been executed\n\nIf no validations has been run, the CLI should raise\na exceptions.CommandError  instead of trying to build the prettytable\nfrom results.\n\nChange-Id: I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e\n(cherry picked from commit efcf2d98be109c919d627f3148522a559d13667a)\n'}, {'number': 3, 'created': '2020-10-26 13:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0c103cc50f6674160fd3eddfcd79d75cf5688338', 'message': 'Raise if no validation has been executed\n\nIf no validations has been run, the CLI should raise\na exceptions.CommandError  instead of trying to build the prettytable\nfrom results.\n\nChange-Id: I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e\n(cherry picked from commit efcf2d98be109c919d627f3148522a559d13667a)\n'}, {'number': 4, 'created': '2020-10-26 13:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/baeec5562e0d725f07be69fcf343d6cf7127c3e3', 'message': 'Raise if no validation has been executed\n\nIf no validations has been run, the CLI should raise\na exceptions.CommandError  instead of trying to build the prettytable\nfrom results.\n\nChange-Id: I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e\n(cherry picked from commit efcf2d98be109c919d627f3148522a559d13667a)\n'}, {'number': 5, 'created': '2021-01-05 08:40:39.000000000', 'files': ['tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a60ec726e4d40b6040f4c08b0f35d35744a8835c', 'message': 'Raise if no validation has been executed\n\nIf no validations has been run, the CLI should raise\na exceptions.CommandError  instead of trying to build the prettytable\nfrom results.\n\nChange-Id: I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e\n(cherry picked from commit efcf2d98be109c919d627f3148522a559d13667a)\n'}]",0,759695,a60ec726e4d40b6040f4c08b0f35d35744a8835c,25,6,5,11491,,,0,"Raise if no validation has been executed

If no validations has been run, the CLI should raise
a exceptions.CommandError  instead of trying to build the prettytable
from results.

Change-Id: I2ed22b9c01ebb64281ad5b8b3b569cc53a4f122e
(cherry picked from commit efcf2d98be109c919d627f3148522a559d13667a)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/95/759695/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_validator.py'],1,1ea9d8205e06367eabaf70ebf52f0be4261be69d,ussuri/vf/bz/1887437," try: results = actions.run_validations( inventory=static_inventory, limit_hosts=limit, group=parsed_args.group, extra_vars=extra_vars, validations_dir=constants.ANSIBLE_VALIDATION_DIR, validation_name=parsed_args.validation_name, extra_env_vars=parsed_args.extra_env_vars, quiet=True) except RuntimeError as e: raise exceptions.CommandError(e) if results: # Build output t = PrettyTable(border=True, header=True, padding_width=1) # Set Field name by getting the result dict keys t.field_names = results[0].keys() for r in results: if r.get('Status_by_Host'): h = [] for host in r['Status_by_Host'].split(', '): _name, _status = host.split(',') color = (GREEN if _status == 'PASSED' else RED) _name = '{}{}{}'.format(color, _name, RESET) h.append(_name) r['Status_by_Host'] = ', '.join(h) if r.get('status'): status = r.get('status') color = (CYAN if status in ['starting', 'running'] else GREEN if status == 'PASSED' else RED) r['status'] = '{}{}{}'.format(color, status, RESET) t.add_row(r.values()) print(t) else: msg = ""No Validation has been run, please check your parameters."" raise exceptions.CommandError(msg)"," results = actions.run_validations( inventory=static_inventory, limit_hosts=limit, group=parsed_args.group, extra_vars=extra_vars, validations_dir=constants.ANSIBLE_VALIDATION_DIR, validation_name=parsed_args.validation_name, extra_env_vars=parsed_args.extra_env_vars, quiet=parsed_args.quiet) # Build output t = PrettyTable(border=True, header=True, padding_width=1) # Set Field name by getting the result dict keys t.field_names = results[0].keys() for r in results: if r.get('Status_by_Host'): h = [] for host in r['Status_by_Host'].split(', '): _name, _status = host.split(',') color = (GREEN if _status == 'PASSED' else RED) _name = '{}{}{}'.format(color, _name, RESET) h.append(_name) r['Status_by_Host'] = ', '.join(h) if r.get('status'): status = r.get('status') color = (CYAN if status in ['starting', 'running'] else GREEN if status == 'PASSED' else RED) r['status'] = '{}{}{}'.format(color, status, RESET) t.add_row(r.values()) print(t)",36,29
openstack%2Fovsdbapp~master~Ibc6f6025b89f2ac893471bf58794569804545b9d,openstack/ovsdbapp,master,Ibc6f6025b89f2ac893471bf58794569804545b9d,Fix gate failure,MERGED,2020-12-18 21:21:15.000000000,2021-01-05 20:15:29.000000000,2021-01-05 20:11:10.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 21:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/c2abfa6cf126a75cd33ed9f102f2c150a747fdbc', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update.\nFix associated new warnings.\n\nChange-Id: Ibc6f6025b89f2ac893471bf58794569804545b9d\n'}, {'number': 2, 'created': '2021-01-04 14:47:33.000000000', 'files': ['ovsdbapp/utils.py', 'test-requirements.txt', 'ovsdbapp/backend/ovs_idl/command.py', 'ovsdbapp/backend/ovs_idl/idlutils.py', 'ovsdbapp/backend/ovs_idl/connection.py', 'ovsdbapp/schema/ovn_northbound/commands.py', 'ovsdbapp/venv.py', 'lower-constraints.txt', 'ovsdbapp/exceptions.py', 'ovsdbapp/backend/ovs_idl/__init__.py', 'ovsdbapp/schema/ovn_southbound/commands.py', 'ovsdbapp/schema/open_vswitch/impl_idl.py', 'ovsdbapp/backend/ovs_idl/transaction.py', 'ovsdbapp/event.py', 'ovsdbapp/backend/ovs_idl/event.py', 'ovsdbapp/schema/open_vswitch/commands.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/0968b410ce13b6420131b28b4d09bdd16e306853', 'message': 'Fix gate failure\n\nBumped a bunch of constraints and requirements to fix\na gate failure with recent pip update.\nFix associated new warnings.\n\nChange-Id: Ibc6f6025b89f2ac893471bf58794569804545b9d\n'}]",3,767956,0968b410ce13b6420131b28b4d09bdd16e306853,17,6,2,11952,,,0,"Fix gate failure

Bumped a bunch of constraints and requirements to fix
a gate failure with recent pip update.
Fix associated new warnings.

Change-Id: Ibc6f6025b89f2ac893471bf58794569804545b9d
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/56/767956/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovsdbapp/utils.py', 'test-requirements.txt', 'ovsdbapp/backend/ovs_idl/command.py', 'ovsdbapp/backend/ovs_idl/idlutils.py', 'ovsdbapp/backend/ovs_idl/connection.py', 'ovsdbapp/schema/ovn_northbound/commands.py', 'ovsdbapp/venv.py', 'lower-constraints.txt', 'ovsdbapp/exceptions.py', 'ovsdbapp/backend/ovs_idl/__init__.py', 'ovsdbapp/schema/ovn_southbound/commands.py', 'ovsdbapp/schema/open_vswitch/impl_idl.py', 'ovsdbapp/backend/ovs_idl/transaction.py', 'ovsdbapp/event.py', 'ovsdbapp/backend/ovs_idl/event.py', 'ovsdbapp/schema/open_vswitch/commands.py']",16,c2abfa6cf126a75cd33ed9f102f2c150a747fdbc,, super().__init__(api) super().__init__(api) super().__init__(api) except idlutils.RowNotFound as e: raise RuntimeError(msg) from e super().__init__(api) super().__init__(api) except idlutils.RowNotFound as e: raise RuntimeError(msg) from e super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) except idlutils.RowNotFound as e: raise RuntimeError(msg) from e super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__(api) super().__init__( super().__init__( super().__init__( super().__init__(," super(AddManagerCommand, self).__init__(api) super(GetManagerCommand, self).__init__(api) super(RemoveManagerCommand, self).__init__(api) except idlutils.RowNotFound: raise RuntimeError(msg) super(AddBridgeCommand, self).__init__(api) super(DelBridgeCommand, self).__init__(api) except idlutils.RowNotFound: raise RuntimeError(msg) super(BridgeExistsCommand, self).__init__(api) super(ListBridgesCommand, self).__init__(api) super(SetControllerCommand, self).__init__(api) super(DelControllerCommand, self).__init__(api) super(GetControllerCommand, self).__init__(api) super(SetFailModeCommand, self).__init__(api) super(AddPortCommand, self).__init__(api) super(DelPortCommand, self).__init__(api) except idlutils.RowNotFound: raise RuntimeError(msg) super(ListPortsCommand, self).__init__(api) super(ListIfacesCommand, self).__init__(api) super(PortToBridgeCommand, self).__init__(api) super(InterfaceToBridgeCommand, self).__init__(api) super(GetExternalIdCommand, self).__init__(api) super(SetExternalIdCommand, self).__init__(api) super(BrGetExternalIdCommand, self).__init__( super(BrSetExternalIdCommand, self).__init__( super(IfaceGetExternalIdCommand, self).__init__( super(IfaceSetExternalIdCommand, self).__init__(",182,179
openstack%2Fblazar~master~I0c39bb5581c120190a764b25890ba868180a59fe,openstack/blazar,master,I0c39bb5581c120190a764b25890ba868180a59fe,Add doc/requirements,MERGED,2021-01-05 10:28:09.000000000,2021-01-05 19:41:01.000000000,2021-01-05 19:39:23.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 10:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d1f4af91a9d71eb8284dc2701c2afbc8cf9aa1bc', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I0c39bb5581c120190a764b25890ba868180a59fe\n""}, {'number': 2, 'created': '2021-01-05 15:21:21.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar/commit/963097ee7fc7d41ebce5a6741fdbe6c17346ce03', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I0c39bb5581c120190a764b25890ba868180a59fe\n""}]",0,769312,963097ee7fc7d41ebce5a6741fdbe6c17346ce03,13,2,2,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I0c39bb5581c120190a764b25890ba868180a59fe
",git fetch https://review.opendev.org/openstack/blazar refs/changes/12/769312/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,d1f4af91a9d71eb8284dc2701c2afbc8cf9aa1bc,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt,9,10
openstack%2Fcharm-deployment-guide~master~I578f8099f2de652042a793f43fe7322e0bfb5bba,openstack/charm-deployment-guide,master,I578f8099f2de652042a793f43fe7322e0bfb5bba,Touchups to page titles and wording,MERGED,2021-01-05 02:04:14.000000000,2021-01-05 19:37:26.000000000,2021-01-05 19:35:43.000000000,"[{'_account_id': 8992}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 02:04:14.000000000', 'files': ['deploy-guide/source/app-certificate-management.rst', 'deploy-guide/source/app-hardware-offload.rst', 'deploy-guide/source/app-octavia.rst', 'deploy-guide/source/app-ovn.rst', 'deploy-guide/source/upgrade-special.rst', 'deploy-guide/source/upgrade-issues.rst', 'deploy-guide/source/app-ha.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/7dc973e7df55e3a660cd7bc6e3ae237a93f78c7a', 'message': 'Touchups to page titles and wording\n\nUpdate links accordingly.\n\nDriveby formatting fixes.\n\nChange-Id: I578f8099f2de652042a793f43fe7322e0bfb5bba\n'}]",0,769234,7dc973e7df55e3a660cd7bc6e3ae237a93f78c7a,7,2,1,30561,,,0,"Touchups to page titles and wording

Update links accordingly.

Driveby formatting fixes.

Change-Id: I578f8099f2de652042a793f43fe7322e0bfb5bba
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/34/769234/1 && git format-patch -1 --stdout FETCH_HEAD,"['deploy-guide/source/app-certificate-management.rst', 'deploy-guide/source/app-hardware-offload.rst', 'deploy-guide/source/app-octavia.rst', 'deploy-guide/source/app-ovn.rst', 'deploy-guide/source/upgrade-special.rst', 'deploy-guide/source/upgrade-issues.rst', 'deploy-guide/source/app-ha.rst']",7,7dc973e7df55e3a660cd7bc6e3ae237a93f78c7a,cdg-reorg,We'll do the former here for simplicity but see `Managing TLS certificates`_ for how to use a chain... _Managing TLS certificates: app-certificate-management.html,We'll do the former here for simplicity but see `Managing TLS certificates with Vault`_ for how to use a chain... _Managing TLS certificates with Vault: app-certificate-management.html,148,155
openstack%2Fcinder-tempest-plugin~master~Ife6511c8d6bbc4c025fa51f022cf6ba995a34bdd,openstack/cinder-tempest-plugin,master,Ife6511c8d6bbc4c025fa51f022cf6ba995a34bdd,Replace stein job with victoria,ABANDONED,2021-01-05 19:15:11.000000000,2021-01-05 19:31:33.000000000,,[],"[{'number': 1, 'created': '2021-01-05 19:15:11.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cinder-tempest-plugin/commit/bccfca901c25f484ef5d3a9cfb0e87c6368a886e', 'message': 'Replace stein job with victoria\n\nStein went to EM on Wed Nov 25 09:57:46 2020 +0000 and will no longer\nbe released from, so replace its job with one for victoria.\n\non Wed Nov 25 09:57:46 2020 +0000\n\nChange-Id: Ife6511c8d6bbc4c025fa51f022cf6ba995a34bdd\n'}]",0,769414,bccfca901c25f484ef5d3a9cfb0e87c6368a886e,2,0,1,5314,,,0,"Replace stein job with victoria

Stein went to EM on Wed Nov 25 09:57:46 2020 +0000 and will no longer
be released from, so replace its job with one for victoria.

on Wed Nov 25 09:57:46 2020 +0000

Change-Id: Ife6511c8d6bbc4c025fa51f022cf6ba995a34bdd
",git fetch https://review.opendev.org/openstack/cinder-tempest-plugin refs/changes/14/769414/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,bccfca901c25f484ef5d3a9cfb0e87c6368a886e,update-jobs, - cinder-tempest-plugin-basic-victoria name: cinder-tempest-plugin-basic-victoria parent: cinder-tempest-plugin-basic nodeset: openstack-single-node-focal override-checkout: stable/victoria - job:, - cinder-tempest-plugin-basic-stein - job: name: cinder-tempest-plugin-basic-stein parent: cinder-tempest-plugin-basic nodeset: openstack-single-node-bionic override-checkout: stable/stein vars: devstack_localrc: USE_PYTHON3: True,7,10
openstack%2Fpython-senlinclient~master~I930fe411c516acff2753cbbbaaa707bc6e6160ba,openstack/python-senlinclient,master,I930fe411c516acff2753cbbbaaa707bc6e6160ba,Remove unicode from python client,MERGED,2021-01-03 03:05:00.000000000,2021-01-05 19:24:54.000000000,2021-01-05 19:23:27.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27224}, {'_account_id': 32029}]","[{'number': 1, 'created': '2021-01-03 03:05:00.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/e6edaee89249f88e7824cc7a175e903f09340ab4', 'message': 'Remove unicode from python client\n\nChange-Id: I930fe411c516acff2753cbbbaaa707bc6e6160ba\n'}]",0,768931,e6edaee89249f88e7824cc7a175e903f09340ab4,9,4,1,29870,,,0,"Remove unicode from python client

Change-Id: I930fe411c516acff2753cbbbaaa707bc6e6160ba
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/31/768931/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,e6edaee89249f88e7824cc7a175e903f09340ab4,remove-unicode,"project = 'Senlin Client Release Notes' copyright = '2015, Senlin Developers' 'Senlin Client Release Notes Documentation', 'Senlin Developers', 'manual'), 'Senlin Client Release Notes Documentation', ['Senlin Developers'], 1) 'Senlin Client Release Notes Documentation', 'Senlin Developers', 'SenlinClientReleaseNotes',","project = u'Senlin Client Release Notes' copyright = u'2015, Senlin Developers' u'Senlin Client Release Notes Documentation', u'Senlin Developers', 'manual'), u'Senlin Client Release Notes Documentation', [u'Senlin Developers'], 1) u'Senlin Client Release Notes Documentation', u'Senlin Developers', 'SenlinClientReleaseNotes',",8,8
openstack%2Fnova~master~Ib424662a52c4439468392dff72a7c64ed40b352a,openstack/nova,master,Ib424662a52c4439468392dff72a7c64ed40b352a,Optionally prevent nova-compute start with DB credentials,NEW,2020-11-10 17:21:28.000000000,2021-01-05 19:11:55.000000000,,"[{'_account_id': 4393}, {'_account_id': 6476}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 23811}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-11-10 17:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df4f6891c6e924c66d6b31babfa634f877079c4a', 'message': 'Prevent nova-compute start with DB credentials\n\nThe nova-compute service does not use direct DB access since Grizzly[1].\nThe change [1] only made sure that service blows when such DB\naccess is performed. Now nova-compute also checks if the configuration\ncontains DB credentials and refuse to start with a proper error message.\n\nRelated-Bug: #1871482\n\n[1] I478230220633e0d2ff94b6a4d756e07eab8517d7\n\nChange-Id: Ib424662a52c4439468392dff72a7c64ed40b352a\n'}, {'number': 2, 'created': '2020-11-11 09:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fad782b3d0bc7d600e203b748426b51f416f6389', 'message': 'Prevent nova-compute start with DB credentials\n\nThe nova-compute service does not use direct DB access since Grizzly[1].\nThe change [1] only made sure that service blows when such DB\naccess is performed. Now nova-compute also checks if the configuration\ncontains DB credentials and refuse to start with a proper error message.\n\nRelated-Bug: #1871482\n\n[1] I478230220633e0d2ff94b6a4d756e07eab8517d7\n\nChange-Id: Ib424662a52c4439468392dff72a7c64ed40b352a\n'}, {'number': 3, 'created': '2020-11-11 10:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84f3971d3bc941519c5fe715ebdb4b0003d8548e', 'message': 'Prevent nova-compute start with DB credentials\n\nThe nova-compute service does not use direct DB access since Grizzly[1].\nThe change [1] only made sure that service blows when such DB\naccess is performed. Now nova-compute also checks if the configuration\ncontains DB credentials and refuse to start with a proper error message.\n\nRelated-Bug: #1871482\n\n[1] I478230220633e0d2ff94b6a4d756e07eab8517d7\n\nChange-Id: Ib424662a52c4439468392dff72a7c64ed40b352a\n'}, {'number': 4, 'created': '2020-11-20 12:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c2f883ca9f4edcaa23b70ccd89094df1371820a', 'message': 'Prevent nova-compute start with DB credentials\n\nThe nova-compute service does not use direct DB access since Grizzly[1].\nThe change [1] only made sure that service blows when such DB\naccess is performed. Now nova-compute also checks if the configuration\ncontains DB credentials and refuse to start with a proper error message.\n\nThis patch also adds a new config option\n[workarounds]fail_to_start_compute_service_with_database_config that is\nFalse by default. This way the current change will not break any\npackager or deployer but allows them to test if they are ready for the\nfuture change where this config is removed and the hard failure is\nenforced by nova.\n\nRelated-Bug: #1871482\n\n[1] I478230220633e0d2ff94b6a4d756e07eab8517d7\n\nChange-Id: Ib424662a52c4439468392dff72a7c64ed40b352a\n'}, {'number': 5, 'created': '2020-11-20 13:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6dda90f91c8fab356ab57c5ad3121ae08aeadb62', 'message': 'Prevent nova-compute start with DB credentials\n\nThe nova-compute service does not use direct DB access since Grizzly[1].\nThe change [1] only made sure that service blows when such DB\naccess is performed. Now nova-compute also checks if the configuration\ncontains DB credentials and refuse to start with a proper error message.\n\nThis patch also adds a new config option\n[workarounds]fail_to_start_compute_service_with_database_config that is\nFalse by default. This way the current change will not break any\npackager or deployer but allows them to test if they are ready for the\nfuture change where this config is removed and the hard failure is\nenforced by nova.\n\nRelated-Bug: #1871482\nRelated-Bug: #1904179\n\n[1] I478230220633e0d2ff94b6a4d756e07eab8517d7\n\nChange-Id: Ib424662a52c4439468392dff72a7c64ed40b352a\n'}, {'number': 6, 'created': '2020-12-16 16:53:08.000000000', 'files': ['nova/tests/unit/cmd/test_common.py', 'nova/cmd/common.py', 'nova/conf/database.py', 'nova/conf/workarounds.py', 'releasenotes/notes/prevent-compute-service-startup-with-api-db-configuration-125bf3fab55edc65.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/1d287527ec939c2a6e1525e1029f7ba1b326311a', 'message': 'Optionally prevent nova-compute start with DB credentials\n\nThe nova-compute service does not use direct DB access since Grizzly[1].\nThe change [1] only made sure that service blows when such DB\naccess is performed. Now nova-compute also checks if the configuration\ncontains DB credentials and optionally refuses to start with a proper\nerror message.\n\nThis patch adds a new config option\n[workarounds]fail_to_start_compute_service_with_database_config that is\nFalse by default. This way the current change will not break any\npackager or deployer but allows them to test if they are ready for the\nfuture change where this config is removed and the hard failure is\nenforced by nova.\n\nRelated-Bug: #1871482\nRelated-Bug: #1904179\n\n[1] I478230220633e0d2ff94b6a4d756e07eab8517d7\n\nChange-Id: Ib424662a52c4439468392dff72a7c64ed40b352a\n'}]",18,762176,1d287527ec939c2a6e1525e1029f7ba1b326311a,75,14,6,9708,,,0,"Optionally prevent nova-compute start with DB credentials

The nova-compute service does not use direct DB access since Grizzly[1].
The change [1] only made sure that service blows when such DB
access is performed. Now nova-compute also checks if the configuration
contains DB credentials and optionally refuses to start with a proper
error message.

This patch adds a new config option
[workarounds]fail_to_start_compute_service_with_database_config that is
False by default. This way the current change will not break any
packager or deployer but allows them to test if they are ready for the
future change where this config is removed and the hard failure is
enforced by nova.

Related-Bug: #1871482
Related-Bug: #1904179

[1] I478230220633e0d2ff94b6a4d756e07eab8517d7

Change-Id: Ib424662a52c4439468392dff72a7c64ed40b352a
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/762176/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/cmd/test_common.py', 'nova/cmd/common.py', 'releasenotes/notes/prevent-compute-service-startup-with-api-db-configuration-125bf3fab55edc65.yaml']",3,df4f6891c6e924c66d6b31babfa634f877079c4a,bug/1871482,"--- other: - | Since the Grizzly relese nova-compute is not allowed to directly access the nova DB. If the service is configured with DB credentials and the code tried to access the DB then the service would fail without proper explanation of the root cause, the configuration issue. Now the nova-compute configuration is checked at service startup and the service refures to start if DB credentials are configured. ",,31,0
openstack%2Fsenlin-tempest-plugin~master~I6a5068449fb2eef67530c2501276b179773e4c46,openstack/senlin-tempest-plugin,master,I6a5068449fb2eef67530c2501276b179773e4c46,Add functional test for cooldown,ABANDONED,2018-10-03 00:34:49.000000000,2021-01-05 19:09:37.000000000,,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 23517}, {'_account_id': 27224}]","[{'number': 1, 'created': '2018-10-03 00:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/bbada8a39fb0632369f0bec81034baf70320338b', 'message': 'Add functional test for cooldown\n\nChange-Id: I6a5068449fb2eef67530c2501276b179773e4c46\n'}, {'number': 2, 'created': '2018-10-03 00:35:17.000000000', 'files': ['senlin_tempest_plugin/tests/functional/test_scaling_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/9a8b5141ba72700ddd79015c7a95b809a9ab598f', 'message': 'Add functional test for cooldown\n\nDepends-On: https://review.openstack.org/#/c/607395/\nChange-Id: I6a5068449fb2eef67530c2501276b179773e4c46\n'}]",0,607407,9a8b5141ba72700ddd79015c7a95b809a9ab598f,20,4,2,27224,,,0,"Add functional test for cooldown

Depends-On: https://review.openstack.org/#/c/607395/
Change-Id: I6a5068449fb2eef67530c2501276b179773e4c46
",git fetch https://review.opendev.org/openstack/senlin-tempest-plugin refs/changes/07/607407/2 && git format-patch -1 --stdout FETCH_HEAD,['senlin_tempest_plugin/tests/functional/test_scaling_policy.py'],1,bbada8a39fb0632369f0bec81034baf70320338b,bug/1795503," @decorators.attr(type=['functional']) @decorators.idempotent_id('69c8a13b-e50b-49bc-94d4-8f8509b119e1') def test_scaling_policy_within_cooldown_scale_out(self): # Create a scaling policy targets on CLUSTER_SCALE_OUT action spec = constants.spec_scaling_policy spec['properties'] = { 'event': 'CLUSTER_SCALE_OUT', 'adjustment': { 'type': 'CHANGE_IN_CAPACITY', 'number': 2, 'min_step': 1, 'best_effort': True, 'cooldown': 60 } } policy_id = utils.create_a_policy(self, spec) scaleout_policy = utils.get_a_policy(self, policy_id) self.addCleanup(utils.delete_a_policy, self, scaleout_policy['id']) # Attach scale out policies to cluster utils.cluster_attach_policy(self, self.cluster_id, scaleout_policy['id']) self.addCleanup(utils.cluster_detach_policy, self, self.cluster_id, scaleout_policy['id']) # Scale out cluster without count specified utils.cluster_scale_out(self, self.cluster_id) # Verify scale out result cluster = utils.get_a_cluster(self, self.cluster_id) self.assertEqual('ACTIVE', cluster['status']) self.assertEqual(3, cluster['desired_capacity']) self.assertEqual(3, len(cluster['nodes'])) # Scale out cluster should fail due to cooldown utils.cluster_scale_out(self, self.cluster_id, expected_status='FAILED') @decorators.attr(type=['functional']) @decorators.idempotent_id('8c46ac47-6267-4e9c-970f-95942b75ffee') def test_scaling_policy_within_cooldown_scale_in(self): # Create a scaling policy targets on CLUSTER_SCALE_OUT action spec = constants.spec_scaling_policy spec['properties'] = { 'event': 'CLUSTER_SCALE_OUT', 'adjustment': { 'type': 'CHANGE_IN_CAPACITY', 'number': 2, 'min_step': 1, 'best_effort': True, 'cooldown': 60 } } policy_id = utils.create_a_policy(self, spec) scaleout_policy = utils.get_a_policy(self, policy_id) self.addCleanup(utils.delete_a_policy, self, scaleout_policy['id']) # Attach scale out policies to cluster utils.cluster_attach_policy(self, self.cluster_id, scaleout_policy['id']) self.addCleanup(utils.cluster_detach_policy, self, self.cluster_id, scaleout_policy['id']) # Scale out cluster without count specified utils.cluster_scale_out(self, self.cluster_id) # Verify scale out result cluster = utils.get_a_cluster(self, self.cluster_id) self.assertEqual('ACTIVE', cluster['status']) self.assertEqual(3, cluster['desired_capacity']) self.assertEqual(3, len(cluster['nodes'])) # Scale in cluster without count specified utils.cluster_scale_in(self, self.cluster_id) # Verify scale in result cluster = utils.get_a_cluster(self, self.cluster_id) self.assertEqual('ACTIVE', cluster['status']) self.assertEqual(2, cluster['desired_capacity']) self.assertEqual(2, len(cluster['nodes'])) @decorators.attr(type=['functional']) @decorators.idempotent_id('a1060233-f800-4abb-8ea0-dc1b967ebb95') def test_scaling_policy_cooldown_scale_in_scale_out(self): # Create a scaling policy targets on CLUSTER_SCALE_OUT action spec = constants.spec_scaling_policy spec['properties'] = { 'event': 'CLUSTER_SCALE_OUT', 'adjustment': { 'type': 'CHANGE_IN_CAPACITY', 'number': 2, 'min_step': 1, 'best_effort': True, 'cooldown': 60 } } policy_id = utils.create_a_policy(self, spec) scaleout_policy = utils.get_a_policy(self, policy_id) self.addCleanup(utils.delete_a_policy, self, scaleout_policy['id']) # Attach scale out policies to cluster utils.cluster_attach_policy(self, self.cluster_id, scaleout_policy['id']) self.addCleanup(utils.cluster_detach_policy, self, self.cluster_id, scaleout_policy['id']) # Scale in cluster without count specified # only scale out policy has cooldown, # so scale in should work utils.cluster_scale_in(self, self.cluster_id) # Verify scale in result cluster = utils.get_a_cluster(self, self.cluster_id) self.assertEqual('ACTIVE', cluster['status']) self.assertEqual(0, cluster['desired_capacity']) self.assertEqual(0, len(cluster['nodes'])) # Scale out cluster should fail due to cooldown utils.cluster_scale_out(self, self.cluster_id, expected_status='FAILED')",,121,0
openstack%2Ftripleo-ansible~stable%2Fvictoria~I808daf58b606c717ab1bbae7d3d869d5baa67352,openstack/tripleo-ansible,stable/victoria,I808daf58b606c717ab1bbae7d3d869d5baa67352,[kernel] Updating facts before disabling NICs,MERGED,2020-12-24 04:37:55.000000000,2021-01-05 19:07:25.000000000,2021-01-05 19:07:25.000000000,"[{'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-12-24 04:37:55.000000000', 'files': ['tripleo_ansible/roles/tripleo_kernel/tasks/reboot.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ae02f6dd1f741afe2653fdb3a354fecd70b816fa', 'message': ""[kernel] Updating facts before disabling NICs\n\nWhen we delete and recreate a stack multiple times, it can lead to\noutdated facts and cause tripleo-kernel to disable nic1 when it\nshouldn't. This happens when we have a bond/team on nic1 at some point\nduring the deployment.\n\nCloses-Bug: #1906082\n\nSigned-off-by: David Vallee Delisle <dvd@redhat.com>\nChange-Id: I808daf58b606c717ab1bbae7d3d869d5baa67352\n(cherry picked from commit 1166412e3bc0d6822ab32f5b405c5ab7593d9883)\n""}]",0,768396,ae02f6dd1f741afe2653fdb3a354fecd70b816fa,11,5,1,27419,,,0,"[kernel] Updating facts before disabling NICs

When we delete and recreate a stack multiple times, it can lead to
outdated facts and cause tripleo-kernel to disable nic1 when it
shouldn't. This happens when we have a bond/team on nic1 at some point
during the deployment.

Closes-Bug: #1906082

Signed-off-by: David Vallee Delisle <dvd@redhat.com>
Change-Id: I808daf58b606c717ab1bbae7d3d869d5baa67352
(cherry picked from commit 1166412e3bc0d6822ab32f5b405c5ab7593d9883)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/96/768396/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_kernel/tasks/reboot.yaml'],1,ae02f6dd1f741afe2653fdb3a354fecd70b816fa,, - name: Update facts before attempting to disable interfaces setup:,,2,0
openstack%2Ftripleo-ansible~master~I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6,openstack/tripleo-ansible,master,I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6,Add role_net_map to expand roles output,MERGED,2020-11-30 11:19:13.000000000,2021-01-05 19:07:08.000000000,2021-01-05 19:05:37.000000000,"[{'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-11-30 11:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e909fe2afe59d84f28a4a1ffe16dae9c71a29805', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 2, 'created': '2020-11-30 17:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8fbdfbc84adef311fe8dcf2cdf0ad73f5a43e1fb', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 3, 'created': '2020-12-01 12:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/00774e3fa74179f2616c1a3ffda60ed64c20c3a0', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 4, 'created': '2020-12-04 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/533d6cd8fa58b4b8c27b4cf6761fc52ac4ecf809', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 5, 'created': '2020-12-04 18:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/196c19d50697eec7925f9ec5fd8458222517d917', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 6, 'created': '2020-12-04 19:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4a77cf9923092fb7bea8284e846129f7bf703335', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 7, 'created': '2020-12-07 17:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/08e576306189d6291ad55f2169605b920028ce2e', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 8, 'created': '2020-12-18 05:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b61808ffc5da7ea57b651a486783ef7be9efb725', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}, {'number': 9, 'created': '2020-12-18 06:47:44.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_baremetal_expand_roles.py', 'tripleo_ansible/tests/plugins/module_utils/test_baremetal_deploy.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/741e8d3be8d549ded0ea14180e156df70f108a19', 'message': 'Add role_net_map to expand roles output\n\nA mapping of roles to associated networks.\n\nThe mapping will be used to write resource registry\noverrides in the populate network ports environment\nmodule.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6\n'}]",0,764639,741e8d3be8d549ded0ea14180e156df70f108a19,37,5,9,24245,,,0,"Add role_net_map to expand roles output

A mapping of roles to associated networks.

The mapping will be used to write resource registry
overrides in the populate network ports environment
module.

Partial-Implements: blueprint network-data-v2-ports
Change-Id: I7bc7f2986cd7574b6c7252dc20f196f59d1f9df6
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/39/764639/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_baremetal_expand_roles.py', 'tripleo_ansible/tests/plugins/module_utils/test_baremetal_deploy.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py']",3,e909fe2afe59d84f28a4a1ffe16dae9c71a29805,nework-data-v2," role_net_map = {} role_net_map.setdefault(name, set()) role_net_map[name].update( [x['network'] for x in inst.get('networks', [])]) role_net_map[name] = sorted(role_net_map[name]) return instances, env, role_net_map"," return instances, env",31,22
openstack%2Fpuppet-neutron~master~I4630ad619382d00132e6b4ab0dc43bf72146073b,openstack/puppet-neutron,master,I4630ad619382d00132e6b4ab0dc43bf72146073b,Fix typos in comment lines,MERGED,2021-01-03 05:50:58.000000000,2021-01-05 19:05:17.000000000,2021-01-05 19:05:17.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d593cc7e147e54a5ca6faa9b50f52b1b395961fd', 'message': 'Fix a typo in comment lines\n\nChange-Id: I4630ad619382d00132e6b4ab0dc43bf72146073b\n'}, {'number': 2, 'created': '2021-01-03 05:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/02534e314d04a07b9f37455bd9028353a78c3b66', 'message': 'Fix typos in comment lines\n\nChange-Id: I4630ad619382d00132e6b4ab0dc43bf72146073b\n'}, {'number': 3, 'created': '2021-01-03 22:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b81ac79f1dc20ee46300da96991d5079ed116fec', 'message': 'Fix typos in comment lines\n\nChange-Id: I4630ad619382d00132e6b4ab0dc43bf72146073b\n'}, {'number': 4, 'created': '2021-01-04 13:42:18.000000000', 'files': ['manifests/plugins/ml2/sriov_driver.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ec1a5f24c3cea1ef2e84b82623e29c472c960a2d', 'message': 'Fix typos in comment lines\n\nChange-Id: I4630ad619382d00132e6b4ab0dc43bf72146073b\n'}]",0,768960,ec1a5f24c3cea1ef2e84b82623e29c472c960a2d,14,3,4,9816,,,0,"Fix typos in comment lines

Change-Id: I4630ad619382d00132e6b4ab0dc43bf72146073b
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/60/768960/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2/sriov_driver.pp'],1,d593cc7e147e54a5ca6faa9b50f52b1b395961fd,typo,# neutron::plugins::ml2::sriov_driver# administratively prohibited by the SRIOV mechanism driver,# neutron::plugins::ml2::ovs_driver# administratively prohibited by the OVS mechanism driver,2,2
openstack%2Fblazar~master~Id572aec8a6fda7676eb03d17c66fd33f9801f25d,openstack/blazar,master,Id572aec8a6fda7676eb03d17c66fd33f9801f25d,Remove six,MERGED,2020-09-30 03:00:55.000000000,2021-01-05 18:59:09.000000000,2021-01-05 18:57:42.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 30092}, {'_account_id': 32238}, {'_account_id': 32475}]","[{'number': 1, 'created': '2020-09-30 03:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/112d84e1597fbe529976922d09b4959ab86b8cbf', 'message': 'Remove six\nReplace the following items with Python 3 style code.\n\n- six.next\n- six.text_type\n- six.add_metaclass\n- six.moves\n\nChange-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d\n'}, {'number': 2, 'created': '2020-09-30 06:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/489d7a1f8d95edf84552b0aa90d57d3c1733f7c0', 'message': 'Remove six\nReplace the following items with Python 3 style code.\n\n- six.next\n- six.text_type\n- six.add_metaclass\n- six.moves\n\nChange-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d\n'}, {'number': 3, 'created': '2020-09-30 06:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/ad6d7a7a93bc6653418273fb5ef5d4674f064618', 'message': 'Remove six\n\nReplace the following items with Python 3 style code.\n\n- six.next\n- six.text_type\n- six.add_metaclass\n- six.moves\n\nChange-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d\n'}, {'number': 4, 'created': '2020-09-30 08:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/06fafeedbb990fe5f585780f8663128ac26bc050', 'message': 'Remove six\n\nReplace the following items with Python 3 style code.\n\n- six.next\n- six.text_type\n- six.add_metaclass\n- six.moves\n\nImplements: blueprint six-removal\n\nChange-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d\n'}, {'number': 5, 'created': '2020-10-07 03:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/a4e26c627889b2f962a0848db4d19b55f46d7660', 'message': 'Remove six\n\nReplace the following items with Python 3 style code.\n\n- six.next\n- six.text_type\n- six.add_metaclass\n- six.moves\n\nImplements: blueprint six-removal\n\nChange-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d\n'}, {'number': 6, 'created': '2021-01-05 16:08:24.000000000', 'files': ['blazar/tests/api/v1/oshosts/test_v1_0.py', 'blazar/tests/test_exceptions.py', 'blazar/api/v2/controllers/extensions/__init__.py', 'blazar/plugins/base.py', 'blazar/tests/api/v1/leases/test_v1_0.py', 'blazar/tests/manager/test_service.py', 'blazar/tests/plugins/instances/test_instance_plugin.py', 'blazar/tests/api/v2/test_leases.py', 'blazar/tests/db/migration/__init__.py', 'blazar/api/app.py', 'lower-constraints.txt', 'blazar/db/migration/alembic_migrations/versions/0_1_initial.py', 'blazar/plugins/instances/instance_plugin.py', 'blazar/tests/db/sqlalchemy/test_utils.py', 'blazar/api/context.py', 'requirements.txt', 'blazar/tests/api/v1/test_api_version_request.py', 'blazar/api/v2/controllers/types.py', 'blazar/tests/api/__init__.py', 'blazar/db/sqlalchemy/models.py', 'blazar/utils/plugins.py', 'blazar/tests/api/v2/test_hosts.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/ae43ea3adf2651d0ba77066053d4e73fa1507aa8', 'message': 'Remove six\n\nReplace the following items with Python 3 style code.\n\n- six.next\n- six.text_type\n- six.add_metaclass\n- six.moves\n\nImplements: blueprint six-removal\n\nChange-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d\n'}]",9,755166,ae43ea3adf2651d0ba77066053d4e73fa1507aa8,24,6,6,30092,,,0,"Remove six

Replace the following items with Python 3 style code.

- six.next
- six.text_type
- six.add_metaclass
- six.moves

Implements: blueprint six-removal

Change-Id: Id572aec8a6fda7676eb03d17c66fd33f9801f25d
",git fetch https://review.opendev.org/openstack/blazar refs/changes/66/755166/3 && git format-patch -1 --stdout FETCH_HEAD,"['blazar/tests/api/v1/oshosts/test_v1_0.py', 'blazar/tests/test_exceptions.py', 'blazar/api/v2/controllers/extensions/__init__.py', 'blazar/plugins/base.py', 'blazar/tests/api/v1/leases/test_v1_0.py', 'blazar/tests/manager/test_service.py', 'blazar/tests/plugins/instances/test_instance_plugin.py', 'blazar/tests/api/v2/test_leases.py', 'blazar/tests/db/migration/__init__.py', 'blazar/api/app.py', 'lower-constraints.txt', 'blazar/db/migration/alembic_migrations/versions/0_1_initial.py', 'blazar/plugins/instances/instance_plugin.py', 'blazar/tests/db/sqlalchemy/test_utils.py', 'blazar/api/context.py', 'requirements.txt', 'blazar/tests/api/v1/test_api_version_request.py', 'blazar/api/v2/controllers/types.py', 'blazar/tests/api/__init__.py', 'blazar/db/sqlalchemy/models.py', 'blazar/utils/plugins.py', 'blazar/tests/api/v2/test_hosts.py']",22,112d84e1597fbe529976922d09b4959ab86b8cbf,bp/six-removal, id1 = str('1') id2 = str('2') self.id1 = str('1') self.id1 = str(uuidutils.generate_uuid()) self.id1 = str('1') self.id1 = str('1'),import six id1 = six.text_type('1') id2 = six.text_type('2') self.id1 = six.text_type('1') self.id1 = six.text_type(uuidutils.generate_uuid()) self.id1 = six.text_type('1') self.id1 = six.text_type('1'),46,73
openstack%2Fnova~master~I65a6234cad239c29a0680670a9066e9aa996cc9d,openstack/nova,master,I65a6234cad239c29a0680670a9066e9aa996cc9d,Add instance project_id for cyborg arq,NEW,2020-06-29 12:00:48.000000000,2021-01-05 18:57:19.000000000,,"[{'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 28182}, {'_account_id': 29963}, {'_account_id': 31412}, {'_account_id': 32071}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-06-29 12:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82ad348e4bccda321d240fc7fb4c4cfad98b3fed', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 2, 'created': '2020-06-30 08:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7922b1bc3c07b390b50c518fe0cf7b450c4bea8', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 3, 'created': '2020-07-01 03:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8015cba91621ba8cf3ee75a127f52ea21d2e02cd', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 4, 'created': '2020-07-28 08:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be452760d5bcd218760c4d43c4384b69da73eea0', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 5, 'created': '2020-09-30 09:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8930ffe9b1e2500e408d98ec2498e7fda1365d68', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 6, 'created': '2020-10-05 03:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3155ae015fb281f0f5c60da1ce258a0c2b379dd5', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 7, 'created': '2020-10-05 10:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4afdc3e8c7c55deadacc3d6ef78b7d9cfe184507', 'message': 'Add instance project_id for cyborg arq\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n'}, {'number': 8, 'created': '2020-10-07 09:18:15.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/accelerator/test_cyborg.py', 'nova/conductor/manager.py', 'nova/accelerator/cyborg.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/58b51edd4979b0844252da0005fdd5f8becf7f7b', 'message': ""Add instance project_id for cyborg arq\n\nWe define 'PROJECT_ID_OF_ARQ_IN_CYBORG' version to limit arq binding\nwith instance project_id to 2.1 and greater\n\nChange-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d\n""}]",9,738428,58b51edd4979b0844252da0005fdd5f8becf7f7b,83,22,8,31412,,,0,"Add instance project_id for cyborg arq

We define 'PROJECT_ID_OF_ARQ_IN_CYBORG' version to limit arq binding
with instance project_id to 2.1 and greater

Change-Id: I65a6234cad239c29a0680670a9066e9aa996cc9d
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/738428/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/manager.py', 'nova/accelerator/cyborg.py']",2,82ad348e4bccda321d240fc7fb4c4cfad98b3fed,arq-instance-project-id," ""hostname"": STRING, ""device_rp_uuid"": UUID, ""instance_uuid"": UUID, ""project_id"": UUID"," ""hostname"": STRING ""device_rp_uuid"": UUID ""instance_uuid"": UUID",12,7
openstack%2Fcharm-neutron-api~master~I98cd67ff0cf5418a9699acc7aff96c3edb9b2341,openstack/charm-neutron-api,master,I98cd67ff0cf5418a9699acc7aff96c3edb9b2341,Use AZLeastRoutersScheduler by default,MERGED,2020-10-28 10:39:09.000000000,2021-01-05 18:51:11.000000000,2021-01-05 18:51:11.000000000,"[{'_account_id': 935}, {'_account_id': 8992}, {'_account_id': 13686}, {'_account_id': 13832}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 21107}, {'_account_id': 22348}, {'_account_id': 24824}]","[{'number': 1, 'created': '2020-10-28 10:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/c6efc82a66f47b886bddb6ce873dcafb7060e257', 'message': 'Use AZLeastRoutersScheduler by default\n\nNeutron uses an AZ-unaware scheduler (LeastRoutersScheduler) by default\nin its configuration and the neutron-api charm does not override it.\n\nAZLeastRoutersScheduler inherits from LeastRoutersScheduler and does the\nsame, plus respects AZ hints when scheduling HA routers.\n\nFor --distributed --ha routers using AZLeastRoutersScheduler means that\nsnat namespaces will be scheduled with respect to the AZ hints specified\nduring router creation by an operator.\n\nFor --ha but not distributed routers using AZLeastRoutersScheduler means\nthat qrouter namespaces will be scheduled with respect to the AZ hints.\n\nsnat namespaces (--ha & --distributed) and qrouter namespaces (--ha\nonly) are placed by the scheduler to l3 agents that run in the dvr_snat\nmode only so the scheduler change will affect both the deployments with\nneutron-gateway units and the ones with neutron-openvswitch running with\nuse-dvr-snat=True.\n\nChange-Id: I98cd67ff0cf5418a9699acc7aff96c3edb9b2341\nCloses-Bug: #1886195\n'}, {'number': 2, 'created': '2020-10-28 10:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/06d3e235251be165841f7a42a8870ae775a543ad', 'message': 'Use AZLeastRoutersScheduler by default\n\nNeutron uses an AZ-unaware scheduler (LeastRoutersScheduler) by default\nin its configuration and the neutron-api charm does not override it.\n\nAZLeastRoutersScheduler inherits from LeastRoutersScheduler and does the\nsame, plus respects AZ hints when scheduling HA routers.\n\nFor --distributed --ha routers using AZLeastRoutersScheduler means that\nsnat namespaces will be scheduled with respect to the AZ hints specified\nduring router creation by an operator.\n\nFor --ha but not distributed routers using AZLeastRoutersScheduler means\nthat qrouter namespaces will be scheduled with respect to the AZ hints.\n\nsnat namespaces (--ha & --distributed) and qrouter namespaces (--ha\nonly) are placed by the scheduler to l3 agents that run in the dvr_snat\nmode only so the scheduler change will affect both the deployments with\nneutron-gateway units and the ones with neutron-openvswitch running with\nuse-dvr-snat=True.\n\nChange-Id: I98cd67ff0cf5418a9699acc7aff96c3edb9b2341\nCloses-Bug: #1886195\n'}, {'number': 3, 'created': '2020-11-09 17:17:26.000000000', 'files': ['templates/newton/neutron.conf', 'templates/pike/neutron.conf', 'templates/queens/neutron.conf', 'templates/ussuri/neutron.conf', 'hooks/neutron_api_context.py', 'templates/train/neutron.conf', 'config.yaml', 'templates/mitaka/neutron.conf', 'templates/rocky/neutron.conf', 'unit_tests/test_neutron_api_context.py', 'templates/ocata/neutron.conf'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/a155e9cf1120ef1d148f9b7cc799c0de552bbab6', 'message': 'Use AZLeastRoutersScheduler by default\n\nNeutron uses an AZ-unaware scheduler (LeastRoutersScheduler) by default\nin its configuration and the neutron-api charm does not override it.\n\nAZLeastRoutersScheduler inherits from LeastRoutersScheduler and does the\nsame, plus respects AZ hints when scheduling HA routers.\n\nFor --distributed --ha routers using AZLeastRoutersScheduler means that\nsnat namespaces will be scheduled with respect to the AZ hints specified\nduring router creation by an operator.\n\nFor --ha but not distributed routers using AZLeastRoutersScheduler means\nthat qrouter namespaces will be scheduled with respect to the AZ hints.\n\nsnat namespaces (--ha & --distributed) and qrouter namespaces (--ha\nonly) are placed by the scheduler to l3 agents that run in the dvr_snat\nmode only so the scheduler change will affect both the deployments with\nneutron-gateway units and the ones with neutron-openvswitch running with\nuse-dvr-snat=True.\n\nChange-Id: I98cd67ff0cf5418a9699acc7aff96c3edb9b2341\nCloses-Bug: #1886195\n'}]",0,760104,a155e9cf1120ef1d148f9b7cc799c0de552bbab6,28,9,3,24824,,,0,"Use AZLeastRoutersScheduler by default

Neutron uses an AZ-unaware scheduler (LeastRoutersScheduler) by default
in its configuration and the neutron-api charm does not override it.

AZLeastRoutersScheduler inherits from LeastRoutersScheduler and does the
same, plus respects AZ hints when scheduling HA routers.

For --distributed --ha routers using AZLeastRoutersScheduler means that
snat namespaces will be scheduled with respect to the AZ hints specified
during router creation by an operator.

For --ha but not distributed routers using AZLeastRoutersScheduler means
that qrouter namespaces will be scheduled with respect to the AZ hints.

snat namespaces (--ha & --distributed) and qrouter namespaces (--ha
only) are placed by the scheduler to l3 agents that run in the dvr_snat
mode only so the scheduler change will affect both the deployments with
neutron-gateway units and the ones with neutron-openvswitch running with
use-dvr-snat=True.

Change-Id: I98cd67ff0cf5418a9699acc7aff96c3edb9b2341
Closes-Bug: #1886195
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/04/760104/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/newton/neutron.conf', 'templates/pike/neutron.conf', 'templates/queens/neutron.conf', 'templates/ussuri/neutron.conf', 'hooks/neutron_api_context.py', 'templates/train/neutron.conf', 'templates/mitaka/neutron.conf', 'templates/rocky/neutron.conf', 'unit_tests/test_neutron_api_context.py', 'templates/ocata/neutron.conf']",10,c6efc82a66f47b886bddb6ce873dcafb7060e257,bug/1886195,{% if router_scheduler_driver -%} router_scheduler_driver = {{ router_scheduler_driver }} {% endif -%},,32,0
openstack%2Fironic~master~Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c,openstack/ironic,master,Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c,Document using ramdisks with the ramdisk deploy interface,MERGED,2020-12-16 17:57:48.000000000,2021-01-05 18:33:42.000000000,2021-01-05 18:31:38.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-16 17:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f2f47684fad24ae29e2ab97655577b57caa433e9', 'message': 'Documenting using ramdisks with the ramdisk deploy interface\n\nChange-Id: Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c\nDepends-On: https://review.opendev.org/c/openstack/ironic-python-agent-builder/+/767376\n'}, {'number': 2, 'created': '2020-12-16 18:13:54.000000000', 'files': ['doc/source/admin/ramdisk-boot.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/20f25068c627974ae8c38ca249fcd96ec6924ed0', 'message': 'Document using ramdisks with the ramdisk deploy interface\n\nChange-Id: Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c\nDepends-On: https://review.opendev.org/c/openstack/ironic-python-agent-builder/+/767376\n'}]",0,767391,20f25068c627974ae8c38ca249fcd96ec6924ed0,11,4,2,10239,,,0,"Document using ramdisks with the ramdisk deploy interface

Change-Id: Ibc28cbfaa9331343c1f91f0e6b32aafda3e5718c
Depends-On: https://review.opendev.org/c/openstack/ironic-python-agent-builder/+/767376
",git fetch https://review.opendev.org/openstack/ironic refs/changes/91/767391/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/ramdisk-boot.rst'],1,f2f47684fad24ae29e2ab97655577b57caa433e9,ramdisk,"Creating a ramdisk ------------------ A ramdisk can be created using the ``ironic-ramdisk-base`` element from ironic-python-agent-builder_, e.g. with Debian: .. code-block:: shell export ELEMENTS_PATH=/opt/stack/ironic-python-agent-builder/dib disk-image-create -o /output/ramdisk \ debian-minimal ironic-ramdisk-base openssh-server You may want to use devuser_ or dynamic-login_ elements to provide SSH access. The resulting files (``/output/ramdisk.kernel`` and ``/output/ramdisk.initramfs`` in this case) can then be used when `Booting a ramdisk`_. Booting a ramdisk ----------------- Pass the kernel and ramdisk as normally, also providing the ramdisk as an image source, for example, .. code-block:: shell baremetal node set <NODE> \ --instance-info kernel=http://path/to/ramdisk.kernel \ --instance-info ramdisk=http://path/to/ramdisk.initramfs \ --instance-info image_source=http://path/to/ramdisk.initramfs baremetal node deploy <NODE> .. note:: The requirement to pass ``image_source`` is artificial and will be fixed in a future version of the Bare Metal service. .. _ironic-python-agent-builder: https://opendev.org/openstack/ironic-python-agent-builder .. _devuser: https://docs.openstack.org/diskimage-builder/latest/elements/devuser/README.html .. _dynamic-login: https://docs.openstack.org/diskimage-builder/latest/elements/dynamic-login/README.html",.. TODO(dtantsur): document how exactly to create and boot a ramdisk,39,1
openstack%2Fpython-cinderclient~master~If8fb8863ee757928a125f967dec1036cbc5178fc,openstack/python-cinderclient,master,If8fb8863ee757928a125f967dec1036cbc5178fc,Fix lower-constraints.txt,ABANDONED,2020-12-18 11:51:50.000000000,2021-01-05 18:20:08.000000000,,"[{'_account_id': 4523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 11:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/cedee7dee9a932b72f42aa95d73edd511c5cee56', 'message': 'lower-constraints: Bump doc8 to 0.7.0\n\nChange-Id: If8fb8863ee757928a125f967dec1036cbc5178fc\n'}, {'number': 2, 'created': '2020-12-18 13:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0962a8d236f3104a6321724c11ef522cb8294a43', 'message': 'lower-constraints: Bump doc8 to 0.7.0\n\nChange-Id: If8fb8863ee757928a125f967dec1036cbc5178fc\n'}, {'number': 3, 'created': '2020-12-21 09:33:12.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/392da27a660511a2efd165a8e87bc7783a75d5cc', 'message': 'Fix lower-constraints.txt\n\nThis has actually been broken for a while but only recently uncovered by\nthe newly introduced dependency resolver in pip.\n\nThis change bumps doc8 in test-requirements as well as doc8, mccabe,\npytz and urllib3 in lower-constraints.\n\nChange-Id: If8fb8863ee757928a125f967dec1036cbc5178fc\n'}]",0,767701,392da27a660511a2efd165a8e87bc7783a75d5cc,7,2,3,10135,,,0,"Fix lower-constraints.txt

This has actually been broken for a while but only recently uncovered by
the newly introduced dependency resolver in pip.

This change bumps doc8 in test-requirements as well as doc8, mccabe,
pytz and urllib3 in lower-constraints.

Change-Id: If8fb8863ee757928a125f967dec1036cbc5178fc
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/01/767701/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,cedee7dee9a932b72f42aa95d73edd511c5cee56,,doc8==0.7.0,doc8==0.6.0,1,1
openstack%2Ftripleo-common~stable%2Ftrain~I137fe3211043b00b553db26b2f5930f98373496d,openstack/tripleo-common,stable/train,I137fe3211043b00b553db26b2f5930f98373496d,"Move away from ""ss"" and drop default verbose mode",MERGED,2020-12-11 13:17:23.000000000,2021-01-05 18:17:56.000000000,2021-01-05 18:09:54.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-12-11 13:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ba09f2af6a0e3fd5332af9086b28cc5b78f00f32', 'message': 'Move away from ""ss"" and drop default verbose mode\n\nThis patch does three main things:\n- drop the ultra-verbose output (set -x), adding a new param we can use\n  when calling the healthcheck directly\n- move away from the ""ss"" calls and the multiple pipes used to filter\n  its output, using ""lsof"" and native filtering\n- rewrite the ""ps"" call in order to use ps native filters instead of\n  piping through grep\n\nThese changes should make the healthchecks stronger, and avoid some\nweird issues due to the pipes, and lower the amount of logs while\nkeeping the important information visible.\n\nIn order to get verbose mode when running the healthcheck directly, you\ncan do as follow:\n\npodman exec -u root -ti <container> bash\nHEALTHCHECK_DEBUG=1 ./openstack/healthcheck\nor\npodman -u root -e ""HEALTHCHECK_DEBUG=1"" <container> /openstack/healthcheck\n\nand enjoy a nice debug output.\n\nChange-Id: I137fe3211043b00b553db26b2f5930f98373496d\n(cherry picked from commit d03401438c22e59d4f51cedfd0af6d7d48328d45)\n'}, {'number': 2, 'created': '2020-12-11 13:18:23.000000000', 'files': ['releasenotes/notes/no_ss-368721c3af17b782.yaml', 'healthcheck/common.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/52394870c0830467a9226168438e00cb2b4f1f96', 'message': 'Move away from ""ss"" and drop default verbose mode\n\nThis patch does three main things:\n- drop the ultra-verbose output (set -x), adding a new param we can use\n  when calling the healthcheck directly\n- move away from the ""ss"" calls and the multiple pipes used to filter\n  its output, using ""lsof"" and native filtering\n- rewrite the ""ps"" call in order to use ps native filters instead of\n  piping through grep\n\nThese changes should make the healthchecks stronger, and avoid some\nweird issues due to the pipes, and lower the amount of logs while\nkeeping the important information visible.\n\nIn order to get verbose mode when running the healthcheck directly, you\ncan do as follow:\n\npodman exec -u root -ti <container> bash\nHEALTHCHECK_DEBUG=1 ./openstack/healthcheck\nor\npodman -u root -e ""HEALTHCHECK_DEBUG=1"" <container> /openstack/healthcheck\n\nand enjoy a nice debug output.\n\nFixes-Bug: #1907811\nChange-Id: I137fe3211043b00b553db26b2f5930f98373496d\n(cherry picked from commit d03401438c22e59d4f51cedfd0af6d7d48328d45)\n'}]",3,766706,52394870c0830467a9226168438e00cb2b4f1f96,16,6,2,5241,,,0,"Move away from ""ss"" and drop default verbose mode

This patch does three main things:
- drop the ultra-verbose output (set -x), adding a new param we can use
  when calling the healthcheck directly
- move away from the ""ss"" calls and the multiple pipes used to filter
  its output, using ""lsof"" and native filtering
- rewrite the ""ps"" call in order to use ps native filters instead of
  piping through grep

These changes should make the healthchecks stronger, and avoid some
weird issues due to the pipes, and lower the amount of logs while
keeping the important information visible.

In order to get verbose mode when running the healthcheck directly, you
can do as follow:

podman exec -u root -ti <container> bash
HEALTHCHECK_DEBUG=1 ./openstack/healthcheck
or
podman -u root -e ""HEALTHCHECK_DEBUG=1"" <container> /openstack/healthcheck

and enjoy a nice debug output.

Fixes-Bug: #1907811
Change-Id: I137fe3211043b00b553db26b2f5930f98373496d
(cherry picked from commit d03401438c22e59d4f51cedfd0af6d7d48328d45)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/06/766706/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/no_ss-368721c3af17b782.yaml', 'healthcheck/common.sh']",2,ba09f2af6a0e3fd5332af9086b28cc5b78f00f32,healthcheck/no-ss-stable/train," # This helps to capture the actual pid running the process pid=$(pgrep -d ',' -f $process) # Here, we use the embedded `ps' filter capabilities, and remove the # output header. We ensure we get the user for the selected PIDs only. # In order to ensure we don't get multiple lines, we truncate it with `head' ps -h -q${pid} -o user | head -n1 ports=${args// /,} pids=$(pgrep -d ',' -f $process) # First match exits - usually TCP and ""sudo TCP"" are enough. # `sudo' is needed, as in some cases even root can get a ""permission denied"" # on some file descriptors (case for heat_manager for example) # UDP support is needed for octavia manager (UDP:5555). lsof -n -w -P -a -iTCP:${ports} -p${pids} >&3 2>&1 || \ sudo -u $puser lsof -n -w -P -a -iTCP:${ports} -p${pids} >&3 2>&1 || \ lsof -w -P -a -iUDP:${ports} -p${pids} >&3 2>&1 || \ sudo -u $puser lsof -n -w -P -a -iUDP:${ports} -p${pids} >&3 2>&1 ports=${args// /,} pids=$(pgrep -d ',' -f $process) lsof -n -w -P -a -p${pids} -iTCP:${ports} -s TCP:LISTEN >&3 2>&1 pids=$(pgrep -d ',' -f $process) lsof -n -Fc -Ua -p${pids} $socket >&3 2>&1 if pgrep -f swift-${service} >&3 2>&1; then"," # This helps to capture the actual pids running the process pids=$(pgrep -d '|' -f $process) # 'cmd' is added to help in case part of the pid is in another pid from # another process. # $ ps -eo user,pid,cmd # USER PID CMD # nova 1 dumb-init --single-child -- kolla_start # nova 7 /usr/bin/python2 /usr/bin/nova-conductor # nova 25 /usr/bin/python2 /usr/bin/nova-conductor # nova 26 /usr/bin/python2 /usr/bin/nova-conductor # root 8311 ps -eo user,pid,cmd # The following ""ps"" command will capture the user from PID 7 which # is safe enough to assert this is the user running the process. ps -eo user,pid,cmd | grep $process | grep -E $pids | awk 'NR==1{print $1}' ports=${args// /|} pids=$(pgrep -d '|' -f $process) # https://bugs.launchpad.net/tripleo/+bug/1843555 # ""ss"" output is different if run as root vs as the user actually running # the process. So we also verify that the process is connected to the # port by using ""sudo -u"" to get the right output. # Note: the privileged containers have the correct ss output with root # user; which is why we need to run with both users, as a best effort. # https://bugs.launchpad.net/tripleo/+bug/1860556 # do ot use ""-q"" option for grep, since it returns 141 for some reason with # set -o pipefail. # See https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -E "":($ports).*,pid=($pids),"">/dev/null ports=${args// /|} pids=$(pgrep -d '|' -f $process) ss -lnp | grep -qE "":($ports).*,pid=($pids),"" # lsof truncate command name to 15 characters and this behaviour # cannot be disabled if [ ${#process} -gt 15 ] ; then process=${process:0:15} fi lsof -Fc -Ua $socket | grep -q ""c$process"" if ps -e | grep --quiet swift-$service; then",34,37
openstack%2Fpython-tripleoclient~stable%2Fvictoria~I28b8fc9884bff9df495e0ea9f0b5e4420880afd5,openstack/python-tripleoclient,stable/victoria,I28b8fc9884bff9df495e0ea9f0b5e4420880afd5,Add Python3 victoria unit tests,MERGED,2020-11-24 16:59:01.000000000,2021-01-05 18:16:36.000000000,2021-01-05 18:09:58.000000000,"[{'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 22816}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-24 16:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0cc6c734aca794ba2afee6b94eea7ae355b15c10', 'message': 'Add Python3 victoria unit tests\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for victoria.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: I28b8fc9884bff9df495e0ea9f0b5e4420880afd5\n'}, {'number': 2, 'created': '2021-01-04 15:34:39.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/95503224f32e2381ef665a2f2b35d2a6d7d9a504', 'message': 'Add Python3 victoria unit tests\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for victoria.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: I28b8fc9884bff9df495e0ea9f0b5e4420880afd5\n'}]",0,764036,95503224f32e2381ef665a2f2b35d2a6d7d9a504,13,5,2,14985,,,0,"Add Python3 victoria unit tests

This is an automatically generated patch to ensure unit testing
is in place for all the of the tested runtimes for victoria.

See also the PTI in governance [1].

[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html

Change-Id: I28b8fc9884bff9df495e0ea9f0b5e4420880afd5
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/36/764036/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,0cc6c734aca794ba2afee6b94eea7ae355b15c10,add-victoria-python-jobtemplates, - openstack-python3-victoria-jobs - openstack-tox-py38, - openstack-python3-ussuri-jobs - openstack-tox-py37,2,2
openstack%2Ftripleo-ci~master~Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a,openstack/tripleo-ci,master,Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a,Enable html report for content provider jobs,MERGED,2020-12-17 17:11:12.000000000,2021-01-05 18:09:49.000000000,2021-01-05 18:09:49.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-12-17 17:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f18225b6ba69423eaeb95009605b152e56dac1fc', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 2, 'created': '2020-12-18 14:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/696ff66da9e90dc3a9aee7abbb947916795b5994', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 3, 'created': '2020-12-18 18:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e3a2a956d780f77f6efbfc908b2630a757832dd3', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 4, 'created': '2020-12-21 14:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/14f040e8565c6607f6d0824f7b361622ae91a458', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor both build containers and content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 5, 'created': '2020-12-21 18:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3512aa16ccc009b9a8271460933cd621bb05cde8', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 6, 'created': '2020-12-22 12:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1a38a85ef468e809f177614c3e4bb48d3796791f', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 7, 'created': '2020-12-22 15:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/006ad0111c06eca825463f2b863d338b4a28ea30', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 8, 'created': '2020-12-22 18:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f7e1bf8c3c206e7dbfb850d96136d078393b30c', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 9, 'created': '2020-12-22 20:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/02719e35d9731f373c4c161bd95af5c667e16ebe', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 10, 'created': '2020-12-23 02:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/36ce06ee0065a0c24934e4e160da175644403f90', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 11, 'created': '2020-12-23 13:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fe9b858260870839aa264643d85fff1201d238d5', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 12, 'created': '2020-12-23 15:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/37e499dda2c22e85d87cd69575377a9d52e1caf3', 'message': 'WIP: Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 13, 'created': '2020-12-23 17:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/334c67f1c966744aa456437a5d4aae6a3bf4fe03', 'message': 'Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs.\nThis change also advertises zuul artifacts using zuul_return\nfor content provider jobs.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 14, 'created': '2020-12-28 13:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/11553df038e341eced64b198a6f8d01d819ce2ab', 'message': 'Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs,\nand use podman to check built images (buildah was inconsitent).\n\nThis change also advertises zuul artifacts using zuul_return and\nchange the build work dir to ansible user home.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}, {'number': 15, 'created': '2020-12-29 12:30:00.000000000', 'files': ['roles/build-containers/tasks/build-report.yaml', 'roles/build-containers/templates/kolla-build.sh.j2', 'zuul.d/base.yaml', 'roles/build-containers/files/build-report.py', 'roles/build-containers/templates/tripleo-build.sh.j2', 'playbooks/tripleo-ci/post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a70bdcd462992a9b9cd166a459aa0f78316389c1', 'message': 'Enable html report for content provider jobs\n\nWire-up build-report post playbook on content provider jobs,\nand use podman to check built images (buildah was inconsitent).\n\nThis change also advertises zuul artifacts using zuul_return and\nchange the build work dir to ansible user home.\n\nChange-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a\n'}]",1,767591,a70bdcd462992a9b9cd166a459aa0f78316389c1,62,9,15,8175,,,0,"Enable html report for content provider jobs

Wire-up build-report post playbook on content provider jobs,
and use podman to check built images (buildah was inconsitent).

This change also advertises zuul artifacts using zuul_return and
change the build work dir to ansible user home.

Change-Id: Ie7c26c28e38035783ec1c5f87b3b6bdd6381376a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/91/767591/5 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/layout.yaml', 'playbooks/tripleo-ci/post.yaml']",2,f18225b6ba69423eaeb95009605b152e56dac1fc,build-report, - name: Build report include: build-report.yaml when: - job.provider_job | default(false) | bool - not use_kolla | default(false) | bool ,,7,17
openstack%2Fpuppet-horizon~stable%2Fvictoria~I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,openstack/puppet-horizon,stable/victoria,I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,add support for SECURE_PROXY_ADDR_HEADER,MERGED,2020-12-28 16:14:27.000000000,2021-01-05 18:06:24.000000000,2021-01-05 18:05:00.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-28 16:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/ffc17805d3a84c8328666a406912155a667bbd3c', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit b7fc17668755b808ccbf5a918bf9f94c78b3473d)\n'}, {'number': 2, 'created': '2020-12-29 20:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/cfea393994fa3f028341af2f33d11a913576a95e', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 319324e188ffee6b60407bfccc22e10b0549fe3d)\n'}, {'number': 3, 'created': '2020-12-30 02:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/0ad9ea9fe4519d44c910b24cc7ea306020b14db8', 'message': 'add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 4, 'created': '2020-12-30 02:47:35.000000000', 'files': ['templates/local_settings.py.erb', 'releasenotes/notes/add-secure-proxy-addr-header-07c36d89f8bf2ad2.yaml', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/2c88b2708208c76f3a35204628d06e8bf8690133', 'message': 'add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 7f6de8aa686382f7b5becd17f2e11c00c07fb493)\n'}]",0,768610,2c88b2708208c76f3a35204628d06e8bf8690133,17,3,4,32881,,,0,"add support for SECURE_PROXY_ADDR_HEADER

Change-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd
(cherry picked from commit 7f6de8aa686382f7b5becd17f2e11c00c07fb493)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/10/768610/3 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,ffc17805d3a84c8328666a406912155a667bbd3c,add-support-for-SECURE-PROXY-ADDR-HEADER," :secure_proxy_addr_header => 'HTTP_X_FORWARDED_FOR', ""SECURE_PROXY_ADDR_HEADER = 'HTTP_X_FORWARDED_FOR'"",",,17,0
openstack%2Fpuppet-horizon~stable%2Ftrain~I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,openstack/puppet-horizon,stable/train,I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,add support for SECURE_PROXY_ADDR_HEADER,MERGED,2020-12-28 16:11:05.000000000,2021-01-05 18:06:22.000000000,2021-01-05 18:05:05.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-28 16:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/039f027f9ac54f9f634a60fb002596b92e5519ed', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit b7fc17668755b808ccbf5a918bf9f94c78b3473d)\n'}, {'number': 2, 'created': '2020-12-29 20:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/b52d7a4d9a5fa84720e5a1eb83f1596b2ee5c793', 'message': 'Add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 319324e188ffee6b60407bfccc22e10b0549fe3d)\n'}, {'number': 3, 'created': '2020-12-29 20:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/d0d06d25040033786f2e8a24050d2de686f46f7a', 'message': 'add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 319324e188ffee6b60407bfccc22e10b0549fe3d)\n'}, {'number': 4, 'created': '2020-12-30 02:51:13.000000000', 'files': ['templates/local_settings.py.erb', 'releasenotes/notes/add-secure-proxy-addr-header-07c36d89f8bf2ad2.yaml', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/cc8289ae952e881ff90d8d9e79a2fec98a9669a7', 'message': 'add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 7f6de8aa686382f7b5becd17f2e11c00c07fb493)\n(cherry picked from commit ee49967ac840b3719f34f8600004c9eab9f1eef3)\n(cherry picked from commit 40310e86112dcfa664c9a2e4a2403b3575d15d6a)\n'}]",0,768608,cc8289ae952e881ff90d8d9e79a2fec98a9669a7,17,3,4,32881,,,0,"add support for SECURE_PROXY_ADDR_HEADER

Change-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd
(cherry picked from commit 7f6de8aa686382f7b5becd17f2e11c00c07fb493)
(cherry picked from commit ee49967ac840b3719f34f8600004c9eab9f1eef3)
(cherry picked from commit 40310e86112dcfa664c9a2e4a2403b3575d15d6a)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/08/768608/4 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,039f027f9ac54f9f634a60fb002596b92e5519ed,add-support-for-SECURE-PROXY-ADDR-HEADER," :secure_proxy_addr_header => 'HTTP_X_FORWARDED_FOR', ""SECURE_PROXY_ADDR_HEADER = 'HTTP_X_FORWARDED_FOR'"",",,17,0
openstack%2Fpuppet-horizon~stable%2Fussuri~I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,openstack/puppet-horizon,stable/ussuri,I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,add support for SECURE_PROXY_ADDR_HEADER,MERGED,2020-12-28 16:13:12.000000000,2021-01-05 18:06:19.000000000,2021-01-05 18:05:03.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-28 16:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/234b96a02c6e89b98da717c208cc2988785a1ab9', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit b7fc17668755b808ccbf5a918bf9f94c78b3473d)\n'}, {'number': 2, 'created': '2020-12-29 20:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/3928ddd916deb192fc6607515e532c914873332a', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 319324e188ffee6b60407bfccc22e10b0549fe3d)\n'}, {'number': 3, 'created': '2020-12-30 02:48:34.000000000', 'files': ['templates/local_settings.py.erb', 'releasenotes/notes/add-secure-proxy-addr-header-07c36d89f8bf2ad2.yaml', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/894db5e21872e6ebde88bda22718663ba2a3926e', 'message': 'add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n(cherry picked from commit 7f6de8aa686382f7b5becd17f2e11c00c07fb493)\n(cherry picked from commit ee49967ac840b3719f34f8600004c9eab9f1eef3)\n'}]",1,768609,894db5e21872e6ebde88bda22718663ba2a3926e,17,3,3,32881,,,0,"add support for SECURE_PROXY_ADDR_HEADER

Change-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd
(cherry picked from commit 7f6de8aa686382f7b5becd17f2e11c00c07fb493)
(cherry picked from commit ee49967ac840b3719f34f8600004c9eab9f1eef3)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/09/768609/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,234b96a02c6e89b98da717c208cc2988785a1ab9,add-support-for-SECURE-PROXY-ADDR-HEADER," :secure_proxy_addr_header => 'HTTP_X_FORWARDED_FOR', ""SECURE_PROXY_ADDR_HEADER = 'HTTP_X_FORWARDED_FOR'"",",,17,0
openstack%2Fpaunch~stable%2Ftrain~I9570b5e4e68b8e1d4181bd5c514193d648a9128f,openstack/paunch,stable/train,I9570b5e4e68b8e1d4181bd5c514193d648a9128f,Fix option to not cleanup containers not in config,MERGED,2020-11-18 09:48:04.000000000,2021-01-05 18:04:15.000000000,2021-01-05 18:02:51.000000000,"[{'_account_id': 6926}, {'_account_id': 8833}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 28182}]","[{'number': 1, 'created': '2020-11-18 09:48:04.000000000', 'files': ['paunch/cmd.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/73ce22c5277ca94865cae2bc227b44138d0d754c', 'message': ""Fix option to not cleanup containers not in config\n\nIn https://review.opendev.org/#/c/707278/ we added an option to\nnot cleanup containers not in config, but it's broken. We should\nuse --no-cleanup with action='strore_false' and default=True.\n\nChange-Id: I9570b5e4e68b8e1d4181bd5c514193d648a9128f\n(cherry picked from commit 5dcc4df5922e3fed766dd733627f008af456ca7a)\n""}]",3,763145,73ce22c5277ca94865cae2bc227b44138d0d754c,50,8,1,8833,,,0,"Fix option to not cleanup containers not in config

In https://review.opendev.org/#/c/707278/ we added an option to
not cleanup containers not in config, but it's broken. We should
use --no-cleanup with action='strore_false' and default=True.

Change-Id: I9570b5e4e68b8e1d4181bd5c514193d648a9128f
(cherry picked from commit 5dcc4df5922e3fed766dd733627f008af456ca7a)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/45/763145/1 && git format-patch -1 --stdout FETCH_HEAD,['paunch/cmd.py'],1,73ce22c5277ca94865cae2bc227b44138d0d754c,," '--no-cleanup', action='store_false',"," '--cleanup', action='store_true',",2,2
openstack%2Fpuppet-glance~stable%2Fvictoria~I4ac04a561746c227b245d11890d02c14a21965d0,openstack/puppet-glance,stable/victoria,I4ac04a561746c227b245d11890d02c14a21965d0,Use glance-swift.conf by default,MERGED,2020-12-28 10:55:57.000000000,2021-01-05 18:00:41.000000000,2021-01-05 17:59:10.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-28 10:55:57.000000000', 'files': ['spec/defines/glance_backend_multistore_swift_spec.rb', 'manifests/backend/multistore/swift.pp', 'releasenotes/notes/change-default-of-swift_store_config_file-e59ff9753f3612a7.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/ddb7d4e48ea5fba85b4ae04274d91f7273d4383e', 'message': 'Use glance-swift.conf by default\n\nThis patch changes default of the swift_store_config_file parameter,\nso that the configuration file generated by puppet-glance is used by\ndefault, instead of requiring users to set the parameter explicitly.\n\nCloses-Bug: #1908917\nChange-Id: I4ac04a561746c227b245d11890d02c14a21965d0\n(cherry picked from commit 26e26d115d04f6208f316932f18a9b57bde4867d)\n'}]",0,768413,ddb7d4e48ea5fba85b4ae04274d91f7273d4383e,8,3,1,9816,,,0,"Use glance-swift.conf by default

This patch changes default of the swift_store_config_file parameter,
so that the configuration file generated by puppet-glance is used by
default, instead of requiring users to set the parameter explicitly.

Closes-Bug: #1908917
Change-Id: I4ac04a561746c227b245d11890d02c14a21965d0
(cherry picked from commit 26e26d115d04f6208f316932f18a9b57bde4867d)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/13/768413/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/glance_backend_multistore_swift_spec.rb', 'manifests/backend/multistore/swift.pp', 'releasenotes/notes/change-default-of-swift_store_config_file-e59ff9753f3612a7.yaml']",3,ddb7d4e48ea5fba85b4ae04274d91f7273d4383e,bug/1908917-stable/victoria,--- fixes: - | The ``swift::backend::multistore::swift::swift_store_config_file`` is now set to ``/etc/glance/glance-swift.conf`` by default. Because of this change the parameter is automatically set to use the configuration file generated by puppet-glance. ,,12,5
openstack%2Fpuppet-horizon~master~I6912b5d2d8be558f52a1ffd30f2ef82bbed0deb6,openstack/puppet-horizon,master,I6912b5d2d8be558f52a1ffd30f2ef82bbed0deb6,Clean up the removed settings from OPENSTACK_NEUTRON_NETWORK,MERGED,2021-01-02 05:53:28.000000000,2021-01-05 17:56:38.000000000,2021-01-05 17:56:38.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-02 05:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/bc89fefaf4450ad66555183bd94e6ead3cf3d932', 'message': 'Clean up the removed settings from OPENSTACK_NEUTRON_NETWORK\n\nThe following settings of OPENSTACK_NEUTRON_NETWORK were already\nremoved[1], so should be removed from local_settings.\n - enable_firewall\n - enable_lb\n - enable_vpn\n\n[1] 53a5164d82a7412d10cee634cd0755336f566e24\n\nChange-Id: I6912b5d2d8be558f52a1ffd30f2ef82bbed0deb6\n'}, {'number': 2, 'created': '2021-01-02 07:27:16.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/f0dd10e51c7374f38a4b6d1ffcb8262c8b8f5210', 'message': 'Clean up the removed settings from OPENSTACK_NEUTRON_NETWORK\n\nThe following settings of OPENSTACK_NEUTRON_NETWORK were already\nremoved[1], so should be removed from local_settings.\n - enable_firewall\n - enable_lb\n - enable_vpn\n\n[1] 53a5164d82a7412d10cee634cd0755336f566e24\n\nChange-Id: I6912b5d2d8be558f52a1ffd30f2ef82bbed0deb6\n'}]",0,768854,f0dd10e51c7374f38a4b6d1ffcb8262c8b8f5210,10,3,2,9816,,,0,"Clean up the removed settings from OPENSTACK_NEUTRON_NETWORK

The following settings of OPENSTACK_NEUTRON_NETWORK were already
removed[1], so should be removed from local_settings.
 - enable_firewall
 - enable_lb
 - enable_vpn

[1] 53a5164d82a7412d10cee634cd0755336f566e24

Change-Id: I6912b5d2d8be558f52a1ffd30f2ef82bbed0deb6
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/54/768854/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,bc89fefaf4450ad66555183bd94e6ead3cf3d932,neutron-deprecated-services," :neutron_options => {'enable_quotas' => false, 'enable_security_group' => false,"," "" 'enable_firewall': False,"", "" 'enable_lb': False,"", "" 'enable_vpn': False,"", :neutron_options => {'enable_lb' => true, 'enable_firewall' => true, 'enable_quotas' => false, 'enable_security_group' => false, 'enable_vpn' => true,",1,14
openstack%2Fpuppet-ceilometer~master~I3e8924c95655e12494382130b8edeb0f47e0fb95,openstack/puppet-ceilometer,master,I3e8924c95655e12494382130b8edeb0f47e0fb95,Rename the redundant worker parameter,MERGED,2020-12-30 12:21:37.000000000,2021-01-05 17:56:27.000000000,2021-01-05 17:54:51.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-30 12:21:37.000000000', 'files': ['manifests/agent/notification.pp', 'spec/classes/ceilometer_agent_notification_spec.rb', 'releasenotes/notes/notification-workers-6a09b1f65a37ab4b.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/15921006c595ff705be40c02d324a387c92a4339', 'message': 'Rename the redundant worker parameter\n\nChange-Id: I3e8924c95655e12494382130b8edeb0f47e0fb95\n'}]",0,768778,15921006c595ff705be40c02d324a387c92a4339,8,3,1,9816,,,0,"Rename the redundant worker parameter

Change-Id: I3e8924c95655e12494382130b8edeb0f47e0fb95
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/78/768778/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agent/notification.pp', 'spec/classes/ceilometer_agent_notification_spec.rb', 'releasenotes/notes/notification-workers-6a09b1f65a37ab4b.yaml']",3,15921006c595ff705be40c02d324a387c92a4339,notification-workers,--- deprecations: - | The ``ceilometer::notification::notification_workers`` parameter has been deprecated and will be removed in a future release. Use the ``workers`` option instead. ,,32,3
openstack%2Fsenlin~master~I0c00d197d5eaa95b2c9102daa8470ac02fbbf15c,openstack/senlin,master,I0c00d197d5eaa95b2c9102daa8470ac02fbbf15c,Add name instead of id of node when add to load balancer,MERGED,2020-06-09 19:15:28.000000000,2021-01-05 17:44:28.000000000,2021-01-05 17:43:09.000000000,"[{'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22998}, {'_account_id': 27224}, {'_account_id': 28691}, {'_account_id': 28752}]","[{'number': 1, 'created': '2020-06-09 19:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/206bcb622ac26ae0b0687f44c0f1779ccb278963', 'message': 'Add name instead of id of node when add to load balancer\n\nWhen we use load balancer policy to attach cluster, members will\nadd to pool by member id. So this patch will improve it by using\nname of node instead of id member (member of pool)\n\nI hope this will make more transparency\n\nChange-Id: I0c00d197d5eaa95b2c9102daa8470ac02fbbf15c\n'}, {'number': 2, 'created': '2020-08-04 01:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/8519a798f615876126122eb8a97326564c1fbfca', 'message': 'Add name instead of id of node when add to load balancer\n\nWhen we use load balancer policy to attach cluster, members will\nadd to pool by member id. So this patch will improve it by using\nname of node instead of id member (member of pool)\n\nI hope this will make more transparency\n\nChange-Id: I0c00d197d5eaa95b2c9102daa8470ac02fbbf15c\n'}, {'number': 3, 'created': '2021-01-05 01:33:33.000000000', 'files': ['senlin/drivers/os/lbaas.py', 'senlin/drivers/os/octavia_v2.py', 'senlin/tests/unit/drivers/test_octavia_v2.py', 'senlin/tests/unit/drivers/test_lbaas.py', 'senlin/tests/drivers/os_test/octavia_v2.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/8be0717e95b6b3dd04d0f698046b4bf380571868', 'message': 'Add name instead of id of node when add to load balancer\n\nWhen we use load balancer policy to attach cluster, members will\nadd to pool by member id. So this patch will improve it by using\nname of node instead of id member (member of pool)\n\nI hope this will make more transparency\n\nChange-Id: I0c00d197d5eaa95b2c9102daa8470ac02fbbf15c\n'}]",0,734678,8be0717e95b6b3dd04d0f698046b4bf380571868,34,7,3,28691,,,0,"Add name instead of id of node when add to load balancer

When we use load balancer policy to attach cluster, members will
add to pool by member id. So this patch will improve it by using
name of node instead of id member (member of pool)

I hope this will make more transparency

Change-Id: I0c00d197d5eaa95b2c9102daa8470ac02fbbf15c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/78/734678/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/drivers/os/lbaas.py', 'senlin/drivers/os/octavia_v2.py', 'senlin/tests/unit/drivers/test_octavia_v2.py', 'senlin/tests/unit/drivers/test_lbaas.py', 'senlin/tests/drivers/os_test/octavia_v2.py']",5,206bcb622ac26ae0b0687f44c0f1779ccb278963,add_name_instead_id," def pool_member_create(self, name, pool_id, address, protocol_port, subnet_id, weight=None, admin_state_up=True): self.fake_member[""name""] = name"," def pool_member_create(self, pool_id, address, protocol_port, subnet_id, weight=None, admin_state_up=True):",16,11
openstack%2Fkolla-ansible~stable%2Fussuri~I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,openstack/kolla-ansible,stable/ussuri,I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,Fix failure during Monasca Grafana upgrade,MERGED,2021-01-05 12:10:30.000000000,2021-01-05 17:40:46.000000000,2021-01-05 17:39:34.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 12:10:30.000000000', 'files': ['ansible/roles/monasca/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/82c5781d8c2d1ad29bebd70b0e120890ce9f3e84', 'message': 'Fix failure during Monasca Grafana upgrade\n\nThe task ""Stopping all Monasca Grafana instances but the first node""\ncan fail with:\n\n    error while evaluating conditional (monasca_grafana_differs[\'result\']): \'dict object\' has no attribute \'result\'\n\nThis is fixed by running this task on the same set of hosts than the\ntask defining monasca_grafana_differs, i.e. groups[\'monasca-grafana\'].\n\nChange-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017\nCloses-Bug: #1907689\n(cherry picked from commit 39e75c308750ab4f259201b13a048f3fe0d3cc67)\n'}]",0,769332,82c5781d8c2d1ad29bebd70b0e120890ce9f3e84,13,3,1,15197,,,0,"Fix failure during Monasca Grafana upgrade

The task ""Stopping all Monasca Grafana instances but the first node""
can fail with:

    error while evaluating conditional (monasca_grafana_differs['result']): 'dict object' has no attribute 'result'

This is fixed by running this task on the same set of hosts than the
task defining monasca_grafana_differs, i.e. groups['monasca-grafana'].

Change-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017
Closes-Bug: #1907689
(cherry picked from commit 39e75c308750ab4f259201b13a048f3fe0d3cc67)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/32/769332/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/monasca/tasks/upgrade.yml'],1,82c5781d8c2d1ad29bebd70b0e120890ce9f3e84,bug/1907689-stable/ussuri, - inventory_hostname in groups['monasca-grafana'],,1,0
openstack%2Ftripleo-repos~master~Ib65ba8db9bd4c3f11254bbacd3bd45949b13e3f2,openstack/tripleo-repos,master,Ib65ba8db9bd4c3f11254bbacd3bd45949b13e3f2,Update TOX_CONSTRAINTS_FILE,MERGED,2020-12-18 09:24:54.000000000,2021-01-05 17:33:20.000000000,2021-01-05 17:33:20.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 09:24:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/8b91dc99861bedbc4584cf7c53ac4894f453a6f2', 'message': 'Update TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: Ib65ba8db9bd4c3f11254bbacd3bd45949b13e3f2\n'}]",0,767682,8b91dc99861bedbc4584cf7c53ac4894f453a6f2,6,2,1,32291,,,0,"Update TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: Ib65ba8db9bd4c3f11254bbacd3bd45949b13e3f2
",git fetch https://review.opendev.org/openstack/tripleo-repos refs/changes/82/767682/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8b91dc99861bedbc4584cf7c53ac4894f453a6f2,, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},1,1
openstack%2Ftripleo-repos~master~I3aea23597063d686021eff8304502429401070dd,openstack/tripleo-repos,master,I3aea23597063d686021eff8304502429401070dd,Add doc/requirements,MERGED,2021-01-05 10:03:20.000000000,2021-01-05 17:32:39.000000000,2021-01-05 17:32:39.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 10:03:20.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/a1bcd1c231c8c63077a9c048b3b3198bef380fb8', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I3aea23597063d686021eff8304502429401070dd\n""}]",0,769304,a1bcd1c231c8c63077a9c048b3b3198bef380fb8,8,3,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.
The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I3aea23597063d686021eff8304502429401070dd
",git fetch https://review.opendev.org/openstack/tripleo-repos refs/changes/04/769304/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,a1bcd1c231c8c63077a9c048b3b3198bef380fb8,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,5,3
openstack%2Fkolla-ansible~stable%2Fussuri~I38a4ecab071306143952c8036830318c476797f2,openstack/kolla-ansible,stable/ussuri,I38a4ecab071306143952c8036830318c476797f2,Fixes solum_api Listening on 127.0.0.1,MERGED,2021-01-05 13:34:30.000000000,2021-01-05 17:23:53.000000000,2021-01-05 17:22:14.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28295}]","[{'number': 1, 'created': '2021-01-05 13:34:30.000000000', 'files': ['ansible/roles/solum/templates/solum.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ae2c9f9da7e7b01235c161f36ae79c2f7a9d88fb', 'message': ""Fixes solum_api Listening on 127.0.0.1\n\nThe default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in\n[api] section of the solum.conf\nThis causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to\nprovide services.\n\nThis fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,\nmaking it available to services like haproxy accessing the service remotely\n\nCloses-Bug: 1909986\nChange-Id: I38a4ecab071306143952c8036830318c476797f2\n(cherry picked from commit e9f4a5a38e405a097c51dac58708947e7767eff9)\n""}]",0,769192,ae2c9f9da7e7b01235c161f36ae79c2f7a9d88fb,10,4,1,14826,,,0,"Fixes solum_api Listening on 127.0.0.1

The default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in
[api] section of the solum.conf
This causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to
provide services.

This fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,
making it available to services like haproxy accessing the service remotely

Closes-Bug: 1909986
Change-Id: I38a4ecab071306143952c8036830318c476797f2
(cherry picked from commit e9f4a5a38e405a097c51dac58708947e7767eff9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/92/769192/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/solum/templates/solum.conf.j2'],1,ae2c9f9da7e7b01235c161f36ae79c2f7a9d88fb,solum-api-stable/ussuri,{% if service_name == 'solum-api' %} host = {{ api_interface_address }} {% endif %},,3,0
openstack%2Fkolla-ansible~stable%2Fvictoria~I38a4ecab071306143952c8036830318c476797f2,openstack/kolla-ansible,stable/victoria,I38a4ecab071306143952c8036830318c476797f2,Fixes solum_api Listening on 127.0.0.1,MERGED,2021-01-05 13:34:21.000000000,2021-01-05 17:23:32.000000000,2021-01-05 17:22:10.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28295}]","[{'number': 1, 'created': '2021-01-05 13:34:21.000000000', 'files': ['ansible/roles/solum/templates/solum.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ac6039bd693f7b3b2ce61dff3d3c24a69450a8a5', 'message': ""Fixes solum_api Listening on 127.0.0.1\n\nThe default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in\n[api] section of the solum.conf\nThis causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to\nprovide services.\n\nThis fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,\nmaking it available to services like haproxy accessing the service remotely\n\nCloses-Bug: 1909986\nChange-Id: I38a4ecab071306143952c8036830318c476797f2\n(cherry picked from commit e9f4a5a38e405a097c51dac58708947e7767eff9)\n""}]",0,769191,ac6039bd693f7b3b2ce61dff3d3c24a69450a8a5,10,4,1,14826,,,0,"Fixes solum_api Listening on 127.0.0.1

The default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in
[api] section of the solum.conf
This causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to
provide services.

This fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,
making it available to services like haproxy accessing the service remotely

Closes-Bug: 1909986
Change-Id: I38a4ecab071306143952c8036830318c476797f2
(cherry picked from commit e9f4a5a38e405a097c51dac58708947e7767eff9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/91/769191/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/solum/templates/solum.conf.j2'],1,ac6039bd693f7b3b2ce61dff3d3c24a69450a8a5,solum-api-stable/victoria,{% if service_name == 'solum-api' %} host = {{ api_interface_address }} {% endif %},,3,0
openstack%2Fpuppet-manila~master~Idc0ef61695b89bbb39cb00706757aa4ccbb8e977,openstack/puppet-manila,master,Idc0ef61695b89bbb39cb00706757aa4ccbb8e977,Remove the deprecated parameters of manila::volume::cinder,MERGED,2021-01-03 05:30:39.000000000,2021-01-05 17:20:42.000000000,2021-01-05 17:19:20.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:30:39.000000000', 'files': ['manifests/volume/cinder.pp', 'spec/classes/manila_volume_cinder_spec.rb', 'releasenotes/notes/remove-deprecated-cinder-params-c5dfd5ece0c1079c.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/4a2d7e249ba758cee8efb8c108f5ec12b40bfadd', 'message': 'Remove the deprecated parameters of manila::volume::cinder\n\nThese parameter were deprecated during the previous cycle[1], so can be\nremoved now.\n\n[1] b5d5e5774c53b36819faf403b2df82590c6cc8bb\n\nChange-Id: Idc0ef61695b89bbb39cb00706757aa4ccbb8e977\n'}]",0,768956,4a2d7e249ba758cee8efb8c108f5ec12b40bfadd,8,3,1,9816,,,0,"Remove the deprecated parameters of manila::volume::cinder

These parameter were deprecated during the previous cycle[1], so can be
removed now.

[1] b5d5e5774c53b36819faf403b2df82590c6cc8bb

Change-Id: Idc0ef61695b89bbb39cb00706757aa4ccbb8e977
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/56/768956/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/volume/cinder.pp', 'spec/classes/manila_volume_cinder_spec.rb', 'releasenotes/notes/remove-deprecated-cinder-params-c5dfd5ece0c1079c.yaml']",3,4a2d7e249ba758cee8efb8c108f5ec12b40bfadd,cinder-params,--- upgrade: - | The following parameters of the ``manila::volume::cinder`` class have been removed. - ``cinder_catalog_info`` - ``cinder_ca_certificates_file`` - ``cinder_http_retries`` - ``cinder_cross_az_attach`` - ``cinder_admin_username`` - ``cinder_admin_password`` - ``cinder_admin_tenant_name`` - ``cinder_admin_auth_url`` ,,22,131
openstack%2Fcharm-neutron-api~master~I39b0c17a9ca04c254b08331ac10198680ce1fa28,openstack/charm-neutron-api,master,I39b0c17a9ca04c254b08331ac10198680ce1fa28,Remove database max_pool_size customisation,MERGED,2020-11-27 03:18:01.000000000,2021-01-05 17:02:22.000000000,2021-01-05 17:02:22.000000000,"[{'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 03:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/b9d70c4a01067f59353a05b82b4b2e3c54b661b5', 'message': 'Remove database max_pool_size customisation\n\nThe database pool is used per-worker and not shared among all of the workers.\nAs a result, there is no need to scale the database pool with the number of\nworkers and having done so results in excessively large numbers of MySQL\nconnections (e.g. 400-1500) per neutron-api node.\n\nCloses-Bug: #1905810\nChange-Id: I39b0c17a9ca04c254b08331ac10198680ce1fa28\n'}, {'number': 2, 'created': '2020-12-01 04:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/90287d950138b89a3e31504d876983ae2643ff7e', 'message': ""Remove database max_pool_size customisation\n\nThe database pool size is per-worker and not shared among the workers.\nCurrently we incorrectly scale max_pool_size with the worker count,\nresulting in an excessive number of database connections that are both\nunnecessary and can exhaust the MySQL server max_connections.\n\nWith the previous formula max_pool_size = workers * 4, the resulting\nconnection count was exponential e.g. with 10 workers you get 400\nconnections but with 20 workers you get 1600. With the commonly deployed\nsetting of worker-multiplier=0.25 you get 20 workers on 40C/80T machines\nand a 3 node HA setup was consuming 3 * 1600 = 4800 MySQL connections.\n\nThis customisation was added when rpc_workers support was added (commit\nb6ff05ddfe) and I cannot find any evidence that a higher pool count is\nneeded, the upstream neutron project also removed it's own customisation\nof 10 in deference to the oslo.db default of (LP: #1682307). So this\nchange appears safe and will result in only 100 connections for 20\nworkers instead of 1600.\n\nCloses-Bug: #1905810\nChange-Id: I39b0c17a9ca04c254b08331ac10198680ce1fa28\n""}, {'number': 3, 'created': '2020-12-17 18:50:11.000000000', 'files': ['templates/parts/section-database'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/074e577791e9313ad36bc313475ef6bcbf7adce6', 'message': ""Remove database max_pool_size customisation\n\nThe database pool size is per-worker and not shared among the workers.\nCurrently we incorrectly scale max_pool_size with the worker count,\nresulting in an excessive number of database connections that are both\nunnecessary and can exhaust the MySQL server max_connections.\n\nWith the previous formula max_pool_size = workers * 4, the resulting\nconnection count was exponential e.g. with 10 workers you get 400\nconnections but with 20 workers you get 1600. With the commonly deployed\nsetting of worker-multiplier=0.25 you get 20 workers on 40C/80T machines\nand a 3 node HA setup was consuming 3 * 1600 = 4800 MySQL connections.\n\nThis customisation was added when rpc_workers support was added (commit\nb6ff05ddfe) and I cannot find any evidence that a higher pool count is\nneeded, the upstream neutron project also removed it's own customisation\nof 10 in deference to the oslo.db default of (LP: #1682307). So this\nchange appears safe and will result in only 100 connections for 20\nworkers instead of 1600.\n\nCloses-Bug: #1905810\nChange-Id: I39b0c17a9ca04c254b08331ac10198680ce1fa28\n""}]",0,764402,074e577791e9313ad36bc313475ef6bcbf7adce6,25,5,3,21107,,,0,"Remove database max_pool_size customisation

The database pool size is per-worker and not shared among the workers.
Currently we incorrectly scale max_pool_size with the worker count,
resulting in an excessive number of database connections that are both
unnecessary and can exhaust the MySQL server max_connections.

With the previous formula max_pool_size = workers * 4, the resulting
connection count was exponential e.g. with 10 workers you get 400
connections but with 20 workers you get 1600. With the commonly deployed
setting of worker-multiplier=0.25 you get 20 workers on 40C/80T machines
and a 3 node HA setup was consuming 3 * 1600 = 4800 MySQL connections.

This customisation was added when rpc_workers support was added (commit
b6ff05ddfe) and I cannot find any evidence that a higher pool count is
needed, the upstream neutron project also removed it's own customisation
of 10 in deference to the oslo.db default of (LP: #1682307). So this
change appears safe and will result in only 100 connections for 20
workers instead of 1600.

Closes-Bug: #1905810
Change-Id: I39b0c17a9ca04c254b08331ac10198680ce1fa28
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/02/764402/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/parts/section-database'],1,b9d70c4a01067f59353a05b82b4b2e3c54b661b5,,,max_pool_size = {{ workers * 4 }},0,1
openstack%2Fneutron-tempest-plugin~master~Ia88848fd9c4ce35d396bc186ae3894a1d5865db9,openstack/neutron-tempest-plugin,master,Ia88848fd9c4ce35d396bc186ae3894a1d5865db9,Add doc/requirements,MERGED,2021-01-05 11:53:21.000000000,2021-01-05 16:53:25.000000000,2021-01-05 16:52:12.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-05 11:53:21.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/2903040070a72c3579a531272d1b344c19f8f178', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ia88848fd9c4ce35d396bc186ae3894a1d5865db9\n'}]",0,769330,2903040070a72c3579a531272d1b344c19f8f178,9,6,1,8313,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: Ia88848fd9c4ce35d396bc186ae3894a1d5865db9
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/30/769330/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,2903040070a72c3579a531272d1b344c19f8f178,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,7,4
openstack%2Ftripleo-upgrade~master~Ie11acbf29fc8b9025756b5516fe2d9b4326b5425,openstack/tripleo-upgrade,master,Ie11acbf29fc8b9025756b5516fe2d9b4326b5425,[ffwd] Don't run healthcheck on redis if it's not present,MERGED,2020-12-18 12:58:05.000000000,2021-01-05 16:47:07.000000000,2021-01-05 16:47:07.000000000,"[{'_account_id': 6816}, {'_account_id': 11090}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 12:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/5a66221f6fa870d3b43b5343c5515a0ea053221f', 'message': ""[ffwd] Don't run healthcheck on redis if it's not present\n\nRedis might not be present on the deployment so we shouldn't\ncheck it's status post upgrade.\n\nChange-Id: Ie11acbf29fc8b9025756b5516fe2d9b4326b5425\nResolves: UPG-2446\n""}, {'number': 2, 'created': '2020-12-22 10:14:29.000000000', 'files': ['tasks/upgrade/controller_node_upgrade.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/87c31a948b88d978b9b0c2dd252e73eee35eb8ae', 'message': ""[ffwd] Don't run healthcheck on redis if it's not present\n\nRedis might not be present on the deployment so we shouldn't\ncheck it's status post upgrade.\n\nChange-Id: Ie11acbf29fc8b9025756b5516fe2d9b4326b5425\nResolves: UPG-2446\n""}]",1,767712,87c31a948b88d978b9b0c2dd252e73eee35eb8ae,11,3,2,11166,,,0,"[ffwd] Don't run healthcheck on redis if it's not present

Redis might not be present on the deployment so we shouldn't
check it's status post upgrade.

Change-Id: Ie11acbf29fc8b9025756b5516fe2d9b4326b5425
Resolves: UPG-2446
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/12/767712/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/upgrade/controller_node_upgrade.yml'],1,5a66221f6fa870d3b43b5343c5515a0ea053221f,," - name: Running post upgrade scripts for {{ node_name | splitext | first }} shell: ""set -o pipefail && {{ working_dir }}/{{ node_name | splitext | first }}_post/{{ item }}.sh"" when: - item in inventory_hostmap loop:",,6,0
openstack%2Fpuppet-octavia~master~I45551178adc7dbea35ffe3acde0c31f3ec3c33c9,openstack/puppet-octavia,master,I45551178adc7dbea35ffe3acde0c31f3ec3c33c9,Deprecate parameters for the Spares Pool feature,MERGED,2020-12-29 03:45:30.000000000,2021-01-05 16:36:11.000000000,2021-01-05 16:34:35.000000000,"[{'_account_id': 6469}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-29 03:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/d409f74ea1c19f8d053f3223542b152d9cf1dc3f', 'message': 'Deprecate parameters for the Spares Pool feature\n\nThe Spares Pool feature of Octavia was deprecated in Octavia during V\ncycle and will be removed in X cycle[1].\n\n[1] 29a2ec7187ff5607a7fb3700a53c6524c4153396\n\nChange-Id: I45551178adc7dbea35ffe3acde0c31f3ec3c33c9\n'}, {'number': 2, 'created': '2020-12-29 03:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/d64138a0a8bb181dbbc625a0936940b6fccc2433', 'message': 'Deprecate parameters for the Spares Pool feature\n\nThe Spares Pool feature of Octavia was deprecated in Octavia during V\ncycle and will be removed in X cycle[1].\n\n[1] 29a2ec7187ff5607a7fb3700a53c6524c4153396\n\nChange-Id: I45551178adc7dbea35ffe3acde0c31f3ec3c33c9\n'}, {'number': 3, 'created': '2021-01-04 12:01:08.000000000', 'files': ['releasenotes/notes/deprecate-spares-pool-feature-a4f19adc1b454904.yaml', 'manifests/housekeeping.pp'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/46cffbd1e9229f587f3b6c703f4964aec4bab452', 'message': 'Deprecate parameters for the Spares Pool feature\n\nThe Spares Pool feature of Octavia was deprecated in Octavia during V\ncycle and will be removed in X cycle[1].\n\n[1] 29a2ec7187ff5607a7fb3700a53c6524c4153396\n\nChange-Id: I45551178adc7dbea35ffe3acde0c31f3ec3c33c9\n'}]",2,768662,46cffbd1e9229f587f3b6c703f4964aec4bab452,15,4,3,9816,,,0,"Deprecate parameters for the Spares Pool feature

The Spares Pool feature of Octavia was deprecated in Octavia during V
cycle and will be removed in X cycle[1].

[1] 29a2ec7187ff5607a7fb3700a53c6524c4153396

Change-Id: I45551178adc7dbea35ffe3acde0c31f3ec3c33c9
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/62/768662/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-spares-pool-feature-a4f19adc1b454904.yaml', 'manifests/housekeeping.pp']",2,d409f74ea1c19f8d053f3223542b152d9cf1dc3f,deprecate-spares,"# [*spare_check_interval*] # (optional) spare check interval in seconds. # Defaults to $::os_service_default # # [*spare_amphora_pool_size*] # (optional) Number of spare amphora. $spare_check_interval = undef, $spare_amphora_pool_size = undef, if $spare_check_interval != undef { warning('The spare_check_interval is deprecated and will be removed in a future release') octavia_config { 'house_keeping/spare_check_interval': value => $spare_check_interval; } } else { octavia_config { 'house_keeping/spare_check_interval': value => $::os_service_default; } } if $spare_amphora_pool_size != undef { warning('The spare_amphora_pool_size is deprecated and will be removed in a future release') octavia_config { 'house_keeping/spare_amphora_pool_size' : value => $spare_amphora_pool_size; } } else { octavia_config { 'house_keeping/spare_amphora_pool_size' : value => $::os_service_default; } }","# [*spare_check_interval*] # (optional) spare check interval in seconds. # Defaults to $::os_service_default # # [*spare_amphora_pool_size*] # (optional) Number of spare amphora. # Defaults to $::os_service_default ## [*spare_amphorae_pool_size*] # (optional) Number of spare amphorae. $spare_check_interval = $::os_service_default, $spare_amphora_pool_size = $::os_service_default, $spare_amphorae_pool_size = undef if $spare_amphorae_pool_size { warning('spare_amphorae_pool_size is deprecated and will be removed in the future. Please use spare_amphora_pool_size.') } $spare_amphora_pool_size_real = pick($spare_amphorae_pool_size, $spare_amphora_pool_size) 'house_keeping/spare_check_interval' : value => $spare_check_interval; 'house_keeping/spare_amphora_pool_size' : value => $spare_amphora_pool_size_real;",43,21
openstack%2Fcloudkitty-tempest-plugin~master~I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1,openstack/cloudkitty-tempest-plugin,master,I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1,Bump hacking max version to 3.0.1,MERGED,2020-12-29 23:07:56.000000000,2021-01-05 16:31:17.000000000,2021-01-05 16:31:17.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28356}, {'_account_id': 32304}]","[{'number': 1, 'created': '2020-12-29 23:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/fcf1b0f9bc849851818d7337a68eb7d27eb32c7d', 'message': 'Add flake8 dependency for pyflakes\n\npep8 job is failing because the current inherited version\nof flake8 (flake8<2.7.0,>=2.6.0) is not compatible with\npyflakes>=2.1.1. Therefore the patch is adding flake8 dep\nexplicitely.\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}, {'number': 2, 'created': '2020-12-29 23:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/0491c4a6bfcd41260db87de9ea1da7c534e3efc5', 'message': 'Add flake8 dependency for pyflakes\n\npep8 job is failing because the current inherited version\nof flake8 (flake8<2.7.0,>=2.6.0) is not compatible with\npyflakes>=2.1.1. Therefore the patch is adding flake8 dep\nexplicitely and lowering min pyflakes version to 2.0.0 as\nthe newest flake8 atm depends on exactly pyflakes==2.0.0\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}, {'number': 3, 'created': '2020-12-29 23:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/6ec65cd5e451c8b4e78483627466953d20a1011b', 'message': 'Add flake8 dependency for pyflakes\n\npep8 job is failing because the current inherited version\nof flake8 (flake8<2.7.0,>=2.6.0) is not compatible with\npyflakes>=2.1.1. Therefore the patch is adding flake8 dep\nexplicitely.\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}, {'number': 4, 'created': '2021-01-02 19:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/64b3bf85ab26d61735e4e54b0b740b3a80014d81', 'message': 'WIP: Add flake8 dependency for pyflakes\n\npep8 job is failing because the current inherited version\nof flake8 (flake8<2.7.0,>=2.6.0) is not compatible with\npyflakes>=2.1.1. Therefore the patch is adding flake8 dep\nexplicitely.\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}, {'number': 5, 'created': '2021-01-02 21:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/890d2ac91e31ee5225359ce95b7504cb8ba95a9b', 'message': 'WIP: Add flake8 dependency for pyflakes\n\npep8 job is failing because the current inherited version\nof flake8 (flake8<2.7.0,>=2.6.0) is not compatible with\npyflakes>=2.1.1. Therefore the patch is adding flake8 dep\nexplicitely.\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}, {'number': 6, 'created': '2021-01-03 02:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/14e2fc9e5052ac9551b42a91ce15e9e1f717cc27', 'message': 'WIP: Add flake8 dependency for pyflakes\n\npep8 job is failing because the current inherited version\nof flake8 (flake8<2.7.0,>=2.6.0) is not compatible with\npyflakes>=2.1.1. Therefore the patch is adding flake8 dep\nexplicitely.\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}, {'number': 7, 'created': '2021-01-03 11:06:10.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/05f144b90bd1525b0a6dab2de01e1019c3430c02', 'message': 'Bump hacking max version to 3.0.1\n\npep8 job is failing because the version of flake8\n(flake8<2.7.0,>=2.6.0) requested by hacking<1.2.0 is not\ncompatible with pyflakes>=2.1.1. Therefore the patch increases\nthe max version of hacking.\n\nChange-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1\n'}]",0,768763,05f144b90bd1525b0a6dab2de01e1019c3430c02,18,4,7,22873,,,0,"Bump hacking max version to 3.0.1

pep8 job is failing because the version of flake8
(flake8<2.7.0,>=2.6.0) requested by hacking<1.2.0 is not
compatible with pyflakes>=2.1.1. Therefore the patch increases
the max version of hacking.

Change-Id: I04635509cc8b794f9aaad8ac43a25bf6ddd9b9e1
",git fetch https://review.opendev.org/openstack/cloudkitty-tempest-plugin refs/changes/63/768763/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,fcf1b0f9bc849851818d7337a68eb7d27eb32c7d,,"pyflakes>=2.1.1 # MIT flake8!=2.7.0,!=3.0.0 # MIT",pyflakes>=2.1.1,2,1
openstack%2Fpuppet-nova~master~I3fe97b4d5c9c2bb3709e37c561af353b859495ef,openstack/puppet-nova,master,I3fe97b4d5c9c2bb3709e37c561af353b859495ef,Fix ignored unit tests,MERGED,2021-01-03 05:36:50.000000000,2021-01-05 16:29:50.000000000,2021-01-05 16:29:50.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d628779a06e947e531ae1d8d28e560869cd55b7d', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}, {'number': 2, 'created': '2021-01-03 05:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d008fa2fdc816bfa7b06a4644b697ba5297cf151', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}, {'number': 3, 'created': '2021-01-03 07:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/681c315a04ec094dc4164a1dad80b9b1fffae068', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}, {'number': 4, 'created': '2021-01-03 07:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c4fa8336b0493a4a0ef0ab52f89f19198e73f763', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}, {'number': 5, 'created': '2021-01-03 10:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/786b999474125696ef421a314def72c16c963647', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}, {'number': 6, 'created': '2021-01-03 10:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/08b7d6237730d1270eeb8231d623483db7f53501', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}, {'number': 7, 'created': '2021-01-03 21:45:06.000000000', 'files': ['spec/classes/nova_cell_v2_map_instances_spec.rb', 'spec/classes/nova_cron_purge_shadow_tables_spec.rb', 'spec/unit/type/nova_cell_v2_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5b135ed130906546980c603b90b3648b80479ff7', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef\n'}]",0,768959,5b135ed130906546980c603b90b3648b80479ff7,20,3,7,9816,,,0,"Fix ignored unit tests

Unit test files should be named like *_spec.rb.

Change-Id: I3fe97b4d5c9c2bb3709e37c561af353b859495ef
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/59/768959/7 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_cell_v2_map_instances_spec.rb', 'spec/classes/nova_cron_purge_shadow_tables_spec.rb']",2,d628779a06e947e531ae1d8d28e560869cd55b7d,ignored-ut,,,0,0
openstack%2Fkolla-ansible~stable%2Ftrain~I38a4ecab071306143952c8036830318c476797f2,openstack/kolla-ansible,stable/train,I38a4ecab071306143952c8036830318c476797f2,Fixes solum_api Listening on 127.0.0.1,MERGED,2021-01-05 13:34:36.000000000,2021-01-05 16:29:26.000000000,2021-01-05 16:27:55.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28295}]","[{'number': 1, 'created': '2021-01-05 13:34:36.000000000', 'files': ['ansible/roles/solum/templates/solum.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/81b8db9c8b9cb26ac748e3c49a71bc2d88a587a8', 'message': ""Fixes solum_api Listening on 127.0.0.1\n\nThe default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in\n[api] section of the solum.conf\nThis causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to\nprovide services.\n\nThis fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,\nmaking it available to services like haproxy accessing the service remotely\n\nCloses-Bug: 1909986\nChange-Id: I38a4ecab071306143952c8036830318c476797f2\n(cherry picked from commit e9f4a5a38e405a097c51dac58708947e7767eff9)\n""}]",0,769193,81b8db9c8b9cb26ac748e3c49a71bc2d88a587a8,9,4,1,14826,,,0,"Fixes solum_api Listening on 127.0.0.1

The default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in
[api] section of the solum.conf
This causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to
provide services.

This fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,
making it available to services like haproxy accessing the service remotely

Closes-Bug: 1909986
Change-Id: I38a4ecab071306143952c8036830318c476797f2
(cherry picked from commit e9f4a5a38e405a097c51dac58708947e7767eff9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/93/769193/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/solum/templates/solum.conf.j2'],1,81b8db9c8b9cb26ac748e3c49a71bc2d88a587a8,solum-api-stable/train,{% if service_name == 'solum-api' %} host = {{ api_interface_address }} {% endif %},,3,0
openstack%2Fpuppet-keystone~master~I760580a32047900c0f9e5b662e700afef3afc0d5,openstack/puppet-keystone,master,I760580a32047900c0f9e5b662e700afef3afc0d5,Refactor unit tests for the keystone class,MERGED,2020-10-28 15:37:04.000000000,2021-01-05 16:23:22.000000000,2021-01-05 16:23:22.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-28 15:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c65ed53ca7417ef6dd96f3af6c56bcfc74a528af', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 2, 'created': '2020-10-28 15:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/6dac60e47dfe78b0fa4ec96b6b14cf657fc6ca28', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 3, 'created': '2020-10-28 15:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7fa86888043691777eaae4b59e4070198456d007', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 4, 'created': '2020-10-28 16:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/71a897e7b7f03677e5af7521ba0bb55386175a8c', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 5, 'created': '2020-10-28 16:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/acdc2fda09bb97b2d63017b9a404af754374e4ef', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 6, 'created': '2020-10-28 23:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/0bd31231f8d3d02667b6a3aa3c917cb6c36bf802', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 7, 'created': '2020-10-29 00:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/2946c70d75f3fa33aef09280a951bf76a013b566', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 8, 'created': '2020-10-29 01:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ae53f0527cd14cc5d1c52c9d7a29dabc753f2be7', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 9, 'created': '2020-10-29 02:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/73e966c377c9507f81615a1d95876edca94e364b', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}, {'number': 10, 'created': '2020-12-30 03:05:52.000000000', 'files': ['spec/classes/keystone_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cd4fe36190031c22e5ce468842b85bd1f921b3c8', 'message': 'Refactor unit tests for the keystone class\n\nChange-Id: I760580a32047900c0f9e5b662e700afef3afc0d5\n'}]",0,760167,cd4fe36190031c22e5ce468842b85bd1f921b3c8,23,3,10,9816,,,0,"Refactor unit tests for the keystone class

Change-Id: I760580a32047900c0f9e5b662e700afef3afc0d5
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/67/760167/10 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/keystone_init_spec.rb'],1,c65ed53ca7417ef6dd96f3af6c56bcfc74a528af,ut-refactor," share_examples 'keystone' do context 'with default parameters' do it { is_expected.to contain_class('keystone::logging') } it { is_expected.to contain_class('keystone::params') } it { is_expected.to contain_class('keystone::policy') } it { is_expected.to contain_package('keystone').with( 'ensure' => 'present', 'tag' => ['openstack', 'keystone-package'], ) } it { is_expected.to contain_class('keystone::client').with( 'ensure' => 'present' ) } it 'should synchronize the db if $sync_db is true' do it 'passes purge to resource' do it is_expected.to contain_keystone_config.with({ :purge => false }) it { is_expected.to contain_class('keystone::db') } it 'should set the default values' do is_expected.to contain_keystone_config('DEFAULT/member_role_id').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('DEFAULT/member_role_name').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('token/expiration').with_value(3600) is_expected.to contain_keystone_config('identity/password_hash_algorithm').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('identity/password_hash_rounds').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('revoke/driver').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('policy/driver').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('ssl/enable').with_value(false) is_expected.to contain_keystone_config('token/revoke_by_id').with_value('<SERVICE DEFAULT>') is_expected.to contain_oslo__middleware('keystone_config').with( :enable_proxy_headers_parsing => '<SERVICE DEFAULT>', :max_request_body_size => '<SERVICE DEFAULT>', ) is_expected.to contain_keystone_config('catalog/driver').with_value('sql') is_expected.to contain_keystone_config('catalog/template_file').with_value('/etc/keystone/default_catalog.templates') is_expected.to contain_keystone_config('token/provider').with_value('fernet') is_expected.to contain_keystone_config('DEFAULT/max_token_size').with_value('<SERVICE DEFAULT>') is_expected.to contain_keystone_config('DEFAULT/notification_format').with_value('<SERVICE DEFAULT>') is_expected.to contain_oslo__messaging__default('keystone_config').with( :trnasport_url => '<SERVICE DEFAULT>', :control_exchange => '<SERVICE DEFAULT>', :rpc_response_timeout => '<SERVICE DEFAULT>', ) is_expected.to contain_oslo__messaging__notification('keystone_config').with( :transport_url => '<SERVICE DEFAULT>', :driver => '<SERVICE DEFAULT>', :topics => '<SERVICE DEFAULT>', ) is_expected.to contain_oslo__messaging__rabbit('keystone_config').with( :kombu_ssl_version => '<SERVICE DEFAULT>', :kombu_ssl_keyfile => '<SERVICE DEFAULT>', :kombu_ssl_certfile => '<SERVICE DEFAULT>', :kombu_ssl_ca_certs => '<SERVICE DEFAULT>', :kombu_reconnect_delay => '<SERVICE DEFAULT>', :kombu_failover_strategy => '<SERVICE DEFAULT>', :kombu_compression => '<SERVICE DEFAULT>', :rabbit_use_ssl => '<SERVICE DEFAULT>', :rabbit_ha_queues => '<SERVICE DEFAULT>', :heartbeat_timeout_threshold => '<SERVICE DEFAULT>', :heartbeat_rate => '<SERVICE DEFAULT>', :heartbeat_in_pthread => '<SERVICE DEFAULT>', :amqp_durable_queues => '<SERVICE DEFAULT>', ) 'ensure' => 'running', it { is_expected.to contain_exec('keystone-manage db_sync') } it { is_expected.to_not contain_file('/etc/keystone/domains') } context 'with overridden parameters' do :member_role_id => 'someid', :member_role_name => 'member', :public_endpoint => 'http://127.0.0.1:5000', :token_expiration => 7200, :password_hash_algorithm => 'bcrypt', :password_hash_rounds => 12, :revoke_driver => 'sql', :policy_driver => 'sql', :revoke_by_id => true, :enable_proxy_headers_parsing => true, :max_request_body_size => 114688, :catalog_type => 'template', :catalog_template_file => '/some/template_file' :token_provider => 'uuid', :max_token_size => 255, :notification_format => 'basic', it 'should set the default values' do is_expected.to contain_keystone_config('DEFAULT/member_role_id').with_value('someid') is_expected.to contain_keystone_config('DEFAULT/member_role_name').with_value('member') is_expected.to contain_keystone_config('DEFAULT/public_endpoint').with_value('http://127.0.0.1:5000') is_expected.to contain_keystone_config('token/expiration').with_value(7200) is_expected.to contain_keystone_config('identity/password_hash_algorithm').with_value('bcrypt') is_expected.to contain_keystone_config('identity/password_hash_rounds').with_value(12) is_expected.to contain_keystone_config('revoke/driver').with_value('sql') is_expected.to contain_keystone_config('policy/driver').with_value('sql') is_expected.to contain_keystone_config('token/revoke_by_id').with_value(true) is_expected.to contain_oslo__middleware('keystone_config').with( :enable_proxy_headers_parsing => true, :max_request_body_size => 114688, ) is_expected.to contain_keystone_config('catalog/driver').with_value('templated') is_expected.to contain_keystone_config('catalog/template_file').with_value('/some/template_file') is_expected.to contain_keystone_config('token/provider').with_value('fernet') is_expected.to contain_keystone_config('DEFAULT/max_token_size').with_value(255) is_expected.to contain_keystone_config('DEFAULT/notification_format').with_value('basic') end context ""when running keystone in wsgi"" do let :params do { 'service_name' => 'httpd' } end let :pre_condition do 'include apache include keystone::wsgi::apache' end it do expect { is_expected.to contain_service(platform_parameters[:service_name]).with('ensure' => 'running') }.to raise_error(RSpec::Expectations::ExpectationNotMetError, /expected that the catalogue would contain Service\[#{platform_parameters[:service_name]}\]/) end it { is_expected.to contain_exec('restart_keystone').with( 'command' => ""service #{platform_parameters[:httpd_service_name]} restart"", ) } end context 'when using invalid service name for keystone' do let (:params) do { 'service_name' => 'foo' } end it_raises 'a Puppet::Error', /Invalid service_name/ end context 'with disabled service managing' do let :params do { :manage_service => false, :enabled => false } end it { is_expected.to contain_service('keystone').with( 'ensure' => nil, 'enable' => false, 'hasstatus' => true, 'hasrestart' => true ) } it { is_expected.to contain_anchor('keystone::service::end') } end context 'with invalid catalog_type' do context 'when sync_db is set to false' do { 'sync_db' => false, } it { is_expected.not_to contain_exec('keystone-manage db_sync') } context 'when enabling SSL' do { 'enable_ssl' => true, } end it {is_expected.to contain_keystone_config('ssl/enable').with_value(true)} it {is_expected.to contain_keystone_config('ssl/certfile').with_value('/etc/keystone/ssl/certs/keystone.pem')} it {is_expected.to contain_keystone_config('ssl/keyfile').with_value('/etc/keystone/ssl/private/keystonekey.pem')} it {is_expected.to contain_keystone_config('ssl/ca_certs').with_value('/etc/keystone/ssl/certs/ca.pem')} it {is_expected.to contain_keystone_config('ssl/ca_key').with_value('/etc/keystone/ssl/private/cakey.pem')} it {is_expected.to contain_keystone_config('ssl/cert_subject').with_value('/C=US/ST=Unset/L=Unset/O=Unset/CN=localhost')} end context 'with RabbitMQ communication SSLed' do let :params do { :rabbit_use_ssl => true, :kombu_ssl_ca_certs => '/path/to/ssl/ca/certs', :kombu_ssl_certfile => '/path/to/ssl/cert/file', :kombu_ssl_keyfile => '/path/to/ssl/keyfile', :kombu_ssl_version => 'TLSv1' } end it { is_expected.to contain_oslo__messaging__rabbit('keystone_config').with( :rabbit_use_ssl => true, :kombu_ssl_ca_certs => '/path/to/ssl/ca/certs', :kombu_ssl_certfile => '/path/to/ssl/cert/file', :kombu_ssl_keyfile => '/path/to/ssl/keyfile', :kombu_ssl_version => 'TLSv1' )} end context 'with RabbitMQ communication not SSLed' do let :params do {} end it { is_expected.to contain_oslo__messaging__rabbit('keystone_config').with( :rabbit_use_ssl => '<SERVICE DEFAULT>', :kombu_ssl_ca_certs => '<SERVICE DEFAULT>', :kombu_ssl_certfile => '<SERVICE DEFAULT>', :kombu_ssl_keyfile => '<SERVICE DEFAULT>', :kombu_ssl_version => '<SERVICE DEFAULT>' )} end context 'setting notification settings' do let :params do { :notification_driver => ['keystone.openstack.common.notifier.rpc_notifier'], :notification_topics => ['notifications'], :notification_format => 'cadf', :control_exchange => 'keystone', :rpc_response_timeout => '120' } end it { is_expected.to contain_keystone_config('oslo_messaging_notifications/driver').with_value(['keystone.openstack.common.notifier.rpc_notifier']) } it { is_expected.to contain_keystone_config('oslo_messaging_notifications/topics').with_value('notifications') } it { is_expected.to contain_keystone_config('DEFAULT/notification_format').with_value('cadf') } it { is_expected.to contain_keystone_config('DEFAULT/control_exchange').with_value('keystone') } it { is_expected.to contain_keystone_config('DEFAULT/rpc_response_timeout').with_value('120') } end context 'setting kombu settings' do let :params do { :kombu_reconnect_delay => '1.0', :kombu_compression => 'gzip', } end it { is_expected.to contain_keystone_config('oslo_messaging_rabbit/kombu_reconnect_delay').with_value('1.0') } it { is_expected.to contain_keystone_config('oslo_messaging_rabbit/kombu_compression').with_value('gzip') } it { is_expected.to contain_keystone_config('oslo_messaging_rabbit/kombu_failover_strategy').with_value('<SERVICE DEFAULT>') } end context 'when enabling credential_setup' do let :params do merge({ } :owner => 'keystone', :group => 'keystone', :command => 'keystone-manage credential_setup --keystone-user keystone --keystone-group keystone', :user => 'keystone', context 'when overriding the credential key directory' do { } context 'when overriding the keystone group and user' do { } context 'when setting credential_keys parameter' do { } context 'when disabling credential_setup' do { } context 'when enabling fernet_setup' do { } :owner => 'keystone', :group => 'keystone', :command => 'keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone', :user => 'keystone', context 'when overriding the fernet key directory' do { } context 'when overriding the keystone group and user' do { } context 'when setting fernet_keys parameter' do { 'enable_fernet_setup' => true, 'fernet_keys' => { '/etc/keystone/fernet-keys/0' => { 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', }, '/etc/keystone/fernet-keys/1' => { 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', }, } } it { is_expected.to_not contain_exec('keystone-manage fernet_setup') } it { is_expected.to contain_file('/etc/keystone/fernet-keys/0').with( 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => true, 'subscribe' => 'Anchor[keystone::install::end]', 'tag' => 'keystone-fernet-key', )} it { is_expected.to contain_file('/etc/keystone/fernet-keys/1').with( 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => true, 'subscribe' => 'Anchor[keystone::install::end]', 'tag' => 'keystone-fernet-key', )} end context 'when not replacing fernet_keys and setting fernet_keys parameter' do let :params do { 'enable_fernet_setup' => true, 'fernet_keys' => { '/etc/keystone/fernet-keys/0' => { 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', }, '/etc/keystone/fernet-keys/1' => { 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', }, }, 'fernet_replace_keys' => false, } end it { is_expected.to_not contain_exec('keystone-manage fernet_setup') } it { is_expected.to contain_file('/etc/keystone/fernet-keys/0').with( 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => false, 'subscribe' => 'Anchor[keystone::install::end]', )} it { is_expected.to contain_file('/etc/keystone/fernet-keys/1').with( 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => false, 'subscribe' => 'Anchor[keystone::install::end]', )} end context 'with default domain and eventlet service is managed and enabled' do let :params do { 'default_domain' => 'test' } end context 'with default domain and wsgi service is managed and enabled' do { } context 'with default domain and service is not managed' do { } context 'when using domain config' do { 'using_domain_config'=> true } context 'when using domain config and a wrong directory' do { } context 'when setting domain directory and not using domain config' do { } context 'when setting domain directory and using domain config' do { } on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts({ :concat_basedir => '/var/lib/puppet/concat', :fqdn => 'some.host.tld' })) end let(:platform_params) do case facts[:osfamily] when 'Debian' if facts[:operatingsystem] == 'Ubuntu' { :package_name => 'keystone', :service_name => 'keystone' } else { :package_name => 'keystone', :service_name => 'keystone' } end when 'RedHat' { :package_name => 'opnestack-keystone', :service_name => 'openstack-keystone' } end end it_behaves_like 'keystone' end end"," let :global_facts do { :concat_basedir => '/var/lib/puppet/concat', :fqdn => 'some.host.tld' } end let :facts do @default_facts.merge(global_facts.merge({ :osfamily => 'Debian', :operatingsystem => 'Debian', :operatingsystemrelease => '7.0', :os => { :name => 'Debian', :family => 'Debian', :release => { :major => '7', :minor => '0' } }, })) end default_params = { 'package_ensure' => 'present', 'client_package_ensure' => 'present', 'catalog_type' => 'sql', 'catalog_driver' => false, 'token_provider' => 'fernet', 'password_hash_algorithm' => '<SERVICE DEFAULT>', 'password_hash_rounds' => '<SERVICE DEFAULT>', 'revoke_driver' => 'sql', 'revoke_by_id' => true, 'enable_ssl' => false, 'ssl_certfile' => '/etc/keystone/ssl/certs/keystone.pem', 'ssl_keyfile' => '/etc/keystone/ssl/private/keystonekey.pem', 'ssl_ca_certs' => '/etc/keystone/ssl/certs/ca.pem', 'ssl_ca_key' => '/etc/keystone/ssl/private/cakey.pem', 'ssl_cert_subject' => '/C=US/ST=Unset/L=Unset/O=Unset/CN=localhost', 'enabled' => true, 'manage_service' => true, 'default_transport_url' => '<SERVICE DEFAULT>', 'notification_transport_url' => '<SERVICE DEFAULT>', 'rabbit_heartbeat_timeout_threshold' => '<SERVICE DEFAULT>', 'rabbit_heartbeat_rate' => '<SERVICE DEFAULT>', 'rabbit_heartbeat_in_pthread' => '<SERVICE DEFAULT>', 'amqp_durable_queues' => '<SERVICE DEFAULT>', 'member_role_id' => '<SERVICE DEFAULT>', 'member_role_name' => '<SERVICE DEFAULT>', 'sync_db' => true, 'purge_config' => false, 'keystone_user' => 'keystone', 'keystone_group' => 'keystone', } override_params = { 'package_ensure' => 'latest', 'client_package_ensure' => 'latest', 'catalog_type' => 'template', 'token_provider' => 'uuid', 'password_hash_algorithm' => 'pbkdf2_sha512', 'password_hash_rounds' => '29000', 'revoke_driver' => 'kvs', 'revoke_by_id' => false, 'public_endpoint' => 'https://localhost:5000', 'enable_ssl' => true, 'ssl_certfile' => '/etc/keystone/ssl/certs/keystone.pem', 'ssl_keyfile' => '/etc/keystone/ssl/private/keystonekey.pem', 'ssl_ca_certs' => '/etc/keystone/ssl/certs/ca.pem', 'ssl_ca_key' => '/etc/keystone/ssl/private/cakey.pem', 'ssl_cert_subject' => '/C=US/ST=Unset/L=Unset/O=Unset/CN=localhost', 'enabled' => false, 'manage_service' => true, 'default_transport_url' => 'rabbit://user:pass@host:1234/virt', 'notification_transport_url' => 'rabbit://user:pass@host:1234/virt', 'rabbit_heartbeat_timeout_threshold' => '60', 'rabbit_heartbeat_rate' => '10', 'rabbit_heartbeat_in_pthread' => true, 'rabbit_ha_queues' => true, 'amqp_durable_queues' => true, 'default_domain' => 'other_domain', 'member_role_id' => '123456789', 'member_role_name' => 'othermember', 'using_domain_config' => false, 'keystone_user' => 'test_user', 'keystone_group' => 'test_group', } httpd_params = {'service_name' => 'httpd'}.merge(default_params) shared_examples 'core keystone examples' do |param_hash| it { is_expected.to contain_class('keystone::logging') } it { is_expected.to contain_class('keystone::params') } it { is_expected.to contain_class('keystone::policy') } it { is_expected.to contain_package('keystone').with( 'ensure' => param_hash['package_ensure'], 'tag' => ['openstack', 'keystone-package'], ) } it { is_expected.to contain_class('keystone::client').with( 'ensure' => param_hash['client_package_ensure'], ) } it 'should synchronize the db if $sync_db is true' do if param_hash['sync_db'] end it 'passes purge to resource' do is_expected.to contain_resources('keystone_config').with({ :purge => false }) end it 'should contain correct config' do [ 'member_role_id', 'member_role_name', ].each do |config| is_expected.to contain_keystone_config(""DEFAULT/#{config}"").with_value(param_hash[config]) end it 'should contain correct mysql config' do is_expected.to contain_class('keystone::db') end it { is_expected.to contain_keystone_config('token/provider').with_value( param_hash['token_provider'] ) } it 'should contain correct revoke driver' do is_expected.to contain_keystone_config('revoke/driver').with_value(param_hash['revoke_driver']) end it 'should contain password_hash_algorithm' do is_expected.to contain_keystone_config('identity/password_hash_algorithm').with_value(param_hash['password_hash_algorithm']) end it 'should contain password_hash_rounds' do is_expected.to contain_keystone_config('identity/password_hash_rounds').with_value(param_hash['password_hash_rounds']) end it 'should contain default revoke_by_id value ' do is_expected.to contain_keystone_config('token/revoke_by_id').with_value(param_hash['revoke_by_id']) end it 'should ensure proper setting of public_endpoint' do if param_hash['public_endpoint'] is_expected.to contain_keystone_config('DEFAULT/public_endpoint').with_value(param_hash['public_endpoint']) else end it 'should contain correct default transport url' do is_expected.to contain_keystone_config('DEFAULT/transport_url').with_value(params['default_transport_url']) end it 'should contain correct rabbit heartbeat configuration' do is_expected.to contain_keystone_config('oslo_messaging_rabbit/heartbeat_timeout_threshold').with_value(param_hash['rabbit_heartbeat_timeout_threshold']) is_expected.to contain_keystone_config('oslo_messaging_rabbit/heartbeat_rate').with_value(param_hash['rabbit_heartbeat_rate']) is_expected.to contain_keystone_config('oslo_messaging_rabbit/heartbeat_in_pthread').with_value(param_hash['rabbit_heartbeat_in_pthread']) is_expected.to contain_keystone_config('oslo_messaging_rabbit/amqp_durable_queues').with_value(param_hash['amqp_durable_queues']) end it 'should remove max_token_size param by default' do is_expected.to contain_keystone_config('DEFAULT/max_token_size').with_value('<SERVICE DEFAULT>') end it 'should ensure rabbit_ha_queues' do if param_hash['rabbit_ha_queues'] is_expected.to contain_keystone_config('oslo_messaging_rabbit/rabbit_ha_queues').with_value(param_hash['rabbit_ha_queues']) else is_expected.to contain_keystone_config('oslo_messaging_rabbit/rabbit_ha_queues').with_value('<SERVICE DEFAULT>') end end if param_hash['default_domain'] it { is_expected.to contain_keystone_domain(param_hash['default_domain']).with(:is_default => true) } it { is_expected.to contain_anchor('default_domain_created') } end end [default_params, override_params].each do |param_hash| describe ""when #{param_hash == default_params ? ""using default"" : ""specifying""} class parameters for service"" do let :params do param_hash end it_behaves_like 'core keystone examples', param_hash 'ensure' => (param_hash['manage_service'] && param_hash['enabled']) ? 'running' : 'stopped', end end shared_examples ""when using default class parameters for httpd on Debian"" do let :params do httpd_params let :pre_condition do 'include keystone::wsgi::apache' end it_behaves_like 'core keystone examples', httpd_params it do expect { is_expected.to contain_service(platform_parameters[:service_name]).with('ensure' => 'running') }.to raise_error(RSpec::Expectations::ExpectationNotMetError, /expected that the catalogue would contain Service\[#{platform_parameters[:service_name]}\]/) end it { is_expected.to contain_exec('restart_keystone').with( 'command' => ""service #{platform_parameters[:httpd_service_name]} restart"", ) } end shared_examples ""when using default class parameters for httpd on RedHat"" do let :params do httpd_params end let :pre_condition do 'include keystone::wsgi::apache' end it_behaves_like 'core keystone examples', httpd_params it do expect { is_expected.to contain_service(platform_parameters[:service_name]).with('ensure' => 'running') }.to raise_error(RSpec::Expectations::ExpectationNotMetError, /expected that the catalogue would contain Service\[#{platform_parameters[:service_name]}\]/) end it { is_expected.to contain_service('httpd').with_before(/Anchor\[keystone::service::end\]/) } it { is_expected.to contain_exec('restart_keystone').with( 'command' => ""service #{platform_parameters[:httpd_service_name]} restart"", ) } end describe 'when using invalid service name for keystone' do let (:params) { {'service_name' => 'foo'}.merge(default_params) } it_raises 'a Puppet::Error', /Invalid service_name/ end describe 'with disabled service managing' do let :params do { :manage_service => false, :enabled => false } end it { is_expected.to contain_service('keystone').with( 'ensure' => nil, 'enable' => false, 'hasstatus' => true, 'hasrestart' => true ) } it { is_expected.to contain_anchor('keystone::service::end') } end describe 'when configuring signing token provider' do describe 'when configuring as UUID' do 'token_provider' => 'keystone.token.providers.uuid.Provider' describe 'with invalid catalog_type' do describe 'when configuring catalog driver' do { :catalog_driver => 'alien' } it { is_expected.to contain_keystone_config('catalog/driver').with_value(params[:catalog_driver]) } end end describe 'when configuring token expiration' do let :params do { 'token_expiration' => '42', } it { is_expected.to contain_keystone_config(""token/expiration"").with_value('42') } end describe 'when not configuring token expiration' do let :params do {} end it { is_expected.to contain_keystone_config(""token/expiration"").with_value('3600') } end describe 'when sync_db is set to false' do let :params do { 'sync_db' => false, } end it { is_expected.not_to contain_exec('keystone-manage db_sync') } end describe 'when enabling SSL' do let :params do { 'enable_ssl' => true, } end it {is_expected.to contain_keystone_config('ssl/enable').with_value(true)} it {is_expected.to contain_keystone_config('ssl/certfile').with_value('/etc/keystone/ssl/certs/keystone.pem')} it {is_expected.to contain_keystone_config('ssl/keyfile').with_value('/etc/keystone/ssl/private/keystonekey.pem')} it {is_expected.to contain_keystone_config('ssl/ca_certs').with_value('/etc/keystone/ssl/certs/ca.pem')} it {is_expected.to contain_keystone_config('ssl/ca_key').with_value('/etc/keystone/ssl/private/cakey.pem')} it {is_expected.to contain_keystone_config('ssl/cert_subject').with_value('/C=US/ST=Unset/L=Unset/O=Unset/CN=localhost')} end describe 'when disabling SSL' do let :params do { 'enable_ssl'=> false, } end it {is_expected.to contain_keystone_config('ssl/enable').with_value(false)} end describe 'not setting notification settings by default' do let :params do default_params end it { is_expected.to contain_keystone_config('oslo_messaging_notifications/transport_url').with_value('<SERVICE DEFAULT>') } it { is_expected.to contain_keystone_config('oslo_messaging_notifications/driver').with_value('<SERVICE DEFAULT>') } it { is_expected.to contain_keystone_config('oslo_messaging_notifications/topics').with_value('<SERVICE DEFAULT>') } it { is_expected.to contain_keystone_config('DEFAULT/notification_format').with_value('<SERVICE DEFAULT>') } it { is_expected.to contain_keystone_config('DEFAULT/control_exchange').with_value('<SERVICE DEFAULT>') } it { is_expected.to contain_keystone_config('DEFAULT/rpc_response_timeout').with_value('<SERVICE DEFAULT>') } end describe 'with RabbitMQ communication SSLed' do let :params do default_params.merge!({ :rabbit_use_ssl => true, :kombu_ssl_ca_certs => '/path/to/ssl/ca/certs', :kombu_ssl_certfile => '/path/to/ssl/cert/file', :kombu_ssl_keyfile => '/path/to/ssl/keyfile', :kombu_ssl_version => 'TLSv1' }) end it { is_expected.to contain_oslo__messaging__rabbit('keystone_config').with( :rabbit_use_ssl => true, :kombu_ssl_ca_certs => '/path/to/ssl/ca/certs', :kombu_ssl_certfile => '/path/to/ssl/cert/file', :kombu_ssl_keyfile => '/path/to/ssl/keyfile', :kombu_ssl_version => 'TLSv1' )} end describe 'with RabbitMQ communication not SSLed' do let :params do default_params.merge!({ :rabbit_use_ssl => '<SERVICE DEFAULT>', :kombu_ssl_ca_certs => '<SERVICE DEFAULT>', :kombu_ssl_certfile => '<SERVICE DEFAULT>', :kombu_ssl_keyfile => '<SERVICE DEFAULT>', :kombu_ssl_version => '<SERVICE DEFAULT>' }) end it { is_expected.to contain_oslo__messaging__rabbit('keystone_config').with( :rabbit_use_ssl => '<SERVICE DEFAULT>', :kombu_ssl_ca_certs => '<SERVICE DEFAULT>', :kombu_ssl_certfile => '<SERVICE DEFAULT>', :kombu_ssl_keyfile => '<SERVICE DEFAULT>', :kombu_ssl_version => '<SERVICE DEFAULT>' )} end describe 'when configuring max_token_size' do let :params do default_params.merge({:max_token_size => '16384' }) end it { is_expected.to contain_keystone_config('DEFAULT/max_token_size').with_value(params[:max_token_size]) } end describe 'setting notification settings' do let :params do default_params.merge({ :notification_driver => ['keystone.openstack.common.notifier.rpc_notifier'], :notification_topics => ['notifications'], :notification_format => 'cadf', :control_exchange => 'keystone', :rpc_response_timeout => '120' }) end it { is_expected.to contain_keystone_config('oslo_messaging_notifications/driver').with_value(['keystone.openstack.common.notifier.rpc_notifier']) } it { is_expected.to contain_keystone_config('oslo_messaging_notifications/topics').with_value('notifications') } it { is_expected.to contain_keystone_config('DEFAULT/notification_format').with_value('cadf') } it { is_expected.to contain_keystone_config('DEFAULT/control_exchange').with_value('keystone') } it { is_expected.to contain_keystone_config('DEFAULT/rpc_response_timeout').with_value('120') } end describe 'setting kombu settings' do let :params do default_params.merge({ :kombu_reconnect_delay => '1.0', :kombu_compression => 'gzip', }) end it { is_expected.to contain_keystone_config('oslo_messaging_rabbit/kombu_reconnect_delay').with_value('1.0') } it { is_expected.to contain_keystone_config('oslo_messaging_rabbit/kombu_compression').with_value('gzip') } it { is_expected.to contain_keystone_config('oslo_messaging_rabbit/kombu_failover_strategy').with_value('<SERVICE DEFAULT>') } end describe 'setting enable_proxy_headers_parsing' do let :params do default_params.merge({:enable_proxy_headers_parsing => true }) end it { is_expected.to contain_oslo__middleware('keystone_config').with( :enable_proxy_headers_parsing => true, )} end describe 'setting max_request_body_size' do let :params do default_params.merge({:max_request_body_size => '1146880' }) end it { is_expected.to contain_oslo__middleware('keystone_config').with( :max_request_body_size => '1146880', )} end describe 'setting sql policy driver' do let :params do default_params.merge({:policy_driver => 'sql' }) end it { is_expected.to contain_keystone_config('policy/driver').with_value('sql') } end describe 'setting sql (default) catalog' do let :params do default_params end it { is_expected.to contain_keystone_config('catalog/driver').with_value('sql') } end describe 'setting default template catalog' do let :params do { :catalog_type => 'template' } end it { is_expected.to contain_keystone_config('catalog/driver').with_value('templated') } it { is_expected.to contain_keystone_config('catalog/template_file').with_value('/etc/keystone/default_catalog.templates') } end describe 'setting another template catalog' do let :params do { :catalog_type => 'template', :catalog_template_file => '/some/template_file' } end it { is_expected.to contain_keystone_config('catalog/driver').with_value('templated') } it { is_expected.to contain_keystone_config('catalog/template_file').with_value('/some/template_file') } end describe 'when using credentials' do describe 'when enabling credential_setup' do default_params.merge({ }) :owner => params['keystone_user'], :group => params['keystone_group'], :command => ""keystone-manage credential_setup --keystone-user #{params['keystone_user']} --keystone-group #{params['keystone_group']}"", :user => params['keystone_user'], describe 'when overriding the credential key directory' do default_params.merge({ }) describe 'when overriding the keystone group and user' do default_params.merge({ }) describe 'when setting credential_keys parameter' do default_params.merge({ }) describe 'when disabling credential_setup' do default_params.merge({ }) end describe 'when using fernet tokens' do describe 'when enabling fernet_setup' do default_params.merge({ }) :owner => params['keystone_user'], :group => params['keystone_group'], :command => ""keystone-manage fernet_setup --keystone-user #{params['keystone_user']} --keystone-group #{params['keystone_group']}"", :user => params['keystone_user'], describe 'when overriding the fernet key directory' do default_params.merge({ }) describe 'when overriding the keystone group and user' do default_params.merge({ }) end end describe 'when setting fernet_keys parameter' do let :params do default_params.merge({ 'enable_fernet_setup' => true, 'fernet_keys' => { '/etc/keystone/fernet-keys/0' => { 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', }, '/etc/keystone/fernet-keys/1' => { 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', }, } }) it { is_expected.to_not contain_exec('keystone-manage fernet_setup') } it { is_expected.to contain_file('/etc/keystone/fernet-keys/0').with( 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => true, 'subscribe' => 'Anchor[keystone::install::end]', 'tag' => 'keystone-fernet-key', )} it { is_expected.to contain_file('/etc/keystone/fernet-keys/1').with( 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => true, 'subscribe' => 'Anchor[keystone::install::end]', 'tag' => 'keystone-fernet-key', )} end describe 'when not replacing fernet_keys and setting fernet_keys parameter' do let :params do default_params.merge({ 'enable_fernet_setup' => true, 'fernet_keys' => { '/etc/keystone/fernet-keys/0' => { 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', }, '/etc/keystone/fernet-keys/1' => { 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', }, }, 'fernet_replace_keys' => false, }) end it { is_expected.to_not contain_exec('keystone-manage fernet_setup') } it { is_expected.to contain_file('/etc/keystone/fernet-keys/0').with( 'content' => 't-WdduhORSqoyAykuqWAQSYjg2rSRuJYySgI2xh48CI=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => false, 'subscribe' => 'Anchor[keystone::install::end]', )} it { is_expected.to contain_file('/etc/keystone/fernet-keys/1').with( 'content' => 'GLlnyygEVJP4-H2OMwClXn3sdSQUZsM5F194139Unv8=', 'owner' => 'keystone', 'mode' => '0600', 'replace' => false, 'subscribe' => 'Anchor[keystone::install::end]', )} end shared_examples ""when configuring default domain"" do describe 'with default domain and eventlet service is managed and enabled' do default_params.merge({ 'default_domain'=> 'test', }) describe 'with default domain and wsgi service is managed and enabled' do default_params.merge({ }) describe 'with default domain and service is not managed' do default_params.merge({ }) end context 'on RedHat platforms' do let :facts do @default_facts.merge(global_facts.merge({ :osfamily => 'RedHat', :operatingsystem => 'RedHat', :operatingsystemrelease => '7.0', :os => { :name => 'RedHat', :family => 'RedHat', :release => { :major => '7', :minor => '0' } }, })) end let :platform_parameters do { :service_name => 'openstack-keystone', :httpd_service_name => 'httpd', } end it_behaves_like 'when using default class parameters for httpd on RedHat' it_behaves_like 'when configuring default domain' end context 'on Debian platforms' do let :facts do @default_facts.merge(global_facts.merge({ :osfamily => 'Debian', :operatingsystem => 'Debian', :operatingsystemrelease => '7.0', :os => { :name => 'Debian', :family => 'Debian', :release => { :major => '7', :minor => '0' } }, })) end let :platform_parameters do { :service_name => 'keystone', :httpd_service_name => 'apache2', } end it_behaves_like 'when using default class parameters for httpd on Debian' it_behaves_like 'when configuring default domain' end describe ""when configuring using_domain_config"" do describe 'with default config' do default_params it { is_expected.to_not contain_file('/etc/keystone/domains') } end describe 'when using domain config' do let :params do default_params.merge({ 'using_domain_config'=> true, }) end describe 'when using domain config and a wrong directory' do default_params.merge({ }) describe 'when setting domain directory and not using domain config' do default_params.merge({ }) describe 'when setting domain directory and using domain config' do default_params.merge({ })",404,633
openstack%2Fneutron-dynamic-routing~master~I2d3a6e6bb0db372565458ea5eed4d84efdef37d2,openstack/neutron-dynamic-routing,master,I2d3a6e6bb0db372565458ea5eed4d84efdef37d2,Add doc/requirements,MERGED,2021-01-05 10:39:04.000000000,2021-01-05 16:22:12.000000000,2021-01-05 16:20:37.000000000,"[{'_account_id': 11975}, {'_account_id': 16137}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-05 10:39:04.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/d7a66c491ea5b8001ad94193603b87afc6e4118f', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: I2d3a6e6bb0db372565458ea5eed4d84efdef37d2\n'}]",1,769315,d7a66c491ea5b8001ad94193603b87afc6e4118f,9,6,1,8313,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: I2d3a6e6bb0db372565458ea5eed4d84efdef37d2
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/15/769315/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,d7a66c491ea5b8001ad94193603b87afc6e4118f,fix-relmgt-pip-doc,deps = {[testenv:docs]deps}deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},# deps = {[testenv:docs]deps},10,5
openstack%2Fpuppet-designate~master~I4a5f1011f21c25e22f3a087e25d5f2974ec29b7b,openstack/puppet-designate,master,I4a5f1011f21c25e22f3a087e25d5f2974ec29b7b,Fix ignored unit tests,MERGED,2021-01-03 05:34:24.000000000,2021-01-05 16:15:40.000000000,2021-01-05 16:15:40.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/9655b14e76bad4a2344005cdeb9ec7d9e49583e3', 'message': 'Fix ignored unit tests for manila::volume::cinder\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I4a5f1011f21c25e22f3a087e25d5f2974ec29b7b\n'}, {'number': 2, 'created': '2021-01-03 05:48:06.000000000', 'files': ['spec/unit/type/designate_api_paste_ini_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/e1d8a9ce89fc9a91fd96801ce676abdb008b2d1b', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I4a5f1011f21c25e22f3a087e25d5f2974ec29b7b\n'}]",0,768958,e1d8a9ce89fc9a91fd96801ce676abdb008b2d1b,9,3,2,9816,,,0,"Fix ignored unit tests

Unit test files should be named like *_spec.rb.

Change-Id: I4a5f1011f21c25e22f3a087e25d5f2974ec29b7b
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/58/768958/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/unit/type/designate_api_paste_ini_spec.rb'],1,9655b14e76bad4a2344005cdeb9ec7d9e49583e3,ignored-ut,,,0,0
openstack%2Fpuppet-barbican~master~I3323204aed1217cc2b0dff9d2955519a6035f7e9,openstack/puppet-barbican,master,I3323204aed1217cc2b0dff9d2955519a6035f7e9,Fix ignored unit tests,MERGED,2021-01-03 05:33:34.000000000,2021-01-05 16:14:08.000000000,2021-01-05 16:14:08.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/b03c8aa3549e46c0dff5c412103f2d23d48b0693', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3323204aed1217cc2b0dff9d2955519a6035f7e9\n'}, {'number': 2, 'created': '2021-01-03 05:47:01.000000000', 'files': ['spec/unit/provider/barbican_config/openstackconfig_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/78b23dbf5d693f18fc72a369586eef3280adc44a', 'message': 'Fix ignored unit tests\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I3323204aed1217cc2b0dff9d2955519a6035f7e9\n'}]",0,768957,78b23dbf5d693f18fc72a369586eef3280adc44a,9,3,2,9816,,,0,"Fix ignored unit tests

Unit test files should be named like *_spec.rb.

Change-Id: I3323204aed1217cc2b0dff9d2955519a6035f7e9
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/57/768957/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/unit/provider/barbican_config/openstackconfig_spec.rb'],1,b03c8aa3549e46c0dff5c412103f2d23d48b0693,ignored-ut,,,0,0
openstack%2Fcinder~master~I3f31acd5fc3d7422270be53510962dcbc08db602,openstack/cinder,master,I3f31acd5fc3d7422270be53510962dcbc08db602,pylint: run coding-checks.sh with bash,MERGED,2021-01-04 13:47:59.000000000,2021-01-05 16:13:14.000000000,2021-01-05 16:10:35.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2021-01-04 13:47:59.000000000', 'files': ['tools/coding-checks.sh'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce060323f0f6bc5bd8a3b4ab8e50935aaef0f27d', 'message': 'pylint: run coding-checks.sh with bash\n\n[[ is a bash extension and therefore not\navailable on platforms where sh is not bash.\nUse bash explicitly.\n\nChange-Id: I3f31acd5fc3d7422270be53510962dcbc08db602\n'}]",1,769146,ce060323f0f6bc5bd8a3b4ab8e50935aaef0f27d,24,3,1,4523,,,0,"pylint: run coding-checks.sh with bash

[[ is a bash extension and therefore not
available on platforms where sh is not bash.
Use bash explicitly.

Change-Id: I3f31acd5fc3d7422270be53510962dcbc08db602
",git fetch https://review.opendev.org/openstack/cinder refs/changes/46/769146/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/coding-checks.sh'],1,ce060323f0f6bc5bd8a3b4ab8e50935aaef0f27d,,#!/bin/bash,#!/bin/sh,1,1
openstack%2Fneutron~stable%2Fussuri~Icfcf8c5406cfdc47fabf012e82ed56c345a73af8,openstack/neutron,stable/ussuri,Icfcf8c5406cfdc47fabf012e82ed56c345a73af8,Flush ebtables arp protect chains before deleting them,MERGED,2020-12-04 10:34:48.000000000,2021-01-05 16:13:11.000000000,2021-01-05 16:10:28.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 27915}, {'_account_id': 28752}, {'_account_id': 32192}]","[{'number': 1, 'created': '2020-12-04 10:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ab130e7b037a48c382e1c14552f256eada1c52e', 'message': 'Flush ebtables arp protect chains before deleting them\n\nWhen a port is removed, the linuxbridge agent cleans up the chains\nneutronARP-* and neutronMAC-*, but in some cases this chains still\ncontains rules and ebtables fails with `CHAIN_USER_DEL failed (Device or\nresource busy)`. Flushing the chains before deleting them, fixes that\nissue.\n\nChange-Id: Icfcf8c5406cfdc47fabf012e82ed56c345a73af8\nCloses-Bug: #1887281\n(cherry picked from commit 2207b885449667a7bc377f427b9123165223dbde)\n'}, {'number': 2, 'created': '2020-12-21 10:07:36.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/test_arp_protect.py', 'neutron/plugins/ml2/drivers/linuxbridge/agent/arp_protect.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a883562300469b55706c99995e8c2fe94b583e1', 'message': 'Flush ebtables arp protect chains before deleting them\n\nWhen a port is removed, the linuxbridge agent cleans up the chains\nneutronARP-* and neutronMAC-*, but in some cases this chains still\ncontains rules and ebtables fails with `CHAIN_USER_DEL failed (Device or\nresource busy)`. Flushing the chains before deleting them, fixes that\nissue.\n\nChange-Id: Icfcf8c5406cfdc47fabf012e82ed56c345a73af8\nCloses-Bug: #1887281\n(cherry picked from commit 2207b885449667a7bc377f427b9123165223dbde)\n'}]",0,765408,2a883562300469b55706c99995e8c2fe94b583e1,29,6,2,28619,,,0,"Flush ebtables arp protect chains before deleting them

When a port is removed, the linuxbridge agent cleans up the chains
neutronARP-* and neutronMAC-*, but in some cases this chains still
contains rules and ebtables fails with `CHAIN_USER_DEL failed (Device or
resource busy)`. Flushing the chains before deleting them, fixes that
issue.

Change-Id: Icfcf8c5406cfdc47fabf012e82ed56c345a73af8
Closes-Bug: #1887281
(cherry picked from commit 2207b885449667a7bc377f427b9123165223dbde)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/765408/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/test_arp_protect.py', 'neutron/plugins/ml2/drivers/linuxbridge/agent/arp_protect.py']",2,2ab130e7b037a48c382e1c14552f256eada1c52e,fix-flush-ebtables-chain-before-deleting-stable/victoria-stable/ussuri," chain_delete(chain_name(vif), table, current_rules)def chain_delete(chain, table, current_rules): # flush and delete chain if exists if chain_exists(chain, current_rules): ebtables(['-F', chain], table=table) ebtables(['-X', chain], table=table) chain_delete(_mac_chain_name(vif), table, current_rules)"," if chain_exists(chain_name(vif), current_rules): ebtables(['-X', chain_name(vif)], table=table) chain = _mac_chain_name(vif) if chain_exists(chain, current_rules): ebtables(['-X', chain], table=table)",25,5
openstack%2Fproject-config~master~Iaaaed7b0ea343bd81b8ad898654658545942a3d0,openstack/project-config,master,Iaaaed7b0ea343bd81b8ad898654658545942a3d0,release-scripts: Remove misleading error message,MERGED,2021-01-05 14:30:05.000000000,2021-01-05 16:11:30.000000000,2021-01-05 16:11:30.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 14:30:05.000000000', 'files': ['roles/copy-release-tools-scripts/files/release-tools/clone_repo.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/885330b8e7795a6750c668e7abd862e071bf4642', 'message': ""release-scripts: Remove misleading error message\n\nIn the normal course of script execution, clone_repo.sh routinely logs\nthe following error message:\n\nerror: pathspec 'xxx' did not match any file(s) known to git\n\nThis error can be safely ignored, as the script moves on to checking out\nmaster instead. But it can be (and has been) mistakenly interpreted as\nthe reason why the script fails.\n\nThis change avoids logging the error message and logs a clearer\nexplanation instead.\n\nChange-Id: Iaaaed7b0ea343bd81b8ad898654658545942a3d0\n""}]",0,769353,885330b8e7795a6750c668e7abd862e071bf4642,7,3,1,308,,,0,"release-scripts: Remove misleading error message

In the normal course of script execution, clone_repo.sh routinely logs
the following error message:

error: pathspec 'xxx' did not match any file(s) known to git

This error can be safely ignored, as the script moves on to checking out
master instead. But it can be (and has been) mistakenly interpreted as
the reason why the script fails.

This change avoids logging the error message and logs a clearer
explanation instead.

Change-Id: Iaaaed7b0ea343bd81b8ad898654658545942a3d0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/53/769353/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/copy-release-tools-scripts/files/release-tools/clone_repo.sh'],1,885330b8e7795a6750c668e7abd862e071bf4642,," (git checkout $BRANCH 2>/dev/null || (echo ""No $BRANCH, checking out master""; git checkout master)) && retry git pull --ff-only)", (git checkout $BRANCH || git checkout master) && retry git pull --ff-only),3,2
openstack%2Fpuppet-manila~master~I5b6c85b7d7a865a0f281a725f8df8b8f0e3d12e8,openstack/puppet-manila,master,I5b6c85b7d7a865a0f281a725f8df8b8f0e3d12e8,Fix ignored unit tests for manila::volume::cinder,MERGED,2021-01-03 05:30:39.000000000,2021-01-05 16:11:11.000000000,2021-01-05 16:11:11.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:30:39.000000000', 'files': ['spec/classes/manila_volume_cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/fea6aabfe2ef829d255e296f966141597eface1e', 'message': 'Fix ignored unit tests for manila::volume::cinder\n\nUnit test files should be named like *_spec.rb.\n\nChange-Id: I5b6c85b7d7a865a0f281a725f8df8b8f0e3d12e8\n'}]",0,768955,fea6aabfe2ef829d255e296f966141597eface1e,9,3,1,9816,,,0,"Fix ignored unit tests for manila::volume::cinder

Unit test files should be named like *_spec.rb.

Change-Id: I5b6c85b7d7a865a0f281a725f8df8b8f0e3d12e8
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/55/768955/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/manila_volume_cinder_spec.rb'],1,fea6aabfe2ef829d255e296f966141597eface1e,ignored-ut, shared_examples 'manila::volume::cinder' do it_behaves_like 'manila::volume::cinder', shared_examples 'manila::cinder' do it_behaves_like 'manila::cinder',2,2
openstack%2Ftacker~master~I0b655d6ebce7c4dacb9cc9c0526aa702d1ac37db,openstack/tacker,master,I0b655d6ebce7c4dacb9cc9c0526aa702d1ac37db,Fix some content of VNFD in UT and FT,MERGED,2021-01-04 06:02:57.000000000,2021-01-05 16:09:09.000000000,2021-01-05 16:07:26.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 27880}, {'_account_id': 32102}, {'_account_id': 32395}]","[{'number': 1, 'created': '2021-01-04 06:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/71cdc6d2a284819f865906bf26bbc019597ad552', 'message': 'Fix some content of VNFD in UT and FT\n\nAdded the policy type to the VNFD, so that the VNFD can pass\nthe newly added policy type check processing in tosca-parser.\n\nCloses-Bug: #1909312\nChange-Id: I0b655d6ebce7c4dacb9cc9c0526aa702d1ac37db\n'}, {'number': 2, 'created': '2021-01-05 00:18:59.000000000', 'files': ['tacker/tests/functional/vnfm/test_vnf_placement_policy.py', 'tacker/tests/etc/samples/etsi/nfv/sample_vnfpkg_no_meta_single_vnfd/vnfd_helloworld_single.yaml', 'tacker/tests/etc/samples/etsi/nfv/sample_vnf_package_csar_in_single_manifest_false_name/VNF.yaml', 'tacker/tests/etc/samples/etsi/nfv/sample_vnf_package_csar_manifest/VNF.yaml', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/test_tosca_vnfd_alarm_scale.yaml', 'tacker/tests/etc/samples/etsi/nfv/test_csar_utils_data/csar_without_flavour_info/Definitions/tosca_with_vdus.yaml', 'tacker/tests/etc/samples/etsi/nfv/test_csar_utils_data/csar_without_flavour_info_in_main_template/Definitions/main_tosca.yaml', 'tacker/tests/etc/samples/etsi/nfv/vnfpkgm3/vnfd_helloworld_single.yaml'], 'web_link': 'https://opendev.org/openstack/tacker/commit/6e7d28c6ed5648979dc1e4450dab7653d669e6ab', 'message': 'Fix some content of VNFD in UT and FT\n\nRecently tosca-parser has started to validate the required properties\nof policies [1]. In current implementation, this caused errors in\ntesting with VNFD where the policy definition was incorrect.\n\n[1] https://review.opendev.org/c/openstack/tosca-parser/+/763144\n\nThis patch fixed the policy type in the VNFD which errored with UT and\nFT, so that the VNFD can pass the enhanced policy type validation\nprocessing in tosca-parser.\n\nCloses-Bug: #1909312\nChange-Id: I0b655d6ebce7c4dacb9cc9c0526aa702d1ac37db\n'}]",3,769083,6e7d28c6ed5648979dc1e4450dab7653d669e6ab,25,6,2,31821,,,0,"Fix some content of VNFD in UT and FT

Recently tosca-parser has started to validate the required properties
of policies [1]. In current implementation, this caused errors in
testing with VNFD where the policy definition was incorrect.

[1] https://review.opendev.org/c/openstack/tosca-parser/+/763144

This patch fixed the policy type in the VNFD which errored with UT and
FT, so that the VNFD can pass the enhanced policy type validation
processing in tosca-parser.

Closes-Bug: #1909312
Change-Id: I0b655d6ebce7c4dacb9cc9c0526aa702d1ac37db
",git fetch https://review.opendev.org/openstack/tacker refs/changes/83/769083/2 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/functional/vnfm/test_vnf_placement_policy.py', 'tacker/tests/etc/samples/etsi/nfv/sample_vnfpkg_no_meta_single_vnfd/vnfd_helloworld_single.yaml', 'tacker/tests/etc/samples/etsi/nfv/sample_vnf_package_csar_in_single_manifest_false_name/VNF.yaml', 'tacker/tests/etc/samples/etsi/nfv/sample_vnf_package_csar_manifest/VNF.yaml', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/test_tosca_vnfd_alarm_scale.yaml', 'tacker/tests/etc/samples/etsi/nfv/test_csar_utils_data/csar_without_flavour_info/Definitions/tosca_with_vdus.yaml', 'tacker/tests/etc/samples/etsi/nfv/test_csar_utils_data/csar_without_flavour_info_in_main_template/Definitions/main_tosca.yaml', 'tacker/tests/etc/samples/etsi/nfv/vnfpkgm3/vnfd_helloworld_single.yaml']",8,71cdc6d2a284819f865906bf26bbc019597ad552,bug/1909312, tosca.datatypes.nfv.ScaleInfo: derived_from: tosca.datatypes.Root description: Indicates for a given scaleAspect the corresponding scaleLevel properties: scale_level: type: integer description: The scale level for a particular aspect required: true constraints: - greater_or_equal: 0 tosca.datatypes.nfv.VirtualLinkBitrateLevel: derived_from: tosca.datatypes.Root description: Describes bitrate requirements applicable to the virtual link instantiated from a particicular VnfVirtualLink properties: bitrate_requirements: type: tosca.datatypes.nfv.LinkBitrateRequirements description: Virtual link bitrate requirements for an instantiation level or bitrate delta for a scaling step required: true ,,99,10
openstack%2Fpython-cinderclient~master~I7b4bc7b392b2192e0c832c4f0148546a5920b9e2,openstack/python-cinderclient,master,I7b4bc7b392b2192e0c832c4f0148546a5920b9e2,Update requirements and lower-constraints,MERGED,2020-12-10 20:43:45.000000000,2021-01-05 16:06:04.000000000,2021-01-05 16:04:42.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-10 20:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/62435315accbfa877982cd2ac89105e91e5f8e42', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}, {'number': 2, 'created': '2020-12-10 20:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/aaf5e4c92fa2fdd37cd80808e63e34c48257c1f1', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}, {'number': 3, 'created': '2020-12-10 23:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/65ad1cdd567ce33b5bc504983ff77fb68f23b2d3', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9. The exception is\njsonschema, whose lower limit less than cinder's in order to\nbe compatible with more versions of tempest.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}, {'number': 4, 'created': '2020-12-14 19:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/ebeb0bb3dfd34b881435061caa856f0f857e9a47', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9. The exceptions are\ncliff and jsonschema, whose lower limits are less than cinder's\nin order to be compatible with more versions of tempest.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}, {'number': 5, 'created': '2020-12-14 20:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2b2cc626260c3aeb473f064b15f64f850fb4a249', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9. The exceptions are\ncliff and jsonschema, whose lower limits are less than cinder's\nin order to be compatible with more versions of tempest.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}, {'number': 6, 'created': '2020-12-22 21:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d014933a04aac8f43d47c98a3c9324641abe5598', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9. Also increased the\nminimum version of tempest to the most recent release.\n\nAlso added indirect dependencies to test-requirements.txt in order\nto limit the number of versions considered by the resolver.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}, {'number': 7, 'created': '2020-12-23 13:04:39.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1abc1b5d404c523a696f7186bc4c4b6fc7407cad', 'message': ""Update requirements and lower-constraints\n\nSync the versions with cinder's, which were recently updated by\nI42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9. Also increased the\nminimum version of tempest to the most recent release.\n\nAlso added indirect dependencies to test-requirements.txt in order\nto limit the number of versions considered by the resolver.\n\nChange-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2\n""}]",5,766544,1abc1b5d404c523a696f7186bc4c4b6fc7407cad,35,4,7,21129,,,0,"Update requirements and lower-constraints

Sync the versions with cinder's, which were recently updated by
I42af21b1c4247d04d479f1fc1ecd6f9baac0cfc9. Also increased the
minimum version of tempest to the most recent release.

Also added indirect dependencies to test-requirements.txt in order
to limit the number of versions considered by the resolver.

Change-Id: I7b4bc7b392b2192e0c832c4f0148546a5920b9e2
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/44/766544/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,62435315accbfa877982cd2ac89105e91e5f8e42,update-l-c,cffi==1.14.2 cliff==3.4.0 cmd2==1.3.8 coverage==5.2.1 cryptography==3.1 ddt==1.4.1 debtcollector==2.2.0 doc8==0.8.1fasteners==0.14.1future==0.18.2 idna==2.10 iso8601==0.1.12 jsonschema==3.2.0 keystoneauth1==4.2.1netaddr==0.8.0 netifaces==0.10.9 oslo.concurrency==4.3.0 oslo.config==8.3.2 oslo.context==3.1.1 oslo.i18n==5.0.1 oslo.log==4.4.0 oslo.serialization==4.0.1 oslo.utils==4.7.0 paramiko==2.7.2 pbr==5.5.0pyasn1==0.4.8 pycparser==2.20pyparsing==2.4.7 pyperclip==1.8.0 python-dateutil==2.8.1python-subunit==1.4.0 pytz==2020.1 PyYAML==5.3.1 reno==3.2.0requests==2.23.0 rfc3986==1.4.0six==1.15.0 stestr==3.0.1 stevedore==3.2.2 tempest>=17.1.0testtools==2.4.0urllib3==1.25.10 wrapt==1.12.1,cffi==1.14.0 cliff==2.8.0 cmd2==0.8.0 coverage==4.0 cryptography==2.7 ddt==1.0.1 debtcollector==1.2.0 doc8==0.6.0fasteners==0.7.0future==0.16.0 idna==2.6 iso8601==0.1.11 jsonschema==2.6.0 keystoneauth1==3.4.0netaddr==0.7.18 netifaces==0.10.4 oslo.concurrency==3.25.0 oslo.config==5.2.0 oslo.context==2.19.2 oslo.i18n==3.15.3 oslo.log==3.36.0 oslo.serialization==2.18.0 oslo.utils==3.33.0 paramiko==2.0.0 pbr==2.0.0pyasn1==0.1.8 pycparser==2.18pyparsing==2.1.0 pyperclip==1.5.27 python-dateutil==2.5.3python-subunit==1.0.0 pytz==2013.6 PyYAML==3.13 reno==3.1.0requests==2.14.2 rfc3986==0.3.1six==1.10.0 stestr==1.0.0 stevedore==1.20.0 tempest==17.1.0testtools==2.2.0urllib3==1.21.1 wrapt==1.7.0,57,57
openstack%2Fneutron~stable%2Fussuri~I12857794f7b8219e90db547e77d835bdaa6cfa6f,openstack/neutron,stable/ussuri,I12857794f7b8219e90db547e77d835bdaa6cfa6f,Fix imports order in neutron.services.ovn_l3_plugin module,MERGED,2020-12-18 15:42:48.000000000,2021-01-05 15:58:25.000000000,2021-01-05 15:54:37.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 15:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8c5a0020cb07ba7d01c21bbd9786ff808f98ecc', 'message': 'Fix imports order in neutron.services.ovn_l3_plugin module\n\nTrivialFix\n\nConflicts:\n    neutron/services/ovn_l3/plugin.py\n\nChange-Id: I12857794f7b8219e90db547e77d835bdaa6cfa6f\n(cherry picked from commit c8f88f2ab6d3daaf85387e930140d2eda5d73fa5)\n'}, {'number': 2, 'created': '2020-12-21 10:20:37.000000000', 'files': ['neutron/services/ovn_l3/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e252634c787f7e917b9443f41cfec264ec55fb68', 'message': 'Fix imports order in neutron.services.ovn_l3_plugin module\n\nTrivialFix\n\nConflicts:\n    neutron/services/ovn_l3/plugin.py\n\nChange-Id: I12857794f7b8219e90db547e77d835bdaa6cfa6f\n(cherry picked from commit c8f88f2ab6d3daaf85387e930140d2eda5d73fa5)\n'}]",0,767821,e252634c787f7e917b9443f41cfec264ec55fb68,14,4,2,11975,,,0,"Fix imports order in neutron.services.ovn_l3_plugin module

TrivialFix

Conflicts:
    neutron/services/ovn_l3/plugin.py

Change-Id: I12857794f7b8219e90db547e77d835bdaa6cfa6f
(cherry picked from commit c8f88f2ab6d3daaf85387e930140d2eda5d73fa5)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/767821/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/ovn_l3/plugin.py'],1,a8c5a0020cb07ba7d01c21bbd9786ff808f98ecc,bug/1906311-stable/victoria-stable/ussuri,from neutron.db import dns_db from neutron.db import extraroute_dbfrom neutron.db import l3_gwmode_db from neutron.db.models import l3 as l3_modelsfrom neutron.quota import resource_registry,from neutron.db import dns_db from neutron.db import extraroute_db from neutron.db import l3_gwmode_db from neutron.db.models import l3 as l3_models from neutron.quota import resource_registry,5,6
openstack%2Ftripleo-heat-templates~stable%2Fstein~Ide6d85c233760fe20956a93144846cdcad4d3f2c,openstack/tripleo-heat-templates,stable/stein,Ide6d85c233760fe20956a93144846cdcad4d3f2c,Add new role parameters for cpu/ram/disk allocation ratio,ABANDONED,2020-12-24 05:04:23.000000000,2021-01-05 15:57:22.000000000,,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-24 05:04:23.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'deployment/nova/nova-base-puppet.yaml', 'releasenotes/notes/allocation_ratio-4a8ecf4cdf5fb7e2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/019ceb931b9045a353a8dd79525f620afb6e192c', 'message': 'Add new role parameters for cpu/ram/disk allocation ratio\n\nThis change adds three new role parameters `NovaCPUAllocationRatio`,\n`NovaRAMAllocationRatio` and `NovaDiskAllocationRatio` for\nconfiguring cpu_allocation_ratio, ram_allocation_ratio and\ndisk_allocation_ratio.\nThe default values for CPU and Disk allocation ratio are taken\nas 0.0 as it will be updated by update_available_resource method\nas mentioned in [1].\n[1] https://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/initial-allocation-ratios.html\n\nConflicts:\n\tdeployment/nova/nova-compute-container-puppet.yaml\n\n(cherry picked from commit 5066737451035de19383bf1f7a2afa5334d7d361)\nChange-Id: Ide6d85c233760fe20956a93144846cdcad4d3f2c\n'}]",1,768386,019ceb931b9045a353a8dd79525f620afb6e192c,10,6,1,27419,,,0,"Add new role parameters for cpu/ram/disk allocation ratio

This change adds three new role parameters `NovaCPUAllocationRatio`,
`NovaRAMAllocationRatio` and `NovaDiskAllocationRatio` for
configuring cpu_allocation_ratio, ram_allocation_ratio and
disk_allocation_ratio.
The default values for CPU and Disk allocation ratio are taken
as 0.0 as it will be updated by update_available_resource method
as mentioned in [1].
[1] https://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/initial-allocation-ratios.html

Conflicts:
	deployment/nova/nova-compute-container-puppet.yaml

(cherry picked from commit 5066737451035de19383bf1f7a2afa5334d7d361)
Change-Id: Ide6d85c233760fe20956a93144846cdcad4d3f2c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/768386/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'deployment/nova/nova-base-puppet.yaml', 'releasenotes/notes/allocation_ratio-4a8ecf4cdf5fb7e2.yaml']",3,019ceb931b9045a353a8dd79525f620afb6e192c,,"--- features: - | Add new role parameters `NovaCPUAllocationRatio`, `NovaRAMAllocationRatio` and `NovaDiskAllocationRatio` which allows to configure `cpu_allocation_ratio`, `ram_allocation_ratio` and `disk_allocation_ratio`. Default value for NovaCPUAllocationRatio is 0.0 Default value for NovaRAMAllocationRatio is 1.0 Default value for NovaDiskAllocationRatio is 0.0 The default values for CPU and Disk allocation ratio are taken 0.0 as mentioned in [1]. [1] https://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/initial-allocation-ratios.html ",,38,2
openstack%2Fblazar-specs~master~I9ffdd1f00af22f0ce5de11371041aecf4737ade2,openstack/blazar-specs,master,I9ffdd1f00af22f0ce5de11371041aecf4737ade2,remove unicode from code,MERGED,2021-01-05 09:14:42.000000000,2021-01-05 15:48:42.000000000,2021-01-05 15:46:37.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 09:14:42.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/blazar-specs/commit/e8615903e8a5cd0fa7fb48d8cc04bd9888552b89', 'message': 'remove unicode from code\n\nChange-Id: I9ffdd1f00af22f0ce5de11371041aecf4737ade2\n'}]",0,769267,e8615903e8a5cd0fa7fb48d8cc04bd9888552b89,7,2,1,32020,,,0,"remove unicode from code

Change-Id: I9ffdd1f00af22f0ce5de11371041aecf4737ade2
",git fetch https://review.opendev.org/openstack/blazar-specs refs/changes/67/769267/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,e8615903e8a5cd0fa7fb48d8cc04bd9888552b89,,"project = 'Blazar Specs' copyright = '2013-present, OpenStack Foundation' ('index', 'doc-blazar-specs.tex', 'Blazar Specs', 'OpenStack Foundation', 'manual', True), ('index', 'Blazar-specs', 'Blazar Specs', ['OpenStack Foundation'], 1) ('index', 'Blazar-specs', 'Blazar Specs', 'OpenStack Foundation',","project = u'Blazar Specs' copyright = u'2013-present, OpenStack Foundation' ('index', 'doc-blazar-specs.tex', u'Blazar Specs', u'OpenStack Foundation', 'manual', True), ('index', 'Blazar-specs', u'Blazar Specs', [u'OpenStack Foundation'], 1) ('index', 'Blazar-specs', u'Blazar Specs', u'OpenStack Foundation',",6,6
openstack%2Fkolla-ansible~stable%2Fvictoria~I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,openstack/kolla-ansible,stable/victoria,I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,Fix failure during Monasca Grafana upgrade,MERGED,2021-01-05 12:09:44.000000000,2021-01-05 15:35:13.000000000,2021-01-05 15:33:14.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 12:09:44.000000000', 'files': ['ansible/roles/monasca/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/996eeb2b7051b3b78e0f5930794e8b7352098d78', 'message': 'Fix failure during Monasca Grafana upgrade\n\nThe task ""Stopping all Monasca Grafana instances but the first node""\ncan fail with:\n\n    error while evaluating conditional (monasca_grafana_differs[\'result\']): \'dict object\' has no attribute \'result\'\n\nThis is fixed by running this task on the same set of hosts than the\ntask defining monasca_grafana_differs, i.e. groups[\'monasca-grafana\'].\n\nChange-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017\nCloses-Bug: #1907689\n(cherry picked from commit 39e75c308750ab4f259201b13a048f3fe0d3cc67)\n'}]",0,769331,996eeb2b7051b3b78e0f5930794e8b7352098d78,9,3,1,15197,,,0,"Fix failure during Monasca Grafana upgrade

The task ""Stopping all Monasca Grafana instances but the first node""
can fail with:

    error while evaluating conditional (monasca_grafana_differs['result']): 'dict object' has no attribute 'result'

This is fixed by running this task on the same set of hosts than the
task defining monasca_grafana_differs, i.e. groups['monasca-grafana'].

Change-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017
Closes-Bug: #1907689
(cherry picked from commit 39e75c308750ab4f259201b13a048f3fe0d3cc67)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/31/769331/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/monasca/tasks/upgrade.yml'],1,996eeb2b7051b3b78e0f5930794e8b7352098d78,bug/1907689-stable/victoria, - inventory_hostname in groups['monasca-grafana'],,1,0
openstack%2Fkolla-ansible~stable%2Ftrain~I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,openstack/kolla-ansible,stable/train,I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,Fix failure during Monasca Grafana upgrade,MERGED,2021-01-05 12:12:11.000000000,2021-01-05 15:34:55.000000000,2021-01-05 15:33:18.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 12:12:11.000000000', 'files': ['ansible/roles/monasca/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b38ccc2ac7119a934262d508da68b751a3c60778', 'message': 'Fix failure during Monasca Grafana upgrade\n\nThe task ""Stopping all Monasca Grafana instances but the first node""\ncan fail with:\n\n    error while evaluating conditional (monasca_grafana_differs[\'result\']): \'dict object\' has no attribute \'result\'\n\nThis is fixed by running this task on the same set of hosts than the\ntask defining monasca_grafana_differs, i.e. groups[\'monasca-grafana\'].\n\nChange-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017\nCloses-Bug: #1907689\n(cherry picked from commit 39e75c308750ab4f259201b13a048f3fe0d3cc67)\n'}]",0,769333,b38ccc2ac7119a934262d508da68b751a3c60778,8,3,1,15197,,,0,"Fix failure during Monasca Grafana upgrade

The task ""Stopping all Monasca Grafana instances but the first node""
can fail with:

    error while evaluating conditional (monasca_grafana_differs['result']): 'dict object' has no attribute 'result'

This is fixed by running this task on the same set of hosts than the
task defining monasca_grafana_differs, i.e. groups['monasca-grafana'].

Change-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017
Closes-Bug: #1907689
(cherry picked from commit 39e75c308750ab4f259201b13a048f3fe0d3cc67)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/33/769333/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/monasca/tasks/upgrade.yml'],1,b38ccc2ac7119a934262d508da68b751a3c60778,bug/1907689-stable/train, - inventory_hostname in groups['monasca-grafana'],,1,0
openstack%2Fkolla~master~Ic0f51563c37679e9bcc2ffe3d95e7b256403f975,openstack/kolla,master,Ic0f51563c37679e9bcc2ffe3d95e7b256403f975,Add maxscale image,ABANDONED,2020-11-22 13:56:01.000000000,2021-01-05 15:34:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-11-22 13:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cd7896bddbded30e4e914bc4ca037dde448594d9', 'message': 'Add maxscale image\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. Maxscale can\nalso do this work.\n\nThis patch is part/dependency of mysql HA rework\nin kolla-ansible.\n\nChange-Id: Ic0f51563c37679e9bcc2ffe3d95e7b256403f975\n'}, {'number': 2, 'created': '2020-11-22 19:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c987b0bba316e93f6c918015a15694938dcd67c7', 'message': 'Add maxscale image\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. Maxscale can\nalso do this work.\n\nThis patch is part/dependency of mysql HA rework\nin kolla-ansible.\n\nChange-Id: Ic0f51563c37679e9bcc2ffe3d95e7b256403f975\n'}, {'number': 3, 'created': '2020-11-23 08:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/721ea88194b1f17504c9d14e901bc255f4c525ae', 'message': 'Add maxscale image\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. Maxscale can\nalso do this work.\n\nThis patch is part/dependency of mysql HA rework\nin kolla-ansible.\n\nChange-Id: Ic0f51563c37679e9bcc2ffe3d95e7b256403f975\n'}, {'number': 4, 'created': '2020-11-23 11:59:28.000000000', 'files': ['docker/maxscale/extend_start.sh', 'docker/base/Dockerfile.j2', 'docker/base/maxscale.repo', 'kolla/template/repos.yaml', 'docker/maxscale/Dockerfile.j2', 'kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/83ce8fe888a3be047f4ca325f04906a347651bc3', 'message': ""Add maxscale image\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. Maxscale can\nalso do this work.\n\nMoreover, maxscale is better because:\n  - It's not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nThis patch is part/dependency of mysql HA rework\nin kolla-ansible.\n\nChange-Id: Ic0f51563c37679e9bcc2ffe3d95e7b256403f975\n""}]",11,763634,83ce8fe888a3be047f4ca325f04906a347651bc3,30,4,4,27339,,,0,"Add maxscale image

Kolla environment currently using haproxy
to fullfill HA in mariadb. Maxscale can
also do this work.

Moreover, maxscale is better because:
  - It's not only TCP balancer as HAProxy.
  - It understands SQL protocol.
  - Can be configured in various ways.
  - Can be used as ShardRouter which is very
    usable when databases are on different group
    of servers.
  - Native monitoring of galera nodes.
  - User is able to apply filters to SQL queries
    on the fly, so it is very easy to analyze traffic.
  - Has very nice dashboard where are stats available
    per shards or per backends.
  - And tons of other features.

This patch is part/dependency of mysql HA rework
in kolla-ansible.

Change-Id: Ic0f51563c37679e9bcc2ffe3d95e7b256403f975
",git fetch https://review.opendev.org/openstack/kolla refs/changes/34/763634/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/maxscale/extend_start.sh', 'docker/base/Dockerfile.j2', 'docker/base/maxscale.repo', 'kolla/template/repos.yaml', 'docker/maxscale/Dockerfile.j2', 'kolla/common/config.py']",6,cd7896bddbded30e4e914bc4ca037dde448594d9,maxscale," 'maxscale', 'maxscale', }, 'maxscale-user': { 'uid': 42486, 'gid': 42486, },", },70,1
openstack%2Fkolla-ansible~master~I152ceb41876b2ae941b85f880ed51be91d6630c2,openstack/kolla-ansible,master,I152ceb41876b2ae941b85f880ed51be91d6630c2,Add service-db-setup role,ABANDONED,2020-12-17 08:40:45.000000000,2021-01-05 15:29:39.000000000,,"[{'_account_id': 22348}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-17 08:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b9e79b2c9e912c3364a5f25c4256b7f425a1b89f', 'message': 'Add service-db-setup role and switch mariadb to maxscale\n\nService-db-setup role is ensuring that DB stuff\nare created by correct way depends on whether\nmaxscale is used or not.\n\nThis patch is also switching mariadb to maxscale.\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nDepends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/766952\nDepends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/767370\n\nChange-Id: I152ceb41876b2ae941b85f880ed51be91d6630c2\n'}, {'number': 2, 'created': '2020-12-19 21:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f3e828475f080be62e45722eaff7a2c5e78334a7', 'message': 'Add service-db-setup role and switch mariadb to maxscale\n\nService-db-setup role is ensuring that DB stuff\nare created by correct way depends on whether\nmaxscale is used or not.\n\nThis patch is also switching mariadb to maxscale.\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\n\nChange-Id: I152ceb41876b2ae941b85f880ed51be91d6630c2\n'}, {'number': 3, 'created': '2020-12-19 21:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2c70fdc829b66600a8f68ff11bf251e55cee5c67', 'message': ""Add service-db-setup role and switch mariadb to maxscale\n\nService-db-setup role is ensuring that DB stuff\nare created by correct way depends on whether\nmaxscale is used or not.\n\nThis patch is also switching mariadb's HA solution\nfrom haproxy to maxscale.\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\n\nChange-Id: I152ceb41876b2ae941b85f880ed51be91d6630c2\n""}, {'number': 4, 'created': '2020-12-21 08:51:48.000000000', 'files': ['ansible/roles/rally/defaults/main.yml', 'ansible/roles/nova-cell/defaults/main.yml', 'ansible/roles/horizon/defaults/main.yml', 'ansible/roles/zun/tasks/bootstrap.yml', 'ansible/roles/service-db-setup/tasks/main.yml', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/murano/tasks/bootstrap.yml', 'ansible/roles/solum/tasks/bootstrap.yml', 'ansible/roles/glance/tasks/bootstrap.yml', 'ansible/roles/cinder/defaults/main.yml', 'ansible/roles/grafana/tasks/bootstrap.yml', 'ansible/roles/blazar/tasks/bootstrap.yml', 'ansible/roles/cinder/tasks/bootstrap.yml', 'ansible/roles/cloudkitty/defaults/main.yml', 'ansible/roles/karbor/tasks/bootstrap.yml', 'ansible/roles/blazar/defaults/main.yml', 'ansible/roles/sahara/tasks/bootstrap.yml', 'ansible/roles/solum/defaults/main.yml', 'ansible/roles/senlin/tasks/bootstrap.yml', 'ansible/roles/mistral/tasks/bootstrap.yml', 'ansible/roles/gnocchi/tasks/bootstrap.yml', 'ansible/roles/murano/defaults/main.yml', 'ansible/roles/nova-cell/tasks/bootstrap.yml', 'ansible/roles/grafana/defaults/main.yml', 'ansible/roles/sahara/defaults/main.yml', 'ansible/roles/barbican/defaults/main.yml', 'ansible/roles/trove/defaults/main.yml', 'ansible/roles/manila/tasks/bootstrap.yml', 'ansible/roles/barbican/tasks/bootstrap.yml', 'ansible/roles/cloudkitty/tasks/bootstrap.yml', 'ansible/roles/freezer/tasks/bootstrap.yml', 'ansible/roles/aodh/defaults/main.yml', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/heat/tasks/bootstrap.yml', 'ansible/roles/magnum/defaults/main.yml', 'ansible/roles/keystone/tasks/bootstrap.yml', 'ansible/roles/vitrage/tasks/bootstrap.yml', 'ansible/roles/zun/defaults/main.yml', 'ansible/roles/watcher/defaults/main.yml', 'ansible/roles/mistral/defaults/main.yml', 'ansible/roles/designate/tasks/bootstrap.yml', 'ansible/roles/freezer/defaults/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/roles/neutron/tasks/bootstrap.yml', 'ansible/roles/aodh/tasks/bootstrap.yml', 'ansible/roles/octavia/tasks/bootstrap.yml', 'ansible/roles/manila/defaults/main.yml', 'ansible/roles/cyborg/defaults/main.yml', 'ansible/roles/placement/tasks/bootstrap.yml', 'ansible/roles/placement/defaults/main.yml', 'ansible/roles/cyborg/tasks/bootstrap.yml', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/masakari/tasks/bootstrap.yml', 'ansible/roles/panko/tasks/bootstrap.yml', 'ansible/roles/magnum/tasks/bootstrap.yml', 'ansible/roles/senlin/defaults/main.yml', 'ansible/roles/designate/defaults/main.yml', 'ansible/roles/nova/tasks/bootstrap.yml', 'ansible/roles/karbor/defaults/main.yml', 'ansible/roles/vitrage/defaults/main.yml', 'ansible/roles/tacker/defaults/main.yml', 'ansible/roles/trove/tasks/bootstrap.yml', 'ansible/roles/tacker/tasks/bootstrap.yml', 'ansible/roles/watcher/tasks/bootstrap.yml', 'ansible/roles/horizon/tasks/bootstrap.yml', 'ansible/roles/gnocchi/defaults/main.yml', 'ansible/roles/masakari/defaults/main.yml', 'ansible/roles/octavia/defaults/main.yml', 'ansible/roles/panko/defaults/main.yml', 'ansible/roles/rally/tasks/bootstrap.yml', 'ansible/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/eae2ca4da852ae9ec33ecc7daa30ce188b4b5ac6', 'message': 'Add service-db-setup role\n\nService-db-setup role is ensuring that DB stuff\nare created by correct way depends on whether\nmaxscale is used or not.\n\nIf haproxy is used, nothing changed and resources\nare created against VIP endpoint, otherwise they\nare created against unix socket in kolla_toolbox.\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\n\nChange-Id: I152ceb41876b2ae941b85f880ed51be91d6630c2\n'}]",0,767475,eae2ca4da852ae9ec33ecc7daa30ce188b4b5ac6,17,2,4,27339,,,0,"Add service-db-setup role

Service-db-setup role is ensuring that DB stuff
are created by correct way depends on whether
maxscale is used or not.

If haproxy is used, nothing changed and resources
are created against VIP endpoint, otherwise they
are created against unix socket in kolla_toolbox.

Depends-On: https://review.opendev.org/c/openstack/kolla/+/763634
Depends-On: https://review.opendev.org/c/openstack/kolla/+/765781

Change-Id: I152ceb41876b2ae941b85f880ed51be91d6630c2
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/75/767475/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rally/defaults/main.yml', 'ansible/roles/nova-cell/defaults/main.yml', 'ansible/roles/horizon/defaults/main.yml', 'ansible/roles/zun/tasks/bootstrap.yml', 'ansible/roles/service-db-setup/tasks/main.yml', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/murano/tasks/bootstrap.yml', 'ansible/roles/solum/tasks/bootstrap.yml', 'ansible/roles/glance/tasks/bootstrap.yml', 'ansible/roles/cinder/defaults/main.yml', 'ansible/roles/grafana/tasks/bootstrap.yml', 'ansible/roles/blazar/tasks/bootstrap.yml', 'ansible/roles/cinder/tasks/bootstrap.yml', 'ansible/roles/cloudkitty/defaults/main.yml', 'ansible/roles/karbor/tasks/bootstrap.yml', 'ansible/roles/blazar/defaults/main.yml', 'ansible/roles/sahara/tasks/bootstrap.yml', 'ansible/roles/solum/defaults/main.yml', 'ansible/roles/senlin/tasks/bootstrap.yml', 'ansible/roles/mistral/tasks/bootstrap.yml', 'etc/kolla/globals.yml', 'ansible/roles/gnocchi/tasks/bootstrap.yml', 'ansible/roles/murano/defaults/main.yml', 'ansible/roles/nova-cell/tasks/bootstrap.yml', 'ansible/roles/grafana/defaults/main.yml', 'ansible/roles/sahara/defaults/main.yml', 'ansible/roles/barbican/defaults/main.yml', 'ansible/roles/trove/defaults/main.yml', 'ansible/roles/manila/tasks/bootstrap.yml', 'ansible/roles/barbican/tasks/bootstrap.yml', 'ansible/roles/qinling/tasks/bootstrap.yml', 'ansible/roles/qinling/defaults/main.yml', 'ansible/roles/cloudkitty/tasks/bootstrap.yml', 'ansible/roles/freezer/tasks/bootstrap.yml', 'ansible/roles/aodh/defaults/main.yml', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/heat/tasks/bootstrap.yml', 'ansible/roles/magnum/defaults/main.yml', 'ansible/roles/keystone/tasks/bootstrap.yml', 'ansible/roles/vitrage/tasks/bootstrap.yml', 'ansible/roles/zun/defaults/main.yml', 'ansible/roles/watcher/defaults/main.yml', 'ansible/roles/mistral/defaults/main.yml', 'ansible/roles/designate/tasks/bootstrap.yml', 'ansible/roles/freezer/defaults/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/roles/neutron/tasks/bootstrap.yml', 'ansible/roles/aodh/tasks/bootstrap.yml', 'ansible/roles/octavia/tasks/bootstrap.yml', 'ansible/roles/manila/defaults/main.yml', 'ansible/roles/cyborg/defaults/main.yml', 'ansible/roles/placement/tasks/bootstrap.yml', 'ansible/roles/placement/defaults/main.yml', 'ansible/roles/cyborg/tasks/bootstrap.yml', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/masakari/tasks/bootstrap.yml', 'ansible/roles/panko/tasks/bootstrap.yml', 'ansible/roles/magnum/tasks/bootstrap.yml', 'ansible/roles/senlin/defaults/main.yml', 'ansible/roles/common/defaults/main.yml', 'ansible/roles/designate/defaults/main.yml', 'ansible/roles/nova/tasks/bootstrap.yml', 'ansible/roles/karbor/defaults/main.yml', 'ansible/roles/vitrage/defaults/main.yml', 'ansible/roles/tacker/defaults/main.yml', 'ansible/roles/trove/tasks/bootstrap.yml', 'ansible/roles/tacker/tasks/bootstrap.yml', 'ansible/roles/watcher/tasks/bootstrap.yml', 'ansible/roles/horizon/tasks/bootstrap.yml', 'ansible/roles/gnocchi/defaults/main.yml', 'ansible/roles/masakari/defaults/main.yml', 'ansible/roles/octavia/defaults/main.yml', 'ansible/roles/panko/defaults/main.yml', 'ansible/roles/rally/tasks/bootstrap.yml', 'ansible/group_vars/all.yml']",76,b9e79b2c9e912c3364a5f25c4256b7f425a1b89f,maxscale,"maxscale_admin_port: ""8990"" enable_loadbalancer: ""{{ enable_haproxy | bool or enable_maxscale | bool }}""enable_maxscale: ""no"" #################### # Database sharding #################### aodh_database_shard: ""default"" barbican_database_shard: ""default"" blazar_database_shard: ""default"" cinder_database_shard: ""default"" cloudkitty_database_shard: ""default"" cyborg_database_shard: ""default"" designate_database_shard: ""default"" freezer_database_shard: ""default"" glance_database_shard: ""default"" gnocchi_database_shard: ""default"" grafana_database_shard: ""default"" heat_database_shard: ""default"" horizon_database_shard: ""default"" karbor_database_shard: ""default"" keystone_database_shard: ""default"" magnum_database_shard: ""default"" manila_database_shard: ""default"" masakari_database_shard: ""default"" mistral_database_shard: ""default"" murano_database_shard: ""default"" neutron_database_shard: ""default"" nova_database_shard: ""default"" nova_cell_database_shard: ""default"" octavia_database_shard: ""default"" panko_database_shard: ""default"" placement_database_shard: ""default"" qinling_database_shard: ""default"" rally_database_shard: ""default"" sahara_database_shard: ""default"" senlin_database_shard: ""default"" solum_database_shard: ""default"" tacker_database_shard: ""default"" trove_database_shard: ""default"" vitrage_database_shard: ""default"" watcher_database_shard: ""default"" zun_database_shard: ""default""",,955,1216
openstack%2Fkolla-ansible~master~I2c7b88f49b38ae009807b54a8607a4e8b1a98986,openstack/kolla-ansible,master,I2c7b88f49b38ae009807b54a8607a4e8b1a98986,Add maxscale support for database,ABANDONED,2020-12-16 15:35:44.000000000,2021-01-05 15:28:47.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-16 15:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a6406f34964a3d80126a18c0d9f2d02162403ce9', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n2. role/haproxy:\n     - Rename haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 2, 'created': '2020-12-16 15:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4692a77d0cf1701bd5295e92aae9887d94c67adf', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 3, 'created': '2020-12-16 16:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/097baeaa441cc1b261e0bc5766d743ebc9b90900', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 4, 'created': '2020-12-16 17:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/558ad6d769042d4a354435c12f2b252286af29c7', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 5, 'created': '2020-12-16 22:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a4a3b7643b4a3e80809cc7d212b09e2bed127353', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 6, 'created': '2020-12-17 07:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/15a0d52c34c49978b01dcebc7bbfeb2d37a12621', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 7, 'created': '2020-12-17 08:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e29a8b8ac181ef4215abf0f5201504cba04cd095', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 8, 'created': '2020-12-17 10:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/563ed57a8830919278e8ff7056efe8682606d97e', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers.\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 9, 'created': '2020-12-18 09:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d2011de57d9887fa6aa93cc1f053715ac2747f84', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers. (this was main idea to implement\n                 this patch)\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale to group loadbalancer.\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers. (Rework handlers from restart to start,stop\n                      because there could be race condition while\n                      haproxy switching to maxscale and port 3306\n                      still listening)\n     - Set default admin password for maxsacle configurable\n       via passwords.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 10, 'created': '2020-12-19 19:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/dd193cba67bd5da0eee740e6c2dbde61484646be', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers. (this was main idea to implement\n                 this patch)\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale to group loadbalancer.\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers. (Rework handlers from restart to start,stop\n                      because there could be race condition while\n                      haproxy switching to maxscale and port 3306\n                      still listening)\n     - Set default admin password for maxsacle configurable\n       via passwords.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 11, 'created': '2020-12-19 21:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/906470f1db070fd1d6217002275f0c252982d168', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers. (this was main idea to implement\n                 this patch)\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale to group loadbalancer.\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers. (Rework handlers from restart to start,stop\n                      because there could be race condition while\n                      haproxy switching to maxscale and port 3306\n                      still listening)\n     - Set default admin password for maxsacle configurable\n       via passwords.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}, {'number': 12, 'created': '2020-12-19 21:50:22.000000000', 'files': ['ansible/inventory/multinode', 'ansible/roles/loadbalancer/tasks/check-containers.yml', 'ansible/roles/loadbalancer/handlers/main.yml', 'ansible/roles/loadbalancer/tasks/pull.yml', 'ansible/roles/loadbalancer/templates/check_alive_maxscale.sh.j2', 'ansible/roles/loadbalancer/templates/maxscale.json.j2', 'ansible/roles/prechecks/tasks/database_checks.yml', 'ansible/roles/haproxy/handlers/main.yml', 'ansible/site.yml', 'ansible/roles/loadbalancer/templates/check_alive_haproxy.sh.j2', 'ansible/roles/haproxy/defaults/main.yml', 'ansible/inventory/all-in-one', 'ansible/roles/loadbalancer/templates/maxscale.cnf.j2', 'ansible/roles/loadbalancer/tasks/check.yml', 'ansible/roles/loadbalancer/templates/keepalived.json.j2', 'ansible/roles/loadbalancer/templates/haproxy_run.sh.j2', 'etc/kolla/globals.yml', 'ansible/roles/loadbalancer/tasks/deploy.yml', 'ansible/roles/loadbalancer/defaults/main.yml', 'ansible/roles/loadbalancer/tasks/deploy-containers.yml', 'ansible/roles/loadbalancer/tasks/copy-certs.yml', 'ansible/roles/loadbalancer/tasks/config-host.yml', 'ansible/roles/loadbalancer/tasks/precheck.yml', 'ansible/roles/loadbalancer/tasks/reconfigure.yml', 'ansible/roles/common/defaults/main.yml', 'ansible/roles/telegraf/templates/telegraf.conf.j2', 'etc/kolla/passwords.yml', 'ansible/roles/loadbalancer/tasks/upgrade.yml', 'ansible/roles/mariadb/tasks/loadbalancer.yml', 'ansible/roles/haproxy/tasks/main.yml', 'ansible/roles/haproxy/tasks/config.yml', 'ansible/roles/loadbalancer/templates/keepalived.conf.j2', 'ansible/roles/loadbalancer/templates/maxscale_run.sh.j2', 'ansible/roles/loadbalancer/templates/haproxy_main.cfg.j2', 'ansible/roles/loadbalancer/tasks/config.yml', 'ansible/group_vars/all.yml', 'ansible/roles/loadbalancer/tasks/main.yml', 'ansible/roles/loadbalancer/tasks/stop.yml', 'tests/templates/inventory.j2', 'ansible/roles/loadbalancer/templates/haproxy.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/64e78353357afda8eeeede578edca72df1e6e3a6', 'message': 'Add maxscale support for database\n\nKolla environment currently using haproxy\nto fullfill HA in mariadb. This patch\nis switching haproxy to maxscale if enabled.\n\nWhy is it better to use MaxScale instead of haproxy ?\n\nMaxscale is better because:\n  - It\'s not only TCP balancer as HAProxy.\n  - It understands SQL protocol.\n  - Can be configured in various ways.\n  - Can be used as ShardRouter which is very\n    usable when databases are on different group\n    of servers. (this was main idea to implement\n                 this patch)\n  - Native monitoring of galera nodes.\n  - User is able to apply filters to SQL queries\n    on the fly, so it is very easy to analyze traffic.\n  - Has very nice dashboard where are stats available\n    per shards or per backends.\n  - And tons of other features.\n\nSummary of changes:\n\n1. role/haproxy:\n     - Rename role/haproxy because it currently install ""loadbalancer""\n       services - keepalived, haproxy, maxscale to group loadbalancer.\n     - Add maxscale container if enable_maxscale: ""yes"".\n     - Copy/remove checks for maxscale/haproxy to keepalived container.\n     - Ensure that haproxy/maxscale is switched properly\n       via handlers. (Rework handlers from restart to start,stop\n                      because there could be race condition while\n                      haproxy switching to maxscale and port 3306\n                      still listening)\n     - Set default admin password for maxsacle configurable\n       via passwords.\n     - Render config for maxscale and start\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/763634\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/765781\nChange-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986\n'}]",0,767370,64e78353357afda8eeeede578edca72df1e6e3a6,38,5,12,27339,,,0,"Add maxscale support for database

Kolla environment currently using haproxy
to fullfill HA in mariadb. This patch
is switching haproxy to maxscale if enabled.

Why is it better to use MaxScale instead of haproxy ?

Maxscale is better because:
  - It's not only TCP balancer as HAProxy.
  - It understands SQL protocol.
  - Can be configured in various ways.
  - Can be used as ShardRouter which is very
    usable when databases are on different group
    of servers. (this was main idea to implement
                 this patch)
  - Native monitoring of galera nodes.
  - User is able to apply filters to SQL queries
    on the fly, so it is very easy to analyze traffic.
  - Has very nice dashboard where are stats available
    per shards or per backends.
  - And tons of other features.

Summary of changes:

1. role/haproxy:
     - Rename role/haproxy because it currently install ""loadbalancer""
       services - keepalived, haproxy, maxscale to group loadbalancer.
     - Add maxscale container if enable_maxscale: ""yes"".
     - Copy/remove checks for maxscale/haproxy to keepalived container.
     - Ensure that haproxy/maxscale is switched properly
       via handlers. (Rework handlers from restart to start,stop
                      because there could be race condition while
                      haproxy switching to maxscale and port 3306
                      still listening)
     - Set default admin password for maxsacle configurable
       via passwords.
     - Render config for maxscale and start

Depends-On: https://review.opendev.org/c/openstack/kolla/+/763634
Depends-On: https://review.opendev.org/c/openstack/kolla/+/765781
Change-Id: I2c7b88f49b38ae009807b54a8607a4e8b1a98986
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/70/767370/10 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/inventory/multinode', 'ansible/roles/loadbalancer/tasks/check-containers.yml', 'ansible/roles/loadbalancer/handlers/main.yml', 'ansible/roles/loadbalancer/tasks/pull.yml', 'ansible/roles/loadbalancer/templates/check_alive_maxscale.sh.j2', 'ansible/roles/loadbalancer/templates/maxscale.json.j2', 'ansible/roles/haproxy/handlers/main.yml', 'ansible/site.yml', 'ansible/roles/loadbalancer/templates/check_alive_haproxy.sh.j2', 'ansible/roles/haproxy/defaults/main.yml', 'ansible/inventory/all-in-one', 'ansible/roles/loadbalancer/templates/maxscale.cnf.j2', 'ansible/roles/loadbalancer/tasks/check.yml', 'ansible/roles/loadbalancer/templates/keepalived.json.j2', 'ansible/roles/loadbalancer/templates/haproxy_run.sh.j2', 'etc/kolla/globals.yml', 'ansible/roles/loadbalancer/tasks/deploy.yml', 'ansible/roles/loadbalancer/defaults/main.yml', 'ansible/roles/loadbalancer/tasks/deploy-containers.yml', 'ansible/roles/loadbalancer/tasks/copy-certs.yml', 'ansible/roles/loadbalancer/tasks/config-host.yml', 'ansible/roles/loadbalancer/tasks/precheck.yml', 'ansible/roles/loadbalancer/tasks/reconfigure.yml', 'ansible/roles/common/defaults/main.yml', 'etc/kolla/passwords.yml', 'ansible/roles/loadbalancer/tasks/upgrade.yml', 'ansible/roles/mariadb/tasks/loadbalancer.yml', 'ansible/roles/haproxy/tasks/config.yml', 'ansible/roles/loadbalancer/templates/keepalived.conf.j2', 'ansible/roles/loadbalancer/templates/maxscale_run.sh.j2', 'ansible/roles/loadbalancer/templates/haproxy_main.cfg.j2', 'ansible/roles/loadbalancer/tasks/config.yml', 'ansible/group_vars/all.yml', 'ansible/roles/loadbalancer/tasks/main.yml', 'ansible/roles/loadbalancer/tasks/stop.yml', 'ansible/roles/loadbalancer/templates/haproxy.json.j2']",36,a6406f34964a3d80126a18c0d9f2d02162403ce9,maxscale,,,933,414
openstack%2Fkuryr-kubernetes~master~I3a7b7dcd46cb5efa747d72517b5c26560db698af,openstack/kuryr-kubernetes,master,I3a7b7dcd46cb5efa747d72517b5c26560db698af,Fix OVN gates,MERGED,2021-01-04 19:09:42.000000000,2021-01-05 15:24:50.000000000,2021-01-05 15:18:25.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2021-01-04 19:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c74d37383b7181991df79ff6532af3f4647ed01e', 'message': 'Fix OVN gates\n\nA new setting was recently introduced[1] for OVN\nOVN_BUILD_FROM_SOURCE allowing to use the packaged\nversion. The value of OVS_RUNDIR changes accordingly\nthat setting, we needs to make sure ovs will always\nbe ran on same path to avoid database connection failures.\n\n[1] https://github.com/openstack/devstack/\n    commit/e651d9ef8840bb7dd497b557125ce1cd5290993d\n\nChange-Id: I3a7b7dcd46cb5efa747d72517b5c26560db698af\n'}, {'number': 2, 'created': '2021-01-04 22:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2aeeffe4c40ccd7fc4d3595a763e7bd2b47b3e35', 'message': 'Fix OVN gates\n\nA new Devstack setting was recently introduced[1] for OVN\nOVN_BUILD_FROM_SOURCE allowing to use the packaged\nversion when set to False. The value of OVS_RUNDIR\nchanges accordingly that setting, so we needs to make sure\novs will always run on same path to avoid database\nconnection failures.\n\n[1] https://github.com/openstack/devstack/\n    commit/e651d9ef8840bb7dd497b557125ce1cd5290993d\n\nChange-Id: I3a7b7dcd46cb5efa747d72517b5c26560db698af\n'}, {'number': 3, 'created': '2021-01-04 22:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/0220defb125cbf37d1947cd5bc5d1ede0936feac', 'message': 'Fix OVN gates\n\nA new Devstack setting was recently introduced[1] for OVN\nOVN_BUILD_FROM_SOURCE allowing to use the packaged\nversion when set to False. The value of OVS_RUNDIR\nchanges accordingly that setting, so we needs to make sure\novs will always run on same path to avoid database\nconnection failures.\n\n[1] https://github.com/openstack/devstack/\n    commit/e651d9ef8840bb7dd497b557125ce1cd5290993d\n\nChange-Id: I3a7b7dcd46cb5efa747d72517b5c26560db698af\n'}, {'number': 4, 'created': '2021-01-05 11:12:57.000000000', 'files': ['devstack/local.conf.ovn.sample', '.zuul.d/sdn.yaml'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c68a6fe1e7877fb56935d67ca16249a3f8a8b386', 'message': 'Fix OVN gates\n\nA new Devstack setting was recently introduced[1] for OVN\nOVN_BUILD_FROM_SOURCE allowing to use the packaged\nversion when set to False. The value of OVS_RUNDIR\nchanges accordingly that setting, so we needs to make sure\novs will always run on same path to avoid database\nconnection failures.\n\n[1] https://github.com/openstack/devstack/\n    commit/e651d9ef8840bb7dd497b557125ce1cd5290993d\n\nChange-Id: I3a7b7dcd46cb5efa747d72517b5c26560db698af\n'}]",3,769206,c68a6fe1e7877fb56935d67ca16249a3f8a8b386,17,4,4,27032,,,0,"Fix OVN gates

A new Devstack setting was recently introduced[1] for OVN
OVN_BUILD_FROM_SOURCE allowing to use the packaged
version when set to False. The value of OVS_RUNDIR
changes accordingly that setting, so we needs to make sure
ovs will always run on same path to avoid database
connection failures.

[1] https://github.com/openstack/devstack/
    commit/e651d9ef8840bb7dd497b557125ce1cd5290993d

Change-Id: I3a7b7dcd46cb5efa747d72517b5c26560db698af
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/06/769206/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/sdn.yaml'],1,c74d37383b7181991df79ff6532af3f4647ed01e,fix-ovn-gate, OVN_BUILD_FROM_SOURCE: true OVN_BUILD_FROM_SOURCE: true,,2,0
openstack%2Fblazar~master~I4224c142d7481a79d4cc5e704436a6002b0d884f,openstack/blazar,master,I4224c142d7481a79d4cc5e704436a6002b0d884f,Fix lower-constraints job,MERGED,2020-12-17 17:19:33.000000000,2021-01-05 15:17:58.000000000,2021-01-05 15:16:32.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 17:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/abae4e2fbb292d8417ac8b7a8cf2c26f6640115c', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 2, 'created': '2020-12-17 17:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/8438a7a0c69af5b903e2dcbb27d341b735467d88', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 3, 'created': '2020-12-17 17:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/aaab9baa3c7e037aa5319fe10d73bd37d1782c62', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 4, 'created': '2021-01-04 16:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/a66c1b9c74031e4ae42df3bf44efe91fff14837e', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 5, 'created': '2021-01-04 16:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/9807b4f31a133138d43c7182a0399bd8cefbbc28', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 6, 'created': '2021-01-04 17:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/e541c2ff6facb82959fcd5bec2ceb66989394657', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 7, 'created': '2021-01-04 17:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/f1f01a5a7e711d619ace73962ac7aaec927fee95', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 8, 'created': '2021-01-04 20:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/09a61d63c24aca77cf4371c899016a502d5f0508', 'message': '[DNM] Test lower-constraints job\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n'}, {'number': 9, 'created': '2021-01-05 09:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/718351feb951ed045660b2f9657a2c7aac0b7388', 'message': ""Fix lower-constraints job\n\n* Move upper constraints from install_command to testenv deps, so it\n  doesn't get inherited by the lower-constraints job. This was causing\n  the wrong set of constraints to be used.\n* Update MarkupSafe to 1.1.1 because of an incompatibility with recent\n  setuptools: https://github.com/pallets/markupsafe/issues/116\n* Update PyYAML to 5.1 to fix build on some platforms such as macOS\n* Update oslo.db to 4.40.0 to fix issues with async keyword:\n  https://opendev.org/openstack/oslo.db/commit/df6bf34\n* Update oslo.utils to 3.37.0 for uuidsentinel:\n  https://opendev.org/openstack/oslo.utils/commit/63d7649\n* Update kombu to 4.2.0 to fix issues with async:\n  https://github.com/celery/kombu/issues/841\n* Remove kombu from requirements since we are not using it directly\n* Update Flask to 1.0.2 due to various API changes\n* Update oslo.service to 1.34.0 for add_timer_args:\n  https://opendev.org/openstack/oslo.service/commit/750b51c\n* Update oslo.context to 2.21.0 for system_scope:\n  https://opendev.org/openstack/oslo.context/commit/1a40b3d\n* Move oslo.context from test-requirements to requirements since we are\n  also using it in non-test code\n* Update keystoneauth1 to 3.13.0 for rate_semaphore:\n  https://opendev.org/openstack/keystoneauth/commit/0993471\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n""}, {'number': 10, 'created': '2021-01-05 09:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/dace34e480d028e1b43ea686f001d4773665c93e', 'message': ""[DNM] Fix lower-constraints job\n\n* Move upper constraints from install_command to testenv deps, so it\n  doesn't get inherited by the lower-constraints job. This was causing\n  the wrong set of constraints to be used.\n* Update MarkupSafe to 1.1.1 because of an incompatibility with recent\n  setuptools: https://github.com/pallets/markupsafe/issues/116\n* Update PyYAML to 5.1 to fix build on some platforms such as macOS\n* Update oslo.db to 4.40.0 to fix issues with async keyword:\n  https://opendev.org/openstack/oslo.db/commit/df6bf34\n* Update oslo.utils to 3.37.0 for uuidsentinel:\n  https://opendev.org/openstack/oslo.utils/commit/63d7649\n* Update kombu to 4.2.0 to fix issues with async:\n  https://github.com/celery/kombu/issues/841\n* Remove kombu from requirements since we are not using it directly\n* Update Flask to 1.0.2 due to various API changes\n* Update oslo.service to 1.34.0 for add_timer_args:\n  https://opendev.org/openstack/oslo.service/commit/750b51c\n* Update oslo.context to 2.21.0 for system_scope:\n  https://opendev.org/openstack/oslo.context/commit/1a40b3d\n* Move oslo.context from test-requirements to requirements since we are\n  also using it in non-test code\n* Update keystoneauth1 to 3.13.0 for rate_semaphore:\n  https://opendev.org/openstack/keystoneauth/commit/0993471\n* Update alembic to 0.9.6: oslo-db 4.40.0 depends on alembic>=0.9.6\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n""}, {'number': 11, 'created': '2021-01-05 10:06:41.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar/commit/4f642c877f46646b22602ea495d9e265c7887c62', 'message': ""Fix lower-constraints job\n\n* Move upper constraints from install_command to testenv deps, so it\n  doesn't get inherited by the lower-constraints job. This was causing\n  the wrong set of constraints to be used.\n* Update MarkupSafe to 1.1.1 because of an incompatibility with recent\n  setuptools: https://github.com/pallets/markupsafe/issues/116\n* Update PyYAML to 5.1 to fix build on some platforms such as macOS\n* Update oslo.db to 4.40.0 to fix issues with async keyword:\n  https://opendev.org/openstack/oslo.db/commit/df6bf34\n* Update oslo.utils to 3.37.0 for uuidsentinel:\n  https://opendev.org/openstack/oslo.utils/commit/63d7649\n* Update kombu to 4.2.0 to fix issues with async:\n  https://github.com/celery/kombu/issues/841\n* Remove kombu from requirements since we are not using it directly\n* Update Flask to 1.0.2 due to various API changes\n* Update oslo.service to 1.34.0 for add_timer_args:\n  https://opendev.org/openstack/oslo.service/commit/750b51c\n* Update oslo.context to 2.21.0 for system_scope:\n  https://opendev.org/openstack/oslo.context/commit/1a40b3d\n* Move oslo.context from test-requirements to requirements since we are\n  also using it in non-test code\n* Update keystoneauth1 to 3.13.0 for rate_semaphore:\n  https://opendev.org/openstack/keystoneauth/commit/0993471\n* Update alembic to 0.9.6: oslo-db 4.40.0 depends on alembic>=0.9.6\n\nChange-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f\n""}]",0,767593,4f642c877f46646b22602ea495d9e265c7887c62,27,2,11,15197,,,0,"Fix lower-constraints job

* Move upper constraints from install_command to testenv deps, so it
  doesn't get inherited by the lower-constraints job. This was causing
  the wrong set of constraints to be used.
* Update MarkupSafe to 1.1.1 because of an incompatibility with recent
  setuptools: https://github.com/pallets/markupsafe/issues/116
* Update PyYAML to 5.1 to fix build on some platforms such as macOS
* Update oslo.db to 4.40.0 to fix issues with async keyword:
  https://opendev.org/openstack/oslo.db/commit/df6bf34
* Update oslo.utils to 3.37.0 for uuidsentinel:
  https://opendev.org/openstack/oslo.utils/commit/63d7649
* Update kombu to 4.2.0 to fix issues with async:
  https://github.com/celery/kombu/issues/841
* Remove kombu from requirements since we are not using it directly
* Update Flask to 1.0.2 due to various API changes
* Update oslo.service to 1.34.0 for add_timer_args:
  https://opendev.org/openstack/oslo.service/commit/750b51c
* Update oslo.context to 2.21.0 for system_scope:
  https://opendev.org/openstack/oslo.context/commit/1a40b3d
* Move oslo.context from test-requirements to requirements since we are
  also using it in non-test code
* Update keystoneauth1 to 3.13.0 for rate_semaphore:
  https://opendev.org/openstack/keystoneauth/commit/0993471
* Update alembic to 0.9.6: oslo-db 4.40.0 depends on alembic>=0.9.6

Change-Id: I4224c142d7481a79d4cc5e704436a6002b0d884f
",git fetch https://review.opendev.org/openstack/blazar refs/changes/93/767593/5 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,abae4e2fbb292d8417ac8b7a8cf2c26f6640115c,fix-lower-constraints, check: jobs: [] jobs: [], - check-requirements - openstack-cover-jobs - openstack-python3-wallaby-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 check: jobs: - blazar-tempest-plugin-base - blazar-tempest-plugin-ipv6-only - openstack-tox-pylint: voting: false jobs: - blazar-tempest-plugin-base - blazar-tempest-plugin-ipv6-only,2,13
openstack%2Fopenstack-ansible~master~I85e79bdee4dd2e24b369d9dd5bdcfb1b51611719,openstack/openstack-ansible,master,I85e79bdee4dd2e24b369d9dd5bdcfb1b51611719,Continue Wallaby release development,MERGED,2020-12-20 15:07:40.000000000,2021-01-05 14:01:38.000000000,2021-01-05 13:59:51.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-20 15:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6519fc3af7df30cc907e006f9afe04f170e56cda', 'message': 'Continue Wallaby release development\n\nDepends-On: https://review.opendev.org/768008\nChange-Id: I85e79bdee4dd2e24b369d9dd5bdcfb1b51611719\n'}, {'number': 2, 'created': '2020-12-20 15:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/458158e0bdb8b3e76dc533920f7d50ce82e1b3da', 'message': 'Continue Wallaby release development\n\nDepends-On: https://review.opendev.org/768008\nChange-Id: I85e79bdee4dd2e24b369d9dd5bdcfb1b51611719\n'}, {'number': 3, 'created': '2020-12-27 08:57:46.000000000', 'files': ['scripts/gate-check-commit.sh', 'releasenotes/source/victoria.rst', 'doc/source/conf.py', 'releasenotes/source/index.rst', 'deploy-guide/source/conf.py', 'ansible-role-requirements.yml', 'playbooks/defaults/repo_packages/openstack_services.yml', 'doc/source/index.rst', 'playbooks/os-tempest-install.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'scripts/run-upgrade.sh', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d7334fc7855cf7e399a0f2614ff055fbf4145e4e', 'message': 'Continue Wallaby release development\n\nDepends-On: https://review.opendev.org/768008\nChange-Id: I85e79bdee4dd2e24b369d9dd5bdcfb1b51611719\n'}]",0,768016,d7334fc7855cf7e399a0f2614ff055fbf4145e4e,22,3,3,28619,,,0,"Continue Wallaby release development

Depends-On: https://review.opendev.org/768008
Change-Id: I85e79bdee4dd2e24b369d9dd5bdcfb1b51611719
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/16/768016/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'doc/source/index.rst', 'playbooks/os-tempest-install.yml', 'scripts/gate-check-commit.sh', 'releasenotes/source/victoria.rst', 'doc/source/conf.py', 'releasenotes/source/index.rst', 'deploy-guide/source/conf.py', 'scripts/run-upgrade.sh', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml']",11,6519fc3af7df30cc907e006f9afe04f170e56cda,, version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master version: master version: master version: master version: master version: stable-5.0 version: master version: master version: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master version: master trackbranch: master, version: 4e44a54b95b76fec380d1bbdf82a939b025a128d trackbranch: stable/victoria version: 479d188c29bf9ca6b2b7500c13f5f695f8008ee6 trackbranch: stable/victoria version: a6347c381154deab33aca49188bea1992dc179ce trackbranch: stable/victoria version: 0b853b1da7802f6fac8da309c88886186f6a15a6 trackbranch: stable/victoria version: f0c208fcb2383a190622a000ce0fa9f40becea02 trackbranch: stable/victoria version: ca2c011cf23a4bcdf469b6c9d07f6956204448dd trackbranch: stable/victoria version: 399654cc70d58bc60376f7dd4eb9d0e8db2605d8 version: b4d4f858bb29e297ece13c307ece71441aff5a23 trackbranch: stable/victoria version: b3bff3289ac2e9510be81f562f6d35500ac47723 trackbranch: stable/victoria version: 2bb11b1b1baceb19f465d7c387db6d18c3592317 trackbranch: stable/victoria version: 8ab8503a15ad5cfe504777647922be301ddac911 trackbranch: stable/victoria version: f1625b38a820dd51cffa66141053a836211695dc trackbranch: stable/victoria version: 242772e99978fe9cd3c50b5b40d5637833f38beb trackbranch: stable/victoria version: 8a4c92ee7eb22aa4d9511760970bb11453a49736 trackbranch: stable/victoria version: 13ef8fa191c283c4f85579b1b7a5f884594119af trackbranch: stable/victoria version: ddf65cdc3ef44b534cbbb713ae5228368ec31855 trackbranch: stable/victoria version: 740806fa1dc4a12c4a75b31c93ce6125b5627e38 trackbranch: stable/victoria version: 6df1fb0fc5610c2f317b5085188b0a60346e7111 trackbranch: stable/victoria version: 00a38c6584c09168faad135f10d265ad9c86efba trackbranch: stable/victoria version: 26f5180a9a2462acde8d65156b09521060e40852 trackbranch: stable/victoria version: 2e553218499594e02602f51b9b5cfdeab79f9cb5 trackbranch: stable/victoria version: 7c9b4258fa6f9288fff25b219e88cb0c9ddfb3c0 trackbranch: stable/victoria version: b73d93efd095b94f3983ff7f3a057deadcededb3 trackbranch: stable/victoria version: 7d14b4e76b2e1b73654f8bfd5b498dfca5954aa5 trackbranch: stable/victoria version: 8e3570e0020168afafd4279f27fd6640cca07b7f trackbranch: stable/victoria version: 67733c8f0cb13c467eb10f256a93d878c56d4743 trackbranch: stable/victoria version: 2ba7654fe687ec680f71cc96970e42de41937cd4 trackbranch: stable/victoria version: dfc29c7bac76f4523e6fb29138629d4212d40266 trackbranch: stable/victoria version: 9cd72c1ad374bb6b6bc113d797d72c9aa44e1e22 trackbranch: stable/victoria version: fc31f37f696ed27d6b2bd0c3cb3c9220d460f917 trackbranch: stable/victoria version: 5e0a408fdb89ff2d5a0fe890230e083113e89451 trackbranch: stable/victoria version: 98b3af136a05b79b49c19407b940223430260eef trackbranch: stable/victoria version: 43b1b62f22b47e3148adcc4cd2396a4e29522e9b trackbranch: stable/victoria version: 3f7a572ebeae9ee76679c0cecb4ffaa0fa552fc3 trackbranch: stable/victoria version: 518112a014c0784106accd5ea27f27fd901351ea trackbranch: stable/victoria version: bf42c4a4038d7743df5134f41f803f26c3cdbd90 trackbranch: stable/victoria version: 77944eef30ac0a248743e4c0edc6f2773cf7100e trackbranch: stable/victoria version: 0f9e76292461a5532f6d43927b71ab9fff692dd5 trackbranch: stable/victoria version: 34105b0a94a0ad4148a4a9a0dc26aa304b354de6 trackbranch: stable/victoria version: 58e003f44e1dba26c5fa8457cd1a41c88a1a2bb9 trackbranch: stable/victoria version: e971939b55f1d9aeaeb04b030d72397b6dcaf2ed trackbranch: stable/victoria version: 49004fb05fa491275848a07020a36d4264ab6d49 trackbranch: stable/victoria version: f37cb8868032b86fbc6aa843321c00b10441eafd trackbranch: stable/victoria version: 07d78458207156378406db2f8cb7a6140c047b47 trackbranch: stable/victoria version: 0b2981a5b59d95302315a89b2dfc65badf618e65 trackbranch: stable/victoria version: 2b7b2ada9fc0ce7c0ca5508f6432627dc70edbac trackbranch: stable/victoria version: e93b7e3477c1e1d6767c447211bb70dbe023e3a8 trackbranch: stable/victoria version: 64c683aa13c509c7b030069388d98706f4644726 trackbranch: stable/victoria version: d616af7883bd6e7a208be3a4f56d129bc2aa92ca trackbranch: stable/victoria version: d52263304292da2f207f4368625ac44c89f89521 trackbranch: stable/victoria version: 61587d5d88ce98deed989ab702af84bff0f037bf version: 9e5a7d7fc8b72ad4aa73280a7638b0554cf20d5c version: ab9861e35c23342fa30c703d29e370da590ea582 version: f8e2d8a89ddb9352d5748332a5f3a33ed33f66ab version: a2ff5ba59b47f96ddddcb7a3a67de93687c317a6 version: 7d088320df1c4a6ed458866c61616a21fddccfe8 version: 4a9217ed0fe9078152435daaa2d3f45b81021b3a version: 8e3a24a35beb16d717072dc83895c5a1f92689fb version: 7ae17fbd39885e0b37383e6d192d25e54d8554c8 version: e20e45fd41daa8374863a47bec8bed3a1e496a6a trackbranch: stable/victoria version: cb736cbc023382ef792465b7d6b3b89797446a25 trackbranch: stable/victoria version: 2abd4c9be81709068770c3115a3db89a1cfad139 trackbranch: stable/victoria version: bcbd5344cf56338adea03ad3ef41466fd8615e70 trackbranch: stable/victoria version: 48a217bf2d8f1416541c92b44cbc80518013f322 trackbranch: stable/victoria version: 2cb805baff2af142099ba692cac047ae963493b1 trackbranch: stable/victoria version: 50a941f55294be4c7fffc77f6bcf99d9ff62a1d5 trackbranch: stable/victoria,227,183
openstack%2Fpuppet-neutron~master~Idea98150c1b1cd5cf41ed2d995208c496af7091f,openstack/puppet-neutron,master,Idea98150c1b1cd5cf41ed2d995208c496af7091f,Deprecate parameters for FWaaS quotas,MERGED,2020-12-25 00:39:20.000000000,2021-01-05 13:59:16.000000000,2021-01-05 13:57:52.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-25 00:39:20.000000000', 'files': ['spec/classes/neutron_quota_spec.rb', 'releasenotes/notes/deprecate-fwaas-quotas-4c48436e96451012.yaml', 'manifests/quota.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1e2c71d36db1126387ae93dc4116313b0b998932', 'message': 'Deprecate parameters for FWaaS quotas\n\n... because Neutron FWaaS has been retired.\n\nChange-Id: Idea98150c1b1cd5cf41ed2d995208c496af7091f\n'}]",0,768490,1e2c71d36db1126387ae93dc4116313b0b998932,14,3,1,9816,,,0,"Deprecate parameters for FWaaS quotas

... because Neutron FWaaS has been retired.

Change-Id: Idea98150c1b1cd5cf41ed2d995208c496af7091f
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/90/768490/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-fwaas-quotas-4c48436e96451012.yaml', 'spec/classes/neutron_quota_spec.rb', 'manifests/quota.pp']",3,1e2c71d36db1126387ae93dc4116313b0b998932,quota,"# [*quota_firewall*] # (optional) Number of firewalls allowed per tenant, -1 for unlimited. # Defaults to undef. # # [*quota_firewall_policy*] # (optional) Number of firewalls policies allowed per tenant, -1 for unlimited. # Defaults to undef. # # [*quota_firewall_rule*] # (optional) Number of firewalls rules allowed per tenant, -1 for unlimited. # Defaults to undef. # $quota_firewall = undef, $quota_firewall_policy = undef, $quota_firewall_rule = undef, 'quota_loadbalancer', 'quota_pool', 'quota_member', 'quota_healthmonitor', 'quota_firewall', 'quota_firewall_policy', 'quota_firewall_rule'","# [*quota_firewall*] # (optional) Number of firewalls allowed per tenant, -1 for unlimited. # Defaults to $::os_service_default. # # [*quota_firewall_policy*] # (optional) Number of firewalls policies allowed per tenant, -1 for unlimited. # Defaults to $::os_service_default. # # [*quota_firewall_rule*] # (optional) Number of firewalls rules allowed per tenant, -1 for unlimited. # Defaults to '-1'. # $quota_firewall = $::os_service_default, $quota_firewall_policy = $::os_service_default, $quota_firewall_rule = -1, 'quota_loadbalancer', 'quota_pool', 'quota_member', 'quota_healthmonitor' 'quotas/quota_firewall': value => $quota_firewall; 'quotas/quota_firewall_policy': value => $quota_firewall_policy; 'quotas/quota_firewall_rule': value => $quota_firewall_rule;",26,23
openstack%2Fkolla-ansible~master~I979f88162ad8a206e413b37ac7fb09bcc912e016,openstack/kolla-ansible,master,I979f88162ad8a206e413b37ac7fb09bcc912e016,Install gnupg before adding docker apt gpg key during pre-install,MERGED,2020-12-20 18:44:55.000000000,2021-01-05 13:52:35.000000000,2021-01-05 13:50:39.000000000,"[{'_account_id': 14826}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-20 18:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1b077c5df0feba8ae2e4a6cf961352c071cd1919', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n'}, {'number': 2, 'created': '2020-12-22 09:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/49ab549d2d5d5fd80654725173d6dfb0b4593069', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n'}, {'number': 3, 'created': '2021-01-05 09:54:47.000000000', 'files': ['ansible/roles/baremetal/tasks/pre-install.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/027b8d244c4c58d98dfadf2933ab5e1c7e43b869', 'message': 'Install gnupg before adding docker apt gpg key during pre-install\n\nAdding docker apt gpg key requires gpupg to be installed.\nTask will fail on minimal Debian 10 install as gnupg absent.\n\nChange-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016\n'}]",2,768020,027b8d244c4c58d98dfadf2933ab5e1c7e43b869,19,4,3,32860,,,0,"Install gnupg before adding docker apt gpg key during pre-install

Adding docker apt gpg key requires gpupg to be installed.
Task will fail on minimal Debian 10 install as gnupg absent.

Change-Id: I979f88162ad8a206e413b37ac7fb09bcc912e016
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/20/768020/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/baremetal/tasks/pre-install.yml'],1,1b077c5df0feba8ae2e4a6cf961352c071cd1919,, - name: Install gnupg package: name: gnupg state: present become: True ,,6,0
openstack%2Fneutron~master~Ib3c8ee48873f3c63c9dc24e4641b392fe7883699,openstack/neutron,master,Ib3c8ee48873f3c63c9dc24e4641b392fe7883699,[ovn]: fix usage of lrp_set_options api to use **options,MERGED,2020-12-22 21:56:28.000000000,2021-01-05 13:49:29.000000000,2021-01-05 13:47:30.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 5948}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32586}]","[{'number': 1, 'created': '2020-12-22 21:56:28.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0c5c4764d3863460f7ed1bff753d213c06c1d44', 'message': ""[ovn]: fix usage of lrp_set_options api to use **options\n\nset_gateway_mtu() in ovn_client was passing in options dictionary\nto ovsdbapp's nb idl lrp_set_options [1] improperly: it needed it to\nbe expanded.\n\n[1]: https://github.com/openstack/ovsdbapp/blob/e36f3270e67d899848341e205ec2f95addd48899/ovsdbapp/schema/ovn_northbound/api.py#L559\n\nCloses-Bug: #1909038\nChange-Id: Ib3c8ee48873f3c63c9dc24e4641b392fe7883699\n""}]",0,768277,d0c5c4764d3863460f7ed1bff753d213c06c1d44,24,9,1,11952,,,0,"[ovn]: fix usage of lrp_set_options api to use **options

set_gateway_mtu() in ovn_client was passing in options dictionary
to ovsdbapp's nb idl lrp_set_options [1] improperly: it needed it to
be expanded.

[1]: https://github.com/openstack/ovsdbapp/blob/e36f3270e67d899848341e205ec2f95addd48899/ovsdbapp/schema/ovn_northbound/api.py#L559

Closes-Bug: #1909038
Change-Id: Ib3c8ee48873f3c63c9dc24e4641b392fe7883699
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/768277/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py']",2,d0c5c4764d3863460f7ed1bff753d213c06c1d44,," lrp_name, **expected_opts)"," lrp_name, expected_opts)",2,2
openstack%2Fopenstack-ansible-os_ceilometer~stable%2Fvictoria~Ied8a54d3837c4447d612457eebb4fd7a8b9d342d,openstack/openstack-ansible-os_ceilometer,stable/victoria,Ied8a54d3837c4447d612457eebb4fd7a8b9d342d,Remove centos-7 conditional configuration,MERGED,2021-01-04 21:13:36.000000000,2021-01-05 13:36:24.000000000,2021-01-05 13:35:17.000000000,"[{'_account_id': 22348}, {'_account_id': 25600}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-04 21:13:36.000000000', 'files': ['vars/source_install.yml', 'vars/distro_install.yml', 'vars/redhat-7.yml', 'vars/redhat.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/cba352ed4a689e534a33a6d717701172f89693be', 'message': ""Remove centos-7 conditional configuration\n\nWe don't support centos-7 for Victoria so remove conditional code.\n\nChange-Id: Ied8a54d3837c4447d612457eebb4fd7a8b9d342d\n(cherry picked from commit 434c24955283fb9cce2835a423f0fb78549fbe24)\n""}]",0,769184,cba352ed4a689e534a33a6d717701172f89693be,10,3,1,25023,,,0,"Remove centos-7 conditional configuration

We don't support centos-7 for Victoria so remove conditional code.

Change-Id: Ied8a54d3837c4447d612457eebb4fd7a8b9d342d
(cherry picked from commit 434c24955283fb9cce2835a423f0fb78549fbe24)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/84/769184/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/source_install.yml', 'vars/distro_install.yml', 'vars/redhat-7.yml', 'vars/redhat.yml', 'defaults/main.yml']",5,cba352ed4a689e534a33a6d717701172f89693be,,"ceilometer_venv_python_executable: ""{{ openstack_venv_python_executable | default('python3') }}""","ceilometer_venv_python_executable: ""{{ _ceilometer_venv_python_executable }}""",1,47
openstack%2Fkayobe~master~I5a3af41e4cc3988540ff95c880207279133a19d4,openstack/kayobe,master,I5a3af41e4cc3988540ff95c880207279133a19d4,Remove Retired Karbor Support,MERGED,2020-12-18 22:09:25.000000000,2021-01-05 13:07:27.000000000,2021-01-05 13:05:37.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 22:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/29bf4b15ec4122bb8657e92910878bb13ac77afc', 'message': 'Remove Retired Karbor Support\n\nAs announced on the openstack-discuss ML[1], Karbor is retiring\nthis cycle (Wallaby).\n\nNeeded-By: https://review.opendev.org/c/openstack/karbor/+/767032\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nChange-Id: I5a3af41e4cc3988540ff95c880207279133a19d4\n'}, {'number': 2, 'created': '2020-12-22 09:32:27.000000000', 'files': ['releasenotes/notes/remove-qinling-support-67635a37e620fc7b.yaml', 'ansible/group_vars/all/kolla', 'ansible/roles/kolla-ansible/templates/overcloud-services.j2', 'releasenotes/notes/remove-searchlight-support-a164fd550bfc14d4.yaml', 'etc/kayobe/kolla.yml', 'ansible/roles/kolla-ansible/templates/overcloud-components.j2', 'releasenotes/notes/remove-karbor-9d3bfad50490ec06.yaml', 'ansible/roles/kolla-ansible/tests/test-extras.yml', 'ansible/roles/kolla-ansible/vars/main.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0644ea238bcf977e153c456d21e13928a2c7c6c1', 'message': 'Remove Retired Karbor Support\n\nAs announced on the openstack-discuss ML[1], Karbor is retiring\nthis cycle (Wallaby).\n\nNeeded-By: https://review.opendev.org/c/openstack/karbor/+/767032\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nChange-Id: I5a3af41e4cc3988540ff95c880207279133a19d4\n'}]",0,767961,0644ea238bcf977e153c456d21e13928a2c7c6c1,19,4,2,16708,,,0,"Remove Retired Karbor Support

As announced on the openstack-discuss ML[1], Karbor is retiring
this cycle (Wallaby).

Needed-By: https://review.opendev.org/c/openstack/karbor/+/767032

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html

Change-Id: I5a3af41e4cc3988540ff95c880207279133a19d4
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/61/767961/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all/kolla', 'ansible/roles/kolla-ansible/templates/overcloud-services.j2', 'etc/kayobe/kolla.yml', 'ansible/roles/kolla-ansible/templates/overcloud-components.j2', 'ansible/roles/kolla-ansible/vars/main.yml']",5,29bf4b15ec4122bb8657e92910878bb13ac77afc,retire-karbor,, - horizon_karbor - karbor,0,20
openstack%2Fopenstack-ansible-os_nova~master~Ie0525a258e859e1545d473175440719ce298631a,openstack/openstack-ansible-os_nova,master,Ie0525a258e859e1545d473175440719ce298631a,Updated from OpenStack Ansible Tests,MERGED,2020-10-19 09:20:39.000000000,2021-01-05 13:02:08.000000000,2021-01-05 13:00:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-19 09:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/cb8bd60dc69fa8e7ebead85ac66edca968a91491', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ie0525a258e859e1545d473175440719ce298631a\n'}, {'number': 2, 'created': '2021-01-05 08:35:39.000000000', 'files': ['tasks/service_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/b03ffb76a244cbe54b289ceb53217f27c27cf960', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ie0525a258e859e1545d473175440719ce298631a\n'}]",0,758752,b03ffb76a244cbe54b289ceb53217f27c27cf960,14,4,2,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ie0525a258e859e1545d473175440719ce298631a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/52/758752/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/service_setup.yml'],1,cb8bd60dc69fa8e7ebead85ac66edca968a91491,openstack/openstack-ansible-tests/sync-tests, openstack.cloud.identity_domain: openstack.cloud.project: openstack.cloud.catalog_service: openstack.cloud.identity_role: openstack.cloud.identity_user: openstack.cloud.role_assignment: openstack.cloud.endpoint:, openstack.cloud.os_keystone_domain: openstack.cloud.os_project: openstack.cloud.os_keystone_service: openstack.cloud.os_keystone_role: openstack.cloud.os_user: openstack.cloud.os_user_role: openstack.cloud.os_keystone_endpoint:,7,7
openstack%2Fkolla-ansible~master~I38a4ecab071306143952c8036830318c476797f2,openstack/kolla-ansible,master,I38a4ecab071306143952c8036830318c476797f2,Fixes solum_api Listening on 127.0.0.1,MERGED,2021-01-04 15:50:41.000000000,2021-01-05 12:59:40.000000000,2021-01-05 12:57:54.000000000,"[{'_account_id': 14826}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 32324}, {'_account_id': 32761}]","[{'number': 1, 'created': '2021-01-04 15:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ba867de1eeb3219259bd85b6290769b97b27b856', 'message': ""Fixes solum_api Listening on 127.0.0.1\n\nThe default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in\n[api] section of the solum.conf\nThis causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to\nprovide services.\n\nThis fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,\nmaking it available to services like haproxy accessing the service remotely\n\nRelated-Bug: 1909986\nChange-Id: I38a4ecab071306143952c8036830318c476797f2\n""}, {'number': 2, 'created': '2021-01-05 09:31:34.000000000', 'files': ['ansible/roles/solum/templates/solum.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e9f4a5a38e405a097c51dac58708947e7767eff9', 'message': ""Fixes solum_api Listening on 127.0.0.1\n\nThe default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in\n[api] section of the solum.conf\nThis causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to\nprovide services.\n\nThis fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,\nmaking it available to services like haproxy accessing the service remotely\n\nCloses-Bug: 1909986\nChange-Id: I38a4ecab071306143952c8036830318c476797f2\n""}]",0,769157,e9f4a5a38e405a097c51dac58708947e7767eff9,22,5,2,28295,,,0,"Fixes solum_api Listening on 127.0.0.1

The default kolla-ansible deployment of solum_api do not provide a value for 'host' variable in
[api] section of the solum.conf
This causes the solum_api service to fallback to default host 127.0.0.1, making haproxy unable to
provide services.

This fix adds value for 'host' variable, so the solum_api service able to listen on provided ip,
making it available to services like haproxy accessing the service remotely

Closes-Bug: 1909986
Change-Id: I38a4ecab071306143952c8036830318c476797f2
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/57/769157/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/solum/templates/solum.conf.j2'],1,ba867de1eeb3219259bd85b6290769b97b27b856,solum-api,{% if service_name == 'solum-api' %} host = {{ api_interface_address }} {% endif %},,3,0
openstack%2Fceilometermiddleware~master~Iddc6f1d90f416b8938a712ac0b04aec807f391a9,openstack/ceilometermiddleware,master,Iddc6f1d90f416b8938a712ac0b04aec807f391a9,Add doc/requirements,NEW,2021-01-05 10:44:16.000000000,2021-01-05 12:48:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-05 10:44:16.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometermiddleware/commit/f956bce9201cc8b3f0438bc945f166d282d21ffe', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoved specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: Iddc6f1d90f416b8938a712ac0b04aec807f391a9\n""}]",0,769317,f956bce9201cc8b3f0438bc945f166d282d21ffe,3,1,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removed specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: Iddc6f1d90f416b8938a712ac0b04aec807f391a9
",git fetch https://review.opendev.org/openstack/ceilometermiddleware refs/changes/17/769317/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,f956bce9201cc8b3f0438bc945f166d282d21ffe,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,6,3
openstack%2Ftripleo-docs~master~I77d38d0474a5f7c202e9eb61e5d18f8e59bade86,openstack/tripleo-docs,master,I77d38d0474a5f7c202e9eb61e5d18f8e59bade86,Add new Component/Integration pipeline docs,MERGED,2020-12-16 16:50:23.000000000,2021-01-05 12:44:32.000000000,2021-01-05 12:43:08.000000000,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 15993}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 29775}, {'_account_id': 30742}, {'_account_id': 30750}, {'_account_id': 31075}]","[{'number': 1, 'created': '2020-12-16 16:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/d499bb39df1858d41e435c9ee7f83808576c03a4', 'message': 'WIP update docs on promotion stages and components\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}, {'number': 2, 'created': '2020-12-18 16:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/eb7dcc59e5c02407d43e91a1c30f32f3150aa6e3', 'message': 'WIP update docs on promotion stages and components\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}, {'number': 3, 'created': '2020-12-21 17:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/62aa1208f14a2fbd823af6a314257c02669bc7ed', 'message': 'WIP update docs on promotion stages and components\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}, {'number': 4, 'created': '2020-12-22 16:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/81c7985c27f7651661b2a10f5e72516ee6e3ba17', 'message': 'WIP update docs on promotion stages and components\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}, {'number': 5, 'created': '2020-12-23 16:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/11e87ec86d19a7f66405215968ed528eadf4e399', 'message': 'WIP update docs on promotion stages and components\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}, {'number': 6, 'created': '2020-12-24 12:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/6fad6ea57ad30632c2446a8c7a94a5baddc514f4', 'message': 'Add new Component/Integration pipeline docs\n\nThis updates the current promotion-stages doc and introduces\nthe concept of component and integration pipelines.\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}, {'number': 7, 'created': '2021-01-04 09:22:33.000000000', 'files': ['doc/source/ci/stages-overview.rst', 'doc/source/ci/component_pipeline_tags_flow.mmd', 'doc/source/ci/component_integration_pipelines.mmd', 'doc/source/ci/promotions.mmd'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/082b163a93c3b9a7b3db3486b486f05dd7ac12a5', 'message': 'Add new Component/Integration pipeline docs\n\nThis updates the current promotion-stages doc and introduces\nthe concept of component and integration pipelines.\n\nChange-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86\n'}]",31,767375,082b163a93c3b9a7b3db3486b486f05dd7ac12a5,33,16,7,8449,,,0,"Add new Component/Integration pipeline docs

This updates the current promotion-stages doc and introduces
the concept of component and integration pipelines.

Change-Id: I77d38d0474a5f7c202e9eb61e5d18f8e59bade86
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/75/767375/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/ci/stages-overview.rst', 'doc/source/ci/promotions.mmd']",2,d499bb39df1858d41e435c9ee7f83808576c03a4,I77d38d0474a5f7c202e9eb61e5d18f8e59bade86, current-consistent --> |tripleo-ci promotion|component-ci-testing component-ci-testing --> |component promotion|tripleo-ci-testing tripleo-ci-testing --> |tripleo-ci promotion|current-tripleo, current-consistent --> |<a href='http://cistatus.tripleo.org/promotion/'>tripleo-ci promotion</a>|current-tripleo,14,5
openstack%2Fkolla-ansible~stable%2Fvictoria~Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e,openstack/kolla-ansible,stable/victoria,Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e,octavia: fix typo in defaults,MERGED,2021-01-05 09:26:54.000000000,2021-01-05 12:40:49.000000000,2021-01-05 12:39:20.000000000,"[{'_account_id': 167}, {'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 32324}]","[{'number': 1, 'created': '2021-01-05 09:26:54.000000000', 'files': ['ansible/roles/octavia/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/174cd7b15145b8ad647d4b4cba9f6ff6664ef1ee', 'message': 'octavia: fix typo in defaults\n\nSigned-off-by: Christian Berendt <berendt@betacloud-solutions.de>\nChange-Id: Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e\n(cherry picked from commit b42688f87b9e551485353a5d426e920c51ad2a01)\n'}]",0,769187,174cd7b15145b8ad647d4b4cba9f6ff6664ef1ee,10,5,1,14826,,,0,"octavia: fix typo in defaults

Signed-off-by: Christian Berendt <berendt@betacloud-solutions.de>
Change-Id: Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e
(cherry picked from commit b42688f87b9e551485353a5d426e920c51ad2a01)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/87/769187/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/octavia/defaults/main.yml'],1,174cd7b15145b8ad647d4b4cba9f6ff6664ef1ee,fix/octavia-prepare-tasks-typo-stable/victoria,# - allocation_pool_end (optional),# - allocation_pool_start (optional),1,1
openstack%2Fcyborg-tempest-plugin~master~Ie289f6210e40185641ab73a6ab40783336627f76,openstack/cyborg-tempest-plugin,master,Ie289f6210e40185641ab73a6ab40783336627f76,add get one deployable method and negative test,MERGED,2020-12-21 01:38:43.000000000,2021-01-05 12:38:55.000000000,2021-01-05 12:38:55.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-12-21 01:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/ce1d127b51edcfe03ed7950e85699bf8419a801a', 'message': 'add get one deployable method and negative test\n\nadd get one deployable method and non-existent deployable uuid negative\ntest\nChange-Id: Ie289f6210e40185641ab73a6ab40783336627f76\n'}, {'number': 2, 'created': '2020-12-21 01:39:58.000000000', 'files': ['cyborg_tempest_plugin/services/cyborg_rest_client.py', 'cyborg_tempest_plugin/tests/api/test_deployable_negative.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/2e87cf281781a72f938ea1b6769f9792070c23c7', 'message': 'add get one deployable method and negative test\n\nadd get one deployable method and non-existent deployable uuid negative\ntest\nChange-Id: Ie289f6210e40185641ab73a6ab40783336627f76\n'}]",0,768033,2e87cf281781a72f938ea1b6769f9792070c23c7,10,3,2,30409,,,0,"add get one deployable method and negative test

add get one deployable method and non-existent deployable uuid negative
test
Change-Id: Ie289f6210e40185641ab73a6ab40783336627f76
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/33/768033/2 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg_tempest_plugin/services/cyborg_rest_client.py', 'cyborg_tempest_plugin/tests/api/test_deployable_negative.py']",2,ce1d127b51edcfe03ed7950e85699bf8419a801a,master6,"# Copyright 2020 Inspur # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from cyborg_tempest_plugin.tests.api import base from tempest.lib import exceptions as lib_exc from tempest import test class DeployableNegativeTest(base.BaseAPITest): credentials = ['admin'] @test.attr(type=['negative', 'gate']) def test_get_non_existent_deployable(self): # get the non-existent device non_existent_id = str(uuid.uuid4()) self.assertRaises(lib_exc.NotFound, self.os_admin.cyborg_client.get_deployable, non_existent_id) ",,37,0
openstack%2Fblazar-nova~master~I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c,openstack/blazar-nova,master,I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c,drop mock from lower-constraints and requirements,NEW,2020-06-08 20:24:52.000000000,2021-01-05 12:31:28.000000000,,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2020-06-08 20:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/888d5b7032024973b66b31da37a99ee95bf7599f', 'message': ""drop mock from lower-constraints and requirements\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we don't need it\nin lower-constraints and requirements.\n\nThese changes will help us to drop `mock` from openstack/requirements\n\nChange-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c\n""}, {'number': 2, 'created': '2020-06-09 09:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/4eefb0fa4ac9597c2127a73ed0a678ffeb9be72d', 'message': ""drop mock from lower-constraints and requirements\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we don't need it\nin lower-constraints and requirements.\n\nThese changes will help us to drop `mock` from openstack/requirements\n\nChange-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c\n""}, {'number': 3, 'created': '2020-06-29 07:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/c444f2741e2e9a9d4f605d6795c38fdb07e5d5b8', 'message': ""drop mock from lower-constraints and requirements\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we don't need it\nin lower-constraints and requirements.\n\nThese changes will help us to drop `mock` from openstack/requirements\n\nChange-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c\n""}, {'number': 4, 'created': '2020-08-18 09:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/3867b8dac5be2c7a7a49e97915c9625ffbd52a16', 'message': ""drop mock from lower-constraints and requirements\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we don't need it\nin lower-constraints and requirements.\n\nThese changes will help us to drop `mock` from openstack/requirements\n\nChange-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c\n""}, {'number': 5, 'created': '2020-08-24 20:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/d2ae25f91fb8881f4b7cdbff225dbb87d65907b9', 'message': ""drop mock from lower-constraints and requirements\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we don't need it\nin lower-constraints and requirements.\n\nThese changes will help us to drop `mock` from openstack/requirements\n\nChange-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c\n""}, {'number': 6, 'created': '2021-01-05 10:56:43.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/5f10a39da9d73e63e6285741531624d1784abfe2', 'message': ""drop mock from lower-constraints and requirements\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we don't need it\nin lower-constraints and requirements.\n\nThese changes will help us to drop `mock` from openstack/requirements\n\nChange-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c\n""}]",0,734225,5f10a39da9d73e63e6285741531624d1784abfe2,17,3,6,28522,,,0,"drop mock from lower-constraints and requirements

The mock third party library was needed for mock support in py2
runtimes. Since we now only support py36 and later, we don't need it
in lower-constraints and requirements.

These changes will help us to drop `mock` from openstack/requirements

Change-Id: I261c48455b2ba0f9d3c44fc0e9a8b8db0307712c
",git fetch https://review.opendev.org/openstack/blazar-nova refs/changes/25/734225/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'lower-constraints.txt']",2,888d5b7032024973b66b31da37a99ee95bf7599f,fix-relmgt-pip-doc,,mock==2.0.0,0,2
openstack%2Ftripleo-common~stable%2Fvictoria~I8616775584cf0216314109d21dabd32635293a27,openstack/tripleo-common,stable/victoria,I8616775584cf0216314109d21dabd32635293a27,Fix ImportWarning during importing a module,MERGED,2020-12-25 20:13:38.000000000,2021-01-05 12:18:45.000000000,2021-01-05 12:17:08.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 32240}]","[{'number': 1, 'created': '2020-12-25 20:13:38.000000000', 'files': ['tripleo_common/utils/config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/697a5e6be3dc7faa802466902dcb1ccefa892b0e', 'message': 'Fix ImportWarning during importing a module\n\nSet warnings category to filter only DeprecationWarnings\nand UserWarning\n\nCloses-Bug: #1889380\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I8616775584cf0216314109d21dabd32635293a27\n(cherry picked from commit c296d83eaa6edc9d14f76fc2995857f3646dac75)\n'}]",0,768406,697a5e6be3dc7faa802466902dcb1ccefa892b0e,11,6,1,14985,,,0,"Fix ImportWarning during importing a module

Set warnings category to filter only DeprecationWarnings
and UserWarning

Closes-Bug: #1889380
Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: I8616775584cf0216314109d21dabd32635293a27
(cherry picked from commit c296d83eaa6edc9d14f76fc2995857f3646dac75)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/06/768406/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/config.py'],1,697a5e6be3dc7faa802466902dcb1ccefa892b0e,bug/1889380-stable/victoria,"warnings.filterwarnings('once', category=DeprecationWarning) warnings.filterwarnings('once', category=UserWarning)",warnings.filterwarnings('once'),2,1
openstack%2Fvalidations-common~master~I851a4ef202694611b0e004de7ade592594f1a078,openstack/validations-common,master,I851a4ef202694611b0e004de7ade592594f1a078,Restrict Ansible dependency,MERGED,2020-12-09 14:02:13.000000000,2021-01-05 12:17:11.000000000,2021-01-05 12:17:11.000000000,"[{'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2020-12-09 14:02:13.000000000', 'files': ['molecule-requirements.txt'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/775f74b069ad09ac8630da2451a234833eb8218a', 'message': 'Restrict Ansible dependency\n\nThis patch adds some version specifiers in the molecule-requirements.txt\nto restrict to specific Ansible release.\n\nChange-Id: I851a4ef202694611b0e004de7ade592594f1a078\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",0,766225,775f74b069ad09ac8630da2451a234833eb8218a,8,6,1,11491,,,0,"Restrict Ansible dependency

This patch adds some version specifiers in the molecule-requirements.txt
to restrict to specific Ansible release.

Change-Id: I851a4ef202694611b0e004de7ade592594f1a078
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/25/766225/1 && git format-patch -1 --stdout FETCH_HEAD,['molecule-requirements.txt'],1,775f74b069ad09ac8630da2451a234833eb8218a,,"ansible>=2.8,!=2.8.9,!=2.9.12,<2.10.0",ansible,1,1
openstack%2Fneutron~stable%2Fussuri~I8c940ac8f7632c69607dea7220146ef59d55ed56,openstack/neutron,stable/ussuri,I8c940ac8f7632c69607dea7220146ef59d55ed56,Ensure ovsdb_probe_interval set before connect(),MERGED,2020-12-04 21:53:46.000000000,2021-01-05 12:08:26.000000000,2021-01-05 12:06:35.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-04 21:53:46.000000000', 'files': ['neutron/agent/ovn/metadata/ovsdb.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/65d3f79ce655ace0c8dacab2196fb019ea9d7f08', 'message': ""Ensure ovsdb_probe_interval set before connect()\n\nSetting the ovsdb_probe_interval after Connection.start() is\ncalled means that the probe interval is not changed from\npython-ovs's default of 5s until after the initial copy of the\ndatabase is retrieved. On busy systems, this can time out and\ncause infinite reconnects.\n\nThis patch passes the probe_interval argument to the ovs.db.Idl\nclass so that it can be set as part of creating the jsonrpc\nSession.\n\nSome unit tests were removed and replaced with a functional test\nwhich ensures not just that set_probe_interval is called, but that\nthe value is actually set before the connection is established.\n\nConflicts:\n  neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py\n  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n\nCloses-bug: #1905611\nChange-Id: I8c940ac8f7632c69607dea7220146ef59d55ed56\n(cherry picked from commit 5783e952887b2fe5e8aaa32b3077e8dcdefa7252)\n""}]",0,765628,65d3f79ce655ace0c8dacab2196fb019ea9d7f08,8,3,1,5756,,,0,"Ensure ovsdb_probe_interval set before connect()

Setting the ovsdb_probe_interval after Connection.start() is
called means that the probe interval is not changed from
python-ovs's default of 5s until after the initial copy of the
database is retrieved. On busy systems, this can time out and
cause infinite reconnects.

This patch passes the probe_interval argument to the ovs.db.Idl
class so that it can be set as part of creating the jsonrpc
Session.

Some unit tests were removed and replaced with a functional test
which ensures not just that set_probe_interval is called, but that
the value is actually set before the connection is established.

Conflicts:
  neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py
  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py

Closes-bug: #1905611
Change-Id: I8c940ac8f7632c69607dea7220146ef59d55ed56
(cherry picked from commit 5783e952887b2fe5e8aaa32b3077e8dcdefa7252)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/765628/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/ovn/metadata/ovsdb.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py']",5,65d3f79ce655ace0c8dacab2196fb019ea9d7f08,fix_ovsdb_probe_interval-stable/ussuri," import fixtures as og_fixturesfrom neutron.conf.plugins.ml2.drivers.ovn import ovn_conffrom neutron.tests.functional.resources import process class OvnIdlProbeInterval(base.TestOVNFunctionalBase): def setUp(self): # skip parent setUp, we don't need it, but we do need grandparent # pylint: disable=bad-super-call super(base.TestOVNFunctionalBase, self).setUp() mm = directory.get_plugin().mechanism_manager self.mech_driver = mm.mech_drivers['ovn'].obj self.temp_dir = self.useFixture(og_fixtures.TempDir()).path install_share_path = self._get_install_share_path() self.mgr = self.useFixture( process.OvsdbServer(self.temp_dir, install_share_path, ovn_nb_db=True, ovn_sb_db=True, protocol='tcp')) connection = self.mgr.get_ovsdb_connection_path self.connections = {'OVN_Northbound': connection(), 'OVN_Southbound': connection(db_type='sb')} def test_ovsdb_probe_interval(self): klasses = { ovsdb_monitor.BaseOvnIdl: ('OVN_Northbound', {}), ovsdb_monitor.OvnNbIdl: ('OVN_Northbound', {'driver': self.mech_driver}), ovsdb_monitor.OvnSbIdl: ('OVN_Southbound', {'driver': self.mech_driver})} idls = [kls.from_server(self.connections[schema], schema, **kwargs) for kls, (schema, kwargs) in klasses.items()] interval = ovn_conf.get_ovn_ovsdb_probe_interval() for idl in idls: self.assertEqual(interval, idl._session.reconnect.probe_interval)",,47,77
openstack%2Fneutron~stable%2Fussuri~Iae86705f1d30c89dc5482261d852b45787bd8782,openstack/neutron,stable/ussuri,Iae86705f1d30c89dc5482261d852b45787bd8782,Fix calling of add_tunnel_port method from sanity checks module,MERGED,2020-12-03 08:34:33.000000000,2021-01-05 12:07:17.000000000,2021-01-05 12:05:48.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 32029}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-03 08:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e65da874216872561dd0697ae7ae35676cf0805a', 'message': 'Fix calling of add_tunnel_port method from sanity checks module\n\nSanity checks functions which are checking if vxlan and geneve tunnels\nare available in openvswitch are now passing all mandatory parameters\nto the ovs_lib.OVSBridge.add_tunnel_port method.\nPreviously port_name was missing.\n\nCloses-Bug: #1905568\nChange-Id: Iae86705f1d30c89dc5482261d852b45787bd8782\n(cherry picked from commit ab6c59b57e732def62e3817a80d081b8392d669a)\n'}, {'number': 2, 'created': '2020-12-21 10:21:32.000000000', 'files': ['neutron/cmd/sanity/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5ea5d305fbb3e74631bec9d80125f16ac3666ed', 'message': 'Fix calling of add_tunnel_port method from sanity checks module\n\nSanity checks functions which are checking if vxlan and geneve tunnels\nare available in openvswitch are now passing all mandatory parameters\nto the ovs_lib.OVSBridge.add_tunnel_port method.\nPreviously port_name was missing.\n\nCloses-Bug: #1905568\nChange-Id: Iae86705f1d30c89dc5482261d852b45787bd8782\n(cherry picked from commit ab6c59b57e732def62e3817a80d081b8392d669a)\n'}]",0,765284,d5ea5d305fbb3e74631bec9d80125f16ac3666ed,30,5,2,11975,,,0,"Fix calling of add_tunnel_port method from sanity checks module

Sanity checks functions which are checking if vxlan and geneve tunnels
are available in openvswitch are now passing all mandatory parameters
to the ovs_lib.OVSBridge.add_tunnel_port method.
Previously port_name was missing.

Closes-Bug: #1905568
Change-Id: Iae86705f1d30c89dc5482261d852b45787bd8782
(cherry picked from commit ab6c59b57e732def62e3817a80d081b8392d669a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/765284/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/cmd/sanity/checks.py'],1,e65da874216872561dd0697ae7ae35676cf0805a,bug/1905568-stable/victoria-stable/ussuri," br_name = common_utils.get_rand_device_name(prefix='vxlantest-') port_name = common_utils.get_rand_device_name(prefix='vxlantest-') with ovs_lib.OVSBridge(br_name) as br: port = br.add_tunnel_port( port_name=port_name, remote_ip=from_ip, local_ip=to_ip, tunnel_type=n_consts.TYPE_VXLAN) br_name = common_utils.get_rand_device_name(prefix='genevetest-') port_name = common_utils.get_rand_device_name(prefix='genevetest-') with ovs_lib.OVSBridge(br_name) as br: port = br.add_tunnel_port( port_name=port_name, remote_ip=from_ip, local_ip=to_ip, tunnel_type=n_consts.TYPE_GENEVE)"," name = common_utils.get_rand_device_name(prefix='vxlantest-') with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port(from_ip, to_ip, n_consts.TYPE_VXLAN) name = common_utils.get_rand_device_name(prefix='genevetest-') with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port(from_ip, to_ip, n_consts.TYPE_GENEVE)",16,6
openstack%2Fmagnum~master~I05cbd1ec62e9a68c68a1666ff62f20138bf8c731,openstack/magnum,master,I05cbd1ec62e9a68c68a1666ff62f20138bf8c731,Update containerd version and tarball URL,MERGED,2020-12-16 02:58:30.000000000,2021-01-05 11:42:29.000000000,2021-01-05 11:40:55.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 30911}]","[{'number': 1, 'created': '2020-12-16 02:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/601566a5689b27b657c43645a440d79b1e635165', 'message': 'Update containerd version and tarball URL\n\n1. Update default containerd version to 1.4.3\n2. Fix the redirect issue of containerd tarball download\n\nstory: 2008451\n\nChange-Id: I05cbd1ec62e9a68c68a1666ff62f20138bf8c731\n'}, {'number': 2, 'created': '2021-01-05 09:35:44.000000000', 'files': ['magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/install-cri.sh', 'releasenotes/notes/update-containerd-version-url-c095c0ee3c1a538b.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8bdf0e76c63c4aa44394f7bd71483d843bccb22c', 'message': 'Update containerd version and tarball URL\n\n1. Update default containerd version to 1.4.3\n2. Fix the redirect issue of containerd tarball download\n\nstory: 2008451\n\nChange-Id: I05cbd1ec62e9a68c68a1666ff62f20138bf8c731\n'}]",1,767263,8bdf0e76c63c4aa44394f7bd71483d843bccb22c,14,4,2,6484,,,0,"Update containerd version and tarball URL

1. Update default containerd version to 1.4.3
2. Fix the redirect issue of containerd tarball download

story: 2008451

Change-Id: I05cbd1ec62e9a68c68a1666ff62f20138bf8c731
",git fetch https://review.opendev.org/openstack/magnum refs/changes/63/767263/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/install-cri.sh', 'releasenotes/notes/update-containerd-version-url-c095c0ee3c1a538b.yaml']",3,601566a5689b27b657c43645a440d79b1e635165,update-containerd-story/2008451,--- upgrade: - | The default containerd version is updated with 1.4.3. ,,8,4
openstack%2Fironic~stable%2Fvictoria~I3589038001b98c866f47339ac8d65edfb891ed79,openstack/ironic,stable/victoria,I3589038001b98c866f47339ac8d65edfb891ed79,Include HeartbeatMixin in the ramdisk deploy,MERGED,2020-12-18 20:47:20.000000000,2021-01-05 11:33:52.000000000,2021-01-05 11:32:25.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-18 20:47:20.000000000', 'files': ['ironic/drivers/modules/pxe.py', 'releasenotes/notes/ramdisk-clean-2d3b033a401b911b.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/29d5c7ddd886ce14747ef67c56dc3f315ca18c57', 'message': 'Include HeartbeatMixin in the ramdisk deploy\n\nOtherwise cleaning gets stuck forever because there is no heartbeat\nimplementation to use.\n\nChange-Id: I3589038001b98c866f47339ac8d65edfb891ed79\n(cherry picked from commit ca37578a0ac6d68a3a7142f189f64735e85b4e48)\n'}]",0,767786,29d5c7ddd886ce14747ef67c56dc3f315ca18c57,8,2,1,10239,,,0,"Include HeartbeatMixin in the ramdisk deploy

Otherwise cleaning gets stuck forever because there is no heartbeat
implementation to use.

Change-Id: I3589038001b98c866f47339ac8d65edfb891ed79
(cherry picked from commit ca37578a0ac6d68a3a7142f189f64735e85b4e48)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/86/767786/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe.py', 'releasenotes/notes/ramdisk-clean-2d3b033a401b911b.yaml']",2,29d5c7ddd886ce14747ef67c56dc3f315ca18c57,ramdisk-clean-stable/victoria,--- fixes: - | Fixes cleaning with the ``ramdisk`` deploy interface by reusing the same procedure as for the ``direct`` deploy interface. ,,7,1
openstack%2Ftripleo-heat-templates~master~Ie240877496b73a37f553a84af47dfebdbaf899e5,openstack/tripleo-heat-templates,master,Ie240877496b73a37f553a84af47dfebdbaf899e5,Fix unreachable handling,MERGED,2020-12-18 14:57:58.000000000,2021-01-05 11:32:52.000000000,2021-01-05 11:32:52.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-18 14:57:58.000000000', 'files': ['common/deploy-steps-playbooks-common.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/969693e667aba8d893f10f7b03bafde3b3f66287', 'message': 'Fix unreachable handling\n\nWhen we clear the cached facts with unreachable nodes, we attempt to\ngather facts by default. This can cause the node to be skipped for every\nfuture playbook. This ends up bypassing all our failure percentage\nlogic.\n\nChange-Id: Ie240877496b73a37f553a84af47dfebdbaf899e5\nRelated-Bug: 1908573\n'}]",0,767760,969693e667aba8d893f10f7b03bafde3b3f66287,10,9,1,14985,,,0,"Fix unreachable handling

When we clear the cached facts with unreachable nodes, we attempt to
gather facts by default. This can cause the node to be skipped for every
future playbook. This ends up bypassing all our failure percentage
logic.

Change-Id: Ie240877496b73a37f553a84af47dfebdbaf899e5
Related-Bug: 1908573
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/767760/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps-playbooks-common.yaml'],1,969693e667aba8d893f10f7b03bafde3b3f66287,bug/1908573," # We don't want to gather facts, just clear them gather_facts: false strategy: tripleo_free gather_facts: true"," gather_facts: yes # False because https://github.com/ansible/ansible/issues/70663 any_errors_fatal: false # If an overcloud node is down, we will let MaxFailPercentage # figuring out if the deployment can continue. For the facts gathering tasks, # we will simply ignore unreachable nodes and errors, and let the # Ansible reports the failure in the next plays. ignore_unreachable: true",4,8
openstack%2Fkolla-ansible~master~I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,openstack/kolla-ansible,master,I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017,Fix failure during Monasca Grafana upgrade,MERGED,2020-12-10 16:17:26.000000000,2021-01-05 11:31:24.000000000,2021-01-05 11:29:40.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 26285}]","[{'number': 1, 'created': '2020-12-10 16:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9cd6e616ad58484b253b16621fe2ab10b8994607', 'message': 'Fix failure during Monasca Grafana upgrade\n\nThe task ""Stopping all Monasca Grafana instances but the first node""\nwould fail with:\n\n    error while evaluating conditional (monasca_grafana_differs[\'result\']): \'dict object\' has no attribute \'result\'\n\nFixed by running this task on the same set of hosts that defines\nmonasca_grafana_differs, i.e. groups[\'monasca-grafana\'].\n\nChange-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017\nCloses-Bug: #1907689\n'}, {'number': 2, 'created': '2020-12-10 16:18:53.000000000', 'files': ['ansible/roles/monasca/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/39e75c308750ab4f259201b13a048f3fe0d3cc67', 'message': 'Fix failure during Monasca Grafana upgrade\n\nThe task ""Stopping all Monasca Grafana instances but the first node""\ncan fail with:\n\n    error while evaluating conditional (monasca_grafana_differs[\'result\']): \'dict object\' has no attribute \'result\'\n\nThis is fixed by running this task on the same set of hosts than the\ntask defining monasca_grafana_differs, i.e. groups[\'monasca-grafana\'].\n\nChange-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017\nCloses-Bug: #1907689\n'}]",0,766503,39e75c308750ab4f259201b13a048f3fe0d3cc67,14,5,2,15197,,,0,"Fix failure during Monasca Grafana upgrade

The task ""Stopping all Monasca Grafana instances but the first node""
can fail with:

    error while evaluating conditional (monasca_grafana_differs['result']): 'dict object' has no attribute 'result'

This is fixed by running this task on the same set of hosts than the
task defining monasca_grafana_differs, i.e. groups['monasca-grafana'].

Change-Id: I6ad0256fb2a3cdc91dddf441e5e1c41f4ac69017
Closes-Bug: #1907689
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/03/766503/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/monasca/tasks/upgrade.yml'],1,9cd6e616ad58484b253b16621fe2ab10b8994607,bug/1907689, - inventory_hostname in groups['monasca-grafana'],,1,0
openstack%2Fswift~master~Ibd42153bf17866a4ce74e265f915b5add41f62b7,openstack/swift,master,Ibd42153bf17866a4ce74e265f915b5add41f62b7,acoles: emeritus no more!,MERGED,2021-01-04 22:34:31.000000000,2021-01-05 11:10:55.000000000,2021-01-05 01:10:30.000000000,"[{'_account_id': 597}, {'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 22:34:31.000000000', 'files': ['AUTHORS'], 'web_link': 'https://opendev.org/openstack/swift/commit/f4341a0d2637981b2d28b333f251165dc599124d', 'message': 'acoles: emeritus no more!\n\nChange-Id: Ibd42153bf17866a4ce74e265f915b5add41f62b7\n'}]",1,769224,f4341a0d2637981b2d28b333f251165dc599124d,9,4,1,15343,,,0,"acoles: emeritus no more!

Change-Id: Ibd42153bf17866a4ce74e265f915b5add41f62b7
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/769224/1 && git format-patch -1 --stdout FETCH_HEAD,['AUTHORS'],1,f4341a0d2637981b2d28b333f251165dc599124d,,,Alistair Coles (alistairncoles@gmail.com),0,1
openstack%2Fcyborg-specs~master~I0b9ac5b00df798753ec1d2b6867a683e37c68736,openstack/cyborg-specs,master,I0b9ac5b00df798753ec1d2b6867a683e37c68736,Remove unicode from code,MERGED,2021-01-05 08:47:35.000000000,2021-01-05 11:05:47.000000000,2021-01-05 11:04:30.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2021-01-05 08:47:35.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/f708d228a2ce555d3088de2001e4ee730b233120', 'message': 'Remove unicode from code\n\nChange-Id: I0b9ac5b00df798753ec1d2b6867a683e37c68736\n'}]",0,769262,f708d228a2ce555d3088de2001e4ee730b233120,8,3,1,31845,,,0,"Remove unicode from code

Change-Id: I0b9ac5b00df798753ec1d2b6867a683e37c68736
",git fetch https://review.opendev.org/openstack/cyborg-specs refs/changes/62/769262/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,f708d228a2ce555d3088de2001e4ee730b233120,,"project = 'cyborg-specs' copyright = '2017, OpenStack Developers' '%s Documentation' % project, 'OpenStack Developers', 'manual'),","project = u'cyborg-specs' copyright = u'2017, OpenStack Developers' u'%s Documentation' % project, u'OpenStack Developers', 'manual'),",4,4
openstack%2Fkolla-ansible~master~Id0bc1e0207a0d411a7000a21ed8f839ec134d1b7,openstack/kolla-ansible,master,Id0bc1e0207a0d411a7000a21ed8f839ec134d1b7,Update website URL for InfluxDB,MERGED,2021-01-03 07:39:38.000000000,2021-01-05 11:04:33.000000000,2021-01-05 11:02:09.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 32324}]","[{'number': 1, 'created': '2021-01-03 07:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3fad8a79e88f6bec133ee79a505ce4e9cfda7910', 'message': 'change the url if InfluexDB\n\nChange-Id: Id0bc1e0207a0d411a7000a21ed8f839ec134d1b7\n'}, {'number': 2, 'created': '2021-01-04 08:54:20.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e04ae1abc34d0adfe0a4e619eaa2127dc96b7581', 'message': 'Update website URL for InfluxDB\n\nChange-Id: Id0bc1e0207a0d411a7000a21ed8f839ec134d1b7\n'}]",0,768980,e04ae1abc34d0adfe0a4e619eaa2127dc96b7581,11,4,2,27399,,,0,"Update website URL for InfluxDB

Change-Id: Id0bc1e0207a0d411a7000a21ed8f839ec134d1b7
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/80/768980/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3fad8a79e88f6bec133ee79a505ce4e9cfda7910,," `InfluxDB <https://www.influxdata.com/products/influxdb-overview/>`__,"," `InfluxDB <https://influxdata.com/time-series-platform/influxdb/>`__,",1,1
openstack%2Fkolla~stable%2Ftrain~I88e5bcf35207670b8611aeee3072215a7d7eb6e5,openstack/kolla,stable/train,I88e5bcf35207670b8611aeee3072215a7d7eb6e5,Fix Freezer & Cyborg API startup on CentOS,MERGED,2021-01-04 18:58:09.000000000,2021-01-05 11:04:11.000000000,2021-01-05 11:02:04.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-04 18:58:09.000000000', 'files': ['docker/cyborg/cyborg-api/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3e020fdf2a26ad640a56134c25a5060c48bb190b', 'message': 'Fix Freezer & Cyborg API startup on CentOS\n\nAffects: Ussuri, Train\n\nAs part of the CentOS 8 support, we added a kolla_httpd_setup script,\nhowever this was not used for Cyborg or Freezer. This has been fixed\nsince Victoria as part of commit\n032804e5a0ddf89f7726880d1b57dd492d7d5c07, but this was not backported to\nUssuri.\n\nCloses-Bug: #1909981\nCo-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\n\nChange-Id: I88e5bcf35207670b8611aeee3072215a7d7eb6e5\n(cherry picked from commit e0d8772efa25b478467afcd3e2ecf2643ea471ff)\n'}]",0,769177,3e020fdf2a26ad640a56134c25a5060c48bb190b,8,3,1,30491,,,0,"Fix Freezer & Cyborg API startup on CentOS

Affects: Ussuri, Train

As part of the CentOS 8 support, we added a kolla_httpd_setup script,
however this was not used for Cyborg or Freezer. This has been fixed
since Victoria as part of commit
032804e5a0ddf89f7726880d1b57dd492d7d5c07, but this was not backported to
Ussuri.

Closes-Bug: #1909981
Co-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>

Change-Id: I88e5bcf35207670b8611aeee3072215a7d7eb6e5
(cherry picked from commit e0d8772efa25b478467afcd3e2ecf2643ea471ff)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/77/769177/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/cyborg/cyborg-api/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh']",2,3e020fdf2a26ad640a56134c25a5060c48bb190b,,. /usr/local/bin/kolla_httpd_setup,"if [[ ""${KOLLA_BASE_DISTRO}"" =~ debian|ubuntu ]]; then # Loading Apache2 ENV variables . /etc/apache2/envvars install -d /var/run/apache2/ rm -rf /var/run/apache2/* else rm -rf /var/run/httpd/* /run/httpd/* /tmp/httpd* fi",2,16
openstack%2Fcyborg-tempest-plugin~master~Idc2186d0a3f471dc033564f070ed8cbe0718c7f6,openstack/cyborg-tempest-plugin,master,Idc2186d0a3f471dc033564f070ed8cbe0718c7f6,add get accelerator request negative test,MERGED,2020-12-16 06:38:41.000000000,2021-01-05 11:03:50.000000000,2021-01-05 11:03:50.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-12-16 06:38:41.000000000', 'files': ['cyborg_tempest_plugin/tests/api/test_accelerator_request_negative.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/240c3f5729926a7938eeb21c738f24dae082ce6e', 'message': 'add get accelerator request negative test\n\nadd get accelerator request non-exiestent accelerator request uuid negative test\nChange-Id: Idc2186d0a3f471dc033564f070ed8cbe0718c7f6\n'}]",0,767276,240c3f5729926a7938eeb21c738f24dae082ce6e,7,3,1,30409,,,0,"add get accelerator request negative test

add get accelerator request non-exiestent accelerator request uuid negative test
Change-Id: Idc2186d0a3f471dc033564f070ed8cbe0718c7f6
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/76/767276/1 && git format-patch -1 --stdout FETCH_HEAD,['cyborg_tempest_plugin/tests/api/test_accelerator_request_negative.py'],1,240c3f5729926a7938eeb21c738f24dae082ce6e,master4,"# Copyright 2020 Inspur # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from cyborg_tempest_plugin.tests.api import base from tempest.lib import exceptions as lib_exc from tempest import test class AcceleratorRequestNegativeTest(base.BaseAPITest): credentials = ['admin'] @test.attr(type=['negative', 'gate']) def test_get_non_existent_accelerator_request(self): # get the non-existent accelerator request non_existent_id = str(uuid.uuid4()) self.assertRaises(lib_exc.NotFound, self.os_admin.cyborg_client.get_accelerator_request, non_existent_id) ",,33,0
openstack%2Fpython-tripleoclient~master~Ide062e65b0a76078b5d3ce55a60df3cb5be34a0e,openstack/python-tripleoclient,master,Ide062e65b0a76078b5d3ce55a60df3cb5be34a0e,[UX] Align to left the table for the validations run results,MERGED,2020-11-30 11:41:36.000000000,2021-01-05 11:02:39.000000000,2021-01-05 11:00:49.000000000,"[{'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-11-30 11:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/40d505ddd004d3a9137d1e5970c9b42ef75f22b4', 'message': '[UX] Align to left the table for the validations run results\n\nAll the PrettyTables are aligned to left and this patch standardizes all\nthe tables.\n\nChange-Id: Ide062e65b0a76078b5d3ce55a60df3cb5be34a0e\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2020-12-07 15:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/7d9153f5df4d85e8bb8dc484bbaeceb8e6148bad', 'message': '[UX] Align to left the table for the validations run results\n\nAll the PrettyTables are aligned to left and this patch standardizes all\nthe tables.\n\nChange-Id: Ide062e65b0a76078b5d3ce55a60df3cb5be34a0e\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 3, 'created': '2021-01-04 14:59:10.000000000', 'files': ['tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c6f22c1f3c0ed775b8276895eb017616cf46c033', 'message': '[UX] Align to left the table for the validations run results\n\nAll the PrettyTables are aligned to left and this patch standardizes all\nthe tables.\n\nChange-Id: Ide062e65b0a76078b5d3ce55a60df3cb5be34a0e\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",0,764642,c6f22c1f3c0ed775b8276895eb017616cf46c033,30,6,3,11491,,,0,"[UX] Align to left the table for the validations run results

All the PrettyTables are aligned to left and this patch standardizes all
the tables.

Change-Id: Ide062e65b0a76078b5d3ce55a60df3cb5be34a0e
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/42/764642/3 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_validator.py'],1,40d505ddd004d3a9137d1e5970c9b42ef75f22b4,UX, t.align = 'l',,1,0
openstack%2Frequirements~master~Ic6a5a33eeebb9deb3c4b67d2f299370e1a10dd61,openstack/requirements,master,Ic6a5a33eeebb9deb3c4b67d2f299370e1a10dd61,Updated from generate-constraints,MERGED,2021-01-05 06:22:25.000000000,2021-01-05 10:57:10.000000000,2021-01-05 10:55:30.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 06:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4ffe26c43ee0f132fb31925487d11df0fd89c4f2', 'message': 'Updated from generate-constraints\n\nChange-Id: Ic6a5a33eeebb9deb3c4b67d2f299370e1a10dd61\n'}, {'number': 2, 'created': '2021-01-05 06:38:24.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4b9c97a1159fc80f3758571aacb855650bc6ffc6', 'message': 'Updated from generate-constraints\n\nChange-Id: Ic6a5a33eeebb9deb3c4b67d2f299370e1a10dd61\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,769246,4b9c97a1159fc80f3758571aacb855650bc6ffc6,10,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: Ic6a5a33eeebb9deb3c4b67d2f299370e1a10dd61
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/46/769246/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,4ffe26c43ee0f132fb31925487d11df0fd89c4f2,openstack/requirements/constraints/noclob,Pillow===8.1.0tripleo-common===13.1.0zeroconf===0.28.8mock===4.0.3os-net-config===13.1.0os-apply-config===12.0.0docutils===0.16boto3===1.16.48Sphinx===3.4.2botocore===1.19.48oslo.db===8.5.0pkg-resources===0.0.0fasteners===0.16virtualenv===20.2.2,Pillow===8.0.1tripleo-common===13.0.0zeroconf===0.28.7mock===3.0.5os-net-config===13.0.0os-apply-config===11.3.0docutils===0.15.2boto3===1.16.47Sphinx===3.4.1botocore===1.19.47oslo.db===8.4.0fasteners===0.14.1virtualenv===20.2.1setuptools===51.1.1,14,14
openstack%2Fneutron~master~I10c64c318cf04692c30eff6cb718450ea174caf0,openstack/neutron,master,I10c64c318cf04692c30eff6cb718450ea174caf0,Refactor the Neutron OSKenApp class,MERGED,2020-12-21 09:37:08.000000000,2021-01-05 10:57:01.000000000,2021-01-05 10:55:21.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-21 09:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83aeb28423aba083438feaa307feb6aa41c605f9', 'message': 'Refactor the Neutron OSKenApp class\n\nMove the duplicated code to a base class BaseNeutronAgentOSKenApp.\n\nRelated-Bug: #1774459\nChange-Id: I10c64c318cf04692c30eff6cb718450ea174caf0\n'}, {'number': 2, 'created': '2020-12-21 09:46:49.000000000', 'files': ['neutron/services/logapi/drivers/openvswitch/log_oskenapp.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ovs_oskenapp.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/base_oskenapp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f158922b67cd5a3085a06818dd56b3f115a1b98', 'message': 'Refactor the Neutron OSKenApp class\n\nMove the duplicated code to a base class BaseNeutronAgentOSKenApp.\n\nAuthored-By: Swaminathan Vasudevan <SVasudevan@suse.com>\nCo-Authored-By: Slawek Kaplonski <skaplons@redhat.com>\n\nRelated-Bug: #1774459\nChange-Id: I10c64c318cf04692c30eff6cb718450ea174caf0\n'}]",1,768052,9f158922b67cd5a3085a06818dd56b3f115a1b98,16,6,2,9531,,,0,"Refactor the Neutron OSKenApp class

Move the duplicated code to a base class BaseNeutronAgentOSKenApp.

Authored-By: Swaminathan Vasudevan <SVasudevan@suse.com>
Co-Authored-By: Slawek Kaplonski <skaplons@redhat.com>

Related-Bug: #1774459
Change-Id: I10c64c318cf04692c30eff6cb718450ea174caf0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/768052/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/logapi/drivers/openvswitch/log_oskenapp.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ovs_oskenapp.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/base_oskenapp.py']",3,83aeb28423aba083438feaa307feb6aa41c605f9,osken_app_refactor,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from os_ken.base import app_manager from os_ken.controller import handler from os_ken.controller import ofp_event from os_ken.ofproto import ofproto_v1_3 from oslo_log import log as logging LOG = logging.getLogger(__name__) class BaseNeutronAgentOSKenApp(app_manager.OSKenApp): OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION] packet_in_handlers = [] def register_packet_in_handler(self, caller): self.packet_in_handlers.append(caller) def unregister_packet_in_handler(self, caller): self.packet_in_handlers.remove(caller) @handler.set_ev_cls(ofp_event.EventOFPPacketIn, handler.MAIN_DISPATCHER) def packet_in_handler(self, ev): for caller in self.packet_in_handlers: caller(ev) ",,45,25
openstack%2Fmagnum~master~I199797cbe20eb36f28b7e4ccf236d182fd26028d,openstack/magnum,master,I199797cbe20eb36f28b7e4ccf236d182fd26028d,Follow redirects for containerd_tarball_url,ABANDONED,2020-12-08 09:07:43.000000000,2021-01-05 10:27:34.000000000,,"[{'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-08 09:07:43.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/install-cri.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/39f62f0d6af9fa0699a33724efe8f3a53f5be7cb', 'message': 'Follow redirects for containerd_tarball_url\n\nAsset links on https://github.com/containerd/containerd/releases\nredirect to temporarily valid locations.\nThis commit adds the `-L` parameter to tell curl to follow redirects\nwhen downloading containerd_tarball_url.\n\nTask: 41377\nStory: 2008428\nChange-Id: I199797cbe20eb36f28b7e4ccf236d182fd26028d\n'}]",0,765927,39f62f0d6af9fa0699a33724efe8f3a53f5be7cb,8,2,1,30911,,,0,"Follow redirects for containerd_tarball_url

Asset links on https://github.com/containerd/containerd/releases
redirect to temporarily valid locations.
This commit adds the `-L` parameter to tell curl to follow redirects
when downloading containerd_tarball_url.

Task: 41377
Story: 2008428
Change-Id: I199797cbe20eb36f28b7e4ccf236d182fd26028d
",git fetch https://review.opendev.org/openstack/magnum refs/changes/27/765927/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/common/templates/kubernetes/fragments/install-cri.sh'],1,39f62f0d6af9fa0699a33724efe8f3a53f5be7cb,story/2008428," until curl -L -o /srv/magnum/cri-containerd.tar.gz ""${CONTAINERD_TARBALL_URL}"""," until curl -o /srv/magnum/cri-containerd.tar.gz ""${CONTAINERD_TARBALL_URL}""",1,1
openstack%2Fmagnum~master~I2cd53bc9c59a60b90f708b1434381f120ace8c49,openstack/magnum,master,I2cd53bc9c59a60b90f708b1434381f120ace8c49,[k8s] Fix default admission controller,MERGED,2020-12-07 21:27:55.000000000,2021-01-05 10:22:12.000000000,2021-01-05 10:19:45.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-12-07 21:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0b5cf5e1befa6418acb96329a5df9c907c46cd00', 'message': '[k8s] Fix default admission controller\n\nThe default admission controller list of k8s is being updated in\nthis patch by removing the SecurityContextDeny controller, which\nwill fix the k8s dashboard and metrics/prometheus creating issue.\n\nStory: 2008426\n\nChange-Id: I2cd53bc9c59a60b90f708b1434381f120ace8c49\n'}, {'number': 2, 'created': '2020-12-17 22:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1227d4d815e0ce6f88c480b90da97e42f6e460bd', 'message': '[k8s] Fix default admission controller\n\nThe default admission controller list of k8s is being updated in\nthis patch by removing the SecurityContextDeny controller, which\nwill fix the k8s dashboard and metrics/prometheus creating issue.\n\nStory: 2008426\n\nChange-Id: I2cd53bc9c59a60b90f708b1434381f120ace8c49\n'}, {'number': 3, 'created': '2021-01-04 15:36:01.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'releasenotes/notes/default-admission-controller-04398548cf63597c.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/fade2451705b915c2625ae006d28d92eddbba27e', 'message': '[k8s] Fix default admission controller\n\nThe default admission controller list of k8s is being updated in\nthis patch by removing the SecurityContextDeny controller, which\nwill fix the k8s dashboard and metrics/prometheus creating issue.\n\nStory: 2008426\n\nChange-Id: I2cd53bc9c59a60b90f708b1434381f120ace8c49\n'}]",2,765881,fade2451705b915c2625ae006d28d92eddbba27e,20,3,3,6484,,,0,"[k8s] Fix default admission controller

The default admission controller list of k8s is being updated in
this patch by removing the SecurityContextDeny controller, which
will fix the k8s dashboard and metrics/prometheus creating issue.

Story: 2008426

Change-Id: I2cd53bc9c59a60b90f708b1434381f120ace8c49
",git fetch https://review.opendev.org/openstack/magnum refs/changes/81/765881/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'releasenotes/notes/default-admission-controller-04398548cf63597c.yaml']",2,0b5cf5e1befa6418acb96329a5df9c907c46cd00,fix-default-admission-controller-story/2008426,"--- upgrade: - | Now the default admission controller list is updated by as ""NodeRestriction, NamespaceLifecycle, LimitRanger, ServiceAccount, ResourceQuota, TaintNodesByCondition, Priority, DefaultTolerationSeconds, DefaultStorageClass, StorageObjectInUseProtection, PersistentVolumeClaimResize, MutatingAdmissionWebhook, ValidatingAdmissionWebhook, RuntimeClass"" ",,6,1
openstack%2Fos-vif~master~I5db16fc3d0e9ff81892d94e4164743ca4836f359,openstack/os-vif,master,I5db16fc3d0e9ff81892d94e4164743ca4836f359,[WIP] get_ifname_by_pci_address compare phys_port_id,ABANDONED,2020-10-15 07:04:07.000000000,2021-01-05 10:03:25.000000000,,"[{'_account_id': 9732}, {'_account_id': 12171}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32296}]","[{'number': 1, 'created': '2020-10-15 07:04:07.000000000', 'files': ['vif_plug_ovs/linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/7226a41b6f760eaef31b2d5b6f98e8f6fc127d4e', 'message': '[WIP] get_ifname_by_pci_address compare phys_port_id\n\nChange-Id: I5db16fc3d0e9ff81892d94e4164743ca4836f359\nSigned-off-by: Mamduh <mamduhala@nvidia.com>\n'}]",0,758352,7226a41b6f760eaef31b2d5b6f98e8f6fc127d4e,8,5,1,32296,,,0,"[WIP] get_ifname_by_pci_address compare phys_port_id

Change-Id: I5db16fc3d0e9ff81892d94e4164743ca4836f359
Signed-off-by: Mamduh <mamduhala@nvidia.com>
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/52/758352/1 && git format-patch -1 --stdout FETCH_HEAD,['vif_plug_ovs/linux_net.py'],1,7226a41b6f760eaef31b2d5b6f98e8f6fc127d4e,port-id,"def get_ifname_by_pci_address(pci_addr, pf_interface=False, switchdev=False, pf_phys_port_id=None): :param pf_phys_port_id: PF phys_port_id to match (fallback to first netdev) if no match found # In case switchdev=False # Return the netdev that matches given phys_port_id if phys_port_id is # not given or no match found fallback to first netdev found if not switchdev: if pf_phys_port_id is not None: for netdev in devices: try: netdev_phys_port_id = get_phys_port_id(netdev) if netdev_phys_port_id == pf_phys_port_id: return netdev except Exception: continue def get_phys_port_id(ifname): """"""Get the interface name and return its phys_port_id :param ifname: The interface name :return: The phys_port_id of the given ifname """""" phys_port_name_path = ""/sys/class/net/%s/phys_port_id"" % ifname if not os.path.isfile(phys_port_name_path): return None with open(phys_port_name_path, 'r') as fd: return fd.readline().strip() ","def get_ifname_by_pci_address(pci_addr, pf_interface=False, switchdev=False): # Return the first netdev in case of switchdev=False if not switchdev:",31,2
openstack%2Fmonasca-specs~master~I88b4a8bb778efdcb2a538bc54bb18509de7b5f09,openstack/monasca-specs,master,I88b4a8bb778efdcb2a538bc54bb18509de7b5f09,remove unicode from code,ABANDONED,2021-01-05 09:23:09.000000000,2021-01-05 09:44:22.000000000,,"[{'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2021-01-05 09:23:09.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/monasca-specs/commit/d08919a4ca91290c8a59fd840e63b26aea24c51d', 'message': 'remove unicode from code\n\nChange-Id: I88b4a8bb778efdcb2a538bc54bb18509de7b5f09\n'}]",1,769282,d08919a4ca91290c8a59fd840e63b26aea24c51d,4,2,1,32020,,,0,"remove unicode from code

Change-Id: I88b4a8bb778efdcb2a538bc54bb18509de7b5f09
",git fetch https://review.opendev.org/openstack/monasca-specs refs/changes/82/769282/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,d08919a4ca91290c8a59fd840e63b26aea24c51d,,project = 'Monasca Specs',project = u'Monasca Specs',1,1
openstack%2Fdiskimage-builder~master~I5d80c7e1566a7a3d544b2b3822c77d9f1b7f16d3,openstack/diskimage-builder,master,I5d80c7e1566a7a3d544b2b3822c77d9f1b7f16d3,Add Python3 Wallaby unit tests,MERGED,2020-10-10 05:29:14.000000000,2021-01-05 09:42:30.000000000,2021-01-05 09:37:46.000000000,"[{'_account_id': 5263}, {'_account_id': 10118}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-10 05:29:14.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ddb67363a30f7b07cd0456fa12f6fd9f53289e2e', 'message': 'Add Python3 Wallaby unit tests\n\nThis change ensures unit testing is in place for all of the tested\nruntimes for Wallaby.\n\nSee also the Project Testing Interface (PTI) in OpenStack Governance.\n\n[1] https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: I5d80c7e1566a7a3d544b2b3822c77d9f1b7f16d3\n'}]",0,757247,ddb67363a30f7b07cd0456fa12f6fd9f53289e2e,11,5,1,32029,,,0,"Add Python3 Wallaby unit tests

This change ensures unit testing is in place for all of the tested
runtimes for Wallaby.

See also the Project Testing Interface (PTI) in OpenStack Governance.

[1] https://governance.openstack.org/tc/reference/project-testing-interface.html

Change-Id: I5d80c7e1566a7a3d544b2b3822c77d9f1b7f16d3
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/47/757247/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,ddb67363a30f7b07cd0456fa12f6fd9f53289e2e,add-wallaby-python-jobtemplates, - openstack-python3-wallaby-jobs, - openstack-python3-victoria-jobs,1,1
openstack%2Frpm-packaging~master~I6b9e020dbabed7a18b9798f70514f107c261ba8d,openstack/rpm-packaging,master,I6b9e020dbabed7a18b9798f70514f107c261ba8d,Update tripleo-common to 13.1.0,MERGED,2021-01-05 08:05:54.000000000,2021-01-05 09:41:03.000000000,2021-01-05 09:41:03.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-05 08:05:54.000000000', 'files': ['openstack/tripleo-common/tripleo-common.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/eef6dcc4f70708b2f501f370456d97f92c729f11', 'message': 'Update tripleo-common to 13.1.0\n\nChange-Id: I6b9e020dbabed7a18b9798f70514f107c261ba8d\n'}]",0,769258,eef6dcc4f70708b2f501f370456d97f92c729f11,9,5,1,27380,,,0,"Update tripleo-common to 13.1.0

Change-Id: I6b9e020dbabed7a18b9798f70514f107c261ba8d
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/58/769258/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tripleo-common/tripleo-common.spec.j2'],1,eef6dcc4f70708b2f501f370456d97f92c729f11,update_tripleo-common,{% set upstream_version = upstream_version('13.1.0') %},{% set upstream_version = upstream_version('13.0.0') %},1,1
openstack%2Fmonasca-specs~master~I396d6ecd3bf3113415f58b0de3d9f5ba226bf423,openstack/monasca-specs,master,I396d6ecd3bf3113415f58b0de3d9f5ba226bf423,remove unicode from code,ABANDONED,2021-01-05 09:31:34.000000000,2021-01-05 09:39:29.000000000,,[],"[{'number': 1, 'created': '2021-01-05 09:31:34.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/monasca-specs/commit/1e87ce5aa27a00810f86265402b6eed2526d83f9', 'message': 'remove unicode from code\n\nChange-Id: I396d6ecd3bf3113415f58b0de3d9f5ba226bf423\n'}]",0,769296,1e87ce5aa27a00810f86265402b6eed2526d83f9,2,0,1,32020,,,0,"remove unicode from code

Change-Id: I396d6ecd3bf3113415f58b0de3d9f5ba226bf423
",git fetch https://review.opendev.org/openstack/monasca-specs refs/changes/96/769296/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,1e87ce5aa27a00810f86265402b6eed2526d83f9,,"copyright = '%s, Monasca Team' % datetime.date.today().year","copyright = u'%s, Monasca Team' % datetime.date.today().year",1,1
openstack%2Fmagnum~master~Id637fe8f93897552048e78d89412be9e2caf5c0b,openstack/magnum,master,Id637fe8f93897552048e78d89412be9e2caf5c0b,Imported Translations from Zanata,MERGED,2020-09-22 07:21:36.000000000,2021-01-05 09:29:46.000000000,2021-01-05 09:28:14.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-09-22 07:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c54c5d639e028eb020041c8332388d7048c7e440', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 2, 'created': '2020-09-24 07:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7573f937f385384941b5b5b0043eeaf187900bf2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 3, 'created': '2020-11-16 07:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c5ff9d683edf8a5cc7493bd7acf6135b3680fcbe', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 4, 'created': '2020-11-30 07:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7b908ce7e1d8af54ffad7440e32c4d8ec6b117ae', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 5, 'created': '2020-12-01 07:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5805e6426c2268a77c298333368a431f8a8ce489', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 6, 'created': '2020-12-03 08:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5b2197264c6a0780356d23eb24035346a5f336c4', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 7, 'created': '2020-12-13 06:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0c4eb4b7db2c1c53f3cf0fe263f19f0c2168d2e3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 8, 'created': '2021-01-01 06:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ee37c97c8b35c98b6201a0946acbf6b34c4402b0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}, {'number': 9, 'created': '2021-01-05 06:49:23.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/magnum/commit/55d3dadac222288ff0499fed63069b082f5de0a1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b\n'}]",0,753237,55d3dadac222288ff0499fed63069b082f5de0a1,26,4,9,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Id637fe8f93897552048e78d89412be9e2caf5c0b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/37/753237/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po'],1,c54c5d639e028eb020041c8332388d7048c7e440,zanata/translations,"# Grald LONLAS <g.lonlas@gmail.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: magnum\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2020-09-16 09:23+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-10-22 04:59+0000\n"" ""Last-Translator: Grald LONLAS <g.lonlas@gmail.com>\n"" ""Language-Team: French\n"" ""Language: fr\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1)\n"" msgid """" ""--keypair-id parameter in magnum CLI cluster-template-create has been "" ""renamed to --keypair."" msgstr """" ""Le paramtre --keypair-id dans cluster-template-create du CLI magnum a t "" ""renomm pour --keypair."" msgid ""3.0.0"" msgstr ""3.0.0"" msgid ""3.1.0"" msgstr ""3.1.0"" msgid "":ref:`genindex`"" msgstr "":ref:`genindex`"" msgid "":ref:`search`"" msgstr "":ref:`search`"" msgid ""Contents:"" msgstr ""Contenu :"" msgid ""Current Series Release Notes"" msgstr ""Note de la release actuelle"" msgid ""Deprecation Notes"" msgstr ""Notes dprcies "" msgid ""Indices and tables"" msgstr ""Index et table des matires"" msgid ""New Features"" msgstr ""Nouvelles fonctionnalits"" msgid ""Newton Series Release Notes"" msgstr ""Note de release pour Newton"" msgid ""Security Issues"" msgstr ""Problmes de scurits"" msgid ""Upgrade Notes"" msgstr ""Notes de mises  jours"" msgid ""Welcome to Magnum Release Notes's documentation!"" msgstr ""Bienvenue dans la documentation de la note de Release de Magnum"" msgid ""[1] https://review.openstack.org/#/c/311476/"" msgstr ""[1] https://review.openstack.org/#/c/311476/"" ",,64,0
openstack%2Fvenus~master~I3a8dbb2ed4c257b7204ea9632b75eff6783168ba,openstack/venus,master,I3a8dbb2ed4c257b7204ea9632b75eff6783168ba,remove py37,MERGED,2021-01-04 02:28:21.000000000,2021-01-05 09:21:48.000000000,2021-01-05 09:21:48.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-04 02:28:21.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/venus/commit/c465f636dcfcc4f19d3a52e5d5ecb0078eb5e62c', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I3a8dbb2ed4c257b7204ea9632b75eff6783168ba\n""}]",0,769077,c465f636dcfcc4f19d3a52e5d5ecb0078eb5e62c,6,2,1,32326,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I3a8dbb2ed4c257b7204ea9632b75eff6783168ba
",git fetch https://review.opendev.org/openstack/venus refs/changes/77/769077/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c465f636dcfcc4f19d3a52e5d5ecb0078eb5e62c,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fvenus-tempest-plugin~master~I02fc4393fcd3414c630647aaec76d45da7f2a9be,openstack/venus-tempest-plugin,master,I02fc4393fcd3414c630647aaec76d45da7f2a9be,remove py37,MERGED,2021-01-04 02:30:49.000000000,2021-01-05 09:11:36.000000000,2021-01-05 09:11:36.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2021-01-04 02:30:49.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/venus-tempest-plugin/commit/b72ff46ce48f1f115bd8117a8dae1b548d71f50a', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I02fc4393fcd3414c630647aaec76d45da7f2a9be\n""}]",0,769078,b72ff46ce48f1f115bd8117a8dae1b548d71f50a,6,2,1,32326,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I02fc4393fcd3414c630647aaec76d45da7f2a9be
",git fetch https://review.opendev.org/openstack/venus-tempest-plugin refs/changes/78/769078/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,b72ff46ce48f1f115bd8117a8dae1b548d71f50a,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fkolla-ansible~master~Id4bb0000c36d1a32ef30b5af61c324da6068cd51,openstack/kolla-ansible,master,Id4bb0000c36d1a32ef30b5af61c324da6068cd51,Remove support for Ubuntu Bionic 18.04 hosts,MERGED,2020-12-21 10:57:56.000000000,2021-01-05 08:57:58.000000000,2021-01-05 08:50:39.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-21 10:57:56.000000000', 'files': ['ansible/roles/prechecks/vars/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/762f315b2921bbc3c0e5a95907a8a4d6f4cbe2f5', 'message': 'Remove support for Ubuntu Bionic 18.04 hosts\n\nUsers running on a Bionic host will now fail in prechecks.\n\nChange-Id: Id4bb0000c36d1a32ef30b5af61c324da6068cd51\n'}]",0,768077,762f315b2921bbc3c0e5a95907a8a4d6f4cbe2f5,14,3,1,14826,,,0,"Remove support for Ubuntu Bionic 18.04 hosts

Users running on a Bionic host will now fail in prechecks.

Change-Id: Id4bb0000c36d1a32ef30b5af61c324da6068cd51
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/77/768077/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/prechecks/vars/main.yml'],1,762f315b2921bbc3c0e5a95907a8a4d6f4cbe2f5,,," - ""bionic""",0,1
openstack%2Fkolla-ansible~master~I8f150b443af4fb831332836f90a9c38ff61a17cc,openstack/kolla-ansible,master,I8f150b443af4fb831332836f90a9c38ff61a17cc,CI: Switch upgrade jobs to Ubuntu focal 20.04,MERGED,2020-12-21 10:57:56.000000000,2021-01-05 08:55:56.000000000,2021-01-05 08:50:28.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 30491}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-21 10:57:56.000000000', 'files': ['zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b39964e5010120b671a834e434af86e8ad5194eb', 'message': 'CI: Switch upgrade jobs to Ubuntu focal 20.04\n\nSince Victoria supports focal, we can switch the upgrade jobs to run on\nfocal.\n\nChange-Id: I8f150b443af4fb831332836f90a9c38ff61a17cc\n'}]",0,768076,b39964e5010120b671a834e434af86e8ad5194eb,11,5,1,14826,,,0,"CI: Switch upgrade jobs to Ubuntu focal 20.04

Since Victoria supports focal, we can switch the upgrade jobs to run on
focal.

Change-Id: I8f150b443af4fb831332836f90a9c38ff61a17cc
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/768076/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml']",2,b39964e5010120b671a834e434af86e8ad5194eb,, nodeset: kolla-ansible-focal nodeset: kolla-ansible-focal-multi, nodeset: kolla-ansible-bionic nodeset: kolla-ansible-bionic-multi,2,8
openstack%2Fkolla-ansible~master~Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e,openstack/kolla-ansible,master,Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e,octavia: fix typo in defaults,MERGED,2021-01-04 14:05:16.000000000,2021-01-05 08:44:13.000000000,2021-01-05 08:41:54.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2021-01-04 14:05:16.000000000', 'files': ['ansible/roles/octavia/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b42688f87b9e551485353a5d426e920c51ad2a01', 'message': 'octavia: fix typo in defaults\n\nSigned-off-by: Christian Berendt <berendt@betacloud-solutions.de>\nChange-Id: Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e\n'}]",0,769147,b42688f87b9e551485353a5d426e920c51ad2a01,10,3,1,167,,,0,"octavia: fix typo in defaults

Signed-off-by: Christian Berendt <berendt@betacloud-solutions.de>
Change-Id: Ib0c96479c79ce3dfa7469a58b1ea8ca038defe1e
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/47/769147/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/octavia/defaults/main.yml'],1,b42688f87b9e551485353a5d426e920c51ad2a01,fix/octavia-prepare-tasks-typo,# - allocation_pool_end (optional),# - allocation_pool_start (optional),1,1
openstack%2Fcyborg-tempest-plugin~master~Ibcc686cc1e64f51dbdad083190c6dadc6f63127d,openstack/cyborg-tempest-plugin,master,Ibcc686cc1e64f51dbdad083190c6dadc6f63127d,Remove unicode from code,MERGED,2021-01-03 09:43:06.000000000,2021-01-05 08:29:05.000000000,2021-01-05 08:29:05.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2021-01-03 09:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/ab26747232a1b261825f6d23f5f03792320eba14', 'message': 'Remove u\n\nChange-Id: Ibcc686cc1e64f51dbdad083190c6dadc6f63127d\n'}, {'number': 2, 'created': '2021-01-04 07:48:13.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/c32e0a235e53fbb4679dc1b2a7888c652023a063', 'message': 'Remove unicode from code\n\nChange-Id: Ibcc686cc1e64f51dbdad083190c6dadc6f63127d\n'}]",1,769060,c32e0a235e53fbb4679dc1b2a7888c652023a063,11,3,2,31845,,,0,"Remove unicode from code

Change-Id: Ibcc686cc1e64f51dbdad083190c6dadc6f63127d
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/60/769060/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,ab26747232a1b261825f6d23f5f03792320eba14,,"project = 'cyborg-tempest-plugin Release Notes' copyright = '2017, OpenStack Developers' 'cyborg-tempest-plugin Release Notes Documentation', 'OpenStack Foundation', 'manual'), 'cyborg-tempest-plugin Release Notes Documentation', ['OpenStack Foundation'], 1) 'cyborg-tempest-plugin Release Notes Documentation', 'OpenStack Foundation', 'cyborg-tempest-pluginReleaseNotes',","project = u'cyborg-tempest-plugin Release Notes' copyright = u'2017, OpenStack Developers' u'cyborg-tempest-plugin Release Notes Documentation', u'OpenStack Foundation', 'manual'), u'cyborg-tempest-plugin Release Notes Documentation', [u'OpenStack Foundation'], 1) u'cyborg-tempest-plugin Release Notes Documentation', u'OpenStack Foundation', 'cyborg-tempest-pluginReleaseNotes',",8,8
openstack%2Ftaskflow~master~Ib2067761e31d3f5e47afb870dfcc25ec59952938,openstack/taskflow,master,Ib2067761e31d3f5e47afb870dfcc25ec59952938,Use unittest.mock instead of mock,ABANDONED,2021-01-02 07:21:46.000000000,2021-01-05 08:25:33.000000000,,"[{'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-02 07:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/72a3c4469506c02f7cfaded7a3342bc8b09eaef4', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: Ib2067761e31d3f5e47afb870dfcc25ec59952938\n'}, {'number': 2, 'created': '2021-01-02 07:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dbe8d844b1909f079b410da8f7e7cc76fa917388', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: Ib2067761e31d3f5e47afb870dfcc25ec59952938\n'}, {'number': 3, 'created': '2021-01-03 01:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ce2afba39dacafd1a8b88729aaa2f33e909179d0', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: Ib2067761e31d3f5e47afb870dfcc25ec59952938\n'}, {'number': 4, 'created': '2021-01-05 07:35:19.000000000', 'files': ['taskflow/test.py', 'test-requirements.txt', 'tools/state_graph.py', 'lower-constraints.txt', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9fd7016e813664e8eb54d2d1e77ee0b9df53f0da', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: Ib2067761e31d3f5e47afb870dfcc25ec59952938\n'}]",0,768861,9fd7016e813664e8eb54d2d1e77ee0b9df53f0da,8,2,4,31027,,,0,"Use unittest.mock instead of mock

The mock third party library was needed for mock support in py2
runtimes. Since we now only support py36 and later, we can use the
standard lib unittest.mock module instead.

Change-Id: Ib2067761e31d3f5e47afb870dfcc25ec59952938
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/61/768861/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/test.py', 'test-requirements.txt', 'tools/state_graph.py', 'lower-constraints.txt', 'setup.cfg']",5,72a3c4469506c02f7cfaded7a3342bc8b09eaef4,,, mock>=2.0.0 # BSD,2,5
openstack%2Fcyborg-tempest-plugin~master~I144f6e8768fe9541dddc6305abff29311d678db7,openstack/cyborg-tempest-plugin,master,I144f6e8768fe9541dddc6305abff29311d678db7,remove unicode from code,ABANDONED,2021-01-04 08:40:38.000000000,2021-01-05 08:20:00.000000000,,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}, {'_account_id': 32761}]","[{'number': 1, 'created': '2021-01-04 08:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/ac468cc3e9b8a8940712a7ccefc353b25bff0714', 'message': 'remove unicode from code\n\nChange-Id: I144f6e8768fe9541dddc6305abff29311d678db7\n'}, {'number': 2, 'created': '2021-01-05 08:11:36.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/7ce47cf63b16366407d98d5e407f5c0ed830e6c8', 'message': 'remove unicode from code\n\nChange-Id: I144f6e8768fe9541dddc6305abff29311d678db7\n'}]",0,769107,7ce47cf63b16366407d98d5e407f5c0ed830e6c8,10,4,2,31828,,,0,"remove unicode from code

Change-Id: I144f6e8768fe9541dddc6305abff29311d678db7
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/07/769107/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,ac468cc3e9b8a8940712a7ccefc353b25bff0714,,"project = 'cyborg-tempest-plugin Release Notes' copyright = '2017, OpenStack Developers' 'cyborg-tempest-plugin Release Notes Documentation', 'OpenStack Foundation', 'manual'), 'cyborg-tempest-plugin Release Notes Documentation', ['OpenStack Foundation'], 1) 'cyborg-tempest-plugin Release Notes Documentation', 'OpenStack Foundation', 'cyborg-tempest-pluginReleaseNotes',","project = u'cyborg-tempest-plugin Release Notes' copyright = u'2017, OpenStack Developers' u'cyborg-tempest-plugin Release Notes Documentation', u'OpenStack Foundation', 'manual'), u'cyborg-tempest-plugin Release Notes Documentation', [u'OpenStack Foundation'], 1) u'cyborg-tempest-plugin Release Notes Documentation', u'OpenStack Foundation', 'cyborg-tempest-pluginReleaseNotes',",8,8
openstack%2Fcyborg~master~I5407d29ba5dcc8647426091b0df51840c3272ba9,openstack/cyborg,master,I5407d29ba5dcc8647426091b0df51840c3272ba9,remove unicode from code,MERGED,2021-01-03 07:51:02.000000000,2021-01-05 08:19:15.000000000,2021-01-05 08:15:50.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2021-01-03 07:51:02.000000000', 'files': ['cyborg/tests/unit/fake_device_profile.py', 'cyborg/tests/unit/fake_device.py', 'doc/source/conf.py', 'api-ref/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/39d51a0a868e0ffc4037af04f3636bc003d66d9b', 'message': 'remove unicode from code\n\nChange-Id: I5407d29ba5dcc8647426091b0df51840c3272ba9\n'}]",0,768987,39d51a0a868e0ffc4037af04f3636bc003d66d9b,8,3,1,31828,,,0,"remove unicode from code

Change-Id: I5407d29ba5dcc8647426091b0df51840c3272ba9
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/87/768987/1 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg/tests/unit/fake_device.py', 'cyborg/tests/unit/fake_device_profile.py', 'api-ref/source/conf.py', 'doc/source/conf.py', 'releasenotes/source/conf.py']",5,39d51a0a868e0ffc4037af04f3636bc003d66d9b,,"copyright = '2018, Cyborg developers' author = 'cyborg developers' 'Cyborg Release Notes Documentation', 'Cyborg developers', 'manual'), (master_doc, 'CyborgReleaseNotes', 'Cyborg Release Notes Documentation', (master_doc, 'CyborgReleaseNotes', 'Cyborg Release Notes Documentation',","copyright = u'2018, Cyborg developers' author = u'cyborg developers' u'Cyborg Release Notes Documentation', u'Cyborg developers', 'manual'), (master_doc, 'CyborgReleaseNotes', u'Cyborg Release Notes Documentation', (master_doc, 'CyborgReleaseNotes', u'Cyborg Release Notes Documentation',",17,17
openstack%2Fnova~master~I9fe0d9519e20c9c68913a5d8645f29d6a3d6d246,openstack/nova,master,I9fe0d9519e20c9c68913a5d8645f29d6a3d6d246,Fixed multipath residue when evacuating the VM,NEW,2020-12-17 08:14:43.000000000,2021-01-05 08:04:20.000000000,,"[{'_account_id': 7634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 08:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f24098da7a58f578eb1e925a24fda9e79b1c946', 'message': 'Fixed multipath residue when evacuating the VM\n\nEvacuation results in multipath residue when the back-end storage uses FC and NOVA to configure multipath, this is part of patch and the other part is in os-brick. its function is to remove local multipath residues.\n\nCloses-Bug: #1906768\nChange-Id: I9fe0d9519e20c9c68913a5d8645f29d6a3d6d246\n'}, {'number': 2, 'created': '2020-12-18 06:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d63fe3d9142a6a7fe0b201a2bb2466519be21a63', 'message': 'Fixed multipath residue when evacuating the VM\n\nEvacuation results in multipath residue when the back-end storage uses FC and NOVA to configure multipath, this is part of patch and the other part is in os-brick. its function is to remove local multipath residues.\n\nCloses-Bug: #1906768\nChange-Id: I9fe0d9519e20c9c68913a5d8645f29d6a3d6d246\n'}, {'number': 3, 'created': '2021-01-05 04:45:41.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3c5d9a96c026f393c53716e3d6599754f2c45300', 'message': 'Fixed multipath residue when evacuating the VM\n\nEvacuation results in multipath residue when the back-end storage uses FC and NOVA to configure multipath, this is part of patch and the other part is in os-brick. its function is to remove local multipath residues.\n\nCloses-Bug: #1906768\nChange-Id: I9fe0d9519e20c9c68913a5d8645f29d6a3d6d246\n'}]",4,767468,3c5d9a96c026f393c53716e3d6599754f2c45300,22,2,3,20252,,,0,"Fixed multipath residue when evacuating the VM

Evacuation results in multipath residue when the back-end storage uses FC and NOVA to configure multipath, this is part of patch and the other part is in os-brick. its function is to remove local multipath residues.

Closes-Bug: #1906768
Change-Id: I9fe0d9519e20c9c68913a5d8645f29d6a3d6d246
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/767468/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/compute/manager.py']",2,4f24098da7a58f578eb1e925a24fda9e79b1c946,bug/1906768," bdi, destroy_disks, destroy_residual_path=True)"," bdi, destroy_disks)",11,6
openstack%2Fcyborg-tempest-plugin~master~Ifd53a9978af7641fce30a5779afd0ca3fe18347f,openstack/cyborg-tempest-plugin,master,Ifd53a9978af7641fce30a5779afd0ca3fe18347f,Remove py37,MERGED,2021-01-03 09:26:59.000000000,2021-01-05 07:52:45.000000000,2021-01-05 07:52:45.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2021-01-03 09:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/b9cea408f75a7015f457f204bc217d8482cf533c', 'message': 'remove python3.7\n\nChange-Id: Ifd53a9978af7641fce30a5779afd0ca3fe18347f\n'}, {'number': 2, 'created': '2021-01-04 08:02:56.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/e6b83e309dc5c71f98a3ba3d673c986afe98d9db', 'message': ""Remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: Ifd53a9978af7641fce30a5779afd0ca3fe18347f\n""}]",0,769056,e6b83e309dc5c71f98a3ba3d673c986afe98d9db,10,3,2,31845,,,0,"Remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: Ifd53a9978af7641fce30a5779afd0ca3fe18347f
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/56/769056/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,b9cea408f75a7015f457f204bc217d8482cf533c,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fcyborg-tempest-plugin~master~I9660f2ab580b78b4b69f3104ed91b8dd703a0ccc,openstack/cyborg-tempest-plugin,master,I9660f2ab580b78b4b69f3104ed91b8dd703a0ccc,remove py37,ABANDONED,2021-01-04 08:37:06.000000000,2021-01-05 07:44:21.000000000,,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2021-01-04 08:37:06.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/61eb4d334fc750d2cb5de3dff10ac1e57654f331', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I9660f2ab580b78b4b69f3104ed91b8dd703a0ccc\n""}]",0,769105,61eb4d334fc750d2cb5de3dff10ac1e57654f331,9,3,1,31828,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I9660f2ab580b78b4b69f3104ed91b8dd703a0ccc
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/05/769105/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,61eb4d334fc750d2cb5de3dff10ac1e57654f331,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fvirtualbmc~master~Ib2570e01bef426c0e5ecfd59249d08ea00749b28,openstack/virtualbmc,master,Ib2570e01bef426c0e5ecfd59249d08ea00749b28,Add doc/requirements,MERGED,2021-01-04 16:23:06.000000000,2021-01-05 07:35:05.000000000,2021-01-05 07:33:43.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-04 16:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/e6b1f8ce41708f6a1c87dc2e792a0f653990c67f', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\n\nChange-Id: Ib2570e01bef426c0e5ecfd59249d08ea00749b28\n'}, {'number': 2, 'created': '2021-01-04 16:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/4b0bd3ad5578428169a3534b9744184cd6d20a31', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ib2570e01bef426c0e5ecfd59249d08ea00749b28\n'}, {'number': 3, 'created': '2021-01-04 17:19:12.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/122f4ba5db11744d5f7155c674f6fde24304487d', 'message': 'Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver for the release team.\nRemoved specific doc requirements from test-requirements.txt\n\nChange-Id: Ib2570e01bef426c0e5ecfd59249d08ea00749b28\n'}]",7,769160,122f4ba5db11744d5f7155c674f6fde24304487d,21,4,3,15519,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver for the release team.
Removed specific doc requirements from test-requirements.txt

Change-Id: Ib2570e01bef426c0e5ecfd59249d08ea00749b28
",git fetch https://review.opendev.org/openstack/virtualbmc refs/changes/60/769160/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/requirements.txt', 'tox.ini']",2,e6b1f8ce41708f6a1c87dc2e792a0f653990c67f,fix-relmgt-pip-doc,deps = {[testenv]deps} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,7,0
openstack%2Fpython-mistralclient~master~Iaaf58b009ea6abea1e7fb32cd87c6aac6e18ac85,openstack/python-mistralclient,master,Iaaf58b009ea6abea1e7fb32cd87c6aac6e18ac85,remove unicode from code,MERGED,2021-01-03 09:07:26.000000000,2021-01-05 07:32:54.000000000,2021-01-05 07:31:39.000000000,"[{'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 09:07:26.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/20a10f0fb54e98368afc92639f6a15ed4a0aa218', 'message': 'remove unicode from code\n\nChange-Id: Iaaf58b009ea6abea1e7fb32cd87c6aac6e18ac85\n'}]",0,769050,20a10f0fb54e98368afc92639f6a15ed4a0aa218,8,3,1,30384,,,0,"remove unicode from code

Change-Id: Iaaf58b009ea6abea1e7fb32cd87c6aac6e18ac85
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/50/769050/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,20a10f0fb54e98368afc92639f6a15ed4a0aa218,,"project = 'Mistral Client Release Notes' copyright = '2016, Mistral developers' 'Mistral Client Release Notes Documentation', 'Mistral developers', 'manual'), 'Mistral Client Release Notes Documentation', ['Mistral developers'], 1) 'Mistral Client Release Notes Documentation', 'Mistral developers', 'MistralClientReleaseNotes',","project = u'Mistral Client Release Notes' copyright = u'2016, Mistral developers' u'Mistral Client Release Notes Documentation', u'Mistral developers', 'manual'), u'Mistral Client Release Notes Documentation', [u'Mistral developers'], 1) u'Mistral Client Release Notes Documentation', u'Mistral developers', 'MistralClientReleaseNotes',",12,12
openstack%2Fopenstack-helm-infra~master~Id9fca020c351683c25ebe83d65e3da2c779bd9b6,openstack/openstack-helm-infra,master,Id9fca020c351683c25ebe83d65e3da2c779bd9b6,Add registry authentication support,ABANDONED,2019-04-10 15:37:14.000000000,2021-01-05 07:25:54.000000000,,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 28101}, {'_account_id': 28435}]","[{'number': 1, 'created': '2019-04-10 15:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bfabbff0afee9ffc2884106bde64ea1261f982f5', 'message': 'Add registry authentication support\n\nWIP\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\n'}, {'number': 2, 'created': '2019-04-11 08:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5486c63384890d07173b00347584f8cd7dedf3bb', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\n'}, {'number': 3, 'created': '2019-04-11 08:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1a6368306cc4cef1f699615dcb8cf9470c038917', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\n'}, {'number': 4, 'created': '2019-04-11 15:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/efd1898c730329dc14b57c559029655534407844', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\n'}, {'number': 5, 'created': '2019-04-11 15:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9166131bf810c7bde865d1a0a4fbc30cfb757f18', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\n'}, {'number': 6, 'created': '2019-04-12 06:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5d47355478aa9e9f4fe430aba06a0a83d4c85973', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\n'}, {'number': 7, 'created': '2019-04-16 07:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c05b5af907c97252a3b2652493cc00be7d8a65c7', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nDepends-On: https://review.openstack.org/#/c/651588\n'}, {'number': 8, 'created': '2019-04-16 08:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1c4e75369865e5e0e8bea63c66ffc9e30c29a826', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nDepends-On: I267b55d737c18c87083c23b1a740b3bb1b6b6b9d\n'}, {'number': 9, 'created': '2019-05-23 07:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a300aead258f5783c829deeda519b34481e36dde', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nDepends-On: I267b55d737c18c87083c23b1a740b3bb1b6b6b9d\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}, {'number': 10, 'created': '2019-06-04 08:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2ea1244f1b23073258a4566cf2e6e57aef10690c', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nDepends-On: I267b55d737c18c87083c23b1a740b3bb1b6b6b9d\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}, {'number': 11, 'created': '2019-06-26 06:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/60d8187878313ef1576c91c92ccdfffc6fc8b357', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nDepends-On: I267b55d737c18c87083c23b1a740b3bb1b6b6b9d\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}, {'number': 12, 'created': '2019-06-26 06:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7653fcbc7fda50db72180efde9a9f46e54af84ee', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nDepends-On: I267b55d737c18c87083c23b1a740b3bb1b6b6b9d\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}, {'number': 13, 'created': '2019-06-26 09:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c91486235222959257c9de4554750b15cff8fa98', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}, {'number': 14, 'created': '2019-07-01 12:40:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/15b310e1cb6d63b60b92e36fad13e7b01e57c88e', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}, {'number': 15, 'created': '2019-07-17 07:26:58.000000000', 'files': ['elastic-packetbeat/values.yaml', 'elasticsearch/values.yaml', 'flannel/templates/secret-registry.yaml', 'mongodb/values.yaml', 'openvswitch/templates/secret-registry.yaml', 'prometheus-process-exporter/templates/secret-registry.yaml', 'elastic-packetbeat/templates/secret-registry.yaml', 'etcd/templates/secret-registry.yaml', 'registry/templates/secret-registry.yaml', 'libvirt/values.yaml', 'memcached/templates/secret-registry.yaml', 'prometheus-node-exporter/templates/secret-registry.yaml', 'kube-dns/templates/secret-registry.yaml', 'prometheus-kube-state-metrics/templates/secret-registry.yaml', 'ceph-osd/templates/secret-registry.yaml', 'prometheus/templates/secret-registry.yaml', 'ldap/values.yaml', 'prometheus-alertmanager/values.yaml', 'prometheus-openstack-exporter/templates/secret-registry.yaml', 'elastic-metricbeat/values.yaml', 'elastic-filebeat/values.yaml', 'ceph-provisioners/templates/secret-registry.yaml', 'openvswitch/values.yaml', 'elasticsearch/templates/secret-registry.yaml', 'ceph-client/values.yaml', 'tiller/templates/secret-registry.yaml', 'kibana/templates/secret-registry.yaml', 'redis/templates/secret-registry.yaml', 'prometheus/values.yaml', 'calico/values.yaml', 'elastic-apm-server/templates/secret-registry.yaml', 'falco/values.yaml', 'nfs-provisioner/templates/secret-registry.yaml', 'kube-dns/values.yaml', 'prometheus-kube-state-metrics/values.yaml', 'nagios/templates/secret-registry.yaml', 'tiller/values.yaml', 'prometheus-openstack-exporter/values.yaml', 'ceph-mon/templates/secret-registry.yaml', 'ceph-osd/values.yaml', 'ldap/templates/secret-registry.yaml', 'prometheus-process-exporter/values.yaml', 'ceph-rgw/values.yaml', 'libvirt/templates/secret-registry.yaml', 'gnocchi/templates/secret-registry.yaml', 'helm-toolkit/templates/manifests/_secret-registry.yaml.tpl', 'elastic-filebeat/templates/secret-registry.yaml', 'helm-toolkit/templates/snippets/_kubernetes_pod_rbac_serviceaccount.tpl', 'ceph-client/templates/secret-registry.yaml', 'etcd/values.yaml', 'elastic-apm-server/values.yaml', 'gnocchi/values.yaml', 'flannel/values.yaml', 'prometheus-alertmanager/templates/secret-registry.yaml', 'kubernetes-keystone-webhook/values.yaml', 'rabbitmq/values.yaml', 'ceph-mon/values.yaml', 'calico/templates/secret-registry.yaml', 'kubernetes-keystone-webhook/templates/secret-registry.yaml', 'grafana/values.yaml', 'memcached/values.yaml', 'nagios/values.yaml', 'registry/values.yaml', 'grafana/templates/secret-registry.yaml', 'mariadb/templates/secret-registry.yaml', 'ceph-rgw/templates/secret-registry.yaml', 'mariadb/values.yaml', 'nfs-provisioner/values.yaml', 'postgresql/values.yaml', 'mongodb/templates/secret-registry.yaml', 'rabbitmq/templates/secret-registry.yaml', 'redis/values.yaml', 'postgresql/templates/secret-registry.yaml', 'ceph-provisioners/values.yaml', 'ingress/templates/secret-registry.yaml', 'prometheus-node-exporter/values.yaml', 'elastic-metricbeat/templates/secret-registry.yaml', 'ingress/values.yaml', 'kibana/values.yaml', 'falco/templates/secret-registry.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8118ba14f0f4591de4f51aee5342389edd4f08f7', 'message': 'Add registry authentication support\n\nAdds support in helm-toolkit to authenticate against a registry by\nadding imagePullSecrets to the ServiceAccount.\n\nAlso add support for the authentication in each of the repository.\n\nChange-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6\nImplements: blueprint support-oci-image-registry-with-authentication-turned-on\nSigned-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>\n'}]",20,651585,8118ba14f0f4591de4f51aee5342389edd4f08f7,51,10,15,28101,,,0,"Add registry authentication support

Adds support in helm-toolkit to authenticate against a registry by
adding imagePullSecrets to the ServiceAccount.

Also add support for the authentication in each of the repository.

Change-Id: Id9fca020c351683c25ebe83d65e3da2c779bd9b6
Implements: blueprint support-oci-image-registry-with-authentication-turned-on
Signed-off-by: Pierre Gaxatte <pierre.gaxatte@corp.ovh.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/85/651585/8 && git format-patch -1 --stdout FETCH_HEAD,"['helm-toolkit/templates/snippets/_kubernetes_pod_rbac_serviceaccount.tpl', 'helm-toolkit/templates/manifests/_secret-registry.yaml.tpl']",2,bfabbff0afee9ffc2884106bde64ea1261f982f5,bp/support-oci-image-registry-with-authentication-turned-on,"{{- define ""helm-toolkit.manifests.secret_registry"" -}} {{- $envAll := index . ""envAll"" }} {{- $registryUser := index . ""registryUser"" }} {{- $secretName := index $envAll.Values.secrets.oci_image_registry $registryUser }} {{- $registryHost := tuple ""oci_image_registry"" ""internal"" $envAll | include ""helm-toolkit.endpoints.endpoint_host_lookup"" }} {{- $registryPort := tuple ""oci_image_registry"" ""internal"" ""registry"" $envAll | include ""helm-toolkit.endpoints.endpoint_port_lookup"" }} {{- $imageCredentials := index $envAll.Values.endpoints.oci_image_registry.auth $registryUser }} {{- $dockerAuthToken := printf ""%s:%s"" $imageCredentials.username $imageCredentials.password | b64enc }} {{- $dockerAuth := """" -}} {{- if eq $registryPort ""443"" -}} {{- $dockerAuth = printf ""{\""auths\"": {\""%s\"": {\""auth\"": \""%s\""}}}"" $registryHost $dockerAuthToken | b64enc }} {{- else -}} {{- $dockerAuth = printf ""{\""auths\"": {\""%s:%s\"": {\""auth\"": \""%s\""}}}"" $registryHost $registryPort $dockerAuthToken | b64enc }} {{- end -}} --- apiVersion: v1 kind: Secret metadata: name: {{ $secretName }} type: kubernetes.io/dockerconfigjson data: .dockerconfigjson: {{ $dockerAuth }} {{- end }} ",,27,0
openstack%2Fpython-ironicclient~master~Ia9bfa3059ec5d6ca1e40258c9f5b9805660bd710,openstack/python-ironicclient,master,Ia9bfa3059ec5d6ca1e40258c9f5b9805660bd710,remove py37,ABANDONED,2021-01-03 08:58:11.000000000,2021-01-05 07:15:43.000000000,,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 32238}]","[{'number': 1, 'created': '2021-01-03 08:58:11.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/710822ee6316fc19c77b99cf94a5c2da65825232', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: Ia9bfa3059ec5d6ca1e40258c9f5b9805660bd710\n""}]",0,769044,710822ee6316fc19c77b99cf94a5c2da65825232,7,5,1,31825,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: Ia9bfa3059ec5d6ca1e40258c9f5b9805660bd710
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/44/769044/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,710822ee6316fc19c77b99cf94a5c2da65825232,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fvitrage-specs~master~If0ce15d90e698ca58a6f00ffb6675250f375cca8,openstack/vitrage-specs,master,If0ce15d90e698ca58a6f00ffb6675250f375cca8,Remove unicode  from specs,MERGED,2021-01-03 01:59:13.000000000,2021-01-05 07:09:27.000000000,2021-01-05 07:08:20.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 01:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/10819db522c7a06549c0925e201d949089d601ac', 'message': 'Remove unicode  from specs\n\nChange-Id: If0ce15d90e698ca58a6f00ffb6675250f375cca8\n'}, {'number': 2, 'created': '2021-01-05 06:54:42.000000000', 'files': ['specs/mitaka/aodh-notifier.rst', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/099e9fd543897da1607aff4bd1fa69a4c2e04942', 'message': 'Remove unicode  from specs\n\nChange-Id: If0ce15d90e698ca58a6f00ffb6675250f375cca8\n'}]",0,768902,099e9fd543897da1607aff4bd1fa69a4c2e04942,11,2,2,32577,,,0,"Remove unicode  from specs

Change-Id: If0ce15d90e698ca58a6f00ffb6675250f375cca8
",git fetch https://review.opendev.org/openstack/vitrage-specs refs/changes/02/768902/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/mitaka/aodh-notifier.rst', 'doc/source/conf.py']",2,10819db522c7a06549c0925e201d949089d601ac,remove-unicode,"project = 'Vitrage Specs' copyright = '%s, OpenStack Vitrage Team' % datetime.date.today().year ('index', 'Vitrage-specs.tex', 'Vitrage Specs', 'OpenStack Vitrage Team', 'manual'), ('index', 'Vitrage-specs', 'Vitrage Design Specs', 'OpenStack Vitrage Team', 'vitrage-specs', 'Design specifications for the Vitrage project.',epub_title = 'Vitrage Specs' epub_author = 'OpenStack Vitrage Team' epub_publisher = 'OpenStack Vitrage Team' epub_copyright = '2014, OpenStack Vitrage Team'","project = u'Vitrage Specs' copyright = u'%s, OpenStack Vitrage Team' % datetime.date.today().year ('index', 'Vitrage-specs.tex', u'Vitrage Specs', u'OpenStack Vitrage Team', 'manual'), ('index', 'Vitrage-specs', u'Vitrage Design Specs', u'OpenStack Vitrage Team', 'vitrage-specs', 'Design specifications for the Vitrage project.',epub_title = u'Vitrage Specs' epub_author = u'OpenStack Vitrage Team' epub_publisher = u'OpenStack Vitrage Team' epub_copyright = u'2014, OpenStack Vitrage Team'",12,12
openstack%2Fvitrage-dashboard~master~I20c7c90e1d6b56e00bb28b1854dee1a629aa09c5,openstack/vitrage-dashboard,master,I20c7c90e1d6b56e00bb28b1854dee1a629aa09c5,Update TOX_CONSTRAINTS_FILE,MERGED,2020-12-18 09:31:24.000000000,2021-01-05 07:07:33.000000000,2021-01-05 07:04:56.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 09:31:24.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/0183ecc648b45e0e6030816ed314479ba43ce57b', 'message': 'Update TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I20c7c90e1d6b56e00bb28b1854dee1a629aa09c5\n'}]",0,767684,0183ecc648b45e0e6030816ed314479ba43ce57b,7,2,1,32291,,,0,"Update TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I20c7c90e1d6b56e00bb28b1854dee1a629aa09c5
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/84/767684/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0183ecc648b45e0e6030816ed314479ba43ce57b,, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},2,2
openstack%2Fvitrage-tempest-plugin~master~I5995ba0dc020fa40ddf66b7ac9f36220967b670e,openstack/vitrage-tempest-plugin,master,I5995ba0dc020fa40ddf66b7ac9f36220967b670e,Remove unicode  from tempest,MERGED,2021-01-03 07:59:10.000000000,2021-01-05 07:06:58.000000000,2021-01-05 07:05:28.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 07:59:10.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/6f1f921662c853137c04e070427dfafc03f10efe', 'message': 'Remove unicode  from tempest\n\nChange-Id: I5995ba0dc020fa40ddf66b7ac9f36220967b670e\n'}]",0,768995,6f1f921662c853137c04e070427dfafc03f10efe,7,2,1,32577,,,0,"Remove unicode  from tempest

Change-Id: I5995ba0dc020fa40ddf66b7ac9f36220967b670e
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/95/768995/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,6f1f921662c853137c04e070427dfafc03f10efe,remove-unicode,"project = 'virtage_tempest_plugin Release Notes' copyright = '2017, OpenStack Developers' 'virtage_tempest_plugin Release Notes Documentation', 'OpenStack Foundation', 'manual'), 'virtage_tempest_plugin Release Notes Documentation', ['OpenStack Foundation'], 1) 'virtage_tempest_plugin Release Notes Documentation', 'OpenStack Foundation', 'virtage_tempest_pluginReleaseNotes',","project = u'virtage_tempest_plugin Release Notes' copyright = u'2017, OpenStack Developers' u'virtage_tempest_plugin Release Notes Documentation', u'OpenStack Foundation', 'manual'), u'virtage_tempest_plugin Release Notes Documentation', [u'OpenStack Foundation'], 1) u'virtage_tempest_plugin Release Notes Documentation', u'OpenStack Foundation', 'virtage_tempest_pluginReleaseNotes',",12,12
openstack%2Ftempest~master~Ida420005fbf87f60cddde53f5f4a6842e4878597,openstack/tempest,master,Ida420005fbf87f60cddde53f5f4a6842e4878597,Change tenant_* to project_*,ABANDONED,2021-01-03 08:56:14.000000000,2021-01-05 07:06:31.000000000,,"[{'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2021-01-03 08:56:14.000000000', 'files': ['tempest/lib/services/compute/project_usages_client.py', 'tempest/tests/lib/services/compute/test_project_usages_client.py', 'tempest/clients.py', 'tempest/api/compute/admin/test_simple_project_usage_negative.py', 'tempest/lib/api_schema/response/compute/v2_1/project_usages.py', 'tempest/api/compute/admin/test_simple_project_usage.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cb35a13f482d0996867260204b3d8f9d23f65d9b', 'message': 'Change tenant_* to project_*\n\nDepends-On: I62efd6b1334f70146c62d145661df1bac49912dc\nChange-Id: Ida420005fbf87f60cddde53f5f4a6842e4878597\n'}]",0,769043,cb35a13f482d0996867260204b3d8f9d23f65d9b,5,2,1,31412,,,0,"Change tenant_* to project_*

Depends-On: I62efd6b1334f70146c62d145661df1bac49912dc
Change-Id: Ida420005fbf87f60cddde53f5f4a6842e4878597
",git fetch https://review.opendev.org/openstack/tempest refs/changes/43/769043/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/services/compute/project_usages_client.py', 'tempest/tests/lib/services/compute/test_project_usages_client.py', 'tempest/clients.py', 'tempest/api/compute/admin/test_simple_project_usage_negative.py', 'tempest/lib/api_schema/response/compute/v2_1/project_usages.py', 'tempest/api/compute/admin/test_simple_project_usage.py']",6,cb35a13f482d0996867260204b3d8f9d23f65d9b,bp/remove-tenant-id,"# Copyright 2013 NEC Corporation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from tempest.api.compute import base from tempest.lib.common.utils import test_utils from tempest.lib import decorators from tempest.lib import exceptions as e # Time that waits for until returning valid response # TODO(takmatsu): Ideally this value would come from configuration. VALID_WAIT = 30 class ProjectUsagesTestJSON(base.BaseV2ComputeAdminTest): """"""Test tenant usages"""""" @classmethod def setup_clients(cls): super(ProjectUsagesTestJSON, cls).setup_clients() cls.adm_client = cls.os_admin.project_usages_client cls.client = cls.os_primary.project_usages_client @classmethod def resource_setup(cls): super(ProjectUsagesTestJSON, cls).resource_setup() cls.project_id = cls.client.project_id # Create a server in the demo tenant cls.create_test_server(wait_until='ACTIVE') now = datetime.datetime.now() cls.start = cls._parse_strtime(now - datetime.timedelta(days=1)) cls.end = cls._parse_strtime(now + datetime.timedelta(days=1)) @classmethod def _parse_strtime(cls, at): # Returns formatted datetime return at.strftime('%Y-%m-%dT%H:%M:%S.%f') def call_until_valid(self, func, duration, *args, **kwargs): # Call until get valid response for ""duration"" # because tenant usage doesn't become available immediately # after create VM. def is_valid(): try: self.resp = func(*args, **kwargs) return True except e.InvalidHTTPResponseBody: return False self.assertEqual(test_utils.call_until_true(is_valid, duration, 1), True, ""%s not return valid response in %s secs"" % ( func.__name__, duration)) return self.resp @decorators.idempotent_id('062c8ae9-9912-4249-8b51-e38d664e926e') def test_list_usage_all_projects(self): """"""Test getting usage for all tenants"""""" project_usage = self.call_until_valid( self.adm_client.list_project_usages, VALID_WAIT, start=self.start, end=self.end, detailed=""1"")['project_usages'][0] self.assertEqual(len(project_usage), 8) @decorators.idempotent_id('94135049-a4c5-4934-ad39-08fa7da4f22e') def test_get_usage_project(self): """"""Test getting usage for a specific project"""""" project_usage = self.call_until_valid( self.adm_client.show_project_usage, VALID_WAIT, self.project_id, start=self.start, end=self.end)['project_usage'] self.assertEqual(len(project_usage), 8) @decorators.idempotent_id('9d00a412-b40e-4fd9-8eba-97b496316116') def test_get_usage_project_with_non_admin_user(self): """"""Test getting usage for a specific tenant with non admin user"""""" project_usage = self.call_until_valid( self.client.show_project_usage, VALID_WAIT, self.project_id, start=self.start, end=self.end)['project_usage'] self.assertEqual(len(project_usage), 8) ","# Copyright 2013 NEC Corporation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from tempest.api.compute import base from tempest.lib.common.utils import test_utils from tempest.lib import decorators from tempest.lib import exceptions as e # Time that waits for until returning valid response # TODO(takmatsu): Ideally this value would come from configuration. VALID_WAIT = 30 class TenantUsagesTestJSON(base.BaseV2ComputeAdminTest): """"""Test tenant usages"""""" @classmethod def setup_clients(cls): super(TenantUsagesTestJSON, cls).setup_clients() cls.adm_client = cls.os_admin.tenant_usages_client cls.client = cls.os_primary.tenant_usages_client @classmethod def resource_setup(cls): super(TenantUsagesTestJSON, cls).resource_setup() cls.tenant_id = cls.client.tenant_id # Create a server in the demo tenant cls.create_test_server(wait_until='ACTIVE') now = datetime.datetime.now() cls.start = cls._parse_strtime(now - datetime.timedelta(days=1)) cls.end = cls._parse_strtime(now + datetime.timedelta(days=1)) @classmethod def _parse_strtime(cls, at): # Returns formatted datetime return at.strftime('%Y-%m-%dT%H:%M:%S.%f') def call_until_valid(self, func, duration, *args, **kwargs): # Call until get valid response for ""duration"" # because tenant usage doesn't become available immediately # after create VM. def is_valid(): try: self.resp = func(*args, **kwargs) return True except e.InvalidHTTPResponseBody: return False self.assertEqual(test_utils.call_until_true(is_valid, duration, 1), True, ""%s not return valid response in %s secs"" % ( func.__name__, duration)) return self.resp @decorators.idempotent_id('062c8ae9-9912-4249-8b51-e38d664e926e') def test_list_usage_all_tenants(self): """"""Test getting usage for all tenants"""""" tenant_usage = self.call_until_valid( self.adm_client.list_tenant_usages, VALID_WAIT, start=self.start, end=self.end, detailed=""1"")['tenant_usages'][0] self.assertEqual(len(tenant_usage), 8) @decorators.idempotent_id('94135049-a4c5-4934-ad39-08fa7da4f22e') def test_get_usage_tenant(self): """"""Test getting usage for a specific tenant"""""" tenant_usage = self.call_until_valid( self.adm_client.show_tenant_usage, VALID_WAIT, self.tenant_id, start=self.start, end=self.end)['tenant_usage'] self.assertEqual(len(tenant_usage), 8) @decorators.idempotent_id('9d00a412-b40e-4fd9-8eba-97b496316116') def test_get_usage_tenant_with_non_admin_user(self): """"""Test getting usage for a specific tenant with non admin user"""""" tenant_usage = self.call_until_valid( self.client.show_tenant_usage, VALID_WAIT, self.tenant_id, start=self.start, end=self.end)['tenant_usage'] self.assertEqual(len(tenant_usage), 8)",734,734
openstack%2Fvitrage-dashboard~master~I1e7cfcdfb4b811ad2c016a7ec1aff119c55575da,openstack/vitrage-dashboard,master,I1e7cfcdfb4b811ad2c016a7ec1aff119c55575da,remove py37,MERGED,2021-01-05 01:13:15.000000000,2021-01-05 07:06:19.000000000,2021-01-05 07:04:50.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 01:13:15.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/6acaab010eccb4d4cff3a5127b942065ed7cdae8', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I1e7cfcdfb4b811ad2c016a7ec1aff119c55575da\n""}]",0,769232,6acaab010eccb4d4cff3a5127b942065ed7cdae8,7,2,1,31825,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I1e7cfcdfb4b811ad2c016a7ec1aff119c55575da
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/32/769232/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,6acaab010eccb4d4cff3a5127b942065ed7cdae8,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fvitrage-dashboard~master~Ibaaa569b62bdb7f6f0d1cd4c8510a7d8270bf495,openstack/vitrage-dashboard,master,Ibaaa569b62bdb7f6f0d1cd4c8510a7d8270bf495,Remove unicode  from dashboard,MERGED,2021-01-03 07:55:26.000000000,2021-01-05 07:04:53.000000000,2021-01-05 07:04:53.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 07:55:26.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/7603de09b98b93128aea18a3808d2ae1ffe1126b', 'message': 'Remove unicode  from dashboard\n\nChange-Id: Ibaaa569b62bdb7f6f0d1cd4c8510a7d8270bf495\n'}]",0,768992,7603de09b98b93128aea18a3808d2ae1ffe1126b,6,2,1,32577,,,0,"Remove unicode  from dashboard

Change-Id: Ibaaa569b62bdb7f6f0d1cd4c8510a7d8270bf495
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/92/768992/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,7603de09b98b93128aea18a3808d2ae1ffe1126b,remove-unicode,"project = 'vitrage-dashboard releasenotes' copyright = '2016, Vitrage developers' '%s Vitrage-Dashboard ReleaseNotes' % project, 'Vitrage developers', 'manual'),","project = u'vitrage-dashboard releasenotes' copyright = u'2016, Vitrage developers' u'%s Vitrage-Dashboard ReleaseNotes' % project, u'Vitrage developers', 'manual'),",8,8
openstack%2Fvitrage~master~I8cf7a696bade952890a41d452196550add0c258d,openstack/vitrage,master,I8cf7a696bade952890a41d452196550add0c258d,remove unicode from code,MERGED,2021-01-04 06:35:45.000000000,2021-01-05 07:01:14.000000000,2021-01-05 06:59:58.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 06:35:45.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/52fee345ebdb0ccb140da523d4a683ecf9cc56e8', 'message': 'remove unicode from code\n\nChange-Id: I8cf7a696bade952890a41d452196550add0c258d\n'}]",0,769086,52fee345ebdb0ccb140da523d4a683ecf9cc56e8,7,2,1,32326,,,0,"remove unicode from code

Change-Id: I8cf7a696bade952890a41d452196550add0c258d
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/86/769086/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,52fee345ebdb0ccb140da523d4a683ecf9cc56e8,,"project = 'vitrage releasenotes' copyright = '2016, Vitrage developers' '%s Vitrage ReleaseNotes' % project, 'Vitrage developers', 'manual'),","project = u'vitrage releasenotes' copyright = u'2016, Vitrage developers' u'%s Vitrage ReleaseNotes' % project, u'Vitrage developers', 'manual'),",8,8
openstack%2Fpython-masakariclient~master~I2441e77bef1a1d2a9acdd6e42d3b2610e9ad8283,openstack/python-masakariclient,master,I2441e77bef1a1d2a9acdd6e42d3b2610e9ad8283,Fix docs reqs for new pip,MERGED,2021-01-04 16:55:58.000000000,2021-01-05 06:21:00.000000000,2021-01-05 06:18:45.000000000,"[{'_account_id': 22348}, {'_account_id': 32304}]","[{'number': 1, 'created': '2021-01-04 16:55:58.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-masakariclient/commit/435abc665475cc0f04a266eadd0a6edecb8e8e34', 'message': 'Fix docs reqs for new pip\n\nPer [1], the docs requirements were failing (or at least could)\ndue to test-requirements being used instead of doc/requirements.\nThe former may include dep versions not compatible with the\nupper-constraints and hence cause issues for the new pip resolver.\nThis patch fixes that.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n\nChange-Id: I2441e77bef1a1d2a9acdd6e42d3b2610e9ad8283\n'}]",0,769163,435abc665475cc0f04a266eadd0a6edecb8e8e34,7,2,1,30491,,,0,"Fix docs reqs for new pip

Per [1], the docs requirements were failing (or at least could)
due to test-requirements being used instead of doc/requirements.
The former may include dep versions not compatible with the
upper-constraints and hence cause issues for the new pip resolver.
This patch fixes that.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html

Change-Id: I2441e77bef1a1d2a9acdd6e42d3b2610e9ad8283
",git fetch https://review.opendev.org/openstack/python-masakariclient refs/changes/63/769163/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,435abc665475cc0f04a266eadd0a6edecb8e8e34,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = {[testenv:docs]deps},,8,5
openstack%2Fbifrost~master~I88178afd407a6339cfa42de14041c3897c3563e3,openstack/bifrost,master,I88178afd407a6339cfa42de14041c3897c3563e3,Disable inspector discovery by default,MERGED,2020-11-17 11:49:15.000000000,2021-01-05 06:16:14.000000000,2021-01-05 06:13:40.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 22348}, {'_account_id': 32177}]","[{'number': 1, 'created': '2020-11-17 11:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/71678012169f9468d09340b0ea88889fc22c0721', 'message': 'Disable inspector discovery by default\n\nThis change disables auto-discovery in ironic inspector. This will\nprevent issues where accidental booting of IPA might result in\nhard to debug situations where an accidentally booted IPA results\nin new node(s) / port(s) added, causing conflicts.\n\nChange-Id: I88178afd407a6339cfa42de14041c3897c3563e3\n'}, {'number': 2, 'created': '2020-11-17 21:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/78334a006c0e089e012637470e2d03a196e6fd97', 'message': 'Disable inspector discovery by default\n\nThis change disables auto-discovery in ironic inspector. This will\nprevent issues where accidental booting of IPA might result in\nhard to debug situations where an accidentally booted IPA results\nin new node(s) / port(s) added, causing conflicts.\n\nChange-Id: I88178afd407a6339cfa42de14041c3897c3563e3\n'}, {'number': 3, 'created': '2021-01-04 23:53:15.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/README.md', 'releasenotes/notes/disable-inspector-discovery-2437e3d9b74f5258.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/9258eeb228babae87e587964f593967145df30d3', 'message': 'Disable inspector discovery by default\n\nThis change disables auto-discovery in ironic inspector. This will\nprevent issues where accidental booting of IPA might result in\nhard to debug situations where an accidentally booted IPA results\nin new node(s) / port(s) added, causing conflicts.\n\nChange-Id: I88178afd407a6339cfa42de14041c3897c3563e3\n'}]",2,762998,9258eeb228babae87e587964f593967145df30d3,16,5,3,32177,,,0,"Disable inspector discovery by default

This change disables auto-discovery in ironic inspector. This will
prevent issues where accidental booting of IPA might result in
hard to debug situations where an accidentally booted IPA results
in new node(s) / port(s) added, causing conflicts.

Change-Id: I88178afd407a6339cfa42de14041c3897c3563e3
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/98/762998/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/README.md', 'releasenotes/notes/disable-inspector-discovery-2437e3d9b74f5258.yaml']",3,71678012169f9468d09340b0ea88889fc22c0721,disable-inspector-discovery,"--- features: - Discovery of nodes via the ironic-inspector is now disabled by default. If you wish to enable this, set ``enable_inspector_discovery`` to ``true`` and re-execute the installation playbook. ",,8,2
openstack%2Fswift~master~I1be1faec53b2cdfaabf927598f1460e23c206b0a,openstack/swift,master,I1be1faec53b2cdfaabf927598f1460e23c206b0a,Let developers/operators add watchers to object audit,MERGED,2020-02-08 04:32:48.000000000,2021-01-05 06:12:08.000000000,2021-01-05 06:08:57.000000000,"[{'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 13852}, {'_account_id': 15343}, {'_account_id': 18142}, {'_account_id': 22348}, {'_account_id': 25251}, {'_account_id': 28182}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-02-08 04:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e2071db74d4d0bc193f0a58d0256c79b56b4549', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 2, 'created': '2020-02-09 02:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fede08a106be90e23de49fd44887bb8caa3af6ca', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 3, 'created': '2020-02-10 01:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f9765bcf5efe0494617015f386eb9af6fc3487c1', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 4, 'created': '2020-02-15 03:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f03e8e06e850b8c3c45d5a1270b9ce75d651b40c', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 5, 'created': '2020-03-05 16:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/91b596c377e9211baa55332aa8eed8a63f52bdf3', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 6, 'created': '2020-03-05 16:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4c8e48c91cc476e83c5e606062bb9327b3ef7e3a', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 7, 'created': '2020-03-10 03:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5c58a1b6d097713c6ec7c8bb699968d9bd843d21', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 8, 'created': '2020-03-17 00:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3e7b5454dd923d768b29af456e2652743deecf71', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 9, 'created': '2020-03-17 00:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/57050f9fbd909403c3f06927b2f2dc3a9f7f0664', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 10, 'created': '2020-03-17 03:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d7c56c01082f03eb0727c7af3b3c233c6ed4a054', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 11, 'created': '2020-03-19 02:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/277b18101162798709392ea02ae486e5ccada9d4', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 12, 'created': '2020-05-20 15:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4a72c1b19ee6eb2c754e8c02bb987c103b200aa6', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, policy_index, object_metadata,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 13, 'created': '2020-06-06 05:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7f240a5a9af8fbe156ea40e6c16eccc9139a464d', 'message': ""WIP: Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 14, 'created': '2020-06-10 14:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3f901587a6be135e374bfc49f59c1e59e567c66c', 'message': ""WIP: Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 15, 'created': '2020-06-10 14:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dc9c67a26ce6f10002906202ad7ea524ce40bed2', 'message': ""WIP: Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 16, 'created': '2020-06-11 02:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/009c17a93478099a6a091af102a1b58782292d90', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 17, 'created': '2020-06-23 14:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/10f6e15e789b0bd69497642f13a587b0075dc03e', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 18, 'created': '2020-06-26 02:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b62e64f4845040d3d7ec2f95f6b79d2b239fecf2', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 19, 'created': '2020-07-08 20:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/05faa6530f12d3adcb51c1e662d5c14bfce6e966', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 20, 'created': '2020-07-09 15:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d4ed4f23ff3cc7af2707036d9a8c5324aff39a96', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 21, 'created': '2020-07-09 15:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a4ab7d873eef67a03b10174462b38701467fc38b', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 22, 'created': '2020-07-09 20:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8725750d7efb5a83def3a4b5f350c83fc7bfc731', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 23, 'created': '2020-07-10 04:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/685aee57611a78f59c11a9a8bb2542bb3d28df5c', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 24, 'created': '2020-07-21 23:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/06e4eec82a1f4a4ab9302236f82292119fe1beac', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 25, 'created': '2020-07-21 23:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0f8dfacf8a5e117e3679ee2e745d44dc29bc5071', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 26, 'created': '2020-07-22 10:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dbe4c09f40f5c0db0ca8863c9eec6fc5558d7543', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 27, 'created': '2020-07-22 13:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dd46912cda8225341dbb99c450dfc75ea33b3a1a', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 28, 'created': '2020-07-22 14:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/97d22ac51c32b275f80ea1fc371de33026615837', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 29, 'created': '2020-08-10 14:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9938facccebc45fa41c5ce62163e6fe208025e6c', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 30, 'created': '2020-09-07 15:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2eb4f0fc63528cb3ea8ac576da7068103cb9ab4b', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 31, 'created': '2020-10-02 14:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/187bcaa57161cd955924ac42d455fd6c8bb94f7f', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 32, 'created': '2020-10-02 14:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8290867021cdd864a549acdee0cd6ef809851840', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 33, 'created': '2020-10-04 11:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/456b16564288a7e908f498ac5a274313ceccd8ac', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 34, 'created': '2020-10-04 14:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/712a8bea6950fc0513c78431978f3e6a00fac101', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 35, 'created': '2020-10-04 16:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd7fbdf36c74de4246ee1fbec64d8dbce266aba4', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 36, 'created': '2020-10-12 12:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a01047624da1ea440f29e5089cee98c05cf08aa4', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 37, 'created': '2020-10-14 01:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/15f7f3880fbd94182b5b0414ea0c33de093fb250', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 38, 'created': '2020-10-28 19:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c4e1906ace36326924b2ca967510da90b4ae7256', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 39, 'created': '2020-11-05 01:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/69ec8930adddea666e026ca883f238368e7ff365', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to scan for objects with\nparticular MD5 checksums and take actions based on that (e.g. pirated\nmovies). Other operators may want to locate old DLO manifests and\nconvert them to SLO manifests. This can be used after a cluster fills\nup to locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 40, 'created': '2020-11-05 18:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/46a22c5e024a60162c223c9059e13635126a0d13', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, sequence_number, object_metadata, policy_index,\n              partition, **kwargs)\n\n   end(self, final_sequence_number, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 41, 'created': '2020-11-26 20:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a463427fb631a76917c1b7f3dfddda1eab99b847', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, policy_index, partition,\n              **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 42, 'created': '2020-12-03 05:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c981baefae6e6be50d8642cbb430437789373742', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, policy_index, partition, df,\n              **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hand, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 43, 'created': '2020-12-11 18:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b85a2fabdfbfbf0ceaf41fd031cb254930d92e9c', 'message': ""Let developers/operators add watchers to object audit (simplified)\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, policy_index, partition, df,\n              **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 44, 'created': '2020-12-12 01:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd99803fd5d13e22dfd572533b1e440ba637ae9a', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, policy_index, partition,\n              data_file_path, **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 45, 'created': '2020-12-16 22:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/227cf528276e2fccb839455af0282c331a05a470', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, policy_index, partition,\n              data_file_path, **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 46, 'created': '2020-12-24 06:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8fccb088e403dfa280d0f5130469432abccc8f62', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, policy_index, partition,\n              data_file_path, **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 47, 'created': '2020-12-26 21:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1bbd7bd83a3f0ea82083db7db34160485759d578', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, data_file_path, **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 48, 'created': '2020-12-26 23:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9748a99647b3914eeab08e3057ff728dcf7bbcbc', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, data_file_path, **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}, {'number': 49, 'created': '2020-12-26 23:25:40.000000000', 'files': ['test/probe/common.py', 'swift/obj/auditor.py', 'test/probe/test_sharder.py', 'swift/proxy/server.py', 'etc/object-server.conf-sample', 'swift/common/exceptions.py', 'test/unit/obj/test_auditor.py', 'doc/source/index.rst', 'swift/obj/watchers/__init__.py', 'swift/common/utils.py', 'setup.cfg', 'swift/obj/watchers/dark_data.py', 'doc/source/development_watchers.rst', 'test/probe/test_dark_data.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b97128090726db8818fccfc0de559c23d871c9fa', 'message': ""Let developers/operators add watchers to object audit\n\nSwift operators may find it useful to operate on each object in their\ncluster in some way. This commit provides them a way to hook into the\nobject auditor with a simple, clearly-defined boundary so that they\ncan iterate over their objects without additional disk IO.\n\nFor example, a cluster operator may want to ensure a semantic\nconsistency with all SLO segments accounted in their manifests,\nor locate objects that aren't in container listings. Now that Swift\nhas encryption support, this could be used to locate unencrypted\nobjects. The list goes on.\n\nThis commit makes the auditor locate, via entry points, the watchers\nnamed in its config file.\n\nA watcher is a class with at least these four methods:\n\n   __init__(self, conf, logger, **kwargs)\n\n   start(self, audit_type, **kwargs)\n\n   see_object(self, object_metadata, data_file_path, **kwargs)\n\n   end(self, **kwargs)\n\nThe auditor will call watcher.start(audit_type) at the start of an\naudit pass, watcher.see_object(...) for each object audited, and\nwatcher.end() at the end of an audit pass. All method arguments are\npassed as keyword args.\n\nThis version of the API is implemented on the context of the\nauditor itself, without spawning any additional processes.\nIf the plugins are not working well -- hang, crash, or leak --\nit's easier to debug them when there's no additional complication\nof processes that run by themselves.\n\nIn addition, we include a reference implementation of plugin for\nthe watcher API, as a help to plugin writers.\n\nChange-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a\n""}]",164,706653,b97128090726db8818fccfc0de559c23d871c9fa,170,10,49,597,,,0,"Let developers/operators add watchers to object audit

Swift operators may find it useful to operate on each object in their
cluster in some way. This commit provides them a way to hook into the
object auditor with a simple, clearly-defined boundary so that they
can iterate over their objects without additional disk IO.

For example, a cluster operator may want to ensure a semantic
consistency with all SLO segments accounted in their manifests,
or locate objects that aren't in container listings. Now that Swift
has encryption support, this could be used to locate unencrypted
objects. The list goes on.

This commit makes the auditor locate, via entry points, the watchers
named in its config file.

A watcher is a class with at least these four methods:

   __init__(self, conf, logger, **kwargs)

   start(self, audit_type, **kwargs)

   see_object(self, object_metadata, data_file_path, **kwargs)

   end(self, **kwargs)

The auditor will call watcher.start(audit_type) at the start of an
audit pass, watcher.see_object(...) for each object audited, and
watcher.end() at the end of an audit pass. All method arguments are
passed as keyword args.

This version of the API is implemented on the context of the
auditor itself, without spawning any additional processes.
If the plugins are not working well -- hang, crash, or leak --
it's easier to debug them when there's no additional complication
of processes that run by themselves.

In addition, we include a reference implementation of plugin for
the watcher API, as a help to plugin writers.

Change-Id: I1be1faec53b2cdfaabf927598f1460e23c206b0a
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/706653/48 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/obj/auditor.py', 'setup.cfg', 'etc/object-server.conf-sample']",4,1e2071db74d4d0bc193f0a58d0256c79b56b4549,auditor_212824_alt,"# A comma-separated list of watcher entry points. This lets operators # programmatically see audited objects. # # The entry point group name is ""swift.object_audit_watcher"". If your # setup.py has something like this: # # entry_points={'swift.object_audit_watcher': [ # 'some_watcher = some_module:Watcher']} # # then you would enable it with ""watchers = some_package#some_watcher"". # For example, the built-in reference implementation is enabled as # ""watchers = swift#dark_data_watcher"". # # watchers = # Time to wait (in seconds) between sending the stop sentinel via the # processing queue and sending a SIGTERM. # # watcher_term_timeout = 30 # Time to wait (in seconds) between sending a SIGTERM and a SIGKILL # to clean up unresponsive watchers. # # watcher_kill_timeout = 5 ",,268,9
openstack%2Foslo.limit~master~Ic7a7b9cfb0607f652b86fa9098fe5ce26c74a4e9,openstack/oslo.limit,master,Ic7a7b9cfb0607f652b86fa9098fe5ce26c74a4e9,[ci] fix openstack-lower-constraints-jobs,ABANDONED,2020-12-23 06:16:24.000000000,2021-01-05 05:14:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-23 06:16:24.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/fdf4a168b36d1a3dc63b6bc2da34688427001611', 'message': '[ci] fix openstack-lower-constraints-jobs\n\nChange-Id: Ic7a7b9cfb0607f652b86fa9098fe5ce26c74a4e9\n'}]",0,768303,fdf4a168b36d1a3dc63b6bc2da34688427001611,3,1,1,32029,,,0,"[ci] fix openstack-lower-constraints-jobs

Change-Id: Ic7a7b9cfb0607f652b86fa9098fe5ce26c74a4e9
",git fetch https://review.opendev.org/openstack/oslo.limit refs/changes/03/768303/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,fdf4a168b36d1a3dc63b6bc2da34688427001611,ci,keystoneauth1==3.14.0oslo.i18n==3.20.0,keystoneauth1==3.9.0oslo.i18n==3.15.3,4,4
openstack%2Fmagnum~master~If3547cac812890003582ac8010ea7d955c109187,openstack/magnum,master,If3547cac812890003582ac8010ea7d955c109187,Remove the unused coding style modules,ABANDONED,2020-10-27 03:45:04.000000000,2021-01-05 05:12:21.000000000,,"[{'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-10-27 03:45:04.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d4bd64011b0892a7b4025c2656fc8561d55cc612', 'message': 'Remove the unused coding style modules\n\nPython modules related to coding style checks (listed in blacklist.txt in\nopenstack/requirements repo) are dropped from lower-constraints.txt\nthey are not needed during installation.\n\nChange-Id: If3547cac812890003582ac8010ea7d955c109187\n'}]",0,759796,d4bd64011b0892a7b4025c2656fc8561d55cc612,7,2,1,32029,,,0,"Remove the unused coding style modules

Python modules related to coding style checks (listed in blacklist.txt in
openstack/requirements repo) are dropped from lower-constraints.txt
they are not needed during installation.

Change-Id: If3547cac812890003582ac8010ea7d955c109187
",git fetch https://review.opendev.org/openstack/magnum refs/changes/96/759796/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,d4bd64011b0892a7b4025c2656fc8561d55cc612,remove_pkg,,mccabe==0.2.1,0,1
openstack%2Fmagnum~master~I1bfcac06669050f687fb79543e44b77e1e96a66f,openstack/magnum,master,I1bfcac06669050f687fb79543e44b77e1e96a66f,remove repeat packages stestr from lower-constraints.txt.,ABANDONED,2020-10-09 02:38:54.000000000,2021-01-05 05:11:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-10-09 02:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8f7596a273e1bd0ee8c2168bd5d44afc78d42542', 'message': 'Drop os-testr from lower-constraints.txt.\n\nChange-Id: I1bfcac06669050f687fb79543e44b77e1e96a66f\n'}, {'number': 2, 'created': '2020-10-10 03:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/785c462d7d1198918452383b73e5130f870740a1', 'message': 'Drop os-testr from lower-constraints.txt.\n\nChange-Id: I1bfcac06669050f687fb79543e44b77e1e96a66f\n'}, {'number': 3, 'created': '2020-10-10 03:22:01.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/0e9cf1def9fa37363638af5fce51235c94a576da', 'message': 'remove repeat packages stestr from lower-constraints.txt.\n\nChange-Id: I1bfcac06669050f687fb79543e44b77e1e96a66f\n'}]",0,756978,0e9cf1def9fa37363638af5fce51235c94a576da,6,1,3,32029,,,0,"remove repeat packages stestr from lower-constraints.txt.

Change-Id: I1bfcac06669050f687fb79543e44b77e1e96a66f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/78/756978/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,8f7596a273e1bd0ee8c2168bd5d44afc78d42542,drop_Repeat_package,,os-testr==1.0.0,0,1
openstack%2Fpuppet-neutron~master~Ib91b8215ff8f07d7e81382cd197d583b6657cc42,openstack/puppet-neutron,master,Ib91b8215ff8f07d7e81382cd197d583b6657cc42,Deprecate parameters for LBaaS quotas,MERGED,2020-12-24 07:32:06.000000000,2021-01-05 04:51:11.000000000,2021-01-05 04:50:00.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-24 07:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/40ffaa9f3232166ece66b56fc27de3083e7c7c58', 'message': 'Deprecate parameters for LBaaS quotas\n\n... because Neutron LBaaS was deprecated a while ago.\n\nChange-Id: Ib91b8215ff8f07d7e81382cd197d583b6657cc42\n'}, {'number': 2, 'created': '2020-12-25 00:39:20.000000000', 'files': ['releasenotes/notes/deprecate-lbaas-quotas-22c3a82c482991ad.yaml', 'spec/classes/neutron_quota_spec.rb', 'manifests/quota.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/4ca9ac106243433eebca1492218d72718617d1d0', 'message': 'Deprecate parameters for LBaaS quotas\n\n... because Neutron LBaaS was deprecated a while ago.\n\nChange-Id: Ib91b8215ff8f07d7e81382cd197d583b6657cc42\n'}]",0,768438,4ca9ac106243433eebca1492218d72718617d1d0,16,3,2,9816,,,0,"Deprecate parameters for LBaaS quotas

... because Neutron LBaaS was deprecated a while ago.

Change-Id: Ib91b8215ff8f07d7e81382cd197d583b6657cc42
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/38/768438/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_quota_spec.rb', 'manifests/quota.pp', 'releasenotes/notes/dperecate-lbaas-quotas-f474da8afed8323e.yaml']",3,40ffaa9f3232166ece66b56fc27de3083e7c7c58,quota,--- deprecations: - | The parameters for quotas in Neutron LBaaS v2 have been deprecated and have no effect. These parameters will be removed in a future release. - ``neutron::quota::quota_loadbalancer`` - ``neutron::quota::quota_pool`` - ``neutron::quota::quota_member`` ,,45,24
openstack%2Ftrove~master~I2684608c4e8ae71a9ded46e54cdba926af6b82f3,openstack/trove,master,I2684608c4e8ae71a9ded46e54cdba926af6b82f3,remove py37,MERGED,2020-12-26 04:43:20.000000000,2021-01-05 04:41:54.000000000,2021-01-05 04:40:30.000000000,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-26 04:43:20.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove/commit/bdb00f659dbae665dff1d3951e9972a0b867ef08', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I2684608c4e8ae71a9ded46e54cdba926af6b82f3\n""}]",0,768524,bdb00f659dbae665dff1d3951e9972a0b867ef08,12,3,1,32029,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I2684608c4e8ae71a9ded46e54cdba926af6b82f3
",git fetch https://review.opendev.org/openstack/trove refs/changes/24/768524/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,bdb00f659dbae665dff1d3951e9972a0b867ef08,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fvitrage-tempest-plugin~master~I90f65e3b76332803f2f9b0367b1c77d5c677159f,openstack/vitrage-tempest-plugin,master,I90f65e3b76332803f2f9b0367b1c77d5c677159f,remove py37,MERGED,2021-01-05 01:17:08.000000000,2021-01-05 04:34:15.000000000,2021-01-05 04:33:13.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 01:17:08.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/021dab338243740957329616008c8665be544846', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I90f65e3b76332803f2f9b0367b1c77d5c677159f\n""}]",0,769233,021dab338243740957329616008c8665be544846,7,2,1,31825,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I90f65e3b76332803f2f9b0367b1c77d5c677159f
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/33/769233/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,021dab338243740957329616008c8665be544846,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fpython-tripleoclient~stable%2Fussuri~If5545e4ce4ee170f38634bc2366775e36657d6c0,openstack/python-tripleoclient,stable/ussuri,If5545e4ce4ee170f38634bc2366775e36657d6c0,Lower ansible poll interval time,MERGED,2020-09-14 18:22:05.000000000,2021-01-05 03:30:21.000000000,2021-01-05 03:29:07.000000000,"[{'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-09-14 18:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a8d74c2503b70e55cef53b6ea3b18d14a860ff98', 'message': ""Lower ansible poll interval time\n\nCurrently we set poll interval in ansible to 0.05 which means it'll wait\n50ms.  The default is 0.001 which at scale is too cpu intensive.  That\nbeing said, waiting 50ms for each task across all hosts increases\noverall execution time. Let's lower it to 0.01 as a middle ground\nbetween the current 0.05 and the 0.001 default.\n\nChange-Id: If5545e4ce4ee170f38634bc2366775e36657d6c0\n(cherry picked from commit c9afd24dbcf8f2aeb6991413a72cad483dc5a08a)\n""}, {'number': 2, 'created': '2021-01-04 15:33:19.000000000', 'files': ['tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f4f5c7f0d47b9a1795c8141ba700eaa01f2c3688', 'message': ""Lower ansible poll interval time\n\nCurrently we set poll interval in ansible to 0.05 which means it'll wait\n50ms.  The default is 0.001 which at scale is too cpu intensive.  That\nbeing said, waiting 50ms for each task across all hosts increases\noverall execution time. Let's lower it to 0.01 as a middle ground\nbetween the current 0.05 and the 0.001 default.\n\nChange-Id: If5545e4ce4ee170f38634bc2366775e36657d6c0\n(cherry picked from commit c9afd24dbcf8f2aeb6991413a72cad483dc5a08a)\n""}]",0,751877,f4f5c7f0d47b9a1795c8141ba700eaa01f2c3688,16,4,2,14985,,,0,"Lower ansible poll interval time

Currently we set poll interval in ansible to 0.05 which means it'll wait
50ms.  The default is 0.001 which at scale is too cpu intensive.  That
being said, waiting 50ms for each task across all hosts increases
overall execution time. Let's lower it to 0.01 as a middle ground
between the current 0.05 and the 0.001 default.

Change-Id: If5545e4ce4ee170f38634bc2366775e36657d6c0
(cherry picked from commit c9afd24dbcf8f2aeb6991413a72cad483dc5a08a)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/77/751877/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,a8d74c2503b70e55cef53b6ea3b18d14a860ff98,improve-responsiveness-stable/ussuri," config.set('defaults', 'internal_poll_interval', '0.01')"," config.set('defaults', 'internal_poll_interval', '0.05')",1,1
openstack%2Fpython-tripleoclient~stable%2Fvictoria~I992af413aea66dc2978e535ead757db7114becf8,openstack/python-tripleoclient,stable/victoria,I992af413aea66dc2978e535ead757db7114becf8,Update TOX_CONSTRAINTS_FILE for stable/victoria,MERGED,2020-10-26 13:05:05.000000000,2021-01-05 02:53:54.000000000,2021-01-05 02:52:47.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-26 13:05:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e6dd17dab8c8b042b0f076f139fbf5e1e24a3aff', 'message': 'Update TOX_CONSTRAINTS_FILE for stable/victoria\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/victoria branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I992af413aea66dc2978e535ead757db7114becf8\n'}]",0,759681,e6dd17dab8c8b042b0f076f139fbf5e1e24a3aff,7,2,1,22816,,,0,"Update TOX_CONSTRAINTS_FILE for stable/victoria

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/victoria branch, tests will
continue to use the upper-constraints list on master.

Change-Id: I992af413aea66dc2978e535ead757db7114becf8
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/81/759681/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e6dd17dab8c8b042b0f076f139fbf5e1e24a3aff,create-victoria, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/victoria} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/victoria} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/victoria}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},3,3
openstack%2Fpuppet-tripleo~master~I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,openstack/puppet-tripleo,master,I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b,Adding key_size option on the certmonger_certificate function,MERGED,2020-10-09 16:00:05.000000000,2021-01-05 02:52:29.000000000,2021-01-05 02:52:29.000000000,"[{'_account_id': 7353}, {'_account_id': 8866}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28182}]","[{'number': 1, 'created': '2020-10-09 16:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/dd5a6375c7aadde7107174f0029a8176feba9a57', 'message': '[WIP]Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on:\nhttps://github.com/saltedsignal/puppet-certmonger/pull/27\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 2, 'created': '2020-11-03 13:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2d7f946223a864a1fb5b271eb9b1171ee7c451b0', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on:\nhttps://github.com/saltedsignal/puppet-certmonger/pull/27\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 3, 'created': '2020-11-12 13:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e42db8a030cd74b0740db36f1208dd188cfd22c4', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on:\nhttps://github.com/saltedsignal/puppet-certmonger/pull/27\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 4, 'created': '2020-11-19 21:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4bd4972126c09a32d6fc8cc8635759500e560133', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on:\nhttps://github.com/saltedsignal/puppet-certmonger/pull/27\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 5, 'created': '2020-11-30 12:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7cc3ef8ba410ba4e3ad17fc0a47269d0aa4575e5', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.4.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.4.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 6, 'created': '2020-12-15 18:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4d26c81f5d917b70fca3df5e810b07fdc3d72c86', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 7, 'created': '2020-12-16 11:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ef92ea221d2d083a8b4deb16efea198a087571ea', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}, {'number': 8, 'created': '2020-12-17 23:22:36.000000000', 'files': ['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/novnc_proxy.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'Puppetfile_extras', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp', 'manifests/certmonger/memcached.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/190aebca609e8ec68586cfa4ced9f2efa65758d1', 'message': 'Adding key_size option on the certmonger_certificate function\n\ncertmonger_certificate function currently does not support\ncreating certificates with private keys stronger than 2048bits.\nAdding a key_size option.\n\nkey_size option were added on puppet_certmonger on the v2.6.0\nupstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0\n\nChange-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b\n'}]",0,757142,190aebca609e8ec68586cfa4ced9f2efa65758d1,50,7,8,8866,,,0,"Adding key_size option on the certmonger_certificate function

certmonger_certificate function currently does not support
creating certificates with private keys stronger than 2048bits.
Adding a key_size option.

key_size option were added on puppet_certmonger on the v2.6.0
upstream: https://github.com/saltedsignal/puppet-certmonger/releases/tag/v2.6.0

Change-Id: I4da96f2164cf1d136f9471f1d6251bdd8cfd2d0b
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/42/757142/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/certmonger/ovn_metadata.pp', 'manifests/certmonger/ovn_octavia.pp', 'manifests/certmonger/ovn_dbs.pp', 'manifests/certmonger/ceph_grafana.pp', 'manifests/certmonger/libvirt.pp', 'manifests/certmonger/ovn_controller.pp', 'manifests/certmonger/redis.pp', 'manifests/certmonger/neutron_ovn.pp', 'manifests/certmonger/openvswitch.pp', 'manifests/certmonger/qemu.pp', 'manifests/certmonger/libvirt_vnc.pp', 'manifests/certmonger/rabbitmq.pp', 'manifests/certmonger/ceph_dashboard.pp', 'manifests/certmonger/neutron.pp', 'manifests/certmonger/haproxy.pp', 'manifests/certmonger/httpd.pp', 'manifests/certmonger/etcd.pp', 'manifests/certmonger/metrics_qdr.pp', 'manifests/certmonger/mysql.pp', 'manifests/certmonger/ceph_rgw.pp', 'manifests/certmonger/memcached.pp']",21,dd5a6375c7aadde7107174f0029a8176feba9a57,key_size_cert,"# [*key_size*] # (Optional) Specifies the private key size used when creating the certificate. # Defaults to 2048bits. # $key_size = 2048, key_size => $key_size,",,126,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Ia8698702c9494d4303ede4fd2955c5975ab07af9,openstack/tripleo-heat-templates,stable/ussuri,Ia8698702c9494d4303ede4fd2955c5975ab07af9,Remove Luna HSM clients on scaledown,MERGED,2020-12-18 18:51:53.000000000,2021-01-05 02:52:25.000000000,2021-01-05 02:52:25.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-18 18:51:53.000000000', 'files': ['deployment/barbican/barbican-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b51683ceb78497a18ed6e9bc64223139db5c2450', 'message': 'Remove Luna HSM clients on scaledown\n\nThis patch adds a scaledown task to remove the HSM\nclient when a Controller node is being removed.\n\nDepends-On: I87f7cb2435f77814169fbad3bd0814d370a546a1\nChange-Id: Ia8698702c9494d4303ede4fd2955c5975ab07af9\n(cherry picked from commit 144eb67ca5590c842a687285b278d1a892e9fe69)\n'}]",0,767931,b51683ceb78497a18ed6e9bc64223139db5c2450,7,3,1,7973,,,0,"Remove Luna HSM clients on scaledown

This patch adds a scaledown task to remove the HSM
client when a Controller node is being removed.

Depends-On: I87f7cb2435f77814169fbad3bd0814d370a546a1
Change-Id: Ia8698702c9494d4303ede4fd2955c5975ab07af9
(cherry picked from commit 144eb67ca5590c842a687285b278d1a892e9fe69)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/31/767931/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/barbican/barbican-api-container-puppet.yaml'],1,b51683ceb78497a18ed6e9bc64223139db5c2450,," scale_tasks: if: - lunasa_hsm_enabled - - name: Remove HSM clients when: step|int == 1 tags: down block: - name: Remove client from HSM import_role: name: lunasa_hsm tasks_from: unregister_client delegate_to: undercloud vars: - map_merge: - {get_param: LunasaVars} - lunasa_client_pin: {get_param: BarbicanPkcs11CryptoLogin} - client_name: ""{{ fqdn_canonical }}"" - null",,19,0
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~Ia8698702c9494d4303ede4fd2955c5975ab07af9,openstack/tripleo-heat-templates,stable/victoria,Ia8698702c9494d4303ede4fd2955c5975ab07af9,Remove Luna HSM clients on scaledown,MERGED,2020-12-18 18:49:52.000000000,2021-01-05 02:52:20.000000000,2021-01-05 02:52:20.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-18 18:49:52.000000000', 'files': ['deployment/barbican/barbican-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0f1e78d7391f7da86919aa44a0065cb631faf8c6', 'message': 'Remove Luna HSM clients on scaledown\n\nThis patch adds a scaledown task to remove the HSM\nclient when a Controller node is being removed.\n\nDepends-On: I87f7cb2435f77814169fbad3bd0814d370a546a1\nChange-Id: Ia8698702c9494d4303ede4fd2955c5975ab07af9\n(cherry picked from commit 144eb67ca5590c842a687285b278d1a892e9fe69)\n'}]",0,767930,0f1e78d7391f7da86919aa44a0065cb631faf8c6,12,5,1,7973,,,0,"Remove Luna HSM clients on scaledown

This patch adds a scaledown task to remove the HSM
client when a Controller node is being removed.

Depends-On: I87f7cb2435f77814169fbad3bd0814d370a546a1
Change-Id: Ia8698702c9494d4303ede4fd2955c5975ab07af9
(cherry picked from commit 144eb67ca5590c842a687285b278d1a892e9fe69)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/767930/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/barbican/barbican-api-container-puppet.yaml'],1,0f1e78d7391f7da86919aa44a0065cb631faf8c6,," scale_tasks: if: - lunasa_hsm_enabled - - name: Remove HSM clients when: step|int == 1 tags: down block: - name: Remove client from HSM import_role: name: lunasa_hsm tasks_from: unregister_client delegate_to: undercloud vars: - map_merge: - {get_param: LunasaVars} - lunasa_client_pin: {get_param: BarbicanPkcs11CryptoLogin} - client_name: ""{{ fqdn_canonical }}"" - null",,19,0
openstack%2Fironic-python-agent-builder~master~I95a12215b8c5b2d52f52145f79b5f245138ebfde,openstack/ironic-python-agent-builder,master,I95a12215b8c5b2d52f52145f79b5f245138ebfde,Remove firmware from debian based systems,MERGED,2020-12-15 17:49:17.000000000,2021-01-05 02:24:30.000000000,2021-01-05 02:23:20.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-12-15 17:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/d468590f5ac9dfc0501ae93dee52f46fb9c2645b', 'message': 'Remove firmware from debian based systems\n\nAdds logic to loop through the path debian uses to remove excess\nfirmware binaries that are un-needed for the agent to operate.\n\nChange-Id: I95a12215b8c5b2d52f52145f79b5f245138ebfde\n'}, {'number': 2, 'created': '2021-01-04 17:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/4596f0304dd1253e82ba0e64ebfbe724488410f0', 'message': 'Remove firmware from debian based systems\n\nAdds logic to loop through the path debian uses to remove excess\nfirmware binaries that are un-needed for the agent to operate.\n\nChange-Id: I95a12215b8c5b2d52f52145f79b5f245138ebfde\n'}, {'number': 3, 'created': '2021-01-04 17:41:12.000000000', 'files': ['dib/ironic-python-agent-ramdisk/post-install.d/99-remove-extra-packages', 'releasenotes/notes/excess-firmware-removal-debian-06c49a8604122b1c.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/1b904b5dd34d89939c8e94bd926201c8c4053745', 'message': 'Remove firmware from debian based systems\n\nAdds logic to loop through the path debian uses to remove excess\nfirmware binaries that are un-needed for the agent to operate.\n\nChange-Id: I95a12215b8c5b2d52f52145f79b5f245138ebfde\n'}]",3,767192,1b904b5dd34d89939c8e94bd926201c8c4053745,13,3,3,11655,,,0,"Remove firmware from debian based systems

Adds logic to loop through the path debian uses to remove excess
firmware binaries that are un-needed for the agent to operate.

Change-Id: I95a12215b8c5b2d52f52145f79b5f245138ebfde
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/92/767192/1 && git format-patch -1 --stdout FETCH_HEAD,"['dib/ironic-python-agent-ramdisk/post-install.d/99-remove-extra-packages', 'releasenotes/notes/excess-firmware-removal-debian-06c49a8604122b1c.yaml']",2,d468590f5ac9dfc0501ae93dee52f46fb9c2645b,no-firmware,--- features: - | Excess hardware firmware on Debian based agent ramdisks is now automatically removed. ,,15,5
openstack%2Fpaunch~stable%2Fussuri~I82172f5a2d4683509c802c0f14d571a40e21e6cc,openstack/paunch,stable/ussuri,I82172f5a2d4683509c802c0f14d571a40e21e6cc,Actually fail if a stop or remove call fails,MERGED,2020-12-11 19:13:25.000000000,2021-01-05 01:55:37.000000000,2021-01-05 01:54:30.000000000,"[{'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-11 19:13:25.000000000', 'files': ['paunch/tests/test_runner.py', 'paunch/runner.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/523465fe8cd845186e6b3095f6fd35fcc9712ace', 'message': ""Actually fail if a stop or remove call fails\n\nAs part of the container rename actions, attempt to stop and remove\ncontainers without actually checking if they exist. Additionally we\ndon't actually fail if these command fail which leads to other errors\nlater that may be unrelated to the core issue. This change adds\nadditional checks around the stop and remove container actions to ensure\nthat the container is running before stopping and exists before\nremoving.\n\nChange-Id: I82172f5a2d4683509c802c0f14d571a40e21e6cc\nCloses-Bug: #1907833\n""}]",0,766779,523465fe8cd845186e6b3095f6fd35fcc9712ace,13,4,1,14985,,,0,"Actually fail if a stop or remove call fails

As part of the container rename actions, attempt to stop and remove
containers without actually checking if they exist. Additionally we
don't actually fail if these command fail which leads to other errors
later that may be unrelated to the core issue. This change adds
additional checks around the stop and remove container actions to ensure
that the container is running before stopping and exists before
removing.

Change-Id: I82172f5a2d4683509c802c0f14d571a40e21e6cc
Closes-Bug: #1907833
",git fetch https://review.opendev.org/openstack/paunch refs/changes/79/766779/1 && git format-patch -1 --stdout FETCH_HEAD,"['paunch/tests/test_runner.py', 'paunch/runner.py']",2,523465fe8cd845186e6b3095f6fd35fcc9712ace,bug/1907833," raise Exception('Unable to remove container: %s' % container) raise Exception('Unable to stop container: %s' % container) # destination container def stop_container(self, container, cont_cmd=None, quiet=False): if not self.container_running(container): self.log.debug('%s not running, skipping stop' % container) return self.log.debug(""Stopping container: %s"" % container) return super(PodmanRunner, self).stop_container(container, cont_cmd, quiet) def remove_container(self, container): if not self.container_exists(container): self.log.debug('%s does not exist, skipping remove' % container) return self.log.debug(""Removing container: %s"" % container) systemd.service_delete(container=container, log=self.log) return super(PodmanRunner, self).remove_container(container) if not self.container_exists(container): self.log.debug('%s is not running because it does not exist' % container) return False"," if self.cont_cmd == 'podman': systemd.service_delete(container=container, log=self.log) self.log.debug(""Removing the destination container %s"" % name) self.log.debug(""Removing a container known as %s"" % container)",69,4
openstack%2Fneutron~master~Ia198d45f49bddda549a0e70a3374b8339f88887b,openstack/neutron,master,Ia198d45f49bddda549a0e70a3374b8339f88887b,Rely on worker count for HashRing caching,MERGED,2020-12-07 21:01:11.000000000,2021-01-05 01:17:20.000000000,2021-01-05 01:15:51.000000000,"[{'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 9845}, {'_account_id': 11952}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-07 21:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39dac639eea2f45c32e10cea40f88d32287b3cd0', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 2, 'created': '2020-12-08 11:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f4e0d8b76d7573e36c245f5569371ccf1a75c5d', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 3, 'created': '2020-12-09 15:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2893a5914a0d5438f60f318f1f2b2d4aeb4355e3', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 4, 'created': '2020-12-09 22:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d7c60d1ff49ca06e98971565eeb4ed6bcbbc77e', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 5, 'created': '2020-12-09 22:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93fd1fd37629858c399926e48317ee42f83ebffa', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 6, 'created': '2020-12-10 15:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f9822207f4df143f61ff7f6b28485960bad5ed9', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 7, 'created': '2020-12-15 20:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2cc615c19e47823327b2c4afeda6f7c95234a41', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 8, 'created': '2020-12-16 18:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8d1f8ddfc1b0c10247a9f1ab9cdb594a41fb5f8', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 9, 'created': '2020-12-16 19:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/796f902689520e312852d8ccf4221eda1a6a022b', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 10, 'created': '2020-12-18 22:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2dd53a796bb2cac7d5d4dbc5d57d8b56086c89d', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nRelated-Bug: #1894117\nCloses-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}, {'number': 11, 'created': '2020-12-21 14:37:57.000000000', 'files': ['neutron/tests/unit/common/ovn/test_hash_ring_manager.py', 'neutron/tests/functional/base.py', 'neutron/common/ovn/hash_ring_manager.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4007b0833111a25d24f597161d39ee9ccd37189', 'message': ""Rely on worker count for HashRing caching\n\nThe current code looks at a hash ring node's created_at/updated_at\nfields and tries to determine whether the node has been updated\nbased on whether updated_at - created_at > 1 second (due to the\nmethod that initially fills them being different by microseconds).\nUnfortunately, due to the notify() method being called which calls\nthe hash ring node's touch_node(), a node can be updated in under\na second, meaning we will prevent caching for much longer than\nwe intend.\n\nWhen using sqlite in-memory db, this continually re-creating the\nHash Ring objects for every event that is processed is exposing an\nissue where rows that should be in the db just *aren't*.\n\nThis patch instead limits the hash ring nodes to api workers and\nprevents caching only until the number of nodes == number of api\nworkers on the host. The switch from spawning hash ring nodes\nwhere !is_maintenance to is_api_worker is primarily because it\nseems to be difficult to get a list of *all* workers from which to\nsubtract the maintenance worker so that _wait_startup_before_caching\ncan wait for that specific number of workers. In practice, this\nmeans that RpcWorker and ServiceWorker workers would not process\nHashRing events.\n\nA note on bug 1903008: While this change will greatly reduce the\nlikelihood of this issue taking place, we still have some work to\ndo in order to fully understand why it rubs the database backend\nin the wrong way. Thus, we will make this change 'related to'\ninstead of closing the bug.\n\nRelated-Bug: #1894117\nRelated-Bug: #1903008\nChange-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b\n""}]",16,765874,c4007b0833111a25d24f597161d39ee9ccd37189,102,10,11,5756,,,0,"Rely on worker count for HashRing caching

The current code looks at a hash ring node's created_at/updated_at
fields and tries to determine whether the node has been updated
based on whether updated_at - created_at > 1 second (due to the
method that initially fills them being different by microseconds).
Unfortunately, due to the notify() method being called which calls
the hash ring node's touch_node(), a node can be updated in under
a second, meaning we will prevent caching for much longer than
we intend.

When using sqlite in-memory db, this continually re-creating the
Hash Ring objects for every event that is processed is exposing an
issue where rows that should be in the db just *aren't*.

This patch instead limits the hash ring nodes to api workers and
prevents caching only until the number of nodes == number of api
workers on the host. The switch from spawning hash ring nodes
where !is_maintenance to is_api_worker is primarily because it
seems to be difficult to get a list of *all* workers from which to
subtract the maintenance worker so that _wait_startup_before_caching
can wait for that specific number of workers. In practice, this
means that RpcWorker and ServiceWorker workers would not process
HashRing events.

A note on bug 1903008: While this change will greatly reduce the
likelihood of this issue taking place, we still have some work to
do in order to fully understand why it rubs the database backend
in the wrong way. Thus, we will make this change 'related to'
instead of closing the bug.

Related-Bug: #1894117
Related-Bug: #1903008
Change-Id: Ia198d45f49bddda549a0e70a3374b8339f88887b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/765874/10 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/base.py', 'neutron/common/ovn/hash_ring_manager.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",4,39dac639eea2f45c32e10cea40f88d32287b3cd0,,import neutron.wsgi worker_class = ovn_utils.get_method_class(trigger) if worker_class == neutron.wsgi.WorkerService: if worker_class == worker.MaintenanceWorker:, is_maintenance = (ovn_utils.get_method_class(trigger) == worker.MaintenanceWorker) if not is_maintenance: if is_maintenance:,23,18
openstack%2Ftrove~master~Ib7eb517f404fe87b880f7091366721d2cfc5cdf8,openstack/trove,master,Ib7eb517f404fe87b880f7091366721d2cfc5cdf8,remove unicode from code,MERGED,2021-01-03 08:43:13.000000000,2021-01-05 01:15:19.000000000,2021-01-05 01:13:54.000000000,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 08:43:13.000000000', 'files': ['trove/tests/unittests/backup/test_backup_models.py', 'trove/common/strategies/cluster/experimental/mongodb/api.py', 'trove/tests/fakes/swift.py', 'trove/tests/unittests/common/test_auth.py', 'trove/tests/unittests/common/test_crypto_utils.py', 'doc/source/conf.py', 'api-ref/source/conf.py', 'trove/tests/unittests/common/test_utils.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/5d641033d40ac53fdae7c12b070a9c54dac6a49c', 'message': 'remove unicode from code\n\nImplements: blueprint remove-unicode\nChange-Id: Ib7eb517f404fe87b880f7091366721d2cfc5cdf8\n'}]",0,769035,5d641033d40ac53fdae7c12b070a9c54dac6a49c,8,3,1,32029,,,0,"remove unicode from code

Implements: blueprint remove-unicode
Change-Id: Ib7eb517f404fe87b880f7091366721d2cfc5cdf8
",git fetch https://review.opendev.org/openstack/trove refs/changes/35/769035/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/unittests/backup/test_backup_models.py', 'trove/common/strategies/cluster/experimental/mongodb/api.py', 'trove/tests/fakes/swift.py', 'trove/tests/unittests/common/test_auth.py', 'trove/tests/unittests/common/test_crypto_utils.py', 'api-ref/source/conf.py', 'doc/source/conf.py', 'trove/tests/unittests/common/test_utils.py', 'releasenotes/source/conf.py']",9,5d641033d40ac53fdae7c12b070a9c54dac6a49c,remove-unicode,"project = 'Trove Release Notes' copyright = '2015, Trove Developers' ('index', 'TroveReleaseNotes.tex', 'Trove Release Notes Documentation', 'Trove Developers', 'manual'), ('index', 'trovereleasenotes', 'Trove Release Notes Documentation', ['Trove Developers'], 1) ('index', 'TroveReleaseNotes', 'Trove Release Notes Documentation', 'Trove Developers', 'TroveReleaseNotes',","project = u'Trove Release Notes' copyright = u'2015, Trove Developers' ('index', 'TroveReleaseNotes.tex', u'Trove Release Notes Documentation', u'Trove Developers', 'manual'), ('index', 'trovereleasenotes', u'Trove Release Notes Documentation', [u'Trove Developers'], 1) ('index', 'TroveReleaseNotes', u'Trove Release Notes Documentation', u'Trove Developers', 'TroveReleaseNotes',",53,53
openstack%2Fpython-troveclient~master~Iadc87779bf513c9d04847b6cf8ecbc60b300d7db,openstack/python-troveclient,master,Iadc87779bf513c9d04847b6cf8ecbc60b300d7db,remove unicode from code,MERGED,2021-01-03 05:04:36.000000000,2021-01-05 01:15:17.000000000,2021-01-05 01:13:58.000000000,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 05:04:36.000000000', 'files': ['troveclient/tests/test_shell.py', 'doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/3bdae37673376529c622452f2f29a0d389c0a7d5', 'message': 'remove unicode from code\n\nChange-Id: Iadc87779bf513c9d04847b6cf8ecbc60b300d7db\nImplements: blueprint remove-unicode\n'}]",0,768953,3bdae37673376529c622452f2f29a0d389c0a7d5,8,3,1,32029,,,0,"remove unicode from code

Change-Id: Iadc87779bf513c9d04847b6cf8ecbc60b300d7db
Implements: blueprint remove-unicode
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/53/768953/1 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/tests/test_shell.py', 'doc/source/conf.py', 'releasenotes/source/conf.py']",3,3bdae37673376529c622452f2f29a0d389c0a7d5,remove-unicode,"project = 'Trove Client Release Notes' copyright = '2016, Trove developers' ('index', 'TroveClientReleaseNotes.tex', 'Trove Client Release Notes Documentation', 'Trove developers', 'manual'), ('index', 'troveclientreleasenotes', 'Trove Client Release Notes Documentation', ['Trove developers'], 1) ('index', 'TroveClientReleaseNotes', 'Trove Client Release Notes Documentation', 'Trove developers', 'TroveClientReleaseNotes', 'OpenStack Database as a Service.',","project = u'Trove Client Release Notes' copyright = u'2016, Trove developers' ('index', 'TroveClientReleaseNotes.tex', u'Trove Client Release Notes Documentation', u'Trove developers', 'manual'), ('index', 'troveclientreleasenotes', u'Trove Client Release Notes Documentation', [u'Trove developers'], 1) ('index', 'TroveClientReleaseNotes', u'Trove Client Release Notes Documentation', u'Trove developers', 'TroveClientReleaseNotes', 'OpenStack Database as a Service.',",34,34
openstack%2Fneutron~stable%2Fvictoria~I8c940ac8f7632c69607dea7220146ef59d55ed56,openstack/neutron,stable/victoria,I8c940ac8f7632c69607dea7220146ef59d55ed56,Ensure ovsdb_probe_interval set before connect(),MERGED,2020-12-04 20:16:18.000000000,2021-01-05 01:13:23.000000000,2021-01-05 01:10:16.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-04 20:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d0a2c47ff85521484ade04e3e3839a92f136c91', 'message': ""Ensure ovsdb_probe_interval set before connect()\n\nSetting the ovsdb_probe_interval after Connection.start() is\ncalled means that the probe interval is not changed from\npython-ovs's default of 5s until after the initial copy of the\ndatabase is retrieved. On busy systems, this can time out and\ncause infinite reconnects.\n\nThis patch passes the probe_interval argument to the ovs.db.Idl\nclass so that it can be set as part of creating the jsonrpc\nSession.\n\nSome unit tests were removed and replaced with a functional test\nwhich ensures not just that set_probe_interval is called, but that\nthe value is actually set before the connection is established.\n\nCloses-bug: #1905611\nChange-Id: I8c940ac8f7632c69607dea7220146ef59d55ed56\n(cherry picked from commit 5783e952887b2fe5e8aaa32b3077e8dcdefa7252)\n""}, {'number': 2, 'created': '2020-12-04 20:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b5cc08701183301974e5c316169eb56f4d9ed78', 'message': ""Ensure ovsdb_probe_interval set before connect()\n\nSetting the ovsdb_probe_interval after Connection.start() is\ncalled means that the probe interval is not changed from\npython-ovs's default of 5s until after the initial copy of the\ndatabase is retrieved. On busy systems, this can time out and\ncause infinite reconnects.\n\nThis patch passes the probe_interval argument to the ovs.db.Idl\nclass so that it can be set as part of creating the jsonrpc\nSession.\n\nSome unit tests were removed and replaced with a functional test\nwhich ensures not just that set_probe_interval is called, but that\nthe value is actually set before the connection is established.\n\nConflicts:\n  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n\nCloses-bug: #1905611\nChange-Id: I8c940ac8f7632c69607dea7220146ef59d55ed56\n(cherry picked from commit 5783e952887b2fe5e8aaa32b3077e8dcdefa7252)\n""}, {'number': 3, 'created': '2021-01-04 14:31:58.000000000', 'files': ['neutron/agent/ovn/metadata/ovsdb.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/031924ad60b137323a7fe836603b3407967faa84', 'message': ""Ensure ovsdb_probe_interval set before connect()\n\nSetting the ovsdb_probe_interval after Connection.start() is\ncalled means that the probe interval is not changed from\npython-ovs's default of 5s until after the initial copy of the\ndatabase is retrieved. On busy systems, this can time out and\ncause infinite reconnects.\n\nThis patch passes the probe_interval argument to the ovs.db.Idl\nclass so that it can be set as part of creating the jsonrpc\nSession.\n\nSome unit tests were removed and replaced with a functional test\nwhich ensures not just that set_probe_interval is called, but that\nthe value is actually set before the connection is established.\n\nConflicts:\n  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n\nCloses-bug: #1905611\nChange-Id: I8c940ac8f7632c69607dea7220146ef59d55ed56\n(cherry picked from commit 5783e952887b2fe5e8aaa32b3077e8dcdefa7252)\n""}]",0,765599,031924ad60b137323a7fe836603b3407967faa84,23,4,3,5756,,,0,"Ensure ovsdb_probe_interval set before connect()

Setting the ovsdb_probe_interval after Connection.start() is
called means that the probe interval is not changed from
python-ovs's default of 5s until after the initial copy of the
database is retrieved. On busy systems, this can time out and
cause infinite reconnects.

This patch passes the probe_interval argument to the ovs.db.Idl
class so that it can be set as part of creating the jsonrpc
Session.

Some unit tests were removed and replaced with a functional test
which ensures not just that set_probe_interval is called, but that
the value is actually set before the connection is established.

Conflicts:
  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py

Closes-bug: #1905611
Change-Id: I8c940ac8f7632c69607dea7220146ef59d55ed56
(cherry picked from commit 5783e952887b2fe5e8aaa32b3077e8dcdefa7252)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/765599/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/ovn/metadata/ovsdb.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py']",5,4d0a2c47ff85521484ade04e3e3839a92f136c91,fix_ovsdb_probe_interval-stable/victoria,"import fixtures as og_fixturesfrom neutron.conf.plugins.ml2.drivers.ovn import ovn_conffrom neutron.tests.functional.resources import process class OvnIdlProbeInterval(base.TestOVNFunctionalBase): def setUp(self): # skip parent setUp, we don't need it, but we do need grandparent # pylint: disable=bad-super-call super(base.TestOVNFunctionalBase, self).setUp() mm = directory.get_plugin().mechanism_manager self.mech_driver = mm.mech_drivers['ovn'].obj self.temp_dir = self.useFixture(og_fixtures.TempDir()).path install_share_path = self._get_install_share_path() self.mgr = self.useFixture( process.OvsdbServer(self.temp_dir, install_share_path, ovn_nb_db=True, ovn_sb_db=True, protocol='tcp')) connection = self.mgr.get_ovsdb_connection_path self.connections = {'OVN_Northbound': connection(), 'OVN_Southbound': connection(db_type='sb')} def test_ovsdb_probe_interval(self): klasses = { ovsdb_monitor.BaseOvnIdl: ('OVN_Northbound', {}), ovsdb_monitor.OvnNbIdl: ('OVN_Northbound', {'driver': self.mech_driver}), ovsdb_monitor.OvnSbIdl: ('OVN_Southbound', {'driver': self.mech_driver})} idls = [kls.from_server(self.connections[schema], schema, **kwargs) for kls, (schema, kwargs) in klasses.items()] interval = ovn_conf.get_ovn_ovsdb_probe_interval() for idl in idls: self.assertEqual(interval, idl._session.reconnect.probe_interval)",,52,12
openstack%2Fneutron~stable%2Fvictoria~Iae86705f1d30c89dc5482261d852b45787bd8782,openstack/neutron,stable/victoria,Iae86705f1d30c89dc5482261d852b45787bd8782,Fix calling of add_tunnel_port method from sanity checks module,MERGED,2020-12-03 08:34:00.000000000,2021-01-05 01:12:01.000000000,2021-01-05 01:10:07.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-03 08:34:00.000000000', 'files': ['neutron/cmd/sanity/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/175f7c9064ec16a4747f075481ece0e2db6f7f0a', 'message': 'Fix calling of add_tunnel_port method from sanity checks module\n\nSanity checks functions which are checking if vxlan and geneve tunnels\nare available in openvswitch are now passing all mandatory parameters\nto the ovs_lib.OVSBridge.add_tunnel_port method.\nPreviously port_name was missing.\n\nCloses-Bug: #1905568\nChange-Id: Iae86705f1d30c89dc5482261d852b45787bd8782\n(cherry picked from commit ab6c59b57e732def62e3817a80d081b8392d669a)\n'}]",0,765283,175f7c9064ec16a4747f075481ece0e2db6f7f0a,14,4,1,11975,,,0,"Fix calling of add_tunnel_port method from sanity checks module

Sanity checks functions which are checking if vxlan and geneve tunnels
are available in openvswitch are now passing all mandatory parameters
to the ovs_lib.OVSBridge.add_tunnel_port method.
Previously port_name was missing.

Closes-Bug: #1905568
Change-Id: Iae86705f1d30c89dc5482261d852b45787bd8782
(cherry picked from commit ab6c59b57e732def62e3817a80d081b8392d669a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/765283/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/cmd/sanity/checks.py'],1,175f7c9064ec16a4747f075481ece0e2db6f7f0a,bug/1905568-stable/victoria," br_name = common_utils.get_rand_device_name(prefix='vxlantest-') port_name = common_utils.get_rand_device_name(prefix='vxlantest-') with ovs_lib.OVSBridge(br_name) as br: port = br.add_tunnel_port( port_name=port_name, remote_ip=from_ip, local_ip=to_ip, tunnel_type=n_consts.TYPE_VXLAN) br_name = common_utils.get_rand_device_name(prefix='genevetest-') port_name = common_utils.get_rand_device_name(prefix='genevetest-') with ovs_lib.OVSBridge(br_name) as br: port = br.add_tunnel_port( port_name=port_name, remote_ip=from_ip, local_ip=to_ip, tunnel_type=n_consts.TYPE_GENEVE)"," name = common_utils.get_rand_device_name(prefix='vxlantest-') with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port(from_ip, to_ip, n_consts.TYPE_VXLAN) name = common_utils.get_rand_device_name(prefix='genevetest-') with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port(from_ip, to_ip, n_consts.TYPE_GENEVE)",16,6
openstack%2Ftripleo-ansible~master~Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b,openstack/tripleo-ansible,master,Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b,Tune-up plan create when running swift-less,MERGED,2020-10-12 21:04:09.000000000,2021-01-05 01:10:53.000000000,2021-01-05 01:10:53.000000000,"[{'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}, {'_account_id': 29268}]","[{'number': 1, 'created': '2020-10-12 21:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9e9c9af75aa6b3ef5a1dfcce6391cef64dfd4605', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2020-10-12 22:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9f2a057943705f150f54e727a11c99ae42fa48c9', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 3, 'created': '2020-10-13 13:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/17f20cfbb101869962dd23f430f962bb8db1089b', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 4, 'created': '2020-10-13 13:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c8942df8a46408fdab0f32939d975bd4c16f3095', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 5, 'created': '2020-10-13 18:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/38e241d9804923f553e6ae2557e71fe8e5de4d07', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 6, 'created': '2020-10-13 19:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f71cde3b49340721b0f271ff1a8804321b04cca1', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 7, 'created': '2020-10-14 13:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4fe896a891cf097c667b054c684172d62c0ef2be', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 8, 'created': '2020-12-01 14:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/18622a351c07a7a51abafe1d3ccebf4b22043fb2', 'message': 'WIP Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 9, 'created': '2020-12-01 14:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/07ffe5aec465b81c6d4f0bafa3c0992209c5e077', 'message': 'Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 10, 'created': '2020-12-02 13:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/86247017647eac7fc632adea75fc6969c9d3829d', 'message': 'Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 11, 'created': '2021-01-04 17:50:08.000000000', 'files': ['tripleo_ansible/playbooks/cli-undercloud-local-artifacts.yaml', 'tripleo_ansible/playbooks/cli-create-deployment-plan.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2f1057780695862fd876873779ae386b0d56389f', 'message': 'Tune-up plan create when running swift-less\n\nThis change modifies the plan creation playbook to ensure its\nfunctional with a swiftless environment.\n\nA new playbook has been added which will create the stacks\ndirectory and set the permissions. This playbook will be used\nwithin tripleo-client to ensure that the local artifact store\nis setup early in the deployment process.\n\nChange-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",4,757648,2f1057780695862fd876873779ae386b0d56389f,41,8,11,7353,,,0,"Tune-up plan create when running swift-less

This change modifies the plan creation playbook to ensure its
functional with a swiftless environment.

A new playbook has been added which will create the stacks
directory and set the permissions. This playbook will be used
within tripleo-client to ensure that the local artifact store
is setup early in the deployment process.

Change-Id: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/48/757648/9 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cli-create-deployment-plan.yaml'],1,9e9c9af75aa6b3ef5a1dfcce6391cef64dfd4605,config-download/swift," - name: Ensure container directory exists become: true file: path: ""/var/lib/tripleo/{{ container }}"" state: directory - name: Check Plan file stat: path: ""/var/lib/tripleo/{{ container }}/plan-environment.yaml"" register: plan_file - name: Write local plan copy become: true copy: src: ""{{ plan_environment | tht_abspath }}"" dest: ""/var/lib/tripleo/{{ container }}/plan-environment.yaml"" remote_src: true when: - not (plan_file.stat.exists | bool) become: true become: true become: true validate: false", validate: false ,24,1
openstack%2Fneutron~master~I406703209cdd720f6fea1a1f15711dc527e1cdb0,openstack/neutron,master,I406703209cdd720f6fea1a1f15711dc527e1cdb0,Check router interface not in use properly,MERGED,2020-12-02 12:09:04.000000000,2021-01-05 00:28:22.000000000,2021-01-05 00:26:32.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-02 12:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5fba3322f1841ba3319c5bd3c30111d83a065b4f', 'message': 'Check router has subnet before check subnet in use\n\n_confirm_router_interface_not_in_use uses subnet cidr\nand does not account for other subnets with same cidr.\nNeed first check that router actually has interface from the this\nsubnet.\nAlso _confirm_router_interface_not_in_use is more expensive\nthan check for router ports, so its better to perform it after\nconfirming router has interface from this subnet.\n\nCloses-Bug: #1906508\nChange-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0\n'}, {'number': 2, 'created': '2020-12-03 07:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/05f63458580103fa7d47e87e9f7c4c9a5c50a275', 'message': 'Check router has subnet before check subnet in use\n\n_confirm_router_interface_not_in_use uses subnet cidr\nand does not account for other subnets with same cidr.\nNeed first check that router actually has interface from the this\nsubnet.\nAlso _confirm_router_interface_not_in_use is more expensive\nthan check for router ports, so its better to perform it after\nconfirming router has interface from this subnet.\n\nCloses-Bug: #1906508\nChange-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0\n'}, {'number': 3, 'created': '2020-12-15 11:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04a4f4d9d536848d744513255b2a51c988aa184a', 'message': 'Check router has subnet before check subnet in use\n\n_confirm_router_interface_not_in_use uses subnet cidr\nand does not account for other subnets with same cidr.\nNeed first check that router actually has interface from the this\nsubnet.\nAlso _confirm_router_interface_not_in_use is more expensive\nthan check for router ports, so its better to perform it after\nconfirming router has interface from this subnet.\n\nCloses-Bug: #1906508\nChange-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0\n'}, {'number': 4, 'created': '2020-12-16 12:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6968831c739621d8963cd7d69ffcbe2e7c5a5031', 'message': 'Check router has subnet before check subnet in use\n\n_confirm_router_interface_not_in_use uses subnet cidr\nand does not account for other subnets with same cidr.\nNeed first check that router actually has interface from the this\nsubnet.\nAlso _confirm_router_interface_not_in_use is more expensive\nthan check for router ports, so its better to perform it after\nconfirming router has interface from this subnet.\n\nCloses-Bug: #1906508\nChange-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0\n'}, {'number': 5, 'created': '2020-12-18 12:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38e5c336342677f4aee37cb1d30d1114e86bb2ba', 'message': 'Check router interface not in use properly\n\n_confirm_router_interface_not_in_use uses subnet cidr\nand does not account for other subnets with same cidr.\nNeed first check that router actually has interface from this\nsubnet.\nAlso _confirm_router_interface_not_in_use is more expensive\nthan check for router ports, so its better to perform it after\nconfirming router has interface from this subnet.\n\nCloses-Bug: #1906508\nChange-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0\n'}, {'number': 6, 'created': '2020-12-18 14:26:46.000000000', 'files': ['neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/715f5f51c4847f46270353c3efceaa8f56c46635', 'message': 'Check router interface not in use properly\n\n_confirm_router_interface_not_in_use uses subnet cidr\nand does not account for other subnets with same cidr.\nNeed first check that router actually has interface from this\nsubnet.\nAlso _confirm_router_interface_not_in_use is more expensive\nthan check for router ports, so its better to perform it after\nconfirming router has interface from this subnet.\n\nCloses-Bug: #1906508\nChange-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0\n'}]",18,765129,715f5f51c4847f46270353c3efceaa8f56c46635,51,8,6,32667,,,0,"Check router interface not in use properly

_confirm_router_interface_not_in_use uses subnet cidr
and does not account for other subnets with same cidr.
Need first check that router actually has interface from this
subnet.
Also _confirm_router_interface_not_in_use is more expensive
than check for router ports, so its better to perform it after
confirming router has interface from this subnet.

Closes-Bug: #1906508
Change-Id: I406703209cdd720f6fea1a1f15711dc527e1cdb0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/765129/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,5fba3322f1841ba3319c5bd3c30111d83a065b4f,bug/1906508," if ports: self._confirm_router_interface_not_in_use( context, router_id, subnet_id)"," self._confirm_router_interface_not_in_use( context, router_id, subnet_id)",3,2
openstack%2Fneutron~stable%2Fussuri~Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f,openstack/neutron,stable/ussuri,Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f,Fix migration from the HA to non-HA routers,MERGED,2020-11-19 10:53:20.000000000,2021-01-05 00:28:19.000000000,2021-01-05 00:26:47.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-11-19 10:53:20.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/l3/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/144d921947a536c88f133c0f04557b60f7b30686', 'message': ""Fix migration from the HA to non-HA routers\n\nIn case if during switching HA router to be down, there will be any\nfailure, router_info will be stored in L3 agent's cache as HaRouter.\nIn case when next update on the router is migration to non-HA router\nthis is wrong class and it causes other issues, e.g. with\nremove_vip_by_ip_address() which is correct only for HA routers.\n\nThis patch fixes that issue by adding check of the router's ha and\ndistributed flags and update local cache with new router_info class\nin case if at least one of those flags don't match.\n\nChange-Id: Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f\nCloses-Bug: #1892846\n(cherry picked from commit 489e0ead7297e3b17ca2bf8c4bea9701ad14a939)\n""}]",0,763345,144d921947a536c88f133c0f04557b60f7b30686,17,6,1,11975,,,0,"Fix migration from the HA to non-HA routers

In case if during switching HA router to be down, there will be any
failure, router_info will be stored in L3 agent's cache as HaRouter.
In case when next update on the router is migration to non-HA router
this is wrong class and it causes other issues, e.g. with
remove_vip_by_ip_address() which is correct only for HA routers.

This patch fixes that issue by adding check of the router's ha and
distributed flags and update local cache with new router_info class
in case if at least one of those flags don't match.

Change-Id: Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f
Closes-Bug: #1892846
(cherry picked from commit 489e0ead7297e3b17ca2bf8c4bea9701ad14a939)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/763345/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/l3/test_agent.py']",2,144d921947a536c88f133c0f04557b60f7b30686,bug/1892846-stable/victoria-stable/ussuri," def mock_get(name): if name == 'ha': return router.ha if name == 'distributed': return router.distributed return mock.Mock() router_info.router.get.side_effect = mock_get def mock_get(name): if name == 'ha': return router.ha if name == 'distributed': return router.distributed return mock.Mock() router_info.router.get.side_effect = mock_get def test_process_router_if_compatible_type_match(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = {'id': _uuid(), 'routes': [], 'admin_state_up': True, 'ha': False, 'distributed': False, 'external_gateway_info': {'network_id': 'aaa'}} ri = mock.Mock(router=router) agent.router_info[router['id']] = ri with mock.patch.object(agent, ""_create_router"") as create_router_mock: agent._process_router_if_compatible(router) create_router_mock.assert_not_called() self.assertIn(router['id'], agent.router_info) self.assertFalse(agent.router_info[router['id']].router['ha']) self.assertFalse(agent.router_info[router['id']].router['distributed']) def test_process_router_if_compatible_type_changed(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = {'id': _uuid(), 'routes': [], 'admin_state_up': True, 'revision_number': 1, 'ha': True, 'distributed': False, 'external_gateway_info': {'network_id': 'aaa'}} ri = mock.Mock(router=router) agent.router_info[router['id']] = ri new_router = copy.deepcopy(router) new_router['ha'] = False with mock.patch.object(agent, ""_create_router"") as create_router_mock: agent._process_router_if_compatible(new_router) create_router_mock.assert_called_once_with( new_router['id'], new_router) self.assertIn(router['id'], agent.router_info) self.assertFalse(agent.router_info[router['id']].router['ha']) self.assertFalse(agent.router_info[router['id']].router['distributed']) ",,77,0
openstack%2Fcinder~master~I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1,openstack/cinder,master,I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1,[SVF] RevertToSnapshot support for GM volumes,MERGED,2020-09-14 15:01:05.000000000,2021-01-04 23:44:43.000000000,2021-01-04 23:43:04.000000000,"[{'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13002}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29122}, {'_account_id': 29705}, {'_account_id': 30615}, {'_account_id': 30688}, {'_account_id': 31868}, {'_account_id': 31980}, {'_account_id': 32036}, {'_account_id': 32159}, {'_account_id': 32171}, {'_account_id': 32266}, {'_account_id': 32425}]","[{'number': 1, 'created': '2020-09-14 15:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb7253cffd1414c6ac36fbfb03b578895017b4f7', 'message': '[Storwize] RevertToSnapshot support for GM volumes\n\nThe current IBM Storwize driver does not support Revert to Snapshot\nfor Global Mirror volumes. Added necessary code changes to storwize\ncinder driver to support revert to snapshot for GM volumes.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\nCloses-bug: #1895532\n'}, {'number': 2, 'created': '2020-09-17 04:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbf56e18c831b342b90cb04b19e6836d8a87de17', 'message': '[Storwize] RevertToSnapshot support for GM volumes\n\nThe current IBM Storwize driver does not support Revert to Snapshot\nfor Global Mirror volumes. Added necessary code changes to storwize\ncinder driver to support revert to snapshot for GM volumes.\n\nLine 7101 : Added one more unit test case with vol_rep_type as True for normal volumes and checked for VolumeBackendAPIException.\nLine 7113 : moved test_stop_relationship to StorwizeHelpersTestCase class.\nLine 7121 : moved test_start_relationship to StorwizeHelpersTestCase class.\nLine 9275 : Renamed test_stop_relationship_gm_vol to test_stop_relationship_mirror_vol and moved to StorwizeHelpersTestCase class.\nLine 9289 : Renamed test_start_relationship_gm_vol to test_start_relationship_mirror_vol and moved to StorwizeHelpersTestCase class.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\nCloses-bug: #1895532\n'}, {'number': 3, 'created': '2020-09-17 04:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e45e3b0a13b04b5c2bbd5594d2e43fc0543b5619', 'message': '[Storwize] RevertToSnapshot support for GM volumes\n\nThe current IBM Storwize driver does not support Revert to Snapshot\nfor Global Mirror volumes. Added necessary code changes to storwize\ncinder driver to support revert to snapshot for GM volumes.\n\nLine7101 :Added one more unit test case with vol_rep_type as True\nfor normal volumes and checked for VolumeBackendAPIException.\nLine7113 :moved test_stop_relationship to StorwizeHelpersTestCase class.\nLine7121 :moved test_start_relationship to StorwizeHelpersTestCase class.\nLine9275 :Renamed test_stop_relationship_gm_vol to\ntest_stop_relationship_mirror_vol and moved to\nStorwizeHelpersTestCase class.\nLine9289 : Renamed test_start_relationship_gm_vol to\ntest_start_relationship_mirror_vol and moved to\nStorwizeHelpersTestCase class.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\nCloses-bug: #1895532\n'}, {'number': 4, 'created': '2020-09-18 09:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b88e61cf48950748773036d772743c58b553aa5', 'message': '[Storwize] RevertToSnapshot support for GM volumes\n\nThe current IBM Storwize driver does not support Revert to Snapshot\nfor Global Mirror volumes. Added necessary code changes to storwize\ncinder driver to support revert to snapshot for GM volumes.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\n'}, {'number': 5, 'created': '2020-10-08 17:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/065385f8ba4fdbf4a0c7f6f878754d512e90c936', 'message': '[Storwize] RevertToSnapshot support for GM volumes\n\nThe current IBM Storwize driver does not support Revert to Snapshot\nfor Global Mirror volumes. Added necessary code changes to storwize\ncinder driver to support revert to snapshot for GM volumes.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\n'}, {'number': 6, 'created': '2020-10-09 07:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/75366fb90348614918bc362b8cdd79323444faa0', 'message': '[SVF] RevertToSnapshot support for GM volumes\n\nThe current IBM Spectrum Virtualize Family does not support\nRevert to Snapshot for Global Mirror volumes. Added necessary\ncode changes to storwize cinder driver to support\nrevert to snapshot for GM volumes.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\n'}, {'number': 7, 'created': '2020-10-23 05:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/edd86c3119026a34dc70787c614ab326196aa77f', 'message': '[SVF] RevertToSnapshot support for GM volumes\n\nThe current IBM Spectrum Virtualize Family does not support\nRevert to Snapshot for Global Mirror volumes. Added necessary\ncode changes to storwize cinder driver to support\nrevert to snapshot for GM volumes.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\n'}, {'number': 8, 'created': '2020-10-27 07:58:22.000000000', 'files': ['cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'releasenotes/notes/svf-revert-to-snapshot-globalmirror-volume-e70fdb9115020283.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/06523d30adc2e2765b3ca1f3e634e9b2d82f3e2f', 'message': '[SVF] RevertToSnapshot support for GM volumes\n\nThe current IBM Spectrum Virtualize Family does not support\nRevert to Snapshot for Global Mirror volumes. Added necessary\ncode changes to storwize cinder driver to support\nrevert to snapshot for GM volumes.\n\nChange-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1\n'}]",12,751837,06523d30adc2e2765b3ca1f3e634e9b2d82f3e2f,311,43,8,32425,,,0,"[SVF] RevertToSnapshot support for GM volumes

The current IBM Spectrum Virtualize Family does not support
Revert to Snapshot for Global Mirror volumes. Added necessary
code changes to storwize cinder driver to support
revert to snapshot for GM volumes.

Change-Id: I71ab47d7e46afebdcd0ed062e26afdd9e598e3f1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/37/751837/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py']",2,eb7253cffd1414c6ac36fbfb03b578895017b4f7,r9_revert," if rep_type: try: self._helpers.stop_relationship(volume.name, access=False) except Exception as err: msg = (_(""Stop RC relationship has failed for %(vol)s"" ""due to: %(err)s."") % {""vol"": volume.name, ""err"": err}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) if rep_type: self._helpers.start_relationship(volume.name, primary=None)", if rep_type: raise exception.InvalidInput( reason=_('Reverting replication volume is not supported.')),97,11
openstack%2Ftripleo-ansible~master~I87d66050f04bd467583990fc97ffa12d457b7d15,openstack/tripleo-ansible,master,I87d66050f04bd467583990fc97ffa12d457b7d15,Populate network ports env module,MERGED,2020-11-30 11:19:13.000000000,2021-01-04 23:32:16.000000000,2021-01-04 23:31:04.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-11-30 11:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cffd462a2556303958ce15efce731848c68832da', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 2, 'created': '2020-11-30 17:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/064698f148fba000509997d867367f8a6640a634', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 3, 'created': '2020-12-01 12:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2e37879b877a0c1345d616b99ca9ad39bf47a080', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 4, 'created': '2020-12-04 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2f6b26d0afb85494ad11b3c7904cc38616a1a80e', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 5, 'created': '2020-12-04 18:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0a98f33db6177fa7502ed0fd9fb0d7e8b0a3e2b5', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 6, 'created': '2020-12-04 19:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d06e1a4476de3f6dfd29008dfb78f41ce8cd35d4', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 7, 'created': '2020-12-07 17:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9206f679d801d20f419e0fcd7959fdf990091c09', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 8, 'created': '2020-12-18 05:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4e3186d0e5325e7114c4d2160c87ee23c2cf445c', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}, {'number': 9, 'created': '2020-12-18 06:47:44.000000000', 'files': ['doc/source/modules/modules-tripleo_network_ports_populate_environment.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_network_ports_populate_environment.py', 'tripleo_ansible/tests/modules/test_tripleo_network_ports_populate_environment.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7aefbb550cbc88319ba033baf90c773d3203dbae', 'message': ""Populate network ports env module\n\nAdd ansible module which creates/adds instnace network\nports information to a triple heat environment file.\n\nThe NodePortMap is added to 'parameter_defaults' and\nresource registry overrides for overcloud port resouces\nto use the network/ports/deployed_{{network.name}}.yaml\ntemplates.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: I87d66050f04bd467583990fc97ffa12d457b7d15\n""}]",2,764638,7aefbb550cbc88319ba033baf90c773d3203dbae,41,5,9,24245,,,0,"Populate network ports env module

Add ansible module which creates/adds instnace network
ports information to a triple heat environment file.

The NodePortMap is added to 'parameter_defaults' and
resource registry overrides for overcloud port resouces
to use the network/ports/deployed_{{network.name}}.yaml
templates.

Partial-Implements: blueprint network-data-v2-ports
Change-Id: I87d66050f04bd467583990fc97ffa12d457b7d15
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/38/764638/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/modules/modules-tripleo_network_ports_populate_environment.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_network_ports_populate_environment.py', 'tripleo_ansible/tests/modules/test_tripleo_network_ports_populate_environment.py']",3,cffd462a2556303958ce15efce731848c68832da,nework-data-v2,"# Copyright 2020 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import openstack from tripleo_ansible.ansible_plugins.modules import ( tripleo_network_ports_populate_environment as plugin) from tripleo_ansible.tests import base as tests_base from tripleo_ansible.tests import stubs class TestTripleoNetworkPortsPopulateEnvironment(tests_base.TestCase): def test_update_environment(self): env = { 'parameter_defaults': { 'FooParam': 'foo', 'BarParam': 'bar'}, 'resource_registry': { 'OS::Some::Existing::Resource': '/foo/bar/some_resource.yaml'} } node_port_map = { 'role-a-0': {'foo': {'ip_address': '1.1.1.1'}, 'bar': {'ip_address': '1.1.2.1'}, 'baz': {'ip_address': '1.1.3.1'}}, 'role-b-0': {'foo': {'ip_address': '1.1.1.2'}, 'bar': {'ip_address': '1.1.2.2'}}, } role_net_map = { 'RoleA': ['ctlplane', 'foo', 'bar', 'baz'], 'RoleB': ['ctlplane', 'foo', 'bar'] } net_name_map = {'foo': 'Foo', 'bar': 'Bar', 'baz': 'Baz'} plugin.update_environment(env, node_port_map, role_net_map, net_name_map) self.assertEqual( {'FooParam': 'foo', 'BarParam': 'bar', 'NodePortMap': { 'role-a-0': {'bar': {'ip_address': '1.1.2.1'}, 'baz': {'ip_address': '1.1.3.1'}, 'foo': {'ip_address': '1.1.1.1'}}, 'role-b-0': {'bar': {'ip_address': '1.1.2.2'}, 'foo': {'ip_address': '1.1.1.2'}}, }}, env['parameter_defaults']) self.assertEqual( {'OS::Some::Existing::Resource': '/foo/bar/some_resource.yaml', 'OS::TripleO::RoleA::Ports::BarPort': '/usr/share/openstack-tripleo-heat-templates/' 'network/ports/deployed_bar.yaml', 'OS::TripleO::RoleA::Ports::BazPort': '/usr/share/openstack-tripleo-heat-templates/' 'network/ports/deployed_baz.yaml', 'OS::TripleO::RoleA::Ports::FooPort': '/usr/share/openstack-tripleo-heat-templates/' 'network/ports/deployed_foo.yaml', 'OS::TripleO::RoleB::Ports::BarPort': '/usr/share/openstack-tripleo-heat-templates/' 'network/ports/deployed_bar.yaml', 'OS::TripleO::RoleB::Ports::FooPort': '/usr/share/openstack-tripleo-heat-templates/' 'network/ports/deployed_foo.yaml'}, env['resource_registry']) @mock.patch.object(openstack.connection, 'Connection', autospec=True) def test_get_net_name_map(self, mock_conn): fake_networks = [ stubs.FakeNeutronNetwork(id='bar', name='bar', tags=['tripleo_network_name=UPPERNAME']), stubs.FakeNeutronNetwork(id='baz', name='baz', tags=['tripleo_network_name=UPPERNAME']), stubs.FakeNeutronNetwork(id='foo', name='foo', tags=['tripleo_network_name=UPPERNAME']), ] mock_conn.network.find_network.side_effect = fake_networks role_net_map = {'RoleA': ['foo', 'bar', 'baz'], 'RoleB': ['foo', 'bar']} # NOTE(hjensas): Different tripleo_network_name in stubs would require # set to list conversion and sorting. self.assertEqual({'foo': 'UPPERNAME', 'bar': 'UPPERNAME', 'baz': 'UPPERNAME'}, plugin.get_net_name_map(mock_conn, role_net_map)) ",,299,0
openstack%2Fmanila-ui~master~I6ddd11535e9365e8b55a6829967b886c2253d6f0,openstack/manila-ui,master,I6ddd11535e9365e8b55a6829967b886c2253d6f0,Update requirements,MERGED,2020-12-16 18:37:47.000000000,2021-01-04 23:26:28.000000000,2021-01-04 23:25:03.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5314}, {'_account_id': 6413}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-16 18:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/da76c21b66c030eb6900a25a7a61750bff3beb50', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 2, 'created': '2020-12-17 11:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/c33c39f2eb3b0d1fc583b229eaac086619af69ea', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 3, 'created': '2020-12-17 12:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/3d495e43b6306e175ce10a593a3f99f2a53dc4f4', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 4, 'created': '2020-12-17 14:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/b3047b5d3144ca9d425a926bb64c78e719093b08', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 5, 'created': '2020-12-17 17:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/bdc7672bd7f59dfbb0ebcdf596ed6bc4443fea24', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 6, 'created': '2020-12-17 18:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/bf4c00cb9a0356bf8907b1699866271122e0aa05', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 7, 'created': '2020-12-18 12:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/9069836659605368e9ee9de3452a7a1bba31e1c8', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 8, 'created': '2020-12-18 14:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/1014c703379de4515a7fef216a5816b22c353b2b', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 9, 'created': '2020-12-18 15:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/d5c047a2235b4e5d48ec7ef25f19d0eee025f0f4', 'message': 'Update requirements\n\nUpdated test requirements to be compatible with pip 20.3\ndependancy resolver. ""XStatic-mdi"" test was failing for me,\nI updated its version lower-constraints.txt and updated\nother packages versions as per recent requirements update\npatches from other projects, so they are reflected in\nmanila-ui as well.\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n'}, {'number': 10, 'created': '2020-12-30 16:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/cc81a42932d061aa5faf5dd06ae97397a5d4f683', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}, {'number': 11, 'created': '2020-12-30 16:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/c78bd1553d806ca3f3c25a087190123e97a1d354', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}, {'number': 12, 'created': '2020-12-30 17:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/80bb2d92e55214329245b9a74a5d816c541602a0', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}, {'number': 13, 'created': '2020-12-30 18:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/598934c1a7e955aac79159c49ecdf431af089eb1', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}, {'number': 14, 'created': '2020-12-31 17:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/b58f2cc04271b72eea6b1b011fc5de8f19e3c5ee', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}, {'number': 15, 'created': '2020-12-31 19:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/b5c1aef0819a24842b3d37f5520e57dc3fe8b2a6', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}, {'number': 16, 'created': '2020-12-31 23:48:18.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/275c132fd5c9383b2540d3a7834013fd32cca90a', 'message': ""Update requirements\n\npip 20.3 brings in a strict dependency resolver which\nis enabled by default. This causes our lower-constraints\ntests to fail, because the requirement files were out\nof date from reality - they had conflicting requirements\nwhich previous versions of pip were ignoring. Let's catch\nup package versions to newer ones that are supported in\nthe python runtimes that the Wallaby release will be\ndeployed to.\n\n[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html\n[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020\n\nChange-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0\n""}]",0,767397,275c132fd5c9383b2540d3a7834013fd32cca90a,52,6,16,32531,,,0,"Update requirements

pip 20.3 brings in a strict dependency resolver which
is enabled by default. This causes our lower-constraints
tests to fail, because the requirement files were out
of date from reality - they had conflicting requirements
which previous versions of pip were ignoring. Let's catch
up package versions to newer ones that are supported in
the python runtimes that the Wallaby release will be
deployed to.

[1] http://pyfound.blogspot.com/2020/11/pip-20-3-new-resolver.html
[2] https://pip.pypa.io/en/stable/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020

Change-Id: I6ddd11535e9365e8b55a6829967b886c2253d6f0
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/97/767397/16 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,da76c21b66c030eb6900a25a7a61750bff3beb50,update-requirements,coverage==5.2.1 cryptography==2.5.0 ddt==1.4.1iso8601==0.1.12keystoneauth1==3.6.2mccabe==0.6.0netaddr==0.8.0oslo.concurrency==4.3.0 oslo.config==8.3.2 oslo.context==3.1.1 oslo.i18n==5.0.1 oslo.log==4.4.0 oslo.policy==3.5.0 oslo.serialization==4.0.1 oslo.utils==4.7.0packaging==20.4 pbr==5.5.0pyparsing==2.4.7python-glanceclient==3.2.2 python-keystoneclient==4.1.1python-novaclient==17.2.1 python-subunit==1.4.0XStatic-mdi==1.6.50.2,coverage==4.0 cryptography==2.1.4 ddt==1.0.1iso8601==0.1.11keystoneauth1==3.4.0mccabe==0.2.1netaddr==0.7.19oslo.concurrency==3.26.0 oslo.config==5.2.0 oslo.context==2.20.0 oslo.i18n==3.20.0 oslo.log==3.37.0 oslo.policy==1.34.0 oslo.serialization==2.25.0 oslo.utils==3.33.0packaging==17.1 pbr==2.0.0pyparsing==2.2.0python-glanceclient==2.9.1 python-keystoneclient==3.22.0python-novaclient==10.1.0 python-subunit==1.0.0XStatic-mdi==1.4.57.0,29,29
openstack%2Fopenstack-tempest-skiplist~master~Ia495a8c3524fcdf4d364f79d7beee918ed000720,openstack/openstack-tempest-skiplist,master,Ia495a8c3524fcdf4d364f79d7beee918ed000720,add skips for glance issues in train,MERGED,2020-12-18 19:25:21.000000000,2021-01-04 23:02:34.000000000,2020-12-18 21:01:27.000000000,"[{'_account_id': 8175}, {'_account_id': 9592}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 19:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/29c5c26003e17d63cf152672d9ed4c3cad635124', 'message': 'add skips for glance issues in train\n\nglance has perm issues\n\nRelated-Bug: #1908750\nChange-Id: Ia495a8c3524fcdf4d364f79d7beee918ed000720\n'}, {'number': 2, 'created': '2020-12-18 19:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/c743f8931ec3c03f7e47157de37409a74a24c88a', 'message': 'add skips for glance issues in train\n\nglance has perm issues\n\nRelated-Bug: #1908750\nChange-Id: Ia495a8c3524fcdf4d364f79d7beee918ed000720\n'}, {'number': 3, 'created': '2020-12-18 19:44:18.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/7c25285a0d9968854e9a75f96f130480a6a672a5', 'message': 'add skips for glance issues in train\n\nglance has perm issues\n\nRelated-Bug: #1908750\nChange-Id: Ia495a8c3524fcdf4d364f79d7beee918ed000720\n'}]",7,767938,7c25285a0d9968854e9a75f96f130480a6a672a5,14,3,3,9592,,,0,"add skips for glance issues in train

glance has perm issues

Related-Bug: #1908750
Change-Id: Ia495a8c3524fcdf4d364f79d7beee918ed000720
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/38/767938/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,29c5c26003e17d63cf152672d9ed4c3cad635124,, - test: tempest.api.compute.servers.test_create_server deployment: - 'overcloud' releases: - name: 'train' reason: 'volume failed to build and is in ERROR status lp: https://bugs.launchpad.net/tripleo/+bug/1908750 jobs: - periodic-tripleo-ci-centos-8-standalone-train - tripleo-ci-centos-8-standalone - periodic-tripleo-ci-centos-8-standalone-full-tempest-api-train - periodic-tripleo-ci-centos-8-standalone-full-tempest-scenario-train - test: tempest.api.volume.test_volumes_actions deployment: - 'overcloud' releases: - name: 'train' reason: 'volume failed to build and is in ERROR status lp: https://bugs.launchpad.net/tripleo/+bug/1908750 jobs: - periodic-tripleo-ci-centos-8-standalone-train - tripleo-ci-centos-8-standalone - periodic-tripleo-ci-centos-8-standalone-full-tempest-api-train - periodic-tripleo-ci-centos-8-standalone-full-tempest-scenario-train - test: tempest.api.volume.test_volumes_list deployment: - 'overcloud' releases: - name: 'train' reason: 'volume failed to build and is in ERROR status lp: https://bugs.launchpad.net/tripleo/+bug/1908750 jobs: - periodic-tripleo-ci-centos-8-standalone-train - tripleo-ci-centos-8-standalone - periodic-tripleo-ci-centos-8-standalone-full-tempest-api-train - periodic-tripleo-ci-centos-8-standalone-full-tempest-scenario-train - test: tempest.api.volume.test_volumes_get.VolumesGetTest deployment: - 'overcloud' releases: - name: 'train' reason: 'volume failed to build and is in ERROR status lp: https://bugs.launchpad.net/tripleo/+bug/1908750 jobs: - periodic-tripleo-ci-centos-8-standalone-train - tripleo-ci-centos-8-standalone - periodic-tripleo-ci-centos-8-standalone-full-tempest-api-train - periodic-tripleo-ci-centos-8-standalone-full-tempest-scenario-train ,,49,0
openstack%2Ftripleo-common~master~I5177408258b6d33daa26239e7b5c4f017b9372cf,openstack/tripleo-common,master,I5177408258b6d33daa26239e7b5c4f017b9372cf,TCIB: Fix debug mode for oslo process execute,MERGED,2020-11-20 11:05:55.000000000,2021-01-04 22:23:38.000000000,2021-01-04 22:21:24.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-11-20 11:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/abe0d7cb49351b36db02c6d8b465c36f144559e1', 'message': 'TCIB: Fix debug mode for oslo process execute\n\nWhen pushing with buildah, there is no logfile options.\nIt dumps results of work to stderr.\nIn debug mode, we want those results logged. But we do not\nreconfigure oslo.log defaults, so it skips all details as\nit goes with INFO config instead.\n\nCapture debug results of process execution utility for buildah\npush and use the current logging context as well.\n\nAlso oslo process utils will log the time it took to do\nbuildah bud builds as a nice free bonus.\n\nChange-Id: I5177408258b6d33daa26239e7b5c4f017b9372cf\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2021-01-04 14:03:01.000000000', 'files': ['tripleo_common/image/builder/buildah.py', 'tripleo_common/utils/process.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e05e6bdf13feed14c286a3385c5a0c67a76f684b', 'message': 'TCIB: Fix debug mode for oslo process execute\n\nWhen pushing with buildah, there is no logfile options.\nIt dumps results of work to stderr.\nIn debug mode, we want those results logged. But we do not\nreconfigure oslo.log defaults, so it skips all details as\nit goes with INFO config instead.\n\nCapture debug results of process execution utility for buildah\npush and use the current logging context as well.\n\nAlso oslo process utils will log the time it took to do\nbuildah bud builds as a nice free bonus.\n\nChange-Id: I5177408258b6d33daa26239e7b5c4f017b9372cf\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",0,763544,e05e6bdf13feed14c286a3385c5a0c67a76f684b,23,8,2,6926,,,0,"TCIB: Fix debug mode for oslo process execute

When pushing with buildah, there is no logfile options.
It dumps results of work to stderr.
In debug mode, we want those results logged. But we do not
reconfigure oslo.log defaults, so it skips all details as
it goes with INFO config instead.

Capture debug results of process execution utility for buildah
push and use the current logging context as well.

Also oslo process utils will log the time it took to do
buildah bud builds as a nice free bonus.

Change-Id: I5177408258b6d33daa26239e7b5c4f017b9372cf
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/44/763544/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/builder/buildah.py', 'tripleo_common/utils/process.py']",2,abe0d7cb49351b36db02c6d8b465c36f144559e1,," logger = kwargs.pop('logger', LOG) logger.debug('Execution completed, command line is ""%s""', ' '.join(map(str, cmd))) if log_stdout: logger.debug('Command stdout is: ""%s""', result[0]) logger.debug('Command stderr is: ""%s""', result[1])"," LOG.debug('Execution completed, command line is ""%s""', ' '.join(map(str, cmd))) if log_stdout: LOG.debug('Command stdout is: ""%s""', result[0]) LOG.debug('Command stderr is: ""%s""', result[1])",16,5
openstack%2Fsushy~master~Ifa13126244aa4ff3f5387ed7f39ff44e3f977748,openstack/sushy,master,Ifa13126244aa4ff3f5387ed7f39ff44e3f977748,WIP: direct boot order setting support,NEW,2020-04-07 22:45:47.000000000,2021-01-04 21:49:26.000000000,,"[{'_account_id': 10239}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-04-07 22:45:47.000000000', 'files': ['sushy/resources/system/constants.py', 'sushy/resources/system/system.py', 'sushy/resources/system/mappings.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/4fe4bb55b4b60ed6c67675e4812a12b9681cf2aa', 'message': 'WIP: direct boot order setting support\n\nChange-Id: Ifa13126244aa4ff3f5387ed7f39ff44e3f977748\n'}]",2,718275,4fe4bb55b4b60ed6c67675e4812a12b9681cf2aa,5,3,1,11655,,,0,"WIP: direct boot order setting support

Change-Id: Ifa13126244aa4ff3f5387ed7f39ff44e3f977748
",git fetch https://review.opendev.org/openstack/sushy refs/changes/75/718275/1 && git format-patch -1 --stdout FETCH_HEAD,"['sushy/resources/system/constants.py', 'sushy/resources/system/system.py', 'sushy/resources/system/mappings.py']",3,4fe4bb55b4b60ed6c67675e4812a12b9681cf2aa,,"BOOT_ORDER_SELECTOR_MAP = { 'AliasBootOrder': sys_cons.ALIAS_BOOT_ORDER, 'BootOrder': sys_cons.BOOT_ORDER, } BOOT_ORDER_SELECTOR_MAP_REV = utils.revert_dictionary(BOOT_ORDER_SELECTOR_MAP) # NOTE(TheJulia): For AliasBootOrder, we MAY want to split the list and # duplicate it, however for Redfish 1.10, the list appears to be identical.",,53,1
openstack%2Fopenstack-helm-images~master~Ia48bc1e6c22667ceb3b3be0b5d4ef22bc0be5db2,openstack/openstack-helm-images,master,Ia48bc1e6c22667ceb3b3be0b5d4ef22bc0be5db2,Fix promotion in loci periodic jobs for non tested releases,MERGED,2020-12-24 20:16:25.000000000,2021-01-04 21:48:40.000000000,2021-01-04 21:41:12.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-12-24 20:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/7918dc27dd1fb74d14e30314556d0ecfd1cfe4e0', 'message': 'Fix promotion in loci periodic jobs for non tested releases\n\nWith [0] introduced, upload and promote logic was decoupled for periodic\npipeline. Returning promotion for images that were previously promoted\nin upload job.\n\n[0] https://review.opendev.org/c/openstack/openstack-helm-images/+/768251\n\nChange-Id: Ia48bc1e6c22667ceb3b3be0b5d4ef22bc0be5db2\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}, {'number': 2, 'created': '2020-12-28 18:48:18.000000000', 'files': ['zuul.d/openstack-loci.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/fb8f0271ebc47741f6fb32da0c31d094af0537d2', 'message': 'Fix promotion in loci periodic jobs for non tested releases\n\nWith [0] introduced, upload and promote logic was decoupled for periodic\npipeline. Returning promotion for images that were previously promoted\nin upload job.\n\n[0] https://review.opendev.org/c/openstack/openstack-helm-images/+/768251\n\nChange-Id: Ia48bc1e6c22667ceb3b3be0b5d4ef22bc0be5db2\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}]",0,768486,fb8f0271ebc47741f6fb32da0c31d094af0537d2,10,5,2,8863,,,0,"Fix promotion in loci periodic jobs for non tested releases

With [0] introduced, upload and promote logic was decoupled for periodic
pipeline. Returning promotion for images that were previously promoted
in upload job.

[0] https://review.opendev.org/c/openstack/openstack-helm-images/+/768251

Change-Id: Ia48bc1e6c22667ceb3b3be0b5d4ef22bc0be5db2
Signed-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/86/768486/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/openstack-loci.yaml'],1,7918dc27dd1fb74d14e30314556d0ecfd1cfe4e0,, - openstack-helm-images-promote-openstack-loci-ocata-ubuntu_xenial: dependencies: - name: openstack-helm-images-upload-openstack-loci-ocata-ubuntu_xenial - openstack-helm-images-promote-openstack-loci-pike-ubuntu_xenial: dependencies: - name: openstack-helm-images-upload-openstack-loci-pike-ubuntu_xenial - openstack-helm-images-promote-openstack-loci-queens-ubuntu_xenial: dependencies: - name: openstack-helm-images-upload-openstack-loci-queens-ubuntu_xenial - openstack-helm-images-promote-openstack-loci-rocky-ubuntu_xenial: dependencies: - name: openstack-helm-images-upload-openstack-loci-rocky-ubuntu_xenial - openstack-helm-images-promote-openstack-loci-rocky-ubuntu_bionic: dependencies: - name: openstack-helm-images-upload-openstack-loci-rocky-ubuntu_bionic - openstack-helm-images-promote-openstack-loci-master-ubuntu_bionic: dependencies: - name: openstack-helm-images-upload-openstack-loci-master-ubuntu_bionic,,18,0
openstack%2Fopenstack-ansible-haproxy_server~stable%2Fvictoria~I51423fff67e6e427f6c7d163d8d1aac6bcd82ca9,openstack/openstack-ansible-haproxy_server,stable/victoria,I51423fff67e6e427f6c7d163d8d1aac6bcd82ca9,Fix HATop for haproxy,MERGED,2021-01-04 17:08:35.000000000,2021-01-04 21:34:27.000000000,2021-01-04 21:33:01.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 28752}]","[{'number': 1, 'created': '2021-01-04 17:08:35.000000000', 'files': ['tasks/haproxy_install.yml', 'releasenotes/notes/haproxy-hatop-4d6525a52f93a69e.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/3a0d672751b88d20942ae7b60142e118837f50ef', 'message': 'Fix HATop for haproxy\n\nReadjust hatop installtion method, removed haproxy_hatop_downloader and\ndeployment-host variables. added ""haproxy_hatop_install | bool"" condition.\n\nChange-Id: I51423fff67e6e427f6c7d163d8d1aac6bcd82ca9\n(cherry picked from commit 0ef22fa4df1d0a66b39978682f29f4035f509809)\n'}]",0,769176,3a0d672751b88d20942ae7b60142e118837f50ef,8,4,1,28619,,,0,"Fix HATop for haproxy

Readjust hatop installtion method, removed haproxy_hatop_downloader and
deployment-host variables. added ""haproxy_hatop_install | bool"" condition.

Change-Id: I51423fff67e6e427f6c7d163d8d1aac6bcd82ca9
(cherry picked from commit 0ef22fa4df1d0a66b39978682f29f4035f509809)
",git fetch https://review.opendev.org/openstack/openstack-ansible-haproxy_server refs/changes/76/769176/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/haproxy_install.yml', 'releasenotes/notes/haproxy-hatop-4d6525a52f93a69e.yaml', 'defaults/main.yml']",3,3a0d672751b88d20942ae7b60142e118837f50ef,osa/haproxy-stable/victoria,# Install hatop haproxy_hatop_install: true,"# Where the extra package download is executed from. # Options are ['deployment-host', 'target-host'] haproxy_hatop_downloader: ""deployment-host""",42,31
openstack%2Fopenstack-helm~master~Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29,openstack/openstack-helm,master,Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29,Modify Password validator related settings in Horizon,MERGED,2020-12-08 11:17:17.000000000,2021-01-04 21:22:30.000000000,2021-01-04 21:19:53.000000000,"[{'_account_id': 1004}, {'_account_id': 11934}, {'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23140}, {'_account_id': 24780}, {'_account_id': 29397}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-08 11:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fb3426bb59d4b81423686e1f6b115459731d9d1c', 'message': 'Modify Password related settings in Horizon\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 2, 'created': '2020-12-08 11:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3f7e9e32bfc58632c6abbb30103137ab507b7d59', 'message': '[WIP] Modify Password related settings in Horizon\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 3, 'created': '2020-12-09 11:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0251190547ac043b50806452462d4daf4dfb459b', 'message': '[WIP] Modify Password related settings in Horizon\n\nModify PASSWORD_VALIDATOR so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 4, 'created': '2020-12-14 14:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/23af533106e1ea8468404881426f994676b16b60', 'message': '[WIP] Modify Password related settings in Horizon\n\nModify PASSWORD_VALIDATOR so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 5, 'created': '2020-12-14 15:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c3829ca583e76a4a18887bf0246021fbc09d74eb', 'message': '[WIP] Modify Password related settings in Horizon\n\nModify PASSWORD_VALIDATOR so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 6, 'created': '2020-12-15 07:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cf913145828645399fbb73c20203fa57b845d72d', 'message': '[WIP] Modify Password related settings in Horizon\n\nModify PASSWORD_VALIDATOR so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 7, 'created': '2020-12-15 10:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e233bf501d59e21728e9ee8cf8092d1f3f804be0', 'message': '[WIP] Modify Password related settings in Horizon\n\nModify PASSWORD_VALIDATOR so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 8, 'created': '2020-12-15 10:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/019e8d6c093364d95ca55c88eed965a1a760ccd4', 'message': '[WIP] Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 9, 'created': '2020-12-15 17:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e9c30ac23a104900d827fdc69bdcb2ecf0e0b0c0', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 10, 'created': '2020-12-16 15:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/daa43932d83626b8ecdf7c81a535640d7adbe34e', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 11, 'created': '2020-12-17 09:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5b1dae147ecbeae0a8b3fc2599fc7692694a2f5e', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 12, 'created': '2020-12-17 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7fffa19c334513d7f28bc7631383eba50f1567e0', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 13, 'created': '2020-12-17 11:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/922260e7b841c01cf4a79bcd944c8d661a6de664', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 14, 'created': '2020-12-17 11:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4a14f79e08317901b23adc5d65f7901670914aa3', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 15, 'created': '2020-12-17 11:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/47a1c859cac02af1b180295acc28f7cb9d78bc4d', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 16, 'created': '2020-12-17 11:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6e245e528c96583d4509d0894046d05d44596320', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 17, 'created': '2020-12-17 11:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4e181e6d554a7778a1a86a6d11beb8ba0e8a6067', 'message': 'Modify Password validator related settings in Horizon\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 18, 'created': '2020-12-17 16:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/19e2e684914408ac0675331d20660be6783781e0', 'message': 'Modify Password validator related settings in Horizon\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 19, 'created': '2020-12-17 16:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/99dbc764046ee77954545b694454f809b293e2ee', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}, {'number': 20, 'created': '2021-01-04 02:25:53.000000000', 'files': ['horizon/Chart.yaml', 'horizon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b65988fa5cd08142facb7709e524d417d2ff9a66', 'message': 'Modify Password validator related settings in Horizon\n\nAdd ""enable_pwd_validator"" variable to apply password\nvalidator settings when enabled in horizon values.\n\nModify ""PASSWORD_VALIDATOR"" so as to enforce password\nrequirements i.e., password must be at least eight\ncharacters in length and must include characters from\nat least two of these groupings: alpha, numeric, and\nspecial characters when ""enable_pwd_validator"" is enabled.\n\nChange-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29\n'}]",6,765966,b65988fa5cd08142facb7709e524d417d2ff9a66,55,11,20,31479,,,0,"Modify Password validator related settings in Horizon

Add ""enable_pwd_validator"" variable to apply password
validator settings when enabled in horizon values.

Modify ""PASSWORD_VALIDATOR"" so as to enforce password
requirements i.e., password must be at least eight
characters in length and must include characters from
at least two of these groupings: alpha, numeric, and
special characters when ""enable_pwd_validator"" is enabled.

Change-Id: Ia866feb875490d0bb40e820c6c32ee2cb6aa4c29
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/66/765966/14 && git format-patch -1 --stdout FETCH_HEAD,['horizon/values.yaml'],1,fb3426bb59d4b81423686e1f6b115459731d9d1c,," HORIZON_CONFIG[""password_validator""] = { ""regex"": '(?=.*[a-zA-Z])(?=.*\d){8,}|(?=.*\d)(?=.*\W).{8,}|(?=.*\W)(?=.*[a-zA-Z]).{8,}', ""help_text"": _(""Your password must be at least eight (8) characters in length and must include characters from at least two (2) of these groupings: alpha, numeric, and special characters.""), }"," #HORIZON_CONFIG[""password_validator""] = { # ""regex"": '.*', # ""help_text"": _(""Your password does not meet the requirements.""), #}",4,4
openstack%2Fneutron~stable%2Fvictoria~I74916acf8311989dca267f23261ec4cf449a6abf,openstack/neutron,stable/victoria,I74916acf8311989dca267f23261ec4cf449a6abf,Fix OVS conjunctive IP flows cleanup,MERGED,2020-12-18 08:51:51.000000000,2021-01-04 21:06:01.000000000,2021-01-04 21:04:01.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28159}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-18 08:51:51.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3801fe6104ef1dd2a56d94126e88a6fd0c4e7ddf', 'message': ""Fix OVS conjunctive IP flows cleanup\n\n Currently when deleting a remote-group's member IPs, the deleted IPs'\n conjunctive flows are not cleaned up in OF tables. This is because\n the conjunctive flows' cookies don't match with the OVSBridge default\n cookie used by the delete flow method. This patch fixed the issue by\n using an ANY cookie that can always match with the cookies of the\n conjunctive flows.\n\nChange-Id: I74916acf8311989dca267f23261ec4cf449a6abf\nCloses-Bug: 1907491\n(cherry picked from commit f4b64e519cdb9fd9c5046f21bc9f325341fd367f)\n""}]",1,767676,3801fe6104ef1dd2a56d94126e88a6fd0c4e7ddf,14,6,1,16688,,,0,"Fix OVS conjunctive IP flows cleanup

 Currently when deleting a remote-group's member IPs, the deleted IPs'
 conjunctive flows are not cleaned up in OF tables. This is because
 the conjunctive flows' cookies don't match with the OVSBridge default
 cookie used by the delete flow method. This patch fixed the issue by
 using an ANY cookie that can always match with the cookies of the
 conjunctive flows.

Change-Id: I74916acf8311989dca267f23261ec4cf449a6abf
Closes-Bug: 1907491
(cherry picked from commit f4b64e519cdb9fd9c5046f21bc9f325341fd367f)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/767676/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py']",2,3801fe6104ef1dd2a56d94126e88a6fd0c4e7ddf,bug/1907491," def test_delete_flow_for_ip_using_cookie_any(self): with mock.patch.object(self.firewall, '_delete_flows') as \ mock_delete_flows: self.firewall.delete_flow_for_ip(('10.1.2.3', None), constants.INGRESS_DIRECTION, constants.IPv4, 100, [0]) _, kwargs = mock_delete_flows.call_args self.assertIn('cookie', kwargs) self.assertIs(ovs_lib.COOKIE_ANY, kwargs['cookie']) ",,15,0
openstack%2Fswift~master~I14bc184d6414b73b43ccc65f3358f193480b7eaf,openstack/swift,master,I14bc184d6414b73b43ccc65f3358f193480b7eaf,proxy: Require container_info to read objects,NEW,2020-12-03 23:23:48.000000000,2021-01-04 20:54:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-03 23:23:48.000000000', 'files': ['test/unit/proxy/test_server.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c148a9b4984a585752f2b0033ed4e47540a76dc5', 'message': ""proxy: Require container_info to read objects\n\nAt least, when there's more than one policy. Otherwise, our current\nassumption of Policy-0 means we may erroneously send back a 404 where a\n503 would've been more appropriate.\n\nWhile we're at it, defend the object-servers a little more when the\ncontainer doesn't exist; we should be fairly confident that the object\ndoesn't either.\n\nChange-Id: I14bc184d6414b73b43ccc65f3358f193480b7eaf\n""}]",12,765420,c148a9b4984a585752f2b0033ed4e47540a76dc5,5,1,1,15343,,,0,"proxy: Require container_info to read objects

At least, when there's more than one policy. Otherwise, our current
assumption of Policy-0 means we may erroneously send back a 404 where a
503 would've been more appropriate.

While we're at it, defend the object-servers a little more when the
container doesn't exist; we should be fairly confident that the object
doesn't either.

Change-Id: I14bc184d6414b73b43ccc65f3358f193480b7eaf
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/765420/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/test_server.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/controllers/base.py']",3,c148a9b4984a585752f2b0033ed4e47540a76dc5,," if info and info.get('status') == HTTP_NOT_FOUND: info = headers_to_container_info({}, 404) info['partition'] = None info['nodes'] = None elif not info or not is_success(info.get('status')):", if not info or not is_success(info.get('status')):,81,1
openstack%2Fpaunch~stable%2Fqueens~I479eaa3b58c3df091e1b78a01c4fb0595d81b37c,openstack/paunch,stable/queens,I479eaa3b58c3df091e1b78a01c4fb0595d81b37c,Allow to not cleanup containers that aren't in config,MERGED,2020-11-17 14:15:32.000000000,2021-01-04 20:52:06.000000000,2021-01-04 20:52:06.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-11-17 14:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/f98e71114e5630b83284d0db82210b28ac551c23', 'message': ""Allow to not cleanup containers that aren't in config\n\nSimilar to Ic06ac0f41767ca513c612b1ebb38d2ff92500ea5 :\n\nRelax Paunch and allows an operator to apply a config on a specific\ncontainer without removing the other containers in the same config_id.\nThanks to the paunch apply (...) --cleanup=False, if a container is\ninstalled on the host for a given config_id, but not in the given config\nanymore; it won't be removed.\n\nThe cleanup still happens by default for backward compatibility.\n\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I479eaa3b58c3df091e1b78a01c4fb0595d81b37c\n(cherry picked from commit 8489a0cfbeafedf635049623fce5d9b3172288de)\n""}, {'number': 2, 'created': '2020-11-18 09:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/57fd64000d2fac0b9db8960fdc153bc0a6169bcb', 'message': ""Allow to not cleanup containers that aren't in config\n\nSimilar to Ic06ac0f41767ca513c612b1ebb38d2ff92500ea5 :\n\nRelax Paunch and allows an operator to apply a config on a specific\ncontainer without removing the other containers in the same config_id.\nThanks to the paunch apply (...) --no-cleanup, if a container is\ninstalled on the host for a given config_id, but not in the given config\nanymore; it won't be removed.\n\nThe cleanup still happens by default for backward compatibility.\n\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I479eaa3b58c3df091e1b78a01c4fb0595d81b37c\n(cherry picked from commit 8489a0cfbeafedf635049623fce5d9b3172288de)\n""}, {'number': 3, 'created': '2020-11-18 09:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/c158ab5bcf028a463f82709294291eff5a076e8e', 'message': ""Allow to not cleanup containers that aren't in config\n\nSimilar to Ic06ac0f41767ca513c612b1ebb38d2ff92500ea5 :\n\nRelax Paunch and allows an operator to apply a config on a specific\ncontainer without removing the other containers in the same config_id.\nThanks to the paunch apply (...) --no-cleanup, if a container is\ninstalled on the host for a given config_id, but not in the given config\nanymore; it won't be removed.\n\nThe cleanup still happens by default for backward compatibility.\n\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I479eaa3b58c3df091e1b78a01c4fb0595d81b37c\n(cherry picked from commit 8489a0cfbeafedf635049623fce5d9b3172288de\nand 5dcc4df5922e3fed766dd733627f008af456ca7a)\n""}, {'number': 4, 'created': '2020-11-18 12:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/47c5d9bc3672bf48c2a5791c1d2d24a498754766', 'message': ""Allow to not cleanup containers that aren't in config\n\nSimilar to Ic06ac0f41767ca513c612b1ebb38d2ff92500ea5 :\n\nRelax Paunch and allows an operator to apply a config on a specific\ncontainer without removing the other containers in the same config_id.\nThanks to the paunch apply (...) --no-cleanup, if a container is\ninstalled on the host for a given config_id, but not in the given config\nanymore; it won't be removed.\n\nThe cleanup still happens by default for backward compatibility.\n\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I479eaa3b58c3df091e1b78a01c4fb0595d81b37c\n(cherry picked from commit 8489a0cfbeafedf635049623fce5d9b3172288de\nand 5dcc4df5922e3fed766dd733627f008af456ca7a)\n""}, {'number': 5, 'created': '2021-01-04 14:00:59.000000000', 'files': ['paunch/cmd.py', 'paunch/builder/compose1.py', 'paunch/tests/test_paunch.py', 'paunch/__init__.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/643d83c8550a28cd037adefb5ac6ff2d19002ebb', 'message': ""Allow to not cleanup containers that aren't in config\n\nSimilar to Ic06ac0f41767ca513c612b1ebb38d2ff92500ea5 :\n\nRelax Paunch and allows an operator to apply a config on a specific\ncontainer without removing the other containers in the same config_id.\nThanks to the paunch apply (...) --no-cleanup, if a container is\ninstalled on the host for a given config_id, but not in the given config\nanymore; it won't be removed.\n\nThe cleanup still happens by default for backward compatibility.\n\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I479eaa3b58c3df091e1b78a01c4fb0595d81b37c\n(cherry picked from commit 8489a0cfbeafedf635049623fce5d9b3172288de\nand 5dcc4df5922e3fed766dd733627f008af456ca7a)\n""}]",4,763015,643d83c8550a28cd037adefb5ac6ff2d19002ebb,56,9,5,6926,,,0,"Allow to not cleanup containers that aren't in config

Similar to Ic06ac0f41767ca513c612b1ebb38d2ff92500ea5 :

Relax Paunch and allows an operator to apply a config on a specific
container without removing the other containers in the same config_id.
Thanks to the paunch apply (...) --no-cleanup, if a container is
installed on the host for a given config_id, but not in the given config
anymore; it won't be removed.

The cleanup still happens by default for backward compatibility.

Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
Change-Id: I479eaa3b58c3df091e1b78a01c4fb0595d81b37c
(cherry picked from commit 8489a0cfbeafedf635049623fce5d9b3172288de
and 5dcc4df5922e3fed766dd733627f008af456ca7a)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/15/763015/2 && git format-patch -1 --stdout FETCH_HEAD,"['paunch/cmd.py', 'paunch/builder/compose1.py', 'paunch/tests/test_paunch.py', 'paunch/__init__.py']",4,f98e71114e5630b83284d0db82210b28ac551c23,q," log_level=None, log_file=None, cleanup=True): :param bool cleanup: optional boolean to delete containers missing in the config. log=log, cleanup=cleanup"," log_level=None, log_file=None): log=log",32,11
openstack%2Fopenstack-ansible-os_keystone~master~Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486,openstack/openstack-ansible-os_keystone,master,Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486,Add no_log to LDAP domain config,MERGED,2020-12-17 12:25:36.000000000,2021-01-04 20:31:32.000000000,2021-01-04 20:30:21.000000000,"[{'_account_id': 22348}, {'_account_id': 27915}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-17 12:25:36.000000000', 'files': ['tasks/keystone_ldap_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/27f3306713982df7685384c24c1880c2b8ae797c', 'message': 'Add no_log to LDAP domain config\n\nThe data contains credentials which should not appear in logs.\n\nChange-Id: Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486\n'}]",0,767525,27f3306713982df7685384c24c1880c2b8ae797c,15,4,1,25023,,,0,"Add no_log to LDAP domain config

The data contains credentials which should not appear in logs.

Change-Id: Ibcc9dfb0c3382b99d9267e69a0b9a0deaad76486
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/25/767525/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/keystone_ldap_setup.yml'],1,27f3306713982df7685384c24c1880c2b8ae797c,, no_log: true no_log: true,,2,0
openstack%2Fos-brick~stable%2Ftrain~If8a12c18daea9513130a020d01db2c27a93c3cfc,openstack/os-brick,stable/train,If8a12c18daea9513130a020d01db2c27a93c3cfc,Adjust lower-constraints,MERGED,2020-12-18 17:18:59.000000000,2021-01-04 20:20:24.000000000,2021-01-04 20:19:03.000000000,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 17:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/07390f9e7d5d4d9b2d42c67d27c68b1cd1485e92', 'message': 'Adjust lower-constraints\n\nTwo minor changes:\n- hacking 0.12.0 -> 1.1.0\n  * it was already at >=1.1.0,<1.2.0 in test-req, so updated l-c\n- flake8 2.5.5 -> 2.6.0 (for hacking)\n\nChange-Id: If8a12c18daea9513130a020d01db2c27a93c3cfc\n'}, {'number': 2, 'created': '2020-12-22 17:04:51.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/071b527f95cf40c63fcec9d565dbc01ebd70efce', 'message': 'Adjust lower-constraints\n\nChanges:\n- hacking 0.12.0 -> 1.1.0\n  * it was already at >=1.1.0,<1.2.0 in test-req, so updated l-c\n- flake8 2.5.5 -> 2.6.0 (for hacking)\n- added bandit to test-requirements and l-c\n  * needed to set cap for py27\n\nChange-Id: If8a12c18daea9513130a020d01db2c27a93c3cfc\n'}]",0,767920,071b527f95cf40c63fcec9d565dbc01ebd70efce,46,3,2,5314,,,0,"Adjust lower-constraints

Changes:
- hacking 0.12.0 -> 1.1.0
  * it was already at >=1.1.0,<1.2.0 in test-req, so updated l-c
- flake8 2.5.5 -> 2.6.0 (for hacking)
- added bandit to test-requirements and l-c
  * needed to set cap for py27

Change-Id: If8a12c18daea9513130a020d01db2c27a93c3cfc
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/20/767920/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,07390f9e7d5d4d9b2d42c67d27c68b1cd1485e92,train-l-c,flake8==2.6.0hacking==1.1.0,flake8==2.5.5hacking==0.12.0,2,2
openstack%2Fopenstack-helm-infra~master~Ib970471bfb185b6acfbb2a6cf3e1d28a85bbbe1b,openstack/openstack-helm-infra,master,Ib970471bfb185b6acfbb2a6cf3e1d28a85bbbe1b,Fixing ceph-mgr memory leak,ABANDONED,2020-03-03 18:53:36.000000000,2021-01-04 19:58:59.000000000,,"[{'_account_id': 22348}, {'_account_id': 28372}, {'_account_id': 29937}, {'_account_id': 29974}]","[{'number': 1, 'created': '2020-03-03 18:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/179339fd9c7dae683c1c0784121eda0d111b3bfb', 'message': 'This commit is to fix the ceph-mgr memory leak.\nTwo parameters added are below\nmgr_client_service_daemon_unregister_timeout: 30\nmgr_connect_retry_interval: 60\n\nAlso this commit disable the iostat module on ceph-mgr.\n\nrefer https://tracker.ceph.com/issues/35998\n\nChange-Id: Ib970471bfb185b6acfbb2a6cf3e1d28a85bbbe1b\n'}, {'number': 2, 'created': '2020-03-03 18:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/93a129ee0d30e68dadbba5ec841b67ed46ac0921', 'message': 'Fixing ceph-mgr memory leak\n\nThis commit is to fix the ceph-mgr memory leak.Two parameters added are below\nmgr_client_service_daemon_unregister_timeout: 30\nmgr_connect_retry_interval: 60\n\nAlso this commit disable the iostat module on ceph-mgr. The iostat module write the\ndata on heap memory, and ceph-mgr has not inernal calls to garbage collect that data.\n\nrefer https://tracker.ceph.com/issues/35998\n\nChange-Id: Ib970471bfb185b6acfbb2a6cf3e1d28a85bbbe1b\n'}, {'number': 3, 'created': '2020-03-03 18:59:03.000000000', 'files': ['ceph-client/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/eed03227f439c45ffa52732ad6331ba1679487c8', 'message': 'Fixing ceph-mgr memory leak\n\nThis commit is to fix the ceph-mgr memory leak.Two parameters added are below\nmgr_client_service_daemon_unregister_timeout: 30\nmgr_connect_retry_interval: 60\n\nAlso this commit disable the iostat module on ceph-mgr. The iostat module write the\ndata on heap memory, and ceph-mgr has no inernal calls to garbage collect that data\nwritten on heap.\n\nrefer https://tracker.ceph.com/issues/35998\n\nChange-Id: Ib970471bfb185b6acfbb2a6cf3e1d28a85bbbe1b\n'}]",0,711085,eed03227f439c45ffa52732ad6331ba1679487c8,6,4,3,30705,,,0,"Fixing ceph-mgr memory leak

This commit is to fix the ceph-mgr memory leak.Two parameters added are below
mgr_client_service_daemon_unregister_timeout: 30
mgr_connect_retry_interval: 60

Also this commit disable the iostat module on ceph-mgr. The iostat module write the
data on heap memory, and ceph-mgr has no inernal calls to garbage collect that data
written on heap.

refer https://tracker.ceph.com/issues/35998

Change-Id: Ib970471bfb185b6acfbb2a6cf3e1d28a85bbbe1b
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/85/711085/3 && git format-patch -1 --stdout FETCH_HEAD,['ceph-client/values.yaml'],1,179339fd9c7dae683c1c0784121eda0d111b3bfb,, mgr_client_service_daemon_unregister_timeout: 30 mgr_connect_retry_interval: 60, - iostat,2,1
openstack%2Ftripleo-ansible~master~Ia6e9124c8a17ac77af31be347ab2426c82dbace4,openstack/tripleo-ansible,master,Ia6e9124c8a17ac77af31be347ab2426c82dbace4,Derived parameters: Add AMD iommu support,MERGED,2020-12-01 19:42:22.000000000,2021-01-04 19:53:40.000000000,2021-01-04 19:53:40.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}, {'_account_id': 27419}, {'_account_id': 29268}]","[{'number': 1, 'created': '2020-12-01 19:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cd74b83b8eea1fb510481a8b023aff2dab5b589a', 'message': 'Derived parameters: Add AMD iommu support\n\nChange-Id: Ia6e9124c8a17ac77af31be347ab2426c82dbace4\n'}, {'number': 2, 'created': '2020-12-01 19:45:30.000000000', 'files': ['tripleo_ansible/roles/tripleo_derived_parameters/tasks/derive-host-parameters.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f8631abe754f7927ee8ef0d2652b80350851d4e4', 'message': 'Derived parameters: Add AMD iommu support\n\nChange-Id: Ia6e9124c8a17ac77af31be347ab2426c82dbace4\nSigned-off-by: Christophe Fontaine <cfontain@redhat.com>\n'}]",0,764997,f8631abe754f7927ee8ef0d2652b80350851d4e4,13,8,2,23618,,,0,"Derived parameters: Add AMD iommu support

Change-Id: Ia6e9124c8a17ac77af31be347ab2426c82dbace4
Signed-off-by: Christophe Fontaine <cfontain@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/97/764997/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_derived_parameters/tasks/derive-host-parameters.yml'],1,cd74b83b8eea1fb510481a8b023aff2dab5b589a,amd_iommu,"- name: Get cpu model set_fact: intel_cpu_model: ""{{ 'Intel' in hw_data.get('inventory', {}).get('cpu', {}).get('model_name', '') }}"" amd_cpu_model: ""{{ 'AMD' in hw_data.get('inventory', {}).get('cpu', {}).get('model_name', '') }}"" iommu_info: ""{% if intel_cpu_model %}intel_iommu=on iommu=pt{% elif amd_cpu_model %}amd_iommu=on iommu=pt{% else %}{% endif %}""","- name: Get cpu modal set_fact: intel_cpu_modal: ""{{ 'Intel' in hw_data.get('inventory', {}).get('cpu', {}).get('model_name', '') }}"" iommu_info: ""{% if intel_cpu_modal %}intel_iommu=on iommu=pt{% else %}{% endif %}""",4,3
openstack%2Ftripleo-ansible~master~Ib7931cae079f923a66b412dc5664d1b119580182,openstack/tripleo-ansible,master,Ib7931cae079f923a66b412dc5664d1b119580182,Introduce role/instance 'networks' key,MERGED,2020-11-10 15:39:48.000000000,2021-01-04 19:52:35.000000000,2021-01-04 19:49:25.000000000,"[{'_account_id': 4571}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-11-10 15:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cf6baad8828fdbddc5d1852ac99035b959ef73e3', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 2, 'created': '2020-11-24 14:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/feca2ea46a18b830f33e2e742a8f5651cf99db77', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 3, 'created': '2020-11-24 14:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/40cd14cf34275185b8c2d057253100f4b375dc3f', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 4, 'created': '2020-11-24 15:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/33c4cd4682384f4f0a457b792693188361e70d9d', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 5, 'created': '2020-11-30 11:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f92281d029f4e573814bed7922664caed7c1ea65', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 6, 'created': '2020-11-30 17:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b3a99db95814925ada404b2c6658547a92022dc5', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 7, 'created': '2020-12-01 12:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e9eed1705ae618eecb4184605d608508fc95a10d', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 8, 'created': '2020-12-04 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1dd758ebf7a80b086b2804544b9eb50b9b1b8920', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 9, 'created': '2020-12-04 18:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7c059c8da116c2596545dd3e73248840a69e7f32', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 10, 'created': '2020-12-04 19:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6aef91459eda27ac7d8c0360976052f6d0018f5c', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 11, 'created': '2020-12-07 17:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b3198688d49e13e444653aab6465ec99cc8b3ec6', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 12, 'created': '2020-12-18 05:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4f5f76ab4c80f7055e9c353443d74ac7983e8b5e', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}, {'number': 13, 'created': '2020-12-18 06:47:44.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_baremetal_expand_roles.py', 'tripleo_ansible/tests/plugins/module_utils/test_baremetal_deploy.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7d71eb6d03a7010965ef6123630a375b32c5aecd', 'message': 'Introduce role/instance \'networks\' key\n\nIntroduce the \'networks\' key in be baremetal YAML\ndefinition. Networks can be defined as VIF (ironic\nattached nic) or as a non-attached ""virtual nic""\nvia the \'vif\' boolean.\n\nThe default_network \'ctlplane\' is updated to have\n\'vif\': True.\n\nRole default networks are merged with instance\nnetworks.\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ib7931cae079f923a66b412dc5664d1b119580182\n'}]",13,762160,7d71eb6d03a7010965ef6123630a375b32c5aecd,62,8,13,24245,,,0,"Introduce role/instance 'networks' key

Introduce the 'networks' key in be baremetal YAML
definition. Networks can be defined as VIF (ironic
attached nic) or as a non-attached ""virtual nic""
via the 'vif' boolean.

The default_network 'ctlplane' is updated to have
'vif': True.

Role default networks are merged with instance
networks.

Partial-Implements: blueprint network-data-v2-ports
Change-Id: Ib7931cae079f923a66b412dc5664d1b119580182
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/60/762160/9 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_baremetal_expand_roles.py', 'tripleo_ansible/tests/plugins/module_utils/test_baremetal_deploy.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py']",3,cf6baad8828fdbddc5d1852ac99035b959ef73e3,nework-data-v2,"from copy import deepcopy as dcopy_NETWORK_SCHEMA = { 'type': 'object', 'properties': { 'network': {'type': 'string'}, 'port': {'type': 'string'}, 'fixed_ip': {'type': 'string'}, 'subnet': {'type': 'string'}, 'vif': {'type': 'boolean'} }, 'additionalProperties': False } 'networks': { 'type': 'array', 'items': _NETWORK_SCHEMA, }, def _merge_instance_role_networks(inst, role): if not inst.get('networks') or not role['defaults'].get('networks'): return inst_dict = {x['network']: x for x in inst['networks']} role_dict = {x['network']: x for x in role['defaults']['networks']} for key in role_dict: if key not in inst_dict: inst['networks'].append(role_dict[key]) def _remove_vif_key(nets): for net in nets: try: del net['vif'] except KeyError: pass role_nets = role['defaults'].setdefault('networks', []) role_nets.extend([net for net in default_network if net not in role_nets]) vif_nets = [net for net in dcopy(role_nets) if net.get('vif')] # Remove 'vif' keys before adding vif_nets to to nics _remove_vif_key(vif_nets) role['defaults'].setdefault('nics', vif_nets) # If role default nics and/or networks is empty, delete the default if not role['defaults']['nics']: del role['defaults']['nics'] if not role['defaults']['networks']: del role['defaults']['networks'] for inst in role.get('instances', []): _merge_instance_role_networks(inst, role) "," role['defaults'].setdefault('nics', default_network) for inst in role.get('instances', []):",195,5
openstack%2Ftripleo-ansible~master~Ie2874190c869abb8f9372acb6a45e93557090b2c,openstack/tripleo-ansible,master,Ie2874190c869abb8f9372acb6a45e93557090b2c,Network ports module,MERGED,2020-11-09 12:20:47.000000000,2021-01-04 19:51:40.000000000,2021-01-04 19:49:11.000000000,"[{'_account_id': 4571}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-11-09 12:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ca20d77c1b17c8a2560569c60c228eb080b054a1', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 netwprks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 2, 'created': '2020-11-10 15:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/58f90888f71a18f8a44f7a7f26002cb9a9add2c0', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 3, 'created': '2020-11-23 15:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8ad6086cdd4b099fb642dbebcf1950a7b91c8f2b', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 4, 'created': '2020-11-30 11:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/22535f32261af828a08b4b5f86257b7f5eb9701a', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 5, 'created': '2020-11-30 17:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2940393f31fdee0acf0b6353d670d217f9099bb0', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 6, 'created': '2020-12-01 12:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/535ba4e998d8c0cd2313142251d2a40d8213e1f5', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 7, 'created': '2020-12-04 14:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2e5ad2c02b164c0ec2f655726dc72efdd43c11ac', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 8, 'created': '2020-12-04 18:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6c4d2dff4e3bee62243dcbb03dc96181d6f02d55', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 9, 'created': '2020-12-04 19:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/90cdc7ec2f2bd2dbdf550c84636d83aaf4dc3142', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Two\ntags will be added to each port resource created, one\nwith a stack_name hint and the other with the hostname.\nThe tags is used to filter instance for already existing\ninstance ports on re-run.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nPerformance stats: 100 nodes x 3 networks = 300 ports\n\n        4xCPU 1.8 GHz (8GB)             8x CPU 2.6 GHz (12GB)\n        -------------------  --------------------------------\nConcurr:                 10          20         10          4\n........     ..............   .........  .........  .........\nCreate       real 5m58.006s   1m48.518s  1m51.998s  1m25.022s\nDelete:      real 4m12.812s   0m47.475s  0m48.956s  1m19.543s\nRe-run:      real 0m19.386s    0m4.389s   0m4.453s   0m4.977s\n\nNOTE: On slow system concurrency ~15 resulted in 504 Gateway\n      timeout. On the faster ~30 caused 504 GW timeout.\n      It's also not neccecarily better to use a high number,\n      but using concurrency = 1 is way slower.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 10, 'created': '2020-12-07 17:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c73cc368ec723a886d40db4e73d967749a042cd2', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Tags\nwill be added to each port resource created, one\nwith a stack_name hint and the other with the hostname\nand a third with the ironic node uuid. Tags are also added\nto metalsmith managed vif ports.\n\nThe tags is used to filter for already existing instance\nports on re-run, i.e idempotency. The tags will also be\nused by tripleo-ansible-inventory to create an ansible\ninventory prior to having a stack created.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 11, 'created': '2020-12-18 05:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d0d176c266359222dbd8768fb54427ae7df351b8', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Tags\nwill be added to each port resource created, one\nwith a stack_name hint and the other with the hostname\nand a third with the ironic node uuid. Tags are also added\nto metalsmith managed vif ports.\n\nThe tags is used to filter for already existing instance\nports on re-run, i.e idempotency. The tags will also be\nused by tripleo-ansible-inventory to create an ansible\ninventory prior to having a stack created.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}, {'number': 12, 'created': '2020-12-18 06:47:44.000000000', 'files': ['doc/source/modules/modules_tripleo_overcloud_network_ports.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_network_ports.py', 'tripleo_ansible/tests/modules/test_tripleo_overcloud_network_ports.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c94945ae6bff3c3f50620c6c6ba5fae8041a7f5e', 'message': ""Network ports module\n\nAnsible module to manage network ports for overcloud\nnodes. The main module option 'instances' takes a list\nof instances similar to the one created by the\ntripleo_baremetal_expand_roles module.\n\nAdditionally the 'stack_name' must be specified. Tags\nwill be added to each port resource created, one\nwith a stack_name hint and the other with the hostname\nand a third with the ironic node uuid. Tags are also added\nto metalsmith managed vif ports.\n\nThe tags is used to filter for already existing instance\nports on re-run, i.e idempotency. The tags will also be\nused by tripleo-ansible-inventory to create an ansible\ninventory prior to having a stack created.\n\nOn re-run existing ports will be updated, if the definition\nchanged.\n\nThe parameter 'concurrency' controls the maximum threads\nto use for parallell processing.\n\nDepends-On: https://review.opendev.org/761845\nDepends-On: https://review.opendev.org/760536\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c\n""}]",14,761908,c94945ae6bff3c3f50620c6c6ba5fae8041a7f5e,73,9,12,24245,,,0,"Network ports module

Ansible module to manage network ports for overcloud
nodes. The main module option 'instances' takes a list
of instances similar to the one created by the
tripleo_baremetal_expand_roles module.

Additionally the 'stack_name' must be specified. Tags
will be added to each port resource created, one
with a stack_name hint and the other with the hostname
and a third with the ironic node uuid. Tags are also added
to metalsmith managed vif ports.

The tags is used to filter for already existing instance
ports on re-run, i.e idempotency. The tags will also be
used by tripleo-ansible-inventory to create an ansible
inventory prior to having a stack created.

On re-run existing ports will be updated, if the definition
changed.

The parameter 'concurrency' controls the maximum threads
to use for parallell processing.

Depends-On: https://review.opendev.org/761845
Depends-On: https://review.opendev.org/760536
Partial-Implements: blueprint network-data-v2-ports
Change-Id: Ie2874190c869abb8f9372acb6a45e93557090b2c
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/08/761908/8 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_network_ports.py', 'tripleo_ansible/tests/modules/test_overcloud_network_ports.py']",2,ca20d77c1b17c8a2560569c60c228eb080b054a1,nework-data-v2,"# Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import openstack from tripleo_ansible.ansible_plugins.modules import ( tripleo_overcloud_network_ports as plugin) from tripleo_ansible.tests import base as tests_base from tripleo_ansible.tests import stubs FAKE_INSTANCE = { 'hostname': 'instance0', 'networks': [ {'network': 'foo', 'subnet': 'foo_subnet'}, {'network': 'bar', 'subnet': 'bar_subnet'}, ], 'state': 'present' } FAKE_NET_NAME_MAP = { 'foo': { 'id': 'foo_id', 'subnets_map': { 'foo_subnet': 'foo_subnet_id', } }, 'bar': { 'id': 'bar_id', 'subnets_map': { 'bar_subnet': 'bar_subnet_id', } }, } class TestTripleoOvercloudNetworkPorts(tests_base.TestCase): def setUp(self): super(TestTripleoOvercloudNetworkPorts, self).setUp() # Helper function to convert array to generator self.a2g = lambda x: (n for n in x) @mock.patch.object(openstack.connection, 'Connection', autospec=True) def test_create_name_id_maps(self, conn_mock): subnet1 = stubs.FakeNeutronSubnet(id='subnet1_id', name='subnet1') subnet2 = stubs.FakeNeutronSubnet(id='subnet2_id', name='subnet2') network1 = stubs.FakeNeutronNetwork( id='network1_id', name='network1', subnet_ids=['subnet1_id', 'subnet2_id'] ) conn_mock.network.networks.return_value = self.a2g([network1]) conn_mock.network.subnets.return_value = self.a2g([subnet1, subnet2]) net_name_map, net_id_map = plugin.create_name_id_maps(conn_mock) expected_net_name_map = { 'network1': { 'id': 'network1_id', 'subnets_map': { 'subnet1': 'subnet1_id', 'subnet2': 'subnet2_id' } } } expected_net_id_map = { 'network1_id': { 'name': 'network1', 'subnets_map': { 'subnet1_id': 'subnet1', 'subnet2_id': 'subnet2' } } } self.assertEqual(expected_net_name_map, net_name_map) self.assertEqual(expected_net_id_map, net_id_map) @mock.patch.object(openstack.connection, 'Connection', autospec=True) def test_delete_ports(self, mock_conn): port1 = stubs.FakeNeutronPort(id='port1_id') port2 = stubs.FakeNeutronPort(id='port2_id') plugin.delete_ports(mock_conn, [port1, port2]) mock_conn.network.delete_port.assert_has_calls([mock.call('port1_id'), mock.call('port2_id')]) @mock.patch.object(openstack.connection, 'Connection', autospec=True) def test_find_pre_provisioned_ports(self, mock_conn): instance_ports = [] FAKE_INSTANCE['networks'] = [{'network': 'foo', 'port': 'some_port'}] some_port = stubs.FakeNeutronPort(name='some_port', id='some_port_id') mock_conn.network.find_port.return_value = some_port plugin.find_pre_provisioned_ports(mock_conn, FAKE_NET_NAME_MAP, FAKE_INSTANCE, instance_ports) mock_conn.network.find_port.assert_called_with( 'some_port', network_id=FAKE_NET_NAME_MAP['foo']['id']) self.assertEqual([some_port], instance_ports) def test_fixed_ips_need_update(self): fake_port = stubs.FakeNeutronPort( fixed_ips=[{'ip_address': '192.168.24.24', 'subnet_id': 'foo_id'}]) port_def = {'fixed_ips': [{'ip_address': '192.168.24.24'}]} self.assertFalse(plugin.fixed_ips_need_update(port_def, fake_port)) port_def = {'fixed_ips': [{'subnet_id': 'foo_id'}]} self.assertFalse(plugin.fixed_ips_need_update(port_def, fake_port)) port_def = {'fixed_ips': [{'subnet_id': 'bar_id'}]} self.assertTrue(plugin.fixed_ips_need_update(port_def, fake_port)) port_def = {'fixed_ips': [{'subnet_id': 'foo_id'}, {'ip_address': '192.168.25.24'}]} self.assertTrue(plugin.fixed_ips_need_update(port_def, fake_port)) @mock.patch.object(plugin, 'fixed_ips_need_update', autospec=True) def test_port_need_update(self, mock_fixed_ips_need_update): port_def = {'name': 'foo', 'network_id': 'foo_id', 'fixed_ips': []} mock_fixed_ips_need_update.return_value = True self.assertEqual({'fixed_ips': []}, plugin.port_need_update(port_def, mock.ANY)) mock_fixed_ips_need_update.return_value = False self.assertEqual({}, plugin.port_need_update(port_def, mock.ANY)) def test_update_instance_ports(self): pass @mock.patch.object(openstack.connection, 'Connection', autospec=True) def test_create_instance_ports(self, mock_conn): instance_ports = [] port_foo = stubs.FakeNeutronPort( name='instance_foo', network_id='foo_id', fixed_ips=[{'subnet_id': 'foo_subnet_id'}]) port_bar = stubs.FakeNeutronPort( name='instance_bar', network_id='bar_id', fixed_ips=[{'subnet_id': 'bar_subnet_id'}]) mock_conn.network.create_ports.return_value = self.a2g( [port_foo, port_bar]) plugin.create_instance_ports(mock_conn, 'overcloud', FAKE_NET_NAME_MAP, FAKE_INSTANCE, instance_ports) mock_conn.network.create_ports.assert_has_calls([ mock.call([ {'name': 'instance0_foo', 'network_id': 'foo_id', 'fixed_ips': [{'subnet_id': 'foo_subnet_id'}]}, {'name': 'instance0_bar', 'network_id': 'bar_id', 'fixed_ips': [{'subnet_id': 'bar_subnet_id'}]} ]) ]) mock_conn.network.set_tags.assert_has_calls([ mock.call(port_foo, ['hostname=instance0', 'stack_name=overcloud']), mock.call(port_bar, ['hostname=instance0', 'stack_name=overcloud']) ]) self.assertEqual([port_foo, port_bar], instance_ports) @mock.patch.object(plugin, 'create_instance_ports', autospec=True) @mock.patch.object(plugin, 'find_pre_provisioned_ports', autospec=True) @mock.patch.object(openstack.connection, 'Connection', autospec=True) def test__provision_instance_ports(self, mock_conn, mock_pre_provisioned, mock_create_instance_ports): changed = False mock_conn.network.ports.return_value = self.a2g([]) mock_pre_provisioned.return_value = None mock_create_instance_ports.return_value = True changed, instance_port_map = plugin._provision_instance_ports( mock_conn, 'overcloud', FAKE_INSTANCE, FAKE_NET_NAME_MAP, {}, changed) mock_pre_provisioned.assert_called_with( mock_conn, FAKE_NET_NAME_MAP, FAKE_INSTANCE, mock.ANY) mock_create_instance_ports.assert_called_with( mock_conn, 'overcloud', FAKE_NET_NAME_MAP, FAKE_INSTANCE, mock.ANY) self.assertTrue(changed) ",,580,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a,openstack/tripleo-heat-templates,stable/ussuri,I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a,Ensure cinder LVM volumes work after system restart,MERGED,2020-12-22 05:52:33.000000000,2021-01-04 19:42:08.000000000,2021-01-04 19:42:08.000000000,"[{'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-22 05:52:33.000000000', 'files': ['deployment/iscsid/iscsid-container-puppet.yaml', 'deployment/cinder/cinder-common-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/833e812bafd8e34919e301537ca655826e393e74', 'message': ""Ensure cinder LVM volumes work after system restart\n\nUpdate the cinder-lvm-losetup systemd service to wait until the local\n/var directory is mounted and the lvm2-monitor service has started\nprior to creating the loopback device used by cinder's LVM backend.\n\nMake LIO SCSI target data persistent by adding container volume mounts\nfor the /etc/target directory so that the data is stored on the host.\n\nCloses-Bug: #1905617\nChange-Id: I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a\n(cherry picked from commit 63b2a989ba4a79c204c6d2a4b1512e3a924ec434)\n(cherry picked from commit 27678af1ab36ac531b8dd694ca92a461df43ec7b)\n""}]",0,768143,833e812bafd8e34919e301537ca655826e393e74,18,5,1,21129,,,0,"Ensure cinder LVM volumes work after system restart

Update the cinder-lvm-losetup systemd service to wait until the local
/var directory is mounted and the lvm2-monitor service has started
prior to creating the loopback device used by cinder's LVM backend.

Make LIO SCSI target data persistent by adding container volume mounts
for the /etc/target directory so that the data is stored on the host.

Closes-Bug: #1905617
Change-Id: I0c0cbed3a41e8d4b1fbaf5c2dc7fd0412fee644a
(cherry picked from commit 63b2a989ba4a79c204c6d2a4b1512e3a924ec434)
(cherry picked from commit 27678af1ab36ac531b8dd694ca92a461df43ec7b)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/768143/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/iscsid/iscsid-container-puppet.yaml', 'deployment/cinder/cinder-common-container-puppet.yaml']",2,833e812bafd8e34919e301537ca655826e393e74,bug/1905617," cinder_iscsi_backend_enabled: {equals: [{get_param: CinderEnableIscsiBackend}, true]} cinder_enable_iscsi_backend: {if: [cinder_iscsi_backend_enabled, true, false]} Requires=lvm2-monitor.service systemd-udev-settle.service After=var.mount lvm2-monitor.service systemd-udev-settle.service - cinder_iscsi_backend_enabled - - /etc/target:/etc/target:z - [] - if:", cinder_enable_iscsi_backend: {get_param: CinderEnableIscsiBackend} Requires=lvm2-lvmetad.service systemd-udev-settle.service After=lvm2-lvmetad.service systemd-udev-settle.service,17,11
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I88ae631c299f408bdedcb80bd5c04e36fda5a2e1,openstack/tripleo-heat-templates,stable/train,I88ae631c299f408bdedcb80bd5c04e36fda5a2e1,Add file which enables QoS related L3 agent extensions,MERGED,2020-11-25 11:17:26.000000000,2021-01-04 19:41:53.000000000,2021-01-04 19:41:53.000000000,"[{'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-11-25 11:17:26.000000000', 'files': ['ci/environments/neutron_l3_qos.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1747a99765af6f2a7684e27b778a7ea05c776b6f', 'message': 'Add file which enables QoS related L3 agent extensions\n\nIt enables extensions like fip_qos and gateway_ip_qos in the\nL3 agent.\n\nRelated-Bug: #1900357\n\nChange-Id: I88ae631c299f408bdedcb80bd5c04e36fda5a2e1\n(cherry picked from commit d910b9486e31bc50d72d671c3c078585e689efd0)\n'}]",0,764092,1747a99765af6f2a7684e27b778a7ea05c776b6f,31,5,1,11975,,,0,"Add file which enables QoS related L3 agent extensions

It enables extensions like fip_qos and gateway_ip_qos in the
L3 agent.

Related-Bug: #1900357

Change-Id: I88ae631c299f408bdedcb80bd5c04e36fda5a2e1
(cherry picked from commit d910b9486e31bc50d72d671c3c078585e689efd0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/92/764092/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/neutron_l3_qos.yaml'],1,1747a99765af6f2a7684e27b778a7ea05c776b6f,bug/1900357-stable/victoria-stable/ussuri-stable/train,"parameter_defaults: NeutronL3AgentExtensions: 'fip_qos,gateway_ip_qos,port_forwarding' ",,2,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I021a2aa173f58e0e7cb37022b73ef17782033f70,openstack/tripleo-heat-templates,stable/train,I021a2aa173f58e0e7cb37022b73ef17782033f70,Move ipa check to external_deploy_tasks,MERGED,2020-12-16 22:35:41.000000000,2021-01-04 19:41:44.000000000,2021-01-04 19:41:44.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-16 22:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87c6d602c12e15b1abeea8a588554f379d9b569e', 'message': ""Move ipa check to external_deploy_tasks\n\nThe ipa dns acl validation needs to occur on the undercloud\nrather than on the node, because in a new environment, the node\nis not yet set up as an ipa client.  That only happens in the\ndeploy_steps tasks.\n\nI also removed the validation tags so that this check could be\ndone even if validations are not requested.  The check itself\nis not expensive, and troubleshooting the issue we're trying to\nprevent is somewhat tricky.  Much better to fail fast.\n\nChange-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70\n(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)\n""}, {'number': 2, 'created': '2020-12-16 22:47:54.000000000', 'files': ['deployment/etcd/etcd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a44e4ad930b82630a725562e6d5193204da2c6f', 'message': ""Move ipa check to external_deploy_tasks\n\nThe ipa dns acl validation needs to occur on the undercloud\nrather than on the node, because in a new environment, the node\nis not yet set up as an ipa client.  That only happens in the\ndeploy_steps tasks.\n\nI also removed the validation tags so that this check could be\ndone even if validations are not requested.  The check itself\nis not expensive, and troubleshooting the issue we're trying to\nprevent is somewhat tricky.  Much better to fail fast.\n\nChange-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70\n(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)\n""}]",0,767329,5a44e4ad930b82630a725562e6d5193204da2c6f,16,4,2,9914,,,0,"Move ipa check to external_deploy_tasks

The ipa dns acl validation needs to occur on the undercloud
rather than on the node, because in a new environment, the node
is not yet set up as an ipa client.  That only happens in the
deploy_steps tasks.

I also removed the validation tags so that this check could be
done even if validations are not requested.  The check itself
is not expensive, and troubleshooting the issue we're trying to
prevent is somewhat tricky.  Much better to fail fast.

Change-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70
(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/29/767329/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/etcd/etcd-container-puppet.yaml'],1,87c6d602c12e15b1abeea8a588554f379d9b569e,fix-ipa-dns-validations-stable/train," - name: create /var/lib/etcd file: path: /var/lib/etcd state: directory setype: container_file_t external_deploy_tasks: if: - internal_tls_enabled<<<<<<< HEAD (d9c57f Merge ""Relax facts gathering plays on the overcloud"" into st)======= - name: check if ipa server has required permissions when: step|int == 1 import_role: name: tls_everywhere tasks_from: ipa-server-check - null >>>>>>> CHANGE (8ffad6 Move ipa check to external_deploy_tasks)", list_concat:,17,1
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I021a2aa173f58e0e7cb37022b73ef17782033f70,openstack/tripleo-heat-templates,stable/ussuri,I021a2aa173f58e0e7cb37022b73ef17782033f70,Move ipa check to external_deploy_tasks,MERGED,2020-12-16 22:34:39.000000000,2021-01-04 19:41:38.000000000,2021-01-04 19:41:38.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-16 22:34:39.000000000', 'files': ['deployment/etcd/etcd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8ffad6e84c99d7b7a41f9d4c22c0da8e18af71ed', 'message': ""Move ipa check to external_deploy_tasks\n\nThe ipa dns acl validation needs to occur on the undercloud\nrather than on the node, because in a new environment, the node\nis not yet set up as an ipa client.  That only happens in the\ndeploy_steps tasks.\n\nI also removed the validation tags so that this check could be\ndone even if validations are not requested.  The check itself\nis not expensive, and troubleshooting the issue we're trying to\nprevent is somewhat tricky.  Much better to fail fast.\n\nChange-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70\n(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)\n""}]",0,767328,8ffad6e84c99d7b7a41f9d4c22c0da8e18af71ed,10,3,1,9914,,,0,"Move ipa check to external_deploy_tasks

The ipa dns acl validation needs to occur on the undercloud
rather than on the node, because in a new environment, the node
is not yet set up as an ipa client.  That only happens in the
deploy_steps tasks.

I also removed the validation tags so that this check could be
done even if validations are not requested.  The check itself
is not expensive, and troubleshooting the issue we're trying to
prevent is somewhat tricky.  Much better to fail fast.

Change-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70
(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/28/767328/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/etcd/etcd-container-puppet.yaml'],1,8ffad6e84c99d7b7a41f9d4c22c0da8e18af71ed,fix-ipa-dns-validation-stable/victoria-stable/ussuri, - name: create /var/lib/etcd file: path: /var/lib/etcd state: directory setype: container_file_t external_deploy_tasks: if: - internal_tls_enabled - name: check if ipa server has required permissions when: step|int == 1 import_role: name: tls_everywhere tasks_from: ipa-server-check - null, list_concat: - name: create /var/lib/etcd file: path: /var/lib/etcd state: directory setype: container_file_t - if: - internal_tls_enabled - - name: check if ipa server has required permissions import_role: name: tls_everywhere tasks_from: ipa-server-check tags: - opendev-validation - opendev-validation-tls-everywhere - null,14,18
openstack%2Fpython-openstackclient~master~Ic3035b49da10b6555066eee607a14a5b73797c00,openstack/python-openstackclient,master,Ic3035b49da10b6555066eee607a14a5b73797c00,Add support '--progress' option for 'image create',MERGED,2020-09-06 21:45:56.000000000,2021-01-04 19:41:34.000000000,2021-01-04 19:40:10.000000000,"[{'_account_id': 2}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 32307}]","[{'number': 1, 'created': '2020-09-06 21:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bed0176da06e69f3edabee65b360cd929563d932', 'message': ""Add support '--progress' option for 'image create'\n\nopenstack-client doesnt support the upload progress bar.\n\nThis patch shows progressbar when create image\nif you added '--progress' option like a python-glanceclient.\n\nlike this.\n[=============================>] 100%\n+------------------+---------------------------+\n| Field            | Value                     |\n+------------------+---------------------------+\n| container_format | bare                      |\n| created_at       | 2020-09-06T20:44:40Z      |\n...\n\nHow to use\nAdd the'--progress' option on the 'openstack image create' command.\n\nCode was written by referring to 'python-glanceclient' project\non stable/ussuri branch\n\nChange-Id: Ic3035b49da10b6555066eee607a14a5b73797c00\ntask: 40003\nstory: 2007777\n""}, {'number': 2, 'created': '2020-12-25 10:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/67f9ce28732733175615a3b5be663d599c7b70b4', 'message': ""Add support '--progress' option for 'image create'\n\nopenstack-client doesnt support the upload progress bar.\n\nThis patch shows progressbar when create image\nif you added '--progress' option like a python-glanceclient.\n\nlike this.\n[=============================>] 100%\n+------------------+---------------------------+\n| Field            | Value                     |\n+------------------+---------------------------+\n| container_format | bare                      |\n| created_at       | 2020-09-06T20:44:40Z      |\n...\n\nHow to use\nAdd the'--progress' option on the 'openstack image create' command.\n\nCode was written by referring to 'python-glanceclient' project\non stable/ussuri branch\n\nChange-Id: Ic3035b49da10b6555066eee607a14a5b73797c00\ntask: 40003\nstory: 2007777\n""}, {'number': 3, 'created': '2021-01-04 17:25:39.000000000', 'files': ['openstackclient/tests/unit/common/test_progressbar.py', 'openstackclient/common/progressbar.py', 'releasenotes/notes/add-image-progress-option-to-create-1ed1881d58ebad4b.yaml', 'openstackclient/image/v2/image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6f616a29b300238c004b676edd98a5337be38193', 'message': ""Add support '--progress' option for 'image create'\n\nopenstack-client doesnt support the upload progress bar.\n\nThis patch shows progressbar when create image\nif you added '--progress' option like a python-glanceclient.\n\nlike this.\n[=============================>] 100%\n+------------------+---------------------------+\n| Field            | Value                     |\n+------------------+---------------------------+\n| container_format | bare                      |\n| created_at       | 2020-09-06T20:44:40Z      |\n...\n\nHow to use\nAdd the'--progress' option on the 'openstack image create' command.\n\nCode was written by referring to 'python-glanceclient' project\non stable/ussuri branch\n\nChange-Id: Ic3035b49da10b6555066eee607a14a5b73797c00\ntask: 40003\nstory: 2007777\n""}]",1,750111,6f616a29b300238c004b676edd98a5337be38193,16,4,3,32307,,,0,"Add support '--progress' option for 'image create'

openstack-client doesnt support the upload progress bar.

This patch shows progressbar when create image
if you added '--progress' option like a python-glanceclient.

like this.
[=============================>] 100%
+------------------+---------------------------+
| Field            | Value                     |
+------------------+---------------------------+
| container_format | bare                      |
| created_at       | 2020-09-06T20:44:40Z      |
...

How to use
Add the'--progress' option on the 'openstack image create' command.

Code was written by referring to 'python-glanceclient' project
on stable/ussuri branch

Change-Id: Ic3035b49da10b6555066eee607a14a5b73797c00
task: 40003
story: 2007777
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/11/750111/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/common/test_progressbar.py', 'openstackclient/common/progressbar.py', 'openstackclient/image/v2/image.py']",3,bed0176da06e69f3edabee65b360cd929563d932,,"from openstackclient.common import progressbar ""--progress"", action=""store_true"", default=False, help=_(""Show upload progress bar.""), ) parser.add_argument( if fp is not None and parsed_args.progress: filesize = os.path.getsize(fname) if filesize is not None: kwargs['validate_checksum'] = False kwargs['data'] = progressbar.VerboseFileWrapper(fp, filesize)",,156,0
openstack%2Fvitrage-tempest-plugin~master~I3320623bce9a3351cac91d5b4c1d30fbb999e5b1,openstack/vitrage-tempest-plugin,master,I3320623bce9a3351cac91d5b4c1d30fbb999e5b1,add requirements to doc,MERGED,2021-01-04 15:51:38.000000000,2021-01-04 19:14:52.000000000,2021-01-04 19:13:32.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 15:51:38.000000000', 'files': ['doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/1583bdaf7bd9193e19663b0f6ffd0225fdab7986', 'message': 'add requirements to doc\n\nChange-Id: I3320623bce9a3351cac91d5b4c1d30fbb999e5b1\n'}]",0,769158,1583bdaf7bd9193e19663b0f6ffd0225fdab7986,9,2,1,19134,,,0,"add requirements to doc

Change-Id: I3320623bce9a3351cac91d5b4c1d30fbb999e5b1
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/58/769158/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/requirements.txt', 'tox.ini']",2,1583bdaf7bd9193e19663b0f6ffd0225fdab7986,doc,deps = -r{toxinidir}/doc/requirements.txt whitelist_externals = rm commands = rm -fr doc/build sphinx-build -E -W --keep-going -b html doc/source doc/build/htmlwhitelist_externals = rm rm -rf releasenotes/build sphinx-build -a -E -W -d releasenotes/build/doctrees --keep-going -b html releasenotes/source releasenotes/build/html,commands = sphinx-build -W -b html doc/source doc/build/html sphinx-build -a -E -W -d releasenotes/build/doctrees -b html releasenotes/source releasenotes/build/html,15,2
openstack%2Fopenstack-tempest-skiplist~master~Ie36878fb75b27dbcfe75b58bdab8e3edf94d1382,openstack/openstack-tempest-skiplist,master,Ie36878fb75b27dbcfe75b58bdab8e3edf94d1382,add puppet-neutron-tripleo-standalone to skip for 1909008,MERGED,2021-01-04 18:07:23.000000000,2021-01-04 18:58:11.000000000,2021-01-04 18:56:50.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 18:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/63342834d9ea589c0bc1f325c84c6ad493c25026', 'message': 'add puppet-neutron-tripleo-standalone to skip for 1909008\n\nRelated-Bug: #1909008\nChange-Id: Ie36878fb75b27dbcfe75b58bdab8e3edf94d1382\n'}, {'number': 2, 'created': '2021-01-04 18:41:24.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/d318c8506c953192b6757d8a370c034e04cd72a2', 'message': 'add puppet-neutron-tripleo-standalone to skip for 1909008\n\nRelated-Bug: #1909008\nChange-Id: Ie36878fb75b27dbcfe75b58bdab8e3edf94d1382\n'}]",0,769199,d318c8506c953192b6757d8a370c034e04cd72a2,11,4,2,9592,,,0,"add puppet-neutron-tripleo-standalone to skip for 1909008

Related-Bug: #1909008
Change-Id: Ie36878fb75b27dbcfe75b58bdab8e3edf94d1382
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/99/769199/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,63342834d9ea589c0bc1f325c84c6ad493c25026,, - puppet-neutron-tripleo-standalone - test: 'neutron_tempest_plugin.api.test_revisions.TestRevisions.',,2,0
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I021a2aa173f58e0e7cb37022b73ef17782033f70,openstack/tripleo-heat-templates,stable/victoria,I021a2aa173f58e0e7cb37022b73ef17782033f70,Move ipa check to external_deploy_tasks,MERGED,2020-12-16 22:34:08.000000000,2021-01-04 18:38:40.000000000,2021-01-04 18:38:40.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-16 22:34:08.000000000', 'files': ['deployment/etcd/etcd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe170a31604e5a54be48290372e1dc041e04f996', 'message': ""Move ipa check to external_deploy_tasks\n\nThe ipa dns acl validation needs to occur on the undercloud\nrather than on the node, because in a new environment, the node\nis not yet set up as an ipa client.  That only happens in the\ndeploy_steps tasks.\n\nI also removed the validation tags so that this check could be\ndone even if validations are not requested.  The check itself\nis not expensive, and troubleshooting the issue we're trying to\nprevent is somewhat tricky.  Much better to fail fast.\n\nChange-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70\n(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)\n""}]",0,767327,fe170a31604e5a54be48290372e1dc041e04f996,10,3,1,9914,,,0,"Move ipa check to external_deploy_tasks

The ipa dns acl validation needs to occur on the undercloud
rather than on the node, because in a new environment, the node
is not yet set up as an ipa client.  That only happens in the
deploy_steps tasks.

I also removed the validation tags so that this check could be
done even if validations are not requested.  The check itself
is not expensive, and troubleshooting the issue we're trying to
prevent is somewhat tricky.  Much better to fail fast.

Change-Id: I021a2aa173f58e0e7cb37022b73ef17782033f70
(cherry picked from commit 81087b49c2dfe3020e5b0ba5e2def9f0b8f9d6aa)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/27/767327/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/etcd/etcd-container-puppet.yaml'],1,fe170a31604e5a54be48290372e1dc041e04f996,fix-ipa-dns-validation-stable/victoria, - name: create /var/lib/etcd file: path: /var/lib/etcd state: directory setype: container_file_t external_deploy_tasks: if: - internal_tls_enabled - name: check if ipa server has required permissions when: step|int == 1 import_role: name: tls_everywhere tasks_from: ipa-server-check - null, list_concat: - name: create /var/lib/etcd file: path: /var/lib/etcd state: directory setype: container_file_t - if: - internal_tls_enabled - - name: check if ipa server has required permissions import_role: name: tls_everywhere tasks_from: ipa-server-check tags: - opendev-validation - opendev-validation-tls-everywhere - null,14,18
openstack%2Fopenstack-ansible-os_ceilometer~master~Ied8a54d3837c4447d612457eebb4fd7a8b9d342d,openstack/openstack-ansible-os_ceilometer,master,Ied8a54d3837c4447d612457eebb4fd7a8b9d342d,Remove centos-7 conditional configuration,MERGED,2020-12-08 09:57:54.000000000,2021-01-04 18:36:21.000000000,2021-01-04 18:35:06.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-08 09:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/f2198e7a1a18e0c7a8f290bc3b7cafb42812b5d3', 'message': ""Remove centos-7 conditional configuration\n\nWe don't support centos-7 for Victoria so remove conditional code.\n\nChange-Id: Ied8a54d3837c4447d612457eebb4fd7a8b9d342d\n""}, {'number': 2, 'created': '2020-12-14 16:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/536b14d5a35ce7bde95ec65fbae406fd6ee06866', 'message': ""Remove centos-7 conditional configuration\n\nWe don't support centos-7 for Victoria so remove conditional code.\n\nChange-Id: Ied8a54d3837c4447d612457eebb4fd7a8b9d342d\n""}, {'number': 3, 'created': '2021-01-04 14:04:39.000000000', 'files': ['vars/source_install.yml', 'vars/distro_install.yml', 'vars/redhat-7.yml', 'vars/redhat.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/434c24955283fb9cce2835a423f0fb78549fbe24', 'message': ""Remove centos-7 conditional configuration\n\nWe don't support centos-7 for Victoria so remove conditional code.\n\nChange-Id: Ied8a54d3837c4447d612457eebb4fd7a8b9d342d\n""}]",0,765956,434c24955283fb9cce2835a423f0fb78549fbe24,24,3,3,25023,,,0,"Remove centos-7 conditional configuration

We don't support centos-7 for Victoria so remove conditional code.

Change-Id: Ied8a54d3837c4447d612457eebb4fd7a8b9d342d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/56/765956/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/source_install.yml', 'vars/distro_install.yml', 'vars/redhat-8.yml', 'vars/redhat.yml', 'defaults/main.yml']",5,f2198e7a1a18e0c7a8f290bc3b7cafb42812b5d3,,"ceilometer_venv_python_executable: ""{{ openstack_venv_python_executable | default('python3') }}""","ceilometer_venv_python_executable: ""{{ _ceilometer_venv_python_executable }}""",1,45
openstack%2Fironic~master~If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb,openstack/ironic,master,If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb,Add troubleshooting on changing ironic.conf default interfaces,MERGED,2021-01-04 17:02:47.000000000,2021-01-04 18:23:22.000000000,2021-01-04 18:21:53.000000000,"[{'_account_id': 11292}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 17:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/67b70a1d617510536054616f416b971a7ca91a1f', 'message': 'Add troubleshooting on changing ironic.conf default interfaces\n\nChange-Id: If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb\n'}, {'number': 2, 'created': '2021-01-04 17:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fc9c44a9f91d320040facf92fbb3f114ccd8e9ef', 'message': 'Add troubleshooting on changing ironic.conf default interfaces\n\nChange-Id: If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb\n'}, {'number': 3, 'created': '2021-01-04 17:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d20690b516bee1e7ec74ea041734567c6953407f', 'message': 'Add troubleshooting on changing ironic.conf default interfaces\n\nChange-Id: If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb\n'}, {'number': 4, 'created': '2021-01-04 17:40:47.000000000', 'files': ['doc/source/admin/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1e96ecbdbc186df81dcd2474651c2e02fedb31b7', 'message': 'Add troubleshooting on changing ironic.conf default interfaces\n\nChange-Id: If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb\n'}]",14,769167,1e96ecbdbc186df81dcd2474651c2e02fedb31b7,16,2,4,11655,,,0,"Add troubleshooting on changing ironic.conf default interfaces

Change-Id: If836d064ed7e8f6eaefbc0cfab8c404d2c3174fb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/67/769167/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/troubleshooting.rst'],1,67b70a1d617510536054616f416b971a7ca91a1f,," I changed ironic.conf, and now I can't edit my nodes. ===================================================== First, undo the changes you made to ``ironic.conf``. Ironic creats a driver ""task"" whenever a node update comes in. So if you do something like have ``default_network_interface=neturon`` or ``enabled_network_interfaces=neutron,flat`` in your ironic.conf, nodes would have been created with the ``neutron`` network interface. This is because ``default_network_interface`` overrides the setting for new nodes, and that setting is **saved** to the database nodes table. Simillarlly, the order of ``enabled_network_interfaces`` takes priority, and the first entry in the list is generally set to the default for the node upon creation, and that record is **saved** to the database nodes table. Example failure --------------- A node in this state, when the ``network_interface`` was saved as ``neutron``, yet the ``neutron`` interface is no longer enabled will fail basic state transition requests.: $ baremetal node manage 7164efca-37ab-1213-1112-b731cf795a5a Could not find the following interface in the 'ironic.hardware.interfaces.network' entrypoint: neutron. Valid interfaces are ['flat']. (HTTP 400) How to fix this? ---------------- As previously mentioned, revert your configuration change to ``ironic.conf``. This applies to any changes to any ``default_*_interface`` options or the order of interfaces in the for the ``enabled_*_interfaces`` options. Once the conductor has been restarted with the updated configuration, you should now be able to update the interface using the ``baremetal node set`` command. In this example we use the ``network_interface`` as this is most commonly where it is encountered.: $ baremetal node set $NAME_OR_UUID --network-interface flat .. note:: There are additional paths one can take to remedy this sort of issue, however we encourage operators to be mindful of operational consistency when making major configuration changes. Once you have updated the saved interfaces, you should be able to safely return the ``ironic.conf`` configuration change in changing what interfaces are enabled by the conductor.",,50,0
openstack%2Fpython-ironicclient~master~I73da9d013a54d3730a9edde33271cb1a1fca481a,openstack/python-ironicclient,master,I73da9d013a54d3730a9edde33271cb1a1fca481a,Add PyPi link to readme.rst,MERGED,2021-01-03 03:20:57.000000000,2021-01-04 18:11:21.000000000,2021-01-04 18:10:05.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-01-03 03:20:57.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/aba663fe6f7c94b122b8d059313d0d5fafb6e2d7', 'message': 'Add PyPi link to readme.rst\n\nChange-Id: I73da9d013a54d3730a9edde33271cb1a1fca481a\n'}]",0,768940,aba663fe6f7c94b122b8d059313d0d5fafb6e2d7,8,3,1,27383,,,0,"Add PyPi link to readme.rst

Change-Id: I73da9d013a54d3730a9edde33271cb1a1fca481a
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/40/768940/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,aba663fe6f7c94b122b8d059313d0d5fafb6e2d7,update_readme,* PyPi: https://pypi.org/project/python-ironicclient,,1,0
openstack%2Fneutron~master~I1da01181c241d5edab6ad9efd03c42d3ac6f11fa,openstack/neutron,master,I1da01181c241d5edab6ad9efd03c42d3ac6f11fa,Implement secure RBAC for the segment API,MERGED,2020-12-03 23:04:21.000000000,2021-01-04 18:08:06.000000000,2021-01-04 18:06:25.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-03 23:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efefd73d4228c27b40b07bbe68e504a8e9378503', 'message': 'Implement secure RBAC for the segment API\n\nThis commit updates the segment policies to understand scope checking and\naccount for a read-only role. This is part of a broader series of changes\nacross OpenStack to provide a consistent RBAC experience and improve security.\n\nChange-Id: I1da01181c241d5edab6ad9efd03c42d3ac6f11fa\n'}, {'number': 2, 'created': '2020-12-08 09:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8fe0e3cba8645720e334902ea924d2b95b482db9', 'message': 'Implement secure RBAC for the segment API\n\nThis commit updates the segment policies to understand scope checking and\naccount for a read-only role. This is part of a broader series of changes\nacross OpenStack to provide a consistent RBAC experience and improve security.\n\nChange-Id: I1da01181c241d5edab6ad9efd03c42d3ac6f11fa\n'}, {'number': 3, 'created': '2020-12-15 16:14:40.000000000', 'files': ['neutron/conf/policies/segment.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bbd5d785d63375c40cc7d152fd42caf012294bbe', 'message': 'Implement secure RBAC for the segment API\n\nThis commit updates the segment policies to understand scope checking and\naccount for a read-only role. This is part of a broader series of changes\nacross OpenStack to provide a consistent RBAC experience and improve security.\n\nChange-Id: I1da01181c241d5edab6ad9efd03c42d3ac6f11fa\n'}]",0,765393,bbd5d785d63375c40cc7d152fd42caf012294bbe,23,3,3,5046,,,0,"Implement secure RBAC for the segment API

This commit updates the segment policies to understand scope checking and
account for a read-only role. This is part of a broader series of changes
across OpenStack to provide a consistent RBAC experience and improve security.

Change-Id: I1da01181c241d5edab6ad9efd03c42d3ac6f11fa
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/765393/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/conf/policies/segment.py'],1,efefd73d4228c27b40b07bbe68e504a8e9378503,secure-rbac,"from oslo_log import versionutilsDEPRECATED_REASON = """""" The segment API now supports system scope and default roles. """"""deprecated_create_segment = policy.DeprecatedRule( name='create_segment', check_str=base.RULE_ADMIN_ONLY ) deprecated_get_segment = policy.DeprecatedRule( name='get_segment', check_str=base.RULE_ADMIN_ONLY ) deprecated_update_segment = policy.DeprecatedRule( name='update_segment', check_str=base.RULE_ADMIN_ONLY ) deprecated_delete_segment = policy.DeprecatedRule( name='delete_segment', check_str=base.RULE_ADMIN_ONLY ) name='create_segment', check_str=base.SYSTEM_ADMIN, scope_types=['system'], description='Create a segment', operations=[ ], deprecated_rule=deprecated_create_segment, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='get_segment', check_str=base.SYSTEM_READER, scope_types=['system'], description='Get a segment', operations=[ ], deprecated_rule=deprecated_get_segment, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='update_segment', check_str=base.SYSTEM_ADMIN, scope_types=['system'], description='Update a segment', operations=[ ], deprecated_rule=deprecated_update_segment, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='delete_segment', check_str=base.SYSTEM_ADMIN, scope_types=['system'], description='Delete a segment', operations=[ ], deprecated_rule=deprecated_delete_segment, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY"," 'create_segment', base.RULE_ADMIN_ONLY, 'Create a segment', [ ] 'get_segment', base.RULE_ADMIN_ONLY, 'Get a segment', [ ] 'update_segment', base.RULE_ADMIN_ONLY, 'Update a segment', [ ] 'delete_segment', base.RULE_ADMIN_ONLY, 'Delete a segment', [ ]",57,20
openstack%2Frequirements~stable%2Fvictoria~I9653ace2ee56cba510bd0c2c3775fb75f1d0d8a8,openstack/requirements,stable/victoria,I9653ace2ee56cba510bd0c2c3775fb75f1d0d8a8,update constraint for os-net-config to new release 13.1.0,MERGED,2021-01-04 10:43:44.000000000,2021-01-04 18:06:35.000000000,2021-01-04 18:06:35.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-04 10:43:44.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9bbbd4f31d452ce323e8505b972cdc88569770db', 'message': 'update constraint for os-net-config to new release 13.1.0\n\nmeta: version: 13.1.0\nmeta: diff-start: -\nmeta: series: victoria\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Marios Andreou <marios@redhat.com>\nmeta: release:Commit: Marios Andreou <marios@redhat.com>\nmeta: release:Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1\nmeta: release:Code-Review+1: yatin <ykarel@redhat.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+1: chandan kumar <chkumar@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I9653ace2ee56cba510bd0c2c3775fb75f1d0d8a8\n'}]",0,769126,9bbbd4f31d452ce323e8505b972cdc88569770db,13,4,1,11131,,,0,"update constraint for os-net-config to new release 13.1.0

meta: version: 13.1.0
meta: diff-start: -
meta: series: victoria
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Marios Andreou <marios@redhat.com>
meta: release:Commit: Marios Andreou <marios@redhat.com>
meta: release:Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1
meta: release:Code-Review+1: yatin <ykarel@redhat.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+1: chandan kumar <chkumar@redhat.com>
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I9653ace2ee56cba510bd0c2c3775fb75f1d0d8a8
",git fetch https://review.opendev.org/openstack/requirements refs/changes/26/769126/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,9bbbd4f31d452ce323e8505b972cdc88569770db,new-release,os-net-config===13.1.0,os-net-config===13.0.0,1,1
openstack%2Fopenstack-ansible~master~I05512c5aa5dd32993405f91523e0e5f90a870b27,openstack/openstack-ansible,master,I05512c5aa5dd32993405f91523e0e5f90a870b27,Bump ansible version to 2.10.4,MERGED,2020-12-16 12:39:33.000000000,2021-01-04 18:05:50.000000000,2021-01-04 18:03:58.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-16 12:39:33.000000000', 'files': ['scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1d7e892b07ee7d0c3719e11c352f1bddef985309', 'message': 'Bump ansible version to 2.10.4\n\nChange-Id: I05512c5aa5dd32993405f91523e0e5f90a870b27\n'}]",0,767343,1d7e892b07ee7d0c3719e11c352f1bddef985309,17,4,1,25023,,,0,"Bump ansible version to 2.10.4

Change-Id: I05512c5aa5dd32993405f91523e0e5f90a870b27
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/43/767343/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/bootstrap-ansible.sh'],1,1d7e892b07ee7d0c3719e11c352f1bddef985309,,"export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible-base==2.10.4""}","export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible-base==2.10.3""}",1,1
openstack%2Fpuppet-swift~master~I88a136115ea454bc6e3dcb32dc72407799899c59,openstack/puppet-swift,master,I88a136115ea454bc6e3dcb32dc72407799899c59,Add missing s3api parameters,MERGED,2020-12-23 07:58:28.000000000,2021-01-04 17:52:09.000000000,2021-01-04 17:49:36.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-23 07:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/b6942e4f387a4f65aba326aa6c0515f11ec8a89f', 'message': 'WIP: Add missing s3api parameters\n\nChange-Id: I88a136115ea454bc6e3dcb32dc72407799899c59\n'}, {'number': 2, 'created': '2020-12-23 09:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/a00c58dac2cf940d43db9dfe09f7093af45e996c', 'message': 'WIP: Add missing s3api parameters\n\nChange-Id: I88a136115ea454bc6e3dcb32dc72407799899c59\n'}, {'number': 3, 'created': '2020-12-23 12:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/bfcba7b3aad34a2dd4e7fafa3a8abd651470ca9f', 'message': 'WIP: Add missing s3api parameters\n\nChange-Id: I88a136115ea454bc6e3dcb32dc72407799899c59\n'}, {'number': 4, 'created': '2020-12-23 12:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/62f4fe2674acc5dcb9a7c2f085d9f4caa1b52b94', 'message': 'Add missing s3api parameters\n\nThis change introduces some parameters to swift::proxy::s3api, to\nimprove support coverage about s3api parameters.\nNote that this change also removes redundant default definition about\nthe max_upload_part_num parameter.\n\nChange-Id: I88a136115ea454bc6e3dcb32dc72407799899c59\n'}, {'number': 5, 'created': '2020-12-29 03:53:34.000000000', 'files': ['releasenotes/notes/s3api-more-parameters-54a8d24510a662ea.yaml', 'manifests/proxy/s3api.pp', 'spec/classes/swift_proxy_s3api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/b153bb414cb42fb039b2678a6d0d6740972d8799', 'message': 'Add missing s3api parameters\n\nThis change introduces some parameters to swift::proxy::s3api, to\nimprove support coverage about s3api parameters.\nNote that this change also removes redundant default definition about\nthe max_upload_part_num parameter.\n\nChange-Id: I88a136115ea454bc6e3dcb32dc72407799899c59\n'}]",0,768308,b153bb414cb42fb039b2678a6d0d6740972d8799,14,3,5,9816,,,0,"Add missing s3api parameters

This change introduces some parameters to swift::proxy::s3api, to
improve support coverage about s3api parameters.
Note that this change also removes redundant default definition about
the max_upload_part_num parameter.

Change-Id: I88a136115ea454bc6e3dcb32dc72407799899c59
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/08/768308/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/proxy/s3api.pp'],1,b6942e4f387a4f65aba326aa6c0515f11ec8a89f,s3api,"# [*dns_compliant_bucket_names*] # Enforce DNS-compliant bucket names # Defaults to $::os_service_default. ## [*storage_domain*] # A host name of the Swift cluster # Defaults to $::os_service_default. # $allow_no_owner = $::os_service_default, $location = $::os_service_default, $dns_compliant_bucket_names = $::os_service_default, $s3_acl = $::os_service_default, $auth_pipeline_check = false, $storage_domain = $::os_service_default, $max_upload_part_num = 1000, $check_bucket_owner = $::os_service_default, $ensure = undef, 'filter:s3api/use': value => 'egg:swift#s3api'; 'filter:s3api/allow_no_owner': value => $allow_no_owner; 'filter:s3api/location': value => $location; 'filter:s3api/dns_compliant_bucket_names': value => $dns_compliant_bucket_names; 'filter:s3api/s3_acl': value => $s3_acl; 'filter:s3api/storage_domain': value => $storage_domain; 'filter:s3api/auth_pipeline_check': value => $auth_pipeline_check; 'filter:s3api/max_upload_part_num': value => $max_upload_part_num; 'filter:s3api/check_bucket_owner': value => $check_bucket_owner;"," $allow_no_owner = $::os_service_default, $location = $::os_service_default, $s3_acl = $::os_service_default, $auth_pipeline_check = false, $max_upload_part_num = 1000, $check_bucket_owner = $::os_service_default, $ensure = undef, 'filter:s3api/use': value => 'egg:swift#s3api'; 'filter:s3api/allow_no_owner': value => $allow_no_owner; 'filter:s3api/location': value => $location; 'filter:s3api/s3_acl': value => $s3_acl; 'filter:s3api/auth_pipeline_check': value => $auth_pipeline_check; 'filter:s3api/max_upload_part_num': value => $max_upload_part_num; 'filter:s3api/check_bucket_owner': value => $check_bucket_owner;",35,14
openstack%2Fpuppet-swift~master~I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31,openstack/puppet-swift,master,I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31,Add missing parameters for ACL feature of s3api middleware,MERGED,2020-12-22 14:52:41.000000000,2021-01-04 17:51:04.000000000,2021-01-04 17:49:33.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-22 14:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/20b227ba4b5dbb30bd43786c434cae644392eb03', 'message': 'Add support for parameters for ACL feature of s3api middleware\n\nChange-Id: I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31\n'}, {'number': 2, 'created': '2020-12-22 14:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/ab59603b00479e440c2bacf9fc9cd88f7b44368d', 'message': 'Add missing parameters for ACL feature of s3api middleware\n\nChange-Id: I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31\n'}, {'number': 3, 'created': '2020-12-22 23:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/626fc2fc78389d17bab2bcc921694cb4e1d29801', 'message': 'Add missing parameters for ACL feature of s3api middleware\n\nChange-Id: I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31\n'}, {'number': 4, 'created': '2020-12-23 07:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/fbf49dedf18525367078a4005f5f3bbf02262767', 'message': 'Add missing parameters for ACL feature of s3api middleware\n\nChange-Id: I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31\n'}, {'number': 5, 'created': '2020-12-29 03:53:34.000000000', 'files': ['manifests/proxy/s3api.pp', 'spec/classes/swift_proxy_s3api_spec.rb', 'releasenotes/notes/s3api-acl-parameters-b0127aa19ece53a4.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/c006f0adb3128b3ac54568fe0322f59ae1386b1e', 'message': 'Add missing parameters for ACL feature of s3api middleware\n\nChange-Id: I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31\n'}]",0,768214,c006f0adb3128b3ac54568fe0322f59ae1386b1e,15,3,5,9816,,,0,"Add missing parameters for ACL feature of s3api middleware

Change-Id: I4e6643d3c48e5d5591d60d26abd2ea037e0a6b31
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/14/768214/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/proxy/s3api.pp', 'spec/classes/swift_proxy_s3api_spec.rb', 'releasenotes/notes/s3api-acl-parameters-b0127aa19ece53a4.yaml']",3,20b227ba4b5dbb30bd43786c434cae644392eb03,s3api,--- features: - | The following parameters have been added to the ``swift::proxy::s3api`` class to support more ACL parameters of s3api middleware. - ``allow_no_owner`` - ``s3_acl`` - ``check_bucket_owner`` ,,37,0
openstack%2Fopenstack-ansible-galera_server~master~I4a4e958c98b67203774e0c8aa0d208aede0673c7,openstack/openstack-ansible-galera_server,master,I4a4e958c98b67203774e0c8aa0d208aede0673c7,Bump mariadb version to 10.5.8,MERGED,2020-12-16 12:32:06.000000000,2021-01-04 17:44:46.000000000,2021-01-04 17:43:20.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-16 12:32:06.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/b0e4cb8953d280906503e8b6ddfabb73aece27e0', 'message': 'Bump mariadb version to 10.5.8\n\nIncorporate latest bug fixes in the 10.5 release\n\nChange-Id: I4a4e958c98b67203774e0c8aa0d208aede0673c7\n'}]",0,767341,b0e4cb8953d280906503e8b6ddfabb73aece27e0,12,3,1,25023,,,0,"Bump mariadb version to 10.5.8

Incorporate latest bug fixes in the 10.5 release

Change-Id: I4a4e958c98b67203774e0c8aa0d208aede0673c7
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/41/767341/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,b0e4cb8953d280906503e8b6ddfabb73aece27e0,,galera_minor_version: 8,galera_minor_version: 6,1,1
openstack%2Fpuppet-swift~master~I2b626c3077d037a209b2717962136ce0dddcac80,openstack/puppet-swift,master,I2b626c3077d037a209b2717962136ce0dddcac80,Add support for the location parameter of s3api middleware,MERGED,2020-12-22 14:42:03.000000000,2021-01-04 17:42:06.000000000,2021-01-04 17:39:48.000000000,"[{'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-22 14:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/2a1ca1cd5e25c023a6b6a0b354a8230834398275', 'message': 'Add support for the location parameter of s3api middleware\n\nThis change introduces support for the location parameter of s3api\nmiddleware which is required for v4 signatures calculation.\n\nChange-Id: I2b626c3077d037a209b2717962136ce0dddcac80\n'}, {'number': 2, 'created': '2020-12-29 03:53:34.000000000', 'files': ['releasenotes/notes/s3api-location-4f482f468f484861.yaml', 'manifests/proxy/s3api.pp', 'spec/classes/swift_proxy_s3api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/cf0fa5d67980c24d67a72912d54a44f640bbdd4f', 'message': 'Add support for the location parameter of s3api middleware\n\nThis change introduces support for the location parameter of s3api\nmiddleware which is required for v4 signatures calculation.\n\nChange-Id: I2b626c3077d037a209b2717962136ce0dddcac80\n'}]",0,768211,cf0fa5d67980c24d67a72912d54a44f640bbdd4f,10,3,2,9816,,,0,"Add support for the location parameter of s3api middleware

This change introduces support for the location parameter of s3api
middleware which is required for v4 signatures calculation.

Change-Id: I2b626c3077d037a209b2717962136ce0dddcac80
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/11/768211/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/s3api-location-4f482f468f484861.yaml', 'manifests/proxy/s3api.pp', 'spec/classes/swift_proxy_s3api_spec.rb']",3,2a1ca1cd5e25c023a6b6a0b354a8230834398275,s3api," is_expected.to contain_swift_proxy_config('filter:s3api/location').with_value('<SERVICE DEFAULT>') :location => 'regionOne', is_expected.to contain_swift_proxy_config('filter:s3api/location').with_value('regionOne')",,14,0
openstack%2Fpuppet-swift~master~I57463d8d6c6756793d397371648ce692dd2c2d09,openstack/puppet-swift,master,I57463d8d6c6756793d397371648ce692dd2c2d09,Deprecate ineffective swift::proxy::s3api::ensure,MERGED,2020-12-22 14:28:39.000000000,2021-01-04 17:41:11.000000000,2021-01-04 17:39:43.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-22 14:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/81c8845cb74d9ebfce5fca95829b08a0febc79aa', 'message': ""Deprecate uneffective swift::proxy::s3api::ensure\n\nThe swift::proxy::s3api::ensure parameter is currently unused. Let's\njust deprecate the parameter because it is useless.\n\nChange-Id: I57463d8d6c6756793d397371648ce692dd2c2d09\n""}, {'number': 2, 'created': '2020-12-22 14:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/f9a4f57c7f6597be70329a26cac6635fea900ca7', 'message': ""Deprecate uneffective swift::proxy::s3api::ensure\n\nThe swift::proxy::s3api::ensure parameter is currently unused. Let's\njust deprecate the parameter because it is useless.\n\nChange-Id: I57463d8d6c6756793d397371648ce692dd2c2d09\n""}, {'number': 3, 'created': '2020-12-22 14:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/027040479078c20be919abbd41e6b6e511ade722', 'message': ""Deprecate uneffective swift::proxy::s3api::ensure\n\nThe swift::proxy::s3api::ensure parameter is currently unused. Let's\njust deprecate the parameter because it is useless.\n\nChange-Id: I57463d8d6c6756793d397371648ce692dd2c2d09\n""}, {'number': 4, 'created': '2020-12-29 03:53:34.000000000', 'files': ['releasenotes/notes/deprecate-s3api-ensure-3d036cfc32340b16.yaml', 'manifests/proxy/s3api.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/42d74471dd1f6f4104a3be0218f007566342bedd', 'message': ""Deprecate ineffective swift::proxy::s3api::ensure\n\nThe swift::proxy::s3api::ensure parameter is currently unused. Let's\njust deprecate the parameter because it is useless.\n\nChange-Id: I57463d8d6c6756793d397371648ce692dd2c2d09\n""}]",0,768207,42d74471dd1f6f4104a3be0218f007566342bedd,13,3,4,9816,,,0,"Deprecate ineffective swift::proxy::s3api::ensure

The swift::proxy::s3api::ensure parameter is currently unused. Let's
just deprecate the parameter because it is useless.

Change-Id: I57463d8d6c6756793d397371648ce692dd2c2d09
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/07/768207/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-s3api-ensure-3d036cfc32340b16.yaml', 'manifests/proxy/s3api.pp']",2,81c8845cb74d9ebfce5fca95829b08a0febc79aa,s3api,"# [*location*] # Region name of the swift cluster # Defaults to $::os_service_default # # DEPRECATED PARAMETERS # # [*ensure*] # Enable or not s3api middleware # Defaults to undef # $s3_acl = $::os_service_default, # DEPRECATED PARAMETERS $ensure = undef, if $ensure != undef { warning('The ensure parameter has been deprecated and has no effect') } swift_proxy_config { 'filter:s3api/use': value => 'egg:swift#s3api';","# [*ensure*] # Enable or not s3api middleware # Defaults to 'present' # $ensure = 'present', swift_proxy_config { 'filter:s3api/use': value => 'egg:swift#s3api';",23,6
openstack%2Fironic~master~Ie7e326de3c40942a2c4c35786e1a4522f046cb09,openstack/ironic,master,Ie7e326de3c40942a2c4c35786e1a4522f046cb09,Increase general base VM to 3200 MB,ABANDONED,2020-12-14 22:17:15.000000000,2021-01-04 17:34:47.000000000,,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-14 22:17:15.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/003ca8b4ceaa4eb85a863c9e647fbd00829cfa1f', 'message': ""Increase general base VM to 3200 MB\n\nCentos Stream images take about 1.1GB\nuncompressed, or about 430MB compressed.\n\nBecause of this, the system's available ramdisk\nstorage is severely starved and the ramdisk sometimes\ndoes not boot.\n\nChange-Id: Ie7e326de3c40942a2c4c35786e1a4522f046cb09\n""}]",0,767026,003ca8b4ceaa4eb85a863c9e647fbd00829cfa1f,8,2,1,11655,,,0,"Increase general base VM to 3200 MB

Centos Stream images take about 1.1GB
uncompressed, or about 430MB compressed.

Because of this, the system's available ramdisk
storage is severely starved and the ramdisk sometimes
does not boot.

Change-Id: Ie7e326de3c40942a2c4c35786e1a4522f046cb09
",git fetch https://review.opendev.org/openstack/ironic refs/changes/26/767026/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,003ca8b4ceaa4eb85a863c9e647fbd00829cfa1f,pip-resolver, IRONIC_VM_SPECS_RAM: 3200, IRONIC_VM_SPECS_RAM: 3072,1,1
openstack%2Fpuppet-glance~master~Ib188ef46d53ea2ac2adc5deaf0d249f8bdb8f1aa,openstack/puppet-glance,master,Ib188ef46d53ea2ac2adc5deaf0d249f8bdb8f1aa,cinder backend: password should be secret,MERGED,2020-12-21 12:03:39.000000000,2021-01-04 17:29:08.000000000,2021-01-04 17:29:08.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-21 12:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/8881711104a47c54c690f9b09a966d4eaaf9e368', 'message': 'cinder backend: password should be secret\n\nThis change ensures that password information for cinder backend is\nproperly hidden.\n\nChange-Id: Ib188ef46d53ea2ac2adc5deaf0d249f8bdb8f1aa\n'}, {'number': 2, 'created': '2020-12-21 12:05:02.000000000', 'files': ['spec/defines/glance_backend_multistore_cinder_spec.rb', 'manifests/backend/multistore/cinder.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/3a9ae92204091bfb4a16e7d342667a945df9a263', 'message': 'cinder backend: password should be secret\n\nThis change ensures that password information for cinder backend is\nproperly hidden.\n\nChange-Id: Ib188ef46d53ea2ac2adc5deaf0d249f8bdb8f1aa\n'}]",0,768082,3a9ae92204091bfb4a16e7d342667a945df9a263,9,4,2,9816,,,0,"cinder backend: password should be secret

This change ensures that password information for cinder backend is
properly hidden.

Change-Id: Ib188ef46d53ea2ac2adc5deaf0d249f8bdb8f1aa
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/82/768082/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/backend/multistore/cinder.pp'],1,8881711104a47c54c690f9b09a966d4eaaf9e368,cinder-password," ""${name}/cinder_store_password"": value => $cinder_store_password, secret => true; ""${name}/cinder_store_password"": value => $cinder_store_password, secret => true;"," ""${name}/cinder_store_password"": value => $cinder_store_password; ""${name}/cinder_store_password"": value => $cinder_store_password;",2,2
openstack%2Fpuppet-glance~master~If0e3e0bd01f976e5a32aa9355ac5dd99425722a3,openstack/puppet-glance,master,If0e3e0bd01f976e5a32aa9355ac5dd99425722a3,Add cinder volume type for multiple cinder stores,MERGED,2020-12-09 07:01:38.000000000,2021-01-04 17:23:24.000000000,2021-01-04 17:22:02.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-09 07:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/96508a3ddb65ba4c0e139db25bed0daf2099c26d', 'message': ""Add cinder volume type for multiple cinder stores\n\nDuring initialization of service, all volume types configured\nin the cinder store(s) will be checked if they exist in deployment\nor not, the store with the wrong type will be disabled. if cinder\nstore is configured using traditional/old way (i.e. using 'stores'\nconfig option) then this validation will not be performed.\n\nAdding missing 'cinder_volume_type' parameter.\n\nPartially Implements: blueprint multiple-cinder-backend-support\n\nChange-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3\n""}, {'number': 2, 'created': '2020-12-15 12:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/c0218f0c48235c7278e8cc7efa240083f40335dd', 'message': ""Add cinder volume type for multiple cinder stores\n\nDuring initialization of service, all volume types configured\nin the cinder store(s) will be checked if they exist in deployment\nor not, the store with the wrong type will be disabled. if cinder\nstore is configured using traditional/old way (i.e. using 'stores'\nconfig option) then this validation will not be performed.\n\nAdding missing 'cinder_volume_type' parameter.\n\nPartially Implements: blueprint multiple-cinder-backend-support\n\nChange-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3\n""}, {'number': 3, 'created': '2020-12-15 12:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/272bc857547a901228a378a5861cd009493c836c', 'message': ""Add cinder volume type for multiple cinder stores\n\nDuring initialization of service, all volume types configured\nin the cinder store(s) will be checked if they exist in deployment\nor not, the store with the wrong type will be disabled. if cinder\nstore is configured using traditional/old way (i.e. using 'stores'\nconfig option) then this validation will not be performed.\n\nAdding missing 'cinder_volume_type' parameter.\n\nPartially Implements: blueprint multiple-cinder-backend-support\n\nChange-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3\n""}, {'number': 4, 'created': '2020-12-17 10:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/755aa44d13610c62b8d88a6f0b7943598d411cae', 'message': ""Add cinder volume type for multiple cinder stores\n\nAdding 'cinder_volume_type' configuration parameter to allow\ncinder stores to specify a volume type for each cinder store.\n\nPartially Implements: blueprint multiple-cinder-backend-support\n\nChange-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3\n""}, {'number': 5, 'created': '2020-12-20 13:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/467970631747e5fb9a4b26a476f44748cf5dd739', 'message': ""Add cinder volume type for multiple cinder stores\n\nAdding 'cinder_volume_type' configuration parameter to allow\ncinder stores to specify a volume type for each cinder store.\n\nPartially Implements: blueprint multiple-cinder-backend-support\n\nChange-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3\n""}, {'number': 6, 'created': '2020-12-21 11:59:34.000000000', 'files': ['releasenotes/notes/add_cinder_volume_type_for_multiple_cinder_stores-c19b0bb1c753715b.yaml', 'spec/defines/glance_backend_multistore_cinder_spec.rb', 'manifests/backend/multistore/cinder.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/28fafd2f0ccada0600a7d4428c37f3bfde525346', 'message': ""Add cinder volume type for multiple cinder stores\n\nAdding 'cinder_volume_type' configuration parameter to allow\ncinder stores to specify a volume type for each cinder store.\n\nPartially Implements: blueprint multiple-cinder-backend-support\n\nChange-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3\n""}]",15,766159,28fafd2f0ccada0600a7d4428c37f3bfde525346,25,4,6,19138,,,0,"Add cinder volume type for multiple cinder stores

Adding 'cinder_volume_type' configuration parameter to allow
cinder stores to specify a volume type for each cinder store.

Partially Implements: blueprint multiple-cinder-backend-support

Change-Id: If0e3e0bd01f976e5a32aa9355ac5dd99425722a3
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/59/766159/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/backend/cinder.pp', 'releasenotes/notes/add_cinder_volume_type_for_multiple_cinder_stores-c19b0bb1c753715b.yaml', 'spec/classes/glance_backend_cinder_spec.rb', 'spec/defines/glance_backend_multistore_cinder_spec.rb', 'manifests/backend/multistore/cinder.pp']",5,96508a3ddb65ba4c0e139db25bed0daf2099c26d,cinder-multistore,"# [*cinder_volume_type*] # (Optional) Volume types configured in the cinder store(s) which will be checked # if they exist in deployment or not, the store with the wrong type will be # disabled. # Defaults to $::os_service_default. # $cinder_volume_type = $::os_service_default, ""${name}/cinder_volume_type"": value => $cinder_volume_type; ""${name}/cinder_volume_type"": value => $cinder_volume_type;",,33,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I56b5792c1d53bb8659e440f598006e471894ff2e,openstack/tripleo-heat-templates,stable/ussuri,I56b5792c1d53bb8659e440f598006e471894ff2e,Define a new CinderVolumeEdge service,MERGED,2020-12-23 17:34:59.000000000,2021-01-04 16:57:50.000000000,2021-01-04 16:57:50.000000000,"[{'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-23 17:34:59.000000000', 'files': ['roles/DistributedComputeHCI.yaml', 'environments/dcn-hci.yaml', 'roles/DistributedCompute.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'sample-env-generator/dcn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b9e1dad6622fb085bce5aa72ac1271256501a99', 'message': 'Define a new CinderVolumeEdge service\n\nCinderVolumeEdge is an optional service (defaults to OS::Heat::None)\nthat can be enabled on DCN/Edge nodes for edge sites that support\npersistent block storage (i.e. cinder). The dcn-hci.yaml environment\nfile enables the service.\n\nThe new service supports the following edge deployment models:\n1. Edge site with no block storage\n   - Deploy DistributedCompute nodes\n   - Use dcn.yaml environment file (the CinderVolumeEdge service\n     remains disabled)\n2. Edge site with traditional HCI storage\n   - Deploy DistributedComputeHCI nodes\n   - Use dcn-hci.yaml env file to enable the CinderVolumeEdge service\n   - Use ceph-ansible.yaml env file to deploy ceph for the RBD backend\n3. Edge site with quasi-hyperconverged storage\n   - Deploy DistributedCompute nodes\n   - Use dcn-hci.yaml env file to enable the CinderVolumeEdge service\n   - Use ceph-ansible-external.yaml env file so the RBD backend can\n     access an external ceph cluster\n\nThis patch adds support for number 3, which is a new capability. Whereas\ntraditional HCI means ceph and cinder services run on compute nodes, the\nnew model is still quasi-hyperconverged because cinder (as well as\nglance) runs on the compute nodes.\n\nChange-Id: I56b5792c1d53bb8659e440f598006e471894ff2e\n(cherry picked from commit 2d60799c49b4b153f59c19c766cf8c6e06312cd2)\n(cherry picked from commit 8e316d7f1b033fcb32dee399d1ed360101e9a00e)\n'}]",0,768362,3b9e1dad6622fb085bce5aa72ac1271256501a99,10,4,1,21129,,,0,"Define a new CinderVolumeEdge service

CinderVolumeEdge is an optional service (defaults to OS::Heat::None)
that can be enabled on DCN/Edge nodes for edge sites that support
persistent block storage (i.e. cinder). The dcn-hci.yaml environment
file enables the service.

The new service supports the following edge deployment models:
1. Edge site with no block storage
   - Deploy DistributedCompute nodes
   - Use dcn.yaml environment file (the CinderVolumeEdge service
     remains disabled)
2. Edge site with traditional HCI storage
   - Deploy DistributedComputeHCI nodes
   - Use dcn-hci.yaml env file to enable the CinderVolumeEdge service
   - Use ceph-ansible.yaml env file to deploy ceph for the RBD backend
3. Edge site with quasi-hyperconverged storage
   - Deploy DistributedCompute nodes
   - Use dcn-hci.yaml env file to enable the CinderVolumeEdge service
   - Use ceph-ansible-external.yaml env file so the RBD backend can
     access an external ceph cluster

This patch adds support for number 3, which is a new capability. Whereas
traditional HCI means ceph and cinder services run on compute nodes, the
new model is still quasi-hyperconverged because cinder (as well as
glance) runs on the compute nodes.

Change-Id: I56b5792c1d53bb8659e440f598006e471894ff2e
(cherry picked from commit 2d60799c49b4b153f59c19c766cf8c6e06312cd2)
(cherry picked from commit 8e316d7f1b033fcb32dee399d1ed360101e9a00e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/768362/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/DistributedComputeHCI.yaml', 'environments/dcn-hci.yaml', 'roles/DistributedCompute.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'sample-env-generator/dcn.yaml']",5,3b9e1dad6622fb085bce5aa72ac1271256501a99,cinder-volume-edge, OS::TripleO::Services::CinderVolumeEdge: ../deployment/cinder/cinder-volume-container-puppet.yaml, OS::TripleO::Services::CinderVolume: ../deployment/cinder/cinder-volume-container-puppet.yaml,6,3
openstack%2Fpuppet-horizon~master~I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,openstack/puppet-horizon,master,I4ab9871e8b238ad87369a77d53acdc7abdf60ffd,add support for SECURE_PROXY_ADDR_HEADER,MERGED,2020-12-28 12:54:30.000000000,2021-01-04 16:52:13.000000000,2021-01-04 16:50:57.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-28 12:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/b7fc17668755b808ccbf5a918bf9f94c78b3473d', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 2, 'created': '2020-12-29 11:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/2a180aea406f56a7dd96ae38d3bc502a99d1f437', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 3, 'created': '2020-12-29 11:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/21ed6adbedc821c6be3f6827925adb9cd4afbb37', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 4, 'created': '2020-12-29 11:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/ff970245c5cd2a2fa08de4f9cd59ea7c11e941f8', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 5, 'created': '2020-12-29 13:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/972448c002a1d5042b1a4e646ad6fdb5ae10b664', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 6, 'created': '2020-12-29 14:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/c973cf0ebccdf1fefd1a4e822c549fa4c66e6324', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 7, 'created': '2020-12-29 19:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/319324e188ffee6b60407bfccc22e10b0549fe3d', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 8, 'created': '2020-12-30 02:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/b5ba774709af19aacd0830d50cb12a9039dced31', 'message': ' add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}, {'number': 9, 'created': '2020-12-30 02:45:30.000000000', 'files': ['templates/local_settings.py.erb', 'releasenotes/notes/add-secure-proxy-addr-header-07c36d89f8bf2ad2.yaml', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/05afbe439913ca04b737639eb50f65cb57a58ed7', 'message': 'add support for SECURE_PROXY_ADDR_HEADER\n\nChange-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd\n'}]",4,768605,05afbe439913ca04b737639eb50f65cb57a58ed7,25,3,9,32881,,,0,"add support for SECURE_PROXY_ADDR_HEADER

Change-Id: I4ab9871e8b238ad87369a77d53acdc7abdf60ffd
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/05/768605/7 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,b7fc17668755b808ccbf5a918bf9f94c78b3473d,add-support-for-SECURE-PROXY-ADDR-HEADER," :secure_proxy_addr_header => 'HTTP_X_FORWARDED_FOR', ""SECURE_PROXY_ADDR_HEADER = 'HTTP_X_FORWARDED_FOR'"",",,17,0
openstack%2Fpython-neutronclient~master~I2521c2ba836b6a332883134112b6f99d996cc4e4,openstack/python-neutronclient,master,I2521c2ba836b6a332883134112b6f99d996cc4e4,remove unicode from code,MERGED,2021-01-03 08:58:37.000000000,2021-01-04 16:50:49.000000000,2021-01-04 16:49:24.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 08:58:37.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4963c7ae14743d2542c8334e3175b7827750bb3d', 'message': 'remove unicode from code\n\nChange-Id: I2521c2ba836b6a332883134112b6f99d996cc4e4\n'}]",0,769045,4963c7ae14743d2542c8334e3175b7827750bb3d,8,3,1,30384,,,0,"remove unicode from code

Change-Id: I2521c2ba836b6a332883134112b6f99d996cc4e4
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/45/769045/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,4963c7ae14743d2542c8334e3175b7827750bb3d,,"project = 'Neutron Client Release Notes' copyright = '2015, Neutron Developers'","project = u'Neutron Client Release Notes' copyright = u'2015, Neutron Developers'",5,5
openstack%2Frpm-packaging~master~I5c6e7052e1b5217656197b16789a5343c1f7b377,openstack/rpm-packaging,master,I5c6e7052e1b5217656197b16789a5343c1f7b377,"Revert ""Update oslo.db.spec.j2""",MERGED,2021-01-04 15:26:30.000000000,2021-01-04 16:44:18.000000000,2021-01-04 16:44:18.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}, {'_account_id': 28654}]","[{'number': 1, 'created': '2021-01-04 15:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/236c402e332538aac9e4751662e2c1be104843d6', 'message': 'Revert ""Update oslo.db.spec.j2""\n\n8.5.0 is causing a lot of failures, including keystone. and is not yet merged upstream: \n\nhttps://review.opendev.org/c/openstack/requirements/+/765497\n\nThis reverts commit e3626d5bb396049de6903f14f40e98170b7272a8.\n\nReason for revert: <INSERT REASONING HERE>\n\nChange-Id: I5c6e7052e1b5217656197b16789a5343c1f7b377\n'}, {'number': 2, 'created': '2021-01-04 15:27:20.000000000', 'files': ['openstack/oslo.db/oslo.db.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e4d97e715769008a8e3741876d771c3626514125', 'message': 'Revert ""Update oslo.db.spec.j2""\n\n8.5.0 is causing a lot of failures, including keystone. and is not yet merged upstream: \nhttps://review.opendev.org/c/openstack/requirements/+/765497\n\nThis reverts commit e3626d5bb396049de6903f14f40e98170b7272a8.\n\nChange-Id: I5c6e7052e1b5217656197b16789a5343c1f7b377\n'}]",0,768751,e4d97e715769008a8e3741876d771c3626514125,9,6,2,6593,,,0,"Revert ""Update oslo.db.spec.j2""

8.5.0 is causing a lot of failures, including keystone. and is not yet merged upstream: 
https://review.opendev.org/c/openstack/requirements/+/765497

This reverts commit e3626d5bb396049de6903f14f40e98170b7272a8.

Change-Id: I5c6e7052e1b5217656197b16789a5343c1f7b377
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/51/768751/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.db/oslo.db.spec.j2'],1,236c402e332538aac9e4751662e2c1be104843d6,,{% set upstream_version = upstream_version('8.4.0') %},{% set upstream_version = upstream_version('8.5.0') %},1,1
openstack%2Fkolla-ansible~stable%2Fussuri~Iec1a8bd9c98dbae03660259468d30ddf8667ff80,openstack/kolla-ansible,stable/ussuri,Iec1a8bd9c98dbae03660259468d30ddf8667ff80,Add `issue` reno for bug #1904062,MERGED,2021-01-04 14:39:15.000000000,2021-01-04 16:10:23.000000000,2021-01-04 16:09:02.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2021-01-04 14:39:15.000000000', 'files': ['releasenotes/notes/issue-bug-1904062-ef446343323c8452.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e1380e259a1e62d9cac5dab546cfe49acb6c4fac', 'message': 'Add `issue` reno for bug #1904062\n\nChange-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80\nRelated-Bug: #1904062\n(cherry picked from commit 10caf4d36caa23199b1358b056838a9ab3d929b7)\n'}]",0,768750,e1380e259a1e62d9cac5dab546cfe49acb6c4fac,8,3,1,30491,,,0,"Add `issue` reno for bug #1904062

Change-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80
Related-Bug: #1904062
(cherry picked from commit 10caf4d36caa23199b1358b056838a9ab3d929b7)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/50/768750/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/issue-bug-1904062-ef446343323c8452.yaml'],1,e1380e259a1e62d9cac5dab546cfe49acb6c4fac,issue-bug/1904062-stable/ussuri,"--- issues: - | Since Ussuri, there is a bug in how Ceph (RBD) is handled with Cinder: the ``backend_host`` option is missing from the generated configuration for external Ceph. The symptoms are that volumes become unmanageable until extra admin action is taken. This does *not* affect the data plane - running virtual machines are *not* affected. There is a related issue regarding active-active ``cinder-volume`` services (single-host ``cinder-volume`` *not* affected), which is that they should not have been configured with ``backend_host`` in the first place but with ``cluster`` and proper coordination instead. Some users might have customised their config already to address this issue. The Kolla team is investigating the best way to address this for all its users. In the meantime, please ensure that, before upgrading to Ussuri, the ``backend_host`` option is set to its previous value (the default was ``rbd:volumes``) via a config override. For more details please refer to the referenced bug. Do note this issue affects both new deployments and upgrades. `LP#1904062 <https://bugs.launchpad.net/kolla-ansible/+bug/1904062>`__ ",,23,0
openstack%2Fkolla~stable%2Fussuri~I88e5bcf35207670b8611aeee3072215a7d7eb6e5,openstack/kolla,stable/ussuri,I88e5bcf35207670b8611aeee3072215a7d7eb6e5,Fix Freezer & Cyborg API startup on CentOS,MERGED,2021-01-04 09:59:42.000000000,2021-01-04 16:10:19.000000000,2021-01-04 16:08:58.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-04 09:59:42.000000000', 'files': ['docker/cyborg/cyborg-api/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e0d8772efa25b478467afcd3e2ecf2643ea471ff', 'message': 'Fix Freezer & Cyborg API startup on CentOS\n\nAffects: Ussuri, Train\n\nAs part of the CentOS 8 support, we added a kolla_httpd_setup script,\nhowever this was not used for Cyborg or Freezer. This has been fixed\nsince Victoria as part of commit\n032804e5a0ddf89f7726880d1b57dd492d7d5c07, but this was not backported to\nUssuri.\n\nCloses-Bug: #1909981\nCo-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\n\nChange-Id: I88e5bcf35207670b8611aeee3072215a7d7eb6e5\n'}]",0,769117,e0d8772efa25b478467afcd3e2ecf2643ea471ff,9,3,1,14826,,,0,"Fix Freezer & Cyborg API startup on CentOS

Affects: Ussuri, Train

As part of the CentOS 8 support, we added a kolla_httpd_setup script,
however this was not used for Cyborg or Freezer. This has been fixed
since Victoria as part of commit
032804e5a0ddf89f7726880d1b57dd492d7d5c07, but this was not backported to
Ussuri.

Closes-Bug: #1909981
Co-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>

Change-Id: I88e5bcf35207670b8611aeee3072215a7d7eb6e5
",git fetch https://review.opendev.org/openstack/kolla refs/changes/17/769117/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/cyborg/cyborg-api/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh']",2,e0d8772efa25b478467afcd3e2ecf2643ea471ff,,. /usr/local/bin/kolla_httpd_setup,"if [[ ""${KOLLA_BASE_DISTRO}"" =~ debian|ubuntu ]]; then # Loading Apache2 ENV variables . /etc/apache2/envvars install -d /var/run/apache2/ rm -rf /var/run/apache2/* else rm -rf /var/run/httpd/* /run/httpd/* /tmp/httpd* fi",2,16
openstack%2Fcharm-barbican-vault~master~Ie2694ba38e08fd9e864bf9d8fa0b63f0e185b8bd,openstack/charm-barbican-vault,master,Ie2694ba38e08fd9e864bf9d8fa0b63f0e185b8bd,Retrieve approle_secret_id from correct relation,MERGED,2020-11-27 15:52:39.000000000,2021-01-04 15:58:20.000000000,2021-01-04 15:58:20.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-27 15:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-barbican-vault/commit/ba062863c2da4549c41cbb0ea1ab34965f65c522', 'message': 'Retrieve approle_secret_id from correct relation\n\nThe existing comment in the code expresses the correct intent:\n""fetch current secret-id, if any, from relation with barbican principle""\nbut then attempts to retrieve the secret-id from the vault\nrelation.\n\nChange-Id: Ie2694ba38e08fd9e864bf9d8fa0b63f0e185b8bd\nCloses-Bug: #1871981\n'}, {'number': 2, 'created': '2020-12-17 19:57:56.000000000', 'files': ['src/reactive/barbican_vault_handlers.py', 'unit_tests/test_barbican_vault_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-barbican-vault/commit/26ba0535efe16f50aca7ffad5496ee9b344a7d7d', 'message': 'Retrieve approle_secret_id from correct relation\n\nThe existing comment in the code expresses the correct intent:\n""fetch current secret-id, if any, from relation with barbican principle""\nbut then attempts to retrieve the secret-id from the vault\nrelation.\n\nChange-Id: Ie2694ba38e08fd9e864bf9d8fa0b63f0e185b8bd\nCloses-Bug: #1871981\n'}]",0,764470,26ba0535efe16f50aca7ffad5496ee9b344a7d7d,22,4,2,12549,,,0,"Retrieve approle_secret_id from correct relation

The existing comment in the code expresses the correct intent:
""fetch current secret-id, if any, from relation with barbican principle""
but then attempts to retrieve the secret-id from the vault
relation.

Change-Id: Ie2694ba38e08fd9e864bf9d8fa0b63f0e185b8bd
Closes-Bug: #1871981
",git fetch https://review.opendev.org/openstack/charm-barbican-vault refs/changes/70/764470/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/reactive/barbican_vault_handlers.py', 'unit_tests/test_barbican_vault_handlers.py']",2,ba062863c2da4549c41cbb0ea1ab34965f65c522,bug/1871981, mock.call('secrets-storage.available')," mock.call('secrets-storage.available'), mock.call('secrets.available'),",3,5
openstack%2Fpuppet-nova~stable%2Ftrain~Ifb0f5e1d7db31885636f689166ff666b049e9414,openstack/puppet-nova,stable/train,Ifb0f5e1d7db31885636f689166ff666b049e9414,Cleanup listen option from libvirtd service file,MERGED,2020-10-14 07:48:42.000000000,2021-01-04 15:56:00.000000000,2021-01-04 15:56:00.000000000,"[{'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-10-14 07:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1148548697308a2990b7ef9d3bf2daf0e9aab7ea', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nRelated-Bug: #1898553\nRelated-Bug: #1880619\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}, {'number': 2, 'created': '2020-10-14 07:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/38440d4c165976e0a73d5da70012624f19cfab5d', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nResolved conflicts caused by missing fix for Ubuntus\n  https://review.opendev.org/#/c/752788/\n\nRelated-Bug: #1898553\nRelated-Bug: #1880619\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}, {'number': 3, 'created': '2020-10-14 07:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/10ab751d5d263867a0ecdc5523d1c522c8a840a6', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nResolved conflicts caused by missing fix for Ubuntus\n  https://review.opendev.org/#/c/752788/\n\nRelated-Bug: #1898553\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}, {'number': 4, 'created': '2020-10-14 07:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/0304b72e0bd80e3d8fac61eb39122f5db5f93a28', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nResolved conflicts caused by missing fix for Ubuntus\n  https://review.opendev.org/#/c/752788/\n\nRelated-Bug: #1880619\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}, {'number': 5, 'created': '2020-10-19 01:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e9bbf59d998fd62a21af1caec0f0a823dc66c5dc', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nResolved conflicts caused by missing fix for Ubuntus\n  https://review.opendev.org/#/c/752788/\n\nRelated-Bug: #1880619\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}, {'number': 6, 'created': '2020-10-19 08:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e115b576214edea2ca54be8f320678d7cfbed40e', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nResolved conflicts caused by missing fix for Ubuntus\n  https://review.opendev.org/#/c/752788/\n\nRelated-Bug: #1880619\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}, {'number': 7, 'created': '2020-12-22 12:25:07.000000000', 'files': ['manifests/migration/libvirt.pp', 'spec/classes/nova_migration_libvirt_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/32bd0fa3b316536d188caedc2331b7c521e85e1e', 'message': 'Cleanup listen option from libvirtd service file\n\nThis patch ensures that listen option is removed from service file when\nlibvirt>=5.6 is used, since the option might be left if the deployment\nis updated or upgraded from old version.\n\nConflicts:\n\tmanifests/migration/libvirt.pp\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nResolved conflicts caused by missing fix for Ubuntus\n  https://review.opendev.org/#/c/752788/\n\nRelated-Bug: #1880619\nChange-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414\n(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)\n(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)\n(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)\n'}]",0,758024,32bd0fa3b316536d188caedc2331b7c521e85e1e,25,5,7,9816,,,0,"Cleanup listen option from libvirtd service file

This patch ensures that listen option is removed from service file when
libvirt>=5.6 is used, since the option might be left if the deployment
is updated or upgraded from old version.

Conflicts:
	manifests/migration/libvirt.pp
	spec/classes/nova_migration_libvirt_spec.rb

Resolved conflicts caused by missing fix for Ubuntus
  https://review.opendev.org/#/c/752788/

Related-Bug: #1880619
Change-Id: Ifb0f5e1d7db31885636f689166ff666b049e9414
(cherry picked from commit 20585762919c49e6dffab58664949b23d2306eae)
(cherry picked from commit 386a5d00285155cc3bc7a5f190fb6c86f05bff23)
(cherry picked from commit 6dafd844a0b6a82d254e7dffaec426779a9a995a)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/24/758024/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/migration/libvirt.pp', 'spec/classes/nova_migration_libvirt_spec.rb']",2,1148548697308a2990b7ef9d3bf2daf0e9aab7ea,bug/1880619," context 'with libvirt < 5.6' do let :params do { :transport => 'tls', :libvirt_version => '4.0' } end it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with( :path => '/etc/default/libvirtd', :line => 'libvirtd_opts=""-l""', :match => 'libvirtd_opts=', :tag => 'libvirt-file_line', ) } it { is_expected.to_not contain_service('libvirtd-tls') } it { is_expected.to_not contain_service('libvirtd-tcp') } end context 'with libvirt >= 5.6' do context 'with tls transport' do let :params do { :transport => 'tls', :libvirt_version => '6.0' } end it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with( :path => '/etc/default/libvirtd', :line => 'libvirtd_opts=', :match => 'libvirtd_opts=', :tag => 'libvirt-file_line', ) } it { is_expected.to contain_service('libvirtd-tls').with( :name => 'libvirtd-tls.socket', :ensure => 'running', :enable => true, )} end context 'with tcp transport' do let :params do { :transport => 'tcp', :libvirt_version => '6.0' } end it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with( :path => '/etc/default/libvirtd', :line => 'libvirtd_opts=', :match => 'libvirtd_opts=', :tag => 'libvirt-file_line', ) } it { is_expected.to contain_service('libvirtd-tcp').with( :name => 'libvirtd-tcp.socket', :ensure => 'running', :enable => true, )} end end context 'with libvirt < 5.6' do let :params do { :transport => 'tls', :libvirt_version => '4.5' } it { is_expected.to contain_file_line('/etc/sysconfig/libvirtd libvirtd args').with( :path => '/etc/sysconfig/libvirtd', :line => 'LIBVIRTD_ARGS=""--listen""', :match => '^LIBVIRTD_ARGS=', :tag => 'libvirt-file_line', )} it { is_expected.to_not contain_service('libvirtd-tls') } it { is_expected.to_not contain_service('libvirtd-tcp') } context 'with libvirt >= 5.6' do context 'with tls transport' do let :params do { :transport => 'tls', :libvirt_version => '5.6' } end it { is_expected.to contain_file_line('/etc/sysconfig/libvirtd libvirtd args').with( :path => '/etc/sysconfig/libvirtd', :line => 'LIBVIRTD_ARGS=', :match => '^LIBVIRTD_ARGS=', :tag => 'libvirt-file_line', )} it { is_expected.to contain_service('libvirtd-tls').with( :name => 'libvirtd-tls.socket', :ensure => 'running', :enable => true, )} context 'with tcp transport' do let :params do { :transport => 'tcp', :libvirt_version => '5.6' } end it { is_expected.to contain_file_line('/etc/sysconfig/libvirtd libvirtd args').with( :path => '/etc/sysconfig/libvirtd', :line => 'LIBVIRTD_ARGS=', :match => '^LIBVIRTD_ARGS=', :tag => 'libvirt-file_line', it { is_expected.to contain_service('libvirtd-tcp').with( :name => 'libvirtd-tcp.socket', :ensure => 'running', :enable => true, )} end"," it { is_expected.to contain_file_line('/etc/default/libvirtd libvirtd opts').with(:line => 'libvirtd_opts=""-l""') } context 'with tls transport' do let(:params) do { :transport => 'tls' } it { is_expected.to contain_service('libvirtd-tls').with( :name => 'libvirtd-tls.socket', :ensure => 'running', :enable => true, )} context 'with tls transport' do let(:params) do { :transport => 'tcp' } it { is_expected.to contain_service('libvirtd-tcp').with( :name => 'libvirtd-tcp.socket', :ensure => 'running', :enable => true,",148,51
openstack%2Fironic-python-agent-builder~master~I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793,openstack/ironic-python-agent-builder,master,I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793,Fix ELEMENTS_PATH environment variable being overwritten.,MERGED,2020-02-20 17:22:59.000000000,2021-01-04 15:55:50.000000000,2021-01-04 15:54:08.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 28182}, {'_account_id': 31258}]","[{'number': 1, 'created': '2020-02-20 17:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/53b2041d5e2e2ed02c307fb4ddf8bfad623964f5', 'message': ""Fix ELEMENTS_PATH environment variable being overwritten.\n\nThis change let user to explicitly set ELEMENTS_PATH to custom DIB elements while\nrunning the script or use already set as environment variable. It will prepend\npath to 'ironic-python-agent-builder' instead of overwriting it.\n\nChange-Id: I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793\nStory: 2007309\nTask: 38809\n""}, {'number': 2, 'created': '2020-02-21 15:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/75b36a6062ac8537dcc622c0133a0f17465dbbe5', 'message': ""Fix ELEMENTS_PATH environment variable being overwritten.\n\nThis change let user to explicitly set ELEMENTS_PATH to custom DIB\nelements while running the script or use already set as environment\nvariable. It will prepend path to 'ironic-python-agent-builder' instead\nof overwriting it.\n\nChange-Id: I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793\nStory: 2007309\nTask: 38809\n""}, {'number': 3, 'created': '2020-12-25 19:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/f5941279b7562fe4040b4fde7c3960ee4fea9917', 'message': ""Fix ELEMENTS_PATH environment variable being overwritten.\n\nThis change let user to explicitly set ELEMENTS_PATH to custom DIB\nelements while running the script or use already set as environment\nvariable. It will prepend path to 'ironic-python-agent-builder' instead\nof overwriting it.\n\nChange-Id: I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793\nStory: 2007309\nTask: 38809\n""}, {'number': 4, 'created': '2020-12-26 00:15:34.000000000', 'files': ['ironic_python_agent_builder/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/b072c155f5e42c049a1a3615814bdf8f004bb7b9', 'message': ""Fix ELEMENTS_PATH environment variable being overwritten.\n\nThis change let user to explicitly set ELEMENTS_PATH to custom DIB\nelements while running the script or use already set as environment\nvariable. It will prepend path to 'ironic-python-agent-builder' instead\nof overwriting it.\n\nChange-Id: I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793\nStory: 2007309\nTask: 38809\n""}]",6,708927,b072c155f5e42c049a1a3615814bdf8f004bb7b9,23,6,4,31258,,,0,"Fix ELEMENTS_PATH environment variable being overwritten.

This change let user to explicitly set ELEMENTS_PATH to custom DIB
elements while running the script or use already set as environment
variable. It will prepend path to 'ironic-python-agent-builder' instead
of overwriting it.

Change-Id: I7ec6c222e9678d7dbb3f4f50c3a2de0a9c9a5793
Story: 2007309
Task: 38809
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/27/708927/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent_builder/__init__.py'],1,53b2041d5e2e2ed02c307fb4ddf8bfad623964f5,," parser.add_argument(""-p"", ""--element-path"", help=""Path to custom DIB elements"") args = parser.parse_args() if args.element_path: os.environ['ELEMENTS_PATH'] = args.element_path if 'ELEMENTS_PATH' in os.environ: os.environ['ELEMENTS_PATH'] += "":"" + find_elements_path() else: os.environ['ELEMENTS_PATH'] = find_elements_path()", os.environ['ELEMENTS_PATH'] = find_elements_path() args = parser.parse_args(),9,2
openstack%2Ftripleo-specs~master~Iae721c373f2bbfffa36ed2db9d9af6569e15ed96,openstack/tripleo-specs,master,Iae721c373f2bbfffa36ed2db9d9af6569e15ed96,Network Data v2 - node ports spec,MERGED,2020-10-30 10:21:25.000000000,2021-01-04 15:47:58.000000000,2021-01-04 15:46:37.000000000,"[{'_account_id': 4571}, {'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 25402}]","[{'number': 1, 'created': '2020-10-30 10:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/322e39f075320d3e8b483b1141c9d6300b87480e', 'message': '[WiP]\xa0Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 2, 'created': '2020-11-03 03:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/86e0aa8180be9b2c369bccbe886dbd8ad9cd7c8f', 'message': '[WiP]\xa0Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 3, 'created': '2020-11-03 03:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d941de1ac91751e16b1ae1be6c51779af5944867', 'message': '[WiP]\xa0Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 4, 'created': '2020-11-04 02:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/30576bf09174fb05abd6e87817aaf264fb6a2ea8', 'message': '[WiP]\xa0Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 5, 'created': '2020-11-06 09:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/a0b71af32a1df84c7a05637b663bd1e60596b62c', 'message': 'Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 6, 'created': '2020-11-09 00:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/706b983253559de3a60b3214f09580ddb93a1aae', 'message': 'Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 7, 'created': '2020-11-09 14:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d1cf9de48ee46ad1e0e9b76cdea743b6908c5b6f', 'message': 'Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 8, 'created': '2020-11-10 00:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/662bfffbde833ae6912196e221ff8b6c5350bed6', 'message': 'Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 9, 'created': '2020-11-10 00:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/e8d5fa874e363a13ab6bc6197daa56cff9648b66', 'message': 'Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 10, 'created': '2020-11-23 15:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/6a85711bea226c37e987c3ef273680b89062e498', 'message': 'Network Data v2 - node ports spec\n\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 11, 'created': '2020-11-30 16:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/ec8c7e3103ae5004dda70f11e9d4f254f1cf49d5', 'message': 'Network Data v2 - node ports spec\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 12, 'created': '2020-12-01 12:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9a96842111c6f72852fe6bdff21f441fc39c3220', 'message': 'Network Data v2 - node ports spec\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 13, 'created': '2020-12-01 14:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/004580cafb1c147abfe9054876c5b6d6174fe04c', 'message': 'Network Data v2 - node ports spec\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 14, 'created': '2020-12-03 07:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d486c857537fc748005a1b389609ca1f91380ce2', 'message': 'Network Data v2 - node ports spec\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}, {'number': 15, 'created': '2020-12-08 11:55:49.000000000', 'files': ['specs/wallaby/triplo-network-data-v2-node-ports.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/93bc0b3faf445deb2ac3526c91f142c95749fcf6', 'message': 'Network Data v2 - node ports spec\n\nPartial-Implements: blueprint network-data-v2-ports\nChange-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96\n'}]",87,760536,93bc0b3faf445deb2ac3526c91f142c95749fcf6,65,13,15,24245,,,0,"Network Data v2 - node ports spec

Partial-Implements: blueprint network-data-v2-ports
Change-Id: Iae721c373f2bbfffa36ed2db9d9af6569e15ed96
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/36/760536/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/triplo-network-data-v2-node-ports.rst'],1,322e39f075320d3e8b483b1141c9d6300b87480e,network-data-v2,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Network Data v2 - node ports ============================ With ""Network Data v2"" the goal is to move management of network resources out of the heat stack. The schema spec [1]_ talked about the `network_data.yaml` format and managing networks, segments and subnets. This spec follows up with node ports for composable networks. Problem description =================== Applying a network change on day 2, currently requires a full stack update since network resources such as ports are managed by heat. It has also been problematic to creating ports for large scale deployments, neutron on the single node undercloud get's overwhelmed and it is difficult to throttle port creation in Heat. Proposed Change =============== Extend the baremetal provisioning workflow that runs before overcloud deployment to also create ports for composable networks. The baremetal provisioning step already create ports for the provisioning network. Moving the management of ports for composable networks to this workflow will consolidate all port management into one workflow. Also make baremetal provisioning workflow execute the tripleo-ansible ``tripleo_network_config`` role to configure node networking after node provisioning. The deploy workflow would be: #. Operator deploys composable networks #. Operator deploys baremetal nodes (This also configured networking on the nodes using ansible role to apply network config with os-net-config [2]_) #. Operator deploys heat stack #. Operator executes config-download to install and configure openstack on the overcloud nodes. Implementation ============== Assignee(s) ----------- Primary assignee: Harald Jenss <hjensas@redhat.com> Approver(s) ----------- Primary approver: TODO Implementation Details ---------------------- The baremetal YAML definition will be extended, adding the ``networks`` and the ``network_config`` keys in role ``defaults`` as well as per-instance to support ``fixed_ip`` addressing, manually pre-created port resource and per-node network configuration template. The workflow will create neutron ports based on the YAML definition and store a network to neutron port uuid in the ironic node ``extra`` field, as shown in the example below. .. code-block:: json {""tripleo_networks"": { ""External"": ""e98a6954-e8a6-4ecb-8916-f123a3eb1e58"", ""InternalApi"": ""776d3eb4-07ef-42ba-8926-7e44703d0628"", ""Tenant"": ""bb655427-8e8d-4d65-b2ca-f793bb501c82""}} Additionally the neutron port's will have be tagged with the ironic node id, as shown in the example below. .. code-block:: json { ""port"": { ""name"": ""controller-1-External"", ""tags"": [""tripleo_node=<IRONIC_NODE_UUID>""], } } For the **pre-deployed** servers scenario there is no Ironic node to update, nor is there a UUID to add to a port's tags. **TODO(hjensas)** Need to spec out how to manage this scenario. Example with defaults properties ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ .. code-block:: yaml - name: Controller count: 1 hostname_format: controller-%index% defaults: profile: control network_config: templates/multiple_nics/multiple_nics.j2 networks: - network: External subnet: external_subnet - network: InternalApi subnet: internal_api_subnet - network: Storage subnet: storage_subnet - network: StorageMgmt subnet: storage_mgmt_subnet - network: Tenant subnet: tenant_subnet - name: Compute count: 1 hostname_format: compute-%index% defaults: profile: compute network_config: templates/multiple_nics/multiple_nics.j2 networks: - network: InternalApi subnet: internal_api_subnet - network: Tenant subnet: tenant_subnet - network: Storage subnet: storage_subnet Example with per-instance overrides ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ .. code-block:: yaml - name: Controller count: 1 hostname_format: controller-%index% defaults: profile: control network_config: templates/multiple_nics/multiple_nics.j2 networks: - network: External subnet: external_subnet - network: InternalApi subnet: internal_api_subnet - network: Storage subnet: storage_subnet - network: StorageMgmt subnet: storage_mgmt_subnet - network: Tenant subnet: tenant_subnet instances: - hostname: controller-0 name: node00 nics: - subnet: ctlplane-subnet networks: InternalApi: fixed_ip: 172.21.11.100 - hostname: controller-1 name: node01 networks: External: port: controller-1-external - hostname: controller-2 name: node02 - name: ComputeLeaf1 count: 1 hostname_format: compute-leaf1-%index% defaults: profile: compute-leaf1 networks: - network: InternalApi subnet: internal_api_subnet - network: Tenant subnet: tenant_subnet - network: Storage subnet: storage_subnet instances: - hostname: overcloud-compute-leaf1-0 name: node03 nics: - subnet: ctlplane-leaf1 network_config: templates/multiple_nics/multiple_nics_dpdk.j2 networks: - network: InternalApi fixed_ip: 172.21.12.105 - network: Tenant port: overcloud-compute-leaf1-0-tenant - network: Storage subnet: storage_subnet Work Items ---------- #. Write ansible inventory after baremetal provisioning Create an ansible inventory, a subset of the inventory currently created by config-download. The ansible inventory is required to apply network configuration to the deployed nodes. #. Extend baremetal provisioning workflow to create neutron ports and update the ironic node ``extra`` field with the ``tripleo_networks`` map. #. The baremetal provisioning workflow need a *pre-deployed-server* option that cause it to not deploy baremetal nodes, only create network ports. When this option is used a YAML describing the already provisioned nodes must be provided. #. Apply and validate network configuration using the **triple-ansible** ``tripleo_network_config`` ansible role. #. Disable and remove management of composable network ports in tripleo-heat-templates. Testing ======= Multinode OVB CI job's with network-isolation will be updated to test the new workflow. Documentation Impact ==================== The documentation effort is **heavy** and will need to be incrementally updated. As a minumum, a separate page explaining the new process must be created. The TripleO docs will need updates in many sections, including: * `TripleO OpenStack Deployment <https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/deployment/install_overcloud.html>`_ * `Provisioning Baremetal Before Overcloud Deploy <https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#>`_ * `Deploying with Custom Networks <https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/custom_networks.html>`_ * `Configuring Network Isolation <https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/network_isolation.html>`_ * `Deploying Overcloud with L3 routed networking <https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/routed_spine_leaf_network.html>`_ Alternatives ============ #. **Not changing how ports are created** In this case we keep creating the ports with heat, the do notghing alternative. #. **Create a completely separate workflow for composable network ports** A separate workflow that can run before/after node provisioning. It can read the same YAML format as baremetal provisioning, or it can have it's own YAML format. The problem with this approach is that we loose the possibility to store relations between neutron-port and baremetal node in a database. As in, we'd need our own database (a file) maintaining the relationships. .. Note:: We need to implement this workflow anyway for a pre-deployed server scenario, but instead of a completely separate workflow the baremetal deploy workflow can take an option to not provision nodes. #. **Create ports in ironic and bind neutron ports** Instead of adding the relation between node <-> network-port in the ironic nodes ``extra`` field, create ports for the ironic nodes. The issue that ironic does not have a concept of virtual port's, so we would have to either add this support in ironic, switch TripleO to use neutron trunk ports or create *fake* ironic ports that don't actually reflect NICs on the baremetal node. (This abandoned ironic spec [3]_ discuss one approach for virtual port support, but it was abandoned in favor of neutron trunk ports.) With the, every PTG, re-occuring suggestion to replace neutron with a more light weight IPAM solution the effort to actually integrate properly with ironic/neutron for composable networks probably is'nt well spent time. References ========== .. [1] `Review: Spec for network data v2 format <https://review.opendev.org/752437>`_. .. [2] `os-net-config <https://opendev.org/openstack/os-net-config>`_. .. [3] `Abandoned spec for VLAN Aware Baremetal Instances <https://review.opendev.org/277853>`_. ",,288,0
openstack%2Ftripleo-specs~master~If98bcd9f52c86e4d7268df8736380b3ad2e10628,openstack/tripleo-specs,master,If98bcd9f52c86e4d7268df8736380b3ad2e10628,Add spec for AWX integration.,ABANDONED,2019-12-13 01:43:20.000000000,2021-01-04 15:38:41.000000000,,"[{'_account_id': 1955}, {'_account_id': 6816}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 9061}, {'_account_id': 9979}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-13 01:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/fa3e8299387f7f1ba8794edfb16d0316fb1afd2d', 'message': 'Add spec for AWX integration.\n\nThis outlines how optional AWX support can be added to TripleO to help with scaling.\nTripleO will support communicating with the AWX API to manage distributed Ansible Jobs\nthat will run across many AWX instances. This will help lower the strain on the\nUndercloud node and increase performance for Overcloud deployments.\n\nChange-Id: If98bcd9f52c86e4d7268df8736380b3ad2e10628\nSigned-off-by: Luke Short <ekultails@gmail.com>\n'}, {'number': 2, 'created': '2019-12-13 01:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/39320c98bb79d49a068ef3d5fd6ced0373e47183', 'message': 'Add spec for AWX integration.\n\nThis outlines how optional AWX support can be added to TripleO to\nhelp with scaling. TripleO will support communicating with the AWX\nAPI to manage distributed Ansible Jobs that will run across many\nAWX instances. This will help lower the strain on the Undercloud\nnode and increase performance for Overcloud deployments.\n\nChange-Id: If98bcd9f52c86e4d7268df8736380b3ad2e10628\nSigned-off-by: Luke Short <ekultails@gmail.com>\n'}, {'number': 3, 'created': '2020-01-16 21:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/552671962eee4c6935525474cc1bea6b4209ad0e', 'message': 'Add spec for AWX integration.\n\nThis outlines how optional AWX support can be added to TripleO to\nhelp with scaling. TripleO will support communicating with the AWX\nAPI to manage distributed Ansible Jobs that will run across many\nAWX instances. This will help lower the strain on the Undercloud\nnode and increase performance for Overcloud deployments.\n\nChange-Id: If98bcd9f52c86e4d7268df8736380b3ad2e10628\nSigned-off-by: Luke Short <ekultails@gmail.com>\n'}, {'number': 4, 'created': '2020-02-18 17:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/687f8a9b445c596fa23a58fc13349bda5255a5d1', 'message': 'Add spec for AWX integration.\n\nThis outlines how optional AWX support can be added to TripleO to\nhelp with scaling. TripleO will support communicating with the AWX\nAPI to manage distributed Ansible Jobs that will run across many\nAWX instances. This will help lower the strain on the Undercloud\nnode and increase performance for Overcloud deployments.\n\nChange-Id: If98bcd9f52c86e4d7268df8736380b3ad2e10628\nSigned-off-by: Luke Short <ekultails@gmail.com>\n'}, {'number': 5, 'created': '2020-02-18 17:09:14.000000000', 'files': ['specs/victoria/awx-integration.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/b3d62cdc853094f9ece41041a4d0400af3d0507e', 'message': 'Add spec for AWX integration.\n\nThis outlines how optional AWX support can be added to TripleO to\nhelp with scaling. TripleO will support communicating with the AWX\nAPI to manage distributed Ansible Jobs that will run across many\nAWX instances. This will help lower the strain on the Undercloud\nnode and increase performance for Overcloud deployments.\n\nChange-Id: If98bcd9f52c86e4d7268df8736380b3ad2e10628\nSigned-off-by: Luke Short <ekultails@gmail.com>\n'}]",6,698828,b3d62cdc853094f9ece41041a4d0400af3d0507e,17,9,5,25877,,,0,"Add spec for AWX integration.

This outlines how optional AWX support can be added to TripleO to
help with scaling. TripleO will support communicating with the AWX
API to manage distributed Ansible Jobs that will run across many
AWX instances. This will help lower the strain on the Undercloud
node and increase performance for Overcloud deployments.

Change-Id: If98bcd9f52c86e4d7268df8736380b3ad2e10628
Signed-off-by: Luke Short <ekultails@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/28/698828/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/awx-integration.rst'],1,fa3e8299387f7f1ba8794edfb16d0316fb1afd2d,awx_support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============== AWX Integration =============== AWX provides a supported platform for distributing and scaling Ansible execution. TripleO can add better support for migrating data into AWX and using it to run Ansible playbooks on a large scale of Overcloud nodes. Problem Description =================== Currently, Ansible is limited to only running on a single Undercloud. The recent scale work regarding Minion nodes does not apply to Ansible. The resource allocation of the primary Undercloud is the limiting factor in Ansible's scale. There are situations where the Undercloud can not be upgraded and/or an operator already has a functional AWX cluster for automating their infrastructure at scale. In these situations, having tight integration between TripleO and AWX would help operators manage deployments in a faster and more reliable manner. Proposed Change =============== Overview -------- AWX is a platform designed to distribute Ansible execution across many different nodes. It exposes an API interface for managing Ansible resources. Additionally, it has other features such as expanded logging settings. Typically it will grab playbooks and roles from a SCM source such as a git repository. TripleO can leverage the strengths of AWX for helping with executing tasks on a large amount of nodes. TripleO already manages the config-download playbooks in a git repository. That repository will be expanded to include all Ansible content so that it becomes more portable. This includes all of the roles and libraries in ``/usr/share/ansible`` installed by the tripleo-ansible package. AWX can also load the dynamic inventory script from the Undercloud. Unlike Minion nodes, AWX instances can be used for other daily operational automation tasks when the Overcloud is not being used. They are designed to be highly-available and always running. For the deployment, AWX instances have to be on the control plane network. Dedicated AWX instances can optionally be created as an Isolated Group that is dedicated to only running Ansible playbooks Jobs relating to the deployment. The addition of better AWX integration is completely optional to the operator and not used by default. It will not be a mandatory requirement for TripleO. Alternatives ------------ `Mitogen <https://mitogen.networkgenomics.com/>`__ is an upstream community project for helping to speed up and distribute Ansible executions. The downside to this would be that this is more of an internal dependency that we would have to maintain and take ownership for. AWX provides an external dependency. Security Impact --------------- Exporting all of the Ansible content to a single directory and allowing it to be distributed may expose sensitive details such as service account passwords. The use of Ansible Vault will be used to encrypt those types of files. Operators are encourged to use a SCM such as git to store their content. Even with files encrypted, there is always the possibility of them being downloaded from the SCM and cracked. Ideally operators will use internal SCM repositories with least-privilege access to them. Ultimately, the operator assumes more responsibility for handling their sensistive information regarding their deployment. Upgrade Impact -------------- Ansible content stored in AWX will need to be updated whenever the Overcloud goes through an update or upgrade. Performance Impact ------------------ Performance will scale along with the number of AWX instances in the cluster. Developer Impact ---------------- Scale testing Ansible can be more easily executed and have better logging. Implementation ============== Assignee(s) ----------- Primary assignee: Luke Short <lshort@redhat.com> Work Items ---------- * Expand the export function of all Ansible/config-download resources. * This includes bundling: playbooks, roles, plugins, and modules. * Add the functionality to automatically push that git repository to a remote source such as GitLab or GitHub. * Add a way to run the tripleo-ansible-inventory dynamic inventory script remotely from AWX. * Add the functionality to communicate to the AWX API to CRUD Jobs and Inventory relating to the Overcloud. * The existing `awx-cli <https://github.com/ansible/awx/tree/devel/awxkit/awxkit/cli/docs>` Python library provides this functionality. Dependencies ============ * The ``awx-cli`` Python utility provides an interface to interact with the AWX API. * This feature requires an external AWX cluster that is not managed by TripleO. Testing ======= A single CI job job will be added to deploy TripleO as a Standalone deployment and AWX as a single node deployment. All the pieces of integration can be tested using that minimal test environment. Documentation Impact ==================== A new guide will be created to explain how to add config-download content into AWX and execute it. References ========== https://docs.ansible.com/ansible-tower/ https://github.com/ansible/awx ",,117,0
openstack%2Fneutron~master~Iefa0044dba9e92592295a79448e5d57d9e14a40b,openstack/neutron,master,Iefa0044dba9e92592295a79448e5d57d9e14a40b,Fix multicast traffic with IGMP snooping enabled,MERGED,2020-12-09 23:17:02.000000000,2021-01-04 15:38:37.000000000,2021-01-04 15:35:25.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-09 23:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b5627f6c4fa7723d9e0366892e94ad79e1e7a23', 'message': 'Fix multicast traffic with IGMP snooping enabled\n\nIn the ML2/OVS when igmp_snooping is enabled but there is no\nexternal querier multicast traffic will stop working after few minutes\nas packets will not be flooded to tunnel/external bridges.\n\nSo this patch sets ""mcast-snooping-disable-flood-unregistered"" option\nof the br-int to False (default value) even when igmp_snooping is\nenabled in the neutron-ovs-agent\'s config file.\n\nAdditionally it configures ""mcast-snooping-flood-reports"" and\n""mcast-snooping-flood"" on patch ports in br-int to True.\n\nThat way we can provide best effort snooping: multicast isolation where\nIGMP queriers are available and flood everywhere else?\n\nCloses-Bug: #1884723\nChange-Id: Iefa0044dba9e92592295a79448e5d57d9e14a40b\n'}, {'number': 2, 'created': '2020-12-10 10:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/326337ed7613f7c996c17f6ee226346fda657056', 'message': 'Fix multicast traffic with IGMP snooping enabled\n\nIn the ML2/OVS when igmp_snooping is enabled but there is no\nexternal querier multicast traffic will stop working after few minutes\nas packets will not be flooded to tunnel/external bridges.\n\nSo this patch sets ""mcast-snooping-disable-flood-unregistered"" option\nof the br-int to False (default value) even when igmp_snooping is\nenabled in the neutron-ovs-agent\'s config file.\n\nAdditionally it configures ""mcast-snooping-flood-reports"" and\n""mcast-snooping-flood"" on patch ports in br-int to True.\n\nThat way we can provide best effort snooping: multicast isolation where\nIGMP queriers are available and flood everywhere else?\n\nCloses-Bug: #1884723\nChange-Id: Iefa0044dba9e92592295a79448e5d57d9e14a40b\n'}, {'number': 3, 'created': '2020-12-15 22:39:28.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/common/ovs_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py', 'neutron/tests/functional/agent/common/test_ovs_lib.py', 'neutron/tests/functional/agent/test_ovs_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4070c975274f53a4a2caaabeb5af55683232d3d', 'message': 'Fix multicast traffic with IGMP snooping enabled\n\nIn the ML2/OVS when igmp_snooping is enabled but there is no\nexternal querier multicast traffic will stop working after few minutes\nas packets will not be flooded to tunnel/external bridges.\n\nSo this patch sets ""mcast-snooping-disable-flood-unregistered"" option\nof the br-int to False (default value) even when igmp_snooping is\nenabled in the neutron-ovs-agent\'s config file.\n\nAdditionally it configures ""mcast-snooping-flood-reports"" and\n""mcast-snooping-flood"" on patch ports in br-int to True.\n\nThat way we can provide best effort snooping: multicast isolation where\nIGMP queriers are available and flood everywhere else?\n\nCloses-Bug: #1884723\nChange-Id: Iefa0044dba9e92592295a79448e5d57d9e14a40b\n'}]",1,766360,b4070c975274f53a4a2caaabeb5af55683232d3d,20,5,3,11975,,,0,"Fix multicast traffic with IGMP snooping enabled

In the ML2/OVS when igmp_snooping is enabled but there is no
external querier multicast traffic will stop working after few minutes
as packets will not be flooded to tunnel/external bridges.

So this patch sets ""mcast-snooping-disable-flood-unregistered"" option
of the br-int to False (default value) even when igmp_snooping is
enabled in the neutron-ovs-agent's config file.

Additionally it configures ""mcast-snooping-flood-reports"" and
""mcast-snooping-flood"" on patch ports in br-int to True.

That way we can provide best effort snooping: multicast isolation where
IGMP queriers are available and flood everywhere else?

Closes-Bug: #1884723
Change-Id: Iefa0044dba9e92592295a79448e5d57d9e14a40b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/766360/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/common/ovs_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py', 'neutron/tests/functional/agent/common/test_ovs_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",5,0b5627f6c4fa7723d9e0366892e94ad79e1e7a23,bug/1884723," dvr_enabled=False, igmp_snooping_enabled=False): mock.call.int_br.set_igmp_snooping_flood( 'int-br-eth', igmp_snooping_enabled), def test_setup_physical_bridges_igmp_snooping_enabled(self): cfg.CONF.set_override('igmp_snooping_enable', True, 'OVS') self._test_setup_physical_bridges(igmp_snooping_enabled=True) mock.call.int_br.set_igmp_snooping_flood( 'int-br-eth', False), mock.patch.object(self.agent.int_br, 'set_igmp_snooping_flood'),\ mock.patch.object(self.agent.int_br, 'set_igmp_snooping_flood'),\", dvr_enabled=False):,53,2
openstack%2Frequirements~master~I5aa1b194f980e5fcdfdd5052d2df334accc025d2,openstack/requirements,master,I5aa1b194f980e5fcdfdd5052d2df334accc025d2,update constraint for os-win to new release 5.4.0,MERGED,2021-01-04 10:23:11.000000000,2021-01-04 15:37:44.000000000,2021-01-04 15:36:02.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-04 10:23:11.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/33ef3a76c72807ef81ee8e5dc7e10e7389ff3f62', 'message': 'update constraint for os-win to new release 5.4.0\n\nmeta: version: 5.4.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Lucian Petrut <lpetrut@cloudbasesolutions.com>\nmeta: release:Commit: Lucian Petrut <lpetrut@cloudbasesolutions.com>\nmeta: release:Change-Id: Ifc0686d216f94569fbf3eb61ad41c46e3c9a31cf\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I5aa1b194f980e5fcdfdd5052d2df334accc025d2\n'}]",0,769121,33ef3a76c72807ef81ee8e5dc7e10e7389ff3f62,10,4,1,11131,,,0,"update constraint for os-win to new release 5.4.0

meta: version: 5.4.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Lucian Petrut <lpetrut@cloudbasesolutions.com>
meta: release:Commit: Lucian Petrut <lpetrut@cloudbasesolutions.com>
meta: release:Change-Id: Ifc0686d216f94569fbf3eb61ad41c46e3c9a31cf
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I5aa1b194f980e5fcdfdd5052d2df334accc025d2
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/769121/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,33ef3a76c72807ef81ee8e5dc7e10e7389ff3f62,new-release,os-win===5.4.0,os-win===5.3.0,1,1
openstack%2Frequirements~stable%2Fvictoria~Id0cb901fff38cbcf5cdfb50e629f454ef4d2e3e9,openstack/requirements,stable/victoria,Id0cb901fff38cbcf5cdfb50e629f454ef4d2e3e9,update constraint for os-apply-config to new release 12.0.0,MERGED,2021-01-04 10:36:06.000000000,2021-01-04 15:36:08.000000000,2021-01-04 15:36:08.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-04 10:36:06.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/cc4466173db2dc8ae63006203e6b2975f0e37b34', 'message': 'update constraint for os-apply-config to new release 12.0.0\n\nmeta: version: 12.0.0\nmeta: diff-start: -\nmeta: series: victoria\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Marios Andreou <marios@redhat.com>\nmeta: release:Commit: Marios Andreou <marios@redhat.com>\nmeta: release:Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1\nmeta: release:Code-Review+1: yatin <ykarel@redhat.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+1: chandan kumar <chkumar@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: Id0cb901fff38cbcf5cdfb50e629f454ef4d2e3e9\n'}]",0,769125,cc4466173db2dc8ae63006203e6b2975f0e37b34,9,4,1,11131,,,0,"update constraint for os-apply-config to new release 12.0.0

meta: version: 12.0.0
meta: diff-start: -
meta: series: victoria
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Marios Andreou <marios@redhat.com>
meta: release:Commit: Marios Andreou <marios@redhat.com>
meta: release:Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1
meta: release:Code-Review+1: yatin <ykarel@redhat.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+1: chandan kumar <chkumar@redhat.com>
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: Id0cb901fff38cbcf5cdfb50e629f454ef4d2e3e9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/25/769125/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,cc4466173db2dc8ae63006203e6b2975f0e37b34,new-release,os-apply-config===12.0.0,os-apply-config===11.3.0,1,1
openstack%2Frequirements~stable%2Fvictoria~Id4d45c6c2e49c9581d174e958161895cd6670805,openstack/requirements,stable/victoria,Id4d45c6c2e49c9581d174e958161895cd6670805,update constraint for tripleo-common to new release 13.1.0,MERGED,2021-01-04 10:47:43.000000000,2021-01-04 15:35:39.000000000,2021-01-04 15:35:39.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-04 10:47:43.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/96d7797d30bebcd68de4d05eab4098ec634cc1c5', 'message': 'update constraint for tripleo-common to new release 13.1.0\n\nmeta: version: 13.1.0\nmeta: diff-start: -\nmeta: series: victoria\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Marios Andreou <marios@redhat.com>\nmeta: release:Commit: Marios Andreou <marios@redhat.com>\nmeta: release:Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1\nmeta: release:Code-Review+1: yatin <ykarel@redhat.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+1: chandan kumar <chkumar@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: Id4d45c6c2e49c9581d174e958161895cd6670805\n'}]",0,769127,96d7797d30bebcd68de4d05eab4098ec634cc1c5,9,4,1,11131,,,0,"update constraint for tripleo-common to new release 13.1.0

meta: version: 13.1.0
meta: diff-start: -
meta: series: victoria
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Marios Andreou <marios@redhat.com>
meta: release:Commit: Marios Andreou <marios@redhat.com>
meta: release:Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1
meta: release:Code-Review+1: yatin <ykarel@redhat.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+1: chandan kumar <chkumar@redhat.com>
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: Id4d45c6c2e49c9581d174e958161895cd6670805
",git fetch https://review.opendev.org/openstack/requirements refs/changes/27/769127/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,96d7797d30bebcd68de4d05eab4098ec634cc1c5,new-release,tripleo-common===13.1.0,tripleo-common===13.0.0,1,1
openstack%2Fopenstack-ansible~stable%2Fvictoria~I52b412339be0ea212f6c1b0c92ac6d6a4421d582,openstack/openstack-ansible,stable/victoria,I52b412339be0ea212f6c1b0c92ac6d6a4421d582,Fix config_template trackbranch,MERGED,2020-12-28 18:49:34.000000000,2021-01-04 15:31:38.000000000,2021-01-04 15:29:59.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-28 18:49:34.000000000', 'files': ['ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b86347c218f49b2906658da88c157e091fa0cd55', 'message': 'Fix config_template trackbranch\n\nChange-Id: I52b412339be0ea212f6c1b0c92ac6d6a4421d582\n'}]",0,768611,b86347c218f49b2906658da88c157e091fa0cd55,14,3,1,28619,,,0,"Fix config_template trackbranch

Change-Id: I52b412339be0ea212f6c1b0c92ac6d6a4421d582
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/11/768611/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible-role-requirements.yml'],1,b86347c218f49b2906658da88c157e091fa0cd55,, trackbranch: master, trackbranch: stable/victoria,1,1
openstack%2Frpm-packaging~master~I3c64aaadd5008b4f1e5dfc6b0ad3f40e810e7863,openstack/rpm-packaging,master,I3c64aaadd5008b4f1e5dfc6b0ad3f40e810e7863,Update oslo.db.spec.j2,MERGED,2020-12-08 02:01:07.000000000,2021-01-04 15:26:30.000000000,2020-12-15 20:09:49.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-08 02:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e54c7fcbca9d6e28e05eb03f7721fcf1c988ad2e', 'message': 'Update oslo.db.spec.j2\n\nChange-Id: I3c64aaadd5008b4f1e5dfc6b0ad3f40e810e7863\n'}, {'number': 2, 'created': '2020-12-15 18:51:47.000000000', 'files': ['openstack/oslo.db/oslo.db.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e3626d5bb396049de6903f14f40e98170b7272a8', 'message': 'Update oslo.db.spec.j2\n\nChange-Id: I3c64aaadd5008b4f1e5dfc6b0ad3f40e810e7863\n'}]",0,765900,e3626d5bb396049de6903f14f40e98170b7272a8,16,5,2,28654,,,0,"Update oslo.db.spec.j2

Change-Id: I3c64aaadd5008b4f1e5dfc6b0ad3f40e810e7863
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/00/765900/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.db/oslo.db.spec.j2'],1,e54c7fcbca9d6e28e05eb03f7721fcf1c988ad2e,,{% set upstream_version = upstream_version('8.5.0') %},{% set upstream_version = upstream_version('8.4.0') %},1,1
openstack%2Fneutron~master~I99e33e8c9a5146dcae3ac9d98aae0284d4d80f20,openstack/neutron,master,I99e33e8c9a5146dcae3ac9d98aae0284d4d80f20,Add script which can clean patch ports between bridges,MERGED,2020-12-08 13:03:40.000000000,2021-01-04 15:23:44.000000000,2021-01-04 15:21:47.000000000,"[{'_account_id': 1955}, {'_account_id': 8313}, {'_account_id': 8655}, {'_account_id': 9373}, {'_account_id': 9845}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-08 13:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/edabc68e4ae91e8214a248fead60e0a7014c8926', 'message': 'Add script which can clean patch ports between bridges\n\nOnce provider bridges are brought up, they should not send any traffic\nto the integration bridge until ovs-agent configures the bridges.\nWhen node is rebooted, patch ports to br-int are preserved because they\nare stored in ovsdb.\n\nThis patch adds script which can removes such patch ports. This script can\nbe used e.g. in some systemd unit files or ifcfg scripts and be run\nduring the node boot process.\n\nCo-authored-by: Jakub Libosvar <jlibosva@redhat.com>\nCo-authored-by: Yatin Karel <ykarel@redhat.com>\nCo-authored-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I99e33e8c9a5146dcae3ac9d98aae0284d4d80f20\n'}, {'number': 2, 'created': '2020-12-10 10:08:02.000000000', 'files': ['neutron/tests/functional/cmd/test_destroy_patch_ports.py', 'neutron/cmd/destroy_patch_ports.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/86f6ea347ac5ae2b966c34843bd2532fd63608b2', 'message': 'Add script which can clean patch ports between bridges\n\nOnce provider bridges are brought up, they should not send any traffic\nto the integration bridge until ovs-agent configures the bridges.\nWhen node is rebooted, patch ports to br-int are preserved because they\nare stored in ovsdb.\n\nThis patch adds script which can removes such patch ports. This script can\nbe used e.g. in some systemd unit files or ifcfg scripts and be run\nduring the node boot process.\n\nCo-authored-by: Jakub Libosvar <jlibosva@redhat.com>\nCo-authored-by: Yatin Karel <ykarel@redhat.com>\nCo-authored-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I99e33e8c9a5146dcae3ac9d98aae0284d4d80f20\n'}]",0,765994,86f6ea347ac5ae2b966c34843bd2532fd63608b2,29,9,2,11975,,,0,"Add script which can clean patch ports between bridges

Once provider bridges are brought up, they should not send any traffic
to the integration bridge until ovs-agent configures the bridges.
When node is rebooted, patch ports to br-int are preserved because they
are stored in ovsdb.

This patch adds script which can removes such patch ports. This script can
be used e.g. in some systemd unit files or ifcfg scripts and be run
during the node boot process.

Co-authored-by: Jakub Libosvar <jlibosva@redhat.com>
Co-authored-by: Yatin Karel <ykarel@redhat.com>
Co-authored-by: Bogdan Dobrelya <bdobreli@redhat.com>
Change-Id: I99e33e8c9a5146dcae3ac9d98aae0284d4d80f20
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/765994/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/cmd/test_destroy_patch_ports.py', 'neutron/cmd/destroy_patch_ports.py']",2,edabc68e4ae91e8214a248fead60e0a7014c8926,add_destroy_patch_ports_script,"# Copyright 2020 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sys from neutron_lib.plugins import utils as p_utils from neutron_lib.utils import helpers from oslo_config import cfg from oslo_log import log as logging from neutron.agent.common import ovs_lib from neutron.common import config as common_config from neutron.conf.agent import common as agent_config from neutron.conf.plugins.ml2.drivers import ovs_conf from neutron.plugins.ml2.drivers.openvswitch.agent.common import constants LOG = logging.getLogger(__name__) def get_patch_port_names(bridge_name): int_if_name = p_utils.get_interface_name( bridge_name, prefix=constants.PEER_INTEGRATION_PREFIX) phys_if_name = p_utils.get_interface_name( bridge_name, prefix=constants.PEER_PHYSICAL_PREFIX) return int_if_name, phys_if_name class PatchPortCleaner(object): def __init__(self, config): LOG.debug(""Get OVS bridge mappings"") mappings = helpers.parse_mappings(config.OVS.bridge_mappings) self.bridges = [ovs_lib.OVSBridge(bridge) for bridge in mappings.values()] self.int_br = ovs_lib.OVSBridge(config.OVS.integration_bridge) def destroy_patch_ports(self): if (not self.int_br.bridge_exists(self.int_br.br_name) or self.flows_configured()): # integration bridge hasn't been created by agent yet or it's been # already configured by the agent return for bridge in self.bridges: try: LOG.debug(""Remove patch port from bridge %s"", bridge.br_name) self._remove_patch_ports_from_int_br(bridge) except Exception as e: LOG.error(""Failed to remove patch port from bridge %s: %s"", bridge.br_name, e) def _remove_patch_ports_from_int_br(self, bridge): int_if_name, phys_if_name = get_patch_port_names( bridge.br_name) int_type = self.int_br.db_get_val( ""Interface"", int_if_name, ""type"", log_errors=False) if int_type == 'patch': self.int_br.delete_port(int_if_name) bridge.delete_port(phys_if_name) def flows_configured(self): """"""Return True if the integration bridge has flows already configured. """""" LOG.debug(""Get configured flows for integration bridge %s"", self.int_br.br_name) return bool(self.int_br.dump_flows_for(table=constants.CANARY_TABLE)) def main(): common_config.init(sys.argv[1:]) ovs_conf.register_ovs_agent_opts() common_config.setup_logging() agent_config.setup_privsep() port_cleaner = PatchPortCleaner(cfg.CONF) port_cleaner.destroy_patch_ports() if __name__ == ""__main__"": main() ",,183,0
openstack%2Fcharm-openstack-dashboard~master~I9b36331127e474440358f98dcced80751836dfa2,openstack/charm-openstack-dashboard,master,I9b36331127e474440358f98dcced80751836dfa2,Charm helper sync for Bug 1898032,MERGED,2020-11-28 12:12:13.000000000,2021-01-04 15:12:56.000000000,2021-01-04 15:12:56.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 12:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/f639a76cc64da6ea24e7ec10b59e30eacb92f79a', 'message': 'Charm helper sync for Bug 1898032\n\nCharm helper sync to bring in fixes for Bug #1898032\n\nChange-Id: I9b36331127e474440358f98dcced80751836dfa2\nCloses-Bug: #1898032\n'}, {'number': 2, 'created': '2020-12-01 08:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/6f89477cb486d0b62fc8630b2c1d69a1d6688c76', 'message': 'Charm helper sync for Bug 1898032\n\nCharm helper sync to bring in fixes for Bug #1898032\n\nChange-Id: I9b36331127e474440358f98dcced80751836dfa2\nCloses-Bug: #1898032\n'}, {'number': 3, 'created': '2021-01-04 13:43:51.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/contrib/hahelpers/apache.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/8eb0864696ec09da13a36ad0ffd5f6ccd98fdacb', 'message': 'Charm helper sync for Bug 1898032\n\nCharm helper sync to bring in fixes for Bug #1898032\n\nChange-Id: I9b36331127e474440358f98dcced80751836dfa2\nCloses-Bug: #1898032\n'}]",0,764551,8eb0864696ec09da13a36ad0ffd5f6ccd98fdacb,15,4,3,12549,,,0,"Charm helper sync for Bug 1898032

Charm helper sync to bring in fixes for Bug #1898032

Change-Id: I9b36331127e474440358f98dcced80751836dfa2
Closes-Bug: #1898032
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/51/764551/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/hahelpers/apache.py', 'charmhelpers/contrib/openstack/cert_utils.py']",10,f639a76cc64da6ea24e7ec10b59e30eacb92f79a,bug/1898032,"from base64 import b64decode remote_service_name, INFO, ADDRESS_MAP, get_default_api_bindings, ) from charmhelpers.contrib.network.ip import ( get_relation_ip, ) CA_CERT_DIR, install_ca_cert, CONFIG_CA_CERT_FILE,def get_certificate_request(json_encode=True, bindings=None): """"""Generate a certificate requests based on the network configuration :param json_encode: Encode request in JSON or not. Used for setting directly on a relation. :type json_encode: boolean :param bindings: List of bindings to check in addition to default api bindings. :type bindings: list of strings :returns: CertRequest request as dictionary or JSON string. :rtype: Union[dict, json] if bindings: # Add default API bindings to bindings list bindings = set(bindings + get_default_api_bindings()) else: # Use default API bindings bindings = get_default_api_bindings() _sans = get_certificate_sans() # Handle specific hostnames per binding for binding in bindings: hostname_override = config(ADDRESS_MAP[binding]['override']) try: net_addr = resolve_address(endpoint_type=binding) ADDRESS_MAP[binding]['binding']) # Add hostname certificate request if hostname_override: binding, hostname_override, # Remove hostname specific addresses from _sans for addr in addresses: try: _sans.remove(addr) except (ValueError, KeyError): pass ""local address found"".format(binding), WARNING) # Gurantee all SANs are covered # These are network addresses with no corresponding hostname. # Add the ips to the hostname cert to allow for this. req.add_hostname_cn_ip(_sans)def get_certificate_sans(bindings=None): """"""Get all possible IP addresses for certificate SANs. """""" _sans = [unit_get('private-address')] if bindings: # Add default API bindings to bindings list bindings = set(bindings + get_default_api_bindings()) else: # Use default API bindings bindings = get_default_api_bindings() for binding in bindings: # Check for config override try: net_config = config(ADDRESS_MAP[binding]['config']) except KeyError: # There is no configuration network for this binding name net_config = None # Using resolve_address is likely redundant. Keeping it here in # case there is an edge case it handles. net_addr = resolve_address(endpoint_type=binding) ip = get_relation_ip(binding, cidr_network=net_config) _sans = _sans + [net_addr, ip] vip = get_vip_in_network(resolve_network_cidr(ip)) if vip: _sans.append(vip) return set(_sans) # This includes the hostname cert and any specific bindng certs: # admin, internal, public req = get_certificate_request(json_encode=False)[""cert_requests""] # Specific certs for cert_req in req.keys(): requested_cert = os.path.join( ssl_dir, 'cert_{}'.format(cert_req)) requested_key = os.path.join( ssl_dir, 'key_{}'.format(cert_req)) for addr in req[cert_req]['sans']: cert = os.path.join(ssl_dir, 'cert_{}'.format(addr)) key = os.path.join(ssl_dir, 'key_{}'.format(addr)) if os.path.isfile(requested_cert) and not os.path.isfile(cert): os.symlink(requested_cert, cert) os.symlink(requested_key, key) # Handle custom hostnamesdef _manage_ca_certs(ca, cert_relation_id): """"""Manage CA certs. :param ca: CA Certificate from certificate relation. :type ca: str :param cert_relation_id: Relation id providing the certs :type cert_relation_id: str """""" config_ssl_ca = config('ssl_ca') config_cert_file = '{}/{}.crt'.format(CA_CERT_DIR, CONFIG_CA_CERT_FILE) if config_ssl_ca: log(""Installing CA certificate from charm ssl_ca config to {}"".format( config_cert_file), INFO) install_ca_cert( b64decode(config_ssl_ca).rstrip(), name=CONFIG_CA_CERT_FILE) elif os.path.exists(config_cert_file): log(""Removing CA certificate {}"".format(config_cert_file), INFO) os.remove(config_cert_file) log(""Installing CA certificate from certificate relation"", INFO) install_ca_cert( ca.encode(), name='{}_juju_ca_cert'.format( remote_service_name(relid=cert_relation_id))) _manage_ca_certs(ca, relation_id)"," ADMIN, INTERNAL, PUBLIC, ADDRESS_MAP) install_ca_certdef get_certificate_request(json_encode=True): """"""Generate a certificatee requests based on the network confioguration for net_type in [INTERNAL, ADMIN, PUBLIC]: net_config = config(ADDRESS_MAP[net_type]['override']) try: net_addr = resolve_address(endpoint_type=net_type) ADDRESS_MAP[net_type]['binding']) if net_config: net_type, net_config, else: # There is network address with no corresponding hostname. # Add the ip to the hostname cert to allow for this. req.add_hostname_cn_ip(addresses) ""local address found"".format(net_type), WARNING) # Add links to hostname cert, used if os-hostname vars not set for net_type in [INTERNAL, ADMIN, PUBLIC]: try: addr = resolve_address(endpoint_type=net_type) cert = os.path.join(ssl_dir, 'cert_{}'.format(addr)) key = os.path.join(ssl_dir, 'key_{}'.format(addr)) if os.path.isfile(hostname_cert) and not os.path.isfile(cert): os.symlink(hostname_cert, cert) os.symlink(hostname_key, key) except NoNetworkBinding: log(""Skipping creating cert symlink for ip in {} space, no "" ""local address found"".format(net_type), WARNING) install_ca_cert(ca.encode())",272,52
openstack%2Fnova~master~I6ce930fa86c82da1008089791942b1fff7d04c18,openstack/nova,master,I6ce930fa86c82da1008089791942b1fff7d04c18,Run the db migration tests in the same test worker,MERGED,2020-12-17 17:06:51.000000000,2021-01-04 15:04:24.000000000,2021-01-04 10:55:58.000000000,"[{'_account_id': 9708}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 23157}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-17 17:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89e484436a9cf891835b70c2870d97f9f85227ab', 'message': 'Increase timeout for db migration tests\n\nIn a heavily IO deprived CI VM the db migration tests could take a\nsignificant amount of time and eventually time out. This patch increase\nour timeout value until a final solution is found. For example we hope\nthat [1] will help eventually.\n\n[1] https://review.opendev.org/q/topic:bp/compact-db-migrations-wallaby\n\nChange-Id: I6ce930fa86c82da1008089791942b1fff7d04c18\nRelated-Bug: #1823251\n'}, {'number': 2, 'created': '2020-12-18 12:46:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/800254c0bc1dff5e4d41fb9739c3498d15d81791', 'message': 'Run the db migration tests in the same test worker\n\nIn a heavily IO deprived CI VM the db migration tests could take a\nsignificant amount of time and eventually time out. This patch moves the\ntests into the same test executor worker process to spread the load\ngenerated by these test in time until a final solution is found. For\nexample we hope that [1] will help eventually to decrease the load.\n\n[1] https://review.opendev.org/q/topic:bp/compact-db-migrations-wallaby\n\nChange-Id: I6ce930fa86c82da1008089791942b1fff7d04c18\nRelated-Bug: #1823251\n'}]",0,767590,800254c0bc1dff5e4d41fb9739c3498d15d81791,72,8,2,9708,,,0,"Run the db migration tests in the same test worker

In a heavily IO deprived CI VM the db migration tests could take a
significant amount of time and eventually time out. This patch moves the
tests into the same test executor worker process to spread the load
generated by these test in time until a final solution is found. For
example we hope that [1] will help eventually to decrease the load.

[1] https://review.opendev.org/q/topic:bp/compact-db-migrations-wallaby

Change-Id: I6ce930fa86c82da1008089791942b1fff7d04c18
Related-Bug: #1823251
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/767590/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_migrations.py', 'nova/tests/functional/db/api/test_migrations.py']",2,89e484436a9cf891835b70c2870d97f9f85227ab,bug/1823251,from oslotest import timeout TIMEOUT_SCALING_FACTOR = 2 self.useFixture(timeout.Timeout( scaling_factor=self.TIMEOUT_SCALING_FACTOR)) TIMEOUT_SCALING_FACTOR = 2 self.useFixture(timeout.Timeout( scaling_factor=self.TIMEOUT_SCALING_FACTOR)),,11,1
openstack%2Fpython-novaclient~master~I9dab95fda5902bf9619393eb2c4a22d9f395d65a,openstack/python-novaclient,master,I9dab95fda5902bf9619393eb2c4a22d9f395d65a,Fix a functional test for 'nova agent-list',MERGED,2021-01-03 12:51:15.000000000,2021-01-04 15:02:39.000000000,2021-01-04 15:01:26.000000000,"[{'_account_id': 679}, {'_account_id': 9708}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 32238}]","[{'number': 1, 'created': '2021-01-03 12:51:15.000000000', 'files': ['novaclient/tests/functional/v2/legacy/test_readonly_nova.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1b5f29a3a4cead30c6455d9ecc47850f5e4994e1', 'message': ""Fix a functional test for 'nova agent-list'\n\nThe os-agents APIs have been removed by the following change.\n\n  I9512f605dd2b3b0e88c951ed086250d57056303d\n\nThis patch fixes a gate failure.\nA subsequent patch will make things related to\nthe os-agents APIs deprecated.\n\nChange-Id: I9dab95fda5902bf9619393eb2c4a22d9f395d65a\nCloses-Bug: #1909899\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n""}]",0,769066,1b5f29a3a4cead30c6455d9ecc47850f5e4994e1,10,5,1,7634,,,0,"Fix a functional test for 'nova agent-list'

The os-agents APIs have been removed by the following change.

  I9512f605dd2b3b0e88c951ed086250d57056303d

This patch fixes a gate failure.
A subsequent patch will make things related to
the os-agents APIs deprecated.

Change-Id: I9dab95fda5902bf9619393eb2c4a22d9f395d65a
Closes-Bug: #1909899
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/66/769066/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/tests/functional/v2/legacy/test_readonly_nova.py'],1,1b5f29a3a4cead30c6455d9ecc47850f5e4994e1,bug/1909899," ex = self.assertRaises(exceptions.CommandFailed, self.nova, 'agent-list') self.assertIn( ""This resource is no longer available. "" ""No forwarding address is given. (HTTP 410)"", str(ex)) ex = self.assertRaises(exceptions.CommandFailed, self.nova, 'agent-list', flags='--debug') self.assertIn( ""This resource is no longer available. "" ""No forwarding address is given. (HTTP 410)"", str(ex))"," self.nova('agent-list') self.nova('agent-list', flags='--debug')",10,2
openstack%2Fironic-python-agent-builder~master~I07c3064322357ddb37cb6e8be2f672adcc1a9a0b,openstack/ironic-python-agent-builder,master,I07c3064322357ddb37cb6e8be2f672adcc1a9a0b,Add ironic-ramdisk-base to build general-purpose ramdisks,MERGED,2020-12-16 16:52:53.000000000,2021-01-04 14:53:51.000000000,2021-01-04 14:52:17.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-16 16:52:53.000000000', 'files': ['releasenotes/notes/ironic-ramdisk-base-3bfb9b90ad416891.yaml', 'dib/ironic-ramdisk-base/README.rst', 'dib/ironic-python-agent-ramdisk/element-deps', 'dib/ironic-ramdisk-base/element-deps', 'dib/ironic-ramdisk-base/cleanup.d/99-ramdisk-create'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/094aa37f9084bae4bcc12e9bf8bb151a2d724006', 'message': 'Add ironic-ramdisk-base to build general-purpose ramdisks\n\nShould be usable with the ramdisk deploy interface.\n\nChange-Id: I07c3064322357ddb37cb6e8be2f672adcc1a9a0b\n'}]",0,767376,094aa37f9084bae4bcc12e9bf8bb151a2d724006,14,4,1,10239,,,0,"Add ironic-ramdisk-base to build general-purpose ramdisks

Should be usable with the ramdisk deploy interface.

Change-Id: I07c3064322357ddb37cb6e8be2f672adcc1a9a0b
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/76/767376/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ironic-ramdisk-base-3bfb9b90ad416891.yaml', 'dib/ironic-ramdisk-base/README.rst', 'dib/ironic-python-agent-ramdisk/element-deps', 'dib/ironic-ramdisk-base/element-deps', 'dib/ironic-ramdisk-base/cleanup.d/99-ramdisk-create']",5,094aa37f9084bae4bcc12e9bf8bb151a2d724006,ironic-ramdisk,,,14,3
openstack%2Fopenstack-ansible-os_zun~master~I14168ae45eb19d4fca10f9803ca559332abf7ec8,openstack/openstack-ansible-os_zun,master,I14168ae45eb19d4fca10f9803ca559332abf7ec8,Updated from OpenStack Ansible Tests,MERGED,2020-09-24 16:58:56.000000000,2021-01-04 14:42:39.000000000,2021-01-04 14:41:24.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-09-24 16:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/c1184730ded627e9dfee8f6253a57c3ce456ac1b', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8\n'}, {'number': 2, 'created': '2020-10-01 14:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/dc2c545ed9337472d64eed63f3dcf7f9199953c3', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8\n'}, {'number': 3, 'created': '2020-10-19 09:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/ab8f6fa38d07a6c06df0004c38d7e7ba9571c5f7', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8\n'}, {'number': 4, 'created': '2020-10-29 10:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/1916d683011573f7787b82746615e9e7ce29dd4b', 'message': 'Updated from OpenStack Ansible Tests\n\nDepends-On: https://review.opendev.org/760304\nChange-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8\n'}, {'number': 5, 'created': '2021-01-04 08:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/df343988c034ce1b00da7c9826f7dc6e17c17157', 'message': 'Updated from OpenStack Ansible Tests\n\nDepends-On: https://review.opendev.org/760304\nChange-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8\n'}, {'number': 6, 'created': '2021-01-04 10:17:40.000000000', 'files': ['run_tests.sh', 'tasks/db_setup.yml', 'tasks/service_setup.yml', 'tasks/mq_setup.yml', 'Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/f82044fc5242bd98f7c8f31df86ac156e07f20bf', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8\n'}]",0,754185,f82044fc5242bd98f7c8f31df86ac156e07f20bf,20,3,6,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I14168ae45eb19d4fca10f9803ca559332abf7ec8
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/85/754185/3 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'Vagrantfile']",2,c1184730ded627e9dfee8f6253a57c3ce456ac1b,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""centos8"" do |centos8| centos8.vm.box = ""centos/8"""," config.vm.define ""centos7"" do |centos7| centos7.vm.box = ""centos/7""",3,6
openstack%2Fkolla-ansible~stable%2Fussuri~If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8,openstack/kolla-ansible,stable/ussuri,If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8,docs: add info on adding and removing hosts,MERGED,2021-01-04 10:06:47.000000000,2021-01-04 14:31:56.000000000,2021-01-04 14:30:27.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-04 10:06:47.000000000', 'files': ['doc/source/user/index.rst', 'doc/source/conf.py', 'doc/source/user/adding-and-removing-hosts.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/90d7cc48181fc287f4b601ef9d94f3dfd9b4cf41', 'message': 'docs: add info on adding and removing hosts\n\nForward-ported from Train commit\nI19c7f05b538a7abc9253194bf041c037b1998378.\n\nChange-Id: If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8\n(cherry picked from commit 03b81174cb70bbfe008c77cc058e6ef3391df787)\n'}]",0,768749,90d7cc48181fc287f4b601ef9d94f3dfd9b4cf41,8,3,1,14826,,,0,"docs: add info on adding and removing hosts

Forward-ported from Train commit
I19c7f05b538a7abc9253194bf041c037b1998378.

Change-Id: If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8
(cherry picked from commit 03b81174cb70bbfe008c77cc058e6ef3391df787)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/49/768749/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/index.rst', 'doc/source/conf.py', 'doc/source/user/adding-and-removing-hosts.rst']",3,90d7cc48181fc287f4b601ef9d94f3dfd9b4cf41,,"========================= Adding and removing hosts ========================= This page discusses how to add and remove nodes from an existing cluster. The procedure differs depending on the type of nodes being added or removed, which services are running, and how they are configured. Here we will consider two types of nodes - controllers and compute nodes. Other types of nodes will need consideration. Any procedure being used should be tested before being applied in a production environment. Adding new hosts ================ .. _adding-new-controllers: Adding new controllers ---------------------- The :doc:`bootstrap-servers command </reference/deployment-and-bootstrapping/bootstrap-servers>` can be used to prepare the new hosts that are being added to the system. It adds an entry to ``/etc/hosts`` for the new hosts, and some services, such as RabbitMQ, require entries to exist for all controllers on every controller. If using a ``--limit`` argument, ensure that all controllers are included, e.g. via ``--limit control``. Be aware of the :ref:`potential issues <rebootstrapping>` with running ``bootstrap-servers`` on an existing system. .. code-block:: console kolla-ansible -i <inventory> bootstrap-servers [ --limit <limit> ] Pull down container images to the new hosts. The ``--limit`` argument may be used and only needs to include the new hosts. .. code-block:: console kolla-ansible -i <inventory> pull [ --limit <limit> ] Deploy containers to the new hosts. If using a ``--limit`` argument, ensure that all controllers are included, e.g. via ``--limit control``. .. code-block:: console kolla-ansible -i <inventory> deploy [ --limit <limit> ] The new controllers are now deployed. It is recommended to perform testing of the control plane at this point to verify that the new controllers are functioning correctly. Some resources may not be automatically balanced onto the new controllers. It may be helpful to manually rebalance these resources onto the new controllers. Examples include networks hosted by Neutron DHCP agent, and routers hosted by Neutron L3 agent. The `removing-existing-controllers`_ section provides an example of how to do this. .. _adding-new-compute-nodes: Adding new compute nodes ------------------------ The :doc:`bootstrap-servers command </reference/deployment-and-bootstrapping/bootstrap-servers>`, can be used to prepare the new hosts that are being added to the system. Be aware of the :ref:`potential issues <rebootstrapping>` with running ``bootstrap-servers`` on an existing system. .. code-block:: console kolla-ansible -i <inventory> bootstrap-servers [ --limit <limit> ] Pull down container images to the new hosts. The ``--limit`` argument may be used and only needs to include the new hosts. .. code-block:: console kolla-ansible -i <inventory> pull [ --limit <limit> ] Deploy containers on the new hosts. The ``--limit`` argument may be used and only needs to include the new hosts. .. code-block:: console kolla-ansible -i <inventory> deploy [ --limit <limit> ] The new compute nodes are now deployed. It is recommended to perform testing of the compute nodes at this point to verify that they are functioning correctly. Server instances are not automatically balanced onto the new compute nodes. It may be helpful to live migrate some server instances onto the new hosts. .. code-block:: console openstack server migrate <server> --live-migration --host <target host> --os-compute-api-version 2.30 Alternatively, a service such as :watcher-doc:`Watcher </>` may be used to do this automatically. Removing existing hosts ======================= .. _removing-existing-controllers: Removing existing controllers ----------------------------- When removing controllers or other hosts running clustered services, consider whether enough hosts remain in the cluster to form a quorum. For example, in a system with 3 controllers, only one should be removed at a time. Consider also the effect this will have on redundancy. Before removing existing controllers from a cluster, it is recommended to move resources they are hosting. Here we will cover networks hosted by Neutron DHCP agent and routers hosted by Neutron L3 agent. Other actions may be necessary, depending on your environment and configuration. For each host being removed, find Neutron routers on that host and move them. Disable the L3 agent. For example: .. code-block:: console l3_id=$(openstack network agent list --host <host> --agent-type l3 -f value -c ID) target_l3_id=$(openstack network agent list --host <target host> --agent-type l3 -f value -c ID) openstack router list --agent $l3_id -f value -c ID | while read router; do openstack network agent remove router $l3_id $router --l3 openstack network agent add router $target_l3_id $router --l3 done openstack network agent set $l3_id --disable Repeat for DHCP agents: .. code-block:: console dhcp_id=$(openstack network agent list --host <host> --agent-type dhcp -f value -c ID) target_dhcp_id=$(openstack network agent list --host <target host> --agent-type dhcp -f value -c ID) openstack network list --agent $dhcp_id -f value -c ID | while read network; do openstack network agent remove network $dhcp_id $network --dhcp openstack network agent add network $target_dhcp_id $network --dhcp done Stop all services running on the hosts being removed: .. code-block:: console kolla-ansible -i <inventory> stop --yes-i-really-really-mean-it [ --limit <limit> ] Remove the hosts from the Ansible inventory. Reconfigure the remaining controllers to update the membership of clusters such as MariaDB and RabbitMQ. Use a suitable limit, such as ``--limit control``. .. code-block:: console kolla-ansible -i <inventory> deploy [ --limit <limit> ] Perform testing to verify that the remaining cluster hosts are operating correctly. For each host, clean up its services: .. code-block:: console openstack network agent list --host <host> -f value -c ID | while read id; do openstack network agent delete $id done openstack compute service list --os-compute-api-version 2.53 --host <host> -f value -c ID | while read id; do openstack compute service delete --os-compute-api-version 2.53 $id done .. _removing-existing-compute-nodes: Removing existing compute nodes ------------------------------- When removing compute nodes from a system, consider whether there is capacity to host the running workload on the remaining compute nodes. Include overhead for failures that may occur. Before removing compute nodes from a system, it is recommended to migrate or destroy any instances that they are hosting. For each host, disable the compute service to ensure that no new instances are scheduled to it. .. code-block:: console openstack compute service set <host> nova-compute --disable If possible, live migrate instances to another host. .. code-block:: console openstack server list --host <host> -f value -c ID | while read server; do openstack server migrate --live-migration $server done Verify that the migrations were successful. Stop all services running on the hosts being removed: .. code-block:: console kolla-ansible -i <inventory> stop --yes-i-really-really-mean-it [ --limit <limit> ] Remove the hosts from the Ansible inventory. Perform testing to verify that the remaining cluster hosts are operating correctly. For each host, clean up its services: .. code-block:: console openstack network agent list --host <host> -f value -c ID | while read id; do openstack network agent delete $id done openstack compute service list --os-compute-api-version 2.53 --host <host> -f value -c ID | while read id; do openstack compute service delete --os-compute-api-version 2.53 $id done ",,226,0
openstack%2Fneutron~master~I57433e1d5c1f32a50651b7b505f3ff016c97845c,openstack/neutron,master,I57433e1d5c1f32a50651b7b505f3ff016c97845c,WIP DNM: Don't use in-memory sqlite,ABANDONED,2020-12-03 22:10:27.000000000,2021-01-04 14:30:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-03 22:10:27.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/59f230c7edda40562d4b6d26de8d6fc26de33357', 'message': ""WIP DNM: Don't use in-memory sqlite\n\nIt appears that due to a combination of\nhttps://review.opendev.org/c/openstack/ovsdbapp/+/745746/ and\nhttps://review.opendev.org/c/openstack/neutron/+/750295 lead to\nintermittent failures of test_distributed_lock. It looks possibly\nrelated to the fact that ml2/ovn's Hash Ring implementation ends\nup running queries from the Connection thread while queriers are\nalso run in the main API thread. Ultimately, it looks like the\nnetworks row in standardattributes does not get added to the db\nand create_initial_revision fails with a foreign key constraint\nerror when referencing it.\n\nThis patch forces the connection uri to use sqlite file mode\ninstead.\n\nChange-Id: I57433e1d5c1f32a50651b7b505f3ff016c97845c\n""}]",0,765386,59f230c7edda40562d4b6d26de8d6fc26de33357,3,1,1,5756,,,0,"WIP DNM: Don't use in-memory sqlite

It appears that due to a combination of
https://review.opendev.org/c/openstack/ovsdbapp/+/745746/ and
https://review.opendev.org/c/openstack/neutron/+/750295 lead to
intermittent failures of test_distributed_lock. It looks possibly
related to the fact that ml2/ovn's Hash Ring implementation ends
up running queries from the Connection thread while queriers are
also run in the main API thread. Ultimately, it looks like the
networks row in standardattributes does not get added to the db
and create_initial_revision fails with a foreign key constraint
error when referencing it.

This patch forces the connection uri to use sqlite file mode
instead.

Change-Id: I57433e1d5c1f32a50651b7b505f3ff016c97845c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/765386/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,59f230c7edda40562d4b6d26de8d6fc26de33357,, OS_TEST_DBAPI_ADMIN_CONNECTION=sqlite:///sqlite.db,,1,0
openstack%2Fkolla-ansible~stable%2Fvictoria~If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8,openstack/kolla-ansible,stable/victoria,If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8,docs: add info on adding and removing hosts,MERGED,2021-01-04 10:06:39.000000000,2021-01-04 14:27:13.000000000,2021-01-04 14:24:45.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-04 10:06:39.000000000', 'files': ['doc/source/user/index.rst', 'doc/source/conf.py', 'doc/source/user/adding-and-removing-hosts.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1f11d2f0125b0030bb782b072ca462833433c14b', 'message': 'docs: add info on adding and removing hosts\n\nForward-ported from Train commit\nI19c7f05b538a7abc9253194bf041c037b1998378.\n\nChange-Id: If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8\n(cherry picked from commit 03b81174cb70bbfe008c77cc058e6ef3391df787)\n'}]",0,768748,1f11d2f0125b0030bb782b072ca462833433c14b,8,3,1,14826,,,0,"docs: add info on adding and removing hosts

Forward-ported from Train commit
I19c7f05b538a7abc9253194bf041c037b1998378.

Change-Id: If07b84e0bbdcb7da8dbef87cc8826987f1d11cf8
(cherry picked from commit 03b81174cb70bbfe008c77cc058e6ef3391df787)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/48/768748/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/index.rst', 'doc/source/conf.py', 'doc/source/user/adding-and-removing-hosts.rst']",3,1f11d2f0125b0030bb782b072ca462833433c14b,,"========================= Adding and removing hosts ========================= This page discusses how to add and remove nodes from an existing cluster. The procedure differs depending on the type of nodes being added or removed, which services are running, and how they are configured. Here we will consider two types of nodes - controllers and compute nodes. Other types of nodes will need consideration. Any procedure being used should be tested before being applied in a production environment. Adding new hosts ================ .. _adding-new-controllers: Adding new controllers ---------------------- The :doc:`bootstrap-servers command </reference/deployment-and-bootstrapping/bootstrap-servers>` can be used to prepare the new hosts that are being added to the system. It adds an entry to ``/etc/hosts`` for the new hosts, and some services, such as RabbitMQ, require entries to exist for all controllers on every controller. If using a ``--limit`` argument, ensure that all controllers are included, e.g. via ``--limit control``. Be aware of the :ref:`potential issues <rebootstrapping>` with running ``bootstrap-servers`` on an existing system. .. code-block:: console kolla-ansible -i <inventory> bootstrap-servers [ --limit <limit> ] Pull down container images to the new hosts. The ``--limit`` argument may be used and only needs to include the new hosts. .. code-block:: console kolla-ansible -i <inventory> pull [ --limit <limit> ] Deploy containers to the new hosts. If using a ``--limit`` argument, ensure that all controllers are included, e.g. via ``--limit control``. .. code-block:: console kolla-ansible -i <inventory> deploy [ --limit <limit> ] The new controllers are now deployed. It is recommended to perform testing of the control plane at this point to verify that the new controllers are functioning correctly. Some resources may not be automatically balanced onto the new controllers. It may be helpful to manually rebalance these resources onto the new controllers. Examples include networks hosted by Neutron DHCP agent, and routers hosted by Neutron L3 agent. The `removing-existing-controllers`_ section provides an example of how to do this. .. _adding-new-compute-nodes: Adding new compute nodes ------------------------ The :doc:`bootstrap-servers command </reference/deployment-and-bootstrapping/bootstrap-servers>`, can be used to prepare the new hosts that are being added to the system. Be aware of the :ref:`potential issues <rebootstrapping>` with running ``bootstrap-servers`` on an existing system. .. code-block:: console kolla-ansible -i <inventory> bootstrap-servers [ --limit <limit> ] Pull down container images to the new hosts. The ``--limit`` argument may be used and only needs to include the new hosts. .. code-block:: console kolla-ansible -i <inventory> pull [ --limit <limit> ] Deploy containers on the new hosts. The ``--limit`` argument may be used and only needs to include the new hosts. .. code-block:: console kolla-ansible -i <inventory> deploy [ --limit <limit> ] The new compute nodes are now deployed. It is recommended to perform testing of the compute nodes at this point to verify that they are functioning correctly. Server instances are not automatically balanced onto the new compute nodes. It may be helpful to live migrate some server instances onto the new hosts. .. code-block:: console openstack server migrate <server> --live-migration --host <target host> --os-compute-api-version 2.30 Alternatively, a service such as :watcher-doc:`Watcher </>` may be used to do this automatically. Removing existing hosts ======================= .. _removing-existing-controllers: Removing existing controllers ----------------------------- When removing controllers or other hosts running clustered services, consider whether enough hosts remain in the cluster to form a quorum. For example, in a system with 3 controllers, only one should be removed at a time. Consider also the effect this will have on redundancy. Before removing existing controllers from a cluster, it is recommended to move resources they are hosting. Here we will cover networks hosted by Neutron DHCP agent and routers hosted by Neutron L3 agent. Other actions may be necessary, depending on your environment and configuration. For each host being removed, find Neutron routers on that host and move them. Disable the L3 agent. For example: .. code-block:: console l3_id=$(openstack network agent list --host <host> --agent-type l3 -f value -c ID) target_l3_id=$(openstack network agent list --host <target host> --agent-type l3 -f value -c ID) openstack router list --agent $l3_id -f value -c ID | while read router; do openstack network agent remove router $l3_id $router --l3 openstack network agent add router $target_l3_id $router --l3 done openstack network agent set $l3_id --disable Repeat for DHCP agents: .. code-block:: console dhcp_id=$(openstack network agent list --host <host> --agent-type dhcp -f value -c ID) target_dhcp_id=$(openstack network agent list --host <target host> --agent-type dhcp -f value -c ID) openstack network list --agent $dhcp_id -f value -c ID | while read network; do openstack network agent remove network $dhcp_id $network --dhcp openstack network agent add network $target_dhcp_id $network --dhcp done Stop all services running on the hosts being removed: .. code-block:: console kolla-ansible -i <inventory> stop --yes-i-really-really-mean-it [ --limit <limit> ] Remove the hosts from the Ansible inventory. Reconfigure the remaining controllers to update the membership of clusters such as MariaDB and RabbitMQ. Use a suitable limit, such as ``--limit control``. .. code-block:: console kolla-ansible -i <inventory> deploy [ --limit <limit> ] Perform testing to verify that the remaining cluster hosts are operating correctly. For each host, clean up its services: .. code-block:: console openstack network agent list --host <host> -f value -c ID | while read id; do openstack network agent delete $id done openstack compute service list --os-compute-api-version 2.53 --host <host> -f value -c ID | while read id; do openstack compute service delete --os-compute-api-version 2.53 $id done .. _removing-existing-compute-nodes: Removing existing compute nodes ------------------------------- When removing compute nodes from a system, consider whether there is capacity to host the running workload on the remaining compute nodes. Include overhead for failures that may occur. Before removing compute nodes from a system, it is recommended to migrate or destroy any instances that they are hosting. For each host, disable the compute service to ensure that no new instances are scheduled to it. .. code-block:: console openstack compute service set <host> nova-compute --disable If possible, live migrate instances to another host. .. code-block:: console openstack server list --host <host> -f value -c ID | while read server; do openstack server migrate --live-migration $server done Verify that the migrations were successful. Stop all services running on the hosts being removed: .. code-block:: console kolla-ansible -i <inventory> stop --yes-i-really-really-mean-it [ --limit <limit> ] Remove the hosts from the Ansible inventory. Perform testing to verify that the remaining cluster hosts are operating correctly. For each host, clean up its services: .. code-block:: console openstack network agent list --host <host> -f value -c ID | while read id; do openstack network agent delete $id done openstack compute service list --os-compute-api-version 2.53 --host <host> -f value -c ID | while read id; do openstack compute service delete --os-compute-api-version 2.53 $id done ",,226,0
openstack%2Fmistral~master~I2b1c85803ea60e621b08192ec3644f071a74ebb6,openstack/mistral,master,I2b1c85803ea60e621b08192ec3644f071a74ebb6,Add API docs for code sources and dynamic actions,MERGED,2021-01-04 10:07:35.000000000,2021-01-04 14:26:29.000000000,2021-01-04 14:25:13.000000000,"[{'_account_id': 8731}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 29124}, {'_account_id': 30755}]","[{'number': 1, 'created': '2021-01-04 10:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b826a9d1b0695194fb91876147ae19dbf872f4c7', 'message': 'Add API docs for code sources and dynamic actions\n\nChange-Id: I2b1c85803ea60e621b08192ec3644f071a74ebb6\n'}, {'number': 2, 'created': '2021-01-04 13:24:40.000000000', 'files': ['doc/source/user/rest_api_v2.rst'], 'web_link': 'https://opendev.org/openstack/mistral/commit/4319dbcb361a6b63ba241d4be0f7d684e88455a1', 'message': 'Add API docs for code sources and dynamic actions\n\nChange-Id: I2b1c85803ea60e621b08192ec3644f071a74ebb6\n'}]",2,769119,4319dbcb361a6b63ba241d4be0f7d684e88455a1,12,6,2,8731,,,0,"Add API docs for code sources and dynamic actions

Change-Id: I2b1c85803ea60e621b08192ec3644f071a74ebb6
",git fetch https://review.opendev.org/openstack/mistral refs/changes/19/769119/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/rest_api_v2.rst'],1,b826a9d1b0695194fb91876147ae19dbf872f4c7,dynamic-actions-doc," Code Sources ------------ Code source is a type of entity that holds information about an executable module. Mostly, it was designed to represent as a Python module and this is its main use at the moment. However, it can also be used for other languages in future. Code sources are now used as part of the dynamic actions mechanism. The normal flow is to first upload a code source, i.e. a regular Python file, and then create one ore more dynamic actions using **POST /v2/dynamic-actions** and specifying the name of the action, its class name as it's declared in the source code, and the reference to the source code itself. .. autotype:: mistral.api.controllers.v2.resources.CodeSource :members: .. autotype:: mistral.api.controllers.v2.resources.CodeSources :members: .. rest-controller:: mistral.api.controllers.v2.code_source:CodeSourcesController :webprefix: /v2/code-sources Dynamic Actions --------------- Dynamic action is the type of action that can be created right through the API, without having to reboot Mistral like in other cases. Before adding a dynamic action, a client first needs to upload a code source (i.e. a Python module) that contains the corresponding Python class that implements the action, and then create the action using the method **POST /v2/dynamic-actions** where the name of the action, its class name as it's declared in the code source code, and the reference to the source code itself must be specified. .. autotype:: mistral.api.controllers.v2.resources.DynamicAction :members: .. autotype:: mistral.api.controllers.v2.resources.DynamicActions :members: .. rest-controller:: mistral.api.controllers.v2.dynamic_action:DynamicActionsController :webprefix: /v2/dynamic-actions",,47,0
openstack%2Fkolla-ansible~stable%2Fvictoria~Iec1a8bd9c98dbae03660259468d30ddf8667ff80,openstack/kolla-ansible,stable/victoria,Iec1a8bd9c98dbae03660259468d30ddf8667ff80,Add `issue` reno for bug #1904062,MERGED,2020-12-18 18:53:57.000000000,2021-01-04 14:25:53.000000000,2021-01-04 14:24:06.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-18 18:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e68a6ac57b99ddfa965be488a9c66cf2030f568f', 'message': 'Add `issue` reno for bug #1904062\n\nChange-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80\nRelated-Bug: #1904062\n'}, {'number': 2, 'created': '2020-12-18 19:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/07a98155ecdf0e752a88fc4f4a32dd4709302eba', 'message': 'Add `issue` reno for bug #1904062\n\nChange-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80\nRelated-Bug: #1904062\n'}, {'number': 3, 'created': '2020-12-21 10:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4a9f3f5788883e7c33d9506284ed53d167aa4049', 'message': 'Add `issue` reno for bug #1904062\n\nChange-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80\nRelated-Bug: #1904062\n'}, {'number': 4, 'created': '2020-12-22 18:29:16.000000000', 'files': ['releasenotes/notes/issue-bug-1904062-ef446343323c8452.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/10caf4d36caa23199b1358b056838a9ab3d929b7', 'message': 'Add `issue` reno for bug #1904062\n\nChange-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80\nRelated-Bug: #1904062\n'}]",0,767932,10caf4d36caa23199b1358b056838a9ab3d929b7,16,5,4,30491,,,0,"Add `issue` reno for bug #1904062

Change-Id: Iec1a8bd9c98dbae03660259468d30ddf8667ff80
Related-Bug: #1904062
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/32/767932/4 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/issue-bug-1904062-ef446343323c8452.yaml'],1,e68a6ac57b99ddfa965be488a9c66cf2030f568f,issue-bug/1904062,"--- issues: - | Since Ussuri, there is a bug in how Ceph (RBD) is handled in the Cinder config: ``backend_host`` is missing from the new recommended way to do external Ceph. However, it has been noted that active-active Cinder, that is affected by this omission (single-host ``cinder-volume`` is *not*), should not have been configured with ``backend_host`` in the first place but with ``cluster`` and proper coordination. Some users might have customised their config already to address this issue. The Kolla team is investigating the best way to address this for all its users. In the meantime, please ensure that, before [ deploying / upgrading to ] Ussuri or deploying Victoria, the ``backend_host`` is set to its previous (or arbitrary new in case of new deployments) value via a config override. For more details please refer to the referenced bug. Do note this issue affects both new deployments and upgrades. The symptoms are that the volumes become unmanageable until extra admin action is taken. This does *not* affect the data plane though - running virtual machines are *not* affected. `LP#1904062 <https://bugs.launchpad.net/kolla-ansible/+bug/1904062>`__ ",,22,0
openstack%2Fhorizon~master~I9c75bafc2301f045096b51f433456d1accb12edf,openstack/horizon,master,I9c75bafc2301f045096b51f433456d1accb12edf,Clean up the removed enable_* settings,MERGED,2021-01-02 06:02:28.000000000,2021-01-04 14:09:34.000000000,2021-01-04 14:08:09.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-02 06:02:28.000000000', 'files': ['doc/source/install/install-ubuntu.rst', 'doc/source/install/install-debian.rst', 'doc/source/install/install-obs.rst', 'doc/source/install/install-rdo.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e1a45db30a53490de989f2c293f77412a5f1477', 'message': 'Clean up the removed enable_* settings\n\nOPENSTACK_NEUTRON_NETWORK no longer supports the following settings[1].\n - enable_firewall\n - enable_lb\n - enable_vpn\n\nThis change removes the remanining usage of these settings from\ninstallation guide.\n\n[1] 53a5164d82a7412d10cee634cd0755336f566e24\n\nChange-Id: I9c75bafc2301f045096b51f433456d1accb12edf\n'}]",0,768855,2e1a45db30a53490de989f2c293f77412a5f1477,8,3,1,9816,,,0,"Clean up the removed enable_* settings

OPENSTACK_NEUTRON_NETWORK no longer supports the following settings[1].
 - enable_firewall
 - enable_lb
 - enable_vpn

This change removes the remanining usage of these settings from
installation guide.

[1] 53a5164d82a7412d10cee634cd0755336f566e24

Change-Id: I9c75bafc2301f045096b51f433456d1accb12edf
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/768855/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/install-ubuntu.rst', 'doc/source/install/install-debian.rst', 'doc/source/install/install-obs.rst', 'doc/source/install/install-rdo.rst']",4,2e1a45db30a53490de989f2c293f77412a5f1477,neutron-removed-services,," 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False,",0,12
openstack%2Fneutron~master~I14b326a5162111f4610c9cb864aa69d16476b5b1,openstack/neutron,master,I14b326a5162111f4610c9cb864aa69d16476b5b1,Rename PortNumaAffinityPolicyExtensionTestPlugin,MERGED,2020-12-18 11:44:02.000000000,2021-01-04 13:59:34.000000000,2021-01-04 13:54:39.000000000,"[{'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 11:44:02.000000000', 'files': ['neutron/tests/unit/extensions/test_port_numa_affinity_policy.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/87578a23bca21ab4737d5975311e7ac9e087b507', 'message': 'Rename PortNumaAffinityPolicyExtensionTestPlugin\n\nTrivial-Fix\n\nChange-Id: I14b326a5162111f4610c9cb864aa69d16476b5b1\n'}]",0,767700,87578a23bca21ab4737d5975311e7ac9e087b507,9,3,1,16688,,,0,"Rename PortNumaAffinityPolicyExtensionTestPlugin

Trivial-Fix

Change-Id: I14b326a5162111f4610c9cb864aa69d16476b5b1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/767700/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/extensions/test_port_numa_affinity_policy.py'],1,87578a23bca21ab4737d5975311e7ac9e087b507,rename_PortNumaAffinityPolicyExtensionTestPlugin,"class PortNumaAffinityPolicyExtensionTestPlugin( PortNumaAffinityPolicyExtensionTestPlugin, PortNumaAffinityPolicyExtensionTestPlugin,class PortNumaAffinityPolicyExtensionTestCase( 'policy.PortNumaAffinityPolicyExtensionTestPlugin') super(PortNumaAffinityPolicyExtensionTestCase,","class PortNumaAffinityPolicyExtensionExtensionTestPlugin( PortNumaAffinityPolicyExtensionExtensionTestPlugin, PortNumaAffinityPolicyExtensionExtensionTestPlugin,class PortNumaAffinityPolicyExtensionExtensionTestCase( 'policy.PortNumaAffinityPolicyExtensionExtensionTestPlugin') super(PortNumaAffinityPolicyExtensionExtensionTestCase,",6,6
openstack%2Ftripleo-common~master~Iba5675e37d693664c3b10404c2816f87f294fd6c,openstack/tripleo-common,master,Iba5675e37d693664c3b10404c2816f87f294fd6c,"Revert ""Removed ubi-8 based jobs""",MERGED,2020-12-23 13:52:08.000000000,2021-01-04 13:59:20.000000000,2021-01-04 13:55:07.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-23 13:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5a31f41df3b2c7c55e4a0c1c946bcb35136b7d8e', 'message': 'Revert ""Removed ubi-8 based jobs""\n\nThis reverts commit 4274d92e78af96b6142663bf5667be3002d95757.\n\nChange-Id: Iba5675e37d693664c3b10404c2816f87f294fd6c\n'}, {'number': 2, 'created': '2020-12-23 14:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a27ed504e8b1fdb19fc24656ddae87e358dc5dee', 'message': 'Revert ""Removed ubi-8 based jobs""\n\nThis reverts commit 4274d92e78af96b6142663bf5667be3002d95757.\n\nChange-Id: Iba5675e37d693664c3b10404c2816f87f294fd6c\n'}, {'number': 3, 'created': '2020-12-23 14:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b949b0fb31931150d3c430612a92f3edc22895be', 'message': 'Revert ""Removed ubi-8 based jobs""\n\nThis reverts commit 4274d92e78af96b6142663bf5667be3002d95757.\n\nApparently tripleo-ci-centos-8-content-provider is not sufficient\nin catching bug like https://bugs.launchpad.net/tripleo/+bug/1909105\nSo Here adding the tripleo-ci-build-containers-ubi-8 job\nin check and gate queue.\n\nChange-Id: Iba5675e37d693664c3b10404c2816f87f294fd6c\n'}, {'number': 4, 'created': '2020-12-29 05:56:47.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b316787336af90d5a9594aeaf2eddbade03a9460', 'message': 'Revert ""Removed ubi-8 based jobs""\n\nThis reverts commit 4274d92e78af96b6142663bf5667be3002d95757.\n\nApparently tripleo-ci-centos-8-content-provider is not sufficient\nin catching bug like https://bugs.launchpad.net/tripleo/+bug/1909105\nSo Here adding the tripleo-ci-build-containers-ubi-8 job\nin check and gate queue.\n\nChange-Id: Iba5675e37d693664c3b10404c2816f87f294fd6c\n'}]",4,768269,b316787336af90d5a9594aeaf2eddbade03a9460,41,8,4,20182,,,0,"Revert ""Removed ubi-8 based jobs""

This reverts commit 4274d92e78af96b6142663bf5667be3002d95757.

Apparently tripleo-ci-centos-8-content-provider is not sufficient
in catching bug like https://bugs.launchpad.net/tripleo/+bug/1909105
So Here adding the tripleo-ci-build-containers-ubi-8 job
in check and gate queue.

Change-Id: Iba5675e37d693664c3b10404c2816f87f294fd6c
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/69/768269/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,5a31f41df3b2c7c55e4a0c1c946bcb35136b7d8e,ubi-8-job-voting-gating, - tripleo-build-containers-ubi-8: dependencies: *deps_unit_lint files: - ^container-images/.*$ - ^tripleo_common/image/builder/.*$,,5,0
openstack%2Fneutron~master~Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2,openstack/neutron,master,Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2,"Change the logic of ""catch_exceptions""",MERGED,2020-12-22 17:12:14.000000000,2021-01-04 13:58:06.000000000,2021-01-04 13:54:15.000000000,"[{'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-12-22 17:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd8baad88a065e6f49eea0e98746c38241c39e21', 'message': 'Change the logic of ""catch_exceptions""\n\nChanged the logic of decorator ""catch_exceptions"" to provide a\nPythonic output: if succeeds, returns True; if fails, returns False.\n\nChange-Id: Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2\nStory: #2007686\nTask: #39975\n'}, {'number': 2, 'created': '2020-12-22 17:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4837621d40549f306d99e1e0b84270e892a0bb63', 'message': 'Change the logic of ""catch_exceptions""\n\nChanged the logic of decorator ""catch_exceptions"" to provide a\nPythonic output: if succeeds, returns True; if fails, returns False.\n\nChange-Id: Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2\nStory: #2007686\nTask: #39975\n'}, {'number': 3, 'created': '2020-12-23 14:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae91533fd46673e7c894d430a0e2b60114a273b4', 'message': 'Change the logic of ""catch_exceptions""\n\nChanged the logic of decorator ""catch_exceptions"" to provide a\nPythonic output: if succeeds, returns True; if fails, returns False.\n\nChange-Id: Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2\nStory: #2007686\nTask: #39975\n'}, {'number': 4, 'created': '2020-12-24 16:27:46.000000000', 'files': ['neutron/plugins/ml2/drivers/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/test_linuxbridge_neutron_agent.py', 'neutron/agent/linux/bridge_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9e725ed72ed09c6815fc7c4c901c70bf2bbab24', 'message': 'Change the logic of ""catch_exceptions""\n\nChanged the logic of decorator ""catch_exceptions"" to provide a\nPythonic output: if succeeds, returns True; if fails, returns False.\n\nChange-Id: Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2\nStory: #2007686\nTask: #39975\n'}]",1,768240,b9e725ed72ed09c6815fc7c4c901c70bf2bbab24,22,6,4,16688,,,0,"Change the logic of ""catch_exceptions""

Changed the logic of decorator ""catch_exceptions"" to provide a
Pythonic output: if succeeds, returns True; if fails, returns False.

Change-Id: Idbf2ffb4ef403f343973bde3b3599f9cd3aaddf2
Story: #2007686
Task: #39975
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/768240/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/test_linuxbridge_neutron_agent.py', 'neutron/agent/linux/bridge_lib.py']",3,fd8baad88a065e6f49eea0e98746c38241c39e21,task/39975," """"""Catch bridge command exceptions Returns True if succeeds and False if fails"""""" return True except (RuntimeError, OSError, netlink_exceptions.NetlinkError): return False"," """"""Catch bridge command exceptions and mimic $? output"""""" return 0 except (RuntimeError, OSError, netlink_exceptions.NetlinkError): return 1",30,32
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I88ae631c299f408bdedcb80bd5c04e36fda5a2e1,openstack/tripleo-heat-templates,stable/queens,I88ae631c299f408bdedcb80bd5c04e36fda5a2e1,Add file which enables QoS related L3 agent extensions,MERGED,2020-11-25 11:18:35.000000000,2021-01-04 13:55:01.000000000,2021-01-04 13:55:01.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-25 11:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f816589046420dc08865c7a8c40ec300bb9b55ae', 'message': 'Add file which enables QoS related L3 agent extensions\n\nIt enables extensions like fip_qos and gateway_ip_qos in the\nL3 agent.\n\nRelated-Bug: #1900357\n\nChange-Id: I88ae631c299f408bdedcb80bd5c04e36fda5a2e1\n(cherry picked from commit d910b9486e31bc50d72d671c3c078585e689efd0)\n'}, {'number': 2, 'created': '2020-12-09 22:48:12.000000000', 'files': ['ci/environments/neutron_l3_qos.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4864c82738da6c8a785cf6a9772b97fef505d841', 'message': 'Add file which enables QoS related L3 agent extensions\n\nIt enables extensions like fip_qos and gateway_ip_qos in the\nL3 agent.\n\nRelated-Bug: #1900357\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/766336/\n\nChange-Id: I88ae631c299f408bdedcb80bd5c04e36fda5a2e1\n(cherry picked from commit d910b9486e31bc50d72d671c3c078585e689efd0)\n'}]",2,764095,4864c82738da6c8a785cf6a9772b97fef505d841,21,3,2,11975,,,0,"Add file which enables QoS related L3 agent extensions

It enables extensions like fip_qos and gateway_ip_qos in the
L3 agent.

Related-Bug: #1900357

Depends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/766336/

Change-Id: I88ae631c299f408bdedcb80bd5c04e36fda5a2e1
(cherry picked from commit d910b9486e31bc50d72d671c3c078585e689efd0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/95/764095/2 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/neutron_l3_qos.yaml'],1,f816589046420dc08865c7a8c40ec300bb9b55ae,bug/1900357-stable/victoria-stable/ussuri-stable/train-stable/stein-stable/rocky-stable/queens,"parameter_defaults: NeutronL3AgentExtensions: 'fip_qos,gateway_ip_qos,port_forwarding' ",,2,0
openstack%2Fpuppet-neutron~master~I85a4526f24a2c0b4a4f8f8659dcbe8c05cfde197,openstack/puppet-neutron,master,I85a4526f24a2c0b4a4f8f8659dcbe8c05cfde197,Disable neutron_tempest_plugin in TripleO job,ABANDONED,2021-01-03 22:17:16.000000000,2021-01-04 13:45:55.000000000,,"[{'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 22:17:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/18c3fd2b04a4a998df15ec894e8922baf7b9df41', 'message': 'Disable neutron_tempest_plugin in TripleO job\n\n... because one of its jobs is constantly failing in gate now.\n\nChange-Id: I85a4526f24a2c0b4a4f8f8659dcbe8c05cfde197\nRelated-Bug: #1909008\n'}]",0,769071,18c3fd2b04a4a998df15ec894e8922baf7b9df41,5,2,1,9816,,,0,"Disable neutron_tempest_plugin in TripleO job

... because one of its jobs is constantly failing in gate now.

Change-Id: I85a4526f24a2c0b4a4f8f8659dcbe8c05cfde197
Related-Bug: #1909008
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/71/769071/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,18c3fd2b04a4a998df15ec894e8922baf7b9df41,bug/1909008,, - 'neutron_tempest_plugin.api',0,1
openstack%2Fnova-specs~master~Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3,openstack/nova-specs,master,Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3,Re-proposes 'Proposal for a safer remote console with password authentication,MERGED,2020-10-27 08:03:21.000000000,2021-01-04 13:26:44.000000000,2020-11-23 16:14:11.000000000,"[{'_account_id': 136}, {'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2020-10-27 08:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2fa4f1051ad92f53bd66470a22a819fceb072bea', 'message': ""Re-proposes 'Proposal for a safer remote console with password authentication\n\nThe feature aims at providing a safer remote console with password\nauthentication. End users can set console password for their instances.\nAny user trying to access the password-encrypted console of instance\nwill get a locked window from web console prompting for ``password``\ninput, and this provides almost the same experience as using VNC clients\n(e.g vncviewer) to access vnc servers that require password\nauthentication.\n\nChange-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3\nPreviously-Approved: Victoria\nPartially-Implements: blueprint nova-support-webvnc-with-password-anthentication\n""}, {'number': 2, 'created': '2020-10-27 08:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5cef0313000504549b7ec6425ac80821ae5c24a8', 'message': ""Re-proposes 'Proposal for a safer remote console with password authentication\n\nThe feature aims at providing a safer remote console with password\nauthentication. End users can set console password for their instances.\nAny user trying to access the password-encrypted console of instance\nwill get a locked window from web console prompting for ``password``\ninput, and this provides almost the same experience as using VNC clients\n(e.g vncviewer) to access vnc servers that require password\nauthentication.\n\nPreviously-Approved: Victoria\nPartially-Implements: blueprint nova-support-webvnc-with-password-anthentication\n\nChange-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3\n""}, {'number': 3, 'created': '2020-10-28 07:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5829309db10ec128e6485076b5e18d78ec4c265e', 'message': ""Re-proposes 'Proposal for a safer remote console with password authentication\n\nThe feature aims at providing a safer remote console with password\nauthentication. End users can set console password for their instances.\nAny user trying to access the password-encrypted console of instance\nwill get a locked window from web console prompting for ``password``\ninput, and this provides almost the same experience as using VNC clients\n(e.g vncviewer) to access vnc servers that require password\nauthentication.\n\nPreviously-Approved: Victoria\nPartially-Implements: blueprint nova-support-webvnc-with-password-anthentication\n\nChange-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3\n""}, {'number': 4, 'created': '2020-10-28 08:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/71aecdf7811c0d6d8d41df071f6e33d75c991a73', 'message': ""Re-proposes 'Proposal for a safer remote console with password authentication\n\nThe feature aims at providing a safer remote console with password\nauthentication. End users can set console password for their instances.\nAny user trying to access the password-encrypted console of instance\nwill get a locked window from web console prompting for ``password``\ninput, and this provides almost the same experience as using VNC clients\n(e.g vncviewer) to access vnc servers that require password\nauthentication.\n\nPreviously-Approved: Victoria\nPartially-Implements: blueprint nova-support-webvnc-with-password-anthentication\n\nChange-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3\n""}, {'number': 5, 'created': '2020-10-28 09:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f3481b8ecef1781e53cf722a75c14952d3f74f59', 'message': ""Re-proposes 'Proposal for a safer remote console with password authentication\n\nThe feature aims at providing a safer remote console with password\nauthentication. End users can set console password for their instances.\nAny user trying to access the password-encrypted console of instance\nwill get a locked window from web console prompting for ``password``\ninput, and this provides almost the same experience as using VNC clients\n(e.g vncviewer) to access vnc servers that require password\nauthentication.\n\nPreviously-Approved: Victoria\nPartially-Implements: blueprint nova-support-webvnc-with-password-anthentication\n\nChange-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3\n""}, {'number': 6, 'created': '2020-11-19 00:42:23.000000000', 'files': ['specs/wallaby/approved/nova-support-webvnc-with-password-anthentication.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/39f671018cc163c35746469f1ba250b9f93f218a', 'message': ""Re-proposes 'Proposal for a safer remote console with password authentication\n\nThe feature aims at providing a safer remote console with password\nauthentication. End users can set console password for their instances.\nAny user trying to access the password-encrypted console of instance\nwill get a locked window from web console prompting for ``password``\ninput, and this provides almost the same experience as using VNC clients\n(e.g vncviewer) to access vnc servers that require password\nauthentication.\n\nPreviously-Approved: Victoria\nPartially-Implements: blueprint nova-support-webvnc-with-password-anthentication\n\nChange-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3\n""}]",45,759828,39f671018cc163c35746469f1ba250b9f93f218a,35,8,6,26458,,,0,"Re-proposes 'Proposal for a safer remote console with password authentication

The feature aims at providing a safer remote console with password
authentication. End users can set console password for their instances.
Any user trying to access the password-encrypted console of instance
will get a locked window from web console prompting for ``password``
input, and this provides almost the same experience as using VNC clients
(e.g vncviewer) to access vnc servers that require password
authentication.

Previously-Approved: Victoria
Partially-Implements: blueprint nova-support-webvnc-with-password-anthentication

Change-Id: Ifaad40483a1ba5ec0600348585ff14fb6d8c7fe3
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/28/759828/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/approved/nova-support-webvnc-with-password-anthentication.rst'],1,2fa4f1051ad92f53bd66470a22a819fceb072bea,bp/nova-support-webvnc-with-password-anthentication,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================= Nova provides remote console with password anthentication ========================================================= https://blueprints.launchpad.net/nova/+spec/nova-support-webvnc-with-password-anthentication The feature aims at providing a safer remote console with password authentication. End users can set console password for their instances. Any user trying to access the password-encrypted console of instance will get a locked window from web console prompting for ``password`` input, and this provides almost the same experience as using VNC clients (e.g vncviewer) to access vnc servers that require password authentication. Problem description =================== There is only a token authentication against nova novncproxy, with the ``token`` parameter appended to the request access_url. While this is convenient, anyone who (e.g. A cloud administrator with too much curiosity about tenants' business) gets the access_url info will have access to operating the instance by the web console directly, which is not that safe. Now an implementation for remote console with password authentication will prevent malicious users from using the instance when failing to pass password authentication, even if they had got the access_url. Use Cases --------- The end user can set a remote console password to avoid the console access url stolen by other user. And end user can reset console password when he forgets. Proposed change =============== * Changes will be patched to python-novaclient (``nova get-*-console`` subcommand) and equivalent in python-openstackclient to provide ``--password`` for reseting remote console password. * Changes will be patched to nova-api when creating remote console: Extra logic will be added to handle both cases(console password provided, and not). If password is not provided, we see it as the existing ``Create Remote Console`` operation, then it jumps to old logic. Or we know it's a request to reset password for ``Remote Console``, and RPC call will be sent to compute service to reset console password. * Changes will be patched to nova-compute and virt driver to handle ``Reset Remote Console Password`` request. And this's only implment for libvirt driver. For other virt drivers, NotImplement will raise. * Changes will be patched to nova-novncproxy: auth schemes(e.g:rfb.VNC) will be added. For the fact that project ``noVNC`` has already provided native support for password authentication(RFB version negotiation, handshakes and password authentication), so rfb.VNC can escape from these jobs. Alternatives ------------ New booting parameter ``console_pasword`` will be added to launch instances. And the password will be used to assemble ``graphics`` tag in libvirt XML. In this way, password-encrypted remote console will be implemented. The shortcoming of this implement is that no API provided to reset console password after instance is booted. Data model impact ----------------- None REST API impact --------------- New microversion will be added to provide extra ``password`` parameter for the Create Remote Console API. URL: /servers/{server_id}/remote-consoles * Request method: POST(update password for remote console) Add ``password`` param to the request body * Update the Create-Remote-Console API: .. code-block:: json { ""remote_console"": { ""protocol"": ""vnc"", ""type"": ""novnc"", ""password"": ""newpass"" } } The ``password`` is in common password format (not more than 8 characters, see `vnc security`_). The ``password`` parameter is optional: - If ``password`` is present, console password will be updated while getting new access_url. - Only `vnc` and `spice` console protols/types support reseting password. If both ``password`` and (``protocol``, ``type``) are provided, and protocol/type not in support list ``HttpBadRequest 400`` will be returned. - And for unsupported virt driver, `HttpNotImplemented 501` will be returned. Security impact --------------- Surely it will make web console safer. And note that console password will only be securely kept by libvirtd and won't be displayed in the result of ``virsh dumpxml <instance UUID>`` or definition XMLs managed by libvirt /qemu in local filesystem except. Briefly speaking, no potential security risks will be introduced. Notifications impact -------------------- None Other end user impact --------------------- It does have impacts on end users: * Web GUI benefiting this feature allow end users to set/reset console passwords for their instances. * When end users access password-encryted console of instances via Web GUI, input for console password will be prompted from web console. * New `get-*-console` CLIs may look like this(using nova command): .. code-block:: shell $ nova get-vnc-console --vnc-password='newpasswd' <VM UUID> ... $ nova get-spice-console --vnc-password='newpasswd' <VM UUID> ... Performance Impact ------------------ None Other deployer impact --------------------- New option ``vnc`` is added to auth_schemes list in ``vnc`` segment in ``nova.conf``. This allows nova-novncproxy to detect and load rfb.VNC auth scheme. .. code-block:: ini [vnc] auth_schemes = none,vnc,vencrypt Developer impact ---------------- None Upgrade impact -------------- We should bump service object version and rpc version for the 'get_*_console' rpc call. Then only when the cluster fully upgrade to Ussuri release, the call can be success. otherwise return failure for the request. Implementation ============== Assignee(s) ----------- Primary assignee: brinzhang Other contributors: songwenping Feature Liaison --------------- Feature liaison: brinzhang Work Items ---------- * python-novaclient(and openstackclient as well): new ``--password`` option will be added to ``get-*-console`` commands and some codes processing this value shall be added. * nova-api: some codes to judge whether to call legacy ``get-*-console`` API or to call remote compute service to reset remote console password. * nova-compute: some codes to handle the request to reset console password: reassemble graphis tag with password and update it to libvirt XML. * nova-novncproxy: some codes to implement rfb auth schemes, security type negotiation (in current version, novncproxy tells tenant_sock to use hardcoded ``vnc.AuthType.NONE`` when serving as mediator between client and vnc server, though noVNC client provides native support for ``vnc.AuthType.VNC`` with password security handshake handle) and ``security handshake`` (no-ops, leave noVNC/websockify to do the stuff). Dependencies ============ None Testing ======= Add releated unit test Documentation Impact ==================== * `Operation Guide` needs some updates, in #User-Facing Operations# section.The ``nova get-*-console`` (or equivalent with openstack CLI) provides ``--vnc-password`` option to user to reset console console password. * `API Guides` needs no updates. However, some texts should be posted to notify developers about how to benefit from this feature. * `Configuration Reference` & `Deployment Guides` need some updates. A change in nova.conf to enable rfb.VNC auth scheme is added (nova -novncproxy cares). References ========== .. _`vnc security`: http://people.redhat.com/pbonzini/qemu-test-doc/_build/html/topics/vnc_005fsecurity.html * https://libvirt.org/formatdomain.html#elementsGraphics * https://bugzilla.redhat.com/show_bug.cgi?id=1180092 * https://tools.ietf.org/html/rfc6143 * https://en.wikipedia.org/wiki/Virtual_Network_Computing History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Ussuri - Approved * - Victoria - Reposeposed * - Wallaby - Reposeposed ",,270,0
openstack%2Fproject-config~master~I6a5a68570b8948692aa48f09003d26590ee621e4,openstack/project-config,master,I6a5a68570b8948692aa48f09003d26590ee621e4,Use python3 to run release note script,MERGED,2021-01-04 11:14:23.000000000,2021-01-04 13:14:50.000000000,2021-01-04 13:14:50.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-04 11:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cfeba11abff6ea2baaff504899baf57c2e4388ad', 'message': 'Use python3 to run release note script\n\nUse python3 when running the script to add release note page as\npart of the release process.\n\nChange-Id: I6a5a68570b8948692aa48f09003d26590ee621e4\n'}, {'number': 2, 'created': '2021-01-04 11:17:04.000000000', 'files': ['roles/copy-release-tools-scripts/files/release-tools/add_release_note_page.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8cf16652808d66be0511d726ff409cb678414de4', 'message': ""Use python3 to run release note script\n\nUse python3 when running the script to add release note page as\npart of the release process.\n\nWithout that we get the following error:\n```\n2020-12-26 16:58:15.569890 | ubuntu-focal | + python -c 'print('\\''victoria'\\''.title())'\n2020-12-26 16:58:15.570573 | ubuntu-focal |\n/home/zuul/scripts/release-tools/add_release_note_page.sh: line 51:\npython: command not found\n```\n\nc.f http://lists.openstack.org/pipermail/release-job-failures/2020-December/001499.html\n\nChange-Id: I6a5a68570b8948692aa48f09003d26590ee621e4\n""}]",0,769128,8cf16652808d66be0511d726ff409cb678414de4,7,2,2,28522,,,0,"Use python3 to run release note script

Use python3 when running the script to add release note page as
part of the release process.

Without that we get the following error:
```
2020-12-26 16:58:15.569890 | ubuntu-focal | + python -c 'print('\''victoria'\''.title())'
2020-12-26 16:58:15.570573 | ubuntu-focal |
/home/zuul/scripts/release-tools/add_release_note_page.sh: line 51:
python: command not found
```

c.f http://lists.openstack.org/pipermail/release-job-failures/2020-December/001499.html

Change-Id: I6a5a68570b8948692aa48f09003d26590ee621e4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/28/769128/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/copy-release-tools-scripts/files/release-tools/add_release_note_page.sh'],1,cfeba11abff6ea2baaff504899baf57c2e4388ad,release-doc-semaphore,"titlebranch=$(python3 -c ""print('$SERIES'.title())"")","titlebranch=$(python -c ""print('$SERIES'.title())"")",1,1
openstack%2Fnova-specs~master~I7c3b6eeb1c2a9d732778a7cc967d78e0b6642900,openstack/nova-specs,master,I7c3b6eeb1c2a9d732778a7cc967d78e0b6642900,"Update modernize-os-hypervisors-api spec, pt. 3",MERGED,2020-12-07 12:03:40.000000000,2021-01-04 12:55:46.000000000,2021-01-04 12:54:09.000000000,"[{'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-07 12:03:40.000000000', 'files': ['specs/wallaby/approved/modernize-os-hypervisors-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9cec000709ad0867da072a1c54da5d84ee4fa740', 'message': ""Update modernize-os-hypervisors-api spec, pt. 3\n\nThe '/os-hypervisors/{hypervisor_id}/uptime' API is pretty much useless.\nUse the vehicle that is the 2.88 microversion to remove this API in\nfavour of simply including this information in the\n'/os-hypervisors/{hypervisor_id}' response.\n\nChange-Id: I7c3b6eeb1c2a9d732778a7cc967d78e0b6642900\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",5,765797,9cec000709ad0867da072a1c54da5d84ee4fa740,13,6,1,15334,,,0,"Update modernize-os-hypervisors-api spec, pt. 3

The '/os-hypervisors/{hypervisor_id}/uptime' API is pretty much useless.
Use the vehicle that is the 2.88 microversion to remove this API in
favour of simply including this information in the
'/os-hypervisors/{hypervisor_id}' response.

Change-Id: I7c3b6eeb1c2a9d732778a7cc967d78e0b6642900
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/97/765797/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/approved/modernize-os-hypervisors-api.rst'],1,9cec000709ad0867da072a1c54da5d84ee4fa740,bp/modernize-os-hypervisors-api,"The majority of this spec is focused on changes to the ``/os-hypervisors/detail`` API. Consider the output of a typical ``GET /os-hypervisors/detail`` call, as taken from the API ref [1]_:In addition to the changes to the ``/os-hypervisors/detail`` API, there are also two other APIs that appear to have outlived their usefulness: ``/os-hypervisors/statistics``, which provides summary information of the above, and ``/os-hypervisors/{hypervisor_id}/uptime``, which provides an entire API to a single figure. The former can be removed entirely in favour of placement, while the latter can be replaced by a new ``uptime`` field on the ``/os-hypervisors/{hypervisor_id}`` API. The ``/os-hypervisors/statistics`` API contains summary information of the above fields and will be removed entirely, returning a HTTP 404 (Not Found) on the new API microversion. The uptime information shown by the ``/os-hypervisors/{hypervisor_id}/uptime`` API doesn't warrant its own API and will also return a HTTP 404 (Not Found) on the new API microversion. This information will be accessible via a new ``uptime`` field on responses from the ``/os-hypervisors/{hypervisor_id}`` API.instead. Regarding the changes to the ``/os-hypervisors/detail`` API:older microversion. Similarly, any users of the ``/os-hypervisors/{hypervisor_id}/uptime`` API will need to use the ``/os-hypervisors/{hypervisor_id}`` API instead.","Consider the output of a typical ``GET /os-hypervisors/detail`` call, as taken from the API ref [1]_:In addition, the ``/os-hypervisors/statistics`` API will be removed entirely and will return a HTTP 404 (Not Found).instead. Specifically:older microversion.",23,6
openstack%2Fopenstack-tempest-skiplist~master~I7652f52d8b3477d7909b27974947b4be015b2a69,openstack/openstack-tempest-skiplist,master,I7652f52d8b3477d7909b27974947b4be015b2a69,Skip neutron tempest api tests on puppet neutron standalone job,MERGED,2021-01-04 12:30:40.000000000,2021-01-04 12:48:54.000000000,2021-01-04 12:47:50.000000000,"[{'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9816}, {'_account_id': 9976}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2021-01-04 12:30:40.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/f0f1868f08cdc62e8d3a4b08a25dafb7fbc2de0e', 'message': 'Skip neutron tempest api tests on puppet neutron standalone job\n\nRelated-Bug: #1909008\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: I7652f52d8b3477d7909b27974947b4be015b2a69\n'}]",0,769137,f0f1868f08cdc62e8d3a4b08a25dafb7fbc2de0e,9,8,1,12393,,,0,"Skip neutron tempest api tests on puppet neutron standalone job

Related-Bug: #1909008

Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
Change-Id: I7652f52d8b3477d7909b27974947b4be015b2a69
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/37/769137/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,f0f1868f08cdc62e8d3a4b08a25dafb7fbc2de0e,skip_job, - tripleo-puppet-ci-centos-8-standalone,,1,0
openstack%2Ftripleo-heat-templates~master~I85fd94b7b8735327522461da2a45601308a38bfa,openstack/tripleo-heat-templates,master,I85fd94b7b8735327522461da2a45601308a38bfa,Wire up master standalone-upgrade content provider template,ABANDONED,2021-01-04 12:06:46.000000000,2021-01-04 12:38:10.000000000,,[],"[{'number': 1, 'created': '2021-01-04 12:06:46.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47341391b29bea2f5e999a6893e334db107c35a0', 'message': 'Wire up master standalone-upgrade content provider template\n\nThe depends-on adds a new upgrade jobs template which is wired up\nhere. Once wired up across tripleo we can remove excess content\nproviders with [1].\n\n[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131\nDepends-On: https://review.opendev.org/761188\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n\nChange-Id: I85fd94b7b8735327522461da2a45601308a38bfa\n'}]",0,769132,47341391b29bea2f5e999a6893e334db107c35a0,5,0,1,8449,,,0,"Wire up master standalone-upgrade content provider template

The depends-on adds a new upgrade jobs template which is wired up
here. Once wired up across tripleo we can remove excess content
providers with [1].

[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131
Depends-On: https://review.opendev.org/761188
Change-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e

Change-Id: I85fd94b7b8735327522461da2a45601308a38bfa
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/32/769132/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,47341391b29bea2f5e999a6893e334db107c35a0,, - tripleo-upgrades-master-pipeline,,1,0
openstack%2Ftripleo-heat-templates~master~I8781f233f5f6829f043d44418caa27aae9c491e1,openstack/tripleo-heat-templates,master,I8781f233f5f6829f043d44418caa27aae9c491e1,Wire up master standalone-upgrade content provider template,ABANDONED,2021-01-04 12:08:42.000000000,2021-01-04 12:37:58.000000000,,[],"[{'number': 1, 'created': '2021-01-04 12:08:42.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/44737579ce23255ce747379e2cf345a40e060d6a', 'message': 'Wire up master standalone-upgrade content provider template\n\nThe depends-on adds a new upgrade jobs template which is wired up\nhere. Once wired up across tripleo we can remove excess content\nproviders with [1].\n\n[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131\nDepends-On: https://review.opendev.org/761188\nChange-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e\n\nChange-Id: I8781f233f5f6829f043d44418caa27aae9c491e1\n'}]",0,769133,44737579ce23255ce747379e2cf345a40e060d6a,5,0,1,8449,,,0,"Wire up master standalone-upgrade content provider template

The depends-on adds a new upgrade jobs template which is wired up
here. Once wired up across tripleo we can remove excess content
providers with [1].

[1] https://review.opendev.org/c/openstack/tripleo-ci/+/769131
Depends-On: https://review.opendev.org/761188
Change-Id: I087439eee69394fad8e5872e64557d2f6c5cd83e

Change-Id: I8781f233f5f6829f043d44418caa27aae9c491e1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/33/769133/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,44737579ce23255ce747379e2cf345a40e060d6a,, - tripleo-upgrades-master-pipeline,,1,0
openstack%2Fnova-specs~master~I36d31f98d57d469aec55ba3a5dec7a27ab1733e1,openstack/nova-specs,master,I36d31f98d57d469aec55ba3a5dec7a27ab1733e1,[Trivial] Clarify the deprecated apis in *Proposed change*,MERGED,2020-12-31 08:15:59.000000000,2021-01-04 12:30:41.000000000,2021-01-04 12:29:07.000000000,"[{'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-31 08:15:59.000000000', 'files': ['specs/wallaby/approved/remove-tenant-id.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c6a2b368999c8970eccde6ee91f595d54165b391', 'message': '[Trivial] Clarify the deprecated apis in *Proposed change*\n\npart of blueprint remove-tenant-id\n\nChange-Id: I36d31f98d57d469aec55ba3a5dec7a27ab1733e1\n'}]",0,768803,c6a2b368999c8970eccde6ee91f595d54165b391,8,3,1,26458,,,0,"[Trivial] Clarify the deprecated apis in *Proposed change*

part of blueprint remove-tenant-id

Change-Id: I36d31f98d57d469aec55ba3a5dec7a27ab1733e1
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/03/768803/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/approved/remove-tenant-id.rst'],1,c6a2b368999c8970eccde6ee91f595d54165b391,bp/remove-tenant-id,* GET /os-cells (List Cells) * GET /os-fping?all_tenants=1 (Ping Instances),* GET /os-cells (List Cells),2,1
openstack%2Fopenstack-ansible~master~I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5,openstack/openstack-ansible,master,I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5,Fix keystone IDP setup,MERGED,2020-12-17 11:08:50.000000000,2021-01-04 12:26:02.000000000,2021-01-04 12:23:17.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27915}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-17 11:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0b6b44d68f802e8b6a2d6eddc6aee23074a16bdc', 'message': 'The current version does not include the os_keystone role correct, as it will run the role again, ignoring the tasks_from: main_keystone_federation_sp_idp_setup.yml part.\nThis fix has been tested and now it corectly configures the SP/IDP config.\nPaste of a test: https://pastebin.com/DnEc86HR\n\nChange-Id: I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5\nCloses-Bug: 1908510\n'}, {'number': 2, 'created': '2020-12-17 11:58:05.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2bb60193028fc848e87cdc7f416019482b8cf2cb', 'message': 'Fix keystone IDP setup\n\nThe current version does not include the os_keystone role correctly,\nas it runs the whole os_keystone role again and ignores the\ntasks_from: parameter.\n\nThis fix has been tested and now it correctly configures the SP/IDP\nconfiguration.\n\nChange-Id: I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5\nCloses-Bug: 1908510\n'}]",0,767513,2bb60193028fc848e87cdc7f416019482b8cf2cb,10,4,2,27915,,,0,"Fix keystone IDP setup

The current version does not include the os_keystone role correctly,
as it runs the whole os_keystone role again and ignores the
tasks_from: parameter.

This fix has been tested and now it correctly configures the SP/IDP
configuration.

Change-Id: I3c57c3aab3cacfd5732b9bf5e251a7a8b654d4f5
Closes-Bug: 1908510
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/13/767513/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-keystone-install.yml'],1,0b6b44d68f802e8b6a2d6eddc6aee23074a16bdc,1908510," tasks: - name: ""Post configure SP/IDP"" include_role: name: os_keystone tasks_from: main_keystone_federation_sp_idp_setup.yml", roles: - role: os_keystone tasks_from: main_keystone_federation_sp_idp_setup.yml,5,3
openstack%2Fopenstack-ansible~stable%2Ftrain~I1ccb6794b17e06f31d16fbdd021adc69f8b9fd94,openstack/openstack-ansible,stable/train,I1ccb6794b17e06f31d16fbdd021adc69f8b9fd94,Bump SHAs for stable/train,MERGED,2020-12-27 17:09:53.000000000,2021-01-04 12:24:51.000000000,2021-01-04 12:22:52.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-27 17:09:53.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a2397d2946d81c14d05778f6687440d28ff004c7', 'message': 'Bump SHAs for stable/train\n\nChange-Id: I1ccb6794b17e06f31d16fbdd021adc69f8b9fd94\n'}]",0,768582,a2397d2946d81c14d05778f6687440d28ff004c7,8,3,1,28619,,,0,"Bump SHAs for stable/train

Change-Id: I1ccb6794b17e06f31d16fbdd021adc69f8b9fd94
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/82/768582/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,a2397d2946d81c14d05778f6687440d28ff004c7,bump_osa, version: 558f33d28d1bbc8975c0f7bbbaa591fb0d24be67 version: ff256cc172056f7c58ad438c0a03e86c9d7c6f8d version: 607ef5a7d2967ad339118b65e288432b0fcf6052, version: caedd0da32eb8c7a3d32b5c7d025232630b737f9 version: ccc7a99a5589ca7fc554f8e88fa23e278bce777f version: d14723d5b47be85f05e3a8febb04aeddbf62b5c9,49,49
openstack%2Fopenstack-ansible~master~I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3,openstack/openstack-ansible,master,I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3,Update deploy guide to reflect the current status of OSA,MERGED,2020-12-16 09:22:39.000000000,2021-01-04 12:24:40.000000000,2021-01-04 12:22:57.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-16 09:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f008f2104f16682da9afa04abf0f50f2d788a7a9', 'message': 'Update deploy guide to reflect the current status of OSA\n\nChange-Id: I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3\n'}, {'number': 2, 'created': '2020-12-16 10:25:08.000000000', 'files': ['deploy-guide/source/app-aboutosa.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6614e27a1139afc748d44f967b560bd845ee04b4', 'message': 'Update deploy guide to reflect the current status of OSA\n\nChange-Id: I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3\n'}]",6,767285,6614e27a1139afc748d44f967b560bd845ee04b4,13,4,2,25023,,,0,"Update deploy guide to reflect the current status of OSA

Change-Id: I381980d89d4d08ab0081a4fa0d02986bdf0fb1d3
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/85/767285/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-aboutosa.rst'],1,f008f2104f16682da9afa04abf0f50f2d788a7a9,,"For isolation and ease of maintenance, all openstack services are installed by default from source code into python virtual environments. The services are further isolated via the use of LXC containers, but these are optional and a bare metal based installation is also possible. We currently support machine containers, If you want to go 100% Docker,* You wish to deploy openstack services from distribution packages (deb or rpm). Whilst there is some support for this, coverage of the services is incomplete and a lot of operator flexibility is lost when using this approach.","For isolation and ease of maintenance, you can install OpenStack components into machine containers.* Supports the major CPU architectures x86, ppc64, s390x (WIP). We currently support machine containers, with lxc and we will support *systemd-nspawn* in the future (WIP). If you want to go 100% Docker,",10,5
openstack%2Fopenstack-ansible~master~Ie671720f48fa447ce2e32aa5e98b2bb0079132fa,openstack/openstack-ansible,master,Ie671720f48fa447ce2e32aa5e98b2bb0079132fa,Set default for octavia_barbican_enabled,MERGED,2020-12-25 16:11:48.000000000,2021-01-04 12:23:02.000000000,2021-01-04 12:23:02.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-25 16:11:48.000000000', 'files': ['inventory/group_vars/octavia_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b18ae0c5468525fe7e958dc3894e783ee7bb557a', 'message': 'Set default for octavia_barbican_enabled\n\nChange-Id: Ie671720f48fa447ce2e32aa5e98b2bb0079132fa\n'}]",0,768515,b18ae0c5468525fe7e958dc3894e783ee7bb557a,8,4,1,28619,,,0,"Set default for octavia_barbican_enabled

Change-Id: Ie671720f48fa447ce2e32aa5e98b2bb0079132fa
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/15/768515/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/octavia_all.yml'],1,b18ae0c5468525fe7e958dc3894e783ee7bb557a,osa/octavia_barbican,"octavia_barbican_enabled: ""{{ (groups['barbican_all'] is defined) and (groups['barbican_all'] | length > 0) }}""",,1,0
openstack%2Fpython-ironicclient~master~I683d3e2342142d6c87c4b270ccaf82445d22e9ef,openstack/python-ironicclient,master,I683d3e2342142d6c87c4b270ccaf82445d22e9ef,Support setting automated_clean to False,MERGED,2020-12-23 16:26:12.000000000,2021-01-04 11:44:05.000000000,2021-01-04 11:42:51.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-12-23 16:26:12.000000000', 'files': ['releasenotes/notes/no-automated-clean-0e437581ded44eb3.yaml', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py', 'ironicclient/osc/v1/baremetal_node.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c94eaae83bf94bdf557be95f2623381f2d76eba3', 'message': 'Support setting automated_clean to False\n\nChange-Id: I683d3e2342142d6c87c4b270ccaf82445d22e9ef\n'}]",0,768350,c94eaae83bf94bdf557be95f2623381f2d76eba3,8,3,1,10239,,,0,"Support setting automated_clean to False

Change-Id: I683d3e2342142d6c87c4b270ccaf82445d22e9ef
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/50/768350/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/no-automated-clean-0e437581ded44eb3.yaml', 'ironicclient/osc/v1/baremetal_node.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py']",3,c94eaae83bf94bdf557be95f2623381f2d76eba3,no-automated-clean," def test_baremetal_create_with_no_automated_clean(self): self.check_with_options(['--no-automated-clean'], [('automated_clean', False)], {'automated_clean': False}) def test_baremetal_set_no_automated_clean(self): arglist = [ 'node_uuid', '--no-automated-clean' ] verifylist = [ ('node', 'node_uuid'), ('automated_clean', False) ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) self.baremetal_mock.node.update.assert_called_once_with( 'node_uuid', [{'path': '/automated_clean', 'value': 'False', 'op': 'add'}], reset_interfaces=None, ) ",,54,5
openstack%2Foctavia~master~Ifca01d91d8eb92115d56744f4963e91ac537dd8e,openstack/octavia,master,Ifca01d91d8eb92115d56744f4963e91ac537dd8e,Fix periodic image builder jobs,MERGED,2020-12-17 08:35:15.000000000,2021-01-04 11:32:07.000000000,2021-01-04 11:28:30.000000000,"[{'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 08:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/5cc434b99d473e2afa88ebea3813fb5875d4e082', 'message': 'DNM WIP Fix periodic image builder jobs\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}, {'number': 2, 'created': '2020-12-17 08:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/678600df370469d3b5fa043b9b5187d02166c005', 'message': 'DNM WIP Fix periodic image builder jobs\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}, {'number': 3, 'created': '2020-12-17 09:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0ef3f5335769a5944597dbfa0622a3eb25ce939b', 'message': 'DNM WIP Fix periodic image builder jobs\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}, {'number': 4, 'created': '2020-12-17 09:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c3c45c2fd2981b06ed4a146be30158fa98d20517', 'message': 'DNM WIP Fix periodic image builder jobs\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}, {'number': 5, 'created': '2020-12-17 10:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/5d5e3444ecb62494169e75fc456db5f41c35c284', 'message': 'DNM WIP Fix periodic image builder jobs\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}, {'number': 6, 'created': '2020-12-17 11:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/949c853884036e3c9aef3037441eef0888e83134', 'message': 'Fix periodic image builder jobs\n\npublish-openstack-octavia-amphora-image* jobs started failing because\nubuntu no longer provides yum-utils package.\nNow dependencies have been cleaned up for the ubuntu job, and the centos\njob uses a centos node. The zuul playbook now works on Ubuntu and\nRedHat/Centos nodes.\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}, {'number': 7, 'created': '2020-12-17 12:51:16.000000000', 'files': ['playbooks/image-build/run.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/d81a0556f575abbaeffbd812b859e489c3f035e4', 'message': 'Fix periodic image builder jobs\n\npublish-openstack-octavia-amphora-image* jobs started failing because\nubuntu no longer provides yum-utils package.\nNow dependencies have been cleaned up for the ubuntu job, and the centos\njob uses a centos node. The zuul playbook now works on Ubuntu and\nRedHat/Centos nodes.\n\nChange-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e\n'}]",1,767471,d81a0556f575abbaeffbd812b859e489c3f035e4,21,3,7,29244,,,0,"Fix periodic image builder jobs

publish-openstack-octavia-amphora-image* jobs started failing because
ubuntu no longer provides yum-utils package.
Now dependencies have been cleaned up for the ubuntu job, and the centos
job uses a centos node. The zuul playbook now works on Ubuntu and
RedHat/Centos nodes.

Change-Id: Ifca01d91d8eb92115d56744f4963e91ac537dd8e
",git fetch https://review.opendev.org/openstack/octavia refs/changes/71/767471/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/image-build/run.yaml', 'zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",3,5cc434b99d473e2afa88ebea3813fb5875d4e082,, #post-run: playbooks/image-build/post.yaml nodeset: centos-8, post-run: playbooks/image-build/post.yaml,86,63
openstack%2Fkolla-ansible~master~Icadf7e8fcfce6211e5b92e8b68c637bc4628360f,openstack/kolla-ansible,master,Icadf7e8fcfce6211e5b92e8b68c637bc4628360f,Add mtail for exporting log events to Prometheus,ABANDONED,2019-03-05 15:54:55.000000000,2021-01-04 11:09:48.000000000,,"[{'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 15:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/431a7b5b32440b2e9a921e6248c9aee4f4c083c0', 'message': 'Add mtail for exporting log events to Prometheus\n\nThis adds support for Google mtail to allow generating metrics from logs,\nfrom which alerts may then be generated. Out of the box, metrics are\ngenerated for user logins from syslog events. Support to add further\nfunctionality, via the use of custom mtail programs, is supported via\nKolla configuration.\n\nChange-Id: Icadf7e8fcfce6211e5b92e8b68c637bc4628360f\nPartially-Implements: blueprint mtail\n'}, {'number': 2, 'created': '2019-03-15 11:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f260a566eb11ce6f32c775df123e92459d98078b', 'message': 'Add mtail for exporting log events to Prometheus\n\nThis adds support for Google mtail to allow generating metrics from logs,\nfrom which alerts may then be generated. Out of the box, metrics are\ngenerated for user logins from syslog events. Support to add further\nfunctionality, via the use of custom mtail programs, is supported via\nKolla configuration.\n\nChange-Id: Icadf7e8fcfce6211e5b92e8b68c637bc4628360f\nPartially-Implements: blueprint mtail\n'}, {'number': 3, 'created': '2019-03-15 11:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/892f72e71ea5b7b8cbb82e3b4d2d2103ecdc89b5', 'message': 'Add mtail for exporting log events to Prometheus\n\nThis adds support for Google mtail to allow generating metrics from logs,\nfrom which alerts may then be generated. Out of the box, metrics are\ngenerated for user logins from syslog events. Support to add further\nfunctionality, via the use of custom mtail programs, is supported via\nKolla configuration.\n\nChange-Id: Icadf7e8fcfce6211e5b92e8b68c637bc4628360f\nPartially-Implements: blueprint mtail\n'}, {'number': 4, 'created': '2019-03-18 13:26:34.000000000', 'files': ['ansible/inventory/multinode', 'ansible/roles/prometheus/templates/prometheus-mtail.json.j2', 'ansible/site.yml', 'releasenotes/notes/add-prometheus-mtail-13f2bc1d7e57293c.yaml', 'ansible/roles/prometheus/templates/prometheus.yml.j2', 'ansible/inventory/all-in-one', 'ansible/roles/prometheus/tasks/config.yml', 'ansible/group_vars/all.yml', 'ansible/roles/prometheus/templates/mtail_progs/syslog.mtail.j2', 'ansible/roles/prometheus/defaults/main.yml', 'ansible/roles/prometheus/tasks/precheck.yml', 'tests/templates/inventory.j2', 'etc/kolla/globals.yml', 'ansible/roles/prometheus/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/569938ecc7622a8144eb30496cd10d49fd86091c', 'message': 'Add mtail for exporting log events to Prometheus\n\nThis adds support for Google mtail to allow generating metrics from logs,\nfrom which alerts may then be generated. Out of the box, metrics are\ngenerated for user logins from syslog events. Support to add further\nfunctionality, via the use of custom mtail programs, is supported via\nKolla configuration.\n\nChange-Id: Icadf7e8fcfce6211e5b92e8b68c637bc4628360f\nPartially-Implements: blueprint mtail\n'}]",1,641060,569938ecc7622a8144eb30496cd10d49fd86091c,11,2,4,17669,,,0,"Add mtail for exporting log events to Prometheus

This adds support for Google mtail to allow generating metrics from logs,
from which alerts may then be generated. Out of the box, metrics are
generated for user logins from syslog events. Support to add further
functionality, via the use of custom mtail programs, is supported via
Kolla configuration.

Change-Id: Icadf7e8fcfce6211e5b92e8b68c637bc4628360f
Partially-Implements: blueprint mtail
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/60/641060/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/inventory/multinode', 'ansible/roles/prometheus/templates/prometheus-mtail.json.j2', 'ansible/site.yml', 'releasenotes/notes/add-prometheus-mtail-13f2bc1d7e57293c.yaml', 'ansible/roles/prometheus/templates/prometheus.yml.j2', 'ansible/inventory/all-in-one', 'ansible/roles/prometheus/tasks/config.yml', 'ansible/group_vars/all.yml', 'ansible/roles/prometheus/templates/mtail_progs/syslog.mtail.j2', 'ansible/roles/prometheus/defaults/main.yml', 'ansible/roles/prometheus/tasks/precheck.yml', 'tests/templates/inventory.j2', 'etc/kolla/globals.yml', 'ansible/roles/prometheus/handlers/main.yml']",14,431a7b5b32440b2e9a921e6248c9aee4f4c083c0,bp/libvirt-exporter," - name: Restart prometheus-mtail container vars: service_name: ""prometheus-mtail"" service: ""{{ prometheus_services[service_name] }}"" config_json: ""{{ prometheus_config_jsons.results|selectattr('item.key', 'equalto', service_name)|first }}"" prometheus_container: ""{{ check_prometheus_containers.results|selectattr('item.key', 'equalto', service_name)|first }}"" kolla_docker: action: ""recreate_or_restart_container"" common_options: ""{{ docker_common_options }}"" name: ""{{ service.container_name }}"" image: ""{{ service.image }}"" volumes: ""{{ service.volumes }}"" dimensions: ""{{ service.dimensions }}"" when: - kolla_action != ""config"" - inventory_hostname in groups[service.group] - service.enabled | bool - config_json.changed | bool or prometheus_mtail_progs.changed | bool or prometheus_mtail_custom_progs.changed | bool or prometheus_container.changed | bool",,176,0
openstack%2Fnova~master~I99e2c19bc78e98a8e9e3743ff51201015fb1d47e,openstack/nova,master,I99e2c19bc78e98a8e9e3743ff51201015fb1d47e,tests: Merge 'test_hypervisor_status' into 'test_hypervisors',MERGED,2020-11-24 17:24:25.000000000,2021-01-04 10:35:32.000000000,2021-01-04 10:33:12.000000000,"[{'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-24 17:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c07a7f3369663e74f60c41aad1d8a67015e0566a', 'message': ""tests: Merge 'test_hypervisor_status' into 'test_hypervisors'\n\nNo need for this to be a separate thing. It's confusing.\n\nChange-Id: I99e2c19bc78e98a8e9e3743ff51201015fb1d47e\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-12-07 12:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8a3c6c4d4f40296f0d78f543aa4d1be798d4a6c', 'message': ""tests: Merge 'test_hypervisor_status' into 'test_hypervisors'\n\nNo need for this to be a separate thing. It's confusing.\n\nChange-Id: I99e2c19bc78e98a8e9e3743ff51201015fb1d47e\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-12-15 17:33:21.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_hypervisor_status.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/00ad3bb1f1ed9ca666dac909baaa3aa97a0e1865', 'message': ""tests: Merge 'test_hypervisor_status' into 'test_hypervisors'\n\nNo need for this to be a separate thing. It's confusing.\n\nChange-Id: I99e2c19bc78e98a8e9e3743ff51201015fb1d47e\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",7,764039,00ad3bb1f1ed9ca666dac909baaa3aa97a0e1865,25,3,3,15334,,,0,"tests: Merge 'test_hypervisor_status' into 'test_hypervisors'

No need for this to be a separate thing. It's confusing.

Change-Id: I99e2c19bc78e98a8e9e3743ff51201015fb1d47e
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/764039/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_hypervisor_status.py']",2,c07a7f3369663e74f60c41aad1d8a67015e0566a,bp/modernize-os-hypervisors-api,,"# Copyright 2014 Intel Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import mock from nova.api.openstack.compute import hypervisors \ as hypervisors_v21 from nova import objects from nova import test from nova.tests.unit.api.openstack.compute import test_hypervisors from nova.tests.unit.api.openstack import fakes TEST_HYPER = test_hypervisors.TEST_HYPERS_OBJ[0].obj_clone() TEST_SERVICE = objects.Service(id=1, host=""compute1"", binary=""nova-compute"", topic=""compute_topic"", report_count=5, disabled=False, disabled_reason=None, availability_zone=""nova"") class HypervisorStatusTestV21(test.NoDBTestCase): def _prepare_extension(self): self.controller = hypervisors_v21.HypervisorsController() self.controller.servicegroup_api.service_is_up = mock.MagicMock( return_value=True) def _get_request(self): return fakes.HTTPRequest.blank( '/v2/%s/os-hypervisors/detail' % fakes.FAKE_PROJECT_ID, use_admin_context=True) def test_view_hypervisor_service_status(self): self._prepare_extension() req = self._get_request() result = self.controller._view_hypervisor( TEST_HYPER, TEST_SERVICE, False, req) self.assertEqual('enabled', result['status']) self.assertEqual('up', result['state']) self.assertEqual('enabled', result['status']) self.controller.servicegroup_api.service_is_up.return_value = False result = self.controller._view_hypervisor( TEST_HYPER, TEST_SERVICE, False, req) self.assertEqual('down', result['state']) hyper = copy.deepcopy(TEST_HYPER) service = copy.deepcopy(TEST_SERVICE) service.disabled = True result = self.controller._view_hypervisor(hyper, service, False, req) self.assertEqual('disabled', result['status']) def test_view_hypervisor_detail_status(self): self._prepare_extension() req = self._get_request() result = self.controller._view_hypervisor( TEST_HYPER, TEST_SERVICE, True, req) self.assertEqual('enabled', result['status']) self.assertEqual('up', result['state']) self.assertIsNone(result['service']['disabled_reason']) self.controller.servicegroup_api.service_is_up.return_value = False result = self.controller._view_hypervisor( TEST_HYPER, TEST_SERVICE, True, req) self.assertEqual('down', result['state']) hyper = copy.deepcopy(TEST_HYPER) service = copy.deepcopy(TEST_SERVICE) service.disabled = True service.disabled_reason = ""fake"" result = self.controller._view_hypervisor(hyper, service, True, req) self.assertEqual('disabled', result['status'],) self.assertEqual('fake', result['service']['disabled_reason']) ",27,99
openstack%2Fkolla-ansible~master~I763317a6f8207357991c23fa5a2fc8cc6f8a17f4,openstack/kolla-ansible,master,I763317a6f8207357991c23fa5a2fc8cc6f8a17f4,Fix Ceph links,MERGED,2020-12-26 22:17:30.000000000,2021-01-04 10:29:42.000000000,2021-01-04 10:28:13.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 28182}, {'_account_id': 30491}, {'_account_id': 32029}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-26 22:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c834b6c02505c0b1adce23fac45901b0a4efe019', 'message': 'Changing links to correct.\n\nChange-Id: I763317a6f8207357991c23fa5a2fc8cc6f8a17f4\n'}, {'number': 2, 'created': '2020-12-28 12:44:39.000000000', 'files': ['doc/source/reference/storage/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e71894b2fbcd84c3871563a2d579277b2bc47ff9', 'message': 'Fix Ceph links\n\nand drop the reference to ceph-deploy (seems abandoned).\n\nChange-Id: I763317a6f8207357991c23fa5a2fc8cc6f8a17f4\n'}]",0,768567,e71894b2fbcd84c3871563a2d579277b2bc47ff9,14,6,2,32690,,,0,"Fix Ceph links

and drop the reference to ceph-deploy (seems abandoned).

Change-Id: I763317a6f8207357991c23fa5a2fc8cc6f8a17f4
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/67/768567/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/storage/external-ceph-guide.rst'],1,c834b6c02505c0b1adce23fac45901b0a4efe019,fix-ceph-link,* `ceph-deploy <https://docs.ceph.com/en/latest/man/8/ceph-deploy/>`_ * `cephadm <https://docs.ceph.com/en/latest/cephadm/install/>`_Refer to https://docs.ceph.com/en/latest/rbd/rbd-openstack/ for details on,* `ceph-deploy <https://docs.ceph.com/docs/master/start/>`_ * `cephadm <https://docs.ceph.com/docs/master/bootstrap/>`_Refer to http://docs.ceph.com/docs/master/rbd/rbd-openstack/ for details on,3,3
openstack%2Freleases~master~I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1,openstack/releases,master,I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1,TripleO repos feature release for stable/victoria,MERGED,2020-12-22 17:08:36.000000000,2021-01-04 10:24:03.000000000,2021-01-04 10:24:03.000000000,"[{'_account_id': 308}, {'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 11904}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-12-22 17:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/72722b452b8627d2c7791197221fb6b325ceaf7d', 'message': 'TripleO repos feature release for stable/victoria\n\nThe related puppet-tripleo metadata bump in [1] is needed before\nthis can merge (gated by openstack-tox-validate). This also\ncreates a victoria branch for os-apply-config that was forgotten\nin [2]\n\n[1] I93e180221b3c589e4a54e926f2be6a27933d8448\n[2] https://review.opendev.org/c/openstack/releases/+/760571\nChange-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1\n'}, {'number': 2, 'created': '2020-12-23 15:07:02.000000000', 'files': ['deliverables/victoria/tripleo-heat-templates.yaml', 'deliverables/victoria/tripleo-validations.yaml', 'deliverables/victoria/os-apply-config.yaml', 'deliverables/victoria/os-net-config.yaml', 'deliverables/victoria/tripleo-ansible.yaml', 'deliverables/victoria/puppet-tripleo.yaml', 'deliverables/victoria/tripleo-common.yaml', 'deliverables/victoria/python-tripleoclient.yaml', 'deliverables/victoria/tripleo-puppet-elements.yaml', 'deliverables/victoria/tripleo-image-elements.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/39e9c42a7f19ce27275612a54731390e5dc07391', 'message': 'TripleO repos feature release for stable/victoria\n\nThe related puppet-tripleo metadata bump in [1] is needed before\nthis can merge (gated by openstack-tox-validate). This also\ncreates a victoria branch for os-apply-config that was forgotten\nin [2]\n\n[1] I93e180221b3c589e4a54e926f2be6a27933d8448\n[2] https://review.opendev.org/c/openstack/releases/+/760571\nChange-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1\n'}]",5,768237,39e9c42a7f19ce27275612a54731390e5dc07391,22,12,2,8449,,,0,"TripleO repos feature release for stable/victoria

The related puppet-tripleo metadata bump in [1] is needed before
this can merge (gated by openstack-tox-validate). This also
creates a victoria branch for os-apply-config that was forgotten
in [2]

[1] I93e180221b3c589e4a54e926f2be6a27933d8448
[2] https://review.opendev.org/c/openstack/releases/+/760571
Change-Id: I46cd8a7b414c6884e311f2fbe9ff3b9a5d9e6bc1
",git fetch https://review.opendev.org/openstack/releases refs/changes/37/768237/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/victoria/tripleo-heat-templates.yaml', 'deliverables/victoria/tripleo-validations.yaml', 'deliverables/victoria/os-apply-config.yaml', 'deliverables/victoria/os-net-config.yaml', 'deliverables/victoria/puppet-tripleo.yaml', 'deliverables/victoria/tripleo-ansible.yaml', 'deliverables/victoria/tripleo-common.yaml', 'deliverables/victoria/python-tripleoclient.yaml', 'deliverables/victoria/tripleo-puppet-elements.yaml', 'deliverables/victoria/tripleo-image-elements.yaml']",10,72722b452b8627d2c7791197221fb6b325ceaf7d,, - version: 12.2.0 projects: - repo: openstack/tripleo-image-elements hash: c1a598f643748f84b802dbb12fdaf74a1819bba6,,43,0
openstack%2Fvalidations-libs~master~Id8f9b8f85a7bed0f39c81650eceea0334dc5d816,openstack/validations-libs,master,Id8f9b8f85a7bed0f39c81650eceea0334dc5d816,Fix typo in validations_libs/ansible.py,MERGED,2021-01-04 08:27:37.000000000,2021-01-04 10:14:19.000000000,2021-01-04 10:12:50.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}]","[{'number': 1, 'created': '2021-01-04 08:27:37.000000000', 'files': ['validations_libs/ansible.py'], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/276c20d88c270f254c77cb16ee158a00cfd1aebd', 'message': 'Fix typo in validations_libs/ansible.py\n\ns/validagions-libs-ansible/validations-libs-ansible/\n\nChange-Id: Id8f9b8f85a7bed0f39c81650eceea0334dc5d816\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",0,769104,276c20d88c270f254c77cb16ee158a00cfd1aebd,8,4,1,11491,,,0,"Fix typo in validations_libs/ansible.py

s/validagions-libs-ansible/validations-libs-ansible/

Change-Id: Id8f9b8f85a7bed0f39c81650eceea0334dc5d816
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/validations-libs refs/changes/04/769104/1 && git format-patch -1 --stdout FETCH_HEAD,['validations_libs/ansible.py'],1,276c20d88c270f254c77cb16ee158a00cfd1aebd,, temp_suffix='validations-libs-ansible'):, temp_suffix='validagions-libs-ansible'):,1,1
openstack%2Freleases~master~I9cead21be5f9e84b41b164d3ab5ce2b174d12399,openstack/releases,master,I9cead21be5f9e84b41b164d3ab5ce2b174d12399,Puppet OpenStack Victoria Milestone 1,MERGED,2020-06-23 03:32:29.000000000,2021-01-04 10:12:24.000000000,2020-06-24 13:28:54.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-06-23 03:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4518428ed0d230eda0ffdb906d1e3de6d72885e2', 'message': 'Puppet OpenStack Victoria Milestone 1\n\nChange-Id: I9cead21be5f9e84b41b164d3ab5ce2b174d12399\n'}, {'number': 2, 'created': '2020-06-23 04:00:32.000000000', 'files': ['deliverables/victoria/puppet-magnum.yaml', 'deliverables/victoria/puppet-nova.yaml', 'deliverables/victoria/puppet-horizon.yaml', 'deliverables/victoria/puppet-tacker.yaml', 'deliverables/victoria/puppet-vitrage.yaml', 'deliverables/victoria/puppet-murano.yaml', 'deliverables/victoria/puppet-keystone.yaml', 'deliverables/victoria/puppet-placement.yaml', 'deliverables/victoria/puppet-manila.yaml', 'deliverables/victoria/puppet-designate.yaml', 'deliverables/victoria/puppet-rally.yaml', 'deliverables/victoria/puppet-barbican.yaml', 'deliverables/victoria/puppet-freezer.yaml', 'deliverables/victoria/puppet-monasca.yaml', 'deliverables/victoria/puppet-ceilometer.yaml', 'deliverables/victoria/puppet-ec2api.yaml', 'deliverables/victoria/puppet-octavia.yaml', 'deliverables/victoria/puppet-oslo.yaml', 'deliverables/victoria/puppet-swift.yaml', 'deliverables/victoria/puppet-cinder.yaml', 'deliverables/victoria/puppet-ironic.yaml', 'deliverables/victoria/puppet-senlin.yaml', 'deliverables/victoria/puppet-zaqar.yaml', 'deliverables/victoria/puppet-neutron.yaml', 'deliverables/victoria/puppet-watcher.yaml', 'deliverables/victoria/puppet-glance.yaml', 'deliverables/victoria/puppet-panko.yaml', 'deliverables/victoria/puppet-vswitch.yaml', 'deliverables/victoria/puppet-cloudkitty.yaml', 'deliverables/victoria/puppet-heat.yaml', 'deliverables/victoria/puppet-qdr.yaml', 'deliverables/victoria/puppet-glare.yaml', 'deliverables/victoria/puppet-aodh.yaml', 'deliverables/victoria/puppet-mistral.yaml', 'deliverables/victoria/puppet-openstacklib.yaml', 'deliverables/victoria/puppet-gnocchi.yaml', 'deliverables/victoria/puppet-tempest.yaml', 'deliverables/victoria/puppet-ovn.yaml', 'deliverables/victoria/puppet-sahara.yaml', 'deliverables/victoria/puppet-trove.yaml', 'deliverables/victoria/puppet-openstack_extras.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/41ecfbc148bebae14b13308ac010cda3c36f4c19', 'message': 'Puppet OpenStack Victoria Milestone 1\n\nChange-Id: I9cead21be5f9e84b41b164d3ab5ce2b174d12399\n'}]",0,737432,41ecfbc148bebae14b13308ac010cda3c36f4c19,13,3,2,9414,,,0,"Puppet OpenStack Victoria Milestone 1

Change-Id: I9cead21be5f9e84b41b164d3ab5ce2b174d12399
",git fetch https://review.opendev.org/openstack/releases refs/changes/32/737432/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/victoria/puppet-magnum.yaml', 'deliverables/victoria/puppet-nova.yaml', 'deliverables/victoria/puppet-horizon.yaml', 'deliverables/victoria/puppet-tacker.yaml', 'deliverables/victoria/puppet-vitrage.yaml', 'deliverables/victoria/puppet-murano.yaml', 'deliverables/victoria/puppet-keystone.yaml', 'deliverables/victoria/puppet-placement.yaml', 'deliverables/victoria/puppet-manila.yaml', 'deliverables/victoria/puppet-designate.yaml', 'deliverables/victoria/puppet-rally.yaml', 'deliverables/victoria/puppet-barbican.yaml', 'deliverables/victoria/puppet-freezer.yaml', 'deliverables/victoria/puppet-monasca.yaml', 'deliverables/victoria/puppet-ceilometer.yaml', 'deliverables/victoria/puppet-ec2api.yaml', 'deliverables/victoria/puppet-octavia.yaml', 'deliverables/victoria/puppet-oslo.yaml', 'deliverables/victoria/puppet-swift.yaml', 'deliverables/victoria/puppet-cinder.yaml', 'deliverables/victoria/puppet-ironic.yaml', 'deliverables/victoria/puppet-senlin.yaml', 'deliverables/victoria/puppet-zaqar.yaml', 'deliverables/victoria/puppet-neutron.yaml', 'deliverables/victoria/puppet-watcher.yaml', 'deliverables/victoria/puppet-glance.yaml', 'deliverables/victoria/puppet-panko.yaml', 'deliverables/victoria/puppet-vswitch.yaml', 'deliverables/victoria/puppet-cloudkitty.yaml', 'deliverables/victoria/puppet-heat.yaml', 'deliverables/victoria/puppet-qdr.yaml', 'deliverables/victoria/puppet-glare.yaml', 'deliverables/victoria/puppet-aodh.yaml', 'deliverables/victoria/puppet-mistral.yaml', 'deliverables/victoria/puppet-openstacklib.yaml', 'deliverables/victoria/puppet-gnocchi.yaml', 'deliverables/victoria/puppet-tempest.yaml', 'deliverables/victoria/puppet-ovn.yaml', 'deliverables/victoria/puppet-sahara.yaml', 'deliverables/victoria/puppet-trove.yaml', 'deliverables/victoria/puppet-openstack_extras.yaml']",41,4518428ed0d230eda0ffdb906d1e3de6d72885e2,puppet-openstack-victoria-m1,releases: - projects: - hash: 796135c8589e184d7c2de6790bcbce023f673fb8 repo: openstack/puppet-openstack_extras version: 17.1.0,,205,0
openstack%2Freleases~master~Ifc0686d216f94569fbf3eb61ad41c46e3c9a31cf,openstack/releases,master,Ifc0686d216f94569fbf3eb61ad41c46e3c9a31cf,Release os-win 5.4.0 (Wallaby),MERGED,2020-12-18 08:23:11.000000000,2021-01-04 10:10:32.000000000,2021-01-04 10:10:32.000000000,"[{'_account_id': 308}, {'_account_id': 8213}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-18 08:23:11.000000000', 'files': ['deliverables/wallaby/os-win.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a0065c036182961f38338878bba821b2b4ff0ad2', 'message': ""Release os-win 5.4.0 (Wallaby)\n\nWe're releasing a new os-win version, including a simple bug fix\nrelated to the vm soft shutdown operation and also the ability to\nlabel VHD images using given GUIDs.\n\nChange-Id: Ifc0686d216f94569fbf3eb61ad41c46e3c9a31cf\n""}]",0,767674,a0065c036182961f38338878bba821b2b4ff0ad2,8,4,1,8543,,,0,"Release os-win 5.4.0 (Wallaby)

We're releasing a new os-win version, including a simple bug fix
related to the vm soft shutdown operation and also the ability to
label VHD images using given GUIDs.

Change-Id: Ifc0686d216f94569fbf3eb61ad41c46e3c9a31cf
",git fetch https://review.opendev.org/openstack/releases refs/changes/74/767674/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/os-win.yaml'],1,a0065c036182961f38338878bba821b2b4ff0ad2,, - version: 5.4.0 projects: - repo: openstack/os-win hash: cce95b44a942ca0175886e84222294c5abaec67b,,4,0
openstack%2Fopenstack-ansible-tests~master~I892c3673a167fff17a720101b301b48485fb2bd5,openstack/openstack-ansible-tests,master,I892c3673a167fff17a720101b301b48485fb2bd5,Bump ansible version to 2.10.4,MERGED,2020-12-16 12:41:11.000000000,2021-01-04 09:56:12.000000000,2021-01-04 09:55:03.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-16 12:41:11.000000000', 'files': ['test-ansible-deps.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/2f89be9cbeb1507545f5de1ddabca36c0fa8cabf', 'message': 'Bump ansible version to 2.10.4\n\nChange-Id: I892c3673a167fff17a720101b301b48485fb2bd5\n'}]",0,767344,2f89be9cbeb1507545f5de1ddabca36c0fa8cabf,8,3,1,25023,,,0,"Bump ansible version to 2.10.4

Change-Id: I892c3673a167fff17a720101b301b48485fb2bd5
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/44/767344/1 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-deps.txt'],1,2f89be9cbeb1507545f5de1ddabca36c0fa8cabf,,ansible-base==2.10.4,ansible-base==2.10.3,1,1
openstack%2Fironic~master~Ic425ecb35bfa173adf72b0ee104d28c6b79cb4b1,openstack/ironic,master,Ic425ecb35bfa173adf72b0ee104d28c6b79cb4b1,Modify port group document for ironic,MERGED,2020-12-30 07:41:28.000000000,2021-01-04 09:53:14.000000000,2021-01-04 09:51:49.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-30 07:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1ea8ec9fa9000e6906e07f89a6d6fc8079ea0b9e', 'message': 'Modify port group document for ironic\n\nAdd a simple sample about configuring bonding via configdrive,\nand it can make user to use port group more easily.\n\nStory: 2008474\nTask: 41514\n\nSigned-off-by: huth <428437106@qq.com>\nChange-Id: Ic425ecb35bfa173adf72b0ee104d28c6b79cb4b1\n'}, {'number': 2, 'created': '2020-12-30 09:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b5adc181047714e9d350d56d420bda5244bb6d7d', 'message': 'Modify port group document for ironic\n\nAdd a simple sample about configuring bonding via configdrive,\nand it can make user to use port group more easily.\n\nStory: 2008474\nTask: 41514\n\nSigned-off-by: huth <428437106@qq.com>\nChange-Id: Ic425ecb35bfa173adf72b0ee104d28c6b79cb4b1\n'}, {'number': 3, 'created': '2020-12-31 02:37:21.000000000', 'files': ['doc/source/admin/portgroups.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/182a6fcff57a95edba2123a7e9234c9951e2ae13', 'message': 'Modify port group document for ironic\n\nAdd a simple sample about configuring bonding via configdrive,\nand it can make user to use port group more easily.\n\nStory: 2008474\nTask: 41514\n\nSigned-off-by: huth <428437106@qq.com>\nChange-Id: Ic425ecb35bfa173adf72b0ee104d28c6b79cb4b1\n'}]",2,768769,182a6fcff57a95edba2123a7e9234c9951e2ae13,15,2,3,32898,,,0,"Modify port group document for ironic

Add a simple sample about configuring bonding via configdrive,
and it can make user to use port group more easily.

Story: 2008474
Task: 41514

Signed-off-by: huth <428437106@qq.com>
Change-Id: Ic425ecb35bfa173adf72b0ee104d28c6b79cb4b1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/768769/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/portgroups.rst'],1,1ea8ec9fa9000e6906e07f89a6d6fc8079ea0b9e,modify_port_group_document," The following is a simple sample for configuring bonding via configdrive:: When booting an instance, it needs to add user-data file for configuring bonding via ``--user-data`` option. For example: { ""networks"": [ { ""type"": ""physical"", ""name"": ""eth0"", ""mac_address"": ""fa:ab:25:48:fd:ba"", }, { ""type"": ""physical"", ""name"": ""eth1"", ""mac_address"": ""fa:ab:25:48:fd:ab"", }, { ""type"": ""bond"", ""name"": ""bond0"", ""bond_interfaces"": [ ""eth0"", ""eth1"" ], ""mode"": ""active-backup"" }, ], } ",,28,0
openstack%2Fopenstack-ansible~stable%2Fussuri~I6e809141b755261f45a57dd61cbd9f7a09d6d407,openstack/openstack-ansible,stable/ussuri,I6e809141b755261f45a57dd61cbd9f7a09d6d407,Fix doc links,MERGED,2020-12-29 09:26:05.000000000,2021-01-04 09:52:24.000000000,2021-01-04 09:51:03.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-29 09:26:05.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dff6f93b51773ce19387c9fa13c7f038ebdbb613', 'message': 'Fix doc links\n\nChange-Id: I6e809141b755261f45a57dd61cbd9f7a09d6d407\n'}]",0,768720,dff6f93b51773ce19387c9fa13c7f038ebdbb613,10,3,1,28619,,,0,"Fix doc links

Change-Id: I6e809141b755261f45a57dd61cbd9f7a09d6d407
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/20/768720/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,dff6f93b51773ce19387c9fa13c7f038ebdbb613,, Deployment guide <https://docs.openstack.org/project-deploy-guide/openstack-ansible/ussuri/> Release notes <https://docs.openstack.org/releasenotes/openstack-ansible/ussuri.html>, Deployment guide <https://docs.openstack.org/project-deploy-guide/openstack-ansible/latest/> Release notes <https://docs.openstack.org/releasenotes/openstack-ansible/unreleased.html>,2,2
openstack%2Fopenstack-ansible~stable%2Fvictoria~I2a9bf00484dd25dc9af9926c2347507ae0ec7cd6,openstack/openstack-ansible,stable/victoria,I2a9bf00484dd25dc9af9926c2347507ae0ec7cd6,Fix documentation links,MERGED,2020-12-29 09:20:01.000000000,2021-01-04 09:52:04.000000000,2021-01-04 09:50:44.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-29 09:20:01.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2e02dd29abd17a686c3f2f39e15d40bbd4f32f87', 'message': 'Fix documentation links\n\nChange-Id: I2a9bf00484dd25dc9af9926c2347507ae0ec7cd6\n'}]",0,768719,2e02dd29abd17a686c3f2f39e15d40bbd4f32f87,8,3,1,28619,,,0,"Fix documentation links

Change-Id: I2a9bf00484dd25dc9af9926c2347507ae0ec7cd6
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/19/768719/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,2e02dd29abd17a686c3f2f39e15d40bbd4f32f87,,Victoria: Release CandidateOpenStack-Ansible Victoria Release Candidate has been created with the 22.0.0.0rc1 tag on 26 December 2020 Deployment guide <https://docs.openstack.org/project-deploy-guide/openstack-ansible/victoria/> Release notes <https://docs.openstack.org/releasenotes/openstack-ansible/victoria.html>,Victoria: Under DevelopmentOpenStack-Ansible Victoria is currently in development. Deployment guide <https://docs.openstack.org/project-deploy-guide/openstack-ansible/latest/> Release notes <https://docs.openstack.org/releasenotes/openstack-ansible/unreleased.html>,5,4
openstack%2Fosc-placement~master~Ie53303153c9e8725ae2b5811f8e336ddd42c3955,openstack/osc-placement,master,Ie53303153c9e8725ae2b5811f8e336ddd42c3955,remove unicode from code,MERGED,2021-01-03 09:44:18.000000000,2021-01-04 09:31:15.000000000,2021-01-04 09:30:00.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 09:44:18.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/f7640c9efad0715c4cd36f88897b1732aa689488', 'message': 'remove unicode from code\n\nChange-Id: Ie53303153c9e8725ae2b5811f8e336ddd42c3955\n'}]",0,769062,f7640c9efad0715c4cd36f88897b1732aa689488,7,2,1,32921,,,0,"remove unicode from code

Change-Id: Ie53303153c9e8725ae2b5811f8e336ddd42c3955
",git fetch https://review.opendev.org/openstack/osc-placement refs/changes/62/769062/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,f7640c9efad0715c4cd36f88897b1732aa689488,,"project = 'osc_placement Release Notes' copyright = '2016, OpenStack Foundation'","project = u'osc_placement Release Notes' copyright = u'2016, OpenStack Foundation'",2,2
openstack%2Fcinder~master~Ie3ad1b435c7ffb12ab0ae00f618151742ea87459,openstack/cinder,master,Ie3ad1b435c7ffb12ab0ae00f618151742ea87459,use HTTPStatus instead of http.client,NEW,2020-11-19 02:23:07.000000000,2021-01-04 09:30:20.000000000,,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 12032}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 24814}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 30092}, {'_account_id': 30688}, {'_account_id': 31868}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-11-19 02:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/896c6fc58a7f340ff574537b498b99d68bba92f0', 'message': 'Import HTTPStatus instead of http_client\n\nChange-Id: Ie3ad1b435c7ffb12ab0ae00f618151742ea87459\n'}, {'number': 2, 'created': '2021-01-04 03:07:50.000000000', 'files': ['cinder/tests/unit/backup/fake_swift_client.py', 'cinder/tests/unit/backup/fake_swift_client2.py', 'cinder/tests/unit/test_exception.py', 'cinder/tests/functional/api/client.py', 'cinder/tests/functional/test_extensions.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f9aa72b1282029513ab9a76a087d2e64a55de2e', 'message': ""use HTTPStatus instead of http.client\n\nWe don't need an HTTP client for this, we only\nneed status codes.  Just load that instead.\n\nhttps: //docs.python.org/3/library/http.html\nChange-Id: Ie3ad1b435c7ffb12ab0ae00f618151742ea87459\n""}]",10,763295,3f9aa72b1282029513ab9a76a087d2e64a55de2e,37,17,2,32326,,,0,"use HTTPStatus instead of http.client

We don't need an HTTP client for this, we only
need status codes.  Just load that instead.

https: //docs.python.org/3/library/http.html
Change-Id: Ie3ad1b435c7ffb12ab0ae00f618151742ea87459
",git fetch https://review.opendev.org/openstack/cinder refs/changes/95/763295/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/backup/fake_swift_client.py', 'cinder/tests/unit/backup/fake_swift_client2.py', 'cinder/tests/functional/api/client.py', 'cinder/tests/unit/test_exception.py', 'cinder/tests/functional/test_extensions.py']",5,896c6fc58a7f340ff574537b498b99d68bba92f0,,"from http import HTTPStatus self.assertEqual(HTTPStatus.OK, response.status_int) self.assertEqual(HTTPStatus.OK, response.status_int) self.assertEqual(HTTPStatus.NOT_FOUND, response.status_int)","from http import client as http_client self.assertEqual(http_client.OK, response.status_int) self.assertEqual(http_client.OK, response.status_int) self.assertEqual(http_client.NOT_FOUND, response.status_int)",34,34
openstack%2Fosc-placement~master~Ia725b1c2210822b7e74a8bcf25a36ac94dfef90f,openstack/osc-placement,master,Ia725b1c2210822b7e74a8bcf25a36ac94dfef90f,remove unicode from code,MERGED,2021-01-03 09:41:55.000000000,2021-01-04 09:29:34.000000000,2021-01-04 09:28:24.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 09:41:55.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/5652b0f0cde9a3593d95d61231e06c2694729553', 'message': 'remove unicode from code\n\nChange-Id: Ia725b1c2210822b7e74a8bcf25a36ac94dfef90f\n'}]",0,769059,5652b0f0cde9a3593d95d61231e06c2694729553,7,2,1,32921,,,0,"remove unicode from code

Change-Id: Ia725b1c2210822b7e74a8bcf25a36ac94dfef90f
",git fetch https://review.opendev.org/openstack/osc-placement refs/changes/59/769059/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,5652b0f0cde9a3593d95d61231e06c2694729553,,"project = 'osc-placement' copyright = '2016, OpenStack Foundation' ('index', 'doc-osc-placement.tex', 'osc-placement Documentation', 'OpenStack Foundation', 'manual'),","project = u'osc-placement' copyright = u'2016, OpenStack Foundation' ('index', 'doc-osc-placement.tex', u'osc-placement Documentation', u'OpenStack Foundation', 'manual'),",4,4
openstack%2Fcyborg~master~I9d2eb1ed962ece148f164634e94999ae9dc00591,openstack/cyborg,master,I9d2eb1ed962ece148f164634e94999ae9dc00591,remove py37,MERGED,2021-01-03 07:53:30.000000000,2021-01-04 09:10:12.000000000,2021-01-04 09:08:56.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2021-01-03 07:53:30.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/4f04cfa4cf5869eafb73ebc887a8677894f18f14', 'message': ""remove py37\n\nRemove python3.7 from setup.cfg, since Wallaby's python\nsupported runtimes are python 3.6 and python 3.8[1]:\n\n[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html\n\nChange-Id: I9d2eb1ed962ece148f164634e94999ae9dc00591\n""}]",0,768989,4f04cfa4cf5869eafb73ebc887a8677894f18f14,8,3,1,31825,,,0,"remove py37

Remove python3.7 from setup.cfg, since Wallaby's python
supported runtimes are python 3.6 and python 3.8[1]:

[1]: https://governance.openstack.org/tc/reference/runtimes/wallaby.html

Change-Id: I9d2eb1ed962ece148f164634e94999ae9dc00591
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/89/768989/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,4f04cfa4cf5869eafb73ebc887a8677894f18f14,,, Programming Language :: Python :: 3.7,0,1
openstack%2Fkolla-ansible~master~I2912285c38fa49eddd6fb817a133f811522f8519,openstack/kolla-ansible,master,I2912285c38fa49eddd6fb817a133f811522f8519,Add Newton release info,ABANDONED,2021-01-03 01:07:31.000000000,2021-01-04 08:53:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-03 01:07:31.000000000', 'files': ['releasenotes/source/newton.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a98f59a5d6ca198911c7c5334c0c7a32d5927361', 'message': 'Add Newton release info\n\nAdd the lack of release information for Victoria, this patch added it.\n\nChange-Id: I2912285c38fa49eddd6fb817a133f811522f8519\n'}]",0,768888,a98f59a5d6ca198911c7c5334c0c7a32d5927361,5,1,1,31828,,,0,"Add Newton release info

Add the lack of release information for Victoria, this patch added it.

Change-Id: I2912285c38fa49eddd6fb817a133f811522f8519
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/88/768888/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/newton.rst', 'releasenotes/source/index.rst']",2,a98f59a5d6ca198911c7c5334c0c7a32d5927361,, newton,,7,0
openstack%2Fos-win~master~Ic3feedde768d18d6751bf278af36779558a8d0a8,openstack/os-win,master,Ic3feedde768d18d6751bf278af36779558a8d0a8,Use TOX_CONSTRAINTS_FILE,MERGED,2020-12-24 08:10:26.000000000,2021-01-04 08:07:37.000000000,2021-01-04 08:06:28.000000000,"[{'_account_id': 8543}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2020-12-24 08:10:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/os-win/commit/80315f76584031575145785abec3131a107b11e6', 'message': 'Use TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\nThis allows to use upper-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: Ic3feedde768d18d6751bf278af36779558a8d0a8\n'}]",0,768453,80315f76584031575145785abec3131a107b11e6,8,3,1,30384,,,0,"Use TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
This allows to use upper-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: Ic3feedde768d18d6751bf278af36779558a8d0a8
",git fetch https://review.opendev.org/openstack/os-win refs/changes/53/768453/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,80315f76584031575145785abec3131a107b11e6,, -c{env:TOX_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt}, -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},1,1
