id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fkolla~master~I2b2d85c2d34908a9b11198eb51b3cf359a06bdf7,openstack/kolla,master,I2b2d85c2d34908a9b11198eb51b3cf359a06bdf7,"Use ""optional"" for ceph confs",MERGED,2016-02-16 16:42:31.000000000,2016-02-19 20:25:18.000000000,2016-02-19 20:25:17.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 3098}, {'_account_id': 16233}]","[{'number': 1, 'created': '2016-02-16 16:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5d484b2663b6813ff27a80fb9d4a22dac10d39da', 'message': 'Use ""optional"" for ceph confs\n\nAlso add missing cinder-backup ceph.conf info\n\nTrivialFix\n\nChange-Id: I2b2d85c2d34908a9b11198eb51b3cf359a06bdf7\n'}, {'number': 2, 'created': '2016-02-16 17:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/790f62c775416de3e468fbd98b5503b86ca226ae', 'message': 'Use ""optional"" for ceph confs\n\nAlso add missing cinder-backup ceph.conf info\n\nTrivialFix\n\nChange-Id: I2b2d85c2d34908a9b11198eb51b3cf359a06bdf7\n'}, {'number': 3, 'created': '2016-02-16 18:08:23.000000000', 'files': ['ansible/roles/cinder/templates/cinder-volume.json.j2', 'ansible/roles/cinder/templates/cinder-backup.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/81f5b2ac79a5e2a7811bb873e190e80484a901bc', 'message': 'Use ""optional"" for ceph confs\n\nAlso add missing cinder-backup ceph.conf info\n\nTrivialFix\n\nChange-Id: I2b2d85c2d34908a9b11198eb51b3cf359a06bdf7\n'}]",4,280808,81f5b2ac79a5e2a7811bb873e190e80484a901bc,11,4,3,14119,,,0,"Use ""optional"" for ceph confs

Also add missing cinder-backup ceph.conf info

TrivialFix

Change-Id: I2b2d85c2d34908a9b11198eb51b3cf359a06bdf7
",git fetch https://review.opendev.org/openstack/kolla refs/changes/08/280808/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/cinder/templates/cinder-volume.json.j2', 'ansible/roles/cinder/templates/cinder-backup.json.j2']",2,5d484b2663b6813ff27a80fb9d4a22dac10d39da,cinder-ceph-fix," }, { ""source"": ""{{ container_config_directory }}/ceph.client.cinder.keyring"", ""dest"": ""/etc/ceph/ceph.client.cinder.keyring"", ""owner"": ""cinder"", ""perm"": ""0600"", ""optional"": True }, { ""source"": ""{{ container_config_directory }}/ceph.conf"", ""dest"": ""/etc/ceph/ceph.conf"", ""owner"": ""cinder"", ""perm"": ""0600"", ""optional"": True",,20,4
openstack%2Fproject-config~master~Id73d5c4baa77c6dac3786e594858dd5484ba8d64,openstack/project-config,master,Id73d5c4baa77c6dac3786e594858dd5484ba8d64,Remove redundant access configuration,MERGED,2016-02-17 18:37:01.000000000,2016-02-19 20:22:40.000000000,2016-02-19 20:22:40.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6987}, {'_account_id': 11515}]","[{'number': 1, 'created': '2016-02-17 18:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/67104482e14e707594350efda1267ea2f6e7b54a', 'message': 'Remove redundant access configuration\n\nany acls which have the same permissions granted in\nrefs/heads/stable/* as refs/heads/* are redundant\n\nChange-Id: Id73d5c4baa77c6dac3786e594858dd5484ba8d64\n'}, {'number': 2, 'created': '2016-02-18 16:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/11564ab48a63cddf4cc748c0a93124c2f1ead882', 'message': 'Remove redundant access configuration\n\nany acls which have the same permissions granted in\nrefs/heads/stable/* as refs/heads/* are redundant\n\nChange-Id: Id73d5c4baa77c6dac3786e594858dd5484ba8d64\n'}, {'number': 3, 'created': '2016-02-19 19:10:30.000000000', 'files': ['gerrit/acls/openstack/openstack.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5d6af813b7a753dad339b0e9f05119149e673e5e', 'message': 'Remove redundant access configuration\n\nany acls which have the same permissions granted in\nrefs/heads/stable/* as refs/heads/* are redundant\n\nChange-Id: Id73d5c4baa77c6dac3786e594858dd5484ba8d64\n'}]",0,281461,5d6af813b7a753dad339b0e9f05119149e673e5e,17,5,3,6987,,,0,"Remove redundant access configuration

any acls which have the same permissions granted in
refs/heads/stable/* as refs/heads/* are redundant

Change-Id: Id73d5c4baa77c6dac3786e594858dd5484ba8d64
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/281461/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/openstack.config'],1,67104482e14e707594350efda1267ea2f6e7b54a,281461,,"[access ""refs/heads/stable/*""] abandon = group Release Managers exclusiveGroupPermissions = abandon label-Code-Review label-Workflow label-Code-Review = -2..+2 group Release Managers label-Workflow = -1..+1 group Release Managers ",0,6
openstack%2Fpython-tripleoclient~master~Ic8473f0510ed847e2f536d20b2589e34f398b21b,openstack/python-tripleoclient,master,Ic8473f0510ed847e2f536d20b2589e34f398b21b,Install bigswitch networking agent by default,MERGED,2016-01-25 10:06:56.000000000,2016-02-19 20:18:56.000000000,2016-02-19 20:18:56.000000000,"[{'_account_id': 3}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 9979}]","[{'number': 1, 'created': '2016-01-25 10:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2bd0491e564b52e1f9e0c312f19d0a676d093b1d', 'message': 'Install bigswitch networking agent by default\n\nInstall the bigswitch networking package\nopenstack-neutron-bigswitch-agent\n\nChange-Id: Ic8473f0510ed847e2f536d20b2589e34f398b21b\nRelated:  rhbz#1262059\n'}, {'number': 2, 'created': '2016-01-25 10:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bfd05a7905f7d4a88383c20fb4246cff2a9fb436', 'message': 'Install bigswitch networking agent by default\n\nInstall the bigswitch networking package\nopenstack-neutron-bigswitch-agent\n\nRelated:  rhbz#1262059\n\nChange-Id: Ic8473f0510ed847e2f536d20b2589e34f398b21b\n'}, {'number': 3, 'created': '2016-01-25 10:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3641c4d78ccc3710de16198915fd020c3d1edf08', 'message': 'Install bigswitch networking agent by default\n\nInstall the bigswitch networking package\nopenstack-neutron-bigswitch-agent\n\nRelated:  rhbz#1262059\n\nThis change needs to be cherry-picked to liberty as well.\n\nChange-Id: Ic8473f0510ed847e2f536d20b2589e34f398b21b\n'}, {'number': 4, 'created': '2016-01-26 08:16:02.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bbd435838711dd96f7a200001562c42e3c01a41b', 'message': 'Install bigswitch networking agent by default\n\nInstall the bigswitch networking package\nopenstack-neutron-bigswitch-agent\n\nRelated:  rhbz#1262059\n\nThis change needs to be cherry-picked to liberty as well.\n\nChange-Id: Ic8473f0510ed847e2f536d20b2589e34f398b21b\n'}]",0,271990,bbd435838711dd96f7a200001562c42e3c01a41b,19,4,4,15342,,,0,"Install bigswitch networking agent by default

Install the bigswitch networking package
openstack-neutron-bigswitch-agent

Related:  rhbz#1262059

This change needs to be cherry-picked to liberty as well.

Change-Id: Ic8473f0510ed847e2f536d20b2589e34f398b21b
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/90/271990/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,2bd0491e564b52e1f9e0c312f19d0a676d093b1d,," ""openstack-neutron-bigswitch-lldp,"" ""openstack-neutron-bigswitch-agent """," ""openstack-neutron-bigswitch-lldp """,4,2
openstack%2Ffreezer~master~I16e73d3eea222742409d03258f6acf5aa0d6a22b,openstack/freezer,master,I16e73d3eea222742409d03258f6acf5aa0d6a22b,Support for rsync block based backups,ABANDONED,2015-02-27 11:52:19.000000000,2016-02-19 20:13:55.000000000,,"[{'_account_id': 3}, {'_account_id': 2039}, {'_account_id': 5202}, {'_account_id': 11151}, {'_account_id': 12211}, {'_account_id': 12443}, {'_account_id': 12512}, {'_account_id': 14028}, {'_account_id': 14123}, {'_account_id': 14159}, {'_account_id': 14340}, {'_account_id': 14509}]","[{'number': 1, 'created': '2015-02-27 11:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c0cda9885b71c6da4f0460e84426861d457a5721', 'message': 'Support for rsync block based backups\n\nWorking in progess. Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplement: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 2, 'created': '2015-02-27 11:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/45161f9d6cbe7c45d0225b9a4b934594fc3727a8', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplement: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 3, 'created': '2015-02-27 11:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/a750e1ddf8d8b4916307f699c4cc1f505dd3dc0f', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 4, 'created': '2015-02-27 12:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/7f61bb22f1bdcb380bb31053cfb5ab9eaaacaca0', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 5, 'created': '2015-03-01 19:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c604bb6ccee51f45865ce6ec136dbadcdccf80c4', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 6, 'created': '2015-03-03 18:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/863f4b1fab9aab9d1eee29a52cf59041b7c5d834', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 7, 'created': '2015-03-03 18:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/995ed32fdce45a46580ee1f2e49d9cfbe5345737', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 8, 'created': '2015-03-11 15:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/48dcff2e0227e8e552cb15d486fd0e142afd6c3e', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 9, 'created': '2015-03-21 23:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/d92b4960de45c339db3e6d380901d66ebdf59809', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 10, 'created': '2015-04-16 15:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/d04e90dccc4c6382705adb6e865e59a22b1606fc', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 11, 'created': '2015-04-17 11:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c146ca59f4a1e4d93b5bb52d2abdd8938e29ba39', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 12, 'created': '2015-04-19 13:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/1b87316715da35e256ee8cb07ab365261f5264f2', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 13, 'created': '2015-04-25 17:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/db673b24245b95a29a43d142b927aa3d17eeecc3', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 14, 'created': '2015-04-26 17:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/f34d67ae5b2c865e5c62b600b9b0ee338cde0954', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 15, 'created': '2015-04-27 10:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/060fc588fb57520995087bfcdf8178f18d5369cf', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: https://blueprints.launchpad.net/freezer/+spec/librsync\n'}, {'number': 16, 'created': '2015-05-04 20:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/41b065a336553ffb6d7b6db99b5470bf11c582fb', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 17, 'created': '2015-05-04 21:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/3acaffe70d0c4bdd8e3f2b380b77f28d3bc4af92', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 18, 'created': '2015-05-21 15:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/8111b621ebe4e0e37add49f045dc0004eeeaf463', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 19, 'created': '2015-05-22 11:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e0cb3d34216713286b28df0d2862d7343047360f', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 20, 'created': '2015-06-01 17:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/3d7c2a46649fc9d22cafa6f195f27b10eb3ec44d', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 21, 'created': '2015-06-03 13:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/773fb11efa4bf962754037f301383c0a6acb5cd6', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 22, 'created': '2015-06-06 18:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/82f6af4d2d14bf9a9e45da51a60bbbe04a1af15a', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 23, 'created': '2015-06-06 18:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e53530eace712b18cd55bfb684cf869d7a50807f', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 24, 'created': '2015-06-06 23:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/1d363571b4960897cf1497f7df637d12fc58edc8', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 25, 'created': '2015-06-07 19:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/8ff058a5ba6589ad661fc2fd9006bb92afa7961e', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 26, 'created': '2015-06-07 20:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/aee253eccbc2c33af858a18de55d4bf8e485b8f0', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 27, 'created': '2015-06-07 23:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/cd247e853c0f31c5f7eab88d7444651a739c59e3', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 28, 'created': '2015-07-04 23:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/7df9640746b77371ec40d831d1b1ea364e5fd2b5', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 29, 'created': '2015-07-05 16:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/1beb8989a2f3d1f9db237502cd0843f76467d15f', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 30, 'created': '2015-07-05 18:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e116adb3efa710bda61e9658f1e457cfb1dbcd8a', 'message': 'Support for rsync block based backups\n\nWork in progress - Do not review\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 31, 'created': '2015-07-05 20:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/a18ec69c446eb6cfcd81cac9f6a9ff791afd46b3', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 32, 'created': '2015-07-06 12:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/b4128a07bab73056c7be6f1073b2fe39dc260013', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 33, 'created': '2015-07-06 16:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/05f9746ed66032e45db62aa2a3360e1433574a32', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 34, 'created': '2015-07-11 18:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/4c2ab1f7f8b5a8f435a95918770e0dd263d2f908', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 35, 'created': '2015-07-12 22:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/6e033cb0dbeddedf0a8ca0fd612a1adfc24987f8', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 36, 'created': '2015-07-18 17:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/2550ac13bd6559cba6708c3523c024929f519714', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}, {'number': 37, 'created': '2015-08-10 16:41:01.000000000', 'files': ['freezer/swift.py', 'freezer/arguments.py', 'freezer/utils.py', 'tests/test_utils.py', 'tests/commons.py', 'freezer/rsync.py', 'freezer/main.py', 'tests/test_main.py', 'tests/test_tar.py', 'tests/test_backup.py', 'tests/test_rsync.py', 'freezer/backup.py', 'freezer/restore.py', 'freezer/tar.py', 'tox.ini', 'freezer/lib/__init__.py', 'freezer/lib/pyrsync.py', 'tests/test_restore.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/8fdbcb61e94f503642b81376ceb58bb6988abcbc', 'message': 'Support for rsync block based backups\n\nFirst base support for block based backups.\nA pure python implementation of the rsync algorithm\nuse being used. In this commit, the incremental\nis not supported, but all the metadata is generated\nand stored.\n\nThe requirements from the bp are splitted in more\ncommits\n\nChange-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b\nImplements: blueprint block-based-backup-restore\n'}]",30,159804,8fdbcb61e94f503642b81376ceb58bb6988abcbc,112,12,37,11151,,,0,"Support for rsync block based backups

First base support for block based backups.
A pure python implementation of the rsync algorithm
use being used. In this commit, the incremental
is not supported, but all the metadata is generated
and stored.

The requirements from the bp are splitted in more
commits

Change-Id: I16e73d3eea222742409d03258f6acf5aa0d6a22b
Implements: blueprint block-based-backup-restore
",git fetch https://review.opendev.org/openstack/freezer refs/changes/04/159804/34 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/arguments.py', 'freezer/utils.py', 'freezer/backup.py', 'freezer/rsync.py', 'setup.py', 'tox.ini', 'freezer/lib/__init__.py', 'freezer/lib/pyrsync.py']",8,c0cda9885b71c6da4f0460e84426861d457a5721,(detached,"#!/usr/bin/env python # -*- coding: utf-8 -*- """""" This is a pure Python implementation of the [rsync algorithm] [TM96]. Updated to use SHA256 hashing (instead of the standard implementation which uses outdated MD5 hashes), and packages for disutils distribution by Isis Lovecruft, <isis@patternsinthevoid.net>. The majority of the code is blatantly stolen from Eric Pruitt's code as posted on [ActiveState] [1]. [1]: https://code.activestate.com/recipes/577518-rsync-algorithm/ [TM96]: Andrew Tridgell and Paul Mackerras. The rsync algorithm. Technical Report TR-CS-96-05, Canberra 0200 ACT, Australia, 1996. http://samba.anu.edu.au/rsync/. ### Example Use Case: ### # On the system containing the file that needs to be patched >>> unpatched = open(""unpatched.file"", ""rb"") >>> hashes = blockchecksums(unpatched) # On the remote system after having received `hashes` >>> patchedfile = open(""patched.file"", ""rb"") >>> delta = rsyncdelta(patchedfile, hashes) # System with the unpatched file after receiving `delta` >>> unpatched.seek(0) >>> save_to = open(""locally-patched.file"", ""wb"") >>> patchstream(unpatched, save_to, delta) """""" import collections import hashlib if not(hasattr(__builtins__, ""bytes"")) or str is bytes: # Python 2.x compatibility def bytes(var, *args): try: return ''.join(map(chr, var)) except TypeError: return map(ord, var) __all__ = [""rollingchecksum"", ""weakchecksum"", ""patchstream"", ""rsyncdelta"", ""blockchecksums""] def rsyncdelta(datastream, remotesignatures, blocksize=4096): """""" Generates a binary patch when supplied with the weak and strong hashes from an unpatched target and a readable stream for the up-to-date data. The blocksize must be the same as the value used to generate remotesignatures. """""" remote_weak, remote_strong = remotesignatures match = True matchblock = -1 deltaqueue = collections.deque() while True: if match and datastream is not None: # Whenever there is a match or the loop is running for the first # time, populate the window using weakchecksum instead of rolling # through every single byte which takes at least twice as long. window = collections.deque(bytes(datastream.read(blocksize))) checksum, a, b = weakchecksum(window) try: # If there are two identical weak checksums in a file, and the # matching strong hash does not occur at the first match, it will # be missed and the data sent over. May fix eventually, but this # problem arises very rarely. matchblock = remote_weak.index(checksum, matchblock + 1) stronghash = hashlib.sha256(bytes(window)).hexdigest() matchblock = remote_strong.index(stronghash, matchblock) match = True deltaqueue.append(matchblock) if datastream.closed: break continue except ValueError: # The weakchecksum did not match match = False try: if datastream: # Get the next byte and affix to the window newbyte = ord(datastream.read(1)) window.append(newbyte) except TypeError: # No more data from the file; the window will slowly shrink. # newbyte needs to be zero from here on to keep the checksum # correct. newbyte = 0 tailsize = datastream.tell() % blocksize datastream = None if datastream is None and len(window) <= tailsize: # The likelihood that any blocks will match after this is # nearly nil so call it quits. deltaqueue.append(window) break # Yank off the extra byte and calculate the new window checksum oldbyte = window.popleft() checksum, a, b = rollingchecksum(oldbyte, newbyte, a, b, blocksize) # Add the old byte the file delta. This is data that was not found # inside of a matching block so it needs to be sent to the target. try: deltaqueue[-1].append(oldbyte) except (AttributeError, IndexError): deltaqueue.append([oldbyte]) # Return a delta that starts with the blocksize and converts all iterables # to bytes. deltastructure = [blocksize] for element in deltaqueue: if isinstance(element, int): deltastructure.append(element) elif element: deltastructure.append(bytes(element)) return deltastructure def blockchecksums(instream, blocksize=4096): """""" Returns a list of weak and strong hashes for each block of the defined size for the given data stream. """""" weakhashes = list() stronghashes = list() read = instream.read(blocksize) while read: weakhashes.append(weakchecksum(bytes(read))[0]) stronghashes.append(hashlib.sha256(read).hexdigest()) read = instream.read(blocksize) return weakhashes, stronghashes def patchstream(instream, outstream, delta): """""" Patches instream using the supplied delta and write the resultantant data to outstream. """""" blocksize = delta[0] for element in delta[1:]: if isinstance(element, int) and blocksize: instream.seek(element * blocksize) element = instream.read(blocksize) outstream.write(element) def rollingchecksum(removed, new, a, b, blocksize=4096): """""" Generates a new weak checksum when supplied with the internal state of the checksum calculation for the previous window, the removed byte, and the added byte. """""" a -= removed - new b -= removed * blocksize - a return (b << 16) | a, a, b def weakchecksum(data): """""" Generates a weak checksum from an iterable set of bytes. """""" a = b = 0 l = len(data) for i in range(l): a += data[i] b += (l - i)*data[i] return (b << 16) | a, a, b ",,634,8
openstack%2Fneutron~stable%2Fkilo~I4fd354965926a8dd6851cf5703db4f3304beaaca,openstack/neutron,stable/kilo,I4fd354965926a8dd6851cf5703db4f3304beaaca,"Upgrade fixtures version, due to Jenkins failures.",ABANDONED,2016-02-15 15:05:19.000000000,2016-02-19 20:10:14.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1269}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15443}]","[{'number': 1, 'created': '2016-02-15 15:05:19.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b81e79cb7b37a38db2f9f4131d68a7d7ef760832', 'message': 'Upgrade fixtures version, due to Jenkins failures.\n\nChange-Id: I4fd354965926a8dd6851cf5703db4f3304beaaca\n'}]",0,280277,b81e79cb7b37a38db2f9f4131d68a7d7ef760832,18,12,1,1269,,,0,"Upgrade fixtures version, due to Jenkins failures.

Change-Id: I4fd354965926a8dd6851cf5703db4f3304beaaca
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/280277/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,b81e79cb7b37a38db2f9f4131d68a7d7ef760832,,fixtures>=1.3.1,"fixtures<1.3.0,>=0.3.14",1,1
openstack%2Fmanila~master~I06494ef149f3c07174d5f7e7c7c4750d18a43de5,openstack/manila,master,I06494ef149f3c07174d5f7e7c7c4750d18a43de5,WIP: pass catalog info when creating novaclient for admin context,ABANDONED,2016-02-07 01:05:00.000000000,2016-02-19 20:04:26.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-02-07 01:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e2aff17beceb15c3ffe1273c6c4e99f3c70b791c', 'message': ""WIP: pass catalog info when creating novaclient for admin context\n\nSince we are passing CONF.nova_api_microversion for the api_version\nwhen creating novaclient (when the context is an admin), we should\nbe explicit about the service/endpoint we want, which should be v2.1\nsince that's the API endpoint that supports nova microversions.\n\nThis explicitly constructs the novaclient in the admin case by passing\nadditional args that we should have probably already been passing since\nthey are configurable for manila (like the cacert and insecure options).\n\nAlso pass http_log_debug=CONF.debug to make debugging communication\nwith nova easier in the case of the admin context.\n\nChange-Id: I06494ef149f3c07174d5f7e7c7c4750d18a43de5\nCloses-Bug: #1538112\n""}, {'number': 2, 'created': '2016-02-18 15:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f7a8060dd3804d9815e69b22170a376fff578da9', 'message': ""WIP: pass catalog info when creating novaclient for admin context\n\nSince we are passing CONF.nova_api_microversion for the api_version\nwhen creating novaclient (when the context is an admin), we should\nbe explicit about the service/endpoint we want, which should be v2.1\nsince that's the API endpoint that supports nova microversions.\n\nAlso pass http_log_debug=CONF.debug to make debugging communication\nwith nova easier in the case of the admin context.\n\nCloses-Bug: #1538112\n\nChange-Id: I06494ef149f3c07174d5f7e7c7c4750d18a43de5\n""}, {'number': 3, 'created': '2016-02-19 19:58:15.000000000', 'files': ['manila/compute/nova.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8899e338abc65611165e9cce716bd84a5ad4b057', 'message': ""WIP: pass catalog info when creating novaclient for admin context\n\nSince we are passing CONF.nova_api_microversion for the api_version\nwhen creating novaclient (when the context is an admin), we should\nbe explicit about the service/endpoint we want, which should be v2.1\nsince that's the API endpoint that supports nova microversions.\n\nAlso pass http_log_debug=CONF.debug to make debugging communication\nwith nova easier in the case of the admin context.\n\nCloses-Bug: #1538112\n\nChange-Id: I06494ef149f3c07174d5f7e7c7c4750d18a43de5\n""}]",0,277140,8899e338abc65611165e9cce716bd84a5ad4b057,20,11,3,6873,,,0,"WIP: pass catalog info when creating novaclient for admin context

Since we are passing CONF.nova_api_microversion for the api_version
when creating novaclient (when the context is an admin), we should
be explicit about the service/endpoint we want, which should be v2.1
since that's the API endpoint that supports nova microversions.

Also pass http_log_debug=CONF.debug to make debugging communication
with nova easier in the case of the admin context.

Closes-Bug: #1538112

Change-Id: I06494ef149f3c07174d5f7e7c7c4750d18a43de5
",git fetch https://review.opendev.org/openstack/manila refs/changes/40/277140/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/compute/nova.py'],1,e2aff17beceb15c3ffe1273c6c4e99f3c70b791c,bug/1538112," service_type, service_name, endpoint_type = ( CONF.nova_catalog_admin_info.split(':')) service_type=service_type, service_name=service_name, endpoint_type=endpoint_type, region_name=CONF.os_region_name, insecure=CONF.nova_api_insecure, cacert=CONF.nova_ca_certificates_file, http_log_debug=CONF.debug,",,9,0
openstack%2Fneutron-fwaas~stable%2Fliberty~I699022b285594edf3c5db10fbdac2f904dc42928,openstack/neutron-fwaas,stable/liberty,I699022b285594edf3c5db10fbdac2f904dc42928,Added constraints tox targets,ABANDONED,2015-12-16 12:12:46.000000000,2016-02-19 20:01:16.000000000,,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 8344}, {'_account_id': 9656}, {'_account_id': 10692}]","[{'number': 1, 'created': '2015-12-16 12:12:46.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/74f5723197d00cfa76caf23fd528a7649f810b16', 'message': ""Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.\n\nMade tox_install.sh use constraints file to install both the project\nand neutron dependency, if the first argument is 'constrained'.\n\nCherry pick of I699022b285594edf3c5db10fbdac2f904dc42928 for liberty.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\nPartial-Bug: #1522503\n""}]",7,258457,74f5723197d00cfa76caf23fd528a7649f810b16,10,5,1,6659,,,0,"Added constraints tox targets

These are eventually going to be used in gate instead of unconstrained
jobs. There is some code duplication in commands definitions, but tox
does not allow to inherit definitions with {posargs} substitution.

Made tox_install.sh use constraints file to install both the project
and neutron dependency, if the first argument is 'constrained'.

Cherry pick of I699022b285594edf3c5db10fbdac2f904dc42928 for liberty.

Change-Id: I699022b285594edf3c5db10fbdac2f904dc42928
Partial-Bug: #1522503
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/57/258457/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,74f5723197d00cfa76caf23fd528a7649f810b16,constraints-fwaas,install_command = constraints: {[testenv:common-constraints]install_command} {toxinidir}/tools/tox_install.sh unconstrained {opts} {packages}[testenv:common-constraints] install_command = {toxinidir}/tools/tox_install.sh constrained -c{env:UPPER_CONTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/liberty} {opts} {packages} [testenv:pep8-constraints] install_command = {[testenv:common-constraints]install_command} commands = {[testenv:pep8]commands} whitelist_externals = {[testenv:pep8]whitelist_externals} [testenv:cover-constraints] commands = install_command = {[testenv:common-constraints]install_command} python setup.py testr --coverage --coverage-package-name=neutron_fwaas --testr-args='{posargs}' [testenv:venv-constraints] install_command = {[testenv:common-constraints]install_command} commands = {posargs} [testenv:docs-constraints] install_command = {[testenv:common-constraints]install_command} commands = {[testenv:docs]commands}[testenv:pylint-constraints] install_command = {[testenv:common-constraints]install_command} deps = {[testenv:pylint]deps} commands = pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_fwaas} ,install_command = pip install -U {opts} {packages},78,1
openstack%2Fproject-config~master~I3038aa00f4638a82ac2ad081e91a723f42517d84,openstack/project-config,master,I3038aa00f4638a82ac2ad081e91a723f42517d84,Make VPN constraints jobs voting,ABANDONED,2015-12-10 17:06:39.000000000,2016-02-19 20:00:38.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6659}, {'_account_id': 9656}, {'_account_id': 10980}, {'_account_id': 12612}]","[{'number': 1, 'created': '2015-12-10 17:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/33b116106caeecbd273f3bba79b2f70128249dbe', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\n'}, {'number': 2, 'created': '2015-12-11 12:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ba4afb44146594de83fba92f7bc61a8926c97f6f', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\n'}, {'number': 3, 'created': '2015-12-11 19:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9b2a436ae428adea78408a1a002b5d579b42f34e', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nNOTE: Disabling constraints jobs and enabling non-constraints jobs\nfor liberty (I hope :) until the tox.ini changes are backported.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\n'}, {'number': 4, 'created': '2015-12-14 13:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/99e7ce3b4c0bef39ca242c99d37634e58cfd201c', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nNOTE: Disabling constraints jobs and enabling non-constraints jobs\nfor liberty, until the tox.ini changes are backported.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\n'}, {'number': 5, 'created': '2015-12-14 14:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/642a6b378bc908e569c76fc8f6f04af5b1eb2d89', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\nDepends-On: I4f73a150184c60f170cf78ae9f9b478a04be2db1\n'}, {'number': 6, 'created': '2015-12-14 19:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ace010bf65cf2c8c82ffeef62c2c6d5946ac9645', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\nDepends-On: I4f73a150184c60f170cf78ae9f9b478a04be2db1\n'}, {'number': 7, 'created': '2015-12-16 11:55:00.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e58cb0f6fd6403374881312bb3016e7f73f3e98f', 'message': 'Make VPN constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. Please let me know\nif that is the right way to enable the jobs (instead of the non-\nconstraint jobs).  For VPN, these are pep8 and docs jobs.\n\nChange-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84\nPartial-Bug: #1522503\nDepends-On: I4f73a150184c60f170cf78ae9f9b478a04be2db1\n'}]",6,255992,e58cb0f6fd6403374881312bb3016e7f73f3e98f,33,6,7,6659,,,0,"Make VPN constraints jobs voting

Since the jobs worked in the experimental queue, making the job
voting, by including the constraints template. Please let me know
if that is the right way to enable the jobs (instead of the non-
constraint jobs).  For VPN, these are pep8 and docs jobs.

Change-Id: I3038aa00f4638a82ac2ad081e91a723f42517d84
Partial-Bug: #1522503
Depends-On: I4f73a150184c60f170cf78ae9f9b478a04be2db1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/255992/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,33b116106caeecbd273f3bba79b2f70128249dbe,constraints, - name: python-constraints-jobs, - gate-neutron-vpnaas-pep8-constraints - gate-neutron-vpnaas-docs-constraints,1,2
openstack%2Fproject-config~master~Id0d75916cc18c5dbd6c673f8926616987c4ebf65,openstack/project-config,master,Id0d75916cc18c5dbd6c673f8926616987c4ebf65,Make LBaaS constraints jobs voting,ABANDONED,2015-12-11 12:43:53.000000000,2016-02-19 20:00:13.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6659}, {'_account_id': 9656}, {'_account_id': 10980}, {'_account_id': 12612}]","[{'number': 1, 'created': '2015-12-11 12:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/da77459199c5d1950a7d08e9eddcb7b42f2748aa', 'message': 'Make LBaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For LB, these are\npep8 and docs jobs.\n\nChange-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65\nPartial-Bug: #1522503\n'}, {'number': 2, 'created': '2015-12-11 20:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1f90850c3a56bc6c2ad2696b95195190f3634174', 'message': 'Make LBaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For LB, these are\npep8 and docs jobs.\n\nNote: Disabled constraints jobs and enabled non-constraints jobs\nfor liberty, until the tox.ini changes are backported.\n\nChange-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65\nPartial-Bug: #1522503\n'}, {'number': 3, 'created': '2015-12-14 14:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4d276f37a9f0db4dbcda89610361cd92e5e4c4df', 'message': 'Make LBaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For LB, these are\npep8 and docs jobs.\n\nChange-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65\nPartial-Bug: #1522503\nDepends-On: Ifc980695f59a1930fe50338ee95d32e78ddfc08c\n'}, {'number': 4, 'created': '2015-12-14 19:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/380000cc2cd66cf987bbf855e3fad717c8b73953', 'message': 'Make LBaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For LB, these are\npep8 and docs jobs.\n\nChange-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65\nPartial-Bug: #1522503\nDepends-On: Ifc980695f59a1930fe50338ee95d32e78ddfc08c\n'}, {'number': 5, 'created': '2015-12-14 19:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/246837408c7c648c06e9595c0162fe602375b5ad', 'message': 'Make LBaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For LB, these are\npep8 and docs jobs.\n\nChange-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65\nPartial-Bug: #1522503\nDepends-On: Ifc980695f59a1930fe50338ee95d32e78ddfc08c\n'}, {'number': 6, 'created': '2015-12-16 11:56:18.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9a7beb0b03b4baab1084fd38d3c51ff7c4e6d448', 'message': 'Make LBaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For LB, these are\npep8 and docs jobs.\n\nChange-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65\nPartial-Bug: #1522503\nDepends-On: Ifc980695f59a1930fe50338ee95d32e78ddfc08c\n'}]",5,256391,9a7beb0b03b4baab1084fd38d3c51ff7c4e6d448,26,6,6,6659,,,0,"Make LBaaS constraints jobs voting

Since the jobs worked in the experimental queue, making the job
voting, by including the constraints template. For LB, these are
pep8 and docs jobs.

Change-Id: Id0d75916cc18c5dbd6c673f8926616987c4ebf65
Partial-Bug: #1522503
Depends-On: Ifc980695f59a1930fe50338ee95d32e78ddfc08c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/91/256391/6 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,da77459199c5d1950a7d08e9eddcb7b42f2748aa,lbaas-constraints, - name: python-constraints-jobs, - name: python-jobs - gate-neutron-lbaas-pep8-constraints - gate-neutron-lbaas-docs-constraints,1,3
openstack%2Fproject-config~master~Ic3dcdf1db12023c85622ee042ca59775b133afc3,openstack/project-config,master,Ic3dcdf1db12023c85622ee042ca59775b133afc3,Make FWaaS constraints jobs voting,ABANDONED,2015-12-11 20:23:07.000000000,2016-02-19 20:00:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6659}, {'_account_id': 7118}, {'_account_id': 10980}, {'_account_id': 12612}]","[{'number': 1, 'created': '2015-12-11 20:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/54f19fdb9a7bce3c5447c708533a49d99b91f7bc', 'message': 'Make FWaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For FW, these are\npep8 and docs jobs.\n\nNote: Disabled constraints jobs and enabled non-constraints jobs\nfor liberty, until the tox.ini changes are backported.\n\nChange-Id: Ic3dcdf1db12023c85622ee042ca59775b133afc3\nPartial-Bug: #1522503\n'}, {'number': 2, 'created': '2015-12-14 14:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/166b120a5fbf099b69bbc98faf7a2c06f4527c21', 'message': 'Make FWaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For FW, these are\npep8 and docs jobs.\n\nChange-Id: Ic3dcdf1db12023c85622ee042ca59775b133afc3\nPartial-Bug: #1522503\nDepends-On: Ice9624e3841691b6714275b14301b146c3676186\n'}, {'number': 3, 'created': '2015-12-14 19:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8914841a97f878a22fb40f27e431841a400d88e3', 'message': 'Make FWaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For FW, these are\npep8 and docs jobs.\n\nChange-Id: Ic3dcdf1db12023c85622ee042ca59775b133afc3\nPartial-Bug: #1522503\nDepends-On: Ice9624e3841691b6714275b14301b146c3676186\n'}, {'number': 4, 'created': '2015-12-15 16:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/aa2429e3ddb0a101497c26381b6006910df34653', 'message': 'Make FWaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For FW, these are\npep8 and docs jobs.\n\nChange-Id: Ic3dcdf1db12023c85622ee042ca59775b133afc3\nPartial-Bug: #1522503\nDepends-On: Ice9624e3841691b6714275b14301b146c3676186\n'}, {'number': 5, 'created': '2015-12-16 11:57:51.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1846ed2fe9d0783a1b3c82f2c5ded4886576016a', 'message': 'Make FWaaS constraints jobs voting\n\nSince the jobs worked in the experimental queue, making the job\nvoting, by including the constraints template. For FW, these are\npep8 and docs jobs.\n\nChange-Id: Ic3dcdf1db12023c85622ee042ca59775b133afc3\nPartial-Bug: #1522503\nDepends-On: Ice9624e3841691b6714275b14301b146c3676186\n'}]",5,256702,1846ed2fe9d0783a1b3c82f2c5ded4886576016a,23,6,5,6659,,,0,"Make FWaaS constraints jobs voting

Since the jobs worked in the experimental queue, making the job
voting, by including the constraints template. For FW, these are
pep8 and docs jobs.

Change-Id: Ic3dcdf1db12023c85622ee042ca59775b133afc3
Partial-Bug: #1522503
Depends-On: Ice9624e3841691b6714275b14301b146c3676186
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/256702/5 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,54f19fdb9a7bce3c5447c708533a49d99b91f7bc,fwaas-constraints," # TODO(pcm): Remove liberty, once tox.ini constraints changes are backported - name: gate-neutron-fwaas-pep8 branch: ^(?:stable/kilo|liberty).*$ - name: gate-neutron-fwaas-docs branch: ^(?:stable/kilo|liberty).*$ - name: ^gate-.neutron-fwaas*-constraints$ branch: ^(?!stable/kilo|liberty).*$ - name: python-constraints-jobs", - gate-neutron-fwaas-pep8-constraints - gate-neutron-fwaas-docs-constraints,11,2
openstack%2Fneutron-lbaas~stable%2Fliberty~I699022b285594edf3c5db10fbdac2f904dc42928,openstack/neutron-lbaas,stable/liberty,I699022b285594edf3c5db10fbdac2f904dc42928,Added constraints tox targets,ABANDONED,2015-12-16 12:11:58.000000000,2016-02-19 19:59:54.000000000,,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 8344}, {'_account_id': 9656}, {'_account_id': 12403}]","[{'number': 1, 'created': '2015-12-16 12:11:58.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/f15aa8516400bc107cf5fe19fd790a5fe182d13c', 'message': ""Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.\n\nMade tox_install.sh use constraints file to install both the project and\nneutron dependency, if the the first argument is 'constrained'.\n\nCherry pick of I699022b285594edf3c5db10fbdac2f904dc42928 for liberty.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\nPartial-Bug: #1522503\n""}]",1,258456,f15aa8516400bc107cf5fe19fd790a5fe182d13c,8,5,1,6659,,,0,"Added constraints tox targets

These are eventually going to be used in gate instead of unconstrained
jobs. There is some code duplication in commands definitions, but tox
does not allow to inherit definitions with {posargs} substitution.

Made tox_install.sh use constraints file to install both the project and
neutron dependency, if the the first argument is 'constrained'.

Cherry pick of I699022b285594edf3c5db10fbdac2f904dc42928 for liberty.

Change-Id: I699022b285594edf3c5db10fbdac2f904dc42928
Partial-Bug: #1522503
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/56/258456/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,f15aa8516400bc107cf5fe19fd790a5fe182d13c,constraint-lbaas,install_command = constraints: {[testenv:common-constraints]install_command} {toxinidir}/tools/tox_install.sh unconstrained {opts} {packages}[testenv:common-constraints] install_command = {toxinidir}/tools/tox_install.sh constrained -c{env:UPPER_CONTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/liberty} {opts} {packages} # pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_lbaas}[testenv:pep8-constraints] install_command = {[testenv:common-constraints]install_command} commands = flake8 # pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_lbaas} neutron-db-manage --subproject neutron-lbaas --config-file neutron_lbaas/tests/etc/neutron.conf check_migration whitelist_externals = {[testenv:pep8]whitelist_externals} [testenv:cover-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py testr --coverage --coverage-package-name=neutron_lbaas --testr-args='{posargs}' [testenv:venv-constraints] install_command = {[testenv:common-constraints]install_command} commands = {posargs} [testenv:docs-constraints] install_command = {[testenv:common-constraints]install_command} commands = {[testenv:docs]commands} [testenv:py34-constraints] install_command = {[testenv:common-constraints]install_command} commands = {[testenv:py34]commands} ,install_command = {toxinidir}/tools/tox_install.sh {opts} {packages}deps = {[testenv]deps},41,6
openstack%2Fneutron-vpnaas~stable%2Fliberty~I699022b285594edf3c5db10fbdac2f904dc42928,openstack/neutron-vpnaas,stable/liberty,I699022b285594edf3c5db10fbdac2f904dc42928,Added constraints tox targets,ABANDONED,2015-12-16 12:11:05.000000000,2016-02-19 19:59:46.000000000,,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 8344}, {'_account_id': 9656}, {'_account_id': 10692}]","[{'number': 1, 'created': '2015-12-16 12:11:05.000000000', 'files': ['doc/source/devref/multiple-local-subnets.rst', 'tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/aa6deccbfa565a6b5773cff96b98109e85022de4', 'message': ""Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.\n\nMade tox_install.sh use constraints file to install both the project and\nneutron dependency, if the first argument is 'constrained'.\n\nNote: To test the docs targets, needed to fix a formatting issue in\nmultiple-local-subnets.rst document.\n\nCherry pick of I699022b285594edf3c5db10fbdac2f904dc42928 for liberty.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\nPartial-Bug: #1522503\n""}]",2,258455,aa6deccbfa565a6b5773cff96b98109e85022de4,8,5,1,6659,,,0,"Added constraints tox targets

These are eventually going to be used in gate instead of unconstrained
jobs. There is some code duplication in commands definitions, but tox
does not allow to inherit definitions with {posargs} substitution.

Made tox_install.sh use constraints file to install both the project and
neutron dependency, if the first argument is 'constrained'.

Note: To test the docs targets, needed to fix a formatting issue in
multiple-local-subnets.rst document.

Cherry pick of I699022b285594edf3c5db10fbdac2f904dc42928 for liberty.

Change-Id: I699022b285594edf3c5db10fbdac2f904dc42928
Partial-Bug: #1522503
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/55/258455/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/multiple-local-subnets.rst', 'tools/tox_install.sh', 'tox.ini']",3,aa6deccbfa565a6b5773cff96b98109e85022de4,constraints-vpnaas,install_command = constraints: {[testenv:common-constraints]install_command} {toxinidir}/tools/tox_install.sh unconstrained {opts} {packages}[testenv:common-constraints] install_command = {toxinidir}/tools/tox_install.sh constrained -c{env:UPPER_CONTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/liberty} {opts} {packages} [testenv:pep8-constraints] install_command = {[testenv:common-constraints]install_command} commands = flake8 pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_vpnaas} {toxinidir}/tools/check_unit_test_structure.sh neutron-db-manage --subproject neutron-vpnaas --database-connection sqlite:// check_migration whitelist_externals = {[testenv:pep8]whitelist_externals} [testenv:cover-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py test --coverage --coverage-package-name=neutron_vpnaas --testr-args='{posargs}' [testenv:venv-constraints] install_command = {[testenv:common-constraints]install_command} commands = {posargs} [testenv:docs-constraints] install_command = {[testenv:common-constraints]install_command} commands = {[testenv:docs]commands} ,install_command = {toxinidir}/tools/tox_install.sh {opts} {packages},110,72
openstack%2Ftripleo-heat-templates~master~I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec,openstack/tripleo-heat-templates,master,I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec,Include big switch puppet modules for deploying overcloud,ABANDONED,2016-01-25 08:38:09.000000000,2016-02-19 19:53:06.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 15342}]","[{'number': 1, 'created': '2016-01-25 08:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/56225ffef8fb2052cc8286d50002c4a733527920', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change include puppet modules for deploying controller\nand compute nodes. It depends on two review requests:\n\nhttps://review.gerrithub.io/#/c/261084/\nhttps://review.openstack.org/#/c/271922/\n\nChange-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec\n'}, {'number': 2, 'created': '2016-01-25 08:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1d99f4b7316532e3642c386e0d054c17fad116ab', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes. It depends on two review requests:\n\nhttps://review.gerrithub.io/#/c/261084/\nhttps://review.openstack.org/#/c/271922/\n\nChange-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec\n'}, {'number': 3, 'created': '2016-01-29 22:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2f839d7b603f5184efbabf37af81e631f40ec397', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes. It depends on two review requests:\n\nhttps://review.openstack.org/#/c/271963/\nhttps://review.openstack.org/#/c/271922/\n\nChange-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec\n'}, {'number': 4, 'created': '2016-02-08 21:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cad60d255f9d98d8ff0dcd931719db762525fca2', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes. It depends on two review requests:\n\nhttps://review.openstack.org/#/c/271963/\nhttps://review.openstack.org/#/c/271922/\n\nChange-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec\n'}, {'number': 5, 'created': '2016-02-09 17:55:53.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/extraconfig/pre_deploy/controller/neutron-ml2-bigswitch.yaml', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ed4585abee2f4da9e3c41ae203da3868a0786b68', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes. It depends on two review requests:\n\nhttps://review.openstack.org/#/c/271963/\nhttps://review.openstack.org/#/c/271922/\n\nChange-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec\n'}]",4,271940,ed4585abee2f4da9e3c41ae203da3868a0786b68,31,6,5,15342,,,0,"Include big switch puppet modules for deploying overcloud

This change includes puppet modules for deploying controller
and compute nodes. It depends on two review requests:

https://review.openstack.org/#/c/271963/
https://review.openstack.org/#/c/271922/

Change-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/271940/3 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp']",3,56225ffef8fb2052cc8286d50002c4a733527920,manual, if 'bsn_ml2' in hiera('neutron_mechanism_drivers') { include ::neutron::agents::bigswitch," if hiera('neutron_enable_bigswitch_ml2', false) {",8,2
openstack%2Fmagnum~master~Ifaa71b6c8a236041b033da8ea0a8e403ff884594,openstack/magnum,master,Ifaa71b6c8a236041b033da8ea0a8e403ff884594,Troubleshooting Kubernetes networking,MERGED,2016-01-23 17:17:34.000000000,2016-02-19 19:51:14.000000000,2016-02-19 19:51:14.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 8143}, {'_account_id': 9591}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 12385}, {'_account_id': 18498}]","[{'number': 1, 'created': '2016-01-23 17:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/062880738769da2774d7e9d82fea4f20e96f9745', 'message': 'Troubleshooting Kubernetes networking\n\nAdd guide for debugging inter-pods communication\n\nThe networking between pods is different and separate from the\nneutron network set up for the cluster.  Flannel is the default\nnetwork for Kubernetes cluster and Docker is configured to use\nFlannel subnet.  If there is a problem, the pods will not be\nable to talk to each other.\n\nThis section describes techniques for debugging Kubernetes\nnetworking based on Flannel.\n\nPartially implements: blueprint magnum-troubleshooting-guide\nChange-Id: Ifaa71b6c8a236041b033da8ea0a8e403ff884594\n'}, {'number': 2, 'created': '2016-01-27 20:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e2374feb6c66c6ab451219f7a6e8f31a40f3bce9', 'message': 'Troubleshooting Kubernetes networking\n\nAdd guide for debugging inter-pods communication\n\nThe networking between pods is different and separate from the\nneutron network set up for the cluster.  Flannel is the default\nnetwork for Kubernetes cluster and Docker is configured to use\nFlannel subnet.  If there is a problem, the pods will not be\nable to talk to each other.\n\nThis section describes techniques for debugging Kubernetes\nnetworking based on Flannel.\n\nPartially implements: blueprint magnum-troubleshooting-guide\nChange-Id: Ifaa71b6c8a236041b033da8ea0a8e403ff884594\n'}, {'number': 3, 'created': '2016-01-28 07:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1a77e0b3401e6d0146ac82b3092be4645528cd3f', 'message': 'Troubleshooting Kubernetes networking\n\nAdd guide for debugging inter-pods communication\n\nThe networking between pods is different and separate from the\nneutron network set up for the cluster.  Flannel is the default\nnetwork for Kubernetes cluster and Docker is configured to use\nFlannel subnet.  If there is a problem, the pods will not be\nable to talk to each other.\n\nThis section describes techniques for debugging Kubernetes\nnetworking based on Flannel.\n\nPartially implements: blueprint magnum-troubleshooting-guide\nChange-Id: Ifaa71b6c8a236041b033da8ea0a8e403ff884594\n'}, {'number': 4, 'created': '2016-01-31 03:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/17cab84fab5faac22b135b28a541d7600f3cdf39', 'message': 'Troubleshooting Kubernetes networking\n\nAdd guide for debugging inter-pods communication\n\nThe networking between pods is different and separate from the\nneutron network set up for the cluster.  Flannel is the default\nnetwork for Kubernetes cluster and Docker is configured to use\nFlannel subnet.  If there is a problem, the pods will not be\nable to talk to each other.\n\nThis section describes techniques for debugging Kubernetes\nnetworking based on Flannel.\n\nPartially implements: blueprint magnum-troubleshooting-guide\nChange-Id: Ifaa71b6c8a236041b033da8ea0a8e403ff884594\n'}, {'number': 5, 'created': '2016-02-01 02:24:12.000000000', 'files': ['doc/source/troubleshooting-guide.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e74830a5889e3db53ffb414e9718235d09cc55f4', 'message': 'Troubleshooting Kubernetes networking\n\nAdd guide for debugging inter-pods communication\n\nThe networking between pods is different and separate from the\nneutron network set up for the cluster.  Flannel is the default\nnetwork for Kubernetes cluster and Docker is configured to use\nFlannel subnet.  If there is a problem, the pods will not be\nable to talk to each other.\n\nThis section describes techniques for debugging Kubernetes\nnetworking based on Flannel.\n\nPartially implements: blueprint magnum-troubleshooting-guide\nChange-Id: Ifaa71b6c8a236041b033da8ea0a8e403ff884594\n'}]",40,271710,e74830a5889e3db53ffb414e9718235d09cc55f4,55,10,5,9591,,,0,"Troubleshooting Kubernetes networking

Add guide for debugging inter-pods communication

The networking between pods is different and separate from the
neutron network set up for the cluster.  Flannel is the default
network for Kubernetes cluster and Docker is configured to use
Flannel subnet.  If there is a problem, the pods will not be
able to talk to each other.

This section describes techniques for debugging Kubernetes
networking based on Flannel.

Partially implements: blueprint magnum-troubleshooting-guide
Change-Id: Ifaa71b6c8a236041b033da8ea0a8e403ff884594
",git fetch https://review.opendev.org/openstack/magnum refs/changes/10/271710/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/troubleshooting-guide.rst'],1,062880738769da2774d7e9d82fea4f20e96f9745,bp/magnum-troubleshooting-guide,"I deploy pods and service on Kubernetes bay but the app is not working The pods and services are running and the status looks correct, but if the app is performing communication between pods through services, verify `Kubernetes networking`_. Kubernetes networking --------------------- The networking between pods is different and separate from the neutron network set up for the cluster. Kubernetes uses a flat network space for the pods and services and Flannel is one way to provide this space. Flannel is an overlay network that runs on top of the neutron network. It works by encapsulating the messages between pods and forwarding them to the correct node that hosts the target pod. When Flannel is specified as the network driver for the cluster, it provides the connectivity between pods. For this section, Flannel is assumed to be the network driver. It is possible for the pods to come up correctly and be able connect to the external internet, but not function with other pods as expected because they cannot reach each other. In this case, use the following steps to verify the inter-pods networking and pinpoint problems. First check the connectivity at the node level. Log into two different minion nodes and run a docker container on each node:: sudo docker run -it busybox In each container, get the IP assigned by:: # ip -f inet -o a | grep eth0 | awk '{print $4}' 10.100.54.2/24 # ip -f inet -o a | grep eth0 | awk '{print $4}' 10.100.49.3/24 Check that the container can see each other by pinging from one to another:: ping 10.100.49.3 PING 10.100.49.3 (10.100.49.3): 56 data bytes 64 bytes from 10.100.49.3: seq=0 ttl=60 time=1.868 ms 64 bytes from 10.100.49.3: seq=1 ttl=60 time=1.108 ms ping 10.100.54.2 PING 10.100.54.2 (10.100.54.2): 56 data bytes 64 bytes from 10.100.54.2: seq=0 ttl=60 time=2.678 ms 64 bytes from 10.100.54.2: seq=1 ttl=60 time=1.240 ms If ping is not successful, check the following: - Is neutron working properly? Try pinging between the VMs. - Verify the IP are in the correct Flannel subnet assigned to the node. If this is not correct, the docker daemon is not configured correctly with the parameter *--bip*. Check the systemd service for docker. Find the Flannel CIDR on each node by:: cat /run/flannel/subnet.env - Is Flannel running properly? check the `flannel service`_. - Ping and try `tcpdump <http://docs.openstack.org/openstack-ops/content/network_troubleshooting.html#tcpdump>`_ on each network interface along the path between two nodes to see how far the message is able to travel. The message path should be as follows: 1. Source node: docker0 2. Source node: flannel0 3. Source node: eth0 4. Target node: eth0 5. Target node: flannel0 6. Target node: docker0 If ping works, this means the flannel overlay network is functioning correctly. The containers created by Kubernetes for pods will be on the same IP subnet as the containers created directly in Docker as above, so they will have the same connectivity. However, the pods still may not be able to reach each other because normally they connect through some Kubernetes services rather than directly. The services are supported by the kube-proxy and rules inserted into the iptables, therefore their networking paths have some extra hops and there may be problems here. To check the connectivity at the Kubernetes pod level, log into the master node and create two pods running busybox and a service for one of the pods:: cat > bb1.yaml << END apiVersion: v1 kind: Pod metadata: name: busybox-1 spec: containers: - name: busybox-1 image: busybox args: - sleep - ""1000000"" END cat > bb2.yaml << END apiVersion: v1 kind: Pod metadata: name: busybox-2 spec: containers: - name: busybox-2 image: busybox args: - sleep - ""1000000"" END cat > bb-service-1.yaml << END apiVersion: v1 kind: Service metadata: name: bb-service-1 spec: ports: - port: 5201 targetPort: 5201 protocol: TCP selector: app: busybox-1 END kubectl create -f bb1.yaml kubectl create -f bb2.yaml kubectl create -f bb-service-1.yaml Get the IP for the bb-service-1, which should route message to the pod busybox-1:: kubectl describe services bb-service-1 | grep IP: | awk '{print $2}' 10.254.152.10 Note the service IP to check below. Log into the node where the busybox-2 pod is running and attach to the busybox-2 container:: export DOCKER_ID=`sudo docker ps | grep k8s_busybox-2 | awk '{print $1}'` sudo docker exec -it $DOCKER_ID sh From here, you can try to reach the busybox-1 pod through the service. Ping does not work on service IP because service is at the UPD/TCP level, but you can check for connectivity by using telnet to the service IP and port. Use the service IP obtained above and run the command:: # telnet 10.254.152.10 5201 If the pod can be reached through the service, the command will return the message:: Connection closed by foreign host If there is no connectivity, the command will hang and time out. In this case, check the following: - Is kube-proxy running on the nodes? It runs as a container on each node:: sudo docker ps | grep k8s_kube-proxy - Try additional `service debugging <https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/user-guide/debugging-services.md>`_. ",,174,0
openstack%2Fproject-config~master~I8f7a1a4e591347349fe9e56ab9f0e86f7d05dbde,openstack/project-config,master,I8f7a1a4e591347349fe9e56ab9f0e86f7d05dbde,osops-tools-monitoring: add bashate job,ABANDONED,2015-09-29 18:25:18.000000000,2016-02-19 19:47:08.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 9060}, {'_account_id': 10980}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-09-29 18:25:18.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1857487c84398dae892221f6367736e2a51698e8', 'message': 'osops-tools-monitoring: add bashate job\n\nChange-Id: I8f7a1a4e591347349fe9e56ab9f0e86f7d05dbde\nDepends-On: Ied0ccbc955c00c77b691d9260cb1077ae2894afd\n'}]",0,229094,1857487c84398dae892221f6367736e2a51698e8,10,6,1,167,,,0,"osops-tools-monitoring: add bashate job

Change-Id: I8f7a1a4e591347349fe9e56ab9f0e86f7d05dbde
Depends-On: Ied0ccbc955c00c77b691d9260cb1077ae2894afd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/94/229094/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,1857487c84398dae892221f6367736e2a51698e8,osops-tools-monitoring-bashate, check: - gate-osops-tools-monitoring-bashate gate: - gate-osops-tools-monitoring-bashate, - name: noop-jobs,11,1
openstack%2Fneutron-lbaas-dashboard~master~Iadc1dae0019d00d1fd13f875ab75da9e8d20f3bb,openstack/neutron-lbaas-dashboard,master,Iadc1dae0019d00d1fd13f875ab75da9e8d20f3bb,Use static file auto-discovery,MERGED,2016-02-13 18:00:55.000000000,2016-02-19 19:45:27.000000000,2016-02-19 19:45:27.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9981}, {'_account_id': 12403}]","[{'number': 1, 'created': '2016-02-13 18:00:55.000000000', 'files': ['neutron_lbaas_dashboard/enabled/_1481_project_ng_loadbalancersv2_panel.py', 'neutron_lbaas_dashboard/dashboards/project/ngloadbalancersv2/__init__.py', 'neutron_lbaas_dashboard/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas-dashboard/commit/d065a53474dd9a08901faa8388b997144b604941', 'message': 'Use static file auto-discovery\n\nThis moves around the REST API module import so that it gets\nimported correctly and does not mess up the static file auto\ndiscovery process. Individual files can then be removed from\nthe plugin file.\n\nPartially-Implements: blueprint horizon-lbaas-v2-ui\nChange-Id: Iadc1dae0019d00d1fd13f875ab75da9e8d20f3bb\n'}]",0,279891,d065a53474dd9a08901faa8388b997144b604941,9,5,1,9647,,,0,"Use static file auto-discovery

This moves around the REST API module import so that it gets
imported correctly and does not mess up the static file auto
discovery process. Individual files can then be removed from
the plugin file.

Partially-Implements: blueprint horizon-lbaas-v2-ui
Change-Id: Iadc1dae0019d00d1fd13f875ab75da9e8d20f3bb
",git fetch https://review.opendev.org/openstack/neutron-lbaas-dashboard refs/changes/91/279891/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas_dashboard/enabled/_1481_project_ng_loadbalancersv2_panel.py', 'neutron_lbaas_dashboard/__init__.py', 'neutron_lbaas_dashboard/dashboards/project/ngloadbalancersv2/__init__.py']",3,d065a53474dd9a08901faa8388b997144b604941,bp/horizon-lbaas-v2-ui,"# Copyright 2016 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # Register the REST API URLs so they can be called from the JavaScript files from neutron_lbaas_dashboard.api import rest # noqa ",,19,81
openstack%2Fcinder~master~I55bcdd350571a96e5bdefb5a820fe84a633f63cf,openstack/cinder,master,I55bcdd350571a96e5bdefb5a820fe84a633f63cf,Updated from global requirements,MERGED,2016-02-12 20:00:25.000000000,2016-02-19 19:44:22.000000000,2016-02-15 17:00:24.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 8871}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 20490}]","[{'number': 1, 'created': '2016-02-12 20:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/050df3d8e1469ea662b34291e0a30d8f41a88039', 'message': 'Updated from global requirements\n\nChange-Id: I55bcdd350571a96e5bdefb5a820fe84a633f63cf\n'}, {'number': 2, 'created': '2016-02-14 01:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/be57765000144c599d253c13acd9ae3b5a856cfe', 'message': 'Updated from global requirements\n\nChange-Id: I55bcdd350571a96e5bdefb5a820fe84a633f63cf\n'}, {'number': 3, 'created': '2016-02-14 23:06:38.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cbeca35da1e887a53a2f801db253cf18bef46710', 'message': 'Updated from global requirements\n\nChange-Id: I55bcdd350571a96e5bdefb5a820fe84a633f63cf\n'}]",0,279759,cbeca35da1e887a53a2f801db253cf18bef46710,60,32,3,11131,,,0,"Updated from global requirements

Change-Id: I55bcdd350571a96e5bdefb5a820fe84a633f63cf
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/279759/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,050df3d8e1469ea662b34291e0a30d8f41a88039,openstack/requirements,oslo.versionedobjects>=1.5.0 # Apache-2.0,oslo.versionedobjects>=1.4.0 # Apache-2.0,1,1
openstack%2Fproject-config~master~I13ab4cf1f0ed1361fd21350d6712aced35f1f78e,openstack/project-config,master,I13ab4cf1f0ed1361fd21350d6712aced35f1f78e,Move multinode job from experimental to non-voting for Tempest,ABANDONED,2015-07-21 05:15:51.000000000,2016-02-19 19:44:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-07-21 05:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7166a542dd1781a3e8cdeff7f639d717bd9f01cc', 'message': 'Move multinode job from experimental to non-voting for Tempest\n\nCurrently ""gate-tempest-dsvm-multinode-full"" job runs as experimental job\nfor Tempest.\nWhen Live Migration tests runs (on this job), we should be actively monitor\nthose with non-voting job.\n\nThis job is non-voting for Nova and will be useful if we have same for Tempest\ntoo so that any changes in multinode tests like Live Migration can be monitored\nactively.\n\nChange-Id: I13ab4cf1f0ed1361fd21350d6712aced35f1f78e\nRelated-Bug: 1476478\n'}, {'number': 2, 'created': '2015-07-22 23:53:41.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1e0d44fc7b3cfe3c7bbe3201c36a5c82ca5dd784', 'message': 'Move multinode job from experimental to non-voting for Tempest\n\nCurrently ""gate-tempest-dsvm-multinode-full"" job runs as experimental job\nfor Tempest.\nWhen Live Migration tests runs (on this job), we should be actively monitor\nthose with non-voting job.\n\nThis job is non-voting for Nova and will be useful if we have same for Tempest\ntoo so that any changes in multinode tests like Live Migration can be monitored\nactively.\n\nChange-Id: I13ab4cf1f0ed1361fd21350d6712aced35f1f78e\nRelated-Bug: 1476478\n'}]",0,203923,1e0d44fc7b3cfe3c7bbe3201c36a5c82ca5dd784,8,5,2,8556,,,0,"Move multinode job from experimental to non-voting for Tempest

Currently ""gate-tempest-dsvm-multinode-full"" job runs as experimental job
for Tempest.
When Live Migration tests runs (on this job), we should be actively monitor
those with non-voting job.

This job is non-voting for Nova and will be useful if we have same for Tempest
too so that any changes in multinode tests like Live Migration can be monitored
actively.

Change-Id: I13ab4cf1f0ed1361fd21350d6712aced35f1f78e
Related-Bug: 1476478
",git fetch https://review.opendev.org/openstack/project-config refs/changes/23/203923/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,7166a542dd1781a3e8cdeff7f639d717bd9f01cc,bug/1476478, - gate-tempest-dsvm-multinode-full, - gate-tempest-dsvm-multinode-full,1,1
openstack%2Fpython-solumclient~master~I0a7c7c572105fd01c702861d73eaf2015ebe0398,openstack/python-solumclient,master,I0a7c7c572105fd01c702861d73eaf2015ebe0398,Added logs support for apps,MERGED,2016-02-10 19:43:50.000000000,2016-02-19 19:35:42.000000000,2016-02-19 19:35:42.000000000,"[{'_account_id': 3}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-02-10 19:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/659e92796de112e8b5213a582bf35bddf24f8f79', 'message': 'Added logs support for apps\n\nChange-Id: I0a7c7c572105fd01c702861d73eaf2015ebe0398\nCloses-Bug: #1544123\n'}, {'number': 2, 'created': '2016-02-11 16:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/8ef7dd4e58b5a992ff839b4215983939d50e626e', 'message': 'Added logs support for apps\n\nChange-Id: I0a7c7c572105fd01c702861d73eaf2015ebe0398\nCloses-Bug: #1544123\n'}, {'number': 3, 'created': '2016-02-17 17:04:12.000000000', 'files': ['solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/3dfb655aed3c9a4a284baba1a25685646c01472f', 'message': 'Added logs support for apps\n\nChange-Id: I0a7c7c572105fd01c702861d73eaf2015ebe0398\nCloses-Bug: #1544123\n'}]",1,278582,3dfb655aed3c9a4a284baba1a25685646c01472f,14,2,3,2506,,,0,"Added logs support for apps

Change-Id: I0a7c7c572105fd01c702861d73eaf2015ebe0398
Closes-Bug: #1544123
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/82/278582/2 && git format-patch -1 --stdout FETCH_HEAD,['solumclient/solum.py'],1,659e92796de112e8b5213a582bf35bddf24f8f79,bug/1544123," solum app logs <NAME|UUID> [--wf-id <wf-id>] Show the logs of an application for all the workflows. wf-id is optional flag which can be used to pass in id of one of the existing workflows. If provided, the logs only for that workflow are displayed. def _display_logs_for_all_workflows(self, app): wfman = cli_wf.WorkflowManager(self.client, app_id=app.id) wfs = wfman.list() all_logs_list = [] fields = [""resource_uuid"", ""created_at""] for wf in wfs: revision = wf.wf_id loglist = wfman.logs(revision_or_id=revision) for log in loglist: all_logs_list.append(log) strategy_info = json.loads(log.strategy_info) if log.strategy == 'local': if 'local_storage' not in fields: fields.append('local_storage') log.local_storage = log.location elif log.strategy == 'swift': if 'swift_container' not in fields: fields.append('swift_container') if 'swift_path' not in fields: fields.append('swift_path') log.swift_container = strategy_info['container'] log.swift_path = log.location else: if 'location' not in fields: fields.append('location') self._print_list(all_logs_list, fields) def logs(self): """"""Print a list of all logs belonging to a single app."""""" self.parser.add_argument('name') self.parser.add_argument('--wf-id', dest='wf_id', help=""Workflow ID"") args = self.parser.parse_args() app = self.client.apps.find(name_or_id=args.name) if args.wf_id: try: revision = int(args.wf_id, 10) except (ValueError, TypeError): revision = args.wf_id display_logs_for_single_workflow(self, app, revision) else: self._display_logs_for_all_workflows(app) def display_logs_for_single_workflow(ref, app, revision): wfman = cli_wf.WorkflowManager(ref.client, app_id=app.id) loglist = wfman.logs(revision_or_id=revision) fields = [""resource_uuid""] for log in loglist: strategy_info = json.loads(log.strategy_info) if log.strategy == 'local': if 'local_storage' not in fields: fields.append('local_storage') log.local_storage = log.location elif log.strategy == 'swift': if 'swift_container' not in fields: fields.append('swift_container') if 'swift_path' not in fields: fields.append('swift_path') log.swift_container = strategy_info['container'] log.swift_path = log.location else: if 'location' not in fields: fields.append('location') ref._print_list(loglist, fields) display_logs_for_single_workflow(self, app, revision) solum app logs <NAME|UUID> [--wf-id <wf-id>] Show the logs of an application for all the workflows. wf-id is optional flag which can be used to pass in id of one of the existing workflows. If provided, the logs only for that workflow are displayed."," wfman = cli_wf.WorkflowManager(self.client, app_id=app.id) loglist = wfman.logs(revision_or_id=revision) fields = [""resource_uuid""] for log in loglist: strategy_info = json.loads(log.strategy_info) if log.strategy == 'local': if 'local_storage' not in fields: fields.append('local_storage') log.local_storage = log.location elif log.strategy == 'swift': if 'swift_container' not in fields: fields.append('swift_container') if 'swift_path' not in fields: fields.append('swift_path') log.swift_container = strategy_info['container'] log.swift_path = log.location else: if 'location' not in fields: fields.append('location') self._print_list(loglist, fields) solum app logs <APP_NAME|UUID> Show the logs of an application for all the deployments.",86,24
openstack%2Fneutron~master~I8c462a4ee6f60ef716bf9e4d7f83a35c7e1dead0,openstack/neutron,master,I8c462a4ee6f60ef716bf9e4d7f83a35c7e1dead0,Allow other extensions to extend Securitygroup resources,MERGED,2015-12-24 15:00:14.000000000,2016-02-19 19:21:47.000000000,2016-02-19 06:33:58.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-12-24 15:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83e2dd250ba3db3bc219ec429a37fb1108994240', 'message': 'Allow other extension to extend Securitygroup resources\n\nChange-Id: I8c462a4ee6f60ef716bf9e4d7f83a35c7e1dead0\nCloses-Bug: #1529109\n'}, {'number': 2, 'created': '2015-12-27 14:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ee7a333d992b81dbee08279c3289690d5e97617', 'message': 'Allow other extensions to extend Securitygroup resources\n\nThe Neutron Securitygroup extension defines two resources:\nsecurity-group\nsecurity-group-rule\n\nSo that other extensions could extend one or both of this resources, the\nsecurity-group extension descriptor must override the base class method,\n""neutron.extensions.ExtensionDescriptor.update_attributes_map"".\n\nChange-Id: I8c462a4ee6f60ef716bf9e4d7f83a35c7e1dead0\nCloses-Bug: #1529109\n'}, {'number': 3, 'created': '2016-02-19 02:25:03.000000000', 'files': ['neutron/extensions/securitygroup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/18bc556bd44c5f73e37dbc9687c7792065440722', 'message': 'Allow other extensions to extend Securitygroup resources\n\nThe Neutron Securitygroup extension defines two resources:\nsecurity-group\nsecurity-group-rule\n\nSo that other extensions could extend one or both of this resources, the\nsecurity-group extension descriptor must override the base class method,\n""neutron.extensions.ExtensionDescriptor.update_attributes_map"".\n\nChange-Id: I8c462a4ee6f60ef716bf9e4d7f83a35c7e1dead0\nCloses-Bug: #1529109\n'}]",6,261338,18bc556bd44c5f73e37dbc9687c7792065440722,63,19,3,9423,,,0,"Allow other extensions to extend Securitygroup resources

The Neutron Securitygroup extension defines two resources:
security-group
security-group-rule

So that other extensions could extend one or both of this resources, the
security-group extension descriptor must override the base class method,
""neutron.extensions.ExtensionDescriptor.update_attributes_map"".

Change-Id: I8c462a4ee6f60ef716bf9e4d7f83a35c7e1dead0
Closes-Bug: #1529109
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/261338/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/securitygroup.py'],1,83e2dd250ba3db3bc219ec429a37fb1108994240,bug/1529109," def update_attributes_map(self, attributes): super(Securitygroup, self).update_attributes_map( attributes, extension_attrs_map=RESOURCE_ATTRIBUTE_MAP) ",,4,0
openstack%2Fbarbican~master~Ib0d6ed503eba0d02b0f60eec9c98734aa6fe4535,openstack/barbican,master,Ib0d6ed503eba0d02b0f60eec9c98734aa6fe4535,Tolerate installation of pycryptodome,ABANDONED,2016-02-14 18:35:39.000000000,2016-02-19 19:12:26.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 8623}, {'_account_id': 10873}, {'_account_id': 15274}]","[{'number': 1, 'created': '2016-02-14 18:35:39.000000000', 'files': ['barbican/plugin/crypto/simple_crypto.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/f5ea17d02431acc5fecff7291c0db6bf83374854', 'message': 'Tolerate installation of pycryptodome\n\nNewer versions of pysaml2 uses pycryptodome, so if by\naccident if this library gets installed, Nova breaks.\n\nparamiko folks are working on this:\nhttps://github.com/paramiko/paramiko/issues/637\n\nIn the meanwhile, we should tolerate if either pycrypto\nor pycryptodome is installed.\n\nIn this specific review, we should pass only the first\nparam and use the defaults for the test of the params:\nhttps://github.com/Legrandin/pycryptodome/blob/master/lib/Crypto/PublicKey/RSA.py#L405\nhttps://github.com/dlitz/pycrypto/blob/master/lib/Crypto/PublicKey/RSA.py#L499\n\nChange-Id: Ib0d6ed503eba0d02b0f60eec9c98734aa6fe4535\n'}]",0,280014,f5ea17d02431acc5fecff7291c0db6bf83374854,8,5,1,5638,,,0,"Tolerate installation of pycryptodome

Newer versions of pysaml2 uses pycryptodome, so if by
accident if this library gets installed, Nova breaks.

paramiko folks are working on this:
https://github.com/paramiko/paramiko/issues/637

In the meanwhile, we should tolerate if either pycrypto
or pycryptodome is installed.

In this specific review, we should pass only the first
param and use the defaults for the test of the params:
https://github.com/Legrandin/pycryptodome/blob/master/lib/Crypto/PublicKey/RSA.py#L405
https://github.com/dlitz/pycrypto/blob/master/lib/Crypto/PublicKey/RSA.py#L499

Change-Id: Ib0d6ed503eba0d02b0f60eec9c98734aa6fe4535
",git fetch https://review.opendev.org/openstack/barbican refs/changes/14/280014/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/crypto/simple_crypto.py'],1,f5ea17d02431acc5fecff7291c0db6bf83374854,, generate_dto.bit_length)," generate_dto.bit_length, None, None, 65537)",1,1
openstack%2Fkolla~master~I02fc66bbc53103f2d71c648d5e2959f10f0130c0,openstack/kolla,master,I02fc66bbc53103f2d71c648d5e2959f10f0130c0,Quick gate fix,MERGED,2016-02-19 18:00:48.000000000,2016-02-19 19:07:44.000000000,2016-02-19 19:07:44.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 10787}]","[{'number': 1, 'created': '2016-02-19 18:00:48.000000000', 'files': ['tools/deploy_aio.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0cb1d969f499df7c4cbbb52a177eefab4973c2d6', 'message': 'Quick gate fix\n\nI accidentally merged a patch with +W that does not work on all gates\nthat infra uses. Specifically it breaks on RAX for unknown reasons.\n\nThis is a quick patch to not fully revert, but allow the gate to stay\ngreen while I work out the issue\n\nChange-Id: I02fc66bbc53103f2d71c648d5e2959f10f0130c0\nPartially-Implements: blueprint functional-testing-gate\n'}]",1,282447,0cb1d969f499df7c4cbbb52a177eefab4973c2d6,8,4,1,14119,,,0,"Quick gate fix

I accidentally merged a patch with +W that does not work on all gates
that infra uses. Specifically it breaks on RAX for unknown reasons.

This is a quick patch to not fully revert, but allow the gate to stay
green while I work out the issue

Change-Id: I02fc66bbc53103f2d71c648d5e2959f10f0130c0
Partially-Implements: blueprint functional-testing-gate
",git fetch https://review.opendev.org/openstack/kolla refs/changes/47/282447/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deploy_aio.sh'],1,0cb1d969f499df7c4cbbb52a177eefab4973c2d6,bp/functional-testing-gate," # TODO(SamYaple): Move these out of the check_failure function once logs # are reddy with Heka # Wait for service ready sleep 15 nova boot --poll --image $(openstack image list | awk '/cirros/ {print $2}') --nic net-id=$(openstack network list | awk '/demo-net/ {print $2}') --flavor 1 kolla_boot_test # If the status is not ACTIVE, print info and exit 1 nova show kolla_boot_test | awk '{buf=buf""\n""$0} $2==""status"" && $4!=""ACTIVE"" {failed=""yes""}; END {if (failed==""yes"") {print buf; exit 1}}' ","# Wait for service ready sleep 15 nova boot --poll --image $(openstack image list | awk '/cirros/ {print $2}') --nic net-id=$(openstack network list | awk '/demo-net/ {print $2}') --flavor 1 kolla_boot_test # If the status is not ACTIVE, print info and exit 1 nova show kolla_boot_test | awk '{buf=buf""\n""$0} $2==""status"" && $4!=""ACTIVE"" {failed=""yes""}; END {if (failed==""yes"") {print buf; exit 1}}'",9,6
openstack%2Fcompute-hyperv~stable%2Fliberty~If78f413a374920ed43d1148ed91457049c4d4eda,openstack/compute-hyperv,stable/liberty,If78f413a374920ed43d1148ed91457049c4d4eda,Adds lookup VM as VSSDs,MERGED,2016-01-26 21:20:39.000000000,2016-02-19 19:05:41.000000000,2016-02-19 18:08:36.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 12604}]","[{'number': 1, 'created': '2016-01-26 21:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/6bd31ba72fbbb109c2baaf744c7a46e446e5523e', 'message': 'Adds lookup VM as VSSDs\n\nA lot of vmutils and vmutilsv2 operations require\na Msvm_VirtualSystemSettingData. Currently, it is fetched\nfrom a Msvm_ComputerSystem associators, which is an expensive\noperation. The needed object can simply be queried directly.\nUsing associators is a time expensive operation, replacing them\nwith direct queries improves the performance by decreasing the\ntime needed to wait to retrieve the associated classes.\n\nCo-Authored-By: Claudiu Belu <cbelu@cloudbasesolutions.com>\nChange-Id: If78f413a374920ed43d1148ed91457049c4d4eda\n'}, {'number': 2, 'created': '2016-02-09 01:14:12.000000000', 'files': ['hyperv/nova/vmutilsv2.py', 'hyperv/tests/unit/test_vmutilsv2.py', 'hyperv/nova/hostutilsv2.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/7cc7b1a54bbaf4ea309928ddb243b5859c77b78e', 'message': 'Adds lookup VM as VSSDs\n\nA lot of vmutils and vmutilsv2 operations require\na Msvm_VirtualSystemSettingData. Currently, it is fetched\nfrom a Msvm_ComputerSystem associators, which is an expensive\noperation. The needed object can simply be queried directly.\nUsing associators is a time expensive operation, replacing them\nwith direct queries improves the performance by decreasing the\ntime needed to wait to retrieve the associated classes.\n\nCo-Authored-By: Claudiu Belu <cbelu@cloudbasesolutions.com>\nChange-Id: If78f413a374920ed43d1148ed91457049c4d4eda\n'}]",0,272739,7cc7b1a54bbaf4ea309928ddb243b5859c77b78e,24,5,2,17019,,,0,"Adds lookup VM as VSSDs

A lot of vmutils and vmutilsv2 operations require
a Msvm_VirtualSystemSettingData. Currently, it is fetched
from a Msvm_ComputerSystem associators, which is an expensive
operation. The needed object can simply be queried directly.
Using associators is a time expensive operation, replacing them
with direct queries improves the performance by decreasing the
time needed to wait to retrieve the associated classes.

Co-Authored-By: Claudiu Belu <cbelu@cloudbasesolutions.com>
Change-Id: If78f413a374920ed43d1148ed91457049c4d4eda
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/39/272739/2 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/vmutilsv2.py', 'hyperv/tests/unit/test_vmutilsv2.py']",2,6bd31ba72fbbb109c2baaf744c7a46e446e5523e,,"from nova import exception import six @mock.patch.object(vmutilsv2.VMUtilsV2, 'get_free_controller_slot') @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_scsi_controller') def test_attach_scsi_drive(self, mock_get_vm_scsi_controller, mock_get_free_controller_slot): mock_vm = self._lookup_vm() mock_get_vm_scsi_controller.return_value = self._FAKE_CTRL_PATH mock_get_free_controller_slot.return_value = self._FAKE_DRIVE_ADDR with mock.patch.object(self._vmutils, 'attach_drive') as mock_attach_drive: self._vmutils.attach_scsi_drive(mock_vm, self._FAKE_PATH, constants.DISK) mock_get_vm_scsi_controller.assert_called_once_with(mock_vm) mock_get_free_controller_slot.assert_called_once_with( self._FAKE_CTRL_PATH) mock_attach_drive.assert_called_once_with( mock_vm, self._FAKE_PATH, self._FAKE_CTRL_PATH, self._FAKE_DRIVE_ADDR, constants.DISK) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_new_resource_setting_data') @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_ide_controller') def test_attach_ide_drive(self, mock_get_ide_ctrl, mock_get_new_rsd): mock_vm = self._lookup_vm() mock_rsd = mock_get_new_rsd.return_value with mock.patch.object(self._vmutils, '_add_virt_resource') as mock_add_virt_res: self._vmutils.attach_ide_drive(self._FAKE_VM_NAME, self._FAKE_CTRL_PATH, self._FAKE_CTRL_ADDR, self._FAKE_DRIVE_ADDR) mock_add_virt_res.assert_called_with(mock_rsd, mock_vm.path_.return_value) mock_get_ide_ctrl.assert_called_with(mock_vm, self._FAKE_CTRL_ADDR) self.assertTrue(mock_get_new_rsd.called) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_disks') def test_get_vm_summary_info(self): self._lookup_vm() mock_summary = mock.MagicMock() mock_svc = self._vmutils._vs_man_svc mock_svc.GetSummaryInformation.return_value = (self._FAKE_RET_VAL, [mock_summary]) for key, val in six.iteritems(self._FAKE_SUMMARY_INFO): setattr(mock_summary, key, val) summary = self._vmutils.get_vm_summary_info(self._FAKE_VM_NAME) self.assertEqual(self._FAKE_SUMMARY_INFO, summary) def _lookup_vm(self): mock_vm = mock.MagicMock() self._vmutils._lookup_vm_check = mock.MagicMock( return_value=mock_vm) mock_vm.path_.return_value = self._FAKE_VM_PATH return mock_vm def test_lookup_vm_ok(self): mock_vm = mock.MagicMock() self._vmutils._conn.Msvm_ComputerSystem.return_value = [mock_vm] vm = self._vmutils._lookup_vm_check(self._FAKE_VM_NAME, as_vssd=False) self.assertEqual(mock_vm, vm) def test_lookup_vm_multiple(self): mockvm = mock.MagicMock() self._vmutils._conn.Msvm_ComputerSystem.return_value = [mockvm, mockvm] self.assertRaises(vmutils.HyperVException, self._vmutils._lookup_vm_check, self._FAKE_VM_NAME, as_vssd=False) def test_lookup_vm_none(self): self._vmutils._conn.Msvm_ComputerSystem.return_value = [] self.assertRaises(exception.InstanceNotFound, self._vmutils._lookup_vm_check, self._FAKE_VM_NAME, as_vssd=False) def test_lookup_vm_as_vssd(self): self._vmutils._conn.Msvm_VirtualSystemSettingData.return_value = [ mock.sentinel.fake_vssd] vssd = self._vmutils._lookup_vm_check(self._FAKE_VM_NAME) self.assertEqual(mock.sentinel.fake_vssd, vssd) def test_set_vm_memory_static(self): self._test_set_vm_memory_dynamic(dynamic_memory_ratio=1.0) def test_set_vm_memory_dynamic(self): self._test_set_vm_memory_dynamic(dynamic_memory_ratio=2.0) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def _test_set_vm_memory_dynamic(self, mock_get_associated_class, dynamic_memory_ratio, mem_per_numa_node=None): mock_s = self._vmutils._conn.Msvm_VirtualSystemSettingData()[0] mock_s.SystemType = 3 mock_get_associated_class.return_value = [mock_s] self._vmutils._modify_virt_resource = mock.MagicMock() self._vmutils._set_vm_memory(mock_s, self._FAKE_MEMORY_MB, mem_per_numa_node, dynamic_memory_ratio) mock_get_associated_class.assert_called_once_with( self._vmutils._MEMORY_SETTING_DATA_CLASS, mock_s) self._vmutils._modify_virt_resource.assert_called_with( mock_s, mock_s.path_.return_value) if mem_per_numa_node: self.assertEqual(mem_per_numa_node, mock_s.MaxMemoryBlocksPerNumaNode) if dynamic_memory_ratio > 1: self.assertTrue(mock_s.DynamicMemoryEnabled) else: self.assertFalse(mock_s.DynamicMemoryEnabled) def test_set_vm_vcpus(self): self._check_set_vm_vcpus() def test_set_vm_vcpus_per_vnuma_node(self): self._check_set_vm_vcpus(vcpus_per_numa_node=1) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def _check_set_vm_vcpus(self, mock_get_associated_class, vcpus_per_numa_node=None): procsetting = mock.MagicMock() mock_vmsetting = mock.MagicMock() mock_get_associated_class.return_value = [procsetting] self._vmutils._modify_virt_resource = mock.MagicMock() self._vmutils._set_vm_vcpus(mock_vmsetting, self._FAKE_VCPUS_NUM, vcpus_per_numa_node, limit_cpu_features=False) mock_get_associated_class.assert_called_once_with( self._vmutils._PROCESSOR_SETTING_DATA_CLASS, mock_vmsetting) self._vmutils._modify_virt_resource.assert_called_once_with( procsetting, mock_vmsetting.path_.return_value) if vcpus_per_numa_node: self.assertEqual(vcpus_per_numa_node, procsetting.MaxProcessorsPerNumaNode) def test_soft_shutdown_vm(self): mock_vm = self._lookup_vm() mock_shutdown = mock.MagicMock() mock_shutdown.InitiateShutdown.return_value = (self._FAKE_RET_VAL, ) self._vmutils._conn.Msvm_ShutdownComponent.return_value = [ mock_shutdown] with mock.patch.object(self._vmutils, 'check_ret_val') as mock_check: self._vmutils.soft_shutdown_vm(self._FAKE_VM_NAME) mock_shutdown.InitiateShutdown.assert_called_once_with( Force=False, Reason=mock.ANY) mock_check.assert_called_once_with(self._FAKE_RET_VAL, None) self._vmutils._conn.Msvm_ShutdownComponent.assert_called_once_with( SystemName=mock_vm.Name) def test_soft_shutdown_vm_no_component(self): mock_vm = self._lookup_vm() self._vmutils._conn.Msvm_ShutdownComponent.return_value = [] with mock.patch.object(self._vmutils, 'check_ret_val') as mock_check: self._vmutils.soft_shutdown_vm(self._FAKE_VM_NAME) self.assertFalse(mock_check.called) self._vmutils._conn.Msvm_ShutdownComponent.assert_called_once_with( SystemName=mock_vm.Name) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_get_vm_disks(self, mock_get_associated_class): mock_vmsettings = self._lookup_vm() mock_rasds = self._create_mock_disks() mock_get_associated_class.return_value = mock_rasds (disks, volumes) = self._vmutils._get_vm_disks(mock_vmsettings) expected_calls = [ mock.call(self._vmutils._STORAGE_ALLOC_SETTING_DATA_CLASS, mock_vmsettings), mock.call(self._vmutils._RESOURCE_ALLOC_SETTING_DATA_CLASS, mock_vmsettings)] mock_get_associated_class.assert_has_calls(expected_calls) self.assertEqual([mock_rasds[0]], disks) self.assertEqual([mock_rasds[1]], volumes) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_disks') def test_get_vm_storage_paths(self, mock_get_vm_disks): self._lookup_vm() mock_rasds = self._create_mock_disks() mock_get_vm_disks.return_value = ([mock_rasds[0]], [mock_rasds[1]]) storage = self._vmutils.get_vm_storage_paths(self._FAKE_VM_NAME) (disk_files, volume_drives) = storage self.assertEqual([self._FAKE_VHD_PATH], disk_files) self.assertEqual([self._FAKE_VOLUME_DRIVE_PATH], volume_drives) @mock.patch.object(vmutilsv2.VMUtilsV2, '_set_vm_vcpus') @mock.patch.object(vmutilsv2.VMUtilsV2, '_set_vm_memory') def test_update_vm(self, mock_set_mem, mock_set_vcpus): mock_vm = self._lookup_vm() self._vmutils.update_vm( mock.sentinel.vm_name, mock.sentinel.memory_mb, mock.sentinel.memory_per_numa, mock.sentinel.vcpus_num, mock.sentinel.vcpus_per_numa, mock.sentinel.limit_cpu_features, mock.sentinel.dynamic_mem_ratio) mock_set_mem.assert_called_once_with( mock_vm, mock.sentinel.memory_mb, mock.sentinel.memory_per_numa, mock.sentinel.dynamic_mem_ratio) mock_set_vcpus.assert_called_once_with( mock_vm, mock.sentinel.vcpus_num, mock.sentinel.vcpus_per_numa, mock.sentinel.limit_cpu_features) vnuma_enabled=True): conn_vssd = self._vmutils._conn.Msvm_VirtualSystemSettingData mock_check_ret_val.return_value = mock.sentinel.job conn_vssd.new.return_value = mock_vs_data mock.sentinel.vm_path, self._vmutils._create_vm_obj(vm_name=fake_vm_name, vm_gen=constants.VM_GEN_2, notes='fake notes', vnuma_enabled=vnuma_enabled, instance_path=mock.sentinel.instance_path) conn_vssd.new.assert_called_once_with() self._test_create_vm_obj() self._test_create_vm_obj(vnuma_enabled=False) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_get_vm_serial_ports(self, mock_get_associated_class): mock_vmsettings = self._lookup_vm() fake_serial_port = mock.MagicMock() fake_serial_port.ResourceSubType = ( self._vmutils._SERIAL_PORT_RES_SUB_TYPE) mock_rasds = [fake_serial_port] mock_get_associated_class.return_value = mock_rasds ret_val = self._vmutils._get_vm_serial_ports(mock_vmsettings) self.assertEqual(mock_rasds, ret_val) mock_get_associated_class.assert_called_once_with( self._vmutils._SERIAL_PORT_SETTING_DATA_CLASS, mock_vmsettings) def test_get_associated_class(self): self._vmutils._conn.query.return_value = mock.sentinel.assoc_class resulted_assoc_class = self._vmutils._get_associated_class( mock.sentinel.class_name, mock.Mock(ConfigurationID=mock.sentinel.conf_id)) expected_query = ( ""SELECT * FROM %(class_name)s WHERE InstanceID LIKE "" ""'Microsoft:%(instance_id)s%%'"" % { 'class_name': mock.sentinel.class_name, 'instance_id': mock.sentinel.conf_id}) self._vmutils._conn.query.assert_called_once_with(expected_query) self.assertEqual(mock.sentinel.assoc_class, resulted_assoc_class) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_get_vm_scsi_controller(self, mock_get_associated_class): self._prepare_get_vm_controller(self._vmutils._SCSI_CTRL_RES_SUB_TYPE, mock_get_associated_class) path = self._vmutils.get_vm_scsi_controller(self._FAKE_VM_NAME) self.assertEqual(self._FAKE_RES_PATH, path) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_get_vm_dvd_disk_paths(self, mock_get_associated_class): self._lookup_vm() mock_get_associated_class.return_value = [mock_sasd1] @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_get_vm_ide_controller(self, mock_get_associated_class): self._prepare_get_vm_controller( self._vmutils._IDE_CTRL_RES_SUB_TYPE, mock_get_associated_class) path = self._vmutils.get_vm_ide_controller( mock.sentinel.FAKE_VM_SETTINGS, self._FAKE_ADDRESS) self.assertEqual(self._FAKE_RES_PATH, path) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_get_vm_ide_controller_none(self, mock_get_associated_class): self._prepare_get_vm_controller( self._vmutils._IDE_CTRL_RES_SUB_TYPE, mock_get_associated_class) path = self._vmutils.get_vm_ide_controller( mock.sentinel.FAKE_VM_SETTINGS, mock.sentinel.FAKE_NOT_FOUND_ADDR) self.assertNotEqual(self._FAKE_RES_PATH, path) def _prepare_get_vm_controller(self, resource_sub_type, mock_get_associated_class): self._lookup_vm() mock_rasds = mock.MagicMock() mock_rasds.path_.return_value = self._FAKE_RES_PATH mock_rasds.ResourceSubType = resource_sub_type mock_rasds.Address = self._FAKE_ADDRESS mock_get_associated_class.return_value = [mock_rasds] def _test_get_vm_gen(self, vm_gen): mock_settings = self._lookup_vm() vm_gen_string = ""Microsoft:Hyper-V:SubType:"" + str(vm_gen) mock_settings.VirtualSystemSubType = vm_gen_string ret = self._vmutils.get_vm_gen(mock_settings) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') mock_new_res_setting_data, mock_get_associated_class): mock_get_associated_class.return_value = [mock_r1, mock_r2] mock_get_associated_class.assert_called_once_with( self._vmutils._CIM_RES_ALLOC_SETTING_DATA_CLASS, mock_vm) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_associated_class') def test_enable_remotefx_video_adapter_already_configured( self, mock_get_associated_class): self._lookup_vm() mock_get_associated_class.return_value = [mock_r] @mock.patch.object(vmutilsv2.VMUtilsV2, 'check_ret_val') @mock.patch.object(vmutilsv2.VMUtilsV2, '_lookup_vm_check') mock_modify_virtual_system): vs_data = mock_lookup_vm_check.return_value mock_modify_virtual_system.assert_called_once_with(None, vs_data) def test_instance_notes(self): mock_vm_settings = self._lookup_vm() mock_vm_settings.Notes = self._get_fake_instance_notes() notes = self._vmutils._get_instance_notes(mock.sentinel.vm_name) self.assertEqual(notes[0], self._FAKE_VM_UUID) def test_stop_vm_jobs(self): mock_vm = self._lookup_vm() mock_job1 = mock.MagicMock(Cancellable=True) mock_job2 = mock.MagicMock(Cancellable=True) mock_job3 = mock.MagicMock(Cancellable=True) self._vmutils._get_wmi_obj = mock.MagicMock( side_effect=[mock_job1, mock_job2, mock_job3]) mock_job1.JobState = 2 mock_job2.JobState = 3 mock_job3.JobState = constants.JOB_STATE_KILLED mock_affecting_job = mock.Mock(AffectingElement=self._FAKE_VM_PATH) mock_jobs_affecting_vm = [mock_affecting_job] * 3 self._vmutils._conn.Msvm_AffectedJobElement.return_value = ( mock_jobs_affecting_vm) self._vmutils.stop_vm_jobs(mock.sentinel.FAKE_VM_NAME) self._vmutils._conn.Msvm_AffectedJobElement.assert_called_once_with( AffectedElement=mock_vm.path_.return_value) mock_job1.RequestStateChange.assert_called_once_with( self._vmutils._KILL_JOB_STATE_CHANGE_REQUEST) mock_job2.RequestStateChange.assert_called_once_with( self._vmutils._KILL_JOB_STATE_CHANGE_REQUEST) self.assertFalse(mock_job3.RequestStateChange.called) def test_drive_to_boot_source(self, mock_wmi, mock_get_disk_res_from_path, mock_is_drive_physical): mock_is_drive_physical.return_value = True mock_drive = mock.MagicMock() mock_logical_identity = mock.MagicMock() mock_rasd_path = mock_drive.path_.return_value mock_logical_identity.SystemElement.upper.return_value = ( mock_rasd_path.upper.return_value) mock_logical_identities = [mock_logical_identity] self._vmutils._conn.Msvm_LogicalIdentity.return_value = ( mock_logical_identities) mock.sentinel.drive_path, is_physical=True) expected_bssd_path = mock_logical_identity.SameElement self.assertEqual(expected_bssd_path, ret) @mock.patch.object(vmutilsv2.VMUtilsV2, '_set_boot_order') def test_set_boot_order_gen1(self, mock_modify_virt_syst): mock_vssd = self._lookup_vm() mock_vssd.name, fake_dev_boot_order) mock_vssd.path_.return_value, mock_vssd) mock_drive_to_boot_source): fake_boot_source1 = mock.MagicMock() fake_boot_source2 = mock.MagicMock() fake_boot_source_net = mock.MagicMock() fake_boot_source1.upper.return_value = mock.sentinel.boot_source1 fake_boot_source2.upper.return_value = mock.sentinel.boot_source2 fake_boot_source_net.upper.return_value = mock.sentinel.boot_source_net fake_boot_dev1.upper.return_value = mock.sentinel.boot_source1 fake_boot_dev2.upper.return_value = mock.sentinel.boot_source2 mock_vssd = self._lookup_vm() old_boot_order = tuple([fake_boot_source2, fake_boot_source1, fake_boot_source_net]) expected_boot_order = tuple([mock.sentinel.boot_source1, mock.sentinel.boot_source2, mock.sentinel.boot_source_net]) self._vmutils._set_boot_order_gen2(mock_vssd.name, fake_dev_order)"," @mock.patch('hyperv.nova.vmutils.VMUtils._get_vm_disks') vm_path, vnuma_enabled=True): mock_job = mock.MagicMock() _conn = self._vmutils._conn.Msvm_VirtualSystemSettingData mock_check_ret_val.return_value = mock_job _conn.new.return_value = mock_vs_data vm_path, mock_job.associators.return_value = ['fake vm path'] response = self._vmutils._create_vm_obj( vm_name=fake_vm_name, vm_gen=constants.VM_GEN_2, notes='fake notes', vnuma_enabled=vnuma_enabled, instance_path=mock.sentinel.instance_path) if not vm_path: mock_job.associators.assert_called_once_with( self._vmutils._AFFECTED_JOB_ELEMENT_CLASS) _conn.new.assert_called_once_with() mock_get_wmi_obj.assert_called_with('fake vm path') self.assertEqual(response, mock_get_wmi_obj()) self._test_create_vm_obj(vm_path='fake vm path') def test_create_vm_obj_no_vm_path(self): self._test_create_vm_obj(vm_path=None) self._test_create_vm_obj(vm_path=None, vnuma_enabled=False) def test_get_vm_dvd_disk_paths(self): mock_vm = self._lookup_vm() mock_settings = mock.MagicMock() mock_settings.associators.return_value = [mock_sasd1] mock_vm.associators.return_value = [mock_settings] @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_setting_data') def _test_get_vm_gen(self, mock_get_vm_setting_data, vm_gen): mock_vm = self._lookup_vm() vm_gen_string = ""Microsoft:Hyper-V:SubType:"" + str(vm_gen) mock_vssd = mock.MagicMock(VirtualSystemSubType=vm_gen_string) mock_get_vm_setting_data.return_value = mock_vssd ret = self._vmutils.get_vm_gen(mock_vm) mock_new_res_setting_data): mock_vm.associators()[0].associators.return_value = [mock_r1, mock_r2] def test_enable_remotefx_video_adapter_already_configured(self): mock_vm = self._lookup_vm() mock_vm.associators()[0].associators.return_value = [mock_r] @mock.patch.object(vmutils.VMUtils, 'check_ret_val') @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_setting_data') @mock.patch.object(vmutils.VMUtils, '_lookup_vm_check') mock_get_vm_setting_data, mock_modify_virtual_system): vm = mock_lookup_vm_check.return_value vs_data = mock_get_vm_setting_data.return_value mock_get_vm_setting_data.assert_called_once_with(vm) mock_modify_virtual_system.assert_called_once_with( vm.path_(), vs_data) def _test_drive_to_boot_source(self, mock_wmi, mock_get_disk_res_from_path, mock_is_drive_physical, is_physical): mock_is_drive_physical.return_value = is_physical mock_drive = mock.MagicMock(Parent=mock.sentinel.fake_drive_parent) mock_drive.associators.return_value = [mock.sentinel.physical_bssd] mock_rads = mock.MagicMock() mock_rads.associators.return_value = [mock.sentinel.bssd] mock_wmi.WMI.return_value = mock_rads mock.sentinel.drive_path, is_physical=is_physical) if is_physical: self.assertEqual(mock.sentinel.physical_bssd, ret) else: self.assertEqual(mock.sentinel.bssd, ret) def test_physical_drive_to_boot_source(self): self._test_drive_to_boot_source(is_physical=True) def test_drive_to_boot_source(self): self._test_drive_to_boot_source(is_physical=False) @mock.patch.object(vmutils.VMUtils, '_set_boot_order') @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_setting_data') def test_set_boot_order_gen1(self, mock_modify_virt_syst, mock_get_vm_setting_data): mock_vm = self._lookup_vm() mock_vssd = mock_get_vm_setting_data.return_value mock_vm.name, fake_dev_boot_order) mock_vm.path_.return_value, mock_vssd) @mock.patch.object(vmutilsv2.VMUtilsV2, '_get_vm_setting_data') mock_drive_to_boot_source, mock_get_vm_setting_data): fake_boot_dev1.path_.return_value = mock.sentinel.BOOT_SOURCE1 fake_boot_dev2.path_.return_value = mock.sentinel.BOOT_SOURCE2 mock_vm = self._lookup_vm() mock_vssd = mock_get_vm_setting_data.return_value old_boot_order = tuple([mock.sentinel.BOOT_SOURCE2, mock.sentinel.BOOT_SOURCE1, mock.sentinel.BOOT_SOURCE_NET]) expected_boot_order = tuple([mock.sentinel.BOOT_SOURCE1, mock.sentinel.BOOT_SOURCE2, mock.sentinel.BOOT_SOURCE_NET]) self._vmutils._set_boot_order_gen2(mock_vm.name, fake_dev_order)",673,150
openstack%2Fnova~master~I1d3cc40928d80b4397756846ab749b8bacf17fc9,openstack/nova,master,I1d3cc40928d80b4397756846ab749b8bacf17fc9,build smaller name regexes for validation,MERGED,2016-02-16 16:51:51.000000000,2016-02-19 18:59:06.000000000,2016-02-19 18:09:20.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-16 16:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e67963cde0466b719ab2f2d3a84ef6d7bb9c279', 'message': 'build smaller name regexes for validation\n\nThe previous name regexes were built by walking the entire utf8 4 byte\nspace and building out a regex with all characters that were\nprintable. When dumped over the wire on a validation error this\ncreates a nearly 2 MB text string (which is also pushed to the logs).\n\nWe can be smarter and assemble character ranges because a-z in regex\nmeans all character values between those 2 character positions. This\nmakes a validate regex approximately 4% the size of the previous one\n(len 1920 vs. len 54263). It thus mitigates the data dump (though it\ndoes not really give a more clear message).\n\nThere will be follow up to create a better error message. A few\nadditional low level validation tests of the regex themselves were\nadded in the process of debugging the exclusion support for cells.\n\nChange-Id: I1d3cc40928d80b4397756846ab749b8bacf17fc9\nPartial-Bug: #1541691\n'}, {'number': 2, 'created': '2016-02-18 12:53:47.000000000', 'files': ['nova/api/validation/parameter_types.py', 'nova/tests/unit/test_api_validation.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f467af7c55af7807603e77effd709a53fba9b8dd', 'message': 'build smaller name regexes for validation\n\nThe previous name regexes were built by walking the entire utf8 4 byte\nspace and building out a regex with all characters that were\nprintable. When dumped over the wire on a validation error this\ncreates a nearly 2 MB text string (which is also pushed to the logs).\n\nWe can be smarter and assemble character ranges because a-z in regex\nmeans all character values between those 2 character positions. This\nmakes a validate regex approximately 4% the size of the previous one\n(len 1920 vs. len 54263). It thus mitigates the data dump (though it\ndoes not really give a more clear message).\n\nTests were added to ensure we were building the ranges correctly, as\nthis is sufficiently tricky.\n\nThere will be follow up to create a better error message. A few\nadditional low level validation tests of the regex themselves were\nadded in the process of debugging the exclusion support for cells.\n\nChange-Id: I1d3cc40928d80b4397756846ab749b8bacf17fc9\nPartial-Bug: #1541691\n'}]",5,280814,f467af7c55af7807603e77effd709a53fba9b8dd,29,11,2,2750,,,0,"build smaller name regexes for validation

The previous name regexes were built by walking the entire utf8 4 byte
space and building out a regex with all characters that were
printable. When dumped over the wire on a validation error this
creates a nearly 2 MB text string (which is also pushed to the logs).

We can be smarter and assemble character ranges because a-z in regex
means all character values between those 2 character positions. This
makes a validate regex approximately 4% the size of the previous one
(len 1920 vs. len 54263). It thus mitigates the data dump (though it
does not really give a more clear message).

Tests were added to ensure we were building the ranges correctly, as
this is sufficiently tricky.

There will be follow up to create a better error message. A few
additional low level validation tests of the regex themselves were
added in the process of debugging the exclusion support for cells.

Change-Id: I1d3cc40928d80b4397756846ab749b8bacf17fc9
Partial-Bug: #1541691
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/280814/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/validation/parameter_types.py', 'nova/tests/unit/test_api_validation.py']",2,0e67963cde0466b719ab2f2d3a84ef6d7bb9c279,1541691,class ValidationRegex(test.NoDBTestCase): def test_cell_names(self): cellre = re.compile(parameter_types.valid_cell_name_regex) self.assertTrue(cellre.search('foo')) self.assertFalse(cellre.search('foo.bar')) self.assertFalse(cellre.search('foo@bar')) self.assertFalse(cellre.search('foo!bar')) self.assertFalse(cellre.search(' foo!bar')) self.assertFalse(cellre.search('\nfoo!bar')) ,,70,10
openstack%2Foslo.messaging~stable%2Fliberty~Ifc243144c61becadf26fac9e1cedba246cf45234,openstack/oslo.messaging,stable/liberty,Ifc243144c61becadf26fac9e1cedba246cf45234,"Revert ""rabbit: fix unit conversion error of expiration""",ABANDONED,2016-02-12 15:22:55.000000000,2016-02-19 18:55:39.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-02-12 15:22:55.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2a0c2d55dac437cdcc0b09196374ec2defcdf01b', 'message': 'Revert ""rabbit: fix unit conversion error of expiration""\n\nThis reverts commit 9f986a71916e4b48515c254c33cd1d1e80194252\n\nFrom what I can tell, the change in kombu for this, as\nreferenced in the bug report, is:\n\nhttps://github.com/celery/kombu/commit/1cfe771f7a586dcad45dfdb2acfdb43403986065\n\nAnd from what I\'m seeing in github, that was released in\nkombu 3.0.25.\n\ng-r on stable/liberty says that we require kombu>=3.0.7\nso we shouldn\'t be making this change in stable/liberty\nif we don\'t require a minimum version of kombu that\nexpects this behavior.\n\nChange-Id: Ifc243144c61becadf26fac9e1cedba246cf45234\n'}]",0,279600,2a0c2d55dac437cdcc0b09196374ec2defcdf01b,11,5,1,6873,,,0,"Revert ""rabbit: fix unit conversion error of expiration""

This reverts commit 9f986a71916e4b48515c254c33cd1d1e80194252

From what I can tell, the change in kombu for this, as
referenced in the bug report, is:

https://github.com/celery/kombu/commit/1cfe771f7a586dcad45dfdb2acfdb43403986065

And from what I'm seeing in github, that was released in
kombu 3.0.25.

g-r on stable/liberty says that we require kombu>=3.0.7
so we shouldn't be making this change in stable/liberty
if we don't require a minimum version of kombu that
expects this behavior.

Change-Id: Ifc243144c61becadf26fac9e1cedba246cf45234
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/00/279600/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,2a0c2d55dac437cdcc0b09196374ec2defcdf01b,bug/1531148-liberty," expiration = None if timeout: # AMQP TTL is in milliseconds when set in the property. # Details: http://www.rabbitmq.com/ttl.html#per-message-ttl expiration = int(timeout * 1000) producer.publish(msg, expiration=expiration)"," producer.publish(msg, expiration=timeout)",8,2
openstack%2Fneutron~master~I596371e64443b140eb68f5a6de0fcdc46b1e0289,openstack/neutron,master,I596371e64443b140eb68f5a6de0fcdc46b1e0289,Provide helper method to update az on networks,ABANDONED,2016-02-04 21:20:47.000000000,2016-02-19 18:49:14.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-02-04 21:20:47.000000000', 'files': ['neutron/db/db_base_plugin_v2.py', 'neutron/db/agentschedulers_db.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f81c14d7f239e5ae9d6450ab4652430c78d05e1', 'message': 'Provide helper method to update az on networks\n\nLots of neutron plugins have added support for the availability_zone\nextension and most of them just duplicate this code from ml2. This patch\nprovides a helper method in the base class mixin so other plugins can\njust use that.\n\nAlso, this helper method: update_az_on_network returns the az_hints\nrather than having the method take an additional results param to pass\nthem back. I think this is a cleaner apporach. Lastly, it adds a stub to\nupdate_network so we can call the base class from the mixin without having\nto call update_network into the plugin.\n\nChange-Id: I596371e64443b140eb68f5a6de0fcdc46b1e0289\n'}]",2,276452,1f81c14d7f239e5ae9d6450ab4652430c78d05e1,19,17,1,4395,,,0,"Provide helper method to update az on networks

Lots of neutron plugins have added support for the availability_zone
extension and most of them just duplicate this code from ml2. This patch
provides a helper method in the base class mixin so other plugins can
just use that.

Also, this helper method: update_az_on_network returns the az_hints
rather than having the method take an additional results param to pass
them back. I think this is a cleaner apporach. Lastly, it adds a stub to
update_network so we can call the base class from the mixin without having
to call update_network into the plugin.

Change-Id: I596371e64443b140eb68f5a6de0fcdc46b1e0289
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/276452/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/db_base_plugin_v2.py', 'neutron/db/agentschedulers_db.py', 'neutron/plugins/ml2/plugin.py']",3,1f81c14d7f239e5ae9d6450ab4652430c78d05e1,," # update the az on network if needed az_hints = self.update_az_on_network(context, net_data) if(az_hints): result[az_ext.AZ_HINTS] = az_hints"," if az_ext.AZ_HINTS in net_data: self.validate_availability_zones(context, 'network', net_data[az_ext.AZ_HINTS]) az_hints = az_ext.convert_az_list_to_string( net_data[az_ext.AZ_HINTS]) res = super(Ml2Plugin, self).update_network(context, result['id'], {'network': {az_ext.AZ_HINTS: az_hints}}) result[az_ext.AZ_HINTS] = res[az_ext.AZ_HINTS]",19,8
openstack%2Frequirements~master~I7773e900f1461b8511207d705cf1c5706b9afe08,openstack/requirements,master,I7773e900f1461b8511207d705cf1c5706b9afe08,Constrain eventlet to 0.18.2 for now,MERGED,2016-02-17 19:28:48.000000000,2016-02-19 18:40:51.000000000,2016-02-19 18:40:51.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 12898}]","[{'number': 1, 'created': '2016-02-17 19:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/cb6546fbb6d3ce2a5b089c27e7a9f4dbb951745e', 'message': 'Constrain eventlet to 0.18.2 for now\n\nSince we have been too easily broken [1] by eventlet releases\nwe must be more careful about vetting them before using them.\n\n- [1] http://lists.openstack.org/pipermail/openstack-dev/2016-February/thread.html#86745\n\nChange-Id: I7773e900f1461b8511207d705cf1c5706b9afe08\n'}, {'number': 2, 'created': '2016-02-17 21:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/846a5a514a633a92f37bf34b8b9bf4bbfee00ab1', 'message': 'Constrain eventlet to less than 0.18.0 for now\n\nSince we have been too easily broken [1] by eventlet releases\nwe must be more careful about vetting them before using them.\n\n- [1] http://lists.openstack.org/pipermail/openstack-dev/2016-February/thread.html#86745\n\nChange-Id: I7773e900f1461b8511207d705cf1c5706b9afe08\n'}, {'number': 3, 'created': '2016-02-18 04:05:28.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e3159cca8a50141306549f61f7cb461fac983c0b', 'message': 'Constrain eventlet to 0.18.2 for now\n\nSince we have been too easily broken [1] by eventlet releases\nwe must be more careful about vetting them before using them.\n\n- [1] http://lists.openstack.org/pipermail/openstack-dev/2016-February/thread.html#86745\n\nChange-Id: I7773e900f1461b8511207d705cf1c5706b9afe08\n'}]",0,281479,e3159cca8a50141306549f61f7cb461fac983c0b,16,4,3,6524,,,0,"Constrain eventlet to 0.18.2 for now

Since we have been too easily broken [1] by eventlet releases
we must be more careful about vetting them before using them.

- [1] http://lists.openstack.org/pipermail/openstack-dev/2016-February/thread.html#86745

Change-Id: I7773e900f1461b8511207d705cf1c5706b9afe08
",git fetch https://review.opendev.org/openstack/requirements refs/changes/79/281479/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,cb6546fbb6d3ce2a5b089c27e7a9f4dbb951745e,eventlet-debacle,eventlet===0.18.2,eventlet===0.18.3,4,2
openstack%2Frequirements~master~I2593cd55fd944c9abe4500c68f61af0576dff6a9,openstack/requirements,master,I2593cd55fd944c9abe4500c68f61af0576dff6a9,bump upper constraint for keystonemiddleware,MERGED,2016-02-17 03:08:46.000000000,2016-02-19 18:40:26.000000000,2016-02-19 18:40:26.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6482}, {'_account_id': 17589}]","[{'number': 1, 'created': '2016-02-17 03:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ca081f3448534631059cc6c6648c57882b114bd7', 'message': 'bump upper constraint for keystonemiddleware\n\nrelease for 4.3.0 of keystonemiddleware: https://review.openstack.org/#/c/281027/\n\nChange-Id: I2593cd55fd944c9abe4500c68f61af0576dff6a9\n'}, {'number': 2, 'created': '2016-02-18 07:47:43.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4051bb982cddf202d2d78f6c2c65f3b428c04b34', 'message': 'bump upper constraint for keystonemiddleware\n\nrelease for 4.3.0 of keystonemiddleware: https://review.openstack.org/#/c/281027/\n\nChange-Id: I2593cd55fd944c9abe4500c68f61af0576dff6a9\n'}]",0,281028,4051bb982cddf202d2d78f6c2c65f3b428c04b34,18,5,2,6482,,,0,"bump upper constraint for keystonemiddleware

release for 4.3.0 of keystonemiddleware: https://review.openstack.org/#/c/281027/

Change-Id: I2593cd55fd944c9abe4500c68f61af0576dff6a9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/281028/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ca081f3448534631059cc6c6648c57882b114bd7,ksm_bump,keystonemiddleware===4.3.0,keystonemiddleware===4.2.0,1,1
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec,openstack/tripleo-heat-templates,stable/liberty,I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec,Include big switch puppet modules for deploying overcloud,ABANDONED,2016-02-16 02:04:03.000000000,2016-02-19 18:38:24.000000000,,"[{'_account_id': 3}, {'_account_id': 8449}]","[{'number': 1, 'created': '2016-02-16 02:04:03.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/extraconfig/pre_deploy/controller/neutron-ml2-bigswitch.yaml', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5abd82f0e35678ff9742e9c7201b0365d4db11c9', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes. It depends on two review requests:\n\nhttps://review.openstack.org/#/c/271963/\nhttps://review.openstack.org/#/c/271922/\n\nChange-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec\n'}]",1,280469,5abd82f0e35678ff9742e9c7201b0365d4db11c9,5,2,1,15342,,,0,"Include big switch puppet modules for deploying overcloud

This change includes puppet modules for deploying controller
and compute nodes. It depends on two review requests:

https://review.openstack.org/#/c/271963/
https://review.openstack.org/#/c/271922/

Change-Id: I6c760e6bd3dddc707fbf66ea7f0437e59a59dbec
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/69/280469/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/extraconfig/pre_deploy/controller/neutron-ml2-bigswitch.yaml', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp']",4,5abd82f0e35678ff9742e9c7201b0365d4db11c9,manual, if 'bsn_ml2' in hiera('neutron::plugins::ml2::mechanism_drivers') { include ::neutron::agents::bigswitch," if hiera('neutron_enable_bigswitch_ml2', false) {",8,3
openstack%2Fneutron-lbaas-dashboard~master~I6cdfb5446362e854da6a18eb16420d9121329ab9,openstack/neutron-lbaas-dashboard,master,I6cdfb5446362e854da6a18eb16420d9121329ab9,Update URL routing,MERGED,2016-02-11 17:01:15.000000000,2016-02-19 18:38:09.000000000,2016-02-19 18:38:09.000000000,"[{'_account_id': 3}, {'_account_id': 9981}, {'_account_id': 12403}]","[{'number': 1, 'created': '2016-02-11 17:01:15.000000000', 'files': ['neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/table.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/lbaasv2.module.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/table.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/healthmonitors/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/table.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/actions/batch-actions.service.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/healthmonitors/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/table.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/table.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/lbaasv2.module.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/pools/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/healthmonitors/detail.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/detail.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/actions/batch-actions.service.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/detail.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/pools/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/pools/detail.html'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas-dashboard/commit/900d73820e0b484782913cdfc200d37c3200b0c9', 'message': 'Update URL routing\n\nThis updates the URL routing so URLs include all IDs of the resource\nhierarchy. This makes it much easier to create links in pages and to\nobtain the information for parent resources.\n\nPartially-Implements: blueprint horizon-lbaas-v2-ui\nChange-Id: I6cdfb5446362e854da6a18eb16420d9121329ab9\n'}]",0,279188,900d73820e0b484782913cdfc200d37c3200b0c9,7,3,1,9647,,,0,"Update URL routing

This updates the URL routing so URLs include all IDs of the resource
hierarchy. This makes it much easier to create links in pages and to
obtain the information for parent resources.

Partially-Implements: blueprint horizon-lbaas-v2-ui
Change-Id: I6cdfb5446362e854da6a18eb16420d9121329ab9
",git fetch https://review.opendev.org/openstack/neutron-lbaas-dashboard refs/changes/88/279188/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/table.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/lbaasv2.module.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/table.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/healthmonitors/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/table.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/actions/batch-actions.service.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/healthmonitors/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/table.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/table.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/lbaasv2.module.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/pools/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/healthmonitors/detail.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/listeners/detail.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/actions/batch-actions.service.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/members/detail.html', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/pools/detail.controller.spec.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/loadbalancers/detail.controller.js', 'neutron_lbaas_dashboard/static/dashboard/project/lbaasv2/pools/detail.html']",22,900d73820e0b484782913cdfc200d37c3200b0c9,bp/horizon-lbaas-v2-ui," <li><a href=""project/ngloadbalancersv2/{$ ::ctrl.loadbalancer.id $}"">{$ ::(ctrl.loadbalancer.name || ctrl.loadbalancer.id) $}</a></li> <li><a href=""project/ngloadbalancersv2/{$ ::ctrl.loadbalancer.id $}/listeners/{$ ::ctrl.listener.id $}"">{$ ::(ctrl.listener.name || ctrl.listener.id) $}</a></li> <dd>{$ ctrl.pool.lb_algorithm | decode:ctrl.loadBalancerAlgorithm $}</dd> <a ng-href=""project/ngloadbalancersv2/{$ ::ctrl.loadbalancer.id $}/listeners/{$ ::ctrl.listener.id $}/pools/{$ ::ctrl.pool.id $}/healthmonitors/{$ ::ctrl.pool.healthmonitor_id $}"">{$ ::ctrl.pool.healthmonitor_id $}</a>"," <li><a href=""project/ngloadbalancersv2/detail/{$ ::ctrl.loadbalancer.id $}"">{$ ::(ctrl.loadbalancer.name || ctrl.loadbalancer.id) $}</a></li> <li><a href=""project/ngloadbalancersv2/listeners/detail/{$ ::ctrl.listener.id $}"">{$ ::(ctrl.listener.name || ctrl.listener.id) $}</a></li> <dd>{$ ctrl.pool.lb_algorithm | decode:ctrl.lb_algorithm_mappings $}</dd> <a ng-href=""project/ngloadbalancersv2/healthmonitors/detail/{$ ::ctrl.pool.healthmonitor_id $}"">{$ ::ctrl.pool.healthmonitor_id $}</a>",172,432
openstack%2Fnova~master~I3bd214049171d4100214b4bd95e5358727bc8d96,openstack/nova,master,I3bd214049171d4100214b4bd95e5358727bc8d96,Replace stubs.Set with stub_out (api),ABANDONED,2016-01-15 19:28:59.000000000,2016-02-19 18:33:17.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5538}, {'_account_id': 7400}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 12299}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16907}]","[{'number': 1, 'created': '2016-01-15 19:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f474994c7d485b7ae4a798cffb7dfcdad932a8c', 'message': 'Replace stubs.Set with stub_out (api)\n\nAs part of the ongoing effort to stop using mox, start replacing\nthe stubs.Set calls with stub_out.\n\nLimit the scope of this patch to the ~140 simple non-compute API stubs.\n\nPart of bp:remove-mox\n\nChange-Id: I3bd214049171d4100214b4bd95e5358727bc8d96\n'}, {'number': 2, 'created': '2016-01-22 17:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a457d1958aecd00ca7c4cb4d20bab8fbd037d00', 'message': 'Replace stubs.Set with stub_out (api)\n\nAs part of the ongoing effort to stop using mox, start replacing\nthe stubs.Set calls with stub_out.\n\nLimit the scope of this patch to the ~140 simple non-compute API stubs.\n\nPart of bp:remove-mox\n\nChange-Id: I3bd214049171d4100214b4bd95e5358727bc8d96\n'}, {'number': 3, 'created': '2016-01-22 19:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3e3073216693478e65e2c9011ab9811a7bd7581', 'message': 'Replace stubs.Set with stub_out (api)\n\nAs part of the ongoing effort to stop using mox, start replacing\nthe stubs.Set calls with stub_out.\n\nLimit the scope of this patch to the ~140 simple non-compute API stubs.\n\nPart of bp:remove-mox\n\nChange-Id: I3bd214049171d4100214b4bd95e5358727bc8d96\n'}, {'number': 4, 'created': '2016-02-01 22:34:37.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_volumes.py', 'nova/tests/unit/api/openstack/compute/test_consoles.py', 'nova/tests/unit/api/openstack/compute/test_cells.py', 'nova/tests/unit/api/openstack/compute/test_extended_volumes.py', 'nova/tests/unit/api/openstack/compute/test_extended_virtual_interfaces_net.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_pools.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/tests/unit/api/openstack/compute/test_snapshots.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_dns.py', 'nova/tests/unit/api/openstack/compute/test_attach_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_virtual_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/05c80c3c48df6bd2a8837a4c3f3d7c84fd601bc9', 'message': 'Replace stubs.Set with stub_out (api)\n\nAs part of the ongoing effort to stop using mox, start replacing\nthe stubs.Set calls with stub_out.\n\nLimit the scope of this patch to the ~140 simple non-compute API stubs.\n\nPart of bp:remove-mox\n\nChange-Id: I3bd214049171d4100214b4bd95e5358727bc8d96\n'}]",2,268300,05c80c3c48df6bd2a8837a4c3f3d7c84fd601bc9,41,14,4,16907,,,0,"Replace stubs.Set with stub_out (api)

As part of the ongoing effort to stop using mox, start replacing
the stubs.Set calls with stub_out.

Limit the scope of this patch to the ~140 simple non-compute API stubs.

Part of bp:remove-mox

Change-Id: I3bd214049171d4100214b4bd95e5358727bc8d96
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/268300/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_volumes.py', 'nova/tests/unit/api/openstack/compute/test_consoles.py', 'nova/tests/unit/api/openstack/compute/test_cells.py', 'nova/tests/unit/api/openstack/compute/test_extended_volumes.py', 'nova/tests/unit/api/openstack/compute/test_extended_virtual_interfaces_net.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_pools.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/tests/unit/api/openstack/compute/test_snapshots.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_dns.py', 'nova/tests/unit/api/openstack/compute/test_attach_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_virtual_interfaces.py']",14,4f474994c7d485b7ae4a798cffb7dfcdad932a8c,bp/remove-mox," self.stub_out(""nova.network.api.API.get_vifs_by_instance"", get_vifs_by_instance)","from nova import network self.stubs.Set(network.api.API, ""get_vifs_by_instance"", get_vifs_by_instance)",252,210
openstack%2Fnova~master~Ibf784f91bf72d8cd0ec068175631fefaa275aa30,openstack/nova,master,Ibf784f91bf72d8cd0ec068175631fefaa275aa30,WIP: Skip fixtures that need config (where possible),ABANDONED,2016-02-17 17:31:03.000000000,2016-02-19 18:33:10.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 16907}]","[{'number': 1, 'created': '2016-02-17 17:31:03.000000000', 'files': ['nova/tests/unit/network/test_network_info.py', 'nova/tests/unit/network/test_api.py', 'nova/tests/unit/cells/test_cells_filters.py', 'nova/tests/unit/cells/test_cells_utils.py', 'nova/tests/unit/api/openstack/compute/test_limits.py', 'nova/tests/unit/virt/disk/mount/test_api.py', 'nova/tests/unit/scheduler/test_host_filters.py', 'nova/tests/unit/test_exception.py', 'nova/tests/unit/pci/test_stats.py', 'nova/tests/unit/test_policy.py', 'nova/tests/unit/cmd/test_manage.py', 'nova/tests/unit/pci/test_devspec.py', 'nova/tests/unit/scheduler/filters/test_retry_filters.py', 'nova/tests/unit/virt/xenapi/test_vm_utils.py', 'nova/tests/unit/scheduler/filters/test_utils.py', 'nova/tests/unit/api/test_validator.py', 'nova/tests/unit/api/openstack/compute/test_simple_tenant_usage.py', 'nova/tests/unit/network/security_group/test_neutron_driver.py', 'nova/tests/unit/virt/vmwareapi/test_io_util.py', 'nova/tests/unit/virt/libvirt/test_designer.py', 'nova/tests/unit/virt/test_fake.py', 'nova/tests/unit/compute/test_resources.py', 'nova/tests/unit/scheduler/filters/test_aggregate_multitenancy_isolation_filters.py', 'nova/tests/unit/virt/ironic/test_patcher.py', 'nova/tests/unit/api/openstack/compute/test_image_metadata.py', 'nova/tests/unit/compute/test_flavors.py', 'nova/tests/unit/scheduler/filters/test_exact_ram_filter.py', 'nova/tests/unit/scheduler/filters/test_affinity_filters.py', 'nova/tests/unit/test_hacking.py', 'nova/tests/unit/virt/xenapi/image/test_vdi_through_dev.py', 'nova/tests/unit/test_test.py', 'nova/tests/unit/network/test_manager.py', 'nova/tests/unit/network/test_linux_net.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/test_events.py', 'nova/tests/unit/pci/test_whitelist.py', 'nova/tests/unit/test_rpc.py', 'nova/tests/unit/test_api_validation.py', 'nova/tests/unit/compute/test_vmmode.py', 'nova/tests/unit/scheduler/test_scheduler_options.py', 'nova/tests/unit/api/openstack/compute/test_access_ips.py', 'nova/tests/unit/console/test_type.py', 'nova/tests/unit/objects/test_pci_device_pool.py', 'nova/tests/unit/scheduler/filters/test_aggregate_instance_extra_specs_filters.py', 'nova/tests/unit/test_block_device.py', 'nova/tests/unit/objects/test_image_meta.py', 'nova/tests/unit/api/test_wsgi.py', 'nova/tests/unit/virt/test_driver.py', 'nova/tests/unit/scheduler/filters/test_pci_passthrough_filters.py', 'nova/tests/unit/scheduler/filters/test_trusted_filters.py', 'nova/tests/unit/api/openstack/test_wsgi.py', 'nova/tests/unit/api/openstack/test_common.py', 'nova/tests/unit/virt/libvirt/test_fakelibvirt.py', 'nova/tests/unit/objects/test_block_device.py', 'nova/tests/unit/test_utils.py', 'nova/tests/unit/compute/test_hvtype.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/keymgr/test_key.py', 'nova/tests/unit/test_wsgi.py', 'nova/tests/unit/scheduler/filters/test_exact_disk_filter.py', 'nova/tests/unit/virt/test_images.py', 'nova/tests/unit/scheduler/filters/test_type_filters.py', 'nova/tests/unit/virt/vmwareapi/test_vim_util.py', 'nova/tests/unit/api/openstack/test_faults.py', 'nova/tests/unit/scheduler/test_ironic_host_manager.py', 'nova/tests/unit/virt/xenapi/image/test_utils.py', 'nova/tests/unit/scheduler/filters/test_extra_specs_ops.py', 'nova/tests/unit/virt/libvirt/test_guest.py', 'nova/tests/unit/db/test_migrations.py', 'nova/tests/unit/virt/test_virt.py', 'nova/tests/unit/test_notifier.py', 'nova/tests/unit/virt/disk/mount/test_block.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'nova/tests/unit/pci/test_manager.py', 'nova/tests/unit/virt/libvirt/test_compat.py', 'nova/tests/unit/scheduler/filters/test_compute_capabilities_filters.py', 'nova/tests/unit/scheduler/filters/test_compute_filters.py', 'nova/tests/unit/api_samples_test_base/test_compare_result.py', 'nova/tests/unit/scheduler/filters/test_availability_zone_filters.py', 'nova/tests/unit/cells/test_cells_state_manager.py', 'nova/tests/unit/virt/test_imagecache.py', 'nova/tests/unit/api/openstack/test_mapper.py', 'nova/tests/unit/virt/libvirt/test_blockinfo.py', 'nova/tests/unit/test_crypto.py', 'nova/tests/unit/test_versions.py', 'nova/tests/unit/virt/test_volumeutils.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py', 'nova/tests/unit/image/test_fake.py', 'nova/tests/unit/scheduler/filters/test_image_props_filters.py', 'nova/tests/unit/volume/test_cinder.py', 'nova/tests/unit/scheduler/filters/test_exact_core_filter.py', 'nova/tests/unit/image/test_glance.py', 'nova/tests/unit/virt/libvirt/volume/test_remotefs.py', 'nova/tests/unit/virt/vmwareapi/test_read_write_util.py', 'nova/tests/unit/virt/disk/test_inject.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/tests/unit/network/test_l3.py', 'nova/tests/unit/objects/test_fields.py', 'nova/tests/unit/test_loadables.py', 'nova/tests/unit/test_signature_utils.py', 'nova/tests/unit/compute/test_tracker.py', 'nova/tests/unit/api/openstack/test_legacy_v2_compatible_wrapper.py', 'nova/tests/unit/scheduler/filters/test_core_filters.py', 'nova/tests/unit/virt/xenapi/test_agent.py', 'nova/tests/unit/api/openstack/compute/test_pci.py', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/conductor/tasks/test_base.py', 'nova/tests/unit/scheduler/weights/test_weights_hosts.py', 'nova/tests/unit/virt/test_hardware.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/tests/unit/test_notifications.py', 'nova/tests/unit/scheduler/test_filters.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/tests/unit/virt/test_osinfo.py', 'nova/tests/unit/virt/vmwareapi/test_ds_util_datastore_selection.py', 'nova/tests/unit/test_weights.py', 'nova/tests/unit/cmd/test_idmapshift.py', 'nova/tests/unit/compute/test_arch.py', 'nova/tests/unit/cells/test_cells_weights.py', 'nova/tests/unit/test_service.py', 'nova/test.py', 'nova/tests/unit/api/openstack/compute/test_extension_info.py', 'nova/tests/unit/virt/disk/mount/test_loop.py', 'nova/tests/unit/api/openstack/test_api_version_request.py', 'nova/tests/unit/virt/libvirt/storage/test_dmcrypt.py', 'nova/tests/unit/scheduler/filters/test_numa_topology_filters.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py', 'nova/tests/unit/virt/libvirt/volume/test_fs.py', 'nova/tests/unit/volume/encryptors/test_base.py', 'nova/tests/unit/objects/test_notification.py', 'nova/tests/unit/test_safeutils.py', 'nova/tests/unit/api/test_compute_req_id.py', 'nova/tests/unit/virt/test_diagnostics.py', 'nova/tests/unit/virt/vmwareapi/test_network_util.py', 'nova/tests/unit/compute/test_stats.py', 'nova/tests/unit/virt/libvirt/test_host.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/scheduler/filters/test_json_filters.py', 'nova/tests/unit/virt/image/test_model.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/scheduler/test_host_manager.py', 'nova/tests/unit/test_nova_manage.py', 'nova/tests/unit/scheduler/filters/test_ram_filters.py', 'nova/tests/unit/virt/libvirt/volume/test_quobyte.py', 'nova/tests/unit/db/test_models.py', 'nova/tests/unit/pci/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/84ea5fde832ffe01759e8eaddf540dc57ff459aa', 'message': 'WIP: Skip fixtures that need config (where possible)\n\nAfter the database, the next most expensive fixtures are the ones that\nload configuration. Make 260+ test classes not load configuration by\nextending a new base test class (NovaTestCase) instead of NoDBTestCase.\n\nFrom least to most expensive: NovaTestCase -> NoDBTestCase -> TestCase\n\nChange-Id: Ibf784f91bf72d8cd0ec068175631fefaa275aa30\n'}]",0,281442,84ea5fde832ffe01759e8eaddf540dc57ff459aa,12,10,1,16907,,,0,"WIP: Skip fixtures that need config (where possible)

After the database, the next most expensive fixtures are the ones that
load configuration. Make 260+ test classes not load configuration by
extending a new base test class (NovaTestCase) instead of NoDBTestCase.

From least to most expensive: NovaTestCase -> NoDBTestCase -> TestCase

Change-Id: Ibf784f91bf72d8cd0ec068175631fefaa275aa30
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/281442/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_network_info.py', 'nova/tests/unit/network/test_api.py', 'nova/tests/unit/cells/test_cells_filters.py', 'nova/tests/unit/cells/test_cells_utils.py', 'nova/tests/unit/api/openstack/compute/test_limits.py', 'nova/tests/unit/virt/disk/mount/test_api.py', 'nova/tests/unit/scheduler/test_host_filters.py', 'nova/tests/unit/test_exception.py', 'nova/tests/unit/pci/test_stats.py', 'nova/tests/unit/test_policy.py', 'nova/tests/unit/cmd/test_manage.py', 'nova/tests/unit/pci/test_devspec.py', 'nova/tests/unit/scheduler/filters/test_retry_filters.py', 'nova/tests/unit/virt/xenapi/test_vm_utils.py', 'nova/tests/unit/scheduler/filters/test_utils.py', 'nova/tests/unit/api/test_validator.py', 'nova/tests/unit/api/openstack/compute/test_simple_tenant_usage.py', 'nova/tests/unit/network/security_group/test_neutron_driver.py', 'nova/tests/unit/virt/vmwareapi/test_io_util.py', 'nova/tests/unit/virt/libvirt/test_designer.py', 'nova/tests/unit/virt/test_fake.py', 'nova/tests/unit/compute/test_resources.py', 'nova/tests/unit/scheduler/filters/test_aggregate_multitenancy_isolation_filters.py', 'nova/tests/unit/virt/ironic/test_patcher.py', 'nova/tests/unit/api/openstack/compute/test_image_metadata.py', 'nova/tests/unit/compute/test_flavors.py', 'nova/tests/unit/scheduler/filters/test_exact_ram_filter.py', 'nova/tests/unit/scheduler/filters/test_affinity_filters.py', 'nova/tests/unit/test_hacking.py', 'nova/tests/unit/virt/xenapi/image/test_vdi_through_dev.py', 'nova/tests/unit/test_test.py', 'nova/tests/unit/network/test_manager.py', 'nova/tests/unit/network/test_linux_net.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/test_events.py', 'nova/tests/unit/pci/test_whitelist.py', 'nova/tests/unit/test_rpc.py', 'nova/tests/unit/test_api_validation.py', 'nova/tests/unit/compute/test_vmmode.py', 'nova/tests/unit/scheduler/test_scheduler_options.py', 'nova/tests/unit/api/openstack/compute/test_access_ips.py', 'nova/tests/unit/console/test_type.py', 'nova/tests/unit/objects/test_pci_device_pool.py', 'nova/tests/unit/scheduler/filters/test_aggregate_instance_extra_specs_filters.py', 'nova/tests/unit/test_block_device.py', 'nova/tests/unit/objects/test_image_meta.py', 'nova/tests/unit/api/test_wsgi.py', 'nova/tests/unit/virt/test_driver.py', 'nova/tests/unit/scheduler/filters/test_pci_passthrough_filters.py', 'nova/tests/unit/scheduler/filters/test_trusted_filters.py', 'nova/tests/unit/api/openstack/test_wsgi.py', 'nova/tests/unit/api/openstack/test_common.py', 'nova/tests/unit/virt/libvirt/test_fakelibvirt.py', 'nova/tests/unit/objects/test_block_device.py', 'nova/tests/unit/test_utils.py', 'nova/tests/unit/compute/test_hvtype.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/keymgr/test_key.py', 'nova/tests/unit/test_wsgi.py', 'nova/tests/unit/scheduler/filters/test_exact_disk_filter.py', 'nova/tests/unit/virt/test_images.py', 'nova/tests/unit/scheduler/filters/test_type_filters.py', 'nova/tests/unit/virt/vmwareapi/test_vim_util.py', 'nova/tests/unit/api/openstack/test_faults.py', 'nova/tests/unit/scheduler/test_ironic_host_manager.py', 'nova/tests/unit/virt/xenapi/image/test_utils.py', 'nova/tests/unit/scheduler/filters/test_extra_specs_ops.py', 'nova/tests/unit/virt/libvirt/test_guest.py', 'nova/tests/unit/db/test_migrations.py', 'nova/tests/unit/virt/test_virt.py', 'nova/tests/unit/test_notifier.py', 'nova/tests/unit/virt/disk/mount/test_block.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'nova/tests/unit/pci/test_manager.py', 'nova/tests/unit/virt/libvirt/test_compat.py', 'nova/tests/unit/scheduler/filters/test_compute_capabilities_filters.py', 'nova/tests/unit/scheduler/filters/test_compute_filters.py', 'nova/tests/unit/api_samples_test_base/test_compare_result.py', 'nova/tests/unit/scheduler/filters/test_availability_zone_filters.py', 'nova/tests/unit/cells/test_cells_state_manager.py', 'nova/tests/unit/virt/test_imagecache.py', 'nova/tests/unit/api/openstack/test_mapper.py', 'nova/tests/unit/virt/libvirt/test_blockinfo.py', 'nova/tests/unit/test_crypto.py', 'nova/tests/unit/test_versions.py', 'nova/tests/unit/virt/test_volumeutils.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py', 'nova/tests/unit/image/test_fake.py', 'nova/tests/unit/scheduler/filters/test_image_props_filters.py', 'nova/tests/unit/volume/test_cinder.py', 'nova/tests/unit/scheduler/filters/test_exact_core_filter.py', 'nova/tests/unit/image/test_glance.py', 'nova/tests/unit/virt/libvirt/volume/test_remotefs.py', 'nova/tests/unit/virt/vmwareapi/test_read_write_util.py', 'nova/tests/unit/virt/disk/test_inject.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/tests/unit/network/test_l3.py', 'nova/tests/unit/objects/test_fields.py', 'nova/tests/unit/test_loadables.py', 'nova/tests/unit/test_signature_utils.py', 'nova/tests/unit/compute/test_tracker.py', 'nova/tests/unit/api/openstack/test_legacy_v2_compatible_wrapper.py', 'nova/tests/unit/scheduler/filters/test_core_filters.py', 'nova/tests/unit/virt/xenapi/test_agent.py', 'nova/tests/unit/api/openstack/compute/test_pci.py', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/conductor/tasks/test_base.py', 'nova/tests/unit/scheduler/weights/test_weights_hosts.py', 'nova/tests/unit/virt/test_hardware.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/tests/unit/test_notifications.py', 'nova/tests/unit/scheduler/test_filters.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/tests/unit/virt/test_osinfo.py', 'nova/tests/unit/virt/vmwareapi/test_ds_util_datastore_selection.py', 'nova/tests/unit/test_weights.py', 'nova/tests/unit/cmd/test_idmapshift.py', 'nova/tests/unit/compute/test_arch.py', 'nova/tests/unit/cells/test_cells_weights.py', 'nova/tests/unit/test_service.py', 'nova/test.py', 'nova/tests/unit/api/openstack/compute/test_extension_info.py', 'nova/tests/unit/virt/disk/mount/test_loop.py', 'nova/tests/unit/api/openstack/test_api_version_request.py', 'nova/tests/unit/virt/libvirt/storage/test_dmcrypt.py', 'nova/tests/unit/scheduler/filters/test_numa_topology_filters.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py', 'nova/tests/unit/virt/libvirt/volume/test_fs.py', 'nova/tests/unit/volume/encryptors/test_base.py', 'nova/tests/unit/objects/test_notification.py', 'nova/tests/unit/test_safeutils.py', 'nova/tests/unit/api/test_compute_req_id.py', 'nova/tests/unit/virt/test_diagnostics.py', 'nova/tests/unit/virt/vmwareapi/test_network_util.py', 'nova/tests/unit/compute/test_stats.py', 'nova/tests/unit/virt/libvirt/test_host.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/scheduler/filters/test_json_filters.py', 'nova/tests/unit/virt/image/test_model.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/scheduler/test_host_manager.py', 'nova/tests/unit/test_nova_manage.py', 'nova/tests/unit/scheduler/filters/test_ram_filters.py', 'nova/tests/unit/virt/libvirt/volume/test_quobyte.py', 'nova/tests/unit/db/test_models.py', 'nova/tests/unit/pci/test_utils.py']",148,84ea5fde832ffe01759e8eaddf540dc57ff459aa,uses_conf,class PciDeviceMatchTestCase(test.NovaTestCase):class PciDeviceAddressParserTestCase(test.NovaTestCase):class GetFunctionByIfnameTestCase(test.NovaTestCase):class IsPhysicalFunctionTestCase(test.NovaTestCase):class GetIfnameByPciAddressTestCase(test.NovaTestCase):class GetVfNumByPciAddressTestCase(test.NovaTestCase):,class PciDeviceMatchTestCase(test.NoDBTestCase):class PciDeviceAddressParserTestCase(test.NoDBTestCase):class GetFunctionByIfnameTestCase(test.NoDBTestCase):class IsPhysicalFunctionTestCase(test.NoDBTestCase):class GetIfnameByPciAddressTestCase(test.NoDBTestCase):class GetVfNumByPciAddressTestCase(test.NoDBTestCase):,296,281
openstack%2Fkeystoneauth~master~I19c97d4b60e18abf95d0d55ae73348d973deec88,openstack/keystoneauth,master,I19c97d4b60e18abf95d0d55ae73348d973deec88,Fix docstring in identity.v3.oidc module,MERGED,2016-02-19 15:21:14.000000000,2016-02-19 18:30:00.000000000,2016-02-19 18:30:00.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-02-19 15:21:14.000000000', 'files': ['keystoneauth1/identity/v3/oidc.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/e250f99b5b8ee0f6a9fc0bbb39ac588d7ab45799', 'message': 'Fix docstring in identity.v3.oidc module\n\nDocstring for ``_OidcBase._get_keystone_token`` was inconsistent with\nthe arguments passed to the method.\n\nChange-Id: I19c97d4b60e18abf95d0d55ae73348d973deec88\n'}]",0,282380,e250f99b5b8ee0f6a9fc0bbb39ac588d7ab45799,7,3,1,8978,,,0,"Fix docstring in identity.v3.oidc module

Docstring for ``_OidcBase._get_keystone_token`` was inconsistent with
the arguments passed to the method.

Change-Id: I19c97d4b60e18abf95d0d55ae73348d973deec88
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/80/282380/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth1/identity/v3/oidc.py'],1,e250f99b5b8ee0f6a9fc0bbb39ac588d7ab45799,fix_docstring," :param federated_token_url: Protected URL for federated authentication, for example: https://localhost:5000/v3/\ OS-FEDERATION/identity_providers/bluepages/\ protocols/oidc/auth :type federated_token_url: string"," :param federated_auth_url: Protected URL for federated authentication, for example: https://localhost:5000/v3/\ OS-FEDERATION/identity_providers/bluepages/\ protocols/oidc/auth :type federated_auth_url: string",5,5
openstack%2Fnetworking-ovn~master~I68e0b52cf7cbcc64b461d27aca875f519a323ebe,openstack/networking-ovn,master,I68e0b52cf7cbcc64b461d27aca875f519a323ebe,Vagrant: Update readme,MERGED,2016-02-17 18:20:00.000000000,2016-02-19 18:22:33.000000000,2016-02-19 18:22:33.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 8410}, {'_account_id': 9515}, {'_account_id': 9970}]","[{'number': 1, 'created': '2016-02-17 18:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e2d49eba6cda7023689acd0cf48a844d64b93ef4', 'message': 'Vagrant: Update readme\n\nUpdate Vagrant readme to include recent architectural\nchanges. Also fix RST build error.\n\nChange-Id: I68e0b52cf7cbcc64b461d27aca875f519a323ebe\n'}, {'number': 2, 'created': '2016-02-19 00:20:08.000000000', 'files': ['doc/source/index.rst', 'vagrant/README.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/80472c6c88fe4d4d1a96b17d8f4975c763980783', 'message': 'Vagrant: Update readme\n\nUpdate Vagrant readme to include recent architectural\nchanges. Also fix RST build error.\n\nChange-Id: I68e0b52cf7cbcc64b461d27aca875f519a323ebe\n'}]",3,281454,80472c6c88fe4d4d1a96b17d8f4975c763980783,14,6,2,9515,,,0,"Vagrant: Update readme

Update Vagrant readme to include recent architectural
changes. Also fix RST build error.

Change-Id: I68e0b52cf7cbcc64b461d27aca875f519a323ebe
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/54/281454/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'vagrant/README.rst']",2,e2d49eba6cda7023689acd0cf48a844d64b93ef4,vagrant-readme1,"================================================= Automatic deployment using Vagrant and VirtualBox ================================================= The Vagrant scripts deploy OpenStack with Open Virtual Network (OVN) using four nodes to implement a minimal variant of the reference architecture: #. Database node containing the OVN northbound (NB) and southbound (SB) databases via the Open vSwitch (OVS) database and ``ovn-northd`` services. #. Controller node containing the Identity service, Image service, control plane portion of the Compute service, control plane portion of the Networking service including the ``networking-ovn`` plug-in, and the dashboard. #. Two compute nodes containing the Compute hypervisor, ``ovn-controller`` service for OVN, DHCP and metadata agents for the Networking service, OVS services. During deployment, Vagrant creates three VirtualBox networks: #. Vagrant management network for deployment and VM access to external networks such as the Internet. Becomes the VM ``eth0`` network interface. #. OpenStack management network for the OpenStack control plane, OVN control plane, and OVN overlay networks. Becomes the VM ``eth1`` network interface. #. OVN provider network that connects OpenStack instances to external networks such as the Internet. Becomes the VM ``eth2`` network interface. Requirements ------------ The default configuration requires approximately 12 GB of RAM and supports launching approximately four OpenStack instances using the ``m1.tiny`` flavor. You can change the amount of resources for each VM in the ``virtualbox.conf.yml`` file. Deployment ---------- #. Install `VirtualBox <https://www.virtualbox.org/wiki/Downloads>`_ and `Vagrant <http://downloads.vagrantup.com>`_. #. Clone the ``networking-ovn`` repository and change to the ``vagrant`` directory:: $ git clone https://git.openstack.org/openstack/networking-ovn.git $ cd networking-ovn/vagrant Note: Clone the ``networking-ovn`` repository into your home directory because Vagrant shares it with the VMs. #. Install plug-ins for Vagrant:: $ vagrant plugin install vagrant-cachier $ vagrant plugin install vagrant-vbguest #. If necessary, adjust any configuration in the ``virtualbox.conf.yml`` file. * If you change any IP addresses or networks, avoid conflicts with the host. * For evaluating large MTUs, adjust the ``mtu`` option. You must also change the MTU on the equivalent ``vboxnet`` interfaces on the host to the same value after Vagrant creates them. For example:: # ip link set dev vboxnet0 mtu 9000 # ip link set dev vboxnet1 mtu 9000 #. Launch the VMs and grab some coffee:: $ vagrant up #. After the process completes, you can use the ``vagrant status`` command to determine the VM status:: $ vagrant status Current machine states: ovn-db running (virtualbox) ovn-controller running (virtualbox) ovn-compute1 running (virtualbox) ovn-compute2 running (virtualbox) #. You can access the VMs using the following commands:: $ vagrant ssh ovn-db $ vagrant ssh ovn-controller $ vagrant ssh ovn-compute1 $ vagrant ssh ovn-compute2 Note: If you prefer to use the VM console, the password for the ``root`` account is ``vagrant``. #. Access OpenStack services via command-line tools on the ``ovn-controller`` node or via the dashboard from the host by pointing a web browser at the IP address of the ``ovn-controller`` node. Note: By default, OpenStack includes two accounts: ``admin`` and ``demo``, both using password ``password``. #. On Linux hosts, you can enable instances to access external networks such # sysctl -w net.ipv4.ip_forward=1 # sysctl -p # iptables -t nat -A POSTROUTING -s 10.10.0.0/16 -o eth0 -j MASQUERADE Note: These commands do not persist after rebooting the host. #. After completing your tasks, you can destroy the VMs:: $ vagrant destroy","============================================ Automated setup using Vagrant + Virtualbox ============================================ Automate the setup described here http://docs.openstack.org/developer/networking-ovn/testing.html. This will create a 3-node devstack (1 controller node + 2 compute nodes), where OVN is used as the OpenStack Neutron backend. Vagrant allows to configure the provider on which the virtual machines are created. Virtualbox is the default provider used to launch the VM's on a developer computer, but other providers can be used: VMWare, AWS, OpenStack, containers stuff, ... Quick Start ----------- 1. Install Virtualbox (https://www.virtualbox.org/wiki/Downloads) and Vagrant (http://downloads.vagrantup.com). 2. Configure:: git clone https://git.openstack.org/openstack/networking-ovn.git cd networking-ovn/vagrant vagrant plugin install vagrant-cachier vagrant plugin install vagrant-vbguest Note: Clone the repositories into your home directory because Vagrant shares them with the VMs it launches. Also, consider updating these repositories prior to launching VMs so they deploy the latest versions. 3. Adjust the settings in `virtualbox.conf.yml` if needed. Notice that 5GB RAM is the minimum to get 1 VM running on the controller node. If other provider is used, then you will need to create a conf file similar to `virtualbox.conf.yml`, then adjusted the file Vagrantfile to load that file. In `virtualbox.conf.yml` file, make sure that the IP addresses for the VMs fall into your VirtualBox Host-Only network IP range, if not, the script most likely will fail when it tries to access the VMs. For evaluating large MTUs, set the 'mtu' option for each VM to the appropriate value. You must also set the MTU on the equivalent ``vboxnet`` interfaces on the host to the same value after Vagrant creates them. For example, using a 9000 MTU:: ip link set dev vboxnet0 mtu 9000 ip link set dev vboxnet1 mtu 9000 4. Build up three VirtualBox VMs using vagrant, the process can take one hour:: vagrant up 5. Once the process is done successfully, you can use vagrant status and ssh command to see VM status and ssh to each of the VMs:: vagrant status The above command will show vagrant project VMs and status, you may see things like the following:: Current machine states: ovn-controller running (virtualbox) ovn-compute1 running (virtualbox) ovn-compute2 running (virtualbox) ... You can now ssh to these machines by using the following command:: vagrant ssh ovn-controller vagrant ssh ovn-compute1 vagrant ssh ovn-compute2 If you like to log in from the console of the VMs, the password for the root user is vagrant. You can point your browser to `http://<<ovn-controller ip address>>` to access the horizon dashboard. By default the ip address of ovn-controller was set to 192.168.33.12 in `provisioning/virtualbox.conf.yml` file. Use admin/password to log in once you see the Horizon login screen. You can certainly change the user name and password in file `networking-ovn/devstack/local.conf.sample` before you run vagrant up if you want different user name and password. 6. On Linux hosts, you can enable instances to access external networks such # sysctl -w net.ipv4.ip_forward=1 # iptables -t nat -A POSTROUTING -s 192.168.66.0/24 -o eth0 -j MASQUERADE 7. After you finished your work with the VMs, you can choose to destroy, suspend and later resume the VMs by using the following commands: vagrant suspend vagrant resume vagrant destroy",85,72
openstack%2Fproject-config~master~Ia2b32b25b27e4a8b4efa60439dc69e80cf49f548,openstack/project-config,master,Ia2b32b25b27e4a8b4efa60439dc69e80cf49f548,Enable coverage non-voting for networking-cisco,MERGED,2016-02-18 16:49:41.000000000,2016-02-19 18:22:04.000000000,2016-02-19 18:22:03.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-18 16:49:41.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cb71ae8a6bae5c31d09ed115e45d36c13bc69d6e', 'message': 'Enable coverage non-voting for networking-cisco\n\nGoal is to provide a tool for reviewers to better tell if unit tests are\nexercising the code being added/changed, in a effort to (indirectly)\nimprove quality. Prior to this commit coverage was 61%.\n\nIf any projects are also doing automated comparisons of coverage results\nwith a baseline, please let me know, as we would be interested in\nexploring taking advantage of that capability too.\n\nChange-Id: Ia2b32b25b27e4a8b4efa60439dc69e80cf49f548\n'}]",0,281956,cb71ae8a6bae5c31d09ed115e45d36c13bc69d6e,9,4,1,6659,,,0,"Enable coverage non-voting for networking-cisco

Goal is to provide a tool for reviewers to better tell if unit tests are
exercising the code being added/changed, in a effort to (indirectly)
improve quality. Prior to this commit coverage was 61%.

If any projects are also doing automated comparisons of coverage results
with a baseline, please let me know, as we would be interested in
exploring taking advantage of that capability too.

Change-Id: Ia2b32b25b27e4a8b4efa60439dc69e80cf49f548
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/281956/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,cb71ae8a6bae5c31d09ed115e45d36c13bc69d6e,, - name: networking-cisco-coverage voting: false - networking-cisco-coverage,,4,0
openstack%2Foslo.log~master~I09f0f061db263fa38507b5fe17a4a674b8d858d2,openstack/oslo.log,master,I09f0f061db263fa38507b5fe17a4a674b8d858d2,Add release note for removed log_format option,MERGED,2016-02-18 17:58:50.000000000,2016-02-19 18:20:41.000000000,2016-02-19 18:20:41.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-02-18 17:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/f8a6d3fb5ebe6c1792bbb826fb6b4b34804d6ba5', 'message': 'Add release note for removed log_format option\n\nRelease note for I09d7dcd0aeb91c2268365a90c491d46b979a49f1\n\nChange-Id: I09f0f061db263fa38507b5fe17a4a674b8d858d2\n'}, {'number': 2, 'created': '2016-02-19 16:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/e9373a79bedd159f712eb543c5b42cb87e6b2df9', 'message': 'Add release note for removed log_format option\n\nRelease note for I09d7dcd0aeb91c2268365a90c491d46b979a49f1\n\nChange-Id: I09f0f061db263fa38507b5fe17a4a674b8d858d2\n'}, {'number': 3, 'created': '2016-02-19 16:22:39.000000000', 'files': ['releasenotes/notes/remove-log-format-b4b949701cee3315.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/49df1e2776ad8c2613613fd388ed38f143a80c8d', 'message': 'Add release note for removed log_format option\n\nRelease note for I09d7dcd0aeb91c2268365a90c491d46b979a49f1\n\nChange-Id: I09f0f061db263fa38507b5fe17a4a674b8d858d2\n'}]",0,281989,49df1e2776ad8c2613613fd388ed38f143a80c8d,11,2,3,16051,,,0,"Add release note for removed log_format option

Release note for I09d7dcd0aeb91c2268365a90c491d46b979a49f1

Change-Id: I09f0f061db263fa38507b5fe17a4a674b8d858d2
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/89/281989/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/remove-log-format-b4b949701cee3315.yaml'],1,f8a6d3fb5ebe6c1792bbb826fb6b4b34804d6ba5,remove_log_format,--- upgrade: - The deprecated log_format configuration option has been removed. ,,3,0
openstack%2Fopenstack-ansible~liberty~Ib3c1f15778599e2aa6b5c1d03a37d9139c6b04cc,openstack/openstack-ansible,liberty,Ib3c1f15778599e2aa6b5c1d03a37d9139c6b04cc,Docs/Reno: Keystone v3 API default,MERGED,2016-02-17 13:49:23.000000000,2016-02-19 18:19:23.000000000,2016-02-19 18:19:23.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 10881}, {'_account_id': 12807}, {'_account_id': 19592}]","[{'number': 1, 'created': '2016-02-17 13:49:23.000000000', 'files': ['releasenotes/notes/keystone-v3-default-5eee0f7ca51bde58.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/917db97e15df5be63a643c333eeda46162683af6', 'message': 'Docs/Reno: Keystone v3 API default\n\nThis patch informs deployers about the Keystone v3 API changes\navailable in Liberty.\n\nCloses-bug: 1509272\n\nChange-Id: Ib3c1f15778599e2aa6b5c1d03a37d9139c6b04cc\n(cherry picked from commit 92ec93397162c9b754a61b3f954a75d8481268e4)\n'}]",0,281282,917db97e15df5be63a643c333eeda46162683af6,9,5,1,538,,,0,"Docs/Reno: Keystone v3 API default

This patch informs deployers about the Keystone v3 API changes
available in Liberty.

Closes-bug: 1509272

Change-Id: Ib3c1f15778599e2aa6b5c1d03a37d9139c6b04cc
(cherry picked from commit 92ec93397162c9b754a61b3f954a75d8481268e4)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/82/281282/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/keystone-v3-default-5eee0f7ca51bde58.yaml'],1,917db97e15df5be63a643c333eeda46162683af6,bug/1509272,--- features: - Keystone's v3 API is now the default for all services. upgrade: - Deployers can optionally remove the Keystone v2 endpoints from the database. Those endpoints will not be removed by the upgrade process. ,,6,0
openstack%2Fheat~master~Ia8bb09d991843860a8f0cfb73453b789fde28afd,openstack/heat,master,Ia8bb09d991843860a8f0cfb73453b789fde28afd,Force config_drive and transport for sw config,MERGED,2016-02-17 20:27:03.000000000,2016-02-19 18:17:57.000000000,2016-02-19 18:17:57.000000000,"[{'_account_id': 3}, {'_account_id': 7253}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-17 20:27:03.000000000', 'files': ['contrib/rackspace/rackspace/resources/cloud_server.py', 'contrib/rackspace/rackspace/tests/test_rackspace_cloud_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/845dd17825bed8be8e097efebc6b42011f03105d', 'message': 'Force config_drive and transport for sw config\n\nEnsure config_drive is enabled automatically if\nthe user data format is SOFTWARE_CONFIG. Also,\nlimit the choices for transport and format to\nonly those supported at Rackspace.\n\nChange-Id: Ia8bb09d991843860a8f0cfb73453b789fde28afd\n'}]",0,281513,845dd17825bed8be8e097efebc6b42011f03105d,11,3,1,7256,,,0,"Force config_drive and transport for sw config

Ensure config_drive is enabled automatically if
the user data format is SOFTWARE_CONFIG. Also,
limit the choices for transport and format to
only those supported at Rackspace.

Change-Id: Ia8bb09d991843860a8f0cfb73453b789fde28afd
",git fetch https://review.opendev.org/openstack/heat refs/changes/13/281513/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/rackspace/rackspace/resources/cloud_server.py', 'contrib/rackspace/rackspace/tests/test_rackspace_cloud_server.py']",2,845dd17825bed8be8e097efebc6b42011f03105d,rax_software_config_drive," def _test_server_config_drive(self, user_data, config_drive, result, ud_format='RAW'): properties['user_data_format'] = ud_format properties['software_config_transport'] = ""POLL_TEMP_URL"" self.patchobject(server, ""_populate_deployments_metadata"") def test_server_no_user_data_software_config(self): self._test_server_config_drive(None, False, True, ud_format=""SOFTWARE_CONFIG"")"," def _test_server_config_drive(self, user_data, config_drive, result):",35,8
openstack%2Fopenstack-ansible-galera_client~master~I74205322b1e2c7951d69222e22c3f6913b6d73d5,openstack/openstack-ansible-galera_client,master,I74205322b1e2c7951d69222e22c3f6913b6d73d5,Only update apt cache if necessary,MERGED,2016-02-15 13:50:40.000000000,2016-02-19 18:17:07.000000000,2016-02-19 18:17:07.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12807}]","[{'number': 1, 'created': '2016-02-15 13:50:40.000000000', 'files': ['tasks/galera_client_install.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/58a35de92a0567a1b72c8ce588d1e8bf5632e249', 'message': ""Only update apt cache if necessary\n\nWorkarounding the upstream ansible apt module bug\n\ndocumented here:\n\nhttps://github.com/ansible/ansible-modules-core/pull/1517\n\nFor the next versions of ansible we'll be using, we should\n\ncheck if the apt bug is fixed. When it's fixed, we could\n\nabandon this change and use the standard apt module\n\nwith correct cache handling.\n\nChange-Id: I74205322b1e2c7951d69222e22c3f6913b6d73d5\n""}]",0,280230,58a35de92a0567a1b72c8ce588d1e8bf5632e249,7,3,1,17068,,,0,"Only update apt cache if necessary

Workarounding the upstream ansible apt module bug

documented here:

https://github.com/ansible/ansible-modules-core/pull/1517

For the next versions of ansible we'll be using, we should

check if the apt bug is fixed. When it's fixed, we could

abandon this change and use the standard apt module

with correct cache handling.

Change-Id: I74205322b1e2c7951d69222e22c3f6913b6d73d5
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/30/280230/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_client_install.yml', 'defaults/main.yml']",2,58a35de92a0567a1b72c8ce588d1e8bf5632e249,gate-optimise,## APT Cache Options cache_timeout: 600 ,,17,6
openstack%2Fpython-openstackclient~master~I8dda7bbf1e27b0ac773f62a5cd293387da96f8df,openstack/python-openstackclient,master,I8dda7bbf1e27b0ac773f62a5cd293387da96f8df,"Subnet Pool: Add ""subnet pool show"" command",MERGED,2016-02-14 09:05:58.000000000,2016-02-19 18:17:00.000000000,2016-02-19 18:17:00.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-14 09:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e9e4520562631493e3a7324340ab9099544489e4', 'message': 'Subnet Pool: Add ""subnet pool show"" command\n\nPartially implements: blueprint neutron-client\nCloses-Bug: 1544590\n\nChange-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df\n'}, {'number': 2, 'created': '2016-02-14 10:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/064050e25828bd4e45035f38c23a92c3aa3cc132', 'message': 'Subnet Pool: Add ""subnet pool show"" command\n\nPartially implements: blueprint neutron-client\nCloses-Bug: 1544590\n\nChange-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df\n'}, {'number': 3, 'created': '2016-02-16 08:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0f06cd37b724b62c2df770b720612774ceb1e436', 'message': 'Subnet Pool: Add ""subnet pool show"" command\n\nChange-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df\nCloses-Bug: 1544590\nPartially implements: blueprint neutron-client\n'}, {'number': 4, 'created': '2016-02-17 06:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2934ccac9ee361a29736305eda4da7cffc151aeb', 'message': 'Subnet Pool: Add ""subnet pool show"" command\n\nChange-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df\nCloses-Bug: 1544590\nPartially implements: blueprint neutron-client\n'}, {'number': 5, 'created': '2016-02-18 00:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/87ba2ac60bdfa2831a61e2f3634e8be7e37eb34d', 'message': 'Subnet Pool: Add ""subnet pool show"" command\n\nChange-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df\nCloses-Bug: 1544590\nPartially implements: blueprint neutron-client\n'}, {'number': 6, 'created': '2016-02-19 03:06:19.000000000', 'files': ['openstackclient/tests/network/v2/fakes.py', 'releasenotes/notes/bug-1544590-8cf42954e28c2f42.yaml', 'openstackclient/network/v2/subnet_pool.py', 'doc/source/command-objects/subnet_pool.rst', 'setup.cfg', 'openstackclient/tests/network/v2/test_subnet_pool.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3c8bb165137ee1f17d99c270896b37fb9d00f07c', 'message': 'Subnet Pool: Add ""subnet pool show"" command\n\nChange-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df\nCloses-Bug: 1544590\nImplements: blueprint neutron-client\n'}]",11,279935,3c8bb165137ee1f17d99c270896b37fb9d00f07c,30,6,6,14937,,,0,"Subnet Pool: Add ""subnet pool show"" command

Change-Id: I8dda7bbf1e27b0ac773f62a5cd293387da96f8df
Closes-Bug: 1544590
Implements: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/35/279935/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/fakes.py', 'releasenotes/notes/bug-1544590-8cf42954e28c2f42.yaml', 'openstackclient/network/v2/subnet_pool.py', 'doc/source/command-objects/subnet_pool.rst', 'setup.cfg', 'openstackclient/tests/network/v2/test_subnet_pool.py']",6,e9e4520562631493e3a7324340ab9099544489e4,bug/1544590,"from openstackclient.common import exceptions from openstackclient.common import utilsfrom openstackclient.tests import utils as tests_utils class TestShowSubnetPool(TestSubnetPool): # The subnet_pool to set. _subnet_pool = network_fakes.FakeSubnetPool.create_one_subnet_pool() columns = ( 'address_scope_id', 'default_prefixlen', 'default_quota', 'id', 'ip_version', 'is_default', 'max_prefixlen', 'min_prefixlen', 'name', 'prefixes', 'project_id', 'shared', ) data = ( _subnet_pool.address_scope_id, _subnet_pool.default_prefixlen, _subnet_pool.default_quota, _subnet_pool.id, _subnet_pool.ip_version, _subnet_pool.is_default, _subnet_pool.max_prefixlen, _subnet_pool.min_prefixlen, _subnet_pool.name, utils.format_list(_subnet_pool.prefixes), _subnet_pool.tenant_id, _subnet_pool.shared, ) def setUp(self): super(TestShowSubnetPool, self).setUp() self.network.find_subnet_pool = mock.Mock( return_value=self._subnet_pool ) # Get the command object to test self.cmd = subnet_pool.ShowSubnetPool(self.app, self.namespace) def test_show_no_options(self): arglist = [] verifylist = [] # Missing required args should bail here self.assertRaises(tests_utils.ParserException, self.check_parser, self.cmd, arglist, verifylist) def test_show_all_options(self): arglist = [ self._subnet_pool.name, ] verifylist = [ ('pool', self._subnet_pool.name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) columns, data = self.cmd.take_action(parsed_args) self.network.find_subnet_pool.assert_called_with( self._subnet_pool.name, ignore_missing=False ) self.assertEqual(self.columns, columns) self.assertEqual(self.data, data)",,149,3
openstack%2Fneutron~stable%2Fkilo~Idda3631b766ea9d7329d3b4beb6eb34a73870684,openstack/neutron,stable/kilo,Idda3631b766ea9d7329d3b4beb6eb34a73870684,Add constants for vhost-user vif,ABANDONED,2016-02-09 16:57:29.000000000,2016-02-19 18:16:59.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 14844}, {'_account_id': 15443}]","[{'number': 1, 'created': '2016-02-09 16:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fda9b973947f08785ee11ce80d3e6c3734d296f', 'message': 'Add constants for vhost-user vif\n\nThis change amends the portbinging extention to include\ndefintions of the VIF_TYPE_VHOST_USER and its related\nVIF_DETAILS attributes\n\nChange-Id: Idda3631b766ea9d7329d3b4beb6eb34a73870684\nCloses-Bug: #1473278\n(cherry picked from commit 454ced5e0f8bb01ef7d64c9f507bf2b35d8fc553)\n'}, {'number': 2, 'created': '2016-02-15 09:50:50.000000000', 'files': ['neutron/extensions/portbindings.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c709471e613a6400387132aeba8a4eda2fa8d212', 'message': 'Add constants for vhost-user vif\n\nThis change amends the portbinging extention to include\ndefintions of the VIF_TYPE_VHOST_USER and its related\nVIF_DETAILS attributes\n\nChange-Id: Idda3631b766ea9d7329d3b4beb6eb34a73870684\nCloses-Bug: #1473278\n(cherry picked from commit 454ced5e0f8bb01ef7d64c9f507bf2b35d8fc553)\n'}]",0,277962,c709471e613a6400387132aeba8a4eda2fa8d212,27,12,2,14844,,,0,"Add constants for vhost-user vif

This change amends the portbinging extention to include
defintions of the VIF_TYPE_VHOST_USER and its related
VIF_DETAILS attributes

Change-Id: Idda3631b766ea9d7329d3b4beb6eb34a73870684
Closes-Bug: #1473278
(cherry picked from commit 454ced5e0f8bb01ef7d64c9f507bf2b35d8fc553)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/277962/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/portbindings.py'],1,6fda9b973947f08785ee11ce80d3e6c3734d296f,bug/1473278,# The keys below are used in the VIF_DETAILS attribute to convey # information related to the configuration of the vhost-user VIF driver. # - vhost_user_mode: String value used to declare the mode of a # vhost-user socket VHOST_USER_MODE = 'vhostuser_mode' # - server: socket created by hypervisor VHOST_USER_MODE_SERVER = 'server' # - client: socket created by vswitch VHOST_USER_MODE_CLIENT = 'client' # - vhostuser_socket String value used to declare the vhostuser socket name VHOST_USER_SOCKET = 'vhostuser_socket' # - vhost_user_ovs_plug: Boolean used to inform Nova that the ovs plug # method should be used when binding the # vhost-user vif. VHOST_USER_OVS_PLUG = 'vhostuser_ovs_plug' VIF_TYPE_VHOST_USER = 'vhostuser',,18,0
openstack%2Fopenstack-ansible-rsyslog_server~master~I00d6d0704e77bc3f8f19fb36933ac518b3372e8d,openstack/openstack-ansible-rsyslog_server,master,I00d6d0704e77bc3f8f19fb36933ac518b3372e8d,Only update apt cache if necessary,MERGED,2016-02-15 13:51:18.000000000,2016-02-19 18:08:56.000000000,2016-02-19 18:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12807}]","[{'number': 1, 'created': '2016-02-15 13:51:18.000000000', 'files': ['defaults/main.yml', 'tasks/rsyslog_server_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/4d4b140d65f7f0220eda9de253007fba28a1ae7d', 'message': ""Only update apt cache if necessary\n\nWorkarounding the upstream ansible apt module bug\n\ndocumented here:\n\nhttps://github.com/ansible/ansible-modules-core/pull/1517\n\nFor the next versions of ansible we'll be using, we should\n\ncheck if the apt bug is fixed. When it's fixed, we could\n\nabandon this change and use the standard apt module\n\nwith correct cache handling.\n\nChange-Id: I00d6d0704e77bc3f8f19fb36933ac518b3372e8d\n""}]",0,280239,4d4b140d65f7f0220eda9de253007fba28a1ae7d,7,3,1,17068,,,0,"Only update apt cache if necessary

Workarounding the upstream ansible apt module bug

documented here:

https://github.com/ansible/ansible-modules-core/pull/1517

For the next versions of ansible we'll be using, we should

check if the apt bug is fixed. When it's fixed, we could

abandon this change and use the standard apt module

with correct cache handling.

Change-Id: I00d6d0704e77bc3f8f19fb36933ac518b3372e8d
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/39/280239/1 && git format-patch -1 --stdout FETCH_HEAD,"['defaults/main.yml', 'tasks/rsyslog_server_install.yml']",2,4d4b140d65f7f0220eda9de253007fba28a1ae7d,gate-optimise,"#TODO(evrardjp): Replace the next 2 tasks by a standard apt with cache #when https://github.com/ansible/ansible-modules-core/pull/1517 is merged #in 1.9.x or we move to 2.0 (if tested working) - name: Check apt last update file stat: path: /var/cache/apt register: apt_cache_stat tags: - rsyslog-apt-packages - name: Update apt if needed when: > ""ansible_date_time.epoch|float - apt_cache_stat.stat.mtime > {{cache_timeout}}"" or add_repos | changed",- name: Update apt sources cache_valid_time: 600 register: apt_update until: apt_update|success retries: 5 delay: 2,17,6
openstack%2Fcinder~master~I9071821f8c1a95fccef214868e5cea026fed9657,openstack/cinder,master,I9071821f8c1a95fccef214868e5cea026fed9657,Update quota when volume type renames,MERGED,2016-01-15 08:14:54.000000000,2016-02-19 18:02:23.000000000,2016-02-19 16:21:44.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 8846}, {'_account_id': 8912}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19917}]","[{'number': 1, 'created': '2016-01-15 08:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4b4c04c711f457635542559032f8f70bbeaab42', 'message': 'Update quota when volume type renames.\n\nThis bug is to update quota_usages when volume_type is renamed.\n\nCloses_Bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\n'}, {'number': 2, 'created': '2016-01-19 09:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc3253cd45f4afee0686844870e223433446c476', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 3, 'created': '2016-01-19 12:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b1397ce751feff89d228b527bf06cb11eca6718', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 4, 'created': '2016-01-19 12:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba782be957f21e2e1ace2f0162681a408c5aeaf4', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 5, 'created': '2016-01-20 01:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e0211ec1aa35a6b9c504186295e7eb7c988999b', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 6, 'created': '2016-01-20 02:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce1c40d9aad444c49442450e0c588e457b8ddca9', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 7, 'created': '2016-01-20 02:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/52f2370a75797eaca92008d7237627c20cf80fa0', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 8, 'created': '2016-01-20 06:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b61386de6b183fcfc13e796199dec80605a59d17', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 9, 'created': '2016-02-02 07:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e361d11bb86f5d85ffb1877147eaed2b20b1116', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 10, 'created': '2016-02-03 07:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/17e4a80ca34c410b9b88678629d20ea80d53affb', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 11, 'created': '2016-02-03 07:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/618a4a05ead5d6e1d1f7ccd703662da35c6c526b', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages,\nquotas, quota_classes should be changed. Or else quota_usage etc show\nincorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 12, 'created': '2016-02-04 07:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b875613ceea1a1204793470f82796bb163859d7', 'message': ""Update quota when volume type renames.\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}, {'number': 13, 'created': '2016-02-15 03:19:09.000000000', 'files': ['cinder/tests/unit/test_db_api.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/db/api.py', 'cinder/volume/volume_types.py', 'cinder/tests/unit/api/contrib/test_types_manage.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/unit/test_quota.py', 'cinder/quota.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b1a322cf8fbf97a48f8fff07f70d2d32c83c9ea6', 'message': ""Update quota when volume type renames\n\nWhen customers rename volume type, the corresponding quota_usages\nshould be changed. Or else quota_usage shows incorrect data.\n\nMeanwhile, it deletes quota_usages whose corresponding volume\ntypes don't exist. These invalid data are left when renaming\nvolume types in old versions.\n\nCloses-bug: #1473183\n\nChange-Id: I9071821f8c1a95fccef214868e5cea026fed9657\nCo-Authored-By: wanghao <wanghao749@huawei.com>\n""}]",23,267999,b1a322cf8fbf97a48f8fff07f70d2d32c83c9ea6,261,49,13,15961,,,0,"Update quota when volume type renames

When customers rename volume type, the corresponding quota_usages
should be changed. Or else quota_usage shows incorrect data.

Meanwhile, it deletes quota_usages whose corresponding volume
types don't exist. These invalid data are left when renaming
volume types in old versions.

Closes-bug: #1473183

Change-Id: I9071821f8c1a95fccef214868e5cea026fed9657
Co-Authored-By: wanghao <wanghao749@huawei.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/267999/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/api.py', 'cinder/volume/volume_types.py', 'cinder/db/sqlalchemy/api.py', 'cinder/quota.py']",4,d4b4c04c711f457635542559032f8f70bbeaab42,bug/1473183," def reset_quota_usage(self, context, volume_type): resource_list = [] for quota in ('volumes', 'gigabytes', 'snapshots'): vtype_quota = ""%s_%s"" % (quota, volume_type.get('name')) resource_list.append(vtype_quota) db.quota_usage_reset(context, resource_list) def update_quota_usage_resource(self, context, old_type_name, new_type_name): for quota in ('volumes', 'gigabytes', 'snapshots'): old_res = ""%s_%s"" % (quota, old_type_name) new_res = ""%s_%s"" % (quota, new_type_name) db.quota_usage_update_resource(context, old_res, new_res) ",,88,4
openstack%2Fkolla~master~I596d4e59ded169d7d67ebbc964b6d2b46c94c8e7,openstack/kolla,master,I596d4e59ded169d7d67ebbc964b6d2b46c94c8e7,Addressed whitespace and idempotence for several items.,ABANDONED,2016-02-19 16:58:35.000000000,2016-02-19 17:50:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}]","[{'number': 1, 'created': '2016-02-19 16:58:35.000000000', 'files': ['tools/build_centos7_binary'], 'web_link': 'https://opendev.org/openstack/kolla/commit/386b85b17f730d2ae74b9082335ca17fc7af8de0', 'message': 'Addressed whitespace and idempotence for several items.\n\nChange-Id: I596d4e59ded169d7d67ebbc964b6d2b46c94c8e7\n'}]",0,282427,386b85b17f730d2ae74b9082335ca17fc7af8de0,4,2,1,20647,,,0,"Addressed whitespace and idempotence for several items.

Change-Id: I596d4e59ded169d7d67ebbc964b6d2b46c94c8e7
",git fetch https://review.opendev.org/openstack/kolla refs/changes/27/282427/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/build_centos7_binary'],1,386b85b17f730d2ae74b9082335ca17fc7af8de0,,"#!/bin/bash # # This script will execute the steps necessary to build CentOS binary images # and push them to a local repository. This was put together following # the quickstart notes (https://github.com/openstack/kolla/blob/master/doc/quickstart.rst) # and the helpful answers given in IRC on #kolla. # # Please configure the IP address of your deployment box that will host the # docker registry. export KOLLA_DEPLOY_REGISTRY=<DEPLOYMENT-IP-HERE> ################## Docker Hosts ####################### # Set selinux in permissive mode for now (docker hosts) # TODO: (high priority) Create selinux policies sudo setenforce 0 sed -i -e 's/SELINUX=.*/SELINUX=permissive/' /etc/selinux/config # Disable firewall for now (docker hosts) # TODO: (high priority) Create selinux policies sudo systemctl stop iptables ip6tables sudo systemctl disable iptables ip6tables # Install docker from upstream curl -sSL https://get.docker.io | bash sudo systemctl restart docker.service # Disable libvirt (just in case, not on minimal install) sudo systemctl stop libvirtd.service sudo systemctl disable libvirtd.service # Enable insecure registry for docker sudo sed -i ""s/other_args=.*/other_args=\""--insecure-registry \ ${KOLLA_DEPLOY_REGISTRY}:4000\""/"" /etc/sysconfig/docker || \ cat << EOF | tee /etc/sysconfig/docker other_args=""--insecure-registry ${KOLLA_DEPLOY_REGISTRY}:4000"" EOF # Modify docker service to include $other_args and change mount flags cat << EOF | sudo tee /etc/systemd/system/docker.service [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network.target docker.socket Requires=docker.socket [Service] EnvironmentFile=/etc/sysconfig/docker Type=notify ExecStart=/usr/bin/docker daemon -H fd:// \$other_args MountFlags=shared LimitNOFILE=1048576 LimitNPROC=1048576 LimitCORE=infinity [Install] WantedBy=multi-user.target EOF # Restart docker sudo systemctl daemon-reload sudo systemctl stop docker sudo systemctl start docker # Enable IP forwarding (this may not be needed, but I ran into it) cat << EOF | sudo tee /etc/sysctl.d/50-ip_forward.conf # This is needed for docker networking net.ipv4.ip_forward=1 EOF sysctl --system # Install setuptools so we can install pip sudo yum install -y python-setuptools # Install pip curl https://bootstrap.pypa.io/get-pip.py | sudo python # Install docker-py sudo pip install docker-py>=1.4.0 ################## Deployment Host ####################### # Install setuptool & EPEL sudo yum install -y python-setuptools epel-release # Install ansible, git sudo yum install -y ansible git # Install pip sudo easy_install pip # Install python openstack clients sudo yum install -y python-devel libffi-devel openssl-devel gcc sudo pip install -U python-openstackclient sudo pip install -U python-neutronclient if [ ! -d ./kolla ]; then # Pull down Kolla git and install prereqs git clone https://git.openstack.org/openstack/kolla else (cd kolla; git pull --rebase) fi pip install -U kolla/ # Skip if the registry is already running if docker ps | sed 's/ \+ /\t/g' | awk -F'\t' '$2 ~ /^registry:/ { print $6 }' | grep -q '4000->5000'; then # Follow steps for docker hosts before proceeding if running registry on # deployment host # Deploy docker registry to deployment host sudo docker run -d -p 4000:5000 --restart=always --name registry registry:2.3 fi # Check if the containers/images already exist, if so, let's cleanup if docker ps -a | grep kollaglue/centos-binary; then ./kolla/tools/cleanup-containers ./kolla/tools/cleanup-images fi # Build images kolla-build --base centos --type binary --registry \ ${KOLLA_DEPLOY_REGISTRY}:4000 --push --tag=2.0.0 ",,121,0
openstack%2Fkeystone~master~I90f4885161a72758986a652e845b4017f9cdcfb7,openstack/keystone,master,I90f4885161a72758986a652e845b4017f9cdcfb7,handle unicode names for federated users,MERGED,2016-02-14 01:43:40.000000000,2016-02-19 17:47:50.000000000,2016-02-19 17:47:49.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 13055}, {'_account_id': 13063}]","[{'number': 1, 'created': '2016-02-14 01:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2bd0c208bd49bd7d335464a5248a948fb6300d73', 'message': 'WIP handle unicode names for federated users\n\nChange-Id: I90f4885161a72758986a652e845b4017f9cdcfb7\nRelated-Bug: 1525250\n'}, {'number': 2, 'created': '2016-02-16 16:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ee136df46d837a6f90c3a23bbf834dd9bd7a7848', 'message': 'WIP handle unicode names for federated users\n\nCo-Authored-By: David Stanek <dstanek@dstanek.com>\nChange-Id: I90f4885161a72758986a652e845b4017f9cdcfb7\nRelated-Bug: 1525250\n'}, {'number': 3, 'created': '2016-02-17 04:23:33.000000000', 'files': ['keystone/federation/utils.py', 'keystone/tests/unit/mapping_fixtures.py', 'keystone/tests/unit/contrib/federation/test_utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e913001cbedb4dd8748023ede31115a032de83f8', 'message': 'handle unicode names for federated users\n\nthe previous logic that handled getting the assertions from\nthe environment did not account for utf8 characters\n\nCo-Authored-By: David Stanek <dstanek@dstanek.com>\nCloses-Bug: 1525250\n\nChange-Id: I90f4885161a72758986a652e845b4017f9cdcfb7\n'}]",3,279908,e913001cbedb4dd8748023ede31115a032de83f8,22,8,3,6482,,,0,"handle unicode names for federated users

the previous logic that handled getting the assertions from
the environment did not account for utf8 characters

Co-Authored-By: David Stanek <dstanek@dstanek.com>
Closes-Bug: 1525250

Change-Id: I90f4885161a72758986a652e845b4017f9cdcfb7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/08/279908/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/mapping_fixtures.py', 'keystone/tests/unit/contrib/federation/test_utils.py']",2,2bd0c208bd49bd7d335464a5248a948fb6300d73,bug/1525250," def test_rule_engine_unicode(self): """"""Test mapping engine when group_ids is explicitly set. If the group ids list has only one group, test if the transformation is done correctly """""" mapping = mapping_fixtures.MAPPING_LARGE assertion = mapping_fixtures.UNICODE_NAME_ASSERTION rp = mapping_utils.RuleProcessor(FAKE_MAPPING_ID, mapping['rules']) values = rp.process(assertion) fn = assertion.get('FirstName') ln = assertion.get('LastName') full_name = '%s %s' % (fn, ln) user_name = values.get('user', {}).get('name') self.assertEqual(full_name, user_name)",,28,0
openstack%2Fpython-openstackclient~master~Ib890e95d775c3fc43df80fa05c82d726e78cdac8,openstack/python-openstackclient,master,Ib890e95d775c3fc43df80fa05c82d726e78cdac8,Don't use Mock.called_once_with that does not exist,MERGED,2016-02-19 06:07:39.000000000,2016-02-19 17:44:56.000000000,2016-02-19 17:44:55.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-02-19 06:07:39.000000000', 'files': ['openstackclient/tests/common/test_commandmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/48681af86a1dfd50a8e90a9d7cd9068417cc52a9', 'message': 'Don\'t use Mock.called_once_with that does not exist\n\nClass mock.Mock does not exist method ""called_once_with()"", it just\nexists method ""assert_called_once_with()"". ""called_once_with()"" does\nnothing because it\'s a mock object.\n\nIn OSC, only one place is still using ""called_once_with()"". Fix it.\n\nChange-Id: Ib890e95d775c3fc43df80fa05c82d726e78cdac8\nPartial Bug: 1544522\n'}]",0,282188,48681af86a1dfd50a8e90a9d7cd9068417cc52a9,15,4,1,14937,,,0,"Don't use Mock.called_once_with that does not exist

Class mock.Mock does not exist method ""called_once_with()"", it just
exists method ""assert_called_once_with()"". ""called_once_with()"" does
nothing because it's a mock object.

In OSC, only one place is still using ""called_once_with()"". Fix it.

Change-Id: Ib890e95d775c3fc43df80fa05c82d726e78cdac8
Partial Bug: 1544522
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/88/282188/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/common/test_commandmanager.py'],1,48681af86a1dfd50a8e90a9d7cd9068417cc52a9,bug/1544522, iter_entry_points.assert_called_once_with('test'), assert iter_entry_points.called_once_with('test'),1,1
openstack%2Fkolla~master~If78b020c81157a948c5c3283f1410bcb6e5c1e61,openstack/kolla,master,If78b020c81157a948c5c3283f1410bcb6e5c1e61,Keep consistent with others for ironic containers,MERGED,2016-02-16 09:04:50.000000000,2016-02-19 17:43:05.000000000,2016-02-19 17:43:05.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 13039}, {'_account_id': 14119}, {'_account_id': 18723}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-16 09:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3f5ea13951b515d14622502efe3f684212456a35', 'message': 'Keep consistent with others for ironic containers name\n\nFix the mistral containers name in cleanup-containers script BTW.\n\nTrivialFix\n\nChange-Id: If78b020c81157a948c5c3283f1410bcb6e5c1e61\n'}, {'number': 2, 'created': '2016-02-16 12:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/645ef677203c864b17be444516aaf09a3d304d25', 'message': 'Keep consistent with others for ironic containers name\n\nFix the mistral containers name in cleanup-containers script BTW.\n\nPartially-implements: blueprint ironic-container\nChange-Id: If78b020c81157a948c5c3283f1410bcb6e5c1e61\n'}, {'number': 3, 'created': '2016-02-19 00:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d44632f6b14fab58ac192730a678aa23576aeaf0', 'message': 'Keep consistent with others for ironic containers name\n\nFix the mistral containers name in cleanup-containers script BTW.\n\nPartially-implements: blueprint ironic-container\nChange-Id: If78b020c81157a948c5c3283f1410bcb6e5c1e61\n'}, {'number': 4, 'created': '2016-02-19 12:32:38.000000000', 'files': ['tools/cleanup-containers', 'ansible/roles/ironic/tasks/bootstrap.yml', 'ansible/roles/ironic/tasks/start.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/75e57824004ce8e5ee1317c3501c3b1bc481c790', 'message': 'Keep consistent with others for ironic containers\n\nMake the containers and volumes names of ironic to be\nconsistent with others.\n\nPartially-implements: blueprint ironic-container\nChange-Id: If78b020c81157a948c5c3283f1410bcb6e5c1e61\n'}]",5,280557,75e57824004ce8e5ee1317c3501c3b1bc481c790,24,7,4,18723,,,0,"Keep consistent with others for ironic containers

Make the containers and volumes names of ironic to be
consistent with others.

Partially-implements: blueprint ironic-container
Change-Id: If78b020c81157a948c5c3283f1410bcb6e5c1e61
",git fetch https://review.opendev.org/openstack/kolla refs/changes/57/280557/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/cleanup-containers', 'ansible/roles/ironic/tasks/start.yml']",2,3f5ea13951b515d14622502efe3f684212456a35,280557," name: ""ironic_api"" name: ""ironic_conductor"" name: ""ironic_discoverd"""," name: ""ironic-api"" name: ""ironic-conductor"" name: ""ironic-discoverd""",5,5
openstack%2Fpython-novaclient~master~Ie430b64c7e08f6cba8771c85cc1894fa71357ccb,openstack/python-novaclient,master,Ie430b64c7e08f6cba8771c85cc1894fa71357ccb,[functional] Move code for boot vm to base testcase,MERGED,2016-02-09 15:50:00.000000000,2016-02-19 17:41:55.000000000,2016-02-19 17:41:55.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 6062}]","[{'number': 1, 'created': '2016-02-09 15:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/13a69251c7a3422d3f8f822b23b683afa08fd66f', 'message': '[functional] Move code for boot vm to base testcase\n\nIt would be nice to reduce code duplication.\n\nChange-Id: Ie430b64c7e08f6cba8771c85cc1894fa71357ccb\n'}, {'number': 2, 'created': '2016-02-09 17:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/4726b7210b32be4c6778e279aad57450338a8891', 'message': '[functional] Move code for boot vm to base testcase\n\nIt would be nice to reduce code duplication.\n\nChange-Id: Ie430b64c7e08f6cba8771c85cc1894fa71357ccb\n'}, {'number': 3, 'created': '2016-02-19 11:22:06.000000000', 'files': ['novaclient/tests/functional/v2/legacy/test_fixedips.py', 'novaclient/tests/functional/v2/test_servers.py', 'novaclient/tests/functional/base.py', 'novaclient/tests/functional/v2/legacy/test_consoles.py', 'novaclient/tests/functional/v2/legacy/test_extended_attributes.py', 'novaclient/tests/functional/v2/legacy/test_virtual_interface.py', 'novaclient/tests/functional/v2/legacy/test_servers.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/083ce7eeeada3e4d73c55e4e2d7239febb3993f6', 'message': '[functional] Move code for boot vm to base testcase\n\nIt would be nice to reduce code duplication.\n\nChange-Id: Ie430b64c7e08f6cba8771c85cc1894fa71357ccb\n'}]",0,277901,083ce7eeeada3e4d73c55e4e2d7239febb3993f6,17,4,3,9545,,,0,"[functional] Move code for boot vm to base testcase

It would be nice to reduce code duplication.

Change-Id: Ie430b64c7e08f6cba8771c85cc1894fa71357ccb
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/01/277901/2 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/functional/v2/legacy/test_fixedips.py', 'novaclient/tests/functional/v2/test_servers.py', 'novaclient/tests/functional/base.py', 'novaclient/tests/functional/v2/legacy/test_consoles.py', 'novaclient/tests/functional/v2/legacy/test_extended_attributes.py', 'novaclient/tests/functional/v2/legacy/test_virtual_interface.py', 'novaclient/tests/functional/v2/legacy/test_servers.py']",7,13a69251c7a3422d3f8f822b23b683afa08fd66f,functional_boot_vm, return [self._create_server(name) for i in range(number)],"from novaclient.v2 import shell network = self.client.networks.list()[0] servers = [] for i in range(number): servers.append(self.client.servers.create( name, self.image, self.flavor, nics=[{""net-id"": network.id}])) shell._poll_for_status( self.client.servers.get, servers[-1].id, 'building', ['active']) self.addCleanup(servers[-1].delete) return servers",21,59
openstack%2Fcompute-hyperv~stable%2Fliberty~Ia81a49b2cd35a17edfe5edab35bef42191c7f4af,openstack/compute-hyperv,stable/liberty,Ia81a49b2cd35a17edfe5edab35bef42191c7f4af,Removes nova from requirements.txt,MERGED,2016-02-18 17:40:06.000000000,2016-02-19 17:41:27.000000000,2016-02-19 17:41:27.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}]","[{'number': 1, 'created': '2016-02-18 17:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/9561226ad26ed7b2bf879fbe3b3acaf66c0a6f20', 'message': 'Removes nova from requirements.txt\n\nRemoves nova from the requirements.txt and instead\nadd tools\\tox_install.sh file, which takes care of\ninstalling nova. This is useful for Jenkins, as it\nneeds nova in order to run its tests.\n\nChange-Id: Ia81a49b2cd35a17edfe5edab35bef42191c7f4af\n'}, {'number': 2, 'created': '2016-02-19 12:54:23.000000000', 'files': ['requirements.txt', 'tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/0aebbdbbfb1884dcbf7b6913184fbafe08debd32', 'message': 'Removes nova from requirements.txt\n\nRemoves nova from the requirements.txt and instead\nadd tools\\tox_install.sh file, which takes care of\ninstalling nova. This is useful for Jenkins, as it\nneeds nova in order to run its tests.\n\nChange-Id: Ia81a49b2cd35a17edfe5edab35bef42191c7f4af\n'}]",0,281977,0aebbdbbfb1884dcbf7b6913184fbafe08debd32,11,3,2,8213,,,0,"Removes nova from requirements.txt

Removes nova from the requirements.txt and instead
add tools\tox_install.sh file, which takes care of
installing nova. This is useful for Jenkins, as it
needs nova in order to run its tests.

Change-Id: Ia81a49b2cd35a17edfe5edab35bef42191c7f4af
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/77/281977/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tools/tox_install.sh', 'tox.ini']",3,9561226ad26ed7b2bf879fbe3b3acaf66c0a6f20,,install_command = {toxinidir}/tools/tox_install.sh {opts} {packages},install_command = pip install --allow-external -U --force-reinstall {opts} {packages},42,2
openstack%2Ffuel-library~master~I8e07a5dd8ac77e8223db751a59828cf9b7cc4d0a,openstack/fuel-library,master,I8e07a5dd8ac77e8223db751a59828cf9b7cc4d0a,Ensure parent directory exists for auxiliary CentOS repo,ABANDONED,2016-02-19 15:03:53.000000000,2016-02-19 17:35:52.000000000,,[{'_account_id': 8971}],"[{'number': 1, 'created': '2016-02-19 15:03:53.000000000', 'files': ['deployment/puppet/fuel/manifests/auxiliaryrepos.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b2e9647ddac5205534eb4527bb47757dad61165e', 'message': ""Ensure parent directory exists for auxiliary CentOS repo\n\nIn case of clean CentOS system we don't have directory structures\nfor auxiliary CentOS repos, so let's create it correctly\n\nCloses-bug: #1547504\nBlueprint: separate-fuel-node-provisioning\n\nСhange-Id: I437e559abf6d71c355a434591127cd825a665207\n\nChange-Id: I8e07a5dd8ac77e8223db751a59828cf9b7cc4d0a\n""}]",0,282370,b2e9647ddac5205534eb4527bb47757dad61165e,9,1,1,12817,,,0,"Ensure parent directory exists for auxiliary CentOS repo

In case of clean CentOS system we don't have directory structures
for auxiliary CentOS repos, so let's create it correctly

Closes-bug: #1547504
Blueprint: separate-fuel-node-provisioning

Сhange-Id: I437e559abf6d71c355a434591127cd825a665207

Change-Id: I8e07a5dd8ac77e8223db751a59828cf9b7cc4d0a
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/70/282370/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/fuel/manifests/auxiliaryrepos.pp'],1,b2e9647ddac5205534eb4527bb47757dad61165e,bp/separate-fuel-node-provisioning," $centos_dir_root = ""${repo_root}/centos/"" $centos_dir = ""${centos_dir_root}/auxiliary/"" $ubuntu_dir = ""${repo_root}/ubuntu/auxiliary/"" file { [$centos_dir_root, $centos_dir]: unless => ""test -d ${ubuntu_dir}/pool && \"," $centos_dir = ""${repo_root}/centos/auxiliary/"" $ubuntu_dir = ""${repo_root}/ubuntu/auxiliary/"" file { $centos_dir: unless => ""test -d ${ubuntu_dir}/pool && \",5,4
openstack%2Fsahara-dashboard~master~I33eb60788a8bbef40ea47b22b11dee24f198effc,openstack/sahara-dashboard,master,I33eb60788a8bbef40ea47b22b11dee24f198effc,"Unbreak ""setup.py install""",MERGED,2016-02-19 16:50:21.000000000,2016-02-19 17:34:18.000000000,2016-02-19 17:23:40.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8090}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-19 16:50:21.000000000', 'files': ['sahara_dashboard/content/data_processing/locale'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/55512fcc5e8d2db09896bcc55352912f8e650b08', 'message': 'Unbreak ""setup.py install""\n\npython setup.py install fails with:\nerror: can\'t copy \'sahara_dashboard/content/data_processing/locale\':\ndoesn\'t exist or not a regular file\n\nThe symbolic link does not work with setuptools, this needs to be\nhandled differently. Remove for now to get requirements gate working\nagain as this blocks *all* changes for the requirements repository.\n\nChange-Id: I33eb60788a8bbef40ea47b22b11dee24f198effc\n'}]",0,282422,55512fcc5e8d2db09896bcc55352912f8e650b08,11,5,1,6547,,,0,"Unbreak ""setup.py install""

python setup.py install fails with:
error: can't copy 'sahara_dashboard/content/data_processing/locale':
doesn't exist or not a regular file

The symbolic link does not work with setuptools, this needs to be
handled differently. Remove for now to get requirements gate working
again as this blocks *all* changes for the requirements repository.

Change-Id: I33eb60788a8bbef40ea47b22b11dee24f198effc
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/22/282422/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara_dashboard/content/data_processing/locale'],1,55512fcc5e8d2db09896bcc55352912f8e650b08,locale-link,,../../locale,0,1
openstack%2Fopenstack-manuals~master~Ie04f83436da9510262e8e8dfb852ffa967013523,openstack/openstack-manuals,master,Ie04f83436da9510262e8e8dfb852ffa967013523,[networking-guide] fix a wrong path,MERGED,2016-02-17 04:29:02.000000000,2016-02-19 17:14:55.000000000,2016-02-17 09:51:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-17 04:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/de0ca52b8576a1adc01ca153b0fa9b919efcb934', 'message': '[networking-guide] fix a wrong path\n\nChange-Id: Ie04f83436da9510262e8e8dfb852ffa967013523\nClose-bug: 1546377\n'}, {'number': 2, 'created': '2016-02-17 07:10:20.000000000', 'files': ['doc/networking-guide/source/adv-config-ipv6.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/902d6a28fe3d65fff34f06113c1500f8e43b55b7', 'message': '[networking-guide] fix a wrong path\n\nChange-Id: Ie04f83436da9510262e8e8dfb852ffa967013523\nClose-bug: 1546377\n'}]",0,281043,902d6a28fe3d65fff34f06113c1500f8e43b55b7,12,3,2,19779,,,0,"[networking-guide] fix a wrong path

Change-Id: Ie04f83436da9510262e8e8dfb852ffa967013523
Close-bug: 1546377
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/281043/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/adv-config-ipv6.rst'],1,de0ca52b8576a1adc01ca153b0fa9b919efcb934,bug/1546377,"To enable prefix delegation, edit the ``/etc/neutron/neutron.conf`` file. If you ``/etc/neutron/neutron.conf``:``/etc/neutron/neutron.conf``:","To enable prefix delegation, edit the ``etc/neutron.conf`` file. If you ``etc/neutron.conf``:``etc/neutron.conf``:",3,3
openstack%2Fneutron~master~I020454276bed79ae43bf57577cc9b7aa30b8756f,openstack/neutron,master,I020454276bed79ae43bf57577cc9b7aa30b8756f,Sean's super crazy metadata test bazzar,ABANDONED,2016-02-18 19:47:07.000000000,2016-02-19 17:01:53.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 20629}]","[{'number': 1, 'created': '2016-02-18 19:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1591e87a67261965a1b0b731932ff1a1c62f7a1', 'message': ""Sean's super crazy metadata test bazzar\n\nChange-Id: I020454276bed79ae43bf57577cc9b7aa30b8756f\n""}, {'number': 2, 'created': '2016-02-18 19:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5376417689483c9b080834d0c287ac90bf409f83', 'message': ""Sean's super crazy metadata test bazzar\n\nDepends-on: I22eb3a3fcd8e74a1d9085acde15c25a927ae12cb\n\nNova logging\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\n\nChange-Id: I020454276bed79ae43bf57577cc9b7aa30b8756f\n""}, {'number': 3, 'created': '2016-02-18 21:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2832984792ac1fd61c2be4b2c7780fc7d7bb834', 'message': ""Sean's super crazy metadata test bazzar\n\nNova logging\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\n\nChange-Id: I020454276bed79ae43bf57577cc9b7aa30b8756f\n""}, {'number': 4, 'created': '2016-02-19 12:03:21.000000000', 'files': ['neutron/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/710656eb3ffc394cea368915f37e704b358647d7', 'message': ""Sean's super crazy metadata test bazzar\n\nNova logging\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\n\nChange-Id: I020454276bed79ae43bf57577cc9b7aa30b8756f\n""}]",0,282031,710656eb3ffc394cea368915f37e704b358647d7,44,13,4,2750,,,0,"Sean's super crazy metadata test bazzar

Nova logging
Depends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474

Change-Id: I020454276bed79ae43bf57577cc9b7aa30b8756f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/282031/4 && git format-patch -1 --stdout FETCH_HEAD,[],0,d1591e87a67261965a1b0b731932ff1a1c62f7a1,,,,0,0
openstack%2Fcinder~master~Ic57d42532f74147376593c85e7e557822c2d9541,openstack/cinder,master,Ic57d42532f74147376593c85e7e557822c2d9541,Fix test_blockbridge to support hash randomization,ABANDONED,2016-02-15 13:35:09.000000000,2016-02-19 16:54:45.000000000,,"[{'_account_id': 3}, {'_account_id': 8122}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19917}, {'_account_id': 20490}]","[{'number': 1, 'created': '2016-02-15 13:35:09.000000000', 'files': ['cinder/tests/unit/test_blockbridge.py', 'cinder/tests/unit/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ded541d30b99c764ec4a499cc724d2e43c69cfb1', 'message': 'Fix test_blockbridge to support hash randomization\n\nOn Python 3, hash randomization is enabled by default: dictionary\nitems are iterated on a random order. tox.ini works around this issue\nusing PYTHONHASHSEED=0, but this change enhances the test to work\nwithout PYTHONHASHSEED.\n\nOn Python 2, hash randomization can be enabled using -R command line\nvariable.\n\nChange-Id: Ic57d42532f74147376593c85e7e557822c2d9541\nRelated-Bug: 1348818\n'}]",2,280224,ded541d30b99c764ec4a499cc724d2e43c69cfb1,30,26,1,9107,,,0,"Fix test_blockbridge to support hash randomization

On Python 3, hash randomization is enabled by default: dictionary
items are iterated on a random order. tox.ini works around this issue
using PYTHONHASHSEED=0, but this change enhances the test to work
without PYTHONHASHSEED.

On Python 2, hash randomization can be enabled using -R command line
variable.

Change-Id: Ic57d42532f74147376593c85e7e557822c2d9541
Related-Bug: 1348818
",git fetch https://review.opendev.org/openstack/cinder refs/changes/24/280224/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_blockbridge.py', 'cinder/tests/unit/utils.py']",2,ded541d30b99c764ec4a499cc724d2e43c69cfb1,bug/1348818,"from oslo_serialization import jsonutils class CompareJSON(object): """"""Compare serialized JSON. Helper for unittest.mock objects used to compare serialized JSON to an object. __eq__() method deserialize JSON instead of comparing serialized JSON to not fail because of hash serialization. """""" def __init__(self, obj): self.obj = obj def __eq__(self, other): obj2 = jsonutils.loads(other) return self.obj == obj2",,19,3
openstack%2Ffuel-web~master~Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8,openstack/fuel-web,master,Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8,Fixed misleading provision task message,MERGED,2016-02-11 12:38:36.000000000,2016-02-19 16:53:15.000000000,2016-02-19 16:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 13505}, {'_account_id': 14357}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-11 12:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/124d113b727862e739bf94e610350dd6cd65194c', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 2, 'created': '2016-02-11 13:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9c9a5a40e0e60ce83dc353b379ec820eddb2b3c9', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 3, 'created': '2016-02-12 07:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a8d137101da19f1992142393a487df32d03175aa', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 4, 'created': '2016-02-12 11:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/00b1fd09865508dc6f68ee256e41922ad1058e3b', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 5, 'created': '2016-02-12 11:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6f1854bdb2fbe72c28e6cacb64e60203f6b0a4ed', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 6, 'created': '2016-02-15 14:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4559354ee86aaa9af9582342e43168f3aa5f0bc7', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 7, 'created': '2016-02-18 09:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c9225d5f98c8f71104f16474e14bc0674a2ab0ff', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 8, 'created': '2016-02-18 13:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cba790c918f083afa6abb79ca749f2d7c6f9039d', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 9, 'created': '2016-02-18 14:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9ca034838e576c9c0c248fe7d0647b6671a37222', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 10, 'created': '2016-02-19 10:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/92ff06ce3f13ec903c166b153c8cc4f4e62f35f2', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}, {'number': 11, 'created': '2016-02-19 14:56:51.000000000', 'files': ['nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/test/integration/test_rpc_consumer.py', 'nailgun/nailgun/test/unit/test_receiver.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/task/fake.py', 'nailgun/nailgun/test/unit/test_objects.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bef4d846030757cfe407c32e715c5197cb559137', 'message': 'Fixed misleading provision task message\n\nIn case if not all nodes are provisioned/deployed  message will be\nshows message that only part of nodes in expected state, otherwise\nshows that whole cluster in expected state.\nAlso fixed calculating status of task is based on all nodes from cluster,\nnow only affected nodes are used to calculate task status.\nAlso fixed truncate of stack on exception handling in fake tasks\n\nChange-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8\nCloses-Bug: 1542196\n'}]",18,279025,bef4d846030757cfe407c32e715c5197cb559137,124,15,11,18205,,,0,"Fixed misleading provision task message

In case if not all nodes are provisioned/deployed  message will be
shows message that only part of nodes in expected state, otherwise
shows that whole cluster in expected state.
Also fixed calculating status of task is based on all nodes from cluster,
now only affected nodes are used to calculate task status.
Also fixed truncate of stack on exception handling in fake tasks

Change-Id: Icdb36e2e6a732becbb48d02b5c087922ecb3b7a8
Closes-Bug: 1542196
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/25/279025/11 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/objects/node.py', 'nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/test/integration/test_rpc_consumer.py', 'nailgun/nailgun/test/unit/test_receiver.py']",5,124d113b727862e739bf94e610350dd6cd65194c,bug/1542201," NailgunReceiver._success_action( self.task, 'ready', 100, self.env.nodes ) ""Deployment of environment '[^\s]+' is done."""," NailgunReceiver._success_action(self.task, 'ready', 100) ""Deployment of environment '[^\s]+' is done. """,149,83
openstack%2Fhorizon~master~I75cec674516b07e141d74729b545e3d2cadee82d,openstack/horizon,master,I75cec674516b07e141d74729b545e3d2cadee82d,exclude subnets without gateway in create interface,MERGED,2015-07-28 12:45:18.000000000,2016-02-19 16:49:38.000000000,2016-02-19 16:49:38.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4264}, {'_account_id': 6610}, {'_account_id': 8040}, {'_account_id': 8871}, {'_account_id': 9622}, {'_account_id': 10442}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 14151}]","[{'number': 1, 'created': '2015-07-28 12:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f5a1ecf2f7b65a249d95ab295b5fc4045b4c8ef2', 'message': ""exclude subnets without gateway in create interface\n\nIn create interface form, if we select the subnet which\ndon't have gateway ip, the create will fail.\n\nwe can remove the subnets which don't have gateway ip\nfrom the sebnet options to prevent the unnecessary\nserver call.\n\nChange-Id: I75cec674516b07e141d74729b545e3d2cadee82d\nCloses-Bug: #1478939\n""}, {'number': 2, 'created': '2015-10-14 06:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/051d1d5f07e6aab332225388e0ede756402d1a3a', 'message': ""exclude subnets without gateway in create interface\n\nIn create interface form, if we select the subnet which\ndon't have gateway ip, the create will fail.\n\nwe can remove the subnets which don't have gateway ip\nfrom the sebnet options to prevent the unnecessary\nserver call.\n\nChange-Id: I75cec674516b07e141d74729b545e3d2cadee82d\nCloses-Bug: #1478939\n""}, {'number': 3, 'created': '2016-02-17 09:12:09.000000000', 'files': ['openstack_dashboard/dashboards/project/routers/ports/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ce65691bfc876400025eb8ba2ae18f8ff96e18f6', 'message': ""exclude subnets without gateway in create interface\n\nIn create interface form, if we select the subnet which\ndon't have gateway ip, the create will fail.\n\nwe can remove the subnets which don't have gateway ip\nfrom the sebnet options to prevent the unnecessary\nserver call.\n\nChange-Id: I75cec674516b07e141d74729b545e3d2cadee82d\nCloses-Bug: #1478939\n""}]",0,206524,ce65691bfc876400025eb8ba2ae18f8ff96e18f6,19,11,3,10442,,,0,"exclude subnets without gateway in create interface

In create interface form, if we select the subnet which
don't have gateway ip, the create will fail.

we can remove the subnets which don't have gateway ip
from the sebnet options to prevent the unnecessary
server call.

Change-Id: I75cec674516b07e141d74729b545e3d2cadee82d
Closes-Bug: #1478939
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/206524/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/routers/ports/forms.py'],1,f5a1ecf2f7b65a249d95ab295b5fc4045b4c8ef2,bug/1478939, if subnet.id not in router_subnet_ids and subnet.gateway_ip], if subnet.id not in router_subnet_ids],2,1
openstack%2Ffuel-web~stable%2F7.0~I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad,openstack/fuel-web,stable/7.0,I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad,Introduce priorities for network_schemes,MERGED,2016-02-04 10:04:16.000000000,2016-02-19 16:49:29.000000000,2016-02-19 16:36:21.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11587}, {'_account_id': 11898}, {'_account_id': 12559}, {'_account_id': 14610}, {'_account_id': 14689}, {'_account_id': 15454}, {'_account_id': 16771}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-04 10:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c4e5aa5d55a3b1a36e201674a16d84d3b01fd2ed', 'message': ""Introduce priorities for network_schemes\n\nCurrently we have no way to control templates applying order\nfor set of roles(cinder+compute). This patch introduces ability\nto specify absolute priority for template to make it possible for\noperator to manage templates order. Patch doesn't affect order of\ntemplates where 'priority' field is not specified.\n\nChange-Id: I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad\nCloses-bug: 1540374\n""}, {'number': 2, 'created': '2016-02-08 10:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/df5dd3faa34d0e2b19bb4df263b4936d10f31198', 'message': ""Introduce priorities for network_schemes\n\nCurrently we have no way to control templates applying order\nfor set of roles(cinder+compute). This patch introduces ability\nto specify absolute priority for template to make it possible for\noperator to manage templates order. Patch doesn't affect order of\ntemplates where 'priority' field is not specified.\n\nChange-Id: I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad\nCloses-bug: 1540374\n""}, {'number': 3, 'created': '2016-02-08 10:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0fafe86792172843484b7dbbe87d7f96d6a9042c', 'message': ""Introduce priorities for network_schemes\n\nCurrently we have no way to control templates applying order\nfor set of roles(cinder+compute). This patch introduces ability\nto specify absolute priority for template to make it possible for\noperator to manage templates order. Patch doesn't affect order of\ntemplates where 'priority' field is not specified.\n\nChange-Id: I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad\nCloses-bug: 1540374\n""}, {'number': 4, 'created': '2016-02-08 11:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6eefce938f1024168226bd4f30953b73dca6917a', 'message': ""Introduce priorities for network_schemes\n\nCurrently we have no way to control templates applying order\nfor set of roles(cinder+compute). This patch introduces ability\nto specify absolute priority for template to make it possible for\noperator to manage templates order. Patch doesn't affect order of\ntemplates where 'priority' field is not specified.\n\nChange-Id: I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad\nCloses-bug: 1540374\n""}, {'number': 5, 'created': '2016-02-10 13:23:18.000000000', 'files': ['nailgun/nailgun/test/unit/test_network_template.py', 'nailgun/nailgun/api/v1/validators/json_schema/network_template.py', 'nailgun/nailgun/fixtures/network_template.json', 'nailgun/nailgun/orchestrator/neutron_serializers.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_70.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1410c5e75fdb06531d744a90f04607a350a7af3f', 'message': ""Introduce priorities for network_schemes\n\nCurrently we have no way to control templates applying order\nfor set of roles(cinder+compute). This patch introduces ability\nto specify absolute priority for template to make it possible for\noperator to manage templates order. Patch doesn't affect order of\ntemplates where 'priority' field is not specified.\n\nChange-Id: I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad\nCloses-bug: 1540374\n""}]",3,276125,1410c5e75fdb06531d744a90f04607a350a7af3f,42,12,5,12559,,,0,"Introduce priorities for network_schemes

Currently we have no way to control templates applying order
for set of roles(cinder+compute). This patch introduces ability
to specify absolute priority for template to make it possible for
operator to manage templates order. Patch doesn't affect order of
templates where 'priority' field is not specified.

Change-Id: I4348d3dea2c382837eb7f96e5b0ae3eb0312c8ad
Closes-bug: 1540374
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/25/276125/4 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/api/v1/validators/json_schema/network_template.py', 'nailgun/nailgun/test/unit/test_network_template.py', 'nailgun/nailgun/orchestrator/neutron_serializers.py']",3,c4e5aa5d55a3b1a36e201674a16d84d3b01fd2ed,bug/1540374,"try: from collections import OrderedDict except ImportError: from ordereddict import OrderedDict import re # If some template contains 'priority' property, than node's # templates order should be based on it, in other case, all node's # templates will have zero priority and have the same order as # there is no property field. role_templates[t] = template['templates'][t].get( 'priority', 0) # sort network schemes by priority sorted_role_templates = sorted(role_templates.iteritems(), key=lambda x: x[1]) for t, p in sorted_role_templates:",from ordereddict import OrderedDictimport re role_templates[t] = True for t in role_templates:,62,4
openstack%2Fapi-site~master~Ieee6fca3aec9f1c7953337661cc6a0806bbd3194,openstack/api-site,master,Ieee6fca3aec9f1c7953337661cc6a0806bbd3194,Update the description corresponding to type,MERGED,2016-02-18 18:52:07.000000000,2016-02-19 16:49:02.000000000,2016-02-19 16:49:02.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-18 18:52:07.000000000', 'files': ['api-ref/src/wadls/clustering-api/src/v1/wadl/clustering-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/99dd028619636fd13c61b4c904b6b9691c78ab84', 'message': ""Update the description corresponding to type\n\nUpdating the description from 'Filters the response by the name of\na profile.' to 'Filters the response by the type of a profile.'\nin the request parameter of API to List Profiles, corresponding to\n'type' parameter.\n\nChange-Id: Ieee6fca3aec9f1c7953337661cc6a0806bbd3194\nCloses-Bug: #1547166\n""}]",0,282006,99dd028619636fd13c61b4c904b6b9691c78ab84,11,3,1,19840,,,0,"Update the description corresponding to type

Updating the description from 'Filters the response by the name of
a profile.' to 'Filters the response by the type of a profile.'
in the request parameter of API to List Profiles, corresponding to
'type' parameter.

Change-Id: Ieee6fca3aec9f1c7953337661cc6a0806bbd3194
Closes-Bug: #1547166
",git fetch https://review.opendev.org/openstack/api-site refs/changes/06/282006/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/clustering-api/src/v1/wadl/clustering-api.wadl'],1,99dd028619636fd13c61b4c904b6b9691c78ab84,bug/1547166, Filters the response by the type of a profile., Filters the response by the name of a profile.,1,1
openstack%2Fopenstack-manuals~stable%2Fliberty~I5edd175b095916338059a6d4023b60f06a65738f,openstack/openstack-manuals,stable/liberty,I5edd175b095916338059a6d4023b60f06a65738f,[networking-guide] change awkward wording in sentence,MERGED,2016-02-19 13:22:48.000000000,2016-02-19 16:45:39.000000000,2016-02-19 16:45:38.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 14947}]","[{'number': 1, 'created': '2016-02-19 13:22:48.000000000', 'files': ['doc/networking-guide/source/intro-network-address-translation.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dedc68feb86566b8cbbde5b48c2e5d61b3b63308', 'message': '[networking-guide] change awkward wording in sentence\n\nChange-Id: I5edd175b095916338059a6d4023b60f06a65738f\n(cherry picked from commit 338969d503a13bdc9f5d29f420c727172e70b44e)\n'}]",0,282330,dedc68feb86566b8cbbde5b48c2e5d61b3b63308,9,3,1,16237,,,0,"[networking-guide] change awkward wording in sentence

Change-Id: I5edd175b095916338059a6d4023b60f06a65738f
(cherry picked from commit 338969d503a13bdc9f5d29f420c727172e70b44e)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/30/282330/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/intro-network-address-translation.rst'],1,dedc68feb86566b8cbbde5b48c2e5d61b3b63308,networking_guide,connect to a server on the public Internet. An example is a user,connect to a server on the public Internet. One such example is a user,1,1
openstack%2Fapp-catalog~master~I07382fcea0a698a33d7667845936ff56060521a5,openstack/app-catalog,master,I07382fcea0a698a33d7667845936ff56060521a5,Detect dead links,MERGED,2016-02-19 06:22:49.000000000,2016-02-19 16:45:20.000000000,2016-02-19 16:45:20.000000000,"[{'_account_id': 3}, {'_account_id': 9788}]","[{'number': 1, 'created': '2016-02-19 06:22:49.000000000', 'files': ['openstack_catalog/web/static/assets_dead.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/cdcb4fb7536aa70e5721cf6c20e5bbcd06ffceb6', 'message': 'Detect dead links\n\nChange-Id: I07382fcea0a698a33d7667845936ff56060521a5\n'}]",0,282197,cdcb4fb7536aa70e5721cf6c20e5bbcd06ffceb6,6,2,1,11131,,,0,"Detect dead links

Change-Id: I07382fcea0a698a33d7667845936ff56060521a5
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/97/282197/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/assets_dead.yaml'],1,cdcb4fb7536aa70e5721cf6c20e5bbcd06ffceb6,detect-dead-links, Fedora 23 Atomic Cloud: {active: false},,1,0
openstack%2Fproject-config~master~Iced830854a000605510de4dfaa733eee98abc51f,openstack/project-config,master,Iced830854a000605510de4dfaa733eee98abc51f,Switch experimental bindep jobs to constraints,MERGED,2016-02-19 16:23:26.000000000,2016-02-19 16:44:06.000000000,2016-02-19 16:44:06.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-19 16:23:26.000000000', 'files': ['jenkins/jobs/experimental-workers.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e85d182410e4bf72c61ce1e17c2d0f7a0958f4d2', 'message': 'Switch experimental bindep jobs to constraints\n\nMost of the production equivalents of the experimental bindep jobs\nwere switched to use zuul-cloner and pip upper constraints, so\nfollow suit. This allows for a more accurate validation of the\nproposed solution.\n\nChange-Id: Iced830854a000605510de4dfaa733eee98abc51f\n'}]",0,282409,e85d182410e4bf72c61ce1e17c2d0f7a0958f4d2,8,4,1,5263,,,0,"Switch experimental bindep jobs to constraints

Most of the production equivalents of the experimental bindep jobs
were switched to use zuul-cloner and pip upper constraints, so
follow suit. This allows for a more accurate validation of the
proposed solution.

Change-Id: Iced830854a000605510de4dfaa733eee98abc51f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/282409/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/experimental-workers.yaml'],1,e85d182410e4bf72c61ce1e17c2d0f7a0958f4d2,bindep, - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints, - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep,6,6
openstack%2Fnova~master~Iac389ebd1d283225e3e1e4b6fd537f78666394e6,openstack/nova,master,Iac389ebd1d283225e3e1e4b6fd537f78666394e6,Add a friendly reminder to EC2 removal release note,ABANDONED,2016-02-19 04:26:18.000000000,2016-02-19 16:41:08.000000000,,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-19 04:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1af4dfc1071a239c6ebf03afa61061ee4ce2fa56', 'message': 'Add a friendly reminder to EC2 removal release note\n\nThe removal of these services affects the api pipeline. For\ndeployments existing before Mitaka, the upgrade phase needs\nto take care of refreshing api-paste.ini to ensure that the\nmissing middleware does not break the metadata pipeline.\n\nChange-Id: Iac389ebd1d283225e3e1e4b6fd537f78666394e6\nRelated-bug: 1545101\n'}, {'number': 2, 'created': '2016-02-19 05:57:08.000000000', 'files': ['releasenotes/notes/remove_ec2_and_objectstore_api-4ccb539db1d171fa.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f1ce0448b5c5a4491f37afd7b674191c964c783', 'message': 'Add a friendly reminder to EC2 removal release note\n\nThe removal of these services affects the api pipeline. For\ndeployments existing before Mitaka, the upgrade phase needs\nto take care of refreshing api-paste.ini to ensure that the\nmissing middleware does not break the metadata pipeline.\n\nRelated-bug: 1545101\n\nChange-Id: Iac389ebd1d283225e3e1e4b6fd537f78666394e6\n'}]",0,282161,8f1ce0448b5c5a4491f37afd7b674191c964c783,22,10,2,748,,,0,"Add a friendly reminder to EC2 removal release note

The removal of these services affects the api pipeline. For
deployments existing before Mitaka, the upgrade phase needs
to take care of refreshing api-paste.ini to ensure that the
missing middleware does not break the metadata pipeline.

Related-bug: 1545101

Change-Id: Iac389ebd1d283225e3e1e4b6fd537f78666394e6
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/282161/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/ec2/__init__.py', 'releasenotes/notes/remove_ec2_and_objectstore_api-4ccb539db1d171fa.yaml']",2,1af4dfc1071a239c6ebf03afa61061ee4ce2fa56,bug/1545101, ec2-api project (http://git.openstack.org/cgit/openstack/ec2-api/). This may affect the metadata api pipeline in api-paste.ini. , ec2-api project (http://git.openstack.org/cgit/openstack/ec2-api/).,4,3
openstack%2Fneutron~master~Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997,openstack/neutron,master,Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997,Test test test,ABANDONED,2016-02-18 01:39:12.000000000,2016-02-19 16:40:37.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 20629}]","[{'number': 1, 'created': '2016-02-18 01:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/caa3e1363b1f3be5e0675c76a4b600de038ae68a', 'message': 'Depends-on: I22eb3a3fcd8e74a1d9085acde15c25a927ae12cb\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 2, 'created': '2016-02-18 05:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/07317fa13e191bd9689c10e79c36dc8660bb4671', 'message': 'Depends-on: I22eb3a3fcd8e74a1d9085acde15c25a927ae12cb\n\nDepends-on: Ia7004a5fb89f60ab48e8b1df600ae43f3a09a27d\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 3, 'created': '2016-02-18 19:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c9c01403abf0fcf70f12eba59fd353db2892ce8', 'message': 'Test test test\n\nDepends-on: I22eb3a3fcd8e74a1d9085acde15c25a927ae12cb\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 4, 'created': '2016-02-18 21:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3bc3b397b41e863ab5a1180fff7dad824076526', 'message': 'Test test test\n\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 5, 'created': '2016-02-19 00:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e81ec36d9f843c35115385a396bd87c4e8a97c04', 'message': 'Test test test\n\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\nDepends-on: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 6, 'created': '2016-02-19 01:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78f9b9c525cc4cd9852a30c76b9362afa9e9c05f', 'message': 'Test test test\n\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\nDepends-on: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 7, 'created': '2016-02-19 03:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db2d0213b3585e04cfc473418ceed024fc620dbb', 'message': 'Test test test\n\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\nDepends-on: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 8, 'created': '2016-02-19 05:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5750dd6240b065ed0664db7eac16ae105308c66', 'message': 'Test test test\n\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\nDepends-on: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}, {'number': 9, 'created': '2016-02-19 06:59:16.000000000', 'files': ['neutron/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/78f1ef6f41e76a79dc3caebc5a76d9595c565d7f', 'message': 'Test test test\n\nDepends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474\nDepends-on: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n\nChange-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997\n'}]",0,281600,78f1ef6f41e76a79dc3caebc5a76d9595c565d7f,115,14,9,748,,,0,"Test test test

Depends-on: I3a244934b44ffdda469bbaa3e6ca43fc48316474
Depends-on: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7

Change-Id: Ifd7b1d4d70e02873f0ea62cf1bdbe8979d94d997
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/281600/7 && git format-patch -1 --stdout FETCH_HEAD,['neutron/__init__.py'],1,caa3e1363b1f3be5e0675c76a4b600de038ae68a,grenade-nonsense,# doh!,,1,0
openstack%2Fgrenade~master~I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7,openstack/grenade,master,I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7,Remove ec2 related middleware from nova metadata api pipeline,ABANDONED,2016-02-19 00:14:33.000000000,2016-02-19 16:40:21.000000000,,"[{'_account_id': 3}, {'_account_id': 748}]","[{'number': 1, 'created': '2016-02-19 00:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/189a37b7a8f7a194fed3bbb62dea0079f7d199aa', 'message': 'WIP: update the metadata pipeline\n\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 2, 'created': '2016-02-19 01:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/fbe381e5518a8f67bf724dcdbea7f8acf8716795', 'message': 'WIP: update the metadata pipeline\n\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 3, 'created': '2016-02-19 03:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/3e9f01831a6780ae30d538e2e70355ec2c803a3a', 'message': 'Remove ec2 related middleware from nova metadata api pipeline\n\nChange eec7a55319 removed ec2 support from Nova in favor of the\nexternal ec2-api project. As a result, the metadata pipeline\nno longer contains ec2 related middleware components.\n\nFor this reason, when upgrading from Liberty, api-paste.ini needs\nto be updated to match its Mitaka version. In fact, if the deprecated\nmiddleware are left behind, this can confuse metadata clients like the\nNeutron metadata agent which proxies requests from instances to\nthe Nova API service.\n\nThis patch removes the deprecated middleware during the upgrade phase.\n\nCloses-bug: 1545101\n\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 4, 'created': '2016-02-19 04:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/68133251b3f65faaafd65ed14c7ba8ccec3781c6', 'message': 'Remove ec2 related middleware from nova metadata api pipeline\n\nChange eec7a55319 removed ec2 support from Nova in favor of the\nexternal ec2-api project. As a result, the metadata pipeline\nno longer contains ec2 related middleware components.\n\nFor this reason, when upgrading from Liberty, api-paste.ini needs\nto be updated to match its Mitaka version. In fact, if the deprecated\nmiddleware are left behind, this can confuse metadata clients like the\nNeutron metadata agent which proxies requests from instances to\nthe Nova API service.\n\nThis patch deletes the deprecated middleware during the upgrade phase.\nMore cleanup of the api-paste.ini would be nice, but removing the\nmiddleware from the metadata pipeline is enough to make the rest\nof the ec2 related api-paste configuration completely silent.\n\nCloses-bug: 1545101\n\nDepends-on: Iac389ebd1d283225e3e1e4b6fd537f78666394e6\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 5, 'created': '2016-02-19 05:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/24fe76f37d8fa1fe70f26cd14ec57c9e0a674d35', 'message': 'Remove ec2 related middleware from nova metadata api pipeline\n\nChange eec7a55319 removed ec2 support from Nova in favor of the\nexternal ec2-api project. As a result, the metadata pipeline\nno longer contains ec2 related middleware components.\n\nFor this reason, when upgrading from Liberty, api-paste.ini needs\nto be updated to match its Mitaka version. In fact, if the deprecated\nmiddleware are left behind, this can confuse metadata clients like the\nNeutron metadata agent which proxies requests from instances to\nthe Nova API service.\n\nThis patch refreshes api-paste.ini to reflect the match its Mitaka\nversion, which includes CORS middleware supports too.\n\nCloses-bug: 1545101\n\nDepends-on: Iac389ebd1d283225e3e1e4b6fd537f78666394e6\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 6, 'created': '2016-02-19 05:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/d3bd88e59cce697589bdb85094797a63ae3ac916', 'message': 'Remove ec2 related middleware from nova metadata api pipeline\n\nChange eec7a55319 removed ec2 support from Nova in favor of the\nexternal ec2-api project. As a result, the metadata pipeline\nno longer contains ec2 related middleware components.\n\nFor this reason, when upgrading from Liberty, api-paste.ini needs\nto be updated to match its Mitaka version. In fact, if the deprecated\nmiddleware are left behind, this can confuse metadata clients like the\nNeutron metadata agent which proxies requests from instances to\nthe Nova API service.\n\nThis patch updates api-paste.ini to match its Mitaka version, which\nincludes CORS middleware supports too.\n\nCloses-bug: 1545101\n\nDepends-on: Iac389ebd1d283225e3e1e4b6fd537f78666394e6\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 7, 'created': '2016-02-19 05:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/19bc8891e80dd2d18c990b2379d1e938c785eb0d', 'message': 'Remove ec2 related middleware from nova metadata api pipeline\n\nChange eec7a55319 removed ec2 support from Nova in favor of the\nexternal ec2-api project. As a result, the metadata pipeline\nno longer contains ec2 related middleware components.\n\nFor this reason, when upgrading from Liberty, api-paste.ini needs\nto be updated to match its Mitaka version. In fact, if the deprecated\nmiddleware are left behind, this can confuse metadata clients like the\nNeutron metadata agent which proxies requests from instances to\nthe Nova API service.\n\nThis patch updates api-paste.ini to match its Mitaka version, which\nincludes CORS middleware supports too. Release note updated in [1].\n\nCloses-bug: 1545101\n\n[1] Iac389ebd1d283225e3e1e4b6fd537f78666394e6\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}, {'number': 8, 'created': '2016-02-19 06:57:19.000000000', 'files': ['projects/60_nova/from-liberty/upgrade-nova'], 'web_link': 'https://opendev.org/openstack/grenade/commit/2937076b50936752368417a6c9dd1168ea7296ae', 'message': 'Remove ec2 related middleware from nova metadata api pipeline\n\nChange eec7a55319 removed ec2 support from Nova in favor of the\nexternal ec2-api project. As a result, the metadata pipeline\nno longer contains ec2 related middleware components.\n\nFor this reason, when upgrading from Liberty, api-paste.ini needs\nto be updated to match its Mitaka version. In fact, if the deprecated\nmiddleware are left behind, this can confuse metadata clients like the\nNeutron metadata agent which proxies requests from instances to\nthe Nova API service.\n\nThis patch updates api-paste.ini to match its Mitaka version, which\nincludes CORS middleware supports too. Release note updated in [1].\n\nCloses-bug: 1545101\n\n[1] Iac389ebd1d283225e3e1e4b6fd537f78666394e6\nChange-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7\n'}]",0,282110,2937076b50936752368417a6c9dd1168ea7296ae,15,2,8,748,,,0,"Remove ec2 related middleware from nova metadata api pipeline

Change eec7a55319 removed ec2 support from Nova in favor of the
external ec2-api project. As a result, the metadata pipeline
no longer contains ec2 related middleware components.

For this reason, when upgrading from Liberty, api-paste.ini needs
to be updated to match its Mitaka version. In fact, if the deprecated
middleware are left behind, this can confuse metadata clients like the
Neutron metadata agent which proxies requests from instances to
the Nova API service.

This patch updates api-paste.ini to match its Mitaka version, which
includes CORS middleware supports too. Release note updated in [1].

Closes-bug: 1545101

[1] Iac389ebd1d283225e3e1e4b6fd537f78666394e6
Change-Id: I80593f07cbe87fe65a69eb7fb3fe972fea44d4b7
",git fetch https://review.opendev.org/openstack/grenade refs/changes/10/282110/7 && git format-patch -1 --stdout FETCH_HEAD,['projects/60_nova/from-liberty/upgrade-nova'],1,189a37b7a8f7a194fed3bbb62dea0079f7d199aa,bug/1545101," # Replace old pipeline with new one iniset $NOVA_API_PASTE_INI pipeline:meta pipeline ""cors metaapp""",,3,0
openstack%2Finstack-undercloud~master~I9fa3e8d8211a054b8ebb9a2a74547b1437b3f69d,openstack/instack-undercloud,master,I9fa3e8d8211a054b8ebb9a2a74547b1437b3f69d,Enable heat-manage purge_deleted cron job,MERGED,2016-02-12 00:42:36.000000000,2016-02-19 16:36:04.000000000,2016-02-19 16:36:04.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-02-12 00:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/6c5a8b11baffb97c1fc93a6626dbcd7a19ff622d', 'message': 'Enable heat-manage purge_deleted cron job\n\nWithout this the heat database tables will grow without limit.\n\nChange-Id: I9fa3e8d8211a054b8ebb9a2a74547b1437b3f69d\nDependsOn: Ia2b80e5003450cd794ebb0c9ca72200ec8616e81\n'}, {'number': 2, 'created': '2016-02-12 01:06:36.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp', 'elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/728d8c9133722aa1d89bb5b0598f2914b5dc73fc', 'message': 'Enable heat-manage purge_deleted cron job\n\nWithout this the heat database tables will grow without limit.\n\nChange-Id: I9fa3e8d8211a054b8ebb9a2a74547b1437b3f69d\nDependsOn: Ia2b80e5003450cd794ebb0c9ca72200ec8616e81\n'}]",0,279338,728d8c9133722aa1d89bb5b0598f2914b5dc73fc,12,4,2,4571,,,0,"Enable heat-manage purge_deleted cron job

Without this the heat database tables will grow without limit.

Change-Id: I9fa3e8d8211a054b8ebb9a2a74547b1437b3f69d
DependsOn: Ia2b80e5003450cd794ebb0c9ca72200ec8616e81
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/38/279338/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/puppet-stack-config/puppet-stack-config.pp', 'elements/puppet-stack-config/puppet-stack-config.yaml.template']",2,6c5a8b11baffb97c1fc93a6626dbcd7a19ff622d,heat_purge_deleted,heat::cron::purge_deleted::age: 1 heat::cron::purge_deleted::age_type: 'days',,3,0
openstack%2Ffuel-web~master~Ic6541f8e227251ae992a3005d543a8e1e42665f3,openstack/fuel-web,master,Ic6541f8e227251ae992a3005d543a8e1e42665f3,Adds ability to force update environment attributes,MERGED,2016-02-05 21:40:00.000000000,2016-02-19 16:31:26.000000000,2016-02-19 15:50:08.000000000,"[{'_account_id': 3}, {'_account_id': 7185}, {'_account_id': 8392}, {'_account_id': 8797}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11827}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 18182}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-05 21:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/09a8ad746881806d0341e7be430a2f14f2da1c9a', 'message': ""Adds ability to force update environment attributes\n\nIn order to upgrade deployed cluster that is in operational state\nwithout re-provisioning it, we need a possibility to forcefully\nupdate cluster attributes (aka cluster/environment settings).\n\nOptional flag '--force' is added to the commands below:\nfuel settings --env <env_id> --upload --force\nfuel env --env <env_id> --attributes --upload --force\n\nThis flag is handled by API here:\nclusters/<id>/attributes/?force=1\n\nPartial-Bug: 1540434\nChange-Id: Ic6541f8e227251ae992a3005d543a8e1e42665f3\n""}, {'number': 2, 'created': '2016-02-09 07:08:40.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/cluster.py', 'nailgun/nailgun/api/v1/validators/cluster.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/af3f5e1dbfa0f8120e63e6b56c8c6913112f938c', 'message': ""Adds ability to force update environment attributes\n\nIn order to upgrade deployed cluster that is in operational state\nwithout re-provisioning it, we need a possibility to forcefully\nupdate cluster attributes (aka cluster/environment settings).\n\nOptional flag '--force' is added to the commands below:\nfuel settings --env <env_id> --upload --force\nfuel env --env <env_id> --attributes --upload --force\n\nThis flag is handled by API here:\nclusters/<id>/attributes/?force=1\n\nPartial-Bug: 1540434\nChange-Id: Ic6541f8e227251ae992a3005d543a8e1e42665f3\n""}]",0,276921,af3f5e1dbfa0f8120e63e6b56c8c6913112f938c,35,13,2,17877,,,0,"Adds ability to force update environment attributes

In order to upgrade deployed cluster that is in operational state
without re-provisioning it, we need a possibility to forcefully
update cluster attributes (aka cluster/environment settings).

Optional flag '--force' is added to the commands below:
fuel settings --env <env_id> --upload --force
fuel env --env <env_id> --attributes --upload --force

This flag is handled by API here:
clusters/<id>/attributes/?force=1

Partial-Bug: 1540434
Change-Id: Ic6541f8e227251ae992a3005d543a8e1e42665f3
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/21/276921/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/api/v1/handlers/cluster.py', 'nailgun/nailgun/api/v1/validators/cluster.py']",2,09a8ad746881806d0341e7be430a2f14f2da1c9a,bug/1540434," def validate(cls, data, cluster=None, force=False): cls.validate_allowed_attributes(cluster, d, force) def validate_allowed_attributes(cls, cluster, data, force): :param force: Allow forcefully update cluster attributes :type force: bool if not cluster.is_locked or force:"," def validate(cls, data, cluster=None): cls.validate_allowed_attributes(cluster, d) def validate_allowed_attributes(cls, cluster, data): if not cluster.is_locked:",10,5
openstack%2Fopenstacksdk~master~I7ba991959e93a95cbb99354bc78093ba9a3bd480,openstack/openstacksdk,master,I7ba991959e93a95cbb99354bc78093ba9a3bd480,Override delete function of senlin cluster/node,MERGED,2016-01-28 10:48:16.000000000,2016-02-19 16:31:10.000000000,2016-02-19 16:31:10.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-01-28 10:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3d452b0aee75982585ba837bc3cbbc3cf4709f6e', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 2, 'created': '2016-01-29 03:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3b08f0ea2601ee840f2227ae7f2c224101c4ecdb', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 3, 'created': '2016-01-31 10:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2b5f71af213fd1cd2c558e843d21aa37fa4dfbe3', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 4, 'created': '2016-02-01 15:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e7f443238fe2929eb95430d0ba7e1002d8d992ad', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 5, 'created': '2016-02-15 02:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ad8f4e11be6f228edb108df3387b38e8e79d158c', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 6, 'created': '2016-02-19 04:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/03c964dab26e9f633fe177a418845ebb5e4e5075', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 7, 'created': '2016-02-19 15:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f07c9bd68f2fe42a349343478d786bac7123f147', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 8, 'created': '2016-02-19 16:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d809d27542c7b1cc3e2ee0d231f769213267b986', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}, {'number': 9, 'created': '2016-02-19 16:07:56.000000000', 'files': ['openstack/cluster/v1/cluster.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_node.py', 'openstack/cluster/v1/node.py', 'openstack/tests/unit/cluster/v1/test_cluster.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0ea34d1e341db544f29cdc35861a4b8403f78e14', 'message': 'Override delete function of senlin cluster/node\n\nRecently senlin change its api, request to delete cluster/node\nwill receive a response with location pointed to an action.\n\nChange-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480\n'}]",11,273450,0ea34d1e341db544f29cdc35861a4b8403f78e14,42,6,9,7404,,,0,"Override delete function of senlin cluster/node

Recently senlin change its api, request to delete cluster/node
will receive a response with location pointed to an action.

Change-Id: I7ba991959e93a95cbb99354bc78093ba9a3bd480
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/50/273450/8 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cluster/v1/cluster.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_node.py', 'openstack/cluster/v1/node.py', 'openstack/tests/unit/cluster/v1/test_cluster.py']",5,3d452b0aee75982585ba837bc3cbbc3cf4709f6e,cluster_delete," def test_cluster_delete(self): sot = cluster.Cluster(FAKE) sot['id'] = 'IDENTIFIER' url = 'clusters/%s' % sot.id resp = mock.Mock(headers={'Location': 'actions/fake_action'}) sess = mock.Mock() sess.delete = mock.Mock(return_value=resp) self.assertEqual({'Location': 'actions/fake_action'}, sot.delete(sess)) sess.delete.assert_called_once_with(url, endpoint_filter=sot.service)",,58,4
openstack%2Fsolum~master~I0b6163d360943affb0f9c96162c3e2c8ace1753d,openstack/solum,master,I0b6163d360943affb0f9c96162c3e2c8ace1753d,Validate scale target and set max scale limit,MERGED,2016-02-16 20:40:05.000000000,2016-02-19 16:29:16.000000000,2016-02-19 16:29:16.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-02-16 20:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/926a41f510645b8714ebd0bc78639abcd661345a', 'message': 'Validate scale target and set max scale limit\n\nChange-Id: I0b6163d360943affb0f9c96162c3e2c8ace1753d\nCloses-Bug: #1546296\n'}, {'number': 2, 'created': '2016-02-16 20:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/9a079936906d05e8a3ecbba78ef00f7a930d05ac', 'message': 'Validate scale target and set max scale limit\n\nChange-Id: I0b6163d360943affb0f9c96162c3e2c8ace1753d\nCloses-Bug: #1546296\n'}, {'number': 3, 'created': '2016-02-18 19:23:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5375c7d9fef46d2a25f9c9838f64cd2f26a280fa', 'message': 'Validate scale target and set max scale limit\n\nChange-Id: I0b6163d360943affb0f9c96162c3e2c8ace1753d\nCloses-Bug: #1546296\n'}, {'number': 4, 'created': '2016-02-19 15:16:01.000000000', 'files': ['solum/api/handlers/workflow_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/6af5181d50e4a679669a802a35da6526a5096447', 'message': 'Validate scale target and set max scale limit\n\nChange-Id: I0b6163d360943affb0f9c96162c3e2c8ace1753d\nCloses-Bug: #1546296\n'}]",0,280921,6af5181d50e4a679669a802a35da6526a5096447,23,4,4,7230,,,0,"Validate scale target and set max scale limit

Change-Id: I0b6163d360943affb0f9c96162c3e2c8ace1753d
Closes-Bug: #1546296
",git fetch https://review.opendev.org/openstack/solum refs/changes/21/280921/4 && git format-patch -1 --stdout FETCH_HEAD,['solum/api/handlers/workflow_handler.py'],1,926a41f510645b8714ebd0bc78639abcd661345a,bug/1546296,"from solum.common import exception cfg.IntOpt('max_instances_per_app', default=100, help='Application scale limit'), try: target = int(target) except ValueError: msg = ""Must provide integer value for scale target."" raise exception.BadRequest(reason=msg) if target <= 0: msg = ""Scale target must be greater than zero."" raise exception.BadRequest(reason=msg) if target > cfg.CONF.api.max_instances_per_app: msg = ""Target scale '%s' exceeds maximum scale limit %s."" % ( target, cfg.CONF.api.max_instances_per_app) raise exception.ResourceLimitExceeded(reason=msg) ",,19,0
openstack%2Finstack-undercloud~master~I08bdf5ee8bcbb8c8f0b0ab0afe64aaa1aac3ded9,openstack/instack-undercloud,master,I08bdf5ee8bcbb8c8f0b0ab0afe64aaa1aac3ded9,Remove some unused bits,MERGED,2016-02-11 21:20:05.000000000,2016-02-19 16:27:23.000000000,2016-02-19 16:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-02-11 21:20:05.000000000', 'files': ['instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/2e7cc877532498bcbc9ad82dfe427b3c216e5743', 'message': ""Remove some unused bits\n\nThese comments and variables are left over from the poc version of\ninstack-undercloud and aren't necessary anymore.\n\nChange-Id: I08bdf5ee8bcbb8c8f0b0ab0afe64aaa1aac3ded9\n""}]",0,279269,2e7cc877532498bcbc9ad82dfe427b3c216e5743,8,3,1,6928,,,0,"Remove some unused bits

These comments and variables are left over from the poc version of
instack-undercloud and aren't necessary anymore.

Change-Id: I08bdf5ee8bcbb8c8f0b0ab0afe64aaa1aac3ded9
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/69/279269/1 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,2e7cc877532498bcbc9ad82dfe427b3c216e5743,cull-old-stuff,," # NOTE(bnemec): I removed the conditional running of os-refresh-config. # To my knowledge it wasn't really being used anymore, and if we do still # need it, it should be reimplemented as a client parameter instead of # an input env var. # TODO(bnemec): Do we still need INSTACK_ROOT? instack_env['INSTACK_ROOT'] = os.environ.get('INSTACK_ROOT') or ''",0,6
openstack%2Fsenlin~master~I7124c689c29af07cc5d99eeaa4f782e099a29747,openstack/senlin,master,I7124c689c29af07cc5d99eeaa4f782e099a29747,Validate 'sort' parameter for listing cluster-policy,MERGED,2016-02-19 08:47:00.000000000,2016-02-19 16:26:18.000000000,2016-02-19 16:26:18.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 08:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f9c0a6b471b0ff60b74714dcb7797eff4884f3bf', 'message': ""Validate 'sort' parameter for listing cluster-policy\n\nThis adds validation to the 'sort' parameter when listing cluster-policy\nbindings.\n\nChange-Id: I7124c689c29af07cc5d99eeaa4f782e099a29747\n""}, {'number': 2, 'created': '2016-02-19 14:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/3c88e94c9264ab016dec9fb47f683bb5159c0b72', 'message': ""Validate 'sort' parameter for listing cluster-policy\n\nThis adds validation to the 'sort' parameter when listing cluster-policy\nbindings.\n\nChange-Id: I7124c689c29af07cc5d99eeaa4f782e099a29747\n""}, {'number': 3, 'created': '2016-02-19 15:28:49.000000000', 'files': ['senlin/tests/unit/engine/service/test_cluster_policies.py', 'senlin/engine/service.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9ef8acba655d3c1d58cf3746fe379145454b94f8', 'message': ""Validate 'sort' parameter for listing cluster-policy\n\nThis adds validation to the 'sort' parameter when listing cluster-policy\nbindings.\n\nChange-Id: I7124c689c29af07cc5d99eeaa4f782e099a29747\n""}]",0,282234,9ef8acba655d3c1d58cf3746fe379145454b94f8,16,2,3,8246,,,0,"Validate 'sort' parameter for listing cluster-policy

This adds validation to the 'sort' parameter when listing cluster-policy
bindings.

Change-Id: I7124c689c29af07cc5d99eeaa4f782e099a29747
",git fetch https://review.opendev.org/openstack/senlin refs/changes/34/282234/3 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_cluster_policies.py']",2,f9c0a6b471b0ff60b74714dcb7797eff4884f3bf,cluster-policy-sort," filters='FOO', sort='enabled') filters='FOO', sort='enabled') def test_cluster_policy_list_bad_sort(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.cluster_policy_list, self.ctx, 'CLUSTER', sort='crazy') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) self.assertEqual(""Invalid value 'crazy' specified for 'sort key'"", six.text_type(ex.exc_info[1]))"," filters='FOO', sort='BAR') filters='FOO', sort='BAR')",13,2
openstack%2Ffuel-qa~master~Idba34e80b430c236015f7f17d597500c757ded38,openstack/fuel-qa,master,Idba34e80b430c236015f7f17d597500c757ded38,Add test for cluster deployment with Ironic and Murano,ABANDONED,2016-02-12 13:59:23.000000000,2016-02-19 16:24:47.000000000,,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 12867}, {'_account_id': 13636}, {'_account_id': 14525}, {'_account_id': 14614}, {'_account_id': 15784}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 17270}]","[{'number': 1, 'created': '2016-02-12 13:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/cf722e193a992c64f4cf9b760c4f05116d1f436f', 'message': 'Add test for cluster deployment with Ironic and Murano\n\nDeploy cluster with Ironic and Murano.\nVerify that Ironic works properly.\n\nChange-Id: Idba34e80b430c236015f7f17d597500c757ded38\nPartial-Bug: #1541847\n'}, {'number': 2, 'created': '2016-02-15 13:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/95db6f32f68887e3c558d4b79aa3211db680743a', 'message': 'Add test for cluster deployment with Ironic and Murano\n\nDeploy cluster with Ironic and Murano.\nVerify that Ironic works properly.\n\nChange-Id: Idba34e80b430c236015f7f17d597500c757ded38\nPartial-Bug: #1541847\n'}, {'number': 3, 'created': '2016-02-16 13:47:38.000000000', 'files': ['fuelweb_test/tests/test_ironic_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6f8346980d7df0c7c082e6671bce24e309909078', 'message': 'Add test for cluster deployment with Ironic and Murano\n\nDeploy cluster with Ironic and Murano.\nMurano should be installed as a plugin.\nVerify that Ironic works properly.\n\nChange-Id: Idba34e80b430c236015f7f17d597500c757ded38\nPartial-Bug: #1541847\n'}]",0,279547,6f8346980d7df0c7c082e6671bce24e309909078,26,12,3,14614,,,0,"Add test for cluster deployment with Ironic and Murano

Deploy cluster with Ironic and Murano.
Murano should be installed as a plugin.
Verify that Ironic works properly.

Change-Id: Idba34e80b430c236015f7f17d597500c757ded38
Partial-Bug: #1541847
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/47/279547/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ironic_base.py'],1,cf722e193a992c64f4cf9b760c4f05116d1f436f,bug/1541847," @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""ironic_deploy_murano""]) @log_snapshot_after_test def ironic_deploy_sahara(self): """"""Deploy Ironic with Murano Scenario: 1. Create cluster. Set option for Murano installation 2. Add 1 node with Controller role 3. Add 1 node with Compute role 4. Add 1 node with Ironic conductor role 5. Deploy the cluster 6. Upload image to Glance 7. Enroll Ironic nodes 8. Boot Nova instance 9. Check Nova instance status Duration 90m Snapshot ironic_deploy_murano """""" self.env.revert_snapshot(""ready_with_3_slaves"") data = { 'net_provider': 'neutron', 'net_segment_type': NEUTRON_SEGMENT['vlan'], 'ironic': True, 'murano': True, 'tenant': 'muranooscomponent', 'user': 'muranooscomponent', 'password': 'muranooscomponent'} nodes = { 'slave-01': ['controller'], 'slave-02': ['compute'], 'slave-03': ['ironic']} self.show_step(1, initialize=True) self.show_step(2) self.show_step(3) self.show_step(4) self.show_step(5) cluster_id = self._deploy_ironic_cluster(settings=data, nodes=nodes) ironic_conn = ironic_actions.IronicActions( self.fuel_web.get_public_vip(cluster_id)) self.show_step(6) self._create_os_resources(ironic_conn) self.show_step(7) self._boot_nova_instances(ironic_conn) self.show_step(8) ironic_conn.wait_for_vms(ironic_conn) self.show_step(9) ironic_conn.verify_vms_connection(ironic_conn) self.env.make_snapshot(""ironic_deploy_murano"")",,58,0
openstack%2Fkolla~master~I636e6954855a8f94d5ea15216d892c1bff53b7a8,openstack/kolla,master,I636e6954855a8f94d5ea15216d892c1bff53b7a8,Aodh ubuntu binary container,MERGED,2016-02-16 06:32:35.000000000,2016-02-19 16:21:15.000000000,2016-02-19 16:21:15.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-16 06:32:35.000000000', 'files': ['docker/aodh/aodh-evaluator/Dockerfile.j2', 'docker/aodh/aodh-base/Dockerfile.j2', 'docker/aodh/aodh-listener/Dockerfile.j2', 'docker/aodh/aodh-expirer/Dockerfile.j2', 'docker/aodh/aodh-api/Dockerfile.j2', 'docker/aodh/aodh-notifier/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/fd6bfd329e95b736c536d95ae095be12bd791fb0', 'message': 'Aodh ubuntu binary container\n\nChange-Id: I636e6954855a8f94d5ea15216d892c1bff53b7a8\nPartially-Implements: blueprint binary-ubuntu\n'}]",0,280515,fd6bfd329e95b736c536d95ae095be12bd791fb0,20,5,1,18009,,,0,"Aodh ubuntu binary container

Change-Id: I636e6954855a8f94d5ea15216d892c1bff53b7a8
Partially-Implements: blueprint binary-ubuntu
",git fetch https://review.opendev.org/openstack/kolla refs/changes/15/280515/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/aodh/aodh-base/Dockerfile.j2', 'docker/aodh/aodh-evaluator/Dockerfile.j2', 'docker/aodh/aodh-listener/Dockerfile.j2', 'docker/aodh/aodh-expirer/Dockerfile.j2', 'docker/aodh/aodh-api/Dockerfile.j2', 'docker/aodh/aodh-notifier/Dockerfile.j2']",6,fd6bfd329e95b736c536d95ae095be12bd791fb0,bp/binary-ubuntu, {% elif base_distro in ['ubuntu'] %} RUN apt-get install -y --no-install-recommends \ aodh-notifier \ && apt-get clean ,,36,0
openstack%2Fsahara~master~Id78d4af41da23b093dafc434c6852e893593d605,openstack/sahara,master,Id78d4af41da23b093dafc434c6852e893593d605,Add regex matching for job_executions_list(),MERGED,2016-02-11 21:40:40.000000000,2016-02-19 16:20:24.000000000,2016-02-19 16:20:24.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 18399}]","[{'number': 1, 'created': '2016-02-11 21:40:40.000000000', 'files': ['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/conductor/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1312f67ab877fc94dfbbf3ee6829a983d0fdc46f', 'message': 'Add regex matching for job_executions_list()\n\nThis change implements regex matching for filters on string\nvalues passed to job_executions_list() in the REST api.\nNo existing internal calls that use job_execution_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: Id78d4af41da23b093dafc434c6852e893593d605\n'}]",0,279275,1312f67ab877fc94dfbbf3ee6829a983d0fdc46f,25,8,1,8091,,,0,"Add regex matching for job_executions_list()

This change implements regex matching for filters on string
values passed to job_executions_list() in the REST api.
No existing internal calls that use job_execution_get_all()
are affected.

Partial-bug: #1503345

Change-Id: Id78d4af41da23b093dafc434c6852e893593d605
",git fetch https://review.opendev.org/openstack/sahara refs/changes/75/279275/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py']",6,1312f67ab877fc94dfbbf3ee6829a983d0fdc46f,bug/1503345," def job_execution_get_all(self, context, regex_search=False, **kwargs): :param context: The context, and associated authentication, to use with this operation :param regex_search: If True, enable regex matching for filter values. See the user guide for more information on how regex matching is handled. If False, no regex matching is done. :param kwargs: Specifies values for named fields by which to constrain the search return self.db.job_execution_get_all(context, regex_search, **kwargs)"," def job_execution_get_all(self, context, **kwargs): e.g. job_execution_get_all(cluster_id=12, input_id=123) job_execution_get_all(**{'cluster.name': 'test', 'job.name': 'wordcount'}) return self.db.job_execution_get_all(context, **kwargs)",121,31
openstack%2Fos-win~master~Id8776ae81f0cfa194be73f614c46e4f007915812,openstack/os-win,master,Id8776ae81f0cfa194be73f614c46e4f007915812,bump version to 0.2.2,MERGED,2016-02-19 14:07:36.000000000,2016-02-19 16:19:27.000000000,2016-02-19 15:59:28.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}]","[{'number': 1, 'created': '2016-02-19 14:07:36.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-win/commit/13f6d4d22a0fdbdb44ddc7d949dde381901b2918', 'message': 'bump version to 0.2.2\n\nChange-Id: Id8776ae81f0cfa194be73f614c46e4f007915812\n'}]",0,282348,13f6d4d22a0fdbdb44ddc7d949dde381901b2918,7,3,1,9426,,,0,"bump version to 0.2.2

Change-Id: Id8776ae81f0cfa194be73f614c46e4f007915812
",git fetch https://review.opendev.org/openstack/os-win refs/changes/48/282348/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,13f6d4d22a0fdbdb44ddc7d949dde381901b2918,,version = 0.2.2,version = 0.2.1,1,1
openstack%2Fpython-openstackclient~master~Ibbd7d6d27b2ff20304e3121fbadd5d50c1836d9b,openstack/python-openstackclient,master,Ibbd7d6d27b2ff20304e3121fbadd5d50c1836d9b,"Use assertIsNone() instead of assertEqual(None, xxx)",MERGED,2016-02-19 09:15:25.000000000,2016-02-19 16:13:40.000000000,2016-02-19 16:13:40.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-02-19 09:15:25.000000000', 'files': ['openstackclient/tests/object/v1/test_container.py', 'openstackclient/tests/network/v2/test_security_group.py', 'openstackclient/tests/network/v2/test_security_group_rule.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ef64a8b47deb8c8c8a49dd3a3c11d675979c91e0', 'message': 'Use assertIsNone() instead of assertEqual(None, xxx)\n\nChange-Id: Ibbd7d6d27b2ff20304e3121fbadd5d50c1836d9b\n'}]",0,282242,ef64a8b47deb8c8c8a49dd3a3c11d675979c91e0,7,4,1,14937,,,0,"Use assertIsNone() instead of assertEqual(None, xxx)

Change-Id: Ibbd7d6d27b2ff20304e3121fbadd5d50c1836d9b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/42/282242/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/object/v1/test_container.py', 'openstackclient/tests/network/v2/test_security_group.py', 'openstackclient/tests/network/v2/test_security_group_rule.py']",3,ef64a8b47deb8c8c8a49dd3a3c11d675979c91e0,use-assert-is-none-20160219, self.assertIsNone(result) self.assertIsNone(result)," self.assertEqual(None, result) self.assertEqual(None, result)",7,7
openstack%2Ftripleo-common~master~I99c2cbc73091c9d3285cf10680969e00317d1d3d,openstack/tripleo-common,master,I99c2cbc73091c9d3285cf10680969e00317d1d3d,Use git.openstack.org where possible,MERGED,2016-01-21 17:21:19.000000000,2016-02-19 16:13:21.000000000,2016-02-19 16:13:21.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 9712}, {'_account_id': 10239}, {'_account_id': 16237}, {'_account_id': 18675}]","[{'number': 1, 'created': '2016-01-21 17:21:19.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fb544eea70c5ad9bea36dd951b3ba8621d7f63fe', 'message': ""Use git.openstack.org where possible\n\nGithub gives us trouble on a semi-regular basis, so let's use\ngit.openstack.org wherever possible.\n\nChange-Id: I99c2cbc73091c9d3285cf10680969e00317d1d3d\n""}]",0,270927,fb544eea70c5ad9bea36dd951b3ba8621d7f63fe,17,6,1,6928,,,0,"Use git.openstack.org where possible

Github gives us trouble on a semi-regular basis, so let's use
git.openstack.org wherever possible.

Change-Id: I99c2cbc73091c9d3285cf10680969e00317d1d3d
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/27/270927/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,fb544eea70c5ad9bea36dd951b3ba8621d7f63fe,git.openstack.org, git clone https://git.openstack.org/openstack/$PROJ.git $TRIPLEO_ROOT/$PROJ, git clone https://github.com/openstack/$PROJ.git $TRIPLEO_ROOT/$PROJ,1,1
openstack%2Fironic-inspector~master~I06a269c1694cdc91bf3a85a78037dfea094c5187,openstack/ironic-inspector,master,I06a269c1694cdc91bf3a85a78037dfea094c5187,Small ValidateInterfacesHook cleanup,MERGED,2016-02-17 10:29:24.000000000,2016-02-19 16:12:27.000000000,2016-02-19 16:12:27.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-02-17 10:29:24.000000000', 'files': ['ironic_inspector/plugins/standard.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ea93510cef83c7167930f1faad169bc089e8ca16', 'message': 'Small ValidateInterfacesHook cleanup\n\n- move all interface validation  checks to _validate_interfaces\n  method;\n- remove redundant args.\n\nChange-Id: I06a269c1694cdc91bf3a85a78037dfea094c5187\n'}]",0,281171,ea93510cef83c7167930f1faad169bc089e8ca16,11,3,1,13636,,,0,"Small ValidateInterfacesHook cleanup

- move all interface validation  checks to _validate_interfaces
  method;
- remove redundant args.

Change-Id: I06a269c1694cdc91bf3a85a78037dfea094c5187
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/71/281171/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_inspector/plugins/standard.py'],1,ea93510cef83c7167930f1faad169bc089e8ca16,cleanup-val-ifaces-hook," def _get_interfaces(self, data=None): inventory = data.get('inventory', {}) if inventory: for iface in inventory.get('interfaces', ()): name = iface.get('name') mac = iface.get('mac_address') ip = iface.get('ipv4_address') if not name: LOG.error(_LE('Malformed interface record: %s'), iface, data=data) continue LOG.debug('Found interface %(name)s with MAC ""%(mac)s"" and ' 'IP address ""%(ip)s""', {'name': name, 'mac': mac, 'ip': ip}, data=data) result[name] = {'ip': ip, 'mac': mac} else: LOG.warning(_LW('No inventory provided: using old bash ramdisk ' 'is deprecated, please switch to ' 'ironic-python-agent'), data=data) result = data.get('interfaces') def _validate_interfaces(self, interfaces, data=None): pxe_mac = utils.get_pxe_mac(data) if not pxe_mac and CONF.processing.add_ports == 'pxe': LOG.warning(_LW('No boot interface provided in the introspection ' 'data, will add all ports with IP addresses')) if not result: raise utils.Error(_('No suitable interfaces found in %s') % interfaces, data=data) all_interfaces = self._get_interfaces(introspection_data) interfaces = self._validate_interfaces(all_interfaces,"," def _get_interfaces(self, inventory, data=None): for iface in inventory.get('interfaces', ()): name = iface.get('name') mac = iface.get('mac_address') ip = iface.get('ipv4_address') if not name: LOG.error(_LE('Malformed interface record: %s'), iface, data=data) continue LOG.debug('Found interface %(name)s with MAC ""%(mac)s"" and ' 'IP address ""%(ip)s""', {'name': name, 'mac': mac, 'ip': ip}, data=data) result[name] = {'ip': ip, 'mac': mac} def _validate_interfaces(self, interfaces, pxe_mac, data=None): inventory = introspection_data.get('inventory', {}) if inventory: all_interfaces = self._get_interfaces(inventory, introspection_data) else: LOG.warning(_LW('No inventory provided: using old bash ramdisk ' 'is deprecated, please switch to ' 'ironic-python-agent'), data=introspection_data) all_interfaces = introspection_data.get('interfaces') pxe_mac = utils.get_pxe_mac(introspection_data) if not pxe_mac and CONF.processing.add_ports == 'pxe': LOG.warning(_LW('No boot interface provided in the introspection ' 'data, will add all ports with IP addresses')) interfaces = self._validate_interfaces(all_interfaces, pxe_mac, if not interfaces: raise utils.Error(_('No suitable interfaces found in %s') % all_interfaces, data=introspection_data)",31,33
openstack%2Ftripleo-docs~master~Ie3f7497de77d8e9deceb1c06a381654e539d655f,openstack/tripleo-docs,master,Ie3f7497de77d8e9deceb1c06a381654e539d655f,Fix formatting and typos,MERGED,2016-02-18 17:33:15.000000000,2016-02-19 16:12:16.000000000,2016-02-19 16:12:16.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-02-18 17:33:15.000000000', 'files': ['doc/source/advanced_deployment/network_isolation.rst', 'doc/source/post_deployment/replace_controller.rst', 'doc/source/post_deployment/quiesce_compute.rst', 'doc/source/environments/virtual.rst', 'doc/source/advanced_deployment/node_config.rst', 'doc/source/advanced_deployment/profile_matching.rst', 'doc/source/contributions/contributions.rst', 'doc/source/introduction/architecture.rst', 'doc/source/basic_deployment/basic_deployment_cli.rst', 'doc/source/advanced_deployment/extra_config.rst', 'doc/source/advanced_deployment/deploy_manila.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/96cd4737e9347f005d66bb2e077bdb8bc63078a4', 'message': 'Fix formatting and typos\n\nChange-Id: Ie3f7497de77d8e9deceb1c06a381654e539d655f\n'}]",0,281973,96cd4737e9347f005d66bb2e077bdb8bc63078a4,8,4,1,4330,,,0,"Fix formatting and typos

Change-Id: Ie3f7497de77d8e9deceb1c06a381654e539d655f
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/73/281973/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/advanced_deployment/network_isolation.rst', 'doc/source/post_deployment/replace_controller.rst', 'doc/source/post_deployment/quiesce_compute.rst', 'doc/source/environments/virtual.rst', 'doc/source/advanced_deployment/node_config.rst', 'doc/source/advanced_deployment/profile_matching.rst', 'doc/source/contributions/contributions.rst', 'doc/source/basic_deployment/basic_deployment_cli.rst', 'doc/source/introduction/architecture.rst', 'doc/source/advanced_deployment/extra_config.rst', 'doc/source/advanced_deployment/deploy_manila.rst']",11,96cd4737e9347f005d66bb2e077bdb8bc63078a4,fixes, - Create the overcloud networks. The :doc:`../basic_deployment/basic_deployment` doc has a more detailed explanation about creating the network and subnet. Note that you may also need to perform the following steps to get Manila working::, - Create the overcloud networks. The :doc:`../basic_deployment/basic_deployment` doc has a more detailed explanation about creating the network and subnet. Note that you may also need to perform the following steps to get Manila working::,40,39
openstack%2Finstack-undercloud~master~Id7c9482c26954fd2dc86bc0ef3325bdd12dd8f42,openstack/instack-undercloud,master,Id7c9482c26954fd2dc86bc0ef3325bdd12dd8f42,Add -w to iptables calls,MERGED,2016-02-15 20:57:53.000000000,2016-02-19 16:09:08.000000000,2016-02-19 16:09:08.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-02-15 20:57:53.000000000', 'files': ['elements/dnsmasq-forwarder/os-refresh-config/post-configure.d/10-dnsmasq-forwarder', 'elements/undercloud-stack-config/os-apply-config/var/opt/undercloud-stack/masquerade', 'elements/puppet-stack-config/os-refresh-config/post-configure.d/10-iptables'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/b26d750e6cf9f436cf3cd6cbe437c50a29877f51', 'message': ""Add -w to iptables calls\n\nIf another process happens to be making an iptables call, the calls\nin our post-configure scripts can be killed, with a message such as\n\nAnother app is currently holding the xtables lock. Perhaps you want\nto use the -w option?\n\nAdding -w will tell iptables to wait until the lock is available,\nso such a situation won't kill the undercloud install.\n\nChange-Id: Id7c9482c26954fd2dc86bc0ef3325bdd12dd8f42\n""}]",0,280401,b26d750e6cf9f436cf3cd6cbe437c50a29877f51,17,5,1,6928,,,0,"Add -w to iptables calls

If another process happens to be making an iptables call, the calls
in our post-configure scripts can be killed, with a message such as

Another app is currently holding the xtables lock. Perhaps you want
to use the -w option?

Adding -w will tell iptables to wait until the lock is available,
so such a situation won't kill the undercloud install.

Change-Id: Id7c9482c26954fd2dc86bc0ef3325bdd12dd8f42
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/01/280401/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/dnsmasq-forwarder/os-refresh-config/post-configure.d/10-dnsmasq-forwarder', 'elements/undercloud-stack-config/os-apply-config/var/opt/undercloud-stack/masquerade', 'elements/puppet-stack-config/os-refresh-config/post-configure.d/10-iptables']",3,b26d750e6cf9f436cf3cd6cbe437c50a29877f51,iptables-wait,iptables -w -t nat -C PREROUTING -d 169.254.169.254/32 -i $EXTERNAL_BRIDGE -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8775 || iptables -w -t nat -I PREROUTING -d 169.254.169.254/32 -i $EXTERNAL_BRIDGE -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8775,iptables -t nat -C PREROUTING -d 169.254.169.254/32 -i $EXTERNAL_BRIDGE -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8775 || iptables -t nat -I PREROUTING -d 169.254.169.254/32 -i $EXTERNAL_BRIDGE -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8775,16,16
openstack%2Fheat-specs~master~Ia3d2b4ed64b48450770efe5c162903c2b8c4eadf,openstack/heat-specs,master,Ia3d2b4ed64b48450770efe5c162903c2b8c4eadf,Fix a yaml syntax error of the repeat function.,MERGED,2016-02-16 02:24:34.000000000,2016-02-19 16:07:39.000000000,2016-02-19 16:07:39.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 10487}, {'_account_id': 12321}, {'_account_id': 12404}, {'_account_id': 13009}, {'_account_id': 19955}]","[{'number': 1, 'created': '2016-02-16 02:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/529fa5685ad81af30adf8a3d73164f58d5552bd1', 'message': ""Fix a grammatical mistake of the repeat function.\n\nYaml don't support a value define like %value%.\nFor this reason,the example of repeat online can't run successfully.\n\nChange-Id: Ia3d2b4ed64b48450770efe5c162903c2b8c4eadf\nCloses-Bug: #1545908\n""}, {'number': 2, 'created': '2016-02-17 08:36:38.000000000', 'files': ['specs/kilo/repeat-function.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/4f73dda42ee5a260d18b399a4e23d0dd6c21d488', 'message': ""Fix a yaml syntax error of the repeat function.\n\nYaml don't support a value define like %value%.\nFor this reason,the example of repeat online can't run successfully.\n\nChange-Id: Ia3d2b4ed64b48450770efe5c162903c2b8c4eadf\nCloses-Bug: #1545908\n""}]",1,280474,4f73dda42ee5a260d18b399a4e23d0dd6c21d488,24,15,2,19963,,,0,"Fix a yaml syntax error of the repeat function.

Yaml don't support a value define like %value%.
For this reason,the example of repeat online can't run successfully.

Change-Id: Ia3d2b4ed64b48450770efe5c162903c2b8c4eadf
Closes-Bug: #1545908
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/74/280474/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/repeat-function.rst'],1,529fa5685ad81af30adf8a3d73164f58d5552bd1,bug/1545908, <%port%>: { get_param: ports } port_range_min: <%port%> port_range_max: <%port%> <%net_name%>: { get_param: networks } template: network: <%net_name%> <%port%>: { get_param: ports } <%protocol%>: { get_param: protocols } template: protocol: <%protocol%> port_range_min: <%port%>, %port%: { get_param: ports } port_range_min: %port% port_range_max: %port% %net_name%: { get_param: networks } template: network: %net_name% %port%: { get_param: ports } %protocol%: { get_param: protocols } template: protocol: %protocol% port_range_min: %port%,9,9
openstack%2Fproject-config~master~I3b9f745c34de2b794f6ea49baa27ca2c5e4c70b3,openstack/project-config,master,I3b9f745c34de2b794f6ea49baa27ca2c5e4c70b3,Fix logic for networking-ovn jobs,ABANDONED,2016-02-19 15:18:04.000000000,2016-02-19 16:01:44.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-19 15:18:04.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/647b471a5a3d2cdcdd60abb4d7dc507045da630b', 'message': ""Fix logic for networking-ovn jobs\n\nA recent addition to the networking-ovn jobs broke the filter\nthat skips expensive jobs for patches that do not benefit from\nthem such as documentation. Instead of further expanding the\nsomewhat lengthy existing filter, create a new block for\nthe networking-ovn project that skips all 'dsvm' jobs for\nthese patches.\n\nChange-Id: I3b9f745c34de2b794f6ea49baa27ca2c5e4c70b3\n""}]",1,282378,647b471a5a3d2cdcdd60abb4d7dc507045da630b,4,3,1,9515,,,0,"Fix logic for networking-ovn jobs

A recent addition to the networking-ovn jobs broke the filter
that skips expensive jobs for patches that do not benefit from
them such as documentation. Instead of further expanding the
somewhat lengthy existing filter, create a new block for
the networking-ovn project that skips all 'dsvm' jobs for
these patches.

Change-Id: I3b9f745c34de2b794f6ea49baa27ca2c5e4c70b3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/78/282378/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,647b471a5a3d2cdcdd60abb4d7dc507045da630b,ovn-jobs2, - name: ^.*(devstack|tempest|grenade|rally|swift|neutron-lbaas|neutron-vpnaas|ironic-inspector|heat)-dsvm.*$ # Skip expensive jobs for patches that do not benefit from them such # as documentation. - name: ^gate-.*dsvm.*$ skip-if: - project: ^openstack/networking-ovn$ all-files-match-any: - ^.*\.rst$ - ^doc/.*$ - ^releasenotes/.*$ - ^tools/.*$ - ^tox.ini$ - ^vagrant/.*$ , - name: ^.*(devstack|tempest|grenade|rally|swift|networking-ovn|neutron-lbaas|neutron-vpnaas|ironic-inspector|heat)-dsvm.*$ - project: ^openstack/networking-ovn$ all-files-match-any: - ^.*\.rst$ - ^doc/.*$ - ^releasenotes/.*$ - ^tools/.*$ - ^tox.ini$ - ^vagrant/.*$,14,9
openstack%2Fpython-senlinclient~master~Ifb2c492cca6435b398f111cd2be5b6b88d97a115,openstack/python-senlinclient,master,Ifb2c492cca6435b398f111cd2be5b6b88d97a115,Add OpenstackClient plugin for cluster node list,MERGED,2016-02-19 12:12:32.000000000,2016-02-19 15:59:01.000000000,2016-02-19 15:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 12:12:32.000000000', 'files': ['senlinclient/osc/v1/node.py', 'senlinclient/tests/unit/osc/v1/test_node.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/ac205b9f0c2ff95e99f06a8cc34d9fefde624daa', 'message': 'Add OpenstackClient plugin for cluster node list\n\nThis change implements the ""openstack cluster node list"" command\n  Based on the existing senlin command: senlin node-list\n\nChange-Id: Ifb2c492cca6435b398f111cd2be5b6b88d97a115\nBlueprint: senlin-support-python-openstackclient\n'}]",0,282304,ac205b9f0c2ff95e99f06a8cc34d9fefde624daa,7,3,1,18389,,,0,"Add OpenstackClient plugin for cluster node list

This change implements the ""openstack cluster node list"" command
  Based on the existing senlin command: senlin node-list

Change-Id: Ifb2c492cca6435b398f111cd2be5b6b88d97a115
Blueprint: senlin-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/04/282304/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/osc/v1/node.py', 'senlinclient/tests/unit/osc/v1/test_node.py', 'setup.cfg']",3,ac205b9f0c2ff95e99f06a8cc34d9fefde624daa,bp/senlin-support-python-openstackclient, cluster_node_list = senlinclient.osc.v1.node:ListNode,,254,0
openstack%2Fpython-openstackclient~master~I7935be2488fb728ced9680d75880870e5d315655,openstack/python-openstackclient,master,I7935be2488fb728ced9680d75880870e5d315655,"Subnet Pool: Add ""subnet pool list"" command",MERGED,2016-02-14 04:50:55.000000000,2016-02-19 15:55:29.000000000,2016-02-19 15:55:29.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-14 04:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/93a6937c9ed23b5596b5ca07e3bc32c25ca482bd', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nPartially implements: blueprint neutron-client\nPartial-Bug: 1544589\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\n'}, {'number': 2, 'created': '2016-02-14 05:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/194e50532abb138784fe36fc6176ab80b3472859', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nPartially implements: blueprint neutron-client\nCloses-Bug: 1544589\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\n'}, {'number': 3, 'created': '2016-02-14 09:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/618917b59b10c52ee419aa5bce5afe054f2e92e6', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nPartially implements: blueprint neutron-client\nCloses-Bug: 1544589\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\n'}, {'number': 4, 'created': '2016-02-16 08:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/44171450664da5664da8f3f71ebe89a5b122135b', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\nCloses-Bug: 1544589\nPartially implements: blueprint neutron-client\n'}, {'number': 5, 'created': '2016-02-17 06:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2977383b6a51f517c22f267504e24f48ee3866ed', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\nCloses-Bug: 1544589\nPartially implements: blueprint neutron-client\n'}, {'number': 6, 'created': '2016-02-18 00:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ba70a45f10feaea8bcb61eac505b9dd73a04210b', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\nCloses-Bug: 1544589\nPartially implements: blueprint neutron-client\n'}, {'number': 7, 'created': '2016-02-19 03:06:19.000000000', 'files': ['openstackclient/tests/network/v2/fakes.py', 'openstackclient/network/v2/subnet_pool.py', 'doc/source/command-objects/subnet_pool.rst', 'releasenotes/notes/bug-1544589-b9f669ef71aa5e57.yaml', 'setup.cfg', 'openstackclient/tests/network/v2/test_subnet_pool.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a04012c3d50c3623c699f57d0dd320783b92e1cb', 'message': 'Subnet Pool: Add ""subnet pool list"" command\n\nChange-Id: I7935be2488fb728ced9680d75880870e5d315655\nCloses-Bug: 1544589\nImplements: blueprint neutron-client\n'}]",9,279918,a04012c3d50c3623c699f57d0dd320783b92e1cb,32,6,7,14937,,,0,"Subnet Pool: Add ""subnet pool list"" command

Change-Id: I7935be2488fb728ced9680d75880870e5d315655
Closes-Bug: 1544589
Implements: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/18/279918/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/fakes.py', 'openstackclient/network/v2/subnet_pool.py', 'doc/source/command-objects/subnet_pool.rst', 'releasenotes/notes/bug-1544589-b9f669ef71aa5e57.yaml', 'setup.cfg', 'openstackclient/tests/network/v2/test_subnet_pool.py']",6,93a6937c9ed23b5596b5ca07e3bc32c25ca482bd,bug/1544590," class TestListSubnetPool(TestSubnetPool): # The subnet pools going to be listed up. _subnet_pools = network_fakes.FakeSubnetPool.create_subnet_pools(count=3) columns = ( 'ID', 'Name', 'Prefixes', ) columns_long = columns + ( 'Project', 'Default', 'Shared', ) data = [] for pool in _subnet_pools: data.append(( pool.id, pool.name, pool.prefixes, )) data_long = [] for pool in _subnet_pools: data_long.append(( pool.id, pool.name, pool.prefixes, pool.tenant_id, pool.is_default, pool.shared, )) def setUp(self): super(TestListSubnetPool, self).setUp() # Get the command object to test self.cmd = subnet_pool.ListSubnetPool(self.app, self.namespace) self.network.subnet_pools = mock.Mock(return_value=self._subnet_pools) def test_subnet_pool_list_no_option(self): arglist = [] verifylist = [ ('long', False), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) columns, data = self.cmd.take_action(parsed_args) self.network.subnet_pools.assert_called_with() self.assertEqual(self.columns, columns) self.assertEqual(self.data, list(data)) def test_subnet_pool_list_long(self): arglist = [ '--long', ] verifylist = [ ('long', True), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) columns, data = self.cmd.take_action(parsed_args) self.network.subnet_pools.assert_called_with() self.assertEqual(self.columns_long, columns) self.assertEqual(self.data_long, list(data))",,150,1
openstack%2Ffuel-astute~master~I4e3f1de45899c99ffb3d7c950385bd873b7ffede,openstack/fuel-astute,master,I4e3f1de45899c99ffb3d7c950385bd873b7ffede,Update rspec and fix tests,MERGED,2016-02-18 13:22:08.000000000,2016-02-19 15:53:08.000000000,2016-02-19 15:52:28.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 9448}]","[{'number': 1, 'created': '2016-02-18 13:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/5ad80afb28d6e51275fd51b77dacec7db75d477a', 'message': 'Update rspec and fix tests\n\nChange-Id: I4e3f1de45899c99ffb3d7c950385bd873b7ffede\n'}, {'number': 2, 'created': '2016-02-19 15:31:32.000000000', 'files': ['spec/unit/pre_deployment_actions/generate_keys_hook_spec.rb', 'spec/unit/nailgun_hooks_spec.rb', 'spec/unit/pre_deployment_actions/sync_puppet_stuff_hook_spec.rb', 'spec/unit/pre_deployment_actions/generate_ssh_keys_hook_spec.rb', 'astute.gemspec', 'spec/unit/post_deployment_actions/upload_cirros_image_hook_spec.rb', 'spec/unit/deployment_engine_spec.rb', 'spec/unit/task_deployment_spec.rb', 'spec/unit/cobbler_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/baf1d3bb7e1f059afa6a15afe67703246c6d9bee', 'message': 'Update rspec and fix tests\n\nChange-Id: I4e3f1de45899c99ffb3d7c950385bd873b7ffede\n'}]",0,281844,baf1d3bb7e1f059afa6a15afe67703246c6d9bee,27,8,2,9037,,,0,"Update rspec and fix tests

Change-Id: I4e3f1de45899c99ffb3d7c950385bd873b7ffede
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/44/281844/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/pre_deployment_actions/generate_keys_hook_spec.rb', 'spec/unit/nailgun_hooks_spec.rb', 'spec/unit/pre_deployment_actions/sync_puppet_stuff_hook_spec.rb', 'astute.gemspec', 'spec/unit/post_deployment_actions/upload_cirros_image_hook_spec.rb', 'spec/unit/pre_deployment_actions/generate_ssh_keys_hook_spec.rb', 'spec/unit/deployment_engine_spec.rb', 'spec/unit/task_deployment_spec.rb', 'spec/unit/cobbler_spec.rb']",9,5ad80afb28d6e51275fd51b77dacec7db75d477a,Update rspec and fix tests, expect { cobbler.sync }.not_to raise_exception(Net::ReadTimeout) expect { cobbler.sync }.not_to raise_exception(XMLRPC::FaultException), expect { cobbler.sync }.to_not raise_exception(Net::ReadTimeout) expect { cobbler.sync }.to_not raise_exception(XMLRPC::FaultException),37,30
openstack%2Ffuel-web~master~I0807c816c9d3af22a0d7e31f9ce96e974749c525,openstack/fuel-web,master,I0807c816c9d3af22a0d7e31f9ce96e974749c525,Fixed missed plugin attributes in deployment info,MERGED,2016-02-17 17:51:14.000000000,2016-02-19 15:52:58.000000000,2016-02-19 15:23:05.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7745}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8789}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 13505}, {'_account_id': 14543}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-17 17:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6534094d65b60821d2a5ce6f6a14425fa359b4d3', 'message': 'Fixed missed plugin attributes in deployment info\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: 1544505\n'}, {'number': 2, 'created': '2016-02-17 21:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f9fd8babdc20414c385b1871fba398c190e9a56c', 'message': 'Fixed missed plugin attributes in deployment info\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: 1544505\n'}, {'number': 3, 'created': '2016-02-18 09:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd5415ab15b6f248452381d6bb64955fbe0c7bfe', 'message': 'Fixed missed plugin attributes in deployment info\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: 1544505\n'}, {'number': 4, 'created': '2016-02-18 10:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b59bea2c1a5bb7fa2b0ff34fae0a72b0bcf40219', 'message': 'Fixed missed plugin attributes in deployment info\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: 1544505\n'}, {'number': 5, 'created': '2016-02-18 11:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0b7056f7b4de08dbcada43fda5c2c6c95bf7533c', 'message': 'Fixed missed plugin attributes in deployment info\n\nIn the old implementation side effect of changing\nAttributes instance data was used. Now we are\nadding plugins data directly in the deployment\nserializer.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: 1544505\n'}, {'number': 6, 'created': '2016-02-18 12:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1a9cd98f149e3aec8ba4f1a602be21a89bc27a95', 'message': 'Fixed missed plugin attributes in deployment info\n\nIn the old implementation side effect of changing\nAttributes instance data was used. Now we are\nadding plugins data directly in the deployment\nserializer.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: 1544505\n'}, {'number': 7, 'created': '2016-02-18 14:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d0189c5a7a73bfcc332ff930cf4b837c7b2257a6', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}, {'number': 8, 'created': '2016-02-18 15:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5b2e8a17c2af2abb3353f8f0888445fff2a7d202', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}, {'number': 9, 'created': '2016-02-18 15:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/81f3dbdcea8cc529080bcbc554a2f0405b258f0c', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}, {'number': 10, 'created': '2016-02-18 17:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5e2f3bd6c33e7e609a4bd4457fea331f9277c5e4', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}, {'number': 11, 'created': '2016-02-19 10:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/748735eabd579fd369fd301e221d87a2a8d9e682', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}, {'number': 12, 'created': '2016-02-19 12:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6a81dd92ad84cfd89f7b1d8d395f85446f915a3e', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}, {'number': 13, 'created': '2016-02-19 14:10:34.000000000', 'files': ['nailgun/nailgun/test/integration/test_orchestrator_serializer_80.py', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_90.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/13e7962001bc036b0f3255a61d9704546aab909e', 'message': ""Fixed missed plugin attributes in deployment info\n\nAfter Mutable DB fields were introduced the changing of nested data in such\nfields leads to saving changes into DB.\nNow we can't use Mutable fields for transfer temporary changed data inside\nthe business logic and all places with implicit using of JSON field for\ntransferring temporary changed data were removed.\nThis is the reason of loosing plugins data from the serialized\ndeployment_info. For fix we are adding cluster plugins attributes into\ndeployment_info explicitly.\n\nChange-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525\nCloses-Bug: #1544505\n""}]",5,281447,13e7962001bc036b0f3255a61d9704546aab909e,174,15,13,18205,,,0,"Fixed missed plugin attributes in deployment info

After Mutable DB fields were introduced the changing of nested data in such
fields leads to saving changes into DB.
Now we can't use Mutable fields for transfer temporary changed data inside
the business logic and all places with implicit using of JSON field for
transferring temporary changed data were removed.
This is the reason of loosing plugins data from the serialized
deployment_info. For fix we are adding cluster plugins attributes into
deployment_info explicitly.

Change-Id: I0807c816c9d3af22a0d7e31f9ce96e974749c525
Closes-Bug: #1544505
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/47/281447/12 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_task_deploy.py', 'nailgun/nailgun/objects/cluster.py']",2,6534094d65b60821d2a5ce6f6a14425fa359b4d3,bug/1544505, Cluster.get_editable_attributes(instance), instance.editable,4,1
openstack%2Fpython-ironicclient~master~Id5907812935096c5c557c896daf72175ed138866,openstack/python-ironicclient,master,Id5907812935096c5c557c896daf72175ed138866,Add 'node-set-provision-state <node> clean',MERGED,2015-12-16 22:36:06.000000000,2016-02-19 15:51:18.000000000,2016-02-19 15:51:18.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 11655}, {'_account_id': 13362}, {'_account_id': 14810}, {'_account_id': 16635}]","[{'number': 1, 'created': '2015-12-16 22:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/b7f4000f1d9c282b638fa7c685b9fa307fb7ecaf', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 2, 'created': '2015-12-17 14:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/6609dd5441b2930435127d35b0d04917fd6e62ab', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 3, 'created': '2015-12-17 23:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/3c4193edb55db5b3a2900a6d17a204d59ff5d52b', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 4, 'created': '2016-02-09 22:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/2bc23be5f089e13fb8c74106532848f399a62699', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 5, 'created': '2016-02-10 14:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9a88b4f051d50f1ce53c76f8d1ba53aa257c2fc9', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 6, 'created': '2016-02-17 19:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a6a3f0253d5d07b75813dcbba30d2cca37b7e52b', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 7, 'created': '2016-02-18 01:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a94a4a834e76722d11cd3cf00a5ae1bd91e80dd5', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 8, 'created': '2016-02-18 03:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a91b80bf999e24235b14ca3f339ef6b84361af10', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}, {'number': 9, 'created': '2016-02-18 16:14:31.000000000', 'files': ['ironicclient/v1/node.py', 'ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/tests/unit/v1/test_node.py', 'releasenotes/notes/manual-clean-09f6b49df7d2513f.yaml'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e6f6d9eacca0b1120b7a7e2030848b33261a351c', 'message': ""Add 'node-set-provision-state <node> clean'\n\nThis adds the manual cleaning CLI:\n\nusage: ironic node-set-provision-state [--config-drive <config-drive>]\n                                       [--clean-steps <clean-steps>]\n                                       <node> <provision-state>\n\nwhere <provision-state> is 'clean' and <clean-steps> is\nthe clean steps in JSON format. May be the path to a file containing\nthe clean steps; OR '-', with the clean steps being read from\nstandard input; OR a string. The value should be a list of clean-step\ndictionaries; each dictionary should have keys 'interface' and\n'step', and optional key 'args'. This argument must be specified\n(and is only valid) when setting provision-state to 'clean'.\n\nChange-Id: Id5907812935096c5c557c896daf72175ed138866\nPartial-Bug: #1526290\nDepends-On: I0e34407133684e34c4ab9446b3521a24f3038f92\n""}]",39,258694,e6f6d9eacca0b1120b7a7e2030848b33261a351c,56,11,9,6618,,,0,"Add 'node-set-provision-state <node> clean'

This adds the manual cleaning CLI:

usage: ironic node-set-provision-state [--config-drive <config-drive>]
                                       [--clean-steps <clean-steps>]
                                       <node> <provision-state>

where <provision-state> is 'clean' and <clean-steps> is
the clean steps in JSON format. May be the path to a file containing
the clean steps; OR '-', with the clean steps being read from
standard input; OR a string. The value should be a list of clean-step
dictionaries; each dictionary should have keys 'interface' and
'step', and optional key 'args'. This argument must be specified
(and is only valid) when setting provision-state to 'clean'.

Change-Id: Id5907812935096c5c557c896daf72175ed138866
Partial-Bug: #1526290
Depends-On: I0e34407133684e34c4ab9446b3521a24f3038f92
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/94/258694/9 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node.py', 'ironicclient/v1/node_shell.py', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/tests/unit/v1/test_node.py']",4,b7f4000f1d9c282b638fa7c685b9fa307fb7ecaf,bug/1526290,"import json import sysimport six.moves.builtins as __builtin__ def test_node_set_provision_state_with_cleansteps(self): cleansteps = '[{""step"": ""upgrade"", ""interface"": ""deploy""}]' target_state = 'clean' self.mgr.set_provision_state(NODE1['uuid'], target_state, cleansteps=cleansteps) body = {'target': target_state, 'clean_steps': json.loads(cleansteps)} expect = [ ('PUT', '/v1/nodes/%s/states/provision' % NODE1['uuid'], {}, body), ] self.assertEqual(expect, self.api.calls) def test_node_set_provision_state_with_cleansteps_badjson(self): cleansteps = 'foo' target_state = 'clean' self.assertRaisesRegex(exc.InvalidAttribute, 'For clean steps', self.mgr.set_provision_state, NODE1['uuid'], target_state, cleansteps=cleansteps) def test_node_set_provision_state_with_cleansteps_file(self): target_state = 'clean' contents = '[{""step"": ""upgrade"", ""interface"": ""deploy""}]' with tempfile.NamedTemporaryFile() as f: f.write(contents) f.flush() self.mgr.set_provision_state(NODE1['uuid'], target_state, cleansteps=f.name) body = {'target': target_state, 'clean_steps': json.loads(contents)} expect = [ ('PUT', '/v1/nodes/%s/states/provision' % NODE1['uuid'], {}, body), ] self.assertEqual(expect, self.api.calls) @mock.patch.object(__builtin__, 'open', autospec=True) def test_node_set_provision_state_with_cleansteps_file_fail(self, mock_open): mock_file_object = mock.MagicMock(spec=file) mock_file_handle = mock.MagicMock(spec=file) mock_file_handle.__enter__.return_value = mock_file_object mock_open.return_value = mock_file_handle mock_file_object.read.side_effect = IOError target_state = 'clean' with tempfile.NamedTemporaryFile() as f: self.assertRaisesRegex(exc.InvalidAttribute, ""from file"", self.mgr.set_provision_state, NODE1['uuid'], target_state, cleansteps=f.name) mock_open.assert_called_once_with(f.name, 'r') mock_file_object.read.assert_called_once_with() @mock.patch.object(sys, 'stdin', autospec=True) def test_node_set_provision_state_with_cleansteps_stdin(self, mock_stdin): target_state = 'clean' contents = '[{""step"": ""upgrade"", ""interface"": ""deploy""}]' mock_stdin.read.return_value = contents self.mgr.set_provision_state(NODE1['uuid'], target_state, cleansteps='-') body = {'target': target_state, 'clean_steps': json.loads(contents)} expect = [ ('PUT', '/v1/nodes/%s/states/provision' % NODE1['uuid'], {}, body), ] self.assertEqual(expect, self.api.calls) mock_stdin.read.assert_called_once_with() @mock.patch.object(sys, 'stdin', autospec=True) def test_node_set_provision_state_with_cleansteps_stdin_fail(self, mock_stdin): target_state = 'clean' mock_stdin.read.side_effect = IOError self.assertRaisesRegex(exc.InvalidAttribute, ""Cannot.*standard input"", self.mgr.set_provision_state, NODE1['uuid'], target_state, cleansteps='-') mock_stdin.read.assert_called_once_with() ",,196,13
openstack%2Fpython-openstackclient~master~I1295e922df695414511d9a07ca4a8e2428040064,openstack/python-openstackclient,master,I1295e922df695414511d9a07ca4a8e2428040064,"Floating IP: Fix ""ip floating list"" in neutron network",MERGED,2016-02-16 07:55:30.000000000,2016-02-19 15:49:47.000000000,2016-02-19 15:49:47.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-16 07:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/70c64b95a42c3fd5ccf84d16729770dd11012eb4', 'message': 'Floating IP: Fix ""ip floating list"" in neutron network\n\nThe current implementation of ""ip floating list"" is incorrect\nbecause the FloatingIP objects returned from Nova and Neutron\nnetwork are different. They need different handling.\n\nThis patch fixes this problem.\n\nThe output for Neutron network would be:\n\n+--------------------------------------+-------------+----------+--------+--------------------------------------+\n| ID                                   | Floating IP | Fixed IP | Status | Network                              |\n+--------------------------------------+-------------+----------+--------+--------------------------------------+\n| 1976df86-e66a-4f96-81bd-c6ffee6407f1 | 172.24.4.3  | None     | DOWN   | 8ff8617d-dc0c-4859-acb3-c0ebff1bb5ff |\n+--------------------------------------+-------------+----------+--------+--------------------------------------+\n\nThe output for Neutron network would be:\n\n+----+--------+------------+----------+-------------+\n| ID | Pool   | IP         | Fixed IP | Instance ID |\n+----+--------+------------+----------+-------------+\n|  1 | public | 172.24.4.1 | None     | None        |\n+----+--------+------------+----------+-------------+\n\nChange-Id: I1295e922df695414511d9a07ca4a8e2428040064\nPartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 2, 'created': '2016-02-16 08:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/165e8898d3b92c7300ff2260f91007eeafb06d2f', 'message': 'Floating IP: Fix ""ip floating list"" in neutron network\n\nThe implementation of ""ip floating list"" in the commit below\nis incorrect:\n\n    Change-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\n\nThis is because the FloatingIP objects returned from Nova and\nNeutron network are different. They need different handling.\n\nThis patch fixes this problem.\n\nThe output for Neutron network would be:\n\n+--------------------------------------+-------------+----------+--------+--------------------------------------+\n| ID                                   | Floating IP | Fixed IP | Status | Network                              |\n+--------------------------------------+-------------+----------+--------+--------------------------------------+\n| 1976df86-e66a-4f96-81bd-c6ffee6407f1 | 172.24.4.3  | None     | DOWN   | 8ff8617d-dc0c-4859-acb3-c0ebff1bb5ff |\n+--------------------------------------+-------------+----------+--------+--------------------------------------+\n\nThe output for Neutron network would be:\n\n+----+--------+------------+----------+-------------+\n| ID | Pool   | IP         | Fixed IP | Instance ID |\n+----+--------+------------+----------+-------------+\n|  1 | public | 172.24.4.1 | None     | None        |\n+----+--------+------------+----------+-------------+\n\nChange-Id: I1295e922df695414511d9a07ca4a8e2428040064\nPartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 3, 'created': '2016-02-17 03:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c490ce75bc2a6d53903b8472766e7791dc67bf72', 'message': 'Floating IP: Fix ""ip floating list"" in neutron network\n\nThe implementation of ""ip floating list"" in the commit below\nis incorrect:\n\n    Change-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\n\nThis is because the FloatingIP objects returned from Nova and\nNeutron network are different. They need different handling.\n\nThis patch fixes this problem.\n\nThe output for Neutron network would be:\n\n+--------------------------------------+---------------------+------------------+--------+--------------------------------------+\n| ID                                   | Floating IP Address | Fixed IP Address | Status | Network                              |\n+--------------------------------------+---------------------+------------------+--------+--------------------------------------+\n| 1976df86-e66a-4f96-81bd-c6ffee6407f1 | 172.24.4.3          | None             | DOWN   | 8ff8617d-dc0c-4859-acb3-c0ebff1bb5ff |\n+--------------------------------------+---------------------+------------------+--------+--------------------------------------+\n\nThe output for Neutron network would be:\n\n+----+---------------------+------------------+-----------+--------+\n| ID | Floating IP Address | Fixed IP Address | Server ID | Pool   |\n+----+---------------------+------------------+-----------+--------+\n|  1 | 172.24.4.1          | None             | None      | public |\n+----+---------------------+------------------+-----------+--------+\n\nChange-Id: I1295e922df695414511d9a07ca4a8e2428040064\nPartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 4, 'created': '2016-02-19 03:47:31.000000000', 'files': ['openstackclient/tests/network/v2/test_floating_ip.py', 'openstackclient/tests/network/v2/fakes.py', 'openstackclient/network/v2/floating_ip.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ca34aa1587212ce5ac456a988fd6b442e646ed16', 'message': 'Floating IP: Fix ""ip floating list"" in neutron network\n\nThe implementation of ""ip floating list"" in the commit below\nis incorrect:\n\n    Change-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\n\nThis is because the FloatingIP objects returned from Nova and\nNeutron network are different. They need different handling.\n\nThis patch fixes this problem.\n\nThe output for Neutron network would be:\n\n+--------------------------------------+---------------------+------------------+------+\n| ID                                   | Floating IP Address | Fixed IP Address | Port |\n+--------------------------------------+---------------------+------------------+------+\n| 1976df86-e66a-4f96-81bd-c6ffee6407f1 | 172.24.4.3          | None             | None |\n+--------------------------------------+---------------------+------------------+------+\n\nThe output for Neutron network would be:\n\n+----+---------------------+------------------+-----------+--------+\n| ID | Floating IP Address | Fixed IP Address | Server ID | Pool   |\n+----+---------------------+------------------+-----------+--------+\n|  1 | 172.24.4.1          | None             | None      | public |\n+----+---------------------+------------------+-----------+--------+\n\nChange-Id: I1295e922df695414511d9a07ca4a8e2428040064\nPartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}]",13,280535,ca34aa1587212ce5ac456a988fd6b442e646ed16,23,6,4,14937,,,0,"Floating IP: Fix ""ip floating list"" in neutron network

The implementation of ""ip floating list"" in the commit below
is incorrect:

    Change-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c

This is because the FloatingIP objects returned from Nova and
Neutron network are different. They need different handling.

This patch fixes this problem.

The output for Neutron network would be:

+--------------------------------------+---------------------+------------------+------+
| ID                                   | Floating IP Address | Fixed IP Address | Port |
+--------------------------------------+---------------------+------------------+------+
| 1976df86-e66a-4f96-81bd-c6ffee6407f1 | 172.24.4.3          | None             | None |
+--------------------------------------+---------------------+------------------+------+

The output for Neutron network would be:

+----+---------------------+------------------+-----------+--------+
| ID | Floating IP Address | Fixed IP Address | Server ID | Pool   |
+----+---------------------+------------------+-----------+--------+
|  1 | 172.24.4.1          | None             | None      | public |
+----+---------------------+------------------+-----------+--------+

Change-Id: I1295e922df695414511d9a07ca4a8e2428040064
Partial-Bug: 1519502
Related-to: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/35/280535/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_floating_ip.py', 'openstackclient/network/v2/floating_ip.py', 'openstackclient/tests/network/v2/fakes.py']",3,70c64b95a42c3fd5ccf84d16729770dd11012eb4,bug/1519502," 'floating_ip_address': '1.0.9.0', 'fixed_ip_address': '2.0.9.0', 'status': 'DOWN', 'floating_network_id': 'network-id-' + uuid.uuid4().hex,"," 'ip': '1.0.9.0', 'fixed_ip': '2.0.9.0', 'instance_id': 'server-id-' + uuid.uuid4().hex, 'pool': 'public',",43,16
openstack%2Fkeystone-specs~master~I52e9c86e8b223f0c064c594db1e9c2f914d2209e,openstack/keystone-specs,master,I52e9c86e8b223f0c064c594db1e9c2f914d2209e,Cleanup formatting,MERGED,2016-02-19 15:40:03.000000000,2016-02-19 15:46:00.000000000,2016-02-19 15:46:00.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-02-19 15:40:03.000000000', 'files': ['api/v3/identity-api-v3-os-oauth1-ext.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/1b897cd3659703054ad82f7c16222b3fd5b73407', 'message': 'Cleanup formatting\n\nThe formatting was a little off so this was rendered incorrectly.\n\nChange-Id: I52e9c86e8b223f0c064c594db1e9c2f914d2209e\n'}]",0,282393,1b897cd3659703054ad82f7c16222b3fd5b73407,6,2,1,6486,,,0,"Cleanup formatting

The formatting was a little off so this was rendered incorrectly.

Change-Id: I52e9c86e8b223f0c064c594db1e9c2f914d2209e
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/93/282393/1 && git format-patch -1 --stdout FETCH_HEAD,['api/v3/identity-api-v3-os-oauth1-ext.rst'],1,1b897cd3659703054ad82f7c16222b3fd5b73407,cleanup,Immutable attributes provided by the Identity service:, Immutable attributes provided by the Identity service:,1,1
openstack%2Fwatcher~master~I384e62320de34761e29d5cbac37ddc8ae253a70c,openstack/watcher,master,I384e62320de34761e29d5cbac37ddc8ae253a70c,Re-enable related Tempest test,MERGED,2016-02-12 16:35:07.000000000,2016-02-19 15:40:36.000000000,2016-02-19 15:40:36.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-02-12 16:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/265f301faf2a22aaa066db046dfbc956e653b54b', 'message': 'Re-enable related Tempest test\n\nFollowing the previous 2 patchset\nhttps://review.openstack.org/#/c/279517/ and\nhttps://review.openstack.org/#/c/279555/, this patchset re-enables\nthe related Tempest test which filters goals while removing the one\nthat was filtering by host aggregate.\n\nChange-Id: I384e62320de34761e29d5cbac37ddc8ae253a70c\nCloses-Bug: #1510189\n'}, {'number': 2, 'created': '2016-02-15 08:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/2153f3039c74f0517859b47a11a82d5b8ce795f1', 'message': 'Re-enable related Tempest test\n\nFollowing the previous 2 patchset\nhttps://review.openstack.org/#/c/279517/ and\nhttps://review.openstack.org/#/c/279555/, this patchset re-enables\nthe related Tempest test which filters goals while removing the one\nthat was filtering by host aggregate.\n\nChange-Id: I384e62320de34761e29d5cbac37ddc8ae253a70c\nCloses-Bug: #1510189\n'}, {'number': 3, 'created': '2016-02-18 13:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/9aa894405d9713d1f4d9f3a93cb10da0ea5df53a', 'message': 'Re-enable related Tempest test\n\nFollowing the previous 2 patchset\nhttps://review.openstack.org/#/c/279517/ and\nhttps://review.openstack.org/#/c/279555/, this patchset re-enables\nthe related Tempest test which filters goals while removing the one\nthat was filtering by host aggregate.\n\nChange-Id: I384e62320de34761e29d5cbac37ddc8ae253a70c\nCloses-Bug: #1510189\n'}, {'number': 4, 'created': '2016-02-19 14:32:42.000000000', 'files': ['watcher_tempest_plugin/tests/api/admin/test_audit_template.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/1ddf69a68f8325334667698c3c3cc87cef63214a', 'message': 'Re-enable related Tempest test\n\nFollowing the previous 2 patchset\nhttps://review.openstack.org/#/c/279517/ and\nhttps://review.openstack.org/#/c/279555/, this patchset re-enables\nthe related Tempest test which filters goals while removing the one\nthat was filtering by host aggregate.\n\nChange-Id: I384e62320de34761e29d5cbac37ddc8ae253a70c\nCloses-Bug: #1510189\n'}]",0,279655,1ddf69a68f8325334667698c3c3cc87cef63214a,19,3,4,18971,,,0,"Re-enable related Tempest test

Following the previous 2 patchset
https://review.openstack.org/#/c/279517/ and
https://review.openstack.org/#/c/279555/, this patchset re-enables
the related Tempest test which filters goals while removing the one
that was filtering by host aggregate.

Change-Id: I384e62320de34761e29d5cbac37ddc8ae253a70c
Closes-Bug: #1510189
",git fetch https://review.opendev.org/openstack/watcher refs/changes/55/279655/4 && git format-patch -1 --stdout FETCH_HEAD,['watcher_tempest_plugin/tests/api/admin/test_audit_template.py'],1,265f301faf2a22aaa066db046dfbc956e653b54b,bug/1510189," _, audit_templates = self.client.list_audit_templates( audit_template_uuids = [ at[""uuid""] for at in audit_templates['audit_templates']] self.assertIn(self.audit_template['uuid'], audit_template_uuids)"," @decorators.skip_because(bug=""1510189"") _, audit_template = self.client.list_audit_templates( self.assert_expected(self.audit_template, audit_template['audit_templates'][0]) @decorators.skip_because(bug=""1510189"") @test.attr(type='smoke') def test_filter_audit_template_by_host_aggregate(self): _, audit_template = self.client.list_audit_templates( host_aggregate=self.audit_template['host_aggregate']) self.assert_expected(self.audit_template, audit_template['audit_templates'][0])",4,13
openstack%2Fmurano~master~Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a,openstack/murano,master,Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a,Support for static methods/properties,MERGED,2016-01-26 14:00:53.000000000,2016-02-19 15:34:16.000000000,2016-02-19 15:34:16.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-01-26 14:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/69fc9964880b889d92d7a00a72f703d27c3be8f8', 'message': '[WiP] Support for static methods/properties\n\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n'}, {'number': 2, 'created': '2016-02-13 23:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ced5430aadbea079ee754cbb21e11d9e52a9362d', 'message': '[WiP] Support for static methods/properties\n\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n'}, {'number': 3, 'created': '2016-02-13 23:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f464501d95008611a4281cdc106b329636659d1b', 'message': '[WiP] Support for static methods/properties\n\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n'}, {'number': 4, 'created': '2016-02-15 00:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a17147477da99b876fbb5695325a00ad17ff1710', 'message': '[WiP] Support for static methods/properties\n\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n'}, {'number': 5, 'created': '2016-02-15 00:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/86115e10bb12ac62bf292435756b5cbf88295910', 'message': '[WiP] Support for static methods/properties\n\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n'}, {'number': 6, 'created': '2016-02-17 00:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2a77801e079d21187a9a71ceaefaa79b4e0e7808', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}, {'number': 7, 'created': '2016-02-18 01:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/eab5ee19bcc783b56a0a890a08971f9939a2104d', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}, {'number': 8, 'created': '2016-02-18 02:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6c18dc3ac4c5f2e2b570c58b4619354a4053af6d', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}, {'number': 9, 'created': '2016-02-18 12:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/36192653ebff706bc364b66721d695b3e1691c2c', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}, {'number': 10, 'created': '2016-02-18 14:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d8bc4dee3238065cebd14f660316668f606822db', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}, {'number': 11, 'created': '2016-02-18 16:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ab111216597f354bb55a021b0dde9af5e88f4df0', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}, {'number': 12, 'created': '2016-02-18 22:23:20.000000000', 'files': ['murano/dsl/exceptions.py', 'murano/dsl/reflection.py', 'murano/dsl/lhs_expression.py', 'murano/tests/unit/test_engine.py', 'releasenotes/notes/statics-9943fe9873138dac.yaml', 'murano/cmd/test_runner.py', 'murano/dsl/yaql_functions.py', 'murano/dsl/yaql_expression.py', 'murano/dsl/murano_method.py', 'murano/dsl/murano_object.py', 'murano/dsl/object_store.py', 'murano/dsl/typespec.py', 'murano/dsl/murano_class.py', 'murano/dsl/helpers.py', 'murano/dsl/dsl.py', 'murano/tests/unit/dsl/meta/TestStaticsBase.yaml', 'murano/tests/unit/dsl/meta/TestStatics.yaml', 'murano/dsl/yaql_integration.py', 'murano/dsl/executor.py', 'murano/tests/unit/dsl/test_statics.py', 'murano/dsl/dsl_types.py', 'murano/tests/unit/dsl/foundation/test_package_loader.py', 'meta/io.murano/Classes/configuration/Linux.yaml', 'murano/dsl/namespace_resolver.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/94c904e1cba6ad6e362f5289aa46b137f59b77ce', 'message': ""Support for static methods/properties\n\nBoth properties and methods can be marked as Usage: Static\n\nStatics can be accessed using ns:Class.property / ns:Class.method(),\n:Class.property / :Class.method() to access class from current namespace\nor type('full.name').property / type('full.name').method() to use full type name.\n\nIn static method $ / $this are referencing current class rather than object.\nStatic properties are not loaded from object model.\n\nAlso methods of io.murano.configuration.Linux class are now static.\nSince static methods can be called on the instance it doesn't break\nbackward compatibility.\n\nImplements blueprint: muranopl-statics\nChange-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a\n""}]",3,272545,94c904e1cba6ad6e362f5289aa46b137f59b77ce,61,8,12,7226,,,0,"Support for static methods/properties

Both properties and methods can be marked as Usage: Static

Statics can be accessed using ns:Class.property / ns:Class.method(),
:Class.property / :Class.method() to access class from current namespace
or type('full.name').property / type('full.name').method() to use full type name.

In static method $ / $this are referencing current class rather than object.
Static properties are not loaded from object model.

Also methods of io.murano.configuration.Linux class are now static.
Since static methods can be called on the instance it doesn't break
backward compatibility.

Implements blueprint: muranopl-statics
Change-Id: Ic7c6beed9222f4bca118877a60fdabfdd9d65e5a
",git fetch https://review.opendev.org/openstack/murano refs/changes/45/272545/12 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/typespec.py', 'murano/dsl/lhs_expression.py', 'murano/dsl/murano_class.py', 'murano/dsl/yaql_functions.py', 'murano/dsl/helpers.py', 'murano/dsl/dsl.py', 'murano/tests/unit/dsl/meta/SampleClass1.yaml', 'murano/dsl/yaql_integration.py', 'murano/dsl/executor.py', 'murano/dsl/murano_method.py', 'murano/dsl/murano_object.py', 'murano/tests/unit/dsl/test_execution.py', 'murano/dsl/object_store.py']",13,69fc9964880b889d92d7a00a72f703d27c3be8f8,static-methods," owner, self, self.executor,"," owner, self,",181,45
openstack%2Ffuel-main~master~I71a6c10dccf33f2ea250da7880e4657393526c77,openstack/fuel-main,master,I71a6c10dccf33f2ea250da7880e4657393526c77,"Add the Fuel node bootstrap script to the ""fuel-setup"" package",MERGED,2016-01-14 10:03:04.000000000,2016-02-19 15:29:52.000000000,2016-02-19 15:29:52.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7562}, {'_account_id': 7613}, {'_account_id': 8777}, {'_account_id': 10288}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 13895}, {'_account_id': 14200}, {'_account_id': 18455}]","[{'number': 1, 'created': '2016-01-14 10:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8ff874233edd5a115cc61cf674f20aeafde48930', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 2, 'created': '2016-01-14 10:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c254e83dd238486ca3f9f633cfebecd911ce31a4', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 3, 'created': '2016-01-14 11:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d8ee62c62cae69c58e0e5fc9f66759c1a9ad6162', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 4, 'created': '2016-01-14 16:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f0adb7c5f9552223445d6442443bf605a945b7c0', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 5, 'created': '2016-02-11 15:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e3fde82c341a4bd03aacfa6fcfec2c29054d2293', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 6, 'created': '2016-02-11 15:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4e8b1680f281ddd3d59718536f54d498ddb89903', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 7, 'created': '2016-02-11 16:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/226f7752863728253ec39ad453c066a9e3d2b436', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 8, 'created': '2016-02-11 16:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/85910c4f7d56c9847d15a88a31ab147454a1d4ea', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 9, 'created': '2016-02-11 16:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/47d257d00c6a469a384bb3c8d786cb287a03cc7a', 'message': 'Add the Fuel node bootstrap script to the ""fuel"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 10, 'created': '2016-02-11 16:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b41d13476fed54c8bc9c5681b7ebd7a8dbbeaf2c', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 11, 'created': '2016-02-11 16:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/22b2b5882101fa7e463cce602f8a175d8f3ab31e', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 12, 'created': '2016-02-11 17:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/948443ab0c80affdde9a0e10ab08e08457f39153', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 13, 'created': '2016-02-11 17:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/52a8567a5cf81132cb8506e5ccdde656b85feb89', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 14, 'created': '2016-02-11 17:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/785d86ee24ed132cc1bfe0dfcb026e8bdb2b2e6e', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 15, 'created': '2016-02-11 17:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7ef9dedf3b68acf788e3f32e5138bf85e9f48990', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 16, 'created': '2016-02-11 22:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/52a14ebe65c2d8963cc9b1e0c6e762083d4d2d98', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 17, 'created': '2016-02-11 22:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/438cb1620bf174e9aafd553e3fdb410d908361aa', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 18, 'created': '2016-02-11 22:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/49afbe141c273fc7730c1adcddeb9bcd4136ae20', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 19, 'created': '2016-02-18 16:00:37.000000000', 'files': ['iso/module.mk', 'specs/fuel-main.spec', 'iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9d71797aa3233dad42a4db7ea41c32a61f8b163d', 'message': 'Add the Fuel node bootstrap script to the ""fuel-setup"" package\n\nChange-Id: I71a6c10dccf33f2ea250da7880e4657393526c77\nBlueprint: separate-fuel-node-provisioning\n'}]",24,267441,9d71797aa3233dad42a4db7ea41c32a61f8b163d,64,11,19,10474,,,0,"Add the Fuel node bootstrap script to the ""fuel-setup"" package

Change-Id: I71a6c10dccf33f2ea250da7880e4657393526c77
Blueprint: separate-fuel-node-provisioning
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/41/267441/17 && git format-patch -1 --stdout FETCH_HEAD,"['packages/module.mk', 'iso/module.mk', 'specs/fuel-main.spec', 'iso/ks.template']",4,8ff874233edd5a115cc61cf674f20aeafde48930,separate-fuel-node-provisioning,,"# Install bootstrap_admin_node.sh and enabling it install -m 0777 -D ${SOURCE}/bootstrap_admin_node.sh /usr/local/sbin/bootstrap_admin_node.sh echo ""ENABLED=1"" > /etc/sysconfig/bootstrap_admin_node ",29,9
openstack%2Fkolla~master~I18b1015ca62a352e193ef01bd49cd6d6f9372193,openstack/kolla,master,I18b1015ca62a352e193ef01bd49cd6d6f9372193,Launch VM in gate,MERGED,2016-02-16 15:05:22.000000000,2016-02-19 15:29:05.000000000,2016-02-19 15:29:05.000000000,"[{'_account_id': 3}, {'_account_id': 13039}, {'_account_id': 14119}, {'_account_id': 15447}, {'_account_id': 18723}]","[{'number': 1, 'created': '2016-02-16 15:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/04697f92d1ceaccdb321b3964eae84c44f109bbc', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 2, 'created': '2016-02-16 15:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9091ca946180702b2f73e2d1fa7b79f32a336c88', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 3, 'created': '2016-02-16 16:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0c8be87953104da5ce2d6d47ab8c819d2efa71ae', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 4, 'created': '2016-02-16 17:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e0f210336e9b2bcd3ffd9d83062a9cb68f7b31e3', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 5, 'created': '2016-02-16 19:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/81c2ff57ebde46ee3f76d2c6e5158a3361d6da09', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 6, 'created': '2016-02-16 22:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5db6029a38b809aa982fda9e562a1a6cf5636b0b', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 7, 'created': '2016-02-16 23:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4bf0df413348c2fe5905781a2f68dc672c8333fc', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 8, 'created': '2016-02-17 01:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/779a4017d8495f7f8e850f5b073ec24a134e99f4', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 9, 'created': '2016-02-17 03:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2fda8286a18713e264636d50dd89ba59e378e53e', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 10, 'created': '2016-02-17 14:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5124bb506f255083d019a9e46894d2bad99be7fc', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 11, 'created': '2016-02-17 22:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8b26e003d0edb83c67def2899f7bce09a41bcb38', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 12, 'created': '2016-02-18 16:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/472c5f539afc1e45f35518abf50bd629a60af1af', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}, {'number': 13, 'created': '2016-02-18 19:55:31.000000000', 'files': ['tools/deploy_aio.sh', 'tools/setup_gate.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ae4407a2aba49984ad327e464b1964a8db0872d2', 'message': 'Launch VM in gate\n\nChange-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193\nPartially-Implements: blueprint functional-testing-gate\n'}]",5,280749,ae4407a2aba49984ad327e464b1964a8db0872d2,38,5,13,14119,,,0,"Launch VM in gate

Change-Id: I18b1015ca62a352e193ef01bd49cd6d6f9372193
Partially-Implements: blueprint functional-testing-gate
",git fetch https://review.opendev.org/openstack/kolla refs/changes/49/280749/9 && git format-patch -1 --stdout FETCH_HEAD,['tools/deploy_aio.sh'],1,04697f92d1ceaccdb321b3964eae84c44f109bbc,bp/functional-testing-gate,# Test OpenStack Environment tools/init-runonce nova boot --poll --image $(openstack image list | awk '/cirros/ {print $2}') --nic net-id=$(openstack network list | awk '/demo-net/ {print $2}') --flavor 1 kolla_boot_test,# TODO(SamYaple): Actually do functional testing of OpenStack,3,1
openstack%2Ffuel-astute~master~Ia5d586867afa5fdc6187b5e6b87536d42508b10d,openstack/fuel-astute,master,Ia5d586867afa5fdc6187b5e6b87536d42508b10d,Add node concurrency,ABANDONED,2016-02-01 16:48:48.000000000,2016-02-19 15:27:07.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-02-01 16:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/8ed097930148776e6a50cfb0336888d61f88e21b', 'message': 'Add node concurrency\n\nChange-Id: Ia5d586867afa5fdc6187b5e6b87536d42508b10d\n'}, {'number': 2, 'created': '2016-02-02 14:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/3ee20938f31a8fcd36d362df5310215e2185e4bd', 'message': 'Add node concurrency\n\nChange-Id: Ia5d586867afa5fdc6187b5e6b87536d42508b10d\n'}, {'number': 3, 'created': '2016-02-05 13:55:37.000000000', 'files': ['lib/fuel_deployment/node.rb', 'tests/node_concurrency.rb', 'lib/fuel_deployment/task.rb', 'lib/fuel_deployment/cluster.rb', 'spec/unit/fuel_deployment/node_spec.rb', 'tests/task_concurrency.rb', 'tests/test_node.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/2a8dd0ba340a9b8e750d3956bd1cec2041150390', 'message': 'Add node concurrency\n\nChange-Id: Ia5d586867afa5fdc6187b5e6b87536d42508b10d\n'}]",4,274782,2a8dd0ba340a9b8e750d3956bd1cec2041150390,16,7,3,9037,,,0,"Add node concurrency

Change-Id: Ia5d586867afa5fdc6187b5e6b87536d42508b10d
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/82/274782/3 && git format-patch -1 --stdout FETCH_HEAD,"['lib/fuel_deployment/node.rb', 'tests/node_concurrency.rb', 'lib/fuel_deployment/task.rb', 'lib/fuel_deployment/cluster.rb', 'spec/unit/fuel_deployment/node_spec.rb', 'tests/task_concurrency.rb', 'tests/test_node.rb']",7,8ed097930148776e6a50cfb0336888d61f88e21b,node_concurrency, def hook_pre_node(*args), def hook_post_node(*args),340,14
openstack%2Fkolla~master~I9f76adf084cd4f68e29326112b76ffd02b5adada,openstack/kolla,master,I9f76adf084cd4f68e29326112b76ffd02b5adada,Added Elasticearch and its deployment.,MERGED,2016-01-14 17:16:20.000000000,2016-02-19 15:25:55.000000000,2016-02-19 15:25:55.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 16620}, {'_account_id': 19300}, {'_account_id': 19472}]","[{'number': 1, 'created': '2016-01-14 17:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/aabd74cd5b33d435e22a7559f2bb0411514c9362', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 2, 'created': '2016-01-20 14:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2dca8addbb3a838a25297adc818930d9b292f7e6', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 3, 'created': '2016-01-20 14:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a93f32a5bf261389d56b160811968b43765b7f3b', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 4, 'created': '2016-01-22 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cf6e3f1ce96882ef11ba276a480e8e8368406585', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 5, 'created': '2016-01-22 14:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/af07ba6592ab2db78db39581dc64f140845552e2', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 6, 'created': '2016-01-25 11:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7bb169d80e4c482620fd9aed2532aad58082c65d', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 7, 'created': '2016-01-27 18:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c6bda11d5019eb29cc10106cd48e138df6e0d1f0', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 8, 'created': '2016-02-02 14:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/720178340ebdb463494cd4572583556ad83bd85f', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 9, 'created': '2016-02-04 09:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ed6f00e39d4bf6c7a62f8c19bee8d1402739a9c4', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 10, 'created': '2016-02-08 10:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9c08d09883bd54fec875d4fcc087ecfef4176bb0', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 11, 'created': '2016-02-10 08:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/210148e4dbf360b01f7ed19b97beccf58442a4cd', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 12, 'created': '2016-02-10 09:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/617522a1e58aa10762e08906827719265729c601', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 13, 'created': '2016-02-12 09:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/86e491f0eb5db9dcb8b9f51efc9f372de73ac41a', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}, {'number': 14, 'created': '2016-02-13 07:53:24.000000000', 'files': ['ansible/inventory/multinode', 'ansible/roles/elasticsearch/tasks/main.yml', 'ansible/roles/elasticsearch/templates/elasticsearch.yml.j2', 'ansible/roles/elasticsearch/defaults/main.yml', 'ansible/site.yml', 'docker/base/elasticsearch.yum.repo', 'docker/elasticsearch/extend_start.sh', 'docker/elasticsearch/elasticsearch_sudoers', 'ansible/inventory/all-in-one', 'ansible/roles/elasticsearch/tasks/config.yml', 'docker/base/sources.list', 'ansible/roles/elasticsearch/templates/elasticsearch.json.j2', 'ansible/roles/elasticsearch/tasks/pull.yml', 'ansible/group_vars/all.yml', 'docker/base/Dockerfile.j2', 'ansible/roles/elasticsearch/meta/main.yml', 'ansible/roles/elasticsearch/tasks/deploy.yml', 'ansible/roles/elasticsearch/tasks/start.yml', 'docker/elasticsearch/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/792666dd79aef7d041c6d5f0ce1f57125ee1affc', 'message': 'Added Elasticearch and its deployment.\n\nPart of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.\n\nChange-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada\nPartially-implements: blueprint central-logging-service\n'}]",65,267714,792666dd79aef7d041c6d5f0ce1f57125ee1affc,74,7,14,16620,,,0,"Added Elasticearch and its deployment.

Part of ELK stack. Includes Dockerfiles for both Centos and Ubuntu.

Change-Id: I9f76adf084cd4f68e29326112b76ffd02b5adada
Partially-implements: blueprint central-logging-service
",git fetch https://review.opendev.org/openstack/kolla refs/changes/14/267714/13 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/inventory/multinode', 'ansible/roles/elasticsearch/tasks/main.yml', 'ansible/roles/elasticsearch/templates/elasticsearch.yml.j2', 'ansible/roles/elasticsearch/defaults/main.yml', 'ansible/site.yml', 'docker/base/elasticsearch.yum.repo', 'ansible/inventory/all-in-one', 'ansible/roles/elasticsearch/tasks/config.yml', 'ansible/roles/elasticsearch/templates/elasticsearch.json.j2', 'ansible/roles/elasticsearch/tasks/pull.yml', 'ansible/group_vars/all.yml', 'docker/base/Dockerfile.j2', 'ansible/roles/elasticsearch/tasks/deploy.yml', 'ansible/roles/elasticsearch/tasks/start.yml', 'docker/elasticsearch/Dockerfile.j2']",15,aabd74cd5b33d435e22a7559f2bb0411514c9362,bp/central-logging-service,"FROM {{ namespace }}/{{ image_prefix }}base:{{ tag }} MAINTAINER {{ maintainer }} ENV ELASTICSEARCH_VERSION 2.1.1 ENV JAVA_HOME /usr/lib/jvm/java-7-openjdk-amd64 {% if base_distro in ['centos', 'fedora', 'oraclelinux', 'rhel'] %} RUN yum -y install java-1.7.0-openjdk && \ yum clean all RUN yum install -y elasticsearch-$ELASTICSEARCH_VERSION && \ yum clean all {% elif base_distro in ['ubuntu', 'debian'] %} RUN apt-get update && apt-get -y install wget openjdk-7-jre && \ apt-get -y clean RUN wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/deb/elasticsearch/$ELASTICSEARCH_VERSION/elasticsearch-$ELASTICSEARCH_VERSION.deb RUN dpkg -i elasticsearch-$ELASTICSEARCH_VERSION.deb RUN rm -f elasticsearch-$ELASTICSEARCH_VERSION.deb {% endif %} ENV elastic_dir /usr/share/elasticsearch RUN mkdir -p $elastic_dir/data $elastic_dir/logs $elastic_dir/config/scripts RUN chown -R elasticsearch:elasticsearch $elastic_dir #by default elasticsearch shell is /bin/false, we need #/bin/bash to run elasticsearch as non-root #https://discuss.elastic.co/t/running-as-non-root-user-service-wrapper-has-changed/7863 RUN usermod -s /bin/bash elasticsearch -d $elastic_dir VOLUME /usr/share/elasticsearch/data EXPOSE 9200 9300 {{ include_footer }} ",,133,1
openstack%2Faodh~master~Ie0df81856425c5c1ad7f8620c7d153363c987fd3,openstack/aodh,master,Ie0df81856425c5c1ad7f8620c7d153363c987fd3,Add composite rule alarm evaluator,MERGED,2015-12-24 08:55:25.000000000,2016-02-19 15:24:43.000000000,2016-02-19 15:24:43.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 9526}]","[{'number': 1, 'created': '2015-12-24 08:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/48d0963945ee43965269d232b7c80eca26799b20', 'message': 'WIP: Add composite rule alarm evaluator\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 2, 'created': '2015-12-31 09:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/6cac57a8348c2bd7bdafc3dea4c131fad25dd4f9', 'message': 'Add composite rule alarm evaluator\n\nTODO: Need to add tests, but this functionality is ready to review.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 3, 'created': '2016-01-11 12:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/35ab5bf7706ec3b9c42ab22f2f442769986565a1', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 4, 'created': '2016-01-11 14:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/608e1715c5ab537385362dffeacf24107fbecba1', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 5, 'created': '2016-01-12 04:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/6962a30909c7142687b99c0abc7d45af0ddf7012', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 6, 'created': '2016-01-12 06:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/054fb1f9174eb75200c839f5d2c01564982120c4', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 7, 'created': '2016-01-12 07:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/008a028aa42880415776aa3c8de94589d2252c81', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 8, 'created': '2016-01-12 07:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/a95192f1b9bd9ab9333085894c35ae869f8bcc99', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 9, 'created': '2016-01-14 12:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/9b2e4fdbe584f652b62ff0353d930919bf1989d2', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 10, 'created': '2016-01-18 12:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/a0492f96bc610f3717870058ff5475d62a94fa76', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 11, 'created': '2016-01-26 07:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/365b399c38439da1ab3ad1aaa4178a9aea75614e', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 12, 'created': '2016-02-04 03:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/629ab02541653a1596f6e1f686f3b96a5db18e39', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 13, 'created': '2016-02-04 03:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/2ae3756497aea1a7d2986be8a71c26021d65ea40', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 14, 'created': '2016-02-14 02:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/99d493190f8a96db8309bf46237d19759cb1f8d4', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}, {'number': 15, 'created': '2016-02-19 02:17:02.000000000', 'files': ['aodh/tests/unit/evaluator/test_composite.py', 'aodh/evaluator/composite.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/aodh/commit/73bc82ba6041c17c10a55cd853a2ea5a5c1f97d1', 'message': 'Add composite rule alarm evaluator\n\nAdd a composite rule alarm evaluator, which will evaluate composite alarms\nbased on threshold evaluators.\n\nblueprint composite-threshold-rule-alarm\n\nChange-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3\n'}]",38,261226,73bc82ba6041c17c10a55cd853a2ea5a5c1f97d1,57,6,15,8290,,,0,"Add composite rule alarm evaluator

Add a composite rule alarm evaluator, which will evaluate composite alarms
based on threshold evaluators.

blueprint composite-threshold-rule-alarm

Change-Id: Ie0df81856425c5c1ad7f8620c7d153363c987fd3
",git fetch https://review.opendev.org/openstack/aodh refs/changes/26/261226/10 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/tests/unit/evaluator/test_composite.py', 'aodh/evaluator/composite.py', 'aodh/evaluator/__init__.py']",3,48d0963945ee43965269d232b7c80eca26799b20,bp/composite-threshold-rule-alarm,"THRESHOLD_EVALUATORS = {} # Expose threshold evaluator for composite alarm evaluation threshold_types = ['threshold', 'gnocchi_resources_threshold', 'gnocchi_aggregation_by_metrics_threshold', 'gnocchi_aggregation_by_resources_threshold'] for t in threshold_types: THRESHOLD_EVALUATORS[t] = self.evaluators[t].obj",,225,0
openstack%2Finstack-undercloud~stable%2Fliberty~I7aae41b57cb82e1d776b200ff56fd90756eff19e,openstack/instack-undercloud,stable/liberty,I7aae41b57cb82e1d776b200ff56fd90756eff19e,Add check for sufficient memory to undercloud install,MERGED,2016-01-08 17:55:10.000000000,2016-02-19 15:23:14.000000000,2016-02-19 15:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-08 17:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/c8726b5563f94de2b97dc39bc0696f8deee921e5', 'message': ""Add check for sufficient memory to undercloud install\n\nIt turns out that it is possible to install the undercloud on a\n2 GB system, but it will cause all kinds of weird problems and not\nperform well.  Let's be explicit about our requirements and refuse\nto install in such an environment.\n\nChange-Id: I7aae41b57cb82e1d776b200ff56fd90756eff19e\n(cherry picked from commit 5b2d555e756f4589048c6b280116b753f6655e9e)\n""}, {'number': 2, 'created': '2016-01-29 20:32:30.000000000', 'files': ['requirements.txt', 'instack_undercloud/undercloud.py', 'instack_undercloud/tests/test_undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/1fd0f4296c79621cb6282dd696c597fe37b77e6b', 'message': ""Add check for sufficient memory to undercloud install\n\nIt turns out that it is possible to install the undercloud on a\n2 GB system, but it will cause all kinds of weird problems and not\nperform well.  Let's be explicit about our requirements and refuse\nto install in such an environment.\n\nChange-Id: I7aae41b57cb82e1d776b200ff56fd90756eff19e\n(cherry picked from commit 5b2d555e756f4589048c6b280116b753f6655e9e)\n""}]",0,265378,1fd0f4296c79621cb6282dd696c597fe37b77e6b,32,4,2,6928,,,0,"Add check for sufficient memory to undercloud install

It turns out that it is possible to install the undercloud on a
2 GB system, but it will cause all kinds of weird problems and not
perform well.  Let's be explicit about our requirements and refuse
to install in such an environment.

Change-Id: I7aae41b57cb82e1d776b200ff56fd90756eff19e
(cherry picked from commit 5b2d555e756f4589048c6b280116b753f6655e9e)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/78/265378/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'instack_undercloud/undercloud.py', 'instack_undercloud/tests/test_undercloud.py']",3,c8726b5563f94de2b97dc39bc0696f8deee921e5,stable-backports," @mock.patch('instack_undercloud.undercloud._check_memory') mock_run_command, mock_check_memory, mock_check_hostname, self.assertEqual(True, mock_check_hostname.called) self.assertEqual(True, mock_check_memory.called)class TestCheckMemory(BaseTestCase): @mock.patch('psutil.virtual_memory') def test_sufficient_memory(self, mock_vm): mock_vm.return_value = mock.Mock() mock_vm.return_value.total = 4143927296 undercloud._check_memory() @mock.patch('psutil.virtual_memory') def test_insufficient_memory(self, mock_vm): mock_vm.return_value = mock.Mock() mock_vm.return_value.total = 2071963648 self.assertRaises(RuntimeError, undercloud._check_memory) "," mock_run_command, mock_check_hostname,",40,1
openstack%2Fglance~master~Id6f610974f4b68e4786b0241478c5b7b7c622eac,openstack/glance,master,Id6f610974f4b68e4786b0241478c5b7b7c622eac,Fix typos in configuring.rst,MERGED,2016-02-04 19:57:35.000000000,2016-02-19 15:19:35.000000000,2016-02-19 15:19:34.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 8158}, {'_account_id': 11391}, {'_account_id': 14676}, {'_account_id': 16183}, {'_account_id': 16237}, {'_account_id': 16658}]","[{'number': 1, 'created': '2016-02-04 19:57:35.000000000', 'files': ['doc/source/configuring.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/fbd2a007f12f7d9ea21523bddb235df813ec7386', 'message': 'Fix typos in configuring.rst\n\nFix several typos.\n\nChange-Id: Id6f610974f4b68e4786b0241478c5b7b7c622eac\n'}]",0,276419,fbd2a007f12f7d9ea21523bddb235df813ec7386,14,8,1,20431,,,0,"Fix typos in configuring.rst

Fix several typos.

Change-Id: Id6f610974f4b68e4786b0241478c5b7b7c622eac
",git fetch https://review.opendev.org/openstack/glance refs/changes/19/276419/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuring.rst'],1,fbd2a007f12f7d9ea21523bddb235df813ec7386,,swift_store_multi_tenant is disabled.Location of ca certificates file to use for cinder client requests.Make sure the directory is writable by the user running the,swift_store_multi_tentant is disabled.Location of ca certicates file to use for cinder client requests.Make sure the directory is writeable by the user running the,3,3
openstack%2Ffuel-qa~master~I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5,openstack/fuel-qa,master,I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5,Add test for cluster deployment with Ironic and Ceilometer,MERGED,2016-02-03 17:01:23.000000000,2016-02-19 15:18:57.000000000,2016-02-19 12:47:42.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 9068}, {'_account_id': 10136}, {'_account_id': 12867}, {'_account_id': 13636}, {'_account_id': 14525}, {'_account_id': 14614}, {'_account_id': 15784}, {'_account_id': 15984}, {'_account_id': 17270}]","[{'number': 1, 'created': '2016-02-03 17:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/8e3ce79d687d37e9e4d7d897033437c80fb6b9c1', 'message': 'Add deployment configuration tests for Ironic\n\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 2, 'created': '2016-02-04 13:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e4684b793a7e5831eef2aaf44783eb084a050f0a', 'message': 'Add deployment configuration tests for Ironic\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 3, 'created': '2016-02-04 17:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a1eb66c6b27e10b1c0c1327e88b4a80a9671457f', 'message': 'Add deployment tests for Ironic\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 4, 'created': '2016-02-08 16:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/5367172eddcd4a6d9b89651bcd7f701a0caf9a89', 'message': 'Add deployment tests for Ironic\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 5, 'created': '2016-02-10 16:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9ce2f215468765068867622356450d4318c91090', 'message': 'Add deployment tests for Ironic\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 6, 'created': '2016-02-11 14:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/27eb40d29db9a214ae047a33e549c7497ad122ac', 'message': 'Add test for cluster deployment with Ironic and Ceilometer\n\nDeploy cluster with Ironic and Ceilometer roles\ncombined on thw same node together.\nVerify that Ironic works properly.\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 7, 'created': '2016-02-15 13:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/8832e0702c93782bc43fbe08103399aae8937637', 'message': 'Add test for cluster deployment with Ironic and Ceilometer\n\nDeploy cluster with Ironic and Ceilometer roles\ncombined on thw same node together.\nVerify that Ironic works properly.\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 8, 'created': '2016-02-19 10:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/5e6ec95fe2581737eb947a46022b7febee851033', 'message': 'Add test for cluster deployment with Ironic and Ceilometer\n\nDeploy cluster with Ironic and Ceilometer roles\ncombined on the same node together.\nVerify that Ironic works properly.\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}, {'number': 9, 'created': '2016-02-19 11:05:40.000000000', 'files': ['fuelweb_test/tests/test_ironic_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ba452c5b802ffc220c890aaea466b38b1aad9b93', 'message': 'Add test for cluster deployment with Ironic and Ceilometer\n\nDeploy cluster with Ironic and Ceilometer roles\ncombined on the same node together.\nVerify that Ironic works properly.\n\nPartial-Bug: #1541847\nChange-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5\n'}]",3,275824,ba452c5b802ffc220c890aaea466b38b1aad9b93,64,12,9,14614,,,0,"Add test for cluster deployment with Ironic and Ceilometer

Deploy cluster with Ironic and Ceilometer roles
combined on the same node together.
Verify that Ironic works properly.

Partial-Bug: #1541847
Change-Id: I66fbd44a52a3e26bfb43b937d6c540fb0e197aa5
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/24/275824/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ironic_base.py'],1,8e3ce79d687d37e9e4d7d897033437c80fb6b9c1,bug/1541847," # new testcase Configuration Tiny @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""ironic_deploy_ceph""]) @log_snapshot_after_test def ironic_deploy_tiny(self): """"""Deploy ironic with 1 baremetal node Scenario: 1. Create cluster 2. Add 1 node with Controller+Ironic role 3. Add 2 nodes with Compute+Ceph roles 4. Deploy the cluster 5. Upload image to glance 6. Enroll Ironic nodes 7. Boot nova instance 8. Check Nova instance status Duration 90m Snapshot ironic_deploy_tiny """""" self.env.revert_snapshot(""ready_with_3_slaves"") data = { 'volumes_ceph': True, 'images_ceph': True, 'objects_ceph': True, 'volumes_lvm': False, 'tenant': 'ceph1', 'user': 'ceph1', 'password': 'ceph1', 'net_provider': 'neutron', 'net_segment_type': NEUTRON_SEGMENT['vlan'], 'ironic': True} nodes = { 'slave-01': ['controller', 'ironic'], 'slave-02': ['compute', 'ceph-osd'], 'slave-03': ['compute', 'ceph-osd']} self.show_step(1, initialize=True) self.show_step(2) self.show_step(3) self.show_step(4) cluster_id = self._deploy_ironic_cluster() ironic_conn = ironic_actions.IronicActions( self.fuel_web.get_public_vip(cluster_id), user='ceph1', passwd='ceph1', tenant='ceph1') self.show_step(6) self.show_step(7) self._create_os_resources(ironic_conn) self.show_step(8) self._boot_nova_instances(ironic_conn) self.show_step(9) ironic_conn.wait_for_vms(ironic_conn) ironic_conn.verify_vms_connection(ironic_conn) self.env.make_snapshot(""ironic_deploy_tiny"") # new testcase Configuration Complex @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""ironic_deploy_ceph""]) @log_snapshot_after_test def ironic_deploy_complex(self): """"""Deploy ironic with 1 baremetal node Scenario: 1. Create cluster 2. Add 2 nodes with Controller+Ironic+Ceph role 3. Add 1 node with Compute+Ceph roles 4. Deploy the cluster 5. Upload image to glance 6. Enroll Ironic nodes 7. Boot nova instance 8. Check Nova instance status Duration 90m Snapshot ironic_deploy_complex """""" self.env.revert_snapshot(""ready_with_3_slaves"") data = { 'volumes_ceph': True, 'images_ceph': True, 'objects_ceph': True, 'volumes_lvm': False, 'tenant': 'ceph1', 'user': 'ceph1', 'password': 'ceph1', 'net_provider': 'neutron', 'net_segment_type': NEUTRON_SEGMENT['vlan'], 'ironic': True} nodes = { 'slave-01': ['controller', 'ironic', 'ceph-osd'], 'slave-02': ['controller', 'ironic', 'ceph-osd'], 'slave-03': ['compute', 'ceph-osd']} self.show_step(1, initialize=True) self.show_step(2) self.show_step(3) self.show_step(4) cluster_id = self._deploy_ironic_cluster(settings=data, nodes=nodes) ironic_conn = ironic_actions.IronicActions( self.fuel_web.get_public_vip(cluster_id), user='ceph1', passwd='ceph1', tenant='ceph1') self.show_step(5) self.show_step(6) self._create_os_resources(ironic_conn) self.show_step(7) self._boot_nova_instances(ironic_conn) self.show_step(8) ironic_conn.wait_for_vms(ironic_conn) ironic_conn.verify_vms_connection(ironic_conn) self.env.make_snapshot(""ironic_deploy_complex"")",,124,0
openstack%2Fglance~master~Ie5b3db154c9008bb0ceb2aee95bcd28a957fe55b,openstack/glance,master,Ie5b3db154c9008bb0ceb2aee95bcd28a957fe55b,Replace assertRaisesRegexp with assertRaisesRegex,MERGED,2016-02-17 09:58:43.000000000,2016-02-19 15:17:58.000000000,2016-02-19 15:17:58.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2016-02-17 09:58:43.000000000', 'files': ['glance/tests/unit/common/test_signature_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/27a9ef355314d2c54cb559a7c4cc179d8dd28c5e', 'message': 'Replace assertRaisesRegexp with assertRaisesRegex\n\nThe unittest.TestCase.assertRaisesRegexp() method is deprecated in\nPython 3.2.\n\nOn Python 2.7, testtools gets the assertRaisesRegex() method from the\nunittest2 module which is a requirement of testtools.\n\nChange-Id: Ie5b3db154c9008bb0ceb2aee95bcd28a957fe55b\n'}]",0,281160,27a9ef355314d2c54cb559a7c4cc179d8dd28c5e,8,2,1,9107,,,0,"Replace assertRaisesRegexp with assertRaisesRegex

The unittest.TestCase.assertRaisesRegexp() method is deprecated in
Python 3.2.

On Python 2.7, testtools gets the assertRaisesRegex() method from the
unittest2 module which is a requirement of testtools.

Change-Id: Ie5b3db154c9008bb0ceb2aee95bcd28a957fe55b
",git fetch https://review.opendev.org/openstack/glance refs/changes/60/281160/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/common/test_signature_utils.py'],1,27a9ef355314d2c54cb559a7c4cc179d8dd28c5e,assertRaisesRegexp," self.assertRaisesRegex(exception.SignatureVerificationError, 'Signature verification failed.', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'Required image properties for signature' ' verification do not exist. Cannot verify' ' signature.', signature_utils.verify_signature, None, None, None) self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid signature key type: .*', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'Signature verification failed.', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid mask_gen_algorithm: .*', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid pss_salt_length: .*', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'Error occurred while verifying' ' the signature', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'Unable to verify signature since the ' 'algorithm is unsupported on this system', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegex(exception.SignatureVerificationError, 'The signature data was not properly' ' encoded using base64', signature_utils.get_signature, '///') self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid signature hash method: .*', signature_utils.get_hash_method, 'SHA-2') self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid signature key type: .*', signature_utils.get_signature_key_type, 'RSB-PSS') self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid public key type for ' 'signature key type: .*', signature_utils.get_public_key, None, None, 'RSA-PSS') self.assertRaisesRegex(exception.SignatureVerificationError, 'Certificate is not valid after: .*', signature_utils.get_certificate, None, cert_uuid) self.assertRaisesRegex(exception.SignatureVerificationError, 'Certificate is not valid before: .*', signature_utils.get_certificate, None, cert_uuid) self.assertRaisesRegex(exception.SignatureVerificationError, 'Unable to retrieve certificate with ID: .*', signature_utils.get_certificate, None, bad_cert_uuid) self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid certificate format: .*', signature_utils.get_certificate, None, cert_uuid)"," self.assertRaisesRegexp(exception.SignatureVerificationError, 'Signature verification failed.', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Required image properties for signature' ' verification do not exist. Cannot verify' ' signature.', signature_utils.verify_signature, None, None, None) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid signature key type: .*', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Signature verification failed.', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid mask_gen_algorithm: .*', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid pss_salt_length: .*', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Error occurred while verifying' ' the signature', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Unable to verify signature since the ' 'algorithm is unsupported on this system', signature_utils.verify_signature, None, checksum_hash, image_properties) self.assertRaisesRegexp(exception.SignatureVerificationError, 'The signature data was not properly' ' encoded using base64', signature_utils.get_signature, '///') self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid signature hash method: .*', signature_utils.get_hash_method, 'SHA-2') self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid signature key type: .*', signature_utils.get_signature_key_type, 'RSB-PSS') self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid public key type for ' 'signature key type: .*', signature_utils.get_public_key, None, None, 'RSA-PSS') self.assertRaisesRegexp(exception.SignatureVerificationError, 'Certificate is not valid after: .*', signature_utils.get_certificate, None, cert_uuid) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Certificate is not valid before: .*', signature_utils.get_certificate, None, cert_uuid) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Unable to retrieve certificate with ID: .*', signature_utils.get_certificate, None, bad_cert_uuid) self.assertRaisesRegexp(exception.SignatureVerificationError, 'Invalid certificate format: .*', signature_utils.get_certificate, None, cert_uuid)",68,68
openstack%2Finstack-undercloud~stable%2Fliberty~I4e6cc3457c62ad1a0f3b81247e1718e492973e8c,openstack/instack-undercloud,stable/liberty,I4e6cc3457c62ad1a0f3b81247e1718e492973e8c,"Set Nova's ram_allocation_ratio configuration option to ""1.0"" By default",MERGED,2016-01-08 17:55:10.000000000,2016-02-19 15:15:57.000000000,2016-02-19 15:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6773}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-08 17:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/7e57192b896e73328d2c9ecd1754f3cd6e8614cb', 'message': 'Set Nova\'s ram_allocation_ratio configuration option to ""1.0"" By default\n\nthe Nova\'s ""ram_allocation_ratio"" is ""1.5"", this doesn\'t make sense for\nbaremetal because we can\'t allocate more memory than the machine already\nhas.\n\nBy leaving it as default (""1.5"") will cause scheduling instances to\nfail in case the amount of RAM in the node\'s is exactly the same amount\nrequested in the flavor.\n\nCloses-Bug: #1524752\nChange-Id: I4e6cc3457c62ad1a0f3b81247e1718e492973e8c\n(cherry picked from commit 4b984a94e4fa85f114def6295095f47b32ffb0ff)\n'}, {'number': 2, 'created': '2016-01-29 20:32:30.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/569144fcdcf68c67b43aa84f5ed5ebf576a49715', 'message': 'Set Nova\'s ram_allocation_ratio configuration option to ""1.0"" By default\n\nthe Nova\'s ""ram_allocation_ratio"" is ""1.5"", this doesn\'t make sense for\nbaremetal because we can\'t allocate more memory than the machine already\nhas.\n\nBy leaving it as default (""1.5"") will cause scheduling instances to\nfail in case the amount of RAM in the node\'s is exactly the same amount\nrequested in the flavor.\n\nCloses-Bug: #1524752\nChange-Id: I4e6cc3457c62ad1a0f3b81247e1718e492973e8c\n(cherry picked from commit 4b984a94e4fa85f114def6295095f47b32ffb0ff)\n'}]",0,265377,569144fcdcf68c67b43aa84f5ed5ebf576a49715,40,7,2,6928,,,0,"Set Nova's ram_allocation_ratio configuration option to ""1.0"" By default

the Nova's ""ram_allocation_ratio"" is ""1.5"", this doesn't make sense for
baremetal because we can't allocate more memory than the machine already
has.

By leaving it as default (""1.5"") will cause scheduling instances to
fail in case the amount of RAM in the node's is exactly the same amount
requested in the flavor.

Closes-Bug: #1524752
Change-Id: I4e6cc3457c62ad1a0f3b81247e1718e492973e8c
(cherry picked from commit 4b984a94e4fa85f114def6295095f47b32ffb0ff)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/77/265377/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,7e57192b896e73328d2c9ecd1754f3cd6e8614cb,stable-backports," class {'::nova::scheduler::filter': ram_allocation_ratio => hiera('nova::scheduler::filter::ram_allocation_ratio'), }",include ::nova::scheduler::filter,4,1
openstack%2Fapi-site~master~I3d6214630f696e3f92a631ac6200c65e8f381108,openstack/api-site,master,I3d6214630f696e3f92a631ac6200c65e8f381108,Remove duplicated error code,MERGED,2016-02-18 10:19:07.000000000,2016-02-19 15:13:48.000000000,2016-02-19 15:13:47.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-18 10:19:07.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-interface-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/b6238d8704a4c7de53dcfb797cf0fe63de4d908b', 'message': 'Remove duplicated error code\n\nremove duplicated error code in interface\n\nChange-Id: I3d6214630f696e3f92a631ac6200c65e8f381108\nPartial-Bug: #1515222\n'}]",0,281743,b6238d8704a4c7de53dcfb797cf0fe63de4d908b,8,3,1,6062,,,0,"Remove duplicated error code

remove duplicated error code in interface

Change-Id: I3d6214630f696e3f92a631ac6200c65e8f381108
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/43/281743/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-interface-v2.1.wadl'],1,b6238d8704a4c7de53dcfb797cf0fe63de4d908b,fix-compute-api-ref, </response> </response> </response>, </response> &commonFaults; &getFaults; </response> &commonFaults; &getFaults; </response> &commonFaults; &getFaults;,3,3
openstack%2Fpython-manilaclient~master~Ia14f4b3f3f4312400d24a0c2bc2ee53900a5048c,openstack/python-manilaclient,master,Ia14f4b3f3f4312400d24a0c2bc2ee53900a5048c,Eliminate unnecessary character,MERGED,2016-02-17 02:09:45.000000000,2016-02-19 15:13:04.000000000,2016-02-19 15:13:04.000000000,"[{'_account_id': 3}, {'_account_id': 11865}, {'_account_id': 14567}, {'_account_id': 17097}]","[{'number': 1, 'created': '2016-02-17 02:09:45.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/c0f1fd7f01e3692029d73bd594cf467131f3a286', 'message': 'Eliminate unnecessary character\n\nEliminated unnecessary character about endpoint of keystone.\n\nChange-Id: Ia14f4b3f3f4312400d24a0c2bc2ee53900a5048c\n'}]",0,281009,c0f1fd7f01e3692029d73bd594cf467131f3a286,11,4,1,16522,,,0,"Eliminate unnecessary character

Eliminated unnecessary character about endpoint of keystone.

Change-Id: Ia14f4b3f3f4312400d24a0c2bc2ee53900a5048c
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/09/281009/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,c0f1fd7f01e3692029d73bd594cf467131f3a286,fix-readme, # use v2.0 auth with http://example.com:5000/v2.0/," # use v2.0 auth with http://example.com:5000/v2.0/"")",1,1
openstack%2Fdesignate~master~Ifacaaff07385b9da01cd0add4d706101e9c109ec,openstack/designate,master,Ifacaaff07385b9da01cd0add4d706101e9c109ec,"Syntax, grammar, and typo fixes",MERGED,2016-02-19 05:05:05.000000000,2016-02-19 15:12:36.000000000,2016-02-19 15:12:36.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 15452}, {'_account_id': 18602}]","[{'number': 1, 'created': '2016-02-19 05:05:05.000000000', 'files': ['doc/source/rest/v2/zones.rst', 'doc/source/rest/v2/recordsets.rst', 'doc/source/install/ubuntu-juno.rst', 'doc/source/production-guidelines.rst', 'doc/source/support-matrix.rst', 'doc/source/rest/v2/tsigkeys.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/49232b2216aa7a80cb0a907c6849c4e03173157a', 'message': 'Syntax, grammar, and typo fixes\n\nChange-Id: Ifacaaff07385b9da01cd0add4d706101e9c109ec\n'}]",0,282170,49232b2216aa7a80cb0a907c6849c4e03173157a,9,5,1,15643,,,0,"Syntax, grammar, and typo fixes

Change-Id: Ifacaaff07385b9da01cd0add4d706101e9c109ec
",git fetch https://review.opendev.org/openstack/designate refs/changes/70/282170/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/rest/v2/zones.rst', 'doc/source/rest/v2/recordsets.rst', 'doc/source/install/ubuntu-juno.rst', 'doc/source/production-guidelines.rst', 'doc/source/support-matrix.rst', 'doc/source/rest/v2/tsigkeys.rst']",6,49232b2216aa7a80cb0a907c6849c4e03173157a,typo-fix, Remove a Tsigkey with the specified tsigkey's id., Remove a Tsigkey with the spefied tsigkey's id.,7,7
openstack%2Fheat~master~I80d818fc8e5765bb872f7e361fde42b69ed7567e,openstack/heat,master,I80d818fc8e5765bb872f7e361fde42b69ed7567e,Fix handling of functions in repeat function template,ABANDONED,2016-02-17 18:36:33.000000000,2016-02-19 15:11:49.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}]","[{'number': 1, 'created': '2016-02-17 18:36:33.000000000', 'files': ['heat/engine/hot/functions.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/be57c670ac97bdde9093fd69ed7e37ab5e8d0b1e', 'message': ""Fix handling of functions in repeat function template\n\nCurrently, we only handle get_param/get_attr if they don't\ninclude any component to be replaced from the for_each values.\n\nThis adjusts the resolution of the template when it's a function\nso that we can resolve data derived from the for_each values\n\nCloses-Bug: #1546684\nChange-Id: I80d818fc8e5765bb872f7e361fde42b69ed7567e\n""}]",0,281460,be57c670ac97bdde9093fd69ed7e37ab5e8d0b1e,6,3,1,4328,,,0,"Fix handling of functions in repeat function template

Currently, we only handle get_param/get_attr if they don't
include any component to be replaced from the for_each values.

This adjusts the resolution of the template when it's a function
so that we can resolve data derived from the for_each values

Closes-Bug: #1546684
Change-Id: I80d818fc8e5765bb872f7e361fde42b69ed7567e
",git fetch https://review.opendev.org/openstack/heat refs/changes/60/281460/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/functions.py', 'heat/tests/test_hot.py']",2,be57c670ac97bdde9093fd69ed7e37ab5e8d0b1e,bug/1546684," def test_get_attr_inside_repeat(self): """"""Test resolution of get_attr nested in a repeat function."""""" hot_tpl = hot_tpl_complex_attrs_all_attrs self.stack = parser.Stack(self.ctx, 'test_get_attr', template.Template(hot_tpl)) self.stack.store() self.stack.create() self.assertEqual((parser.Stack.CREATE, parser.Stack.COMPLETE), self.stack.state) snippet = {'repeat': { 'template': {'key-%var%': {'get_attr': ['resource1', 'flat_dict', '%var%']}}, 'for_each': {'%var%': ['key1', 'key2', 'key3']}}} self.assertEqual([{'key-key1': 'val1'}, {'key-key2': 'val2'}, {'key-key3': 'val3'}], self.resolve(snippet)) ",,28,2
openstack%2Fproject-config~master~I2eecb7028bcab7d5d82ad4155a775a9b2daa441f,openstack/project-config,master,I2eecb7028bcab7d5d82ad4155a775a9b2daa441f,Unshadow All-Projects in exclusiveGroupPermissions,MERGED,2016-02-17 22:45:33.000000000,2016-02-19 15:10:05.000000000,2016-02-19 15:10:05.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6554}]","[{'number': 1, 'created': '2016-02-17 22:45:33.000000000', 'files': ['gerrit/acls/openstack/networking-vsphere.config', 'gerrit/acls/openstack/governance.config', 'gerrit/acls/openstack/kingbird.config', 'gerrit/acls/openstack/networking-midonet.config', 'gerrit/acls/openstack/python-keystoneclient.config', 'gerrit/acls/openstack/networking-onos.config', 'gerrit/acls/openstack/fuel-nailgun-agent.config', 'gerrit/acls/openstack/networking-fortinet.config', 'gerrit/acls/openstack/ceilometer.config', 'tools/normalize_acl.py', 'gerrit/acls/openstack/shotgun.config', 'gerrit/acls/openstack/python-ironicclient.config', 'gerrit/acls/openstack/neutron-lbaas-dashboard.config', 'gerrit/acls/openstack/fuel-web.config', 'gerrit/acls/openstack/kuryr.config', 'gerrit/acls/openstack/ceilometermiddleware.config', 'gerrit/acls/openstack/kosmos.config', 'gerrit/acls/openstack/python-ceilometerclient.config', 'gerrit/acls/openstack/networking-arista.config', 'gerrit/acls/openstack/mistral.config', 'gerrit/acls/openstack/trove.config', 'gerrit/acls/openstack/manila.config', 'gerrit/acls/openstack/networking-infoblox.config', 'gerrit/acls/openstack/python-zaqarclient.config', 'gerrit/acls/openstack/neutron-classifier.config', 'gerrit/acls/openstack/horizon.config', 'gerrit/acls/openstack/neutron-fwaas.config', 'gerrit/acls/openstack/python-saharaclient.config', 'gerrit/acls/openstack/python-cinderclient.config', 'gerrit/acls/openstack/python-glanceclient.config', 'gerrit/acls/openstack/neutron-lbaas.config', 'gerrit/acls/openstack/transparency-policy.config', 'gerrit/acls/openstack/fuel-mirror.config', 'gerrit/acls/openstack/intel-nfv-ci-tests.config', 'gerrit/acls/openstack/python-novaclient.config', 'gerrit/acls/openstack/ironic-python-agent.config', 'gerrit/acls/openstack/networking-ovn.config', 'gerrit/acls/openstack/tripleo-image-elements.config', 'gerrit/acls/openstack/networking-plumgrid.config', 'gerrit/acls/openstack/trove-dashboard.config', 'gerrit/acls/openstack/django_openstack_auth.config', 'gerrit/acls/openstack/octavia.config', 'gerrit/acls/openstack/glance.config', 'gerrit/acls/openstack/heat.config', 'gerrit/acls/openstack/networking-sfc.config', 'gerrit/acls/openstack/sahara-etc.config', 'gerrit/acls/openstack/networking-ale-omniswitch.config', 'gerrit/acls/openstack/python-designateclient.config', 'gerrit/acls/openstack/networking-lenovo.config', 'gerrit/acls/openstack/python-swiftclient.config', 'gerrit/acls/openstack/sahara-dashboard.config', 'gerrit/acls/openstack/keystonemiddleware.config', 'gerrit/acls/openstack/fuel-main.config', 'gerrit/acls/openstack/glance_store.config', 'gerrit/acls/openstack/fuel-astute.config', 'gerrit/acls/openstack/python-fuelclient.config', 'gerrit/acls/openstack/murano.config', 'gerrit/acls/openstack/designate.config', 'gerrit/acls/openstack/congress.config', 'gerrit/acls/openstack/fuel-menu.config', 'gerrit/acls/openstack/keystone.config', 'gerrit/acls/openstack/networking-hyperv.config', 'gerrit/acls/openstack/python-aodhclient.config', 'gerrit/acls/openstack/networking-cisco.config', 'gerrit/acls/openstack/barbican.config', 'gerrit/acls/openstack/neutron-vpnaas.config', 'gerrit/acls/openstack/dragonflow.config', 'gerrit/acls/openstack/oslo-incubator.config', 'gerrit/acls/openstack/swift.config', 'gerrit/acls/openstack/freezer.config', 'gerrit/acls/openstack/smaug.config', 'gerrit/acls/openstack/networking-calico.config', 'gerrit/acls/openstack/ironic-inspector.config', 'gerrit/acls/openstack/fuel-ostf.config', 'gerrit/acls/openstack/fuel-agent.config', 'gerrit/acls/openstack/network-checker.config', 'gerrit/acls/openstack/networking-ovs-dpdk.config', 'gerrit/acls/openstack/sahara.config', 'gerrit/acls/openstack/networking-bgpvpn.config', 'gerrit/acls/openstack/yaql.config', 'gerrit/acls/openstack/openstack.config', 'gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/collectd-ceilometer-plugin.config', 'gerrit/acls/openstack/networking-odl.config', 'gerrit/acls/openstack/zaqar.config', 'gerrit/acls/openstack/networking-fujitsu.config', 'gerrit/acls/openstack/fuel-library.config', 'gerrit/acls/openstack/cinder.config', 'gerrit/acls/openstack/networking-bagpipe.config', 'gerrit/acls/openstack/python-troveclient.config', 'gerrit/acls/openstack/networking-ofagent.config', 'gerrit/acls/openstack/aodh.config', 'gerrit/acls/openstack/neutron.config', 'gerrit/acls/openstack/vmware-nsx.config', 'gerrit/acls/openstack/ironic-webclient.config', 'gerrit/acls/openstack/networking-powervm.config', 'gerrit/acls/openstack/ironic.config', 'gerrit/acls/openstack/python-heatclient.config', 'gerrit/acls/openstack/networking-l2gw.config', 'gerrit/acls/openstack/python-neutronclient.config', 'gerrit/acls/openstack/requirements.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f62e441f245c86655bfdfe5af81f339f20a9e689', 'message': 'Unshadow All-Projects in exclusiveGroupPermissions\n\nWhenever a project-specific ACL declares exclusiveGroupPermissions\non some permission, it can block other valid uses of that permission\nwhich would otherwise be inherited from the All-Projects pseudoACL.\nMake sure that Project Bootstrappers retains access to abandon,\n-2..+2 on label-Code-Review and -1..+1 on label-Workflow. Also make\nsure Change Owners can still abandon and add -1..0 on\nlabel-Workflow, and that Registered Users can always -1..+1 on\nlabel-Code-Review.\n\nThis change corrects existing ACLs to meet the above criteria, and\nalso introduces a normalization rule to prevent regression.\n\nChange-Id: I2eecb7028bcab7d5d82ad4155a775a9b2daa441f\n'}]",0,281563,f62e441f245c86655bfdfe5af81f339f20a9e689,13,4,1,5263,,,0,"Unshadow All-Projects in exclusiveGroupPermissions

Whenever a project-specific ACL declares exclusiveGroupPermissions
on some permission, it can block other valid uses of that permission
which would otherwise be inherited from the All-Projects pseudoACL.
Make sure that Project Bootstrappers retains access to abandon,
-2..+2 on label-Code-Review and -1..+1 on label-Workflow. Also make
sure Change Owners can still abandon and add -1..0 on
label-Workflow, and that Registered Users can always -1..+1 on
label-Code-Review.

This change corrects existing ACLs to meet the above criteria, and
also introduces a normalization rule to prevent regression.

Change-Id: I2eecb7028bcab7d5d82ad4155a775a9b2daa441f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/281563/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/networking-vsphere.config', 'gerrit/acls/openstack/governance.config', 'gerrit/acls/openstack/kingbird.config', 'gerrit/acls/openstack/networking-midonet.config', 'gerrit/acls/openstack/python-keystoneclient.config', 'gerrit/acls/openstack/networking-onos.config', 'gerrit/acls/openstack/fuel-nailgun-agent.config', 'gerrit/acls/openstack/networking-fortinet.config', 'gerrit/acls/openstack/ceilometer.config', 'tools/normalize_acl.py', 'gerrit/acls/openstack/shotgun.config', 'gerrit/acls/openstack/python-ironicclient.config', 'gerrit/acls/openstack/neutron-lbaas-dashboard.config', 'gerrit/acls/openstack/fuel-web.config', 'gerrit/acls/openstack/kuryr.config', 'gerrit/acls/openstack/ceilometermiddleware.config', 'gerrit/acls/openstack/kosmos.config', 'gerrit/acls/openstack/python-ceilometerclient.config', 'gerrit/acls/openstack/networking-arista.config', 'gerrit/acls/openstack/mistral.config', 'gerrit/acls/openstack/trove.config', 'gerrit/acls/openstack/manila.config', 'gerrit/acls/openstack/networking-infoblox.config', 'gerrit/acls/openstack/python-zaqarclient.config', 'gerrit/acls/openstack/neutron-classifier.config', 'gerrit/acls/openstack/horizon.config', 'gerrit/acls/openstack/neutron-fwaas.config', 'gerrit/acls/openstack/python-saharaclient.config', 'gerrit/acls/openstack/python-cinderclient.config', 'gerrit/acls/openstack/python-glanceclient.config', 'gerrit/acls/openstack/neutron-lbaas.config', 'gerrit/acls/openstack/transparency-policy.config', 'gerrit/acls/openstack/fuel-mirror.config', 'gerrit/acls/openstack/intel-nfv-ci-tests.config', 'gerrit/acls/openstack/python-novaclient.config', 'gerrit/acls/openstack/ironic-python-agent.config', 'gerrit/acls/openstack/networking-ovn.config', 'gerrit/acls/openstack/tripleo-image-elements.config', 'gerrit/acls/openstack/networking-plumgrid.config', 'gerrit/acls/openstack/trove-dashboard.config', 'gerrit/acls/openstack/django_openstack_auth.config', 'gerrit/acls/openstack/octavia.config', 'gerrit/acls/openstack/glance.config', 'gerrit/acls/openstack/heat.config', 'gerrit/acls/openstack/networking-sfc.config', 'gerrit/acls/openstack/sahara-etc.config', 'gerrit/acls/openstack/networking-ale-omniswitch.config', 'gerrit/acls/openstack/python-designateclient.config', 'gerrit/acls/openstack/networking-lenovo.config', 'gerrit/acls/openstack/python-swiftclient.config', 'gerrit/acls/openstack/sahara-dashboard.config', 'gerrit/acls/openstack/keystonemiddleware.config', 'gerrit/acls/openstack/fuel-main.config', 'gerrit/acls/openstack/glance_store.config', 'gerrit/acls/openstack/fuel-astute.config', 'gerrit/acls/openstack/python-fuelclient.config', 'gerrit/acls/openstack/murano.config', 'gerrit/acls/openstack/designate.config', 'gerrit/acls/openstack/congress.config', 'gerrit/acls/openstack/fuel-menu.config', 'gerrit/acls/openstack/keystone.config', 'gerrit/acls/openstack/networking-hyperv.config', 'gerrit/acls/openstack/python-aodhclient.config', 'gerrit/acls/openstack/networking-cisco.config', 'gerrit/acls/openstack/barbican.config', 'gerrit/acls/openstack/neutron-vpnaas.config', 'gerrit/acls/openstack/dragonflow.config', 'gerrit/acls/openstack/oslo-incubator.config', 'gerrit/acls/openstack/swift.config', 'gerrit/acls/openstack/freezer.config', 'gerrit/acls/openstack/smaug.config', 'gerrit/acls/openstack/networking-calico.config', 'gerrit/acls/openstack/ironic-inspector.config', 'gerrit/acls/openstack/fuel-ostf.config', 'gerrit/acls/openstack/fuel-agent.config', 'gerrit/acls/openstack/network-checker.config', 'gerrit/acls/openstack/networking-ovs-dpdk.config', 'gerrit/acls/openstack/sahara.config', 'gerrit/acls/openstack/networking-bgpvpn.config', 'gerrit/acls/openstack/yaql.config', 'gerrit/acls/openstack/openstack.config', 'gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/collectd-ceilometer-plugin.config', 'gerrit/acls/openstack/networking-odl.config', 'gerrit/acls/openstack/zaqar.config', 'gerrit/acls/openstack/networking-fujitsu.config', 'gerrit/acls/openstack/fuel-library.config', 'gerrit/acls/openstack/cinder.config', 'gerrit/acls/openstack/networking-bagpipe.config', 'gerrit/acls/openstack/python-troveclient.config', 'gerrit/acls/openstack/networking-ofagent.config', 'gerrit/acls/openstack/aodh.config', 'gerrit/acls/openstack/neutron.config', 'gerrit/acls/openstack/vmware-nsx.config', 'gerrit/acls/openstack/ironic-webclient.config', 'gerrit/acls/openstack/networking-powervm.config', 'gerrit/acls/openstack/ironic.config', 'gerrit/acls/openstack/python-heatclient.config', 'gerrit/acls/openstack/networking-l2gw.config', 'gerrit/acls/openstack/python-neutronclient.config', 'gerrit/acls/openstack/requirements.config']",101,f62e441f245c86655bfdfe5af81f339f20a9e689,feature/gerrit_perms,abandon = group Change Owner abandon = group Project Bootstrapperslabel-Code-Review = -2..+2 group Project Bootstrapperslabel-Workflow = -1..+0 group Change Owner label-Workflow = -1..+1 group Project Bootstrappers,,479,1
openstack%2Fsenlin~master~Idf162a81185aa4e8924bba205b83f0fa9ed5bd05,openstack/senlin,master,Idf162a81185aa4e8924bba205b83f0fa9ed5bd05,Validate 'sort' parameter for nodes in engine,MERGED,2016-02-19 08:40:13.000000000,2016-02-19 15:09:01.000000000,2016-02-19 15:09:01.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 08:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/49b906290b4b377c6c9d485b917580eb3feb9fbb', 'message': ""Validate 'sort' parameter for nodes in engine\n\nThis adds validation of the 'sort' parameter when listing nodes at\nservice engine layer.\n\nChange-Id: Idf162a81185aa4e8924bba205b83f0fa9ed5bd05\n""}, {'number': 2, 'created': '2016-02-19 14:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/b6956aa4438bfa8a09c6f6c05d462924e1d42fd8', 'message': ""Validate 'sort' parameter for nodes in engine\n\nThis adds validation of the 'sort' parameter when listing nodes at\nservice engine layer.\n\nChange-Id: Idf162a81185aa4e8924bba205b83f0fa9ed5bd05\n""}, {'number': 3, 'created': '2016-02-19 14:55:54.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_nodes.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/5dc5cd39bf85d71b58f1f9ac8ca1c2daaa2e2a94', 'message': ""Validate 'sort' parameter for nodes in engine\n\nThis adds validation of the 'sort' parameter when listing nodes at\nservice engine layer.\n\nChange-Id: Idf162a81185aa4e8924bba205b83f0fa9ed5bd05\n""}]",0,282231,5dc5cd39bf85d71b58f1f9ac8ca1c2daaa2e2a94,11,2,3,8246,,,0,"Validate 'sort' parameter for nodes in engine

This adds validation of the 'sort' parameter when listing nodes at
service engine layer.

Change-Id: Idf162a81185aa4e8924bba205b83f0fa9ed5bd05
",git fetch https://review.opendev.org/openstack/senlin refs/changes/31/282231/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_nodes.py']",2,49b906290b4b377c6c9d485b917580eb3feb9fbb,node-sort," filters={'K': 'V'}, sort='name', filters={'K': 'V'}, sort='name', sort='status', limit=123, marker='MMM', filters='FFF', sort='status', def test_node_list_bad_sort(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, sort='crazykey') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) self.assertEqual(""Invalid value 'crazykey' specified for 'sort key'"", six.text_type(ex.exc_info[1])) "," filters={'K': 'V'}, sort='SSS', filters={'K': 'V'}, sort='SSS', sort='SSS', limit=123, marker='MMM', filters='FFF', sort='SSS',",13,4
openstack%2Foslo.messaging~stable%2Fliberty~Ib69fb7a159eab722fe399f64caa742b77ef45bec,openstack/oslo.messaging,stable/liberty,Ib69fb7a159eab722fe399f64caa742b77ef45bec,Kombu: make reply and fanout queues expire instead of auto-delete,MERGED,2016-02-12 14:24:13.000000000,2016-02-19 15:06:37.000000000,2016-02-19 14:03:21.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6159}]","[{'number': 1, 'created': '2016-02-12 14:24:13.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/393370072e9f8122967c4864c9dc8a7bda731f3a', 'message': 'Kombu: make reply and fanout queues expire instead of auto-delete\n\nBackport of fix made for bug #1515278.\n\nRight now fanout and reply queues are unconditionally created with\nauto-delete flag which causes a number of problems listed in bug\n1495568. Replacing auto-delete with queue expiration with some sane\ntimeout should fix all these issues at once.\n\nOriginal: https://review.openstack.org/#/c/243845/\n\nChange-Id: Ib69fb7a159eab722fe399f64caa742b77ef45bec\nCloses-bug: #1515278\nSigned-off-by: Jorge Niedbalski <jorge.niedbalski@canonical.com>\n'}]",0,279561,393370072e9f8122967c4864c9dc8a7bda731f3a,7,3,1,2276,,,0,"Kombu: make reply and fanout queues expire instead of auto-delete

Backport of fix made for bug #1515278.

Right now fanout and reply queues are unconditionally created with
auto-delete flag which causes a number of problems listed in bug
1495568. Replacing auto-delete with queue expiration with some sane
timeout should fix all these issues at once.

Original: https://review.openstack.org/#/c/243845/

Change-Id: Ib69fb7a159eab722fe399f64caa742b77ef45bec
Closes-bug: #1515278
Signed-off-by: Jorge Niedbalski <jorge.niedbalski@canonical.com>
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/61/279561/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,393370072e9f8122967c4864c9dc8a7bda731f3a,bug/1515278," cfg.IntOpt('rabbit_transient_queues_ttl', min=1, default=600, help='Positive integer representing duration in seconds for ' 'queue TTL (x-expires). Queues which are unused for the ' 'duration of the TTL are automatically deleted. The ' 'parameter affects only reply and fanout queues.'),def _get_queue_arguments(rabbit_ha_queues, rabbit_queue_ttl): args = {} if rabbit_ha_queues: args['x-ha-policy'] = 'all' if rabbit_queue_ttl > 0: args['x-expires'] = rabbit_queue_ttl * 1000 return args exchange_auto_delete, queue_auto_delete, callback, nowait=True, rabbit_ha_queues=None, rabbit_queue_ttl=0): self.exchange_auto_delete = exchange_auto_delete self.queue_auto_delete = queue_auto_delete self.queue_arguments = _get_queue_arguments(rabbit_ha_queues, rabbit_queue_ttl) auto_delete=self.exchange_auto_delete) auto_delete=self.exchange_auto_delete, self.rabbit_transient_queues_ttl = \ driver_conf.rabbit_transient_queues_ttl exchange_auto_delete=True, queue_auto_delete=False, rabbit_ha_queues=self.rabbit_ha_queues, rabbit_queue_ttl=self.rabbit_transient_queues_ttl) exchange_auto_delete=self.amqp_auto_delete, queue_auto_delete=self.amqp_auto_delete, exchange_auto_delete=True, queue_auto_delete=False, rabbit_ha_queues=self.rabbit_ha_queues, rabbit_queue_ttl=self.rabbit_transient_queues_ttl) queue_arguments=_get_queue_arguments(self.rabbit_ha_queues, 0))","def _get_queue_arguments(rabbit_ha_queues): auto_delete, callback, nowait=True, rabbit_ha_queues=None): self.auto_delete = auto_delete self.queue_arguments = _get_queue_arguments(rabbit_ha_queues) auto_delete=self.auto_delete) auto_delete=self.auto_delete, auto_delete=True, rabbit_ha_queues=self.rabbit_ha_queues) auto_delete=self.amqp_auto_delete, auto_delete=True, rabbit_ha_queues=self.rabbit_ha_queues) queue_arguments=_get_queue_arguments(self.rabbit_ha_queues))",39,12
openstack%2Ffuel-web~master~Ib98e569f2742d6e86336cbe4681d3d6e064e4f2e,openstack/fuel-web,master,Ib98e569f2742d6e86336cbe4681d3d6e064e4f2e,Fix random failures of test_assign_given_vips_for_net_groups,MERGED,2016-02-19 12:28:38.000000000,2016-02-19 15:03:04.000000000,2016-02-19 14:35:03.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-19 12:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6bf7d3176a9b0fbd1bcec31120bfb0d84610e2b9', 'message': 'Fix random failures of test_assign_given_vips_for_net_groups\n\nChange-Id: Ib98e569f2742d6e86336cbe4681d3d6e064e4f2e\nCloses-Bug: #1547489\n'}, {'number': 2, 'created': '2016-02-19 13:23:25.000000000', 'files': ['nailgun/nailgun/test/integration/test_network_manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd552bb20c68ddaa8bb83d40aa870080d5ad1ff9', 'message': 'Fix random failures of test_assign_given_vips_for_net_groups\n\nRemoved manual setting of additional VIPs from test code. Such operation is\nnot needed anymore as VIPs are allocated on cluster creation, otherwise\nwe ended up with several entries in db with same vip_name attribute and\nnetwork_manager.assign_given_vips_for_net_groups will produce incorrect\nresults as it relies on its value.\n\nChange-Id: Ib98e569f2742d6e86336cbe4681d3d6e064e4f2e\nCloses-Bug: #1547489\n'}]",1,282311,dd552bb20c68ddaa8bb83d40aa870080d5ad1ff9,30,9,2,8931,,,0,"Fix random failures of test_assign_given_vips_for_net_groups

Removed manual setting of additional VIPs from test code. Such operation is
not needed anymore as VIPs are allocated on cluster creation, otherwise
we ended up with several entries in db with same vip_name attribute and
network_manager.assign_given_vips_for_net_groups will produce incorrect
results as it relies on its value.

Change-Id: Ib98e569f2742d6e86336cbe4681d3d6e064e4f2e
Closes-Bug: #1547489
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/11/282311/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/test/integration/test_network_manager.py'],1,6bf7d3176a9b0fbd1bcec31120bfb0d84610e2b9,bug/1547489_fix_test_assign_given_vips_for_net_groups," # rewrite VIPs allocated on creation of cluster 'vrouter': '192.168.0.4', 'management': '192.168.0.5',"," vips_to_create = { 'management': { 'vrouter': '192.168.0.1', }, 'public': { 'vrouter_pub': '172.16.0.2', }, } 'vrouter': '192.168.0.2', 'management': '192.168.0.3', self.env.create_ip_addrs_by_rules(self.cluster, vips_to_create)",3,11
openstack%2Fcinder~master~I4c3d6b4300298ad0ac4e40a7a1a815cbf88bb151,openstack/cinder,master,I4c3d6b4300298ad0ac4e40a7a1a815cbf88bb151,Fix dynamic import of CONF.volume_api_class,MERGED,2016-02-08 17:25:55.000000000,2016-02-19 15:01:40.000000000,2016-02-14 16:51:08.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4159}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2016-02-08 17:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/13a2f4ada5825ad8eb7a2dd1aa85eb934c597305', 'message': ""Fix dynamic import of CONF.volume_api_class\n\nModifies the import to actually happen when API() is called instead of\nwhen the module is loaded.\n\nThis is necessary because CONF.volume_api_class is always evaluated as\nthe default value since the config file hadn't been parsed yet when the\nmodule is loaded.\n\nNova fixed this problem a while ago for the compute driver in\nhttps://review.openstack.org/#/c/14353/.\n\nChange-Id: I4c3d6b4300298ad0ac4e40a7a1a815cbf88bb151\nCloses-Bug: #1543219\n""}, {'number': 2, 'created': '2016-02-12 16:50:47.000000000', 'files': ['cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/api/contrib/test_volume_tenant_attribute.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/volume/__init__.py', 'cinder/tests/unit/api/contrib/test_volume_image_metadata.py', 'cinder/tests/unit/api/contrib/test_volume_migration_status_attribute.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/api/v2/test_snapshot_metadata.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py', 'cinder/tests/unit/api/v1/test_volume_metadata.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/010d4a23b7f25cfa9786cecc35939f667a6812ba', 'message': ""Fix dynamic import of CONF.volume_api_class\n\nModifies the import to actually happen when API() is called instead of\nwhen the module is loaded.\n\nThis is necessary because CONF.volume_api_class is always evaluated as\nthe default value since the config file hadn't been parsed yet when the\nmodule is loaded.\n\nNova fixed this problem a while ago for the compute driver in\nhttps://review.openstack.org/#/c/14353/.\n\nChange-Id: I4c3d6b4300298ad0ac4e40a7a1a815cbf88bb151\nCloses-Bug: #1543219\n""}]",0,277504,010d4a23b7f25cfa9786cecc35939f667a6812ba,84,25,2,4159,,,0,"Fix dynamic import of CONF.volume_api_class

Modifies the import to actually happen when API() is called instead of
when the module is loaded.

This is necessary because CONF.volume_api_class is always evaluated as
the default value since the config file hadn't been parsed yet when the
module is loaded.

Nova fixed this problem a while ago for the compute driver in
https://review.openstack.org/#/c/14353/.

Change-Id: I4c3d6b4300298ad0ac4e40a7a1a815cbf88bb151
Closes-Bug: #1543219
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/277504/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/__init__.py'],1,13a2f4ada5825ad8eb7a2dd1aa85eb934c597305,bug/1543219,"def API(*args, **kwargs): class_name = CONF.volume_api_class return importutils.import_object(class_name, *args, **kwargs)",API = importutils.import_class(CONF.volume_api_class),3,1
openstack%2Fpython-muranoclient~master~I44885bcf8e5735a89ee418358184169853024113,openstack/python-muranoclient,master,I44885bcf8e5735a89ee418358184169853024113,Add test to check category-delete error message,MERGED,2016-02-17 16:34:07.000000000,2016-02-19 14:58:09.000000000,2016-02-19 14:58:09.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-17 16:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/e08905f869772f250d0174be6850aec4035f74ae', 'message': 'Add test to check category-delete error message\n\nTest case check that error message after calling category-delete with\nnon existing category name contains user friendly substring\n\nChange-Id: I44885bcf8e5735a89ee418358184169853024113\n'}, {'number': 2, 'created': '2016-02-18 06:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/de711caccd8208b1f99552b178b69774e5b6a383', 'message': 'Add test to check category-delete error message\n\nTest case check that error message after calling category-delete with\nnon existing category name contains user friendly substring\n\nTargets: blueprint murano-cli-integration-test-coverage\n\nChange-Id: I44885bcf8e5735a89ee418358184169853024113\n'}, {'number': 3, 'created': '2016-02-18 07:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/57be10f8233af921ddfba5e156ea3307f563f3ee', 'message': 'Add test to check category-delete error message\n\nTest case check that error message after calling category-delete with\nnon existing category name contains user friendly substring\n\nTargets: blueprint murano-cli-integration-test-coverage\n\nChange-Id: I44885bcf8e5735a89ee418358184169853024113\n'}, {'number': 4, 'created': '2016-02-18 15:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/29bbce7a8a38abe9ed0969f7c4d8b57f6a69d04a', 'message': 'Add test to check category-delete error message\n\nTest case check that error message after calling category-delete with\nnon existing category name contains user friendly substring\n\nTargets: blueprint murano-cli-integration-test-coverage\n\nChange-Id: I44885bcf8e5735a89ee418358184169853024113\n'}, {'number': 5, 'created': '2016-02-19 13:17:27.000000000', 'files': ['muranoclient/tests/functional/cli/test_murano.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/3a69cf33c8ea4cf1c8fd90e6913599b7c3f4615f', 'message': 'Add test to check category-delete error message\n\nTest case check that error message after calling category-delete with\nnon existing category name contains user friendly substring\n\nTargets: blueprint murano-cli-integration-test-coverage\n\nChange-Id: I44885bcf8e5735a89ee418358184169853024113\n'}]",0,281379,3a69cf33c8ea4cf1c8fd90e6913599b7c3f4615f,31,11,5,19265,,,0,"Add test to check category-delete error message

Test case check that error message after calling category-delete with
non existing category name contains user friendly substring

Targets: blueprint murano-cli-integration-test-coverage

Change-Id: I44885bcf8e5735a89ee418358184169853024113
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/79/281379/2 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/tests/functional/cli/test_murano.py'],1,e08905f869772f250d0174be6850aec4035f74ae,bp/murano-cli-integration-test-coverage," def test_non_existing_category_delete(self): """"""Test scenario: 1) try to call category-delete for non existing category 2) check that error message contains user friendly substring """""" result = self.murano('category-delete', params='non-existing', fail_ok=True) self.assertIn(""Failed to delete 'non-existing'; category not found"", result) ",,10,0
openstack%2Fpython-senlinclient~master~Iab715ce2f2f13432e60187f42ca34d07c1f29fd0,openstack/python-senlinclient,master,Iab715ce2f2f13432e60187f42ca34d07c1f29fd0,Add OpenstackClient plugin for cluster profile type show,MERGED,2016-02-19 02:00:55.000000000,2016-02-19 14:57:16.000000000,2016-02-19 14:57:16.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-02-19 02:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/63ca78a741d4e0914aaff2bbea4ea750398edddc', 'message': 'Add OpenstackClient plugin for cluster profile type show\n\nThis change implements the ""openstack cluster profile type show"" command\n  Based on the existing senlin command: senlin profile-type-show\n\nChange-Id: Iab715ce2f2f13432e60187f42ca34d07c1f29fd0\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-02-19 08:46:05.000000000', 'files': ['senlinclient/osc/v1/profile_type.py', 'senlinclient/tests/unit/osc/v1/test_profile_type.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/827d5c84ae5898c68fcd7ecb63a0b59aba5b6244', 'message': 'Add OpenstackClient plugin for cluster profile type show\n\nThis change implements the ""openstack cluster profile type show"" command\n  Based on the existing senlin command: senlin profile-type-show\n\nChange-Id: Iab715ce2f2f13432e60187f42ca34d07c1f29fd0\nBlueprint: senlin-support-python-openstackclient\n'}]",2,282133,827d5c84ae5898c68fcd7ecb63a0b59aba5b6244,15,4,2,18389,,,0,"Add OpenstackClient plugin for cluster profile type show

This change implements the ""openstack cluster profile type show"" command
  Based on the existing senlin command: senlin profile-type-show

Change-Id: Iab715ce2f2f13432e60187f42ca34d07c1f29fd0
Blueprint: senlin-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/33/282133/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/osc/v1/profile_type.py', 'senlinclient/tests/unit/osc/v1/test_profile_type.py', 'setup.cfg']",3,63ca78a741d4e0914aaff2bbea4ea750398edddc,bp/senlin-support-python-openstackclient, cluster_profile_type_show = senlinclient.osc.v1.profile_type:ProfileTypeShow,,67,0
openstack%2Fsahara-dashboard~master~Icf3fb352187698f544dd7234d66df1f9c5c65a16,openstack/sahara-dashboard,master,Icf3fb352187698f544dd7234d66df1f9c5c65a16,Fixing up integration tests after UI reorganization,MERGED,2016-02-18 19:01:39.000000000,2016-02-19 14:52:45.000000000,2016-02-19 14:52:45.000000000,"[{'_account_id': 3}, {'_account_id': 8090}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-18 19:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/f827e4c1c58bdb01bfb48ede0a6f812b77f08936', 'message': 'Fixing up integration tests after UI reorganization\n\nThis patch reorganizes the integration tests so that the\npages are in-line with the new UI layout.\n\nChange-Id: Icf3fb352187698f544dd7234d66df1f9c5c65a16\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 2, 'created': '2016-02-19 13:53:09.000000000', 'files': ['sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/jobbinariespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/__init__.py', 'sahara_dashboard/test/integration_tests/tests/test_sahara_job_binaries.py', 'sahara_dashboard/test/integration_tests/tests/test_sahara_image_registry.py', 'sahara_dashboard/test/integration_tests/horizon.conf', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/clusters/__init__.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/clusters/dataimageregistrypage.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/7d3f48c0ce5b39ef6677a3ae329d618e1673dc05', 'message': 'Fixing up integration tests after UI reorganization\n\nThis patch reorganizes the integration tests so that the\npages are in-line with the new UI layout.\n\nChange-Id: Icf3fb352187698f544dd7234d66df1f9c5c65a16\nPartial-Implements: bp reduce-number-of-panels\n'}]",0,282009,7d3f48c0ce5b39ef6677a3ae329d618e1673dc05,10,4,2,8090,,,0,"Fixing up integration tests after UI reorganization

This patch reorganizes the integration tests so that the
pages are in-line with the new UI layout.

Change-Id: Icf3fb352187698f544dd7234d66df1f9c5c65a16
Partial-Implements: bp reduce-number-of-panels
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/09/282009/2 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/jobbinariespage.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/jobs/__init__.py', 'sahara_dashboard/test/integration_tests/tests/test_sahara_job_binaries.py', 'sahara_dashboard/test/integration_tests/tests/test_sahara_image_registry.py', 'sahara_dashboard/test/integration_tests/horizon.conf', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/clusters/__init__.py', 'sahara_dashboard/test/integration_tests/pages/project/data_processing/clusters/dataimageregistrypage.py']",7,f827e4c1c58bdb01bfb48ede0a6f812b77f08936,bp/reduce-number-of-panels,"class DataimageregistryPage(basepage.BaseNavigationPage): super(DataimageregistryPage, self).__init__(driver, conf) self._page_title = ""Clusters""","class ImageregistryPage(basepage.BaseNavigationPage): super(ImageregistryPage, self).__init__(driver, conf) self._page_title = ""Data Processing""",31,20
openstack%2Fneutron~master~Ia80c8a7a48e5161a680bf305a8c6b46efa919cc7,openstack/neutron,master,Ia80c8a7a48e5161a680bf305a8c6b46efa919cc7,DONTMERGE: Proof that LB fullstack test can't use more vms,ABANDONED,2016-02-19 12:43:41.000000000,2016-02-19 14:44:09.000000000,,"[{'_account_id': 8655}, {'_account_id': 14212}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 20629}]","[{'number': 1, 'created': '2016-02-19 12:43:41.000000000', 'files': ['neutron/tests/fullstack/test_connectivity.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e6c5c5ec01be18eb99bfd400f03661b61d93f23', 'message': ""DONTMERGE: Proof that LB fullstack test can't use more vms\n\nChange-Id: Ia80c8a7a48e5161a680bf305a8c6b46efa919cc7\n""}]",0,282316,6e6c5c5ec01be18eb99bfd400f03661b61d93f23,8,6,1,8655,,,0,"DONTMERGE: Proof that LB fullstack test can't use more vms

Change-Id: Ia80c8a7a48e5161a680bf305a8c6b46efa919cc7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/282316/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/fullstack/test_connectivity.py'],1,6e6c5c5ec01be18eb99bfd400f03661b61d93f23,bug/1518675, for i in range(3) for j in range(2)], for i in range(3)],1,1
openstack%2Fgnocchi~master~I2c0cba1bc8f12d868a091b6777e8c06df91435bf,openstack/gnocchi,master,I2c0cba1bc8f12d868a091b6777e8c06df91435bf,Use '#flake8: noqa' to skip file check,MERGED,2016-02-19 13:43:10.000000000,2016-02-19 14:39:35.000000000,2016-02-19 14:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2016-02-19 13:43:10.000000000', 'files': ['gnocchi/indexer/alembic/versions/1c98ac614015_initial_base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e82fbfa79e9a44ff203bd146e6cde53b1ff449e0', 'message': ""Use '#flake8: noqa' to skip file check\n\nBetter use '#flake8: noqa' to skip file check, rather than writing\na file path in tox.ini to exclude it.\nrefer to:\nhttps://flake8.readthedocs.org/en/latest/\n\nChange-Id: I2c0cba1bc8f12d868a091b6777e8c06df91435bf\n""}]",0,282340,e82fbfa79e9a44ff203bd146e6cde53b1ff449e0,6,2,1,17081,,,0,"Use '#flake8: noqa' to skip file check

Better use '#flake8: noqa' to skip file check, rather than writing
a file path in tox.ini to exclude it.
refer to:
https://flake8.readthedocs.org/en/latest/

Change-Id: I2c0cba1bc8f12d868a091b6777e8c06df91435bf
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/40/282340/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/indexer/alembic/versions/1c98ac614015_initial_base.py', 'tox.ini']",2,e82fbfa79e9a44ff203bd146e6cde53b1ff449e0,update-flake8,"exclude = .tox,.eggs,doc","exclude = .tox,.eggs,doc,gnocchi/indexer/alembic/versions/1c98ac614015_initial_base.py",2,2
openstack%2Fmistral~master~I27c3f2ee2719d08908f2eda314798d1a7e877c65,openstack/mistral,master,I27c3f2ee2719d08908f2eda314798d1a7e877c65,Release notes for Barbican actions,MERGED,2016-02-18 13:56:52.000000000,2016-02-19 14:36:52.000000000,2016-02-19 14:36:52.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-02-18 13:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a84df7635a7bff158a1b7dd25133921f9d6d1c94', 'message': 'Release notes for Barbican actions\n\nChange-Id: I27c3f2ee2719d08908f2eda314798d1a7e877c65\nImplements: blueprint support-barbican-actions\n'}, {'number': 2, 'created': '2016-02-19 07:52:32.000000000', 'files': ['releasenotes/notes/support-barbican-0ac77ff11bde19d3.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/2f973a1910acc444cb61b8120cddcb3dbe4e508f', 'message': 'Release notes for Barbican actions\n\nChange-Id: I27c3f2ee2719d08908f2eda314798d1a7e877c65\nImplements: blueprint support-barbican-actions\n'}]",1,281872,2f973a1910acc444cb61b8120cddcb3dbe4e508f,12,8,2,15881,,,0,"Release notes for Barbican actions

Change-Id: I27c3f2ee2719d08908f2eda314798d1a7e877c65
Implements: blueprint support-barbican-actions
",git fetch https://review.opendev.org/openstack/mistral refs/changes/72/281872/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/support-barbican-0ac77ff11bde19d3.yaml'],1,a84df7635a7bff158a1b7dd25133921f9d6d1c94,bp/support-barbican-actions,--- prelude: > Mistral now supports Barbican actions in workbook or workflow ,,4,0
openstack%2Fsahara-dashboard~master~I3ccd8370d40bdf9002ae23cbbbfd655a951969a2,openstack/sahara-dashboard,master,I3ccd8370d40bdf9002ae23cbbbfd655a951969a2,Reorganizing job and cluster guide pages,MERGED,2016-01-20 20:59:13.000000000,2016-02-19 14:32:46.000000000,2016-02-19 14:32:46.000000000,"[{'_account_id': 3}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-01-20 20:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4db405a113fa145156f8f567e632bb26f90f8ef4', 'message': 'Reorganizing job and cluster guide pages\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 2, 'created': '2016-01-22 19:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/daae4f1c4349e2b227dac4ca9231f499eb8770f7', 'message': 'Reorganizing job and cluster guide pages\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 3, 'created': '2016-01-25 20:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/8fdb0cb011a98e5519e58f947eccd9961e9dae08', 'message': 'Reorganizing job and cluster guide pages\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 4, 'created': '2016-01-27 19:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/f7799e1296bf69d650b6e810df869d412abb86c7', 'message': 'Reorganizing job and cluster guide pages\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 5, 'created': '2016-02-05 16:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/583310a3772d61b3c07d3e7a3454af838a5dff8c', 'message': 'Reorganizing job and cluster guide pages\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 6, 'created': '2016-02-08 16:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/593995413a73440fe6728dd462e8d7ee83664fac', 'message': 'Reorganizing job and cluster guide pages\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 7, 'created': '2016-02-08 19:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/44bcf3dc0fe3ad2e9295e0445645021d35d29149', 'message': 'Reorganizing job and cluster guide pages\n\nRemoving the separate guide panels and putting\nthe code for each guide under the cluster and\njobs panels.  Links to the guides still appear\nat the top of the job and cluster tables.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 8, 'created': '2016-02-11 18:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4440f094e4bdea5b284dff3585f80a0127408a61', 'message': 'Reorganizing job and cluster guide pages\n\nRemoving the separate guide panels and putting\nthe code for each guide under the cluster and\njobs panels.  Links to the guides still appear\nat the top of the job and cluster tables.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 9, 'created': '2016-02-12 18:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/7098dce6843284bd0b609905f50b8263e99f48f3', 'message': 'Reorganizing job and cluster guide pages\n\nRemoving the separate guide panels and putting\nthe code for each guide under the cluster and\njobs panels.  Links to the guides still appear\nat the top of the job and cluster tables.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 10, 'created': '2016-02-12 18:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/87bee04cd2a35f2973021592e5e2f4788376f6fc', 'message': 'Reorganizing job and cluster guide pages\n\nRemoving the separate guide panels and putting\nthe code for each guide under the cluster and\njobs panels.  Links to the guides still appear\nat the top of the job and cluster tables.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 11, 'created': '2016-02-15 18:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/b69afae4ce997f7927d89cc9d4ea0c1c48a8e7d6', 'message': 'Reorganizing job and cluster guide pages\n\nRemoving the separate guide panels and putting\nthe code for each guide under the cluster and\njobs panels.  Links to the guides still appear\nat the top of the job and cluster tables.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 12, 'created': '2016-02-15 21:52:33.000000000', 'files': ['sahara_dashboard/content/data_processing/clusters/wizard/views.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/wizard/tests.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_wizard/_job_type_select.html', 'sahara_dashboard/content/data_processing/wizard/panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_ngt_select_help.html', 'sahara_dashboard/content/data_processing/wizard/urls.py', 'sahara_dashboard/content/data_processing/jobs/wizard/tests.py', 'sahara_dashboard/content/data_processing/jobs/wizard/__init__.py', 'sahara_dashboard/content/data_processing/clusters/clusters/tables.py', 'sahara_dashboard/content/data_processing/utils/helpers.py', 'sahara_dashboard/content/data_processing/wizard/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_wizard/_job_type_select_help.html', 'sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_ngt_select.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/ngt_select.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_wizard/job_type_select.html', 'sahara_dashboard/content/data_processing/jobs/urls.py', 'sahara_dashboard/content/data_processing/jobs/wizard/forms.py', 'sahara_dashboard/enabled/_1815_data_processing_wizard_panel.py', 'sahara_dashboard/content/data_processing/clusters/wizard/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/plugin_select.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/cluster_guide.html', 'sahara_dashboard/content/data_processing/jobs/wizard/views.py', 'sahara_dashboard/content/data_processing/jobs/jobs/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_plugin_select.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_wizard/_plugin_select_help.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_wizard/jobex_guide.html', 'sahara_dashboard/content/data_processing/clusters/wizard/tests.py', 'sahara_dashboard/content/data_processing/clusters/wizard/forms.py', 'sahara_dashboard/content/data_processing/clusters/urls.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/625dcfab246f51cd72c60fb11aa1827ba286d392', 'message': 'Reorganizing job and cluster guide pages\n\nRemoving the separate guide panels and putting\nthe code for each guide under the cluster and\njobs panels.  Links to the guides still appear\nat the top of the job and cluster tables.\n\nChange-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2\nPartial-Implements: bp reduce-number-of-panels\n'}]",0,270478,625dcfab246f51cd72c60fb11aa1827ba286d392,33,5,12,8090,,,0,"Reorganizing job and cluster guide pages

Removing the separate guide panels and putting
the code for each guide under the cluster and
jobs panels.  Links to the guides still appear
at the top of the job and cluster tables.

Change-Id: I3ccd8370d40bdf9002ae23cbbbfd655a951969a2
Partial-Implements: bp reduce-number-of-panels
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/78/270478/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/clusters/wizard/views.py', 'sahara_dashboard/content/data_processing/wizard/tests.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.wizard/_job_type_select.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/cluster_guide.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/wizard/panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/_ngt_select.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.wizard/jobex_guide.html', 'sahara_dashboard/content/data_processing/wizard/urls.py', 'sahara_dashboard/content/data_processing/jobs/wizard/tests.py', 'sahara_dashboard/content/data_processing/jobs/wizard/__init__.py', 'sahara_dashboard/content/data_processing/clusters/clusters/tables.py', 'sahara_dashboard/content/data_processing/utils/helpers.py', 'sahara_dashboard/content/data_processing/wizard/views.py', 'sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/_plugin_select.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/ngt_select.html', 'sahara_dashboard/content/data_processing/jobs/urls.py', 'sahara_dashboard/content/data_processing/jobs/wizard/forms.py', 'sahara_dashboard/enabled/_1815_data_processing_wizard_panel.py', 'sahara_dashboard/content/data_processing/clusters/wizard/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/_ngt_select_help.html', 'sahara_dashboard/content/data_processing/jobs/wizard/views.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/_plugin_select_help.html', 'sahara_dashboard/content/data_processing/jobs/jobs/tables.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.wizard/_job_type_select_help.html', 'sahara_dashboard/content/data_processing/clusters/wizard/tests.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_wizard/plugin_select.html', 'sahara_dashboard/content/data_processing/clusters/wizard/forms.py', 'sahara_dashboard/content/data_processing/clusters/urls.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.wizard/job_type_select.html']",32,4db405a113fa145156f8f567e632bb26f90f8ef4,bp/reduce-number-of-panels, {% include 'data_processing.wizard/_job_type_select.html' %}, {% include 'project/data_processing.wizard/_job_type_select.html' %},255,461
openstack%2Fsahara-dashboard~master~Iaa883135befd8306d79b97d5e96c9e46748be4b0,openstack/sahara-dashboard,master,Iaa883135befd8306d79b97d5e96c9e46748be4b0,Reorganizing job-related panels into tabs,MERGED,2016-01-19 17:14:26.000000000,2016-02-19 14:32:21.000000000,2016-02-19 14:32:21.000000000,"[{'_account_id': 3}, {'_account_id': 7132}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-01-19 17:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/aa3a71322b75fdb7cd9303cc98be6d7c3930154b', 'message': 'Reorganizing job-related panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the jobs panel works.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 2, 'created': '2016-01-19 19:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e1c7c474f930fefe1a717e6f4465ebe2f6b04a48', 'message': 'Reorganizing job-related panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the jobs panel works.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 3, 'created': '2016-01-25 19:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/0e40d15d86dc4aea5f3f9e0cf37e40ca505918c6', 'message': 'Reorganizing job-related panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the jobs panel works.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 4, 'created': '2016-01-25 20:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4c9e5da62312d6df65606251ca492b90dd70e72e', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 5, 'created': '2016-01-27 18:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e4848eaa39dcac8975f40bab8d57f513b7e69dbf', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 6, 'created': '2016-02-04 19:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4885a690f9590796482b24e3ccf5e7f0b83fe20f', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 7, 'created': '2016-02-08 16:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/f865bdcd5ef352b962b44def2b0a5b17a6ef3469', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 8, 'created': '2016-02-08 16:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/35ce678f7bf3c5eee55c5fc307c8ab830921e2e9', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 9, 'created': '2016-02-11 18:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4adddd5b55852ebcff9171ee567b2aa6d2eae307', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 10, 'created': '2016-02-12 18:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e57132cc14e43ee002d8b98ef223255b87c549e2', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 11, 'created': '2016-02-12 18:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/7fb841f537c78282e17d5af3626845afd1db66b3', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 12, 'created': '2016-02-15 18:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/29cd6bc166b0b1eceb815df7b2d96eb2e2a23fbb', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 13, 'created': '2016-02-15 21:36:43.000000000', 'files': ['sahara_dashboard/content/data_processing/jobs/job_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_libs_help.html', 'sahara_dashboard/content/data_processing/jobs/job_templates/tabs.py', 'sahara_dashboard/enabled/_1840_data_processing_jobs_panel.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/__init__.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_sources/_create_data_source_help.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_details.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/config_template.html', 'sahara_dashboard/content/data_processing/jobs/data_plugins/tests.py', 'sahara_dashboard/enabled/_1845_data_processing_job_binaries_panel.py', 'sahara_dashboard/content/data_processing/jobs/data_sources/tables.py', 'sahara_dashboard/content/data_processing/job_executions/__init__.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_help.html', 'sahara_dashboard/content/data_processing/data_plugins/urls.py', 'sahara_dashboard/content/data_processing/job_executions/urls.py', 'sahara_dashboard/content/data_processing/jobs/panel.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create_job_binary_help.html', 'sahara_dashboard/content/data_processing/jobs/job_templates/workflows/__init__.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/_launch_job_configure_help.html', 'sahara_dashboard/content/data_processing/jobs/urls.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/_create_job_help.html', 'sahara_dashboard/content/data_processing/jobs/templates/jobs/_details.html', 'sahara_dashboard/content/data_processing/jobs/data_sources/workflows/edit.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_sources/create.html', 'sahara_dashboard/content/data_processing/jobs/data_sources/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/jobs.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/create.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_sources/_details.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_binaries/_create.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/launch.html', 'sahara_dashboard/content/data_processing/jobs/data_sources/__init__.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/forms.py', 'sahara_dashboard/content/data_processing/jobs/data_plugins/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_sources/data_sources.html', 'sahara_dashboard/content/data_processing/jobs/job_templates/__init__.py', 'sahara_dashboard/content/data_processing/jobs/templates/jobs/index.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/job_interface_arguments_template.html', 'sahara_dashboard/content/data_processing/jobs/job_binaries/views.py', 'sahara_dashboard/content/data_processing/jobs/jobs/views.py', 'sahara_dashboard/content/data_processing/jobs/data_sources/workflows/create.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/tables.py', 'sahara_dashboard/content/data_processing/jobs/jobs/tests.py', 'sahara_dashboard/content/data_processing/jobs/tabs.py', 'sahara_dashboard/content/data_processing/jobs/jobs/__init__.py', 'sahara_dashboard/content/data_processing/jobs/data_sources/tests.py', 'sahara_dashboard/content/data_processing/data_plugins/panel.py', 'sahara_dashboard/content/data_processing/job_binaries/panel.py', 'sahara_dashboard/content/data_processing/jobs/jobs/tabs.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/tabs.py', 'sahara_dashboard/content/data_processing/jobs/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_plugins/_details.html', 'sahara_dashboard/enabled/_1860_data_processing_data_plugins_panel.py', 'sahara_dashboard/content/data_processing/jobs/templates/jobs/job_executions.html', 'sahara_dashboard/content/data_processing/jobs/data_sources/workflows/__init__.py', 'sahara_dashboard/content/data_processing/jobs/jobs/tables.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/_details.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/library_template.html', 'sahara_dashboard/content/data_processing/job_binaries/urls.py', 'sahara_dashboard/content/data_processing/jobs/data_plugins/__init__.py', 'sahara_dashboard/content/data_processing/jobs/data_plugins/tables.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/tests.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_plugins/plugins.html', 'sahara_dashboard/enabled/_1850_data_processing_data_sources_panel.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_binaries/create.html', 'sahara_dashboard/enabled/_1825_data_processing_job_executions_panel.py', 'sahara_dashboard/content/data_processing/job_executions/panel.py', 'sahara_dashboard/content/data_processing/data_sources/urls.py', 'sahara_dashboard/content/data_processing/jobs/data_sources/tabs.py', 'sahara_dashboard/content/data_processing/jobs/templates/job_binaries/job_binaries.html', 'sahara_dashboard/content/data_processing/data_sources/panel.py', 'sahara_dashboard/content/data_processing/jobs/data_plugins/tabs.py', 'sahara_dashboard/content/data_processing/jobs/job_templates/tables.py', 'sahara_dashboard/content/data_processing/jobs/job_binaries/tests.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/d35b7b5e170c96c5deee7ac044c383e9686e90ab', 'message': 'Reorganizing job-related panels into tabs\n\nAnother step in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThis patch addresses moving the job-related panels\nunder a single panel with tabs for each object.\n\nChange-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0\nPartial-Implements: bp reduce-number-of-panels\n'}]",0,269778,d35b7b5e170c96c5deee7ac044c383e9686e90ab,35,6,13,8090,,,0,"Reorganizing job-related panels into tabs

Another step in reorganizing the sahara UI to be more
tab oriented rather than death by a thousand panels.
This patch addresses moving the job-related panels
under a single panel with tabs for each object.

Change-Id: Iaa883135befd8306d79b97d5e96c9e46748be4b0
Partial-Implements: bp reduce-number-of-panels
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/78/269778/7 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/_details.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/library_template.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/launch.html', 'sahara_dashboard/enabled/_1840_data_processing_jobs_panel.py', 'sahara_dashboard/content/data_processing/job_executions/tables.py', 'sahara_dashboard/content/data_processing/job_executions/tabs.py', 'sahara_dashboard/content/data_processing/job_executions/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/_create_job_libs_help.html', 'sahara_dashboard/content/data_processing/job_executions/__init__.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/jobs.html', 'sahara_dashboard/content/data_processing/jobs/tests.py', 'sahara_dashboard/content/data_processing/jobs/tabs.py', 'sahara_dashboard/content/data_processing/job_binaries/tests.py', 'sahara_dashboard/content/data_processing/job_executions/urls.py', 'sahara_dashboard/content/data_processing/jobs/panel.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/index.html', 'sahara_dashboard/content/data_processing/jobs/tables.py', 'sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/create.html', 'sahara_dashboard/content/data_processing/job_binaries/__init__.py', 'sahara_dashboard/content/data_processing/job_binaries/forms.py', 'sahara_dashboard/content/data_processing/job_binaries/tabs.py', 'sahara_dashboard/content/data_processing/job_binaries/panel.py', 'sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/create.html', 'sahara_dashboard/content/data_processing/jobs/urls.py', 'sahara_dashboard/content/data_processing/jobs/views.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_executions/_details.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_executions/job_executions.html', 'sahara_dashboard/content/data_processing/jobs/workflows/launch.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/_launch_job_help.html', 'sahara_dashboard/content/data_processing/jobs/workflows/create.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/_launch_job_configure_help.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/_create_job_help.html', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/job_interface_arguments_template.html', 'sahara_dashboard/content/data_processing/job_executions/tests.py', 'sahara_dashboard/content/data_processing/jobs/templates/data_processing.job_templates/config_template.html', 'sahara_dashboard/content/data_processing/jobs/workflows/__init__.py', 'sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html', 'sahara_dashboard/content/data_processing/job_binaries/urls.py', 'sahara_dashboard/content/data_processing/job_binaries/views.py', 'sahara_dashboard/enabled/_1825_data_processing_job_executions_panel.py', 'sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/job_binaries.html', 'sahara_dashboard/content/data_processing/job_executions/panel.py', 'sahara_dashboard/content/data_processing/job_binaries/tables.py', 'sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html']",45,aa3a71322b75fdb7cd9303cc98be6d7c3930154b,bp/reduce-number-of-panels,,"{% load i18n horizon %} <div class=""well""> <p> {% blocktrans %}<b>Important</b>: The name that you give your job binary will be the name used in your job execution. If your binary requires a particular name or extension (ie: "".jar""), be sure to include it here.{% endblocktrans %} </p> <p> {% blocktrans %}Select the storage type for your job binary.{% endblocktrans %} <ul class=""list-bullet""> <li>{% blocktrans %}Data Processing internal database{% endblocktrans %}</li> <li>{% blocktrans %}Swift{% endblocktrans %}</li> </ul> </p> <p> {% blocktrans %}For Data Processing internal job binaries, you may choose from the following:{% endblocktrans %} <ul class=""list-bullet""> <li>{% blocktrans %}Choose an existing file{% endblocktrans %}</li> <li>{% blocktrans %}Upload a new file{% endblocktrans %}</li> <li>{% blocktrans %}Create a script to be uploaded dynamically{% endblocktrans %}</ul> </ul> </p> <p> {% blocktrans %}For Object Store job binaries, you must:{% endblocktrans %} <ul class=""list-bullet""> <li>{% blocktrans %}Enter the URL for the file{% endblocktrans %}</li> <li>{% blocktrans %}Enter the username and password required to access that file{% endblocktrans %}</li> </ul> </p> <p> {% blocktrans %}You may also enter an optional description for your job binary.{% endblocktrans %} </p> </div>",248,2888
openstack%2Fsahara-dashboard~master~Iae4bf4b5127fb29153ec5335070cde7d344e059e,openstack/sahara-dashboard,master,Iae4bf4b5127fb29153ec5335070cde7d344e059e,Reorganizing cluster panels into tabs,MERGED,2016-01-12 20:46:43.000000000,2016-02-19 14:31:48.000000000,2016-02-19 14:31:48.000000000,"[{'_account_id': 3}, {'_account_id': 7132}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-01-12 20:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/ef93ae112e21b8f31e6e492b932ae8c6711116da', 'message': 'Reorganizing cluster panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the clusters panel works (tests\nnotwithstanding for now).\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 2, 'created': '2016-01-13 19:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/ab513e01d7ee9e8dc33caafe61b36b7b833ee249', 'message': 'Reorganizing cluster panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the clusters panel works (tests\nnotwithstanding for now).\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 3, 'created': '2016-01-15 20:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/2658a192a63a35b928ba7f75f72dc5b855402905', 'message': 'Reorganizing cluster panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the clusters panel works.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 4, 'created': '2016-01-15 20:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/c2d94f9f570cc6b6a8fc78036a061b0c99feb3cb', 'message': 'Reorganizing cluster panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the clusters panel works.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 5, 'created': '2016-01-18 16:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/27450d1a6d5b86909db31ed1bff1aa0e430cc1fe', 'message': 'Reorganizing cluster panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the clusters panel works.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 6, 'created': '2016-01-18 16:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/82ec4985590ffd2a33e6c6172463367587cba0f4', 'message': 'Reorganizing cluster panels into tabs\n\nWIP:  This is a very early draft in progress of reorganizing\nthe sahara UI to be more tab oriented rather than death\nby a thousand panels.  Still tons to be done, but for the\nmost part, the clusters panel works.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 7, 'created': '2016-01-25 19:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/9f0ce6f32ad84ec980547818a9c2b27f50f658fa', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 8, 'created': '2016-01-27 17:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/547948c917ff31747716e0e7621b95cd73eb8f5e', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 9, 'created': '2016-02-04 15:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/986bcabff70b0a9b66dcf6c50f3f39caf439458d', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 10, 'created': '2016-02-08 16:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/615680483033dfc3aaf377b0c86bb8dfe3907ab6', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 11, 'created': '2016-02-11 18:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/5aa293ef28b8ce15870f805c423592a85ff8ac82', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 12, 'created': '2016-02-15 18:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/6db4fdb2ee3f0c552d4b74f22975f1f8c61cee4b', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}, {'number': 13, 'created': '2016-02-15 19:05:43.000000000', 'files': ['sahara_dashboard/content/data_processing/clusters/clusters/views.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/configure.html', 'sahara_dashboard/content/data_processing/clusters/clusters/tabs.py', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_create_general_help.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/views.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tests.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/edit_tags.html', 'sahara_dashboard/content/data_processing/clusters/clusters/tests.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_cluster_template_configs_details.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/__init__.py', 'sahara_dashboard/content/data_processing/jobs/workflows/launch.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_nodegroups_details.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/upload_file.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/tables.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/copy.py', 'sahara_dashboard/content/data_processing/clusters/clusters/__init__.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_details.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/copy.py', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/create_cluster.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_details.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/image_registry.html', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_fields_help.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_nodegroups_details.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py', 'sahara_dashboard/content/data_processing/clusters/urls.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/edit.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_instances_details.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/_edit_tags.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_details.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/_list_tags.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/_help.html', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/create.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/tests.py', 'sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html', 'sahara_dashboard/content/data_processing/data_image_registry/urls.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/__init__.py', 'sahara_dashboard/enabled/_1830_data_processing_cluster_templates_panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/_register_image.html', 'sahara_dashboard/content/data_processing/nodegroup_templates/urls.py', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/tabs.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/register_image.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py', 'sahara_dashboard/content/data_processing/tabs.py', 'sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/image_registry.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_cluster_configs_details.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_upload_file.html', 'sahara_dashboard/enabled/_1820_data_processing_clusters_panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/index.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/create.html', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/configure.html', 'sahara_dashboard/enabled/_1855_data_processing_data_image_registry_panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/configure.html', 'sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/update.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_create_general_help.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/cluster_node_groups_template.html', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/nodegroup_templates.html', 'sahara_dashboard/content/data_processing/cluster_templates/urls.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/update.html', 'sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/create.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tests.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_rich_status.html', 'sahara_dashboard/content/data_processing/nodegroup_templates/panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/create.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_configure_general_help.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_create_cluster.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_event_log.html', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_create_general_help.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/forms.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/clusters.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/scale.html', 'sahara_dashboard/content/data_processing/clusters/templates/nodegroup_templates/_service_confs.html', 'sahara_dashboard/content/data_processing/utils/workflow_helpers.py', 'sahara_dashboard/enabled/_1835_data_processing_nodegroup_templates_panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/_configure_general_help.html', 'sahara_dashboard/content/data_processing/clusters/clusters/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/cluster_templates/cluster_templates.html', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_configure_general_help.html', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py', 'sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html', 'sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html', 'sahara_dashboard/content/data_processing/clusters/views.py', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/__init__.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/forms.py', 'sahara_dashboard/content/data_processing/data_image_registry/panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_image_registry/_tag_form.html', 'sahara_dashboard/content/data_processing/cluster_templates/panel.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/5aa8b83bc90dc5861215ffb71aecb6588399997b', 'message': 'Reorganizing cluster panels into tabs\n\nFirst patch in reorganizing the sahara UI to be more\ntab oriented rather than death by a thousand panels.\nThere are other patches that will complete the work,\n but this patch addresses the cluster-oriented panels\n by moving them under a single panel named Clusters.\n\nChange-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e\nPartial-Implements: bp reduce-number-of-panels\n'}]",0,266566,5aa8b83bc90dc5861215ffb71aecb6588399997b,43,6,13,8090,,,0,"Reorganizing cluster panels into tabs

First patch in reorganizing the sahara UI to be more
tab oriented rather than death by a thousand panels.
There are other patches that will complete the work,
 but this patch addresses the cluster-oriented panels
 by moving them under a single panel named Clusters.

Change-Id: Iae4bf4b5127fb29153ec5335070cde7d344e059e
Partial-Implements: bp reduce-number-of-panels
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/66/266566/12 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/clusters/clusters/views.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/_details.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/configure.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/_upload_file.html', 'sahara_dashboard/content/data_processing/clusters/clusters/tabs.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/urls.py', 'sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/create.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/_create_general_help.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/views.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/_configure_general_help.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/_details.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tests.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tabs.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/views.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/_nodegroups_details.html', 'sahara_dashboard/content/data_processing/clusters/clusters/tests.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/_help.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/__init__.py', 'sahara_dashboard/content/data_processing/jobs/workflows/launch.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/cluster_node_groups_template.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/tables.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/copy.py', 'sahara_dashboard/content/data_processing/clusters/clusters/__init__.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/views.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/_fields_help.html', 'sahara_dashboard/content/data_processing/cluster_templates/urls.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/copy.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tests.py', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/scale.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/tables.py', 'sahara_dashboard/content/data_processing/nodegroup_templates/panel.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/create.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/_tag_form.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/register_image.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/_edit_tags.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tables.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/workflows/edit.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/index.html', 'sahara_dashboard/content/data_processing/clusters/urls.py', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/workflows/edit.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/nodegroup_templates.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/cluster_templates.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/configure.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/forms.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/_configure_general_help.html', 'sahara_dashboard/content/data_processing/utils/workflow_helpers.py', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/_list_tags.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/urls.py', 'sahara_dashboard/content/data_processing/clusters/clusters/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/_register_image.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/upload_file.html', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/tests.py', 'sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/create.py', 'sahara_dashboard/content/data_processing/clusters/tabs.py', 'sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/image_registry.html', 'sahara_dashboard/content/data_processing/clusters/views.py', 'sahara_dashboard/content/data_processing/nodegroup_templates/urls.py', 'sahara_dashboard/content/data_processing/clusters/data_image_registry/tabs.py', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/urls.py', 'sahara_dashboard/content/data_processing/clusters/clusters/workflows/__init__.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.cluster_templates/_create_general_help.html', 'sahara_dashboard/content/data_processing/clusters/nodegroup_templates/tabs.py', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.data_image_registry/edit_tags.html', 'sahara_dashboard/content/data_processing/clusters/templates/data_processing.nodegroup_templates/_service_confs.html', 'sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/image_registry.html', 'sahara_dashboard/content/data_processing/clusters/cluster_templates/forms.py', 'sahara_dashboard/content/data_processing/data_image_registry/panel.py', 'sahara_dashboard/content/data_processing/cluster_templates/panel.py']",77,ef93ae112e21b8f31e6e492b932ae8c6711116da,bp/reduce-number-of-panels,,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from django.utils.translation import ugettext_lazy as _ import horizon from openstack_dashboard.dashboards.project import dashboard class ClusterTemplatesPanel(horizon.Panel): name = _(""Cluster Templates"") slug = 'data_processing.cluster_templates' permissions = (('openstack.services.data-processing', 'openstack.services.data_processing'),) dashboard.Project.register(ClusterTemplatesPanel) ",1058,814
openstack%2Fsalt-formula-heat~master~Id806232f83641f1f7773d38414a53236f36f7d42,openstack/salt-formula-heat,master,Id806232f83641f1f7773d38414a53236f36f7d42,refactor heka config,MERGED,2016-02-19 14:06:26.000000000,2016-02-19 14:28:43.000000000,2016-02-19 14:28:43.000000000,"[{'_account_id': 3}, {'_account_id': 18092}]","[{'number': 1, 'created': '2016-02-19 14:06:26.000000000', 'files': ['heat/files/heka.toml'], 'web_link': 'https://opendev.org/openstack/salt-formula-heat/commit/441d0892708721b3249472815c796fd0c300c8f4', 'message': 'refactor heka config\n\nChange-Id: Id806232f83641f1f7773d38414a53236f36f7d42\n'}]",0,282346,441d0892708721b3249472815c796fd0c300c8f4,6,2,1,20430,,,0,"refactor heka config

Change-Id: Id806232f83641f1f7773d38414a53236f36f7d42
",git fetch https://review.opendev.org/openstack/salt-formula-heat refs/changes/46/282346/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/files/heka.toml'],1,441d0892708721b3249472815c796fd0c300c8f4,heka_refactor,"file_match = '(?P<Service>.+)\.log\.?(?P<Seq>\d*)$' differentiator = [""'heat','_','Service'""]decoder = ""openstack"" [openstack]","file_match = 'heat-engine\.log\.?(?P<Index>\d+)?(.gz)?'decoder = ""heat"" oldest_duration = ""168h"" [heat]",6,4
openstack%2Ffuel-web~master~Id676658a0cb08237e099b7c22ba5b416c57c13a9,openstack/fuel-web,master,Id676658a0cb08237e099b7c22ba5b416c57c13a9,Delete data about images after env removal,MERGED,2016-01-26 14:52:14.000000000,2016-02-19 14:20:02.000000000,2016-02-19 13:53:47.000000000,"[{'_account_id': 3}, {'_account_id': 8003}, {'_account_id': 8392}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10665}, {'_account_id': 10808}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 13505}, {'_account_id': 14543}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-01-26 14:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/66a94e125bc77248a2a83a3383a5a7d5f5a0679d', 'message': 'Adds removing yaml\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 2, 'created': '2016-01-27 16:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/010258a59bc2bffc5ba770dc367daa02405251a8', 'message': 'Adds removing yaml\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 3, 'created': '2016-02-03 13:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/292e492db01946a43bc803c8ca0311464279fad2', 'message': 'Adds removing yaml\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 4, 'created': '2016-02-04 16:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/255038a5a07967280c0ee6bf46e9810975b811dd', 'message': 'Delete data about images after env removal\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 5, 'created': '2016-02-08 16:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ef5dda01afd80e4c344e45e5a5de3a8ea7209cc7', 'message': 'Delete data about images after env removal\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 6, 'created': '2016-02-09 11:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5aff5037d58982dd8d19ddda42506223fecd36bf', 'message': 'Delete data about images after env removal\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 7, 'created': '2016-02-18 14:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3b762c64d4c1454f249c40cba441a7befc3026d2', 'message': 'Delete data about images after env removal\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 8, 'created': '2016-02-19 10:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/02963a673e7fcd8d47e1c9fee88581969a056360', 'message': 'Delete data about images after env removal\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}, {'number': 9, 'created': '2016-02-19 12:26:36.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/unit/test_task.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/73ab06a5a9465afc90c2ef2f9dc67a289e53646d', 'message': 'Delete data about images after env removal\n\nAdds removing yaml with data about target images\nafter environment removal\n\nChange-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9\nCloses-Bug: #1492243\n'}]",15,272567,73ab06a5a9465afc90c2ef2f9dc67a289e53646d,91,14,9,10665,,,0,"Delete data about images after env removal

Adds removing yaml with data about target images
after environment removal

Change-Id: Id676658a0cb08237e099b7c22ba5b416c57c13a9
Closes-Bug: #1492243
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/67/272567/9 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/unit/test_task.py']",2,66a94e125bc77248a2a83a3383a5a7d5f5a0679d,bug/1492243," self.assertIn('/fake/path/fake.yaml', rm_cmd)",,12,3
openstack%2Fgnocchi~master~I7283132fb1f71496b134db11255f1bb8609e2b25,openstack/gnocchi,master,I7283132fb1f71496b134db11255f1bb8609e2b25,Allows to use cradox with ceph storage,MERGED,2016-02-12 10:05:51.000000000,2016-02-19 14:18:14.000000000,2016-02-19 14:18:14.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-02-12 10:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e330e5c06a819356ea98c3b15de37d2ddd3ff39a', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 2, 'created': '2016-02-12 10:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/de3fede9b83d8fc745eba38dd412b2a82df769b7', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 3, 'created': '2016-02-12 11:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/af4d9203148957c036871cf1993cf9f4787a4a69', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 4, 'created': '2016-02-12 12:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/dca38b36af424aaa6c40984bad8369a7434582eb', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 5, 'created': '2016-02-15 08:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/dfe00bce816c175da8de446835133cd2d14679dc', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 6, 'created': '2016-02-15 09:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/bf10fc5d0cdfe843b86f3cef9db8e46ac52df7d5', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 7, 'created': '2016-02-15 09:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1314d88fdc0333e92e8beba184175cd5a4ed7e6e', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 8, 'created': '2016-02-15 10:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/11191a3410c38c303d00e33f0ad1e710b0180b60', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 9, 'created': '2016-02-15 10:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9686de38a792d9ce2bee372fc4678d05b4a6f365', 'message': 'POC: cradox tests\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 10, 'created': '2016-02-16 07:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8351b577c1688ce5be515d820314f3cc99115b51', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 11, 'created': '2016-02-16 08:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/76019b3198ccc3604717ea6e0fa8842ff22fcc44', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 12, 'created': '2016-02-16 09:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b2510f51a1a3965bbfa61c3e9fe52d63063f1bf6', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 13, 'created': '2016-02-16 11:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/37899f52c707b7edaac599da34a985898d565f93', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 14, 'created': '2016-02-16 11:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/82fe52f04524858651b7890c0940e276c05a6542', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 15, 'created': '2016-02-16 12:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/32ede01109fb9ee583c2d76afb642bfd0c89f36e', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\n'}, {'number': 16, 'created': '2016-02-16 18:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/66201e6e31d7846f743f4255ace25d88f2b73d7d', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\nSigned-off-by: Mehdi Abaakouk <sileht@redhat.com>\n'}, {'number': 17, 'created': '2016-02-17 10:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/03d496521225d50901bc0dded9bc35964833f91e', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\nSigned-off-by: Mehdi Abaakouk <sileht@redhat.com>\n'}, {'number': 18, 'created': '2016-02-18 07:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/50b9111e6491424e98e22faf4123aeca17f6b590', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\nSigned-off-by: Mehdi Abaakouk <sileht@redhat.com>\n'}, {'number': 19, 'created': '2016-02-18 09:56:30.000000000', 'files': ['gnocchi/storage/ceph.py', 'doc/source/configuration.rst', 'devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e8e1274da685d5f1dfdcd6f8e6e018f338bd583f', 'message': 'Allows to use cradox with ceph storage\n\nChange-Id: I7283132fb1f71496b134db11255f1bb8609e2b25\nSigned-off-by: Mehdi Abaakouk <sileht@redhat.com>\n'}]",28,279448,e8e1274da685d5f1dfdcd6f8e6e018f338bd583f,57,4,19,2813,,,0,"Allows to use cradox with ceph storage

Change-Id: I7283132fb1f71496b134db11255f1bb8609e2b25
Signed-off-by: Mehdi Abaakouk <sileht@redhat.com>
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/48/279448/18 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/ceph.py', 'devstack/plugin.sh']",2,e330e5c06a819356ea98c3b15de37d2ddd3ff39a,sileht/ceph-test-batch," # We don't use setup_package because we don't follow openstack/requirementsc if [[ ""$GNOCCHI_STORAGE_BACKEND"" = 'ceph' ]] ; then install_package cypthon install_package librados-dev sudo -H pip install -e ""git+https://github.com/sileht/pycradox.git#egg=cradox"" ", # We don't use setup_package because we don't follow openstack/requirements,10,5
openstack%2Foslo.messaging~master~I207b7a7e82cbd7e5848231115b3577be7b600638,openstack/oslo.messaging,master,I207b7a7e82cbd7e5848231115b3577be7b600638,.testr.conf: revert workaround of testtools bug,MERGED,2016-02-17 10:35:02.000000000,2016-02-19 14:14:15.000000000,2016-02-19 14:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 8601}]","[{'number': 1, 'created': '2016-02-17 10:35:02.000000000', 'files': ['.testr.conf'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e384dca5a1af89daa3e72476b2cd35d043d3a8f7', 'message': '.testr.conf: revert workaround of testtools bug\n\nRevert the change I6507e693fc929e03884f933bbda241f744d3a7c0. The\ntesttools bug was fixed, the ""| cat"" workaround is no more needed.\n\nFix for subunit (for testtools), workaround the eventlet bug:\nhttps://github.com/testing-cabal/subunit/pull/14\n\nFix of the root cause in eventlet:\nhttps://github.com/eventlet/eventlet/issues/248\n\nThe bug was limited to Python 3 and related to non-blocking stdout.\n\nChange-Id: I207b7a7e82cbd7e5848231115b3577be7b600638\nRelated-Bug: 1492505\n'}]",0,281178,e384dca5a1af89daa3e72476b2cd35d043d3a8f7,7,3,1,9107,,,0,".testr.conf: revert workaround of testtools bug

Revert the change I6507e693fc929e03884f933bbda241f744d3a7c0. The
testtools bug was fixed, the ""| cat"" workaround is no more needed.

Fix for subunit (for testtools), workaround the eventlet bug:
https://github.com/testing-cabal/subunit/pull/14

Fix of the root cause in eventlet:
https://github.com/eventlet/eventlet/issues/248

The bug was limited to Python 3 and related to non-blocking stdout.

Change-Id: I207b7a7e82cbd7e5848231115b3577be7b600638
Related-Bug: 1492505
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/78/281178/1 && git format-patch -1 --stdout FETCH_HEAD,['.testr.conf'],1,e384dca5a1af89daa3e72476b2cd35d043d3a8f7,bug/1492505,test_command=OS_STDOUT_CAPTURE=${OS_STDOUT_CAPTURE:-1} OS_STDERR_CAPTURE=${OS_STDERR_CAPTURE:-1} OS_TEST_TIMEOUT=${OS_TEST_TIMEOUT:-60} ${PYTHON:-python} -m subunit.run discover -t ./ . $LISTOPT $IDOPTION,test_command=OS_STDOUT_CAPTURE=${OS_STDOUT_CAPTURE:-1} OS_STDERR_CAPTURE=${OS_STDERR_CAPTURE:-1} OS_TEST_TIMEOUT=${OS_TEST_TIMEOUT:-60} ${PYTHON:-python} -m subunit.run discover -t ./ . $LISTOPT $IDOPTION | cat,1,1
openstack%2Foslo.messaging~stable%2Fliberty~I762265f23084a95f2d24cb434bad7d9556d4edd5,openstack/oslo.messaging,stable/liberty,I762265f23084a95f2d24cb434bad7d9556d4edd5,Fix kombu accept different TTL since version 3.0.25,MERGED,2016-02-19 05:20:45.000000000,2016-02-19 14:14:13.000000000,2016-02-19 14:14:13.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-19 05:20:45.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ee46dda59f605f721c9b31641d1950c454856131', 'message': 'Fix kombu accept different TTL since version 3.0.25\n\nkombu accept TTL as seconds instead of millisecond since version 3.0.25,\nWe remove TTL conversion in commit d49ddc3b9828f097d5bb39bca0381386a9de7762,\nwhich is valid only when kombu >=3.0.25, so need do conversion according\nto kombu version.\n\nNote: Remove this workaround when all supported branches with\nrequirement kombu >=3.0.25\n\nCloses-Bug: #1531148\nChange-Id: I762265f23084a95f2d24cb434bad7d9556d4edd5\n(cherry picked from commit 9cfaf50c45cf82f102f157655359e9705dc5733c)\n'}]",0,282175,ee46dda59f605f721c9b31641d1950c454856131,7,3,1,9796,,,0,"Fix kombu accept different TTL since version 3.0.25

kombu accept TTL as seconds instead of millisecond since version 3.0.25,
We remove TTL conversion in commit d49ddc3b9828f097d5bb39bca0381386a9de7762,
which is valid only when kombu >=3.0.25, so need do conversion according
to kombu version.

Note: Remove this workaround when all supported branches with
requirement kombu >=3.0.25

Closes-Bug: #1531148
Change-Id: I762265f23084a95f2d24cb434bad7d9556d4edd5
(cherry picked from commit 9cfaf50c45cf82f102f157655359e9705dc5733c)
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/75/282175/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,ee46dda59f605f721c9b31641d1950c454856131,bug/1531148,"from oslo_utils import versionutils import pkg_resources def _get_expiration(self, timeout): # NOTE(gcb) kombu accept TTL as seconds instead of millisecond since # version 3.0.25, so do conversion according to kombu version. # TODO(gcb) remove this workaround when all supported branches # with requirement kombu >=3.0.25 if timeout is not None: kombu_version = pkg_resources.get_distribution('kombu').version if not versionutils.is_compatible('3.0.25', kombu_version): timeout = int(timeout * 1000) return timeout producer.publish(msg, expiration=self._get_expiration(timeout))"," producer.publish(msg, expiration=timeout)",27,2
openstack%2Ffuel-qa~master~I97d1934342efc43aeafa3046d9e79059a6dc8541,openstack/fuel-qa,master,I97d1934342efc43aeafa3046d9e79059a6dc8541,The number of restarts for repetitive_restart test was added as parameter,MERGED,2016-02-19 13:20:36.000000000,2016-02-19 14:11:08.000000000,2016-02-19 14:11:08.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2016-02-19 13:20:36.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_repetitive_restart.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/92e5df5d56c181ca30f9aa6b3c86f938bd9381bd', 'message': 'The number of restarts for repetitive_restart test was added as\nparameter\n\nChange-Id: I97d1934342efc43aeafa3046d9e79059a6dc8541\nCloses-Bug: #1547502\n'}]",0,282329,92e5df5d56c181ca30f9aa6b3c86f938bd9381bd,10,4,1,17861,,,0,"The number of restarts for repetitive_restart test was added as
parameter

Change-Id: I97d1934342efc43aeafa3046d9e79059a6dc8541
Closes-Bug: #1547502
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/29/282329/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_repetitive_restart.py', 'fuelweb_test/settings.py']",2,92e5df5d56c181ca30f9aa6b3c86f938bd9381bd,,"# The number of cold restarts # in the 'repetitive_restart' test group RESTART_COUNT = os.environ.get(""RESTART_COUNT"", 10) ",,5,1
openstack%2Fceilometer~master~Ia0d3a30a90bd7f21344081233ef16ff0936d5475,openstack/ceilometer,master,Ia0d3a30a90bd7f21344081233ef16ff0936d5475,Alphabetized setup.cfg for cleanliness,ABANDONED,2016-02-19 10:52:36.000000000,2016-02-19 14:10:55.000000000,,"[{'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-02-19 10:52:36.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2bbb7f0630d7121b7a3e4f703a22ee230fa34652', 'message': 'Alphabetized setup.cfg for cleanliness\n\nChange-Id: Ia0d3a30a90bd7f21344081233ef16ff0936d5475\n'}]",0,282274,2bbb7f0630d7121b7a3e4f703a22ee230fa34652,5,3,1,19963,,,0,"Alphabetized setup.cfg for cleanliness

Change-Id: Ia0d3a30a90bd7f21344081233ef16ff0936d5475
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/74/282274/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2bbb7f0630d7121b7a3e4f703a22ee230fa34652,, dns.domain.exists = ceilometer.dns.notifications:DomainExists instance = ceilometer.compute.notifications.instance:Instance instance_scheduled = ceilometer.compute.notifications.instance:InstanceScheduled meter = ceilometer.meter.notifications:ProcessMeterNotifications network = ceilometer.network.notifications:Network port = ceilometer.network.notifications:Port router = ceilometer.network.notifications:Router subnet = ceilometer.network.notifications:Subnet _sample = ceilometer.telemetry.notifications:TelemetryIpc fw_services = ceilometer.network.services.discovery:FirewallDiscovery fw_policy = ceilometer.network.services.discovery:FirewallPolicyDiscovery ipsec_connections = ceilometer.network.services.discovery:IPSecConnectionsDiscovery local_instances = ceilometer.compute.discovery:InstanceDiscovery tenant = ceilometer.agent.discovery.tenant:TenantDiscovery vpn_services = ceilometer.network.services.discovery:VPNServicesDiscovery cpu = ceilometer.compute.pollsters.cpu:CPUPollster cpu_util = ceilometer.compute.pollsters.cpu:CPUUtilPollster instance = ceilometer.compute.pollsters.instance:InstancePollster memory.usage = ceilometer.compute.pollsters.memory:MemoryUsagePollster memory.resident = ceilometer.compute.pollsters.memory:MemoryResidentPollster network.incoming.bytes = ceilometer.compute.pollsters.net:IncomingBytesPollster network.incoming.packets = ceilometer.compute.pollsters.net:IncomingPacketsPollster network.outgoing.bytes = ceilometer.compute.pollsters.net:OutgoingBytesPollster network.outgoing.packets = ceilometer.compute.pollsters.net:OutgoingPacketsPollster network.incoming.bytes.rate = ceilometer.compute.pollsters.net:IncomingBytesRatePollster network.outgoing.bytes.rate = ceilometer.compute.pollsters.net:OutgoingBytesRatePollster energy = ceilometer.energy.kwapi:EnergyPollster network.services.lb.pool = ceilometer.network.services.lbaas:LBPoolPollster network.services.lb.vip = ceilometer.network.services.lbaas:LBVipPollster network.services.lb.member = ceilometer.network.services.lbaas:LBMemberPollster network.services.lb.health_monitor = ceilometer.network.services.lbaas:LBHealthMonitorPollster network.services.lb.total.connections = ceilometer.network.services.lbaas:LBTotalConnectionsPollster network.services.lb.active.connections = ceilometer.network.services.lbaas:LBActiveConnectionsPollster network.services.lb.incoming.bytes = ceilometer.network.services.lbaas:LBBytesInPollster network.services.lb.outgoing.bytes = ceilometer.network.services.lbaas:LBBytesOutPollster network.services.vpn = ceilometer.network.services.vpnaas:VPNServicesPollster network.services.vpn.connections = ceilometer.network.services.vpnaas:IPSecConnectionsPollster network.services.firewall = ceilometer.network.services.fwaas:FirewallPollster network.services.firewall.policy = ceilometer.network.services.fwaas:FirewallPolicyPollster power = ceilometer.energy.kwapi:PowerPollster db2 = ceilometer.event.storage.impl_db2:Connection hbase = ceilometer.event.storage.impl_hbase:Connection db2 = ceilometer.storage.impl_db2:Connection hbase = ceilometer.storage.impl_hbase:Connection libvirt = ceilometer.compute.virt.libvirt.inspector:LibvirtInspector delta = ceilometer.transformer.conversions:DeltaTransformer rate_of_change = ceilometer.transformer.conversions:RateOfChangeTransformer unit_conversion = ceilometer.transformer.conversions:ScalingTransformer file = ceilometer.publisher.file:FilePublisher notifier = ceilometer.publisher.messaging:SampleNotifierPublisher test = ceilometer.publisher.test:TestPublisher udp = ceilometer.publisher.udp:UDPPublisher notifier = ceilometer.publisher.messaging:EventNotifierPublisher test = ceilometer.publisher.test:TestPublisher split = ceilometer.event.trait_plugins:SplitterTraitPlugin http = ceilometer.dispatcher.http:HttpDispatcherwarnerrors = trueoutput_dir = ceilometer/locale , instance = ceilometer.compute.notifications.instance:Instance instance_scheduled = ceilometer.compute.notifications.instance:InstanceScheduled network = ceilometer.network.notifications:Network subnet = ceilometer.network.notifications:Subnet port = ceilometer.network.notifications:Port router = ceilometer.network.notifications:Router _sample = ceilometer.telemetry.notifications:TelemetryIpc dns.domain.exists = ceilometer.dns.notifications:DomainExists meter = ceilometer.meter.notifications:ProcessMeterNotifications local_instances = ceilometer.compute.discovery:InstanceDiscovery tenant = ceilometer.agent.discovery.tenant:TenantDiscovery vpn_services = ceilometer.network.services.discovery:VPNServicesDiscovery ipsec_connections = ceilometer.network.services.discovery:IPSecConnectionsDiscovery fw_services = ceilometer.network.services.discovery:FirewallDiscovery fw_policy = ceilometer.network.services.discovery:FirewallPolicyDiscovery cpu = ceilometer.compute.pollsters.cpu:CPUPollster cpu_util = ceilometer.compute.pollsters.cpu:CPUUtilPollster network.incoming.bytes = ceilometer.compute.pollsters.net:IncomingBytesPollster network.incoming.packets = ceilometer.compute.pollsters.net:IncomingPacketsPollster network.outgoing.bytes = ceilometer.compute.pollsters.net:OutgoingBytesPollster network.outgoing.packets = ceilometer.compute.pollsters.net:OutgoingPacketsPollster network.incoming.bytes.rate = ceilometer.compute.pollsters.net:IncomingBytesRatePollster network.outgoing.bytes.rate = ceilometer.compute.pollsters.net:OutgoingBytesRatePollster instance = ceilometer.compute.pollsters.instance:InstancePollster memory.usage = ceilometer.compute.pollsters.memory:MemoryUsagePollster memory.resident = ceilometer.compute.pollsters.memory:MemoryResidentPollster energy = ceilometer.energy.kwapi:EnergyPollster power = ceilometer.energy.kwapi:PowerPollster network.services.lb.pool = ceilometer.network.services.lbaas:LBPoolPollster network.services.lb.vip = ceilometer.network.services.lbaas:LBVipPollster network.services.lb.member = ceilometer.network.services.lbaas:LBMemberPollster network.services.lb.health_monitor = ceilometer.network.services.lbaas:LBHealthMonitorPollster network.services.lb.total.connections = ceilometer.network.services.lbaas:LBTotalConnectionsPollster network.services.lb.active.connections = ceilometer.network.services.lbaas:LBActiveConnectionsPollster network.services.lb.incoming.bytes = ceilometer.network.services.lbaas:LBBytesInPollster network.services.lb.outgoing.bytes = ceilometer.network.services.lbaas:LBBytesOutPollster network.services.vpn = ceilometer.network.services.vpnaas:VPNServicesPollster network.services.vpn.connections = ceilometer.network.services.vpnaas:IPSecConnectionsPollster network.services.firewall = ceilometer.network.services.fwaas:FirewallPollster network.services.firewall.policy = ceilometer.network.services.fwaas:FirewallPolicyPollster hbase = ceilometer.event.storage.impl_hbase:Connection db2 = ceilometer.event.storage.impl_db2:Connection hbase = ceilometer.storage.impl_hbase:Connection db2 = ceilometer.storage.impl_db2:Connection libvirt = ceilometer.compute.virt.libvirt.inspector:LibvirtInspector delta = ceilometer.transformer.conversions:DeltaTransformer unit_conversion = ceilometer.transformer.conversions:ScalingTransformer rate_of_change = ceilometer.transformer.conversions:RateOfChangeTransformer test = ceilometer.publisher.test:TestPublisher notifier = ceilometer.publisher.messaging:SampleNotifierPublisher udp = ceilometer.publisher.udp:UDPPublisher file = ceilometer.publisher.file:FilePublisher test = ceilometer.publisher.test:TestPublisher notifier = ceilometer.publisher.messaging:EventNotifierPublisher split = ceilometer.event.trait_plugins:SplitterTraitPlugin http = ceilometer.dispatcher.http:HttpDispatcherwarnerrors = trueoutput_dir = ceilometer/locale,60,58
openstack%2Fsenlin~master~I8be16377875bbbbce528fe9dc8e0ec27c4fdae53,openstack/senlin,master,I8be16377875bbbbce528fe9dc8e0ec27c4fdae53,Validate 'sort' parameter for clusters in engine,MERGED,2016-02-19 08:35:22.000000000,2016-02-19 14:10:45.000000000,2016-02-19 14:10:45.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 08:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/160cf0aa7a01bea179bd58c47f0e5f327604598c', 'message': ""Validate 'sort' parameter for clusters in engine\n\nThis adds validation to the 'sort' parameter when listing clusters at\nengline layer.\n\nChange-Id: I8be16377875bbbbce528fe9dc8e0ec27c4fdae53\n""}, {'number': 2, 'created': '2016-02-19 13:56:19.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/cbe32bf343b7a0a3e7a13a1b56edb05b328def92', 'message': ""Validate 'sort' parameter for clusters in engine\n\nThis adds validation to the 'sort' parameter when listing clusters at\nengline layer.\n\nChange-Id: I8be16377875bbbbce528fe9dc8e0ec27c4fdae53\n""}]",0,282228,cbe32bf343b7a0a3e7a13a1b56edb05b328def92,9,2,2,8246,,,0,"Validate 'sort' parameter for clusters in engine

This adds validation to the 'sort' parameter when listing clusters at
engline layer.

Change-Id: I8be16377875bbbbce528fe9dc8e0ec27c4fdae53
",git fetch https://review.opendev.org/openstack/senlin refs/changes/28/282228/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py']",2,160cf0aa7a01bea179bd58c47f0e5f327604598c,cluster-sort," filters={'foo': 'bar'}, sort='name:asc', filters={'foo': 'bar'}, sort='name:asc', self.ctx, sort='crazykey') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) ex = self.assertRaises(rpc.ExpectedException, self.eng.cluster_list,"," filters={'foo': 'bar'}, sort='k:asc', filters={'foo': 'bar'}, sort='k:asc',",9,2
openstack%2Faodh~master~I5769233067995158aa864d5f400de051241f1455,openstack/aodh,master,I5769233067995158aa864d5f400de051241f1455,Alphabetized setup.cfg for cleanliness,ABANDONED,2016-02-19 11:08:54.000000000,2016-02-19 14:10:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2016-02-19 11:08:54.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/aodh/commit/eac01f145dff068f82524776ef6ca446df6587d2', 'message': 'Alphabetized setup.cfg for cleanliness\n\neach line is sorted by alphabetical order.\n\nChange-Id: I5769233067995158aa864d5f400de051241f1455\n'}]",0,282282,eac01f145dff068f82524776ef6ca446df6587d2,5,3,1,19963,,,0,"Alphabetized setup.cfg for cleanliness

each line is sorted by alphabetical order.

Change-Id: I5769233067995158aa864d5f400de051241f1455
",git fetch https://review.opendev.org/openstack/aodh refs/changes/82/282282/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,eac01f145dff068f82524776ef6ca446df6587d2,," SQLAlchemy<1.1.0,>=0.9.7 SQLAlchemy<1.1.0,>=0.9.7 gabbi>=0.12.0 # Apache-2.0 overtest>=0.7.0 oslotest>=1.5.1 # Apache-2.0 python-subunit>=0.0.18 hbase = aodh.storage.impl_hbase:Connection event = aodh.api.controllers.v2.alarm_rules.event:AlarmEventRule threshold = aodh.api.controllers.v2.alarm_rules.threshold:AlarmThresholdRule threshold = aodh.evaluator.threshold:ThresholdEvaluator log = aodh.notifier.log:LogAlarmNotifier test = aodh.notifier.test:TestAlarmNotifierwarnerrors = trueoutput_dir = aodh/locale"," SQLAlchemy<1.1.0,>=0.9.7 SQLAlchemy<1.1.0,>=0.9.7 overtest>=0.7.0 oslotest>=1.5.1 # Apache-2.0 gabbi>=0.12.0 # Apache-2.0 python-subunit>=0.0.18 hbase = aodh.storage.impl_hbase:Connection threshold = aodh.api.controllers.v2.alarm_rules.threshold:AlarmThresholdRule event = aodh.api.controllers.v2.alarm_rules.event:AlarmEventRule threshold = aodh.evaluator.threshold:ThresholdEvaluator log = aodh.notifier.log:LogAlarmNotifier test = aodh.notifier.test:TestAlarmNotifierwarnerrors = trueoutput_dir = aodh/locale",16,14
openstack%2Fsenlin~master~Ibb5667a728d447e326dea3ff4ba14f7f2cb0e8be,openstack/senlin,master,Ibb5667a728d447e326dea3ff4ba14f7f2cb0e8be,Fix a bug in cluster recover action,MERGED,2016-02-19 10:42:11.000000000,2016-02-19 14:10:19.000000000,2016-02-19 14:10:19.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 10:42:11.000000000', 'files': ['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/215768d9a42ab7adfac02a47897849e4bb28b435', 'message': 'Fix a bug in cluster recover action\n\nThis patch fixes a bug in cluster recover action.\n\nChange-Id: Ibb5667a728d447e326dea3ff4ba14f7f2cb0e8be\nCloses-Bug: #1547433\n'}]",0,282267,215768d9a42ab7adfac02a47897849e4bb28b435,11,2,1,11034,,,0,"Fix a bug in cluster recover action

This patch fixes a bug in cluster recover action.

Change-Id: Ibb5667a728d447e326dea3ff4ba14f7f2cb0e8be
Closes-Bug: #1547433
",git fetch https://review.opendev.org/openstack/senlin refs/changes/67/282267/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py']",2,215768d9a42ab7adfac02a47897849e4bb28b435,bug/1545549/functional-test-cluster-check-recover," mock_wait.return_value = (action.RES_OK, 'All dependents ended with success') self.assertEqual('All dependents ended with success', res_msg) def test_do_recover_all_nodes_active(self, mock_load): cluster = mock.Mock() cluster.id = 'FAKE_ID' cluster.RECOVERING = 'RECOVERING' node1 = mock.Mock() node1.id = 'fake id 1' node1.cluster_id = 'FAKE_ID' node1.status = 'ACTIVE' node2 = mock.Mock() node2.id = 'fake id 2' node2.cluster_id = 'FAKE_ID' node2.status = 'ACTIVE' mock_load.return_value = cluster cluster.nodes = [node1, node2] action = ca.ClusterAction(cluster.id, 'CLUSTER_ACTION', self.ctx) action.id = 'CLUSTER_ACTION_ID' action.data = {} # do it res_code, res_msg = action.do_recover() # assertions self.assertEqual(action.RES_OK, res_code) self.assertEqual('Cluster recovery succeeded.', res_msg) "," mock_wait.return_value = (action.RES_OK, 'OK') self.assertEqual('Cluster recovery succeeded.', res_msg)",43,15
openstack%2Ffuel-octane~stable%2F7.0~Ia04b0b7290830ef997ddd7a84205a64837b6b77c,openstack/fuel-octane,stable/7.0,Ia04b0b7290830ef997ddd7a84205a64837b6b77c,Define required method 'backup' for puppet archiver,MERGED,2016-02-19 13:28:31.000000000,2016-02-19 14:09:03.000000000,2016-02-19 14:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}]","[{'number': 1, 'created': '2016-02-19 13:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/4efbdfd4d01a565ede13ef101c3cbcf034565a68', 'message': ""Define required method 'backup' for puppet archiver\n\nChange-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c\n""}, {'number': 2, 'created': '2016-02-19 13:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/e2d7037a6cf2f3eb2dd813d20cba34a7da227918', 'message': ""Define required method 'backup' for puppet archiver\n\nChange-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c\n(cherry picked from commit 8209db6af1faa421d0bde704294284ee42540014)""}, {'number': 3, 'created': '2016-02-19 13:42:13.000000000', 'files': ['octane/handlers/backup_restore/puppet.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/e4a6d33029126318b52fe57dccdc4c141c71e48e', 'message': ""Define required method 'backup' for puppet archiver\n\nChange-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c\n(cherry picked from commit 8209db6af1faa421d0bde704294284ee42540014)""}]",0,282335,e4a6d33029126318b52fe57dccdc4c141c71e48e,13,3,3,6677,,,0,"Define required method 'backup' for puppet archiver

Change-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c
(cherry picked from commit 8209db6af1faa421d0bde704294284ee42540014)",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/35/282335/2 && git format-patch -1 --stdout FETCH_HEAD,['octane/handlers/backup_restore/puppet.py'],1,4efbdfd4d01a565ede13ef101c3cbcf034565a68,282317, def backup(self): pass ,,3,0
openstack%2Ffuel-octane~stable%2F7.0~I1a09c48481df0a1c3d00f11be0c508c76acbe78e,openstack/fuel-octane,stable/7.0,I1a09c48481df0a1c3d00f11be0c508c76acbe78e,Delete systemctl stuff from postgres restore,MERGED,2016-02-19 13:11:36.000000000,2016-02-19 14:09:01.000000000,2016-02-19 14:08:55.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}]","[{'number': 1, 'created': '2016-02-19 13:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/c75bf2d5cb1fd873b6c5d057eabfe9f403919a1c', 'message': 'Delete systemctl stuff from postgres restore\n\nChange-Id: I1a09c48481df0a1c3d00f11be0c508c76acbe78e\n'}, {'number': 2, 'created': '2016-02-19 13:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/761965cd19dc019bcc7e7661586b044f2f4a09d6', 'message': 'Delete systemctl stuff from postgres restore\n\nChange-Id: I1a09c48481df0a1c3d00f11be0c508c76acbe78e\n'}, {'number': 3, 'created': '2016-02-19 13:40:53.000000000', 'files': ['octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/tests/conftest.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/a8da0f0ec6100b85407e8cbe57a61c44480e86ed', 'message': 'Delete systemctl stuff from postgres restore\n\nChange-Id: I1a09c48481df0a1c3d00f11be0c508c76acbe78e\n'}]",1,282326,a8da0f0ec6100b85407e8cbe57a61c44480e86ed,15,3,3,6677,,,0,"Delete systemctl stuff from postgres restore

Change-Id: I1a09c48481df0a1c3d00f11be0c508c76acbe78e
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/26/282326/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/tests/conftest.py']",3,c75bf2d5cb1fd873b6c5d057eabfe9f403919a1c,282317," 'stdin', 'stdout', 'stderr', 'shell', 'cwd', 'name',"," 'stdin', 'stdout', 'stderr', 'shell', 'cwd',",3,15
openstack%2Ffuel-octane~stable%2F7.0~I3809d2a4439d5d0866a7e29ee70a68e54c123c4f,openstack/fuel-octane,stable/7.0,I3809d2a4439d5d0866a7e29ee70a68e54c123c4f,Run puppet agent in the end of restore,MERGED,2016-02-19 13:11:36.000000000,2016-02-19 14:08:58.000000000,2016-02-19 14:08:51.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}]","[{'number': 1, 'created': '2016-02-19 13:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/06a0633168899dd450dbc6a4c37437de34cb2937', 'message': 'Run puppet agent in the end of restore\n\nAdd class for puppet agent run in octane.handlers.backup_restore.puppet\nmodule. Add this class to archivators pipeline in the end of the\nprocedure. Call puppet agent for restore method only.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n'}, {'number': 2, 'created': '2016-02-19 13:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/7c1b5baea50f7f9e0a597893f9382f2ae59664db', 'message': 'Run puppet agent in the end of restore\n\nAdd class for puppet agent run in octane.handlers.backup_restore.puppet\nmodule. Add this class to archivators pipeline in the end of the\nprocedure. Call puppet agent for restore method only.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n(cherry picked from commit 30b775d528805726104ceb5913ca66e03fb3d790)'}, {'number': 3, 'created': '2016-02-19 13:40:36.000000000', 'files': ['octane/handlers/backup_restore/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/9173ce5ff0044debff2de0e19408abef95c1d243', 'message': 'Run puppet agent in the end of restore\n\nAdd class for puppet agent run in octane.handlers.backup_restore.puppet\nmodule. Add this class to archivators pipeline in the end of the\nprocedure. Call puppet agent for restore method only.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n(cherry picked from commit 30b775d528805726104ceb5913ca66e03fb3d790)'}]",1,282325,9173ce5ff0044debff2de0e19408abef95c1d243,16,3,3,6677,,,0,"Run puppet agent in the end of restore

Add class for puppet agent run in octane.handlers.backup_restore.puppet
module. Add this class to archivators pipeline in the end of the
procedure. Call puppet agent for restore method only.

Change-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f
Related-bug: 1544967
(cherry picked from commit 30b775d528805726104ceb5913ca66e03fb3d790)",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/25/282325/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/handlers/backup_restore/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/__init__.py']",4,06a0633168899dd450dbc6a4c37437de34cb2937,282317," puppet.PuppetApplyHost,",,14,5
openstack%2Ffuel-octane~stable%2F7.0~Id641813c0d68d00a4430faae83fe235750bb93f9,openstack/fuel-octane,stable/7.0,Id641813c0d68d00a4430faae83fe235750bb93f9,Remove unused password param from restore command,MERGED,2016-02-19 13:11:36.000000000,2016-02-19 14:08:52.000000000,2016-02-19 14:08:46.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}, {'_account_id': 19157}]","[{'number': 1, 'created': '2016-02-19 13:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/8c0b9b37ee58b65cc30b6af40405eb8dcca4e3da', 'message': 'Remove unused password param from restore command\n\nChange-Id: Id641813c0d68d00a4430faae83fe235750bb93f9\n'}, {'number': 2, 'created': '2016-02-19 13:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/32208ac435fe997a3bee60441fe731f8e6564ecf', 'message': 'Remove unused password param from restore command\n\nChange-Id: Id641813c0d68d00a4430faae83fe235750bb93f9\n(cherry picked from commit d3ea58730c21a83decf5bb8c2715ae0c388bb673)'}, {'number': 3, 'created': '2016-02-19 13:40:00.000000000', 'files': ['octane/tests/test_restore.py', 'octane/magic_consts.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/handlers/backup_restore/base.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/cobbler.py', 'octane/commands/restore.py', 'octane/handlers/backup_restore/__init__.py', 'octane/handlers/backup_restore/nailgun_plugins.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/c813bafc5be976b6d70a50e894eb9ed1ae7fefeb', 'message': 'Remove unused password param from restore command\n\nChange-Id: Id641813c0d68d00a4430faae83fe235750bb93f9\n(cherry picked from commit d3ea58730c21a83decf5bb8c2715ae0c388bb673)'}]",1,282324,c813bafc5be976b6d70a50e894eb9ed1ae7fefeb,16,4,3,6677,,,0,"Remove unused password param from restore command

Change-Id: Id641813c0d68d00a4430faae83fe235750bb93f9
(cherry picked from commit d3ea58730c21a83decf5bb8c2715ae0c388bb673)",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/24/282324/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_restore.py', 'octane/magic_consts.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/base.py', 'octane/handlers/backup_restore/cobbler.py', 'octane/commands/restore.py', 'octane/handlers/backup_restore/__init__.py', 'octane/handlers/backup_restore/nailgun_plugins.py']",10,8c0b9b37ee58b65cc30b6af40405eb8dcca4e3da,282317," def restore(self): super(NailgunPluginsArchivator, self).restore()"," def post_restore_action(self, *args, **kwargs):",83,81
openstack%2Ffuel-octane~stable%2F7.0~Ie371c6b02ddcd5fcb25040408e27983b67e7bdb8,openstack/fuel-octane,stable/7.0,Ie371c6b02ddcd5fcb25040408e27983b67e7bdb8,Fix creation new nailgun releases over restore,MERGED,2016-02-19 12:43:42.000000000,2016-02-19 14:08:48.000000000,2016-02-19 14:08:42.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}, {'_account_id': 19157}]","[{'number': 1, 'created': '2016-02-19 12:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/3583be94bb50bacfd30f48684e3e6939e2578ad5', 'message': 'Fix creation new nailgun releases over restore\n\nChange-Id: Ie371c6b02ddcd5fcb25040408e27983b67e7bdb8\n'}, {'number': 2, 'created': '2016-02-19 13:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/6701fd644415132c97a968b3c67edee85eeeb881', 'message': 'Fix creation new nailgun releases over restore\n\nChange-Id: Ie371c6b02ddcd5fcb25040408e27983b67e7bdb8\n'}, {'number': 3, 'created': '2016-02-19 13:39:09.000000000', 'files': ['octane/util/helpers.py', 'octane/tests/test_helpers.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/51d5c7f8ba1a3d1d1a8b5a0608f99a49f1936cb6', 'message': 'Fix creation new nailgun releases over restore\n\nChange-Id: Ie371c6b02ddcd5fcb25040408e27983b67e7bdb8\n(cherry picked from commit e99941fc43faec9cf18a675e947230cf6a221308)'}]",1,282317,51d5c7f8ba1a3d1d1a8b5a0608f99a49f1936cb6,16,4,3,6677,,,0,"Fix creation new nailgun releases over restore

Change-Id: Ie371c6b02ddcd5fcb25040408e27983b67e7bdb8
(cherry picked from commit e99941fc43faec9cf18a675e947230cf6a221308)",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/17/282317/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/util/helpers.py', 'octane/tests/test_helpers.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py']",4,3583be94bb50bacfd30f48684e3e6939e2578ad5,282317,"from octane.util import helpers release = helpers.merge_dicts( base_release_fields, fixture['fields'])", release = base_release_fields.copy() release.update(fixture['fields']),86,16
openstack%2Ffuel-octane~stable%2F7.0~I79cd4ecfec4ce2da981067106401d315ee295534,openstack/fuel-octane,stable/7.0,I79cd4ecfec4ce2da981067106401d315ee295534,Fix release sync after nailrun db restore,MERGED,2016-02-10 09:29:58.000000000,2016-02-19 14:08:43.000000000,2016-02-19 14:08:36.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 6677}, {'_account_id': 10808}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-02-10 09:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/bb01ccf31bccc478a5d26132d32bf376d3792889', 'message': 'Fix release sync after nailrun db restore\n\nChange-Id: I79cd4ecfec4ce2da981067106401d315ee295534\nCloses-bug: 1541429\n(cherry picked from commit d0acfbed00d3ccf92e5d9ad186f22dfaad7c26bf)\n'}, {'number': 2, 'created': '2016-02-19 12:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/28c7ea6ff578cac223ca8028227867192076768f', 'message': 'Fix release sync after nailrun db restore\n\nChange-Id: I79cd4ecfec4ce2da981067106401d315ee295534\nCloses-bug: 1541429\n(cherry picked from commit d0acfbed00d3ccf92e5d9ad186f22dfaad7c26bf)\n'}, {'number': 3, 'created': '2016-02-19 12:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/6a477a789fb21a1a2096cf6799a01119d7ad7671', 'message': 'Fix release sync after nailrun db restore\n\nChange-Id: I79cd4ecfec4ce2da981067106401d315ee295534\nCloses-bug: 1541429\n(cherry picked from commit d0acfbed00d3ccf92e5d9ad186f22dfaad7c26bf)\n'}, {'number': 4, 'created': '2016-02-19 13:11:36.000000000', 'files': ['octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/handlers/backup_restore/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/ba9761f8024415e3552182d8862a90df87bdce03', 'message': 'Fix release sync after nailrun db restore\n\nChange-Id: I79cd4ecfec4ce2da981067106401d315ee295534\nCloses-bug: 1541429\n(cherry picked from commit d0acfbed00d3ccf92e5d9ad186f22dfaad7c26bf)\n'}]",1,278269,ba9761f8024415e3552182d8862a90df87bdce03,23,6,4,19157,,,0,"Fix release sync after nailrun db restore

Change-Id: I79cd4ecfec4ce2da981067106401d315ee295534
Closes-bug: 1541429
(cherry picked from commit d0acfbed00d3ccf92e5d9ad186f22dfaad7c26bf)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/69/278269/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/handlers/backup_restore/__init__.py']",3,bb01ccf31bccc478a5d26132d32bf376d3792889,282317," postgres.KeystoneArchivator, # Nailgun restore should be after puppet restore postgres.NailgunArchivator,"," postgres.KeystoneArchivator, postgres.NailgunArchivator,",13,3
openstack%2Fpython-ironic-inspector-client~master~I6eb22842c80a7f1df0ad39463fa88d7ea89ad888,openstack/python-ironic-inspector-client,master,I6eb22842c80a7f1df0ad39463fa88d7ea89ad888,Update README: `start` cli doesn't rely on Ironic,MERGED,2016-02-19 09:56:41.000000000,2016-02-19 14:08:06.000000000,2016-02-19 14:08:06.000000000,"[{'_account_id': 3}, {'_account_id': 6637}, {'_account_id': 7419}, {'_account_id': 10239}, {'_account_id': 13636}, {'_account_id': 18893}]","[{'number': 1, 'created': '2016-02-19 09:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/3397b47d9fe9cd8261dc276951a903a38a1a4543', 'message': ""Update README: `start` cli doesn't rely on Ironiic\n\nCLI call:\n    openstack baremetal introspection start\n\ndoesn't rely on Ironic, introspected node still be in ``MANAGEABLE``\nstate, it means while node is inspecting, other operations could be\nperformed, it may cause node state inconsistency and operation errors.\n\nChange-Id: I6eb22842c80a7f1df0ad39463fa88d7ea89ad888\n""}, {'number': 2, 'created': '2016-02-19 09:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/ce03737a6d0e1fb1765f6c0a42cf173febb7f623', 'message': ""Update README: `start` cli doesn't rely on Ironic\n\nCLI call:\n    openstack baremetal introspection start\n\ndoesn't rely on Ironic, introspected node still be in ``MANAGEABLE``\nstate, it means while node is inspecting, other operations could be\nperformed, it may cause node state inconsistency and operation errors.\n\nChange-Id: I6eb22842c80a7f1df0ad39463fa88d7ea89ad888\n""}, {'number': 3, 'created': '2016-02-19 11:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/f34bd6c99d7aaf30f7b6b8090ac5b39022bcf4c7', 'message': ""Update README: `start` cli doesn't rely on Ironiic\n\nCLI call:\n    openstack baremetal introspection start\n\ndoesn't rely on Ironic, and the introspected node will be left in\n``MANAGEABLE`` state. This means that the Ironic node is not protected from other\noperations being performed by Ironic, which could cause inconsistency in the\nnode's state, and lead to operational errors.\n\nChange-Id: I6eb22842c80a7f1df0ad39463fa88d7ea89ad888\n""}, {'number': 4, 'created': '2016-02-19 11:22:38.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/cbcd3af7607890d2280a52cb1ea6ca5babe8b717', 'message': ""Update README: `start` cli doesn't rely on Ironic\n\nCLI call:\n    openstack baremetal introspection start\n\ndoesn't rely on Ironic, and the introspected node will be left in\n``MANAGEABLE`` state. This means that the Ironic node is not protected from other\noperations being performed by Ironic, which could cause inconsistency in the\nnode's state, and lead to operational errors.\n\nChange-Id: I6eb22842c80a7f1df0ad39463fa88d7ea89ad888\n""}]",4,282253,cbcd3af7607890d2280a52cb1ea6ca5babe8b717,15,6,4,13636,,,0,"Update README: `start` cli doesn't rely on Ironic

CLI call:
    openstack baremetal introspection start

doesn't rely on Ironic, and the introspected node will be left in
``MANAGEABLE`` state. This means that the Ironic node is not protected from other
operations being performed by Ironic, which could cause inconsistency in the
node's state, and lead to operational errors.

Change-Id: I6eb22842c80a7f1df0ad39463fa88d7ea89ad888
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/53/282253/4 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3397b47d9fe9cd8261dc276951a903a38a1a4543,inpestion-start-note,".. note:: This CLI call doesn't rely on Ironic, introspected node still be in ``MANAGEABLE`` state, it means while node is inspecting, other operations could be performed, it may cause node state inconsistency and operation errors. ",,5,0
openstack%2Foslo.service~master~I7f25913168ebe5854f360db3d6310b72a56b2b4d,openstack/oslo.service,master,I7f25913168ebe5854f360db3d6310b72a56b2b4d,Allow the backdoor to serve from a local unix domain socket,MERGED,2016-02-03 00:35:02.000000000,2016-02-19 14:05:04.000000000,2016-02-19 14:05:04.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 7293}, {'_account_id': 9796}, {'_account_id': 15311}]","[{'number': 1, 'created': '2016-02-03 00:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/93b43e683b209b93121097d29d4920b194954ada', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 2, 'created': '2016-02-03 00:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/9feb8954aa7c943fea45a86cf37a0c97320fbb1d', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 3, 'created': '2016-02-03 17:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/cd62048e087e6b5c3c60edfe96cabe18c15ddf17', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 4, 'created': '2016-02-03 23:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/8b15a66961cbf7e8e4da0eba0af61a0bf77ad033', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 5, 'created': '2016-02-03 23:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/9d5c61245c0186404fe561be007bac70119f858c', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 6, 'created': '2016-02-04 00:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/9634f449d7dd797535a9219e6394261b9313ce10', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 7, 'created': '2016-02-04 20:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/9a7c488aa569828366f4b38556eca840ca0a4993', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}, {'number': 8, 'created': '2016-02-19 03:24:55.000000000', 'files': ['oslo_service/_options.py', 'oslo_service/tests/test_eventlet_backdoor.py', 'oslo_service/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/db1fc249e67c7d12602257804400304d58b74d8b', 'message': 'Allow the backdoor to serve from a local unix domain socket\n\nLocal files can be made accessible to certain users vs random\nports which can be accessible to anyone on a machine so allow\nusing unix files as a way to start the eventlet backdoor (so that\nuser and group permissions common on unix are not lost).\n\nTo use this new type of files `socat` is needed (or other way\nto interact with telnet over a unix domain socket).\n\nFor example (with the path at /tmp/my_special_socket):\n\n  socat - UNIX-CONNECT:/tmp/my_special_socket\n\nDepends-On: Ia2385879e09991102f8f305ec41dbb651a4374de\n\nChange-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d\n'}]",10,275453,db1fc249e67c7d12602257804400304d58b74d8b,41,6,8,1297,,,0,"Allow the backdoor to serve from a local unix domain socket

Local files can be made accessible to certain users vs random
ports which can be accessible to anyone on a machine so allow
using unix files as a way to start the eventlet backdoor (so that
user and group permissions common on unix are not lost).

To use this new type of files `socat` is needed (or other way
to interact with telnet over a unix domain socket).

For example (with the path at /tmp/my_special_socket):

  socat - UNIX-CONNECT:/tmp/my_special_socket

Depends-On: Ia2385879e09991102f8f305ec41dbb651a4374de

Change-Id: I7f25913168ebe5854f360db3d6310b72a56b2b4d
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/53/275453/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_service/_options.py', 'requirements.txt', 'oslo_service/eventlet_backdoor.py']",3,93b43e683b209b93121097d29d4920b194954ada,275453," if conf.backdoor_port is None and conf.backdoor_socket is None: if conf.backdoor_socket is None: start_port, end_port = _parse_port_range(str(conf.backdoor_port)) sock = _listen('localhost', start_port, end_port, eventlet.listen) # In the case of backdoor port being zero, a port number is assigned by # listen(). In any case, pull the port number out here. where_running = sock.getsockname()[1] else: sock = eventlet.listen(conf.backdoor_socket, socket.AF_UNIX) where_running = conf.backdoor_socket _LI('Eventlet backdoor listening on %(where_running)s for' ' process %(pid)d'), {'where_running': where_running, 'pid': os.getpid()} return (where_running, thread) where_running_thread = _initialize_if_enabled(conf) if not where_running: where_running, _thread = where_running_thread return where_running where_running_thread = _initialize_if_enabled(conf) if not where_running_thread: raise RuntimeError(""Did not create backdoor at requested location"") else: _where_running, thread = where_running_thread"," if conf.backdoor_port is None: start_port, end_port = _parse_port_range(str(conf.backdoor_port)) sock = _listen('localhost', start_port, end_port, eventlet.listen) # In the case of backdoor port being zero, a port number is assigned by # listen(). In any case, pull the port number out here. port = sock.getsockname()[1] _LI('Eventlet backdoor listening on %(port)s for process %(pid)d'), {'port': port, 'pid': os.getpid()} return (port, thread) port_thread = _initialize_if_enabled(conf) if not port_thread: port, _thread = port_thread return port port_thread = _initialize_if_enabled(conf) if not port_thread: raise RuntimeError(""Did not create backdoor at requested port"") else: _port, thread = port_thread",31,20
openstack%2Fanchor~master~I025abea5d1deae4523f159396053b75923507b08,openstack/anchor,master,I025abea5d1deae4523f159396053b75923507b08,More test coverage,MERGED,2015-11-09 08:04:57.000000000,2016-02-19 14:04:46.000000000,2016-02-19 14:04:46.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}]","[{'number': 1, 'created': '2015-11-09 08:04:57.000000000', 'files': ['tests/X509/test_x509_certificate.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/86c69760c701edecc5b4c88989d3553185d643fe', 'message': 'More test coverage\n\nChange-Id: I025abea5d1deae4523f159396053b75923507b08\n'}]",0,242970,86c69760c701edecc5b4c88989d3553185d643fe,7,3,1,1528,,,0,"More test coverage

Change-Id: I025abea5d1deae4523f159396053b75923507b08
",git fetch https://review.opendev.org/openstack/anchor refs/changes/70/242970/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/X509/test_x509_certificate.py'],1,86c69760c701edecc5b4c88989d3553185d643fe,test_sig_mismatch,from pyasn1.type import univ as asn1_univ def test_verify_signature_mismatch(self): alg = asn1_univ.ObjectIdentifier('1.2.3.4') self.cert._cert['signatureAlgorithm']['algorithm'] = alg with self.assertRaises(x509_errors.X509Error): self.cert.verify(),,7,0
openstack%2Foslo.messaging~master~I686c8c341f117dbc0b02443306395d5fd011c2f1,openstack/oslo.messaging,master,I686c8c341f117dbc0b02443306395d5fd011c2f1,fix override_pool_size,MERGED,2016-02-17 14:48:24.000000000,2016-02-19 14:03:15.000000000,2016-02-19 14:03:15.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 8601}]","[{'number': 1, 'created': '2016-02-17 14:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f151836ea42d422c37a7e2097969b8ea5c8b0299', 'message': 'fix override_pool_size\n\nrelated to Id3af696193af2ccf5e5f3a1ae1d22f4f80860606. we need to make\noverride_pool_size accessible for external use.\n\nChange-Id: I686c8c341f117dbc0b02443306395d5fd011c2f1\n'}, {'number': 2, 'created': '2016-02-17 22:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f1f7407c7c7a7c01e5b15f8f1cc9d6bb23403668', 'message': 'fix override_pool_size\n\nrelated to Id3af696193af2ccf5e5f3a1ae1d22f4f80860606. we need to make\noverride_pool_size accessible for external use.\n\nChange-Id: I686c8c341f117dbc0b02443306395d5fd011c2f1\n'}, {'number': 3, 'created': '2016-02-18 16:29:30.000000000', 'files': ['oslo_messaging/_executors/base.py', 'oslo_messaging/tests/rpc/test_server.py', 'oslo_messaging/server.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1bca96ff782e967860c3ceb62bf25586be6df58c', 'message': 'fix override_pool_size\n\nrelated to Id3af696193af2ccf5e5f3a1ae1d22f4f80860606. we need to make\noverride_pool_size accessible for external use.\n\nChange-Id: I686c8c341f117dbc0b02443306395d5fd011c2f1\n'}]",0,281313,1bca96ff782e967860c3ceb62bf25586be6df58c,17,6,3,6537,,,0,"fix override_pool_size

related to Id3af696193af2ccf5e5f3a1ae1d22f4f80860606. we need to make
override_pool_size accessible for external use.

Change-Id: I686c8c341f117dbc0b02443306395d5fd011c2f1
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/13/281313/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/server.py'],1,f151836ea42d422c37a7e2097969b8ea5c8b0299,override_thread_pool," def start(self, override_pool_size=None): executor.start(override_pool_size=override_pool_size)", def start(self): executor.start(),2,2
openstack%2Foslo.messaging~master~I046717f9ea7f203f7e5837c7b62a6a7d7cc7bb4d,openstack/oslo.messaging,master,I046717f9ea7f203f7e5837c7b62a6a7d7cc7bb4d,Log format change in simulator.py,MERGED,2016-02-18 11:43:37.000000000,2016-02-19 14:03:02.000000000,2016-02-19 14:03:02.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 8601}]","[{'number': 1, 'created': '2016-02-18 11:43:37.000000000', 'files': ['tools/simulator.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c10ee15fe0955a89be215f84e3c3a7843a7a6d2f', 'message': 'Log format change in simulator.py\n\nChange-Id: I046717f9ea7f203f7e5837c7b62a6a7d7cc7bb4d\n'}]",0,281781,c10ee15fe0955a89be215f84e3c3a7843a7a6d2f,7,3,1,7534,,,0,"Log format change in simulator.py

Change-Id: I046717f9ea7f203f7e5837c7b62a6a7d7cc7bb4d
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/81/281781/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/simulator.py'],1,c10ee15fe0955a89be215f84e3c3a7843a7a6d2f,(detached," logging.basicConfig( stream=sys.stdout, level=log_level, format=""%(asctime)-15s %(levelname)s %(name)s %(message)s"")"," logging.basicConfig(stream=sys.stdout, level=log_level)",3,1
openstack%2Fpython-openstackclient~master~Id0289596796d28d67912bcfca4da1f88c6d84da1,openstack/python-openstackclient,master,Id0289596796d28d67912bcfca4da1f88c6d84da1,Same exception handling for gets() in find_resource,ABANDONED,2015-07-16 19:50:18.000000000,2016-02-19 13:59:21.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-07-16 19:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9ac67ee77e22faa99b4a7a7391a251fa3f3f1aa4', 'message': 'Same exception handling for gets() in find_resource\n\nThere\'s 2 calls to get() in find_resource, one has special exception\nhandling to check for ""NotFound"" errors while the other just ignores the exception, which masks\nerrors and makes it difficult to debug. This change makes it so that\nboth legs use the same exception handling so a NotFound will be\npassed and other errors will be raised rather than ignored.\n\nChange-Id: Id0289596796d28d67912bcfca4da1f88c6d84da1\n'}, {'number': 2, 'created': '2015-07-16 19:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/056eddfbbfbb8b0879241d5b0938eec8e44b3d42', 'message': 'Same exception handling for gets() in find_resource\n\nThere\'s 2 calls to get() in find_resource, one has special exception\nhandling to check for ""NotFound"" errors while the other just ignores the exception, which masks\nerrors and makes it difficult to debug. This change makes it so that\nboth legs use the same exception handling so a NotFound will be\npassed and other errors will be raised rather than ignored.\n\nChange-Id: Id0289596796d28d67912bcfca4da1f88c6d84da1\n'}, {'number': 3, 'created': '2015-07-16 20:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/68f875a04176210e66ef069114a0d6a4c4cf3d61', 'message': 'Same exception handling for gets() in find_resource\n\nThere\'s 2 calls to get() in find_resource, one has special exception\nhandling to check for ""NotFound"" errors while the other just ignores the exception, which masks\nerrors and makes it difficult to debug. This change makes it so that\nboth legs use the same exception handling so a NotFound will be\npassed and other errors will be raised rather than ignored.\n\nCloses-Bug: 1475413\nChange-Id: Id0289596796d28d67912bcfca4da1f88c6d84da1\n'}, {'number': 4, 'created': '2015-07-17 13:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c240be9b7299caf2c38f6080effc23b4e9d0a8c9', 'message': 'Same exception handling for gets() in find_resource\n\nThere\'s 2 calls to get() in find_resource, one has special exception\nhandling to check for ""NotFound"" errors while the other just ignores the exception, which masks\nerrors and makes it difficult to debug. This change makes it so that\nboth legs use the same exception handling so a NotFound will be\npassed and other errors will be raised rather than ignored.\n\nCloses-Bug: 1475413\nChange-Id: Id0289596796d28d67912bcfca4da1f88c6d84da1\n'}, {'number': 5, 'created': '2015-07-17 14:54:03.000000000', 'files': ['openstackclient/tests/common/test_utils.py', 'openstackclient/tests/volume/test_find_resource.py', 'openstackclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4b5869d370acd7de6efcb303c9d16df11d7efc1b', 'message': 'Same exception handling for gets() in find_resource\n\nThere\'s 2 calls to get() in find_resource, one has special exception\nhandling to check for ""NotFound"" errors while the other just ignores the exception, which masks\nerrors and makes it difficult to debug. This change makes it so that\nboth legs use the same exception handling so a NotFound will be\npassed and other errors will be raised rather than ignored.\n\nCloses-Bug: 1475413\nChange-Id: Id0289596796d28d67912bcfca4da1f88c6d84da1\n'}]",0,202760,4b5869d370acd7de6efcb303c9d16df11d7efc1b,17,4,5,6486,,,0,"Same exception handling for gets() in find_resource

There's 2 calls to get() in find_resource, one has special exception
handling to check for ""NotFound"" errors while the other just ignores the exception, which masks
errors and makes it difficult to debug. This change makes it so that
both legs use the same exception handling so a NotFound will be
passed and other errors will be raised rather than ignored.

Closes-Bug: 1475413
Change-Id: Id0289596796d28d67912bcfca4da1f88c6d84da1
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/60/202760/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/common/test_utils.py', 'openstackclient/tests/volume/test_find_resource.py', 'openstackclient/common/utils.py']",3,9ac67ee77e22faa99b4a7a7391a251fa3f3f1aa4,bug/1475413," def get(name_or_id): # Try directly using the passed value try: return manager.get(name_or_id, **kwargs) # FIXME(dtroyer): The exception to catch here is dependent on which # client library the manager passed in belongs to. # Eventually this should be pulled from a common set # of client exceptions. except Exception as ex: if type(ex).__name__ == 'NotFound': pass else: raise # Try to get entity as integer id if isinstance(name_or_id, int) or name_or_id.isdigit(): ret = get(int(name_or_id)) if ret: return ret ret = get(name_or_id) if ret: return ret"," # Try to get entity as integer id try: if isinstance(name_or_id, int) or name_or_id.isdigit(): return manager.get(int(name_or_id), **kwargs) # FIXME(dtroyer): The exception to catch here is dependent on which # client library the manager passed in belongs to. # Eventually this should be pulled from a common set # of client exceptions. except Exception as ex: if type(ex).__name__ == 'NotFound': pass else: raise # Try directly using the passed value try: return manager.get(name_or_id, **kwargs) except Exception: pass",31,23
openstack%2Fpython-openstackclient~master~I372f09bae0d223a984e8f5d6cd355a6a4fddde03,openstack/python-openstackclient,master,I372f09bae0d223a984e8f5d6cd355a6a4fddde03,"Revert ""Fix the way we call find_resource when only using ID""",ABANDONED,2015-07-17 13:25:17.000000000,2016-02-19 13:59:17.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-07-17 13:25:17.000000000', 'files': ['openstackclient/identity/common.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/528874b8878392309293b47eb4e364c7a45bdf59', 'message': 'Revert ""Fix the way we call find_resource when only using ID""\n\nThis reverts commit 37c83e6231dcfb2f0f4d28f13f78ac2dc170b768.\n\nChange-Id: I372f09bae0d223a984e8f5d6cd355a6a4fddde03\n'}]",0,203025,528874b8878392309293b47eb4e364c7a45bdf59,6,3,1,6486,,,0,"Revert ""Fix the way we call find_resource when only using ID""

This reverts commit 37c83e6231dcfb2f0f4d28f13f78ac2dc170b768.

Change-Id: I372f09bae0d223a984e8f5d6cd355a6a4fddde03
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/25/203025/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/common.py'],1,528874b8878392309293b47eb4e364c7a45bdf59,bug/1475127," return _find_identity_resource(identity_client.groups, name_or_id, groups.Group, domain_id=domain_id) return _find_identity_resource(identity_client.projects, name_or_id, projects.Project, domain_id=domain_id) return _find_identity_resource(identity_client.users, name_or_id, users.User, domain_id=domain_id)"," if not domain_id: return _find_identity_resource(identity_client.groups, name_or_id, groups.Group) else: return _find_identity_resource(identity_client.groups, name_or_id, groups.Group, domain_id=domain_id) if not domain_id: return _find_identity_resource(identity_client.projects, name_or_id, projects.Project) else: return _find_identity_resource(identity_client.projects, name_or_id, projects.Project, domain_id=domain_id) if not domain_id: return _find_identity_resource(identity_client.users, name_or_id, users.User) else: return _find_identity_resource(identity_client.users, name_or_id, users.User, domain_id=domain_id)",6,18
openstack%2Fsalt-formula-nova~master~I3bbc18a6f00cc7cc88f73f02667808d7534c7091,openstack/salt-formula-nova,master,I3bbc18a6f00cc7cc88f73f02667808d7534c7091,refactor heka config,MERGED,2016-02-19 13:53:59.000000000,2016-02-19 13:58:46.000000000,2016-02-19 13:58:46.000000000,"[{'_account_id': 3}, {'_account_id': 18092}]","[{'number': 1, 'created': '2016-02-19 13:53:59.000000000', 'files': ['nova/files/heka.toml'], 'web_link': 'https://opendev.org/openstack/salt-formula-nova/commit/ad16f61b90d675a5ed2a01b7f5407f537fac07d2', 'message': 'refactor heka config\n\nChange-Id: I3bbc18a6f00cc7cc88f73f02667808d7534c7091\n'}]",0,282343,ad16f61b90d675a5ed2a01b7f5407f537fac07d2,7,2,1,20430,,,0,"refactor heka config

Change-Id: I3bbc18a6f00cc7cc88f73f02667808d7534c7091
",git fetch https://review.opendev.org/openstack/salt-formula-nova refs/changes/43/282343/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/files/heka.toml'],1,ad16f61b90d675a5ed2a01b7f5407f537fac07d2,heka_refactor,"[logstreamer_nova]file_match = '(?P<Service>.+)\.log\.?(?P<Seq>\d*)$' differentiator = [""'nova','_','Service'""]","{%- if pillar.nova.compute is defined %} [logstreamer_nova_compute]file_match = 'nova-compute\.log\.?(?P<Index>\d+)?(.gz)?'{%- endif %} {%- if pillar.nova.controller is defined %} [logstreamer nova_scheduler] type = ""LogstreamerInput"" log_directory = ""/var/log/nova"" file_match = 'nova-scheduler\.log\.?(?P<Index>\d+)?(.gz)?' priority = [""^Index""] decoder = ""openstack"" oldest_duration: ""7d"" [logstreamer_nova_conductor] type = ""LogstreamerInput"" log_directory = ""/var/log/nova"" log_directory = 'nova-conductor\.log\.?(?P<Index>\d+)?(.gz)?' priority = [""^Index""] decoder = ""openstack"" oldest_duration: ""7d"" [logstreamer_nova_consoleauth] type = ""LogstreamerInput"" log_directory = ""/var/log/nova"" log_directory = 'nova-consoleauth\.log\.?(?P<Index>\d+)?(.gz)?' priority = [""^Index""] decoder = ""openstack"" oldest_duration: ""7d"" [logstreamer_nova_cert] type = ""LogstreamerInput"" log_directory = ""/var/log/nova"" log_directory = 'nova-cert\.log\.?(?P<Index>\d+)?(.gz)?' priority = [""^Index""] decoder = ""openstack"" oldest_duration: ""7d"" {%- endif %}",4,38
openstack%2Ftempest-lib~master~Ie708ec456c867a90fb7150e4753c57b27af009cb,openstack/tempest-lib,master,Ie708ec456c867a90fb7150e4753c57b27af009cb,Add auth.get_version_endpoint,ABANDONED,2016-01-04 21:32:05.000000000,2016-02-19 13:58:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2016-01-04 21:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/b5fe36b38e11088bb9d44684d1dce535cee0f645', 'message': ""Add auth.get_version_endpoint\n\nTo do version discovery, we'll need a function that returns\nthe URL that's compatible with the given version.\n\nChange-Id: Ie708ec456c867a90fb7150e4753c57b27af009cb\n""}, {'number': 2, 'created': '2016-01-31 17:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/32c5eccb061a9a1c7893b94363335120a7ada0a3', 'message': ""Add auth.get_version_endpoint\n\nTo do version discovery, we'll need a function that returns\nthe URL that's compatible with the given version.\n\nChange-Id: Ie708ec456c867a90fb7150e4753c57b27af009cb\n""}, {'number': 3, 'created': '2016-01-31 17:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/11d848115408a5d79ad5f98749a8c716ac924d49', 'message': ""Add auth.get_version_endpoint\n\nTo do version discovery, we'll need a function that returns\nthe URL that's compatible with the given version.\n\nChange-Id: Ie708ec456c867a90fb7150e4753c57b27af009cb\n""}, {'number': 4, 'created': '2016-01-31 17:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/d5c30e96c8148411367d5c4c5e1fa265884b36e6', 'message': ""Add auth.get_version_endpoint\n\nTo do version discovery, we'll need a function that returns\nthe URL that's compatible with the given version.\n\nChange-Id: Ie708ec456c867a90fb7150e4753c57b27af009cb\n""}, {'number': 5, 'created': '2016-02-01 18:52:26.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/8b83f585c2bb82a05fa8221ea5613906adde5f66', 'message': ""Add auth.get_version_endpoint\n\nTo do version discovery, we'll need a function that returns\nthe URL that's compatible with the given version.\n\nChange-Id: Ie708ec456c867a90fb7150e4753c57b27af009cb\n""}]",0,263448,8b83f585c2bb82a05fa8221ea5613906adde5f66,11,2,5,6486,,,0,"Add auth.get_version_endpoint

To do version discovery, we'll need a function that returns
the URL that's compatible with the given version.

Change-Id: Ie708ec456c867a90fb7150e4753c57b27af009cb
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/48/263448/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,b5fe36b38e11088bb9d44684d1dce535cee0f645,bug/1530181," class TestGetVersionEndpoint(base.TestCase): def test_v3_v3_only(self): # When the versions only has v3.5 and the requested version is v3, # the v3 endpoint is returned. target_version = (3,) versions = [('v3.5', 'http://hostname/openstack/identity/v3/')] self.assertEqual('http://hostname/openstack/identity/v3/', auth.get_version_endpoint(target_version, versions)) def test_v2_v2_only(self): # When the versions only has v2 and the requested version is v2, # the v2 endpoint is returned. target_version = (2,) versions = [('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual('http://hostname/openstack/identity/v2.0/', auth.get_version_endpoint(target_version, versions)) def test_v3_v2_v3(self): # When the versions has v3.5 and v2 and the requested version is v3, # the v3 endpoint is returned. target_version = (3,) versions = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual('http://hostname/openstack/identity/v3/', auth.get_version_endpoint(target_version, versions)) def test_v2_v2_v3(self): # When the versions has v3.5 and v2 and the requested version is v2, # the v3 endpoint is returned. target_version = (2,) versions = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual('http://hostname/openstack/identity/v2.0/', auth.get_version_endpoint(target_version, versions)) def test_v3_v2_only(self): # When the versions has v2 only and the requested version is v3, # then DiscoveryError is raised. target_version = (3,) versions = [('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertRaises(auth.DiscoveryError, auth.get_version_endpoint, target_version, versions)",,66,0
openstack%2Ftempest-lib~master~I12a44d95f4f1728d322df5102a5ad5c0fd914e50,openstack/tempest-lib,master,I12a44d95f4f1728d322df5102a5ad5c0fd914e50,Add auth.versions_compatible,ABANDONED,2016-01-04 21:32:05.000000000,2016-02-19 13:58:29.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2016-01-04 21:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/0e65b0cac1d05e19816bcc5225d1210189e6f1d9', 'message': 'Add auth.versions_compatible\n\nTo do version discovery, we\'ll need a function to check if\na version reported by the API (e.g., ""v3.5"") is compatible with the\nversion that you want to use (e.g., 3 or 2).\n\nChange-Id: I12a44d95f4f1728d322df5102a5ad5c0fd914e50\n'}, {'number': 2, 'created': '2016-01-31 17:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/36770649e1c5fcdf06b4c42cb78ca3221586f12e', 'message': 'Add auth.versions_compatible\n\nTo do version discovery, we\'ll need a function to check if\na version reported by the API (e.g., ""v3.5"") is compatible with the\nversion that you want to use (e.g., 3 or 2).\n\nChange-Id: I12a44d95f4f1728d322df5102a5ad5c0fd914e50\n'}, {'number': 3, 'created': '2016-01-31 17:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/7d3bcbb37b9f8fe2be3d9346d673a8f460f08b9a', 'message': 'Add auth.versions_compatible\n\nTo do version discovery, we\'ll need a function to check if\na version reported by the API (e.g., ""v3.5"") is compatible with the\nversion that you want to use (e.g., 3 or 2).\n\nChange-Id: I12a44d95f4f1728d322df5102a5ad5c0fd914e50\n'}, {'number': 4, 'created': '2016-02-01 18:52:26.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/184f7cc9df42291f44c10396af41cf3ba9dc535d', 'message': 'Add auth.versions_compatible\n\nTo do version discovery, we\'ll need a function to check if\na version reported by the API (e.g., ""v3.5"") is compatible with the\nversion that you want to use (e.g., 3 or 2).\n\nChange-Id: I12a44d95f4f1728d322df5102a5ad5c0fd914e50\n'}]",0,263447,184f7cc9df42291f44c10396af41cf3ba9dc535d,11,2,4,6486,,,0,"Add auth.versions_compatible

To do version discovery, we'll need a function to check if
a version reported by the API (e.g., ""v3.5"") is compatible with the
version that you want to use (e.g., 3 or 2).

Change-Id: I12a44d95f4f1728d322df5102a5ad5c0fd914e50
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/47/263447/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,0e65b0cac1d05e19816bcc5225d1210189e6f1d9,bug/1530181," class TestVersionsCompatible(base.TestCase): def test_same(self): # When the versions are the same, then they're compatible self.assertTrue(auth.versions_compatible(target=(2, 0), given=(2, 0))) def test_compatible_points(self): # When the target version is 2 and the given version is 2.0 then # compatible. self.assertTrue(auth.versions_compatible(target=(2,), given=(2, 0))) def test_incompatible_major(self): # When the target version is 3 and the given version is 2.0 then # not compatible. self.assertFalse(auth.versions_compatible(target=(3,), given=(2, 0))) def test_incompatible_points(self): # When the target version is 2.1 and the given version is 2.0 then # not compatible. self.assertFalse(auth.versions_compatible(target=(2, 1), given=(2, 0)))",,45,0
openstack%2Ftempest-lib~master~I49bc565c1b0bd07f9555f42b17099d8b24ff4268,openstack/tempest-lib,master,I49bc565c1b0bd07f9555f42b17099d8b24ff4268,Add auth.parse_version,ABANDONED,2016-01-04 21:32:05.000000000,2016-02-19 13:58:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7350}]","[{'number': 1, 'created': '2016-01-04 21:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/992be2a7904bec43797f027df567f7068a455c73', 'message': ""Add auth.parse_version\n\nTo do version discovery properly, we'll need a method to parse\nversion strings.\n\nChange-Id: I49bc565c1b0bd07f9555f42b17099d8b24ff4268\n""}, {'number': 2, 'created': '2016-01-31 17:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/739f180ead3aca13c0d08248b40d1cabfc52a8c7', 'message': ""Add auth.parse_version\n\nTo do version discovery properly, we'll need a method to parse\nversion strings.\n\nChange-Id: I49bc565c1b0bd07f9555f42b17099d8b24ff4268\n""}, {'number': 3, 'created': '2016-02-01 18:52:26.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/153ba581715915e967e712c706626781d85ed0dc', 'message': ""Add auth.parse_version\n\nTo do version discovery properly, we'll need a method to parse\nversion strings.\n\nChange-Id: I49bc565c1b0bd07f9555f42b17099d8b24ff4268\n""}]",0,263446,153ba581715915e967e712c706626781d85ed0dc,11,3,3,6486,,,0,"Add auth.parse_version

To do version discovery properly, we'll need a method to parse
version strings.

Change-Id: I49bc565c1b0bd07f9555f42b17099d8b24ff4268
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/46/263446/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,992be2a7904bec43797f027df567f7068a455c73,bug/1530181," class TestParseVersions(base.TestCase): def test_v2(self): self.assertEquals((2, 0), auth.parse_version('v2.0')) def test_v3(self): self.assertEquals((3, 5), auth.parse_version('v3.5')) def test_no_point(self): self.assertEquals((3,), auth.parse_version('v3')) def test_empty(self): # In the case of an empty string, get no version self.assertEquals(tuple(), auth.parse_version('')) def test_not_version(self): # If it's not a version string, fails with ValueError. self.assertRaises(ValueError, auth.parse_version, 'something')",,27,0
openstack%2Ftempest-lib~master~I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67,openstack/tempest-lib,master,I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67,Add auth.discover_versions(),ABANDONED,2015-12-30 22:13:53.000000000,2016-02-19 13:58:18.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-12-30 22:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/e5de415ae66edf9e6e205f23d8224af370c2176f', 'message': ""Add auth.discover_versions()\n\nIn order to do version discovery for identity, we'll need a\nfunction that given a URL finds the version data by potentially\nsearching up the path, then returns the version info (the versions\nand the URL for each version), and the trailing path info.\n\nChange-Id: I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67\n""}, {'number': 2, 'created': '2015-12-31 16:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/fd3d2efe5bda6b294e2fb419f68685942b7f6f46', 'message': ""Add auth.discover_versions()\n\nIn order to do version discovery for identity, we'll need a\nfunction that given a URL finds the version data by potentially\nsearching up the path, then returns the version info (the versions\nand the URL for each version), and the trailing path info.\n\nChange-Id: I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67\n""}, {'number': 3, 'created': '2016-01-31 16:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/dca81f5910d92f75125ccb02fd22550eb4e3f088', 'message': ""Add auth.discover_versions()\n\nIn order to do version discovery for identity, we'll need a\nfunction that given a URL finds the version data by potentially\nsearching up the path, then returns the version info (the versions\nand the URL for each version), and the trailing path info.\n\nChange-Id: I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67\n""}, {'number': 4, 'created': '2016-02-01 18:52:26.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/30f8b4bcf77238333d199f8c485db6d3abe0f50c', 'message': ""Add auth.discover_versions()\n\nIn order to do version discovery for identity, we'll need a\nfunction that given a URL finds the version data by potentially\nsearching up the path, then returns the version info (the versions\nand the URL for each version), and the trailing path info.\n\nChange-Id: I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67\n""}]",0,262620,30f8b4bcf77238333d199f8c485db6d3abe0f50c,13,2,4,6486,,,0,"Add auth.discover_versions()

In order to do version discovery for identity, we'll need a
function that given a URL finds the version data by potentially
searching up the path, then returns the version info (the versions
and the URL for each version), and the trailing path info.

Change-Id: I9dbcd2f38cfed84bc2a86aa52b7e30bb2ca59e67
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/20/262620/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,e5de415ae66edf9e6e205f23d8224af370c2176f,bug/1530181," class TestDiscoverVersions(base.TestCase): def test_versions(self): # When the versions response is returned for the url, # base_url is url, trailing_path is empty, and get both version data. url = 'http://hostname/openstack/identity/' m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) m.get(url, status_code=300, reason='Multiple Choices', json=SAMPLE_IDENTITY_VERSIONS_RESPONSE) res = auth.discover_versions(url) base_url, trailing_path, versions = res self.assertEqual(url, base_url) self.assertEqual('', trailing_path) expected = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual(expected, versions) def test_version_to_versions(self): # When the version response is returned for the url and then parent # returns the versions response then # base_url is parent of URL, trailing_path is empty, and get both # version data. m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) url = 'http://hostname/openstack/identity/v2.0' m.get(url, json=SAMPLE_IDENTITY_V2_RESPONSE) url_parent = 'http://hostname/openstack/identity' m.get(url_parent, status_code=300, reason='Multiple Choices', json=SAMPLE_IDENTITY_VERSIONS_RESPONSE) res = auth.discover_versions(url) base_url, trailing_path, versions = res self.assertEqual(url_parent, base_url) self.assertEqual('', trailing_path) expected = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual(expected, versions) def test_version_no_versions(self): # When the version response is returned for the url and then parent # doesn't return the versions response then # base_url is URL, trailing_path is empty, and one version data. # Not sure why this would happen but might as well handle it. m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) url = 'http://hostname/openstack/identity/v3' m.get(url, json=SAMPLE_IDENTITY_V3_RESPONSE) url_parent = 'http://hostname/openstack/identity' m.get(url_parent, status_code=404, reason='Not Found', text='Not Found') res = auth.discover_versions(url) base_url, trailing_path, versions = res self.assertEqual(url, base_url) self.assertEqual('', trailing_path) expected = [('v3.5', 'http://hostname/openstack/identity/v3/')] self.assertEqual(expected, versions) def test_trailing_path(self): # When the version response is returned for the parent of the url and # then grandparent returns the versions response then # base_url is grandparent of URL, trailing_path is the trailing part, # and get both version data. m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) url = 'http://hostname/openstack/identity/v2.0/something' m.get(url, status_code=200, json={'users': []}) version_url = 'http://hostname/openstack/identity/v2.0' m.get(version_url, json=SAMPLE_IDENTITY_V2_RESPONSE) versions_url = 'http://hostname/openstack/identity' m.get(versions_url, status_code=300, reason='Multiple Choices', json=SAMPLE_IDENTITY_VERSIONS_RESPONSE) res = auth.discover_versions(url) base_url, trailing_path, versions = res self.assertEqual(versions_url, base_url) self.assertEqual('/something', trailing_path) expected = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual(expected, versions)",,143,0
openstack%2Ftempest-lib~master~I08b336365a4e7938d066b6b0314e369e2a1321d4,openstack/tempest-lib,master,I08b336365a4e7938d066b6b0314e369e2a1321d4,Add function to fetch identity version data,ABANDONED,2015-12-30 22:13:53.000000000,2016-02-19 13:58:14.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-12-30 22:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/c3189bd11fc60ef516d57cfd99f387a696448a54', 'message': ""Add auth.check_url for identity version discovery\n\nIn order to do version discovery, we're going to need a function\nthat does GET on a URL and returns the version data if the URL is\nfor the identity service GET version function.\n\nChange-Id: I08b336365a4e7938d066b6b0314e369e2a1321d4\n""}, {'number': 2, 'created': '2016-01-31 16:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/dd62920771328c886f76a6887aa440c0e26900ce', 'message': ""Add function to fetch identity version data\n\nIn order to do version discovery, we're going to need a function\nthat does GET on a URL and returns the advertised version\nendpoints.\n\nChange-Id: I08b336365a4e7938d066b6b0314e369e2a1321d4\n""}, {'number': 3, 'created': '2016-01-31 16:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/f339c7f53f8c62a9c8dbcaa9f14a1153bfa6cc1d', 'message': ""Add function to fetch identity version data\n\nIn order to do version discovery, we're going to need a function\nthat does GET on a URL and returns the advertised version\nendpoints.\n\nChange-Id: I08b336365a4e7938d066b6b0314e369e2a1321d4\n""}, {'number': 4, 'created': '2016-02-01 18:52:26.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/773b72c06fe74007c1fead09490ee375b16145c5', 'message': ""Add function to fetch identity version data\n\nIn order to do version discovery, we're going to need a function\nthat does GET on a URL and returns the advertised version\nendpoints.\n\nChange-Id: I08b336365a4e7938d066b6b0314e369e2a1321d4\n""}]",0,262619,773b72c06fe74007c1fead09490ee375b16145c5,13,2,4,6486,,,0,"Add function to fetch identity version data

In order to do version discovery, we're going to need a function
that does GET on a URL and returns the advertised version
endpoints.

Change-Id: I08b336365a4e7938d066b6b0314e369e2a1321d4
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/19/262619/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",4,c3189bd11fc60ef516d57cfd99f387a696448a54,bug/1530181,"import requests_mock class TestCheckUrl(base.TestCase): def _set_fake_response(self, url, **kwargs): m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) m.get(url, **kwargs) def test_v3(self): # When the v3 response is returned, # is_versions_response is False and get V3 version data. sample_v3_url = 'http://hostname/openstack/identity/v3' self._set_fake_response( sample_v3_url, json=SAMPLE_IDENTITY_V3_RESPONSE) res = auth.check_url(sample_v3_url) is_versions_response, versions = res self.assertFalse(is_versions_response) expected = [('v3.5', 'http://hostname/openstack/identity/v3/')] self.assertEqual(expected, versions) def test_v2(self): # When the v2 response is returned, # is_versions_response is False and get V2 version data. sample_v2_url = 'http://hostname/openstack/identity/v2.0' self._set_fake_response( sample_v2_url, json=SAMPLE_IDENTITY_V2_RESPONSE) res = auth.check_url(sample_v2_url) is_versions_response, versions = res self.assertFalse(is_versions_response) expected = [('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual(expected, versions) def test_versions(self): # When the versions response is returned, is_versions_response is True # and get both version data. sample_url = 'http://hostname/openstack/identity/' self._set_fake_response( sample_url, status_code=300, reason='Multiple Choices', json=SAMPLE_IDENTITY_VERSIONS_RESPONSE) res = auth.check_url(sample_url) is_versions_response, versions = res self.assertTrue(is_versions_response) expected = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] self.assertEqual(expected, versions) def test_invalid_404(self): # When a 404 is returned then DiscoveryError is raised. sample_url = 'http://hostname/openstack/identity/v3/something' self._set_fake_response( sample_url, status_code=404, reason='Not Found', text='Not Found', ) self.assertRaises(auth.DiscoveryError, auth.check_url, sample_url) def test_invalid_200_not_version(self): # When a 200 but not version response then DiscoveryError is raised. sample_url = 'http://hostname/openstack/identity/v3/users' self._set_fake_response( sample_url, json={'users': []}, ) self.assertRaises(auth.DiscoveryError, auth.check_url, sample_url) def test_invalid_300_not_versions(self): # When a 300 but not versions response then DiscoveryError is raised. sample_url = 'http://hostname/openstack/identity/v3/users' self._set_fake_response( sample_url, status_code=300, reason='Multiple Choices', json={'users': []}) self.assertRaises(auth.DiscoveryError, auth.check_url, sample_url)",,98,1
openstack%2Ftempest-lib~master~Ib435075b9b61954b6b025c80f3fe41917fe0cd7f,openstack/tempest-lib,master,Ib435075b9b61954b6b025c80f3fe41917fe0cd7f,Function to extract data from identity version responses,ABANDONED,2015-12-30 22:13:53.000000000,2016-02-19 13:58:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-12-30 22:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/49dcab235e74e26185babf5753d06f986caa17e1', 'message': 'Function to parse identity version responses\n\nTo do identity version discovery, tempest-lib needs to be able to\nknow how to parse identity version responses.\n\nChange-Id: Ib435075b9b61954b6b025c80f3fe41917fe0cd7f\n'}, {'number': 2, 'created': '2016-01-31 16:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/3f90076333528327dcd5faef495018c7dbd8f5ac', 'message': 'Function to extract data from identity version responses\n\nTo do Identity version discovery, tempest-lib needs to be able to\nknow how to extract version and endpoint info from identity\nversion responses (the result of GET /identity/v3 and\nGET /identity).\n\nChange-Id: Ib435075b9b61954b6b025c80f3fe41917fe0cd7f\n'}, {'number': 3, 'created': '2016-01-31 16:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/4b8195b76f89de41a8007c779db26563e8486678', 'message': 'Function to extract data from identity version responses\n\nTo do Identity version discovery, tempest-lib needs to be able to\nknow how to extract version and endpoint info from identity\nversion responses (the result of GET /identity/v3 and\nGET /identity).\n\nChange-Id: Ib435075b9b61954b6b025c80f3fe41917fe0cd7f\n'}, {'number': 4, 'created': '2016-01-31 16:42:32.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/64231394e5c4dfb12394d7b04ac9af488b321ad7', 'message': 'Function to extract data from identity version responses\n\nTo do Identity version discovery, tempest-lib needs to be able to\nknow how to extract version and endpoint info from identity\nversion responses (the result of GET /identity/v3 and\nGET /identity).\n\nChange-Id: Ib435075b9b61954b6b025c80f3fe41917fe0cd7f\n'}]",0,262618,64231394e5c4dfb12394d7b04ac9af488b321ad7,13,4,4,6486,,,0,"Function to extract data from identity version responses

To do Identity version discovery, tempest-lib needs to be able to
know how to extract version and endpoint info from identity
version responses (the result of GET /identity/v3 and
GET /identity).

Change-Id: Ib435075b9b61954b6b025c80f3fe41917fe0cd7f
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/18/262618/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,49dcab235e74e26185babf5753d06f986caa17e1,bug/1530181," SAMPLE_IDENTITY_V2_VALUE = { ""id"": ""v2.0"", ""links"": [ { ""href"": ""http://hostname/openstack/identity/v2.0/"", ""rel"": ""self"" }, { ""href"": ""http://docs.openstack.org/"", ""rel"": ""describedby"", ""type"": ""text/html"" } ], ""media-types"": [ { ""base"": ""application/json"", ""type"": ""application/vnd.openstack.identity-v2.0+json"" } ], ""status"": ""stable"", ""updated"": ""2014-04-17T00:00:00Z"" } # This is the response you get if you do # http://hostname/openstack/identity/v2.0 SAMPLE_IDENTITY_V2_RESPONSE = { ""version"": SAMPLE_IDENTITY_V2_VALUE } SAMPLE_IDENTITY_V3_VALUE = { ""id"": ""v3.5"", ""links"": [ { ""href"": ""http://hostname/openstack/identity/v3/"", ""rel"": ""self"" } ], ""media-types"": [ { ""base"": ""application/json"", ""type"": ""application/vnd.openstack.identity-v3+json"" } ], ""status"": ""stable"", ""updated"": ""2015-09-15T00:00:00Z"" } # This is the response you get if you do http://hostname/openstack/identity/v3 SAMPLE_IDENTITY_V3_RESPONSE = { ""version"": SAMPLE_IDENTITY_V3_VALUE } class TestParseIdentityVersionResponse(base.TestCase): def test_v2(self): # Verify the result for a GET /v2.0 response. expected = ('v2.0', 'http://hostname/openstack/identity/v2.0/') result = auth.parse_identity_version_response( SAMPLE_IDENTITY_V2_RESPONSE) self.assertEqual(expected, result) def test_v3(self): # Verify the result for a GET /v3 response. expected = ('v3.5', 'http://hostname/openstack/identity/v3/') result = auth.parse_identity_version_response( SAMPLE_IDENTITY_V3_RESPONSE) self.assertEqual(expected, result) def test_invalid_not_dict(self): # When the response isn't a dict then DiscoveryError is raised. sample_response = ['something'] self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_no_version(self): # When the response doesn't have 'version' then DiscoveryError is # raised. sample_response = {'something': 'something'} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_no_links(self): # If the response doesn't have 'links' then DiscoveryError is raised. sample_response = {'version': {}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_links_not_iterable(self): # When the 'links' isn't iterable then DiscoveryError is raised. sample_response = {'version': {'links': 1}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_link_not_dict(self): # When a link isn't dict then DiscoveryError is raised. sample_response = {'version': {'links': [[]]}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_link_no_rel(self): # When a link doesn't have 'rel' then DiscoveryError is raised. sample_response = {'version': {'links': [{'href': 'something'}]}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_no_id(self): # When 'version' doesn't have 'id' then DiscoveryError is raised. sample_response = { 'version': {'links': [{'rel': 'self', 'href': 'something'}]}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) def test_invalid_no_self_link(self): # When 'version' doesn't have 'id' then DiscoveryError is raised. sample_response = { 'version': {'links': [{'rel': 'doc', 'href': 'something'}]}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_version_response, sample_response) # This is the response you get if you do http://hostname/openstack/identity/ # and both versions are enabled. SAMPLE_IDENTITY_VERSIONS_RESPONSE = { ""versions"": { ""values"": [ SAMPLE_IDENTITY_V3_VALUE, SAMPLE_IDENTITY_V2_VALUE ] } } # This is the response you get if you do http://hostname/openstack/identity/ # and only v3 is enabled. SAMPLE_IDENTITY_VERSIONS_RESPONSE_V3_ONLY = { ""versions"": { ""values"": [ SAMPLE_IDENTITY_V3_VALUE ] } } # This is the response you get if you do http://hostname/openstack/identity/ # and only v2 is enabled. SAMPLE_IDENTITY_VERSIONS_RESPONSE_V2_ONLY = { ""versions"": { ""values"": [ SAMPLE_IDENTITY_V2_VALUE ] } } class TestParseIdentityVersionsResponse(base.TestCase): def test_both(self): # Verify the result when both versions are enabled. expected = [('v3.5', 'http://hostname/openstack/identity/v3/'), ('v2.0', 'http://hostname/openstack/identity/v2.0/')] result = auth.parse_identity_versions_response( SAMPLE_IDENTITY_VERSIONS_RESPONSE) self.assertEqual(expected, result) def test_v3_only(self): # Verify the result when only v3 is enabled. expected = [('v3.5', 'http://hostname/openstack/identity/v3/')] result = auth.parse_identity_versions_response( SAMPLE_IDENTITY_VERSIONS_RESPONSE_V3_ONLY) self.assertEqual(expected, result) def test_v2_only(self): # Verify the result when only v3 is enabled. expected = [('v2.0', 'http://hostname/openstack/identity/v2.0/')] result = auth.parse_identity_versions_response( SAMPLE_IDENTITY_VERSIONS_RESPONSE_V2_ONLY) self.assertEqual(expected, result) def test_invalid_not_dict(self): # When 'res' isn't a dict then DiscoveryError is raised. sample_response = 'something' self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response) def test_invalid_no_versions(self): # When 'versions' isn't in the response then DiscoveryError is raised. sample_response = {'something': 'abc'} self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response) def test_invalid_versions_not_dict(self): # When 'versions' isn't a dict then DiscoveryError is raised. sample_response = {'versions': 'abc'} self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response) def test_invalid_no_values(self): # When 'values' isn't in the response then DiscoveryError is raised. sample_response = {'versions': {}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response) def test_invalid_values_not_iterable(self): # When 'values' isn't iterable then DiscoveryError is raised. sample_response = {'versions': {'values': 1}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response) def test_invalid_value_not_version(self): # When value isn't valid version data then DiscoveryError is # raised. sample_response = {'versions': {'values': [{'notvalid': 'something'}]}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response) def test_invalid_value_some_versions_valid(self): # When a value isn't valid version data then DiscoveryError is # raised. # Maybe this should return the valid ones? sample_response = {'versions': {'values': [ SAMPLE_IDENTITY_V3_VALUE, SAMPLE_IDENTITY_V2_VALUE, {'notvalid': 'something'}]}} self.assertRaises( auth.DiscoveryError, auth.parse_identity_versions_response, sample_response)",,294,0
openstack%2Ftempest-lib~master~I0626719ba9a473a8dac0ebda8318ce35d0726f54,openstack/tempest-lib,master,I0626719ba9a473a8dac0ebda8318ce35d0726f54,Add auth.discover_replace_api_version,ABANDONED,2016-01-04 21:32:05.000000000,2016-02-19 13:57:49.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 15482}]","[{'number': 1, 'created': '2016-01-04 21:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/105d65eba1dbc1318f7a49957fc1140a60a32879', 'message': ""Add auth.discover_replace_api_version\n\nTo do replacements with version discovery, we'll need a function\nthat does replacements with version discovery.\n\nChange-Id: I0626719ba9a473a8dac0ebda8318ce35d0726f54\n""}, {'number': 2, 'created': '2016-01-31 17:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/2d0d996228d4a23624eb0d9010dcf18bbe40e6cc', 'message': ""Add auth.discover_replace_api_version\n\nTo do replacements with version discovery, we'll need a function\nthat does replacements with version discovery.\n\nChange-Id: I0626719ba9a473a8dac0ebda8318ce35d0726f54\n""}, {'number': 3, 'created': '2016-01-31 17:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/00e578d99465656239f48fe1150746373c4b6f31', 'message': ""Add auth.discover_replace_api_version\n\nTo do replacements with version discovery, we'll need a function\nthat does replacements with version discovery.\n\nChange-Id: I0626719ba9a473a8dac0ebda8318ce35d0726f54\n""}, {'number': 4, 'created': '2016-02-01 18:52:26.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/c05163a04bb0d832384b7c727555fdbc10b76139', 'message': ""Add auth.discover_replace_api_version\n\nTo do replacements with version discovery, we'll need a function\nthat does replacements with version discovery.\n\nChange-Id: I0626719ba9a473a8dac0ebda8318ce35d0726f54\n""}]",0,263449,c05163a04bb0d832384b7c727555fdbc10b76139,12,3,4,6486,,,0,"Add auth.discover_replace_api_version

To do replacements with version discovery, we'll need a function
that does replacements with version discovery.

Change-Id: I0626719ba9a473a8dac0ebda8318ce35d0726f54
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/49/263449/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,105d65eba1dbc1318f7a49957fc1140a60a32879,bug/1530181," self.assertEqual((2, 0), auth.parse_version('v2.0')) self.assertEqual((3, 5), auth.parse_version('v3.5')) self.assertEqual((3,), auth.parse_version('v3')) self.assertEqual(tuple(), auth.parse_version('')) auth.get_version_endpoint(target_version, versions)) auth.get_version_endpoint(target_version, versions)) auth.get_version_endpoint(target_version, versions)) auth.get_version_endpoint(target_version, versions)) class TestReplaceApiVersionUsingDiscovery(base.TestCase): def test_works_no_trailing(self): # When discovery works and there's no trailing path, the result is just # the endpoint for the requested version that the version request # returned. url = 'http://hostname/openstack/identity/' m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) m.get(url, status_code=300, reason='Multiple Choices', json=SAMPLE_IDENTITY_VERSIONS_RESPONSE) res = auth.discover_replace_api_version(url, 'v3') self.assertEqual('http://hostname/openstack/identity/v3/', res) def test_works_trailing(self): # When there's a trailing path and discovery works the version is # replaced and the trailing path is still there. url = 'http://hostname/openstack/identity/v3/something' m = requests_mock.Mocker() m.start() self.addCleanup(m.stop) m.get('http://hostname/openstack/identity', status_code=300, reason='Multiple Choices', json=SAMPLE_IDENTITY_VERSIONS_RESPONSE) m.get('http://hostname/openstack/identity/v3', json=SAMPLE_IDENTITY_V3_RESPONSE) m.get(url, status_code=401, reason='Unauthorized', text='not authorized') res = auth.discover_replace_api_version(url, 'v2') self.assertEqual('http://hostname/openstack/identity/v2.0/something', res)"," self.assertEquals((2, 0), auth.parse_version('v2.0')) self.assertEquals((3, 5), auth.parse_version('v3.5')) self.assertEquals((3,), auth.parse_version('v3')) self.assertEquals(tuple(), auth.parse_version('')) auth.get_version_endpoint(target_version, versions)) auth.get_version_endpoint(target_version, versions)) auth.get_version_endpoint(target_version, versions)) auth.get_version_endpoint(target_version, versions))",61,8
openstack%2Ftempest-lib~master~I070b9b76a3f2c627e86642bd65a99b8cb5d793b3,openstack/tempest-lib,master,I070b9b76a3f2c627e86642bd65a99b8cb5d793b3,Use discovery for version replacement,ABANDONED,2016-01-04 21:42:19.000000000,2016-02-19 13:57:38.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 15482}]","[{'number': 1, 'created': '2016-01-04 21:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/ae143bd4dd0637b32d45e9dc813eec0a20c12695', 'message': 'Use discovery for version replacement\n\nWhen doing version replacement, first try using version discovery\nand only do string replacement if that failed.\n\nChange-Id: I070b9b76a3f2c627e86642bd65a99b8cb5d793b3\n'}, {'number': 2, 'created': '2016-01-31 17:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/98f3967579db9920a86d24dc0faf5066f7b46d3d', 'message': 'Use discovery for version replacement\n\nWhen doing version replacement, first try using version discovery\nand only do string replacement if that failed.\n\nChange-Id: I070b9b76a3f2c627e86642bd65a99b8cb5d793b3\n'}, {'number': 3, 'created': '2016-01-31 17:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/4ff8ef70e9abba782c0663a521acb6b110c928c8', 'message': 'Use discovery for version replacement\n\nWhen doing version replacement, first try using version discovery\nand only do string replacement if that failed.\n\nChange-Id: I070b9b76a3f2c627e86642bd65a99b8cb5d793b3\n'}, {'number': 4, 'created': '2016-02-01 18:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/6bfc585718041eb0115c0a60bf81355ea75146d4', 'message': 'Use discovery for version replacement\n\nWhen doing version replacement, first try using version discovery\nand only do string replacement if that failed.\n\nChange-Id: I070b9b76a3f2c627e86642bd65a99b8cb5d793b3\n'}, {'number': 5, 'created': '2016-02-01 19:09:31.000000000', 'files': ['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/0725c97c329af2cb50726cdfeb41bd35a3d3faaf', 'message': 'Use discovery for version replacement\n\nWhen doing version replacement, first try using version discovery\nand only do string replacement if that failed.\n\nChange-Id: I070b9b76a3f2c627e86642bd65a99b8cb5d793b3\n'}]",0,263452,0725c97c329af2cb50726cdfeb41bd35a3d3faaf,14,3,5,6486,,,0,"Use discovery for version replacement

When doing version replacement, first try using version discovery
and only do string replacement if that failed.

Change-Id: I070b9b76a3f2c627e86642bd65a99b8cb5d793b3
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/52/263452/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest_lib/auth.py'],1,ae143bd4dd0637b32d45e9dc813eec0a20c12695,bug/1530181," try: return discover_replace_api_version(url, new_version) except DiscoveryError: # Discovery didn't work, go back to old behavior of string replacement. pass ",,6,0
openstack%2Fanchor~master~I0c89ee950d27fb36e3c9b6f22b3d13d9e4d8c20c,openstack/anchor,master,I0c89ee950d27fb36e3c9b6f22b3d13d9e4d8c20c,Raise better error on file read problems,MERGED,2016-02-04 03:25:16.000000000,2016-02-19 13:57:10.000000000,2016-02-19 13:57:10.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2016-02-04 03:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/f0aa593cf4e5a793d5fda12ceed7653f00ae3c94', 'message': 'Raise better error on file read problems\n\nChange-Id: I0c89ee950d27fb36e3c9b6f22b3d13d9e4d8c20c\n'}, {'number': 2, 'created': '2016-02-08 05:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/506455aef53f1a6968389b2d4cb593f9a0b71380', 'message': 'Raise better error on file read problems\n\nChange-Id: I0c89ee950d27fb36e3c9b6f22b3d13d9e4d8c20c\n'}, {'number': 3, 'created': '2016-02-08 05:44:33.000000000', 'files': ['anchor/X509/signing_request.py', 'tests/X509/test_x509_csr.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/9e7cdf50b18aed553f031291eb55ec42913938c3', 'message': 'Raise better error on file read problems\n\nChange-Id: I0c89ee950d27fb36e3c9b6f22b3d13d9e4d8c20c\n'}]",0,276025,9e7cdf50b18aed553f031291eb55ec42913938c3,13,4,3,1528,,,0,"Raise better error on file read problems

Change-Id: I0c89ee950d27fb36e3c9b6f22b3d13d9e4d8c20c
",git fetch https://review.opendev.org/openstack/anchor refs/changes/25/276025/1 && git format-patch -1 --stdout FETCH_HEAD,['anchor/X509/signing_request.py'],1,f0aa593cf4e5a793d5fda12ceed7653f00ae3c94,better_error," except IOError: raise X509CsrError(""Could not read from file %s"" % f)",,2,0
openstack%2Ffuel-ostf~master~If1f66939ac568a9faff2142564ba94ad5cf10352,openstack/fuel-ostf,master,If1f66939ac568a9faff2142564ba94ad5cf10352,Fix test check openstack cred changed,MERGED,2016-02-19 09:49:02.000000000,2016-02-19 13:56:48.000000000,2016-02-19 13:56:42.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 10808}, {'_account_id': 14614}, {'_account_id': 16414}]","[{'number': 1, 'created': '2016-02-19 09:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/7a2c70eda100fc8eb9edc4e53bb5e866e550c754', 'message': 'Fix test check openstack creadenational changed\n\nAssert that any of user or password was changed, if so tests passed.\nIf user and passward for openstack stay with default value, test fail.\n\nChange-Id: If1f66939ac568a9faff2142564ba94ad5cf10352\nCloses-Bug: #1547022\n'}, {'number': 2, 'created': '2016-02-19 10:40:25.000000000', 'files': ['fuel_health/tests/configuration/test_configuration.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/f85307434cfe19ec7647fdf8228469c863d711ae', 'message': 'Fix test check openstack cred changed\n\nAssert that any of user or password was changed, if so test pass.\nIf user and password for openstack stay with default value, test fail.\n\nChange-Id: If1f66939ac568a9faff2142564ba94ad5cf10352\nCloses-Bug: #1547022\n'}]",0,282251,f85307434cfe19ec7647fdf8228469c863d711ae,18,6,2,6719,,,0,"Fix test check openstack cred changed

Assert that any of user or password was changed, if so test pass.
If user and password for openstack stay with default value, test fail.

Change-Id: If1f66939ac568a9faff2142564ba94ad5cf10352
Closes-Bug: #1547022
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/51/282251/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/tests/configuration/test_configuration.py'],1,7a2c70eda100fc8eb9edc4e53bb5e866e550c754,1547022," 'username': self.config.identity.admin_username} default_data = { 'password': 'admin', 'username': 'admin'} self.verify_response_body_not_equal( exp_content=default_data, act_content=cluster_data, msg='Default credentials values are used. ' 'We kindly recommend that you changed all defaults.', failed_step='1')"," 'username': self.config.identity.admin_username, 'tenant': self.config.identity.admin_tenant_name} for key in cluster_data: self.verify_response_body_not_equal( exp_content='admin', act_content=cluster_data[key], msg='Default credentials values are used. ' 'We kindly recommend that you changed all defaults.', failed_step='1')",11,9
openstack%2Ffuel-qa~stable%2F8.0~I0bafd2de624ece0e882de1c182ddad2573f51641,openstack/fuel-qa,stable/8.0,I0bafd2de624ece0e882de1c182ddad2573f51641,Fix network template for manual tests,MERGED,2016-02-19 13:27:08.000000000,2016-02-19 13:55:47.000000000,2016-02-19 13:55:47.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2016-02-19 13:27:08.000000000', 'files': ['fuelweb_test/network_templates/hardware.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/06fdb8dcc703bf2fc1e852e14ce9d16aaeee5b49', 'message': ""Fix network template for manual tests\n\nFix network template which is used during manual\ntesting:\n\n * correct default NICs mapping\n * remove incorrect bond creation (transformation\n   format was changed) since it can't be used on\n   environments with NICs located in different L2\n\nChange-Id: I0bafd2de624ece0e882de1c182ddad2573f51641\n""}]",0,282333,06fdb8dcc703bf2fc1e852e14ce9d16aaeee5b49,10,6,1,11081,,,0,"Fix network template for manual tests

Fix network template which is used during manual
testing:

 * correct default NICs mapping
 * remove incorrect bond creation (transformation
   format was changed) since it can't be used on
   environments with NICs located in different L2

Change-Id: I0bafd2de624ece0e882de1c182ddad2573f51641
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/33/282333/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/network_templates/hardware.yaml'],1,06fdb8dcc703bf2fc1e852e14ce9d16aaeee5b49,fix_manual_net_template, name: <% if2 %>.360 if1: enp0s3 if2: enp0s4, name: <% if1 %>.360 - action: add-port name: <% if2 %>.360 - action: add-bond bond_properties: mode: active-backup interface_properties: {} interfaces: - <% if1 %>.360 - <% if2 %>.360 name: lnxbond0 if1: enp0s1 if2: enp0s2,3,13
openstack%2Ffuel-qa~master~I0bafd2de624ece0e882de1c182ddad2573f51641,openstack/fuel-qa,master,I0bafd2de624ece0e882de1c182ddad2573f51641,Fix network template for manual tests,MERGED,2016-02-19 13:26:29.000000000,2016-02-19 13:55:44.000000000,2016-02-19 13:55:44.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2016-02-19 13:26:29.000000000', 'files': ['fuelweb_test/network_templates/hardware.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/7160d3aa52cad22d99465addc44cf729266a26a1', 'message': ""Fix network template for manual tests\n\nFix network template which is used during manual\ntesting:\n\n * correct default NICs mapping\n * remove incorrect bond creation (transformation\n   format was changed) since it can't be used on\n   environments with NICs located in different L2\n\nChange-Id: I0bafd2de624ece0e882de1c182ddad2573f51641\n""}]",0,282331,7160d3aa52cad22d99465addc44cf729266a26a1,11,6,1,11081,,,0,"Fix network template for manual tests

Fix network template which is used during manual
testing:

 * correct default NICs mapping
 * remove incorrect bond creation (transformation
   format was changed) since it can't be used on
   environments with NICs located in different L2

Change-Id: I0bafd2de624ece0e882de1c182ddad2573f51641
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/31/282331/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/network_templates/hardware.yaml'],1,7160d3aa52cad22d99465addc44cf729266a26a1,fix_manual_net_template, name: <% if2 %>.360 if1: enp0s3 if2: enp0s4, name: <% if1 %>.360 - action: add-port name: <% if2 %>.360 - action: add-bond bond_properties: mode: active-backup interface_properties: {} interfaces: - <% if1 %>.360 - <% if2 %>.360 name: lnxbond0 if1: enp0s1 if2: enp0s2,3,13
openstack%2Fproject-config~master~I4404aa2c3084c35849964b67ff8c8a3a0342806e,openstack/project-config,master,I4404aa2c3084c35849964b67ff8c8a3a0342806e,Fix centos support for bindep-fallback.txt,MERGED,2016-02-19 01:15:44.000000000,2016-02-19 13:50:53.000000000,2016-02-19 13:50:52.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-19 01:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a0784bad00650f8f620c96b5c2937295860d71b', 'message': 'Fix centos support for bindep-fallback.txt\n\nLooking at the current experimental job[1] we can see 5 packages that\nfail to install, 3 are mysql, 1 python3-devel and 1 dvipng. This patch\nupdates bindep to use the RHEL based package names.\n\n[1] http://logs.openstack.org/94/264994/4/experimental/gate-bindep-fallback-devstack-centos7-nv/f7d9d8e/console.html\n\nChange-Id: I4404aa2c3084c35849964b67ff8c8a3a0342806e\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}, {'number': 2, 'created': '2016-02-19 01:21:04.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6d32de036da48f2648077f551d6ccb17a9a6ad27', 'message': 'Fix centos support for bindep-fallback.txt\n\nLooking at the current experimental job[1] we can see 5 packages that\nfail to install, 3 are mysql, 1 python3-devel and 1 dvipng. This patch\nupdates bindep to use the RHEL based package names.\n\n[1] http://logs.openstack.org/94/264994/4/experimental/gate-bindep-fallback-devstack-centos7-nv/f7d9d8e/console.html\n\nChange-Id: I4404aa2c3084c35849964b67ff8c8a3a0342806e\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",1,282122,6d32de036da48f2648077f551d6ccb17a9a6ad27,13,4,2,4162,,,0,"Fix centos support for bindep-fallback.txt

Looking at the current experimental job[1] we can see 5 packages that
fail to install, 3 are mysql, 1 python3-devel and 1 dvipng. This patch
updates bindep to use the RHEL based package names.

[1] http://logs.openstack.org/94/264994/4/experimental/gate-bindep-fallback-devstack-centos7-nv/f7d9d8e/console.html

Change-Id: I4404aa2c3084c35849964b67ff8c8a3a0342806e
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/282122/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,4a0784bad00650f8f620c96b5c2937295860d71b,,dvipng [platform:dpkg]mariadb [platform:rpm] mariadb-devel [platform:rpm] mariadb-server [platform:rpm]mysql-server [platform:dpkg]python3-devel [platform:fedora] python34-devel [platform:centos]texlive-dvipng-bin [platform:rpm],dvipngmysql-devel [platform:rpm] mysql-serverpython3-devel [platform:rpm],8,4
openstack%2Fproject-config~master~If9f92717a6f0b309e0b76bb596046393a6c58b12,openstack/project-config,master,If9f92717a6f0b309e0b76bb596046393a6c58b12,Switch gate-{name}-requirements-bindep to ubuntu-trusty,MERGED,2016-02-18 15:25:13.000000000,2016-02-19 13:50:01.000000000,2016-02-19 13:50:01.000000000,"[{'_account_id': 3}, {'_account_id': 5545}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-18 15:25:13.000000000', 'files': ['jenkins/jobs/experimental-workers.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c860c9df4659a2a98d60f3e76a3f586beafeb6f4', 'message': 'Switch gate-{name}-requirements-bindep to ubuntu-trusty\n\nBecause this is a bindep job, we need to be using ubuntu-trusty as we\nplan to migrate away from bare-trusty.\n\nChange-Id: If9f92717a6f0b309e0b76bb596046393a6c58b12\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,281907,c860c9df4659a2a98d60f3e76a3f586beafeb6f4,8,4,1,4162,,,0,"Switch gate-{name}-requirements-bindep to ubuntu-trusty

Because this is a bindep job, we need to be using ubuntu-trusty as we
plan to migrate away from bare-trusty.

Change-Id: If9f92717a6f0b309e0b76bb596046393a6c58b12
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/281907/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/experimental-workers.yaml'],1,c860c9df4659a2a98d60f3e76a3f586beafeb6f4,, node: ubuntu-trusty, node: bare-trusty,1,1
openstack%2Ffuel-qa~master~If22c32f1bba34fc73a0ea8afe4e59f53b7242657,openstack/fuel-qa,master,If22c32f1bba34fc73a0ea8afe4e59f53b7242657,Fix type error in test_cli.py,MERGED,2016-02-19 08:43:47.000000000,2016-02-19 13:48:57.000000000,2016-02-19 13:48:57.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 16414}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-02-19 08:43:47.000000000', 'files': ['fuelweb_test/tests/test_cli.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/333b4c319813c2353cdb1827e0f8862e450ec954', 'message': 'Fix type error in test_cli.py\n\nMethods signatures in tests.cli_base.py were changed.\nSo we need to update it usage in test_cli.py\n\nChange-Id: If22c32f1bba34fc73a0ea8afe4e59f53b7242657\nRelated-Bug: #1547195\n'}]",0,282232,333b4c319813c2353cdb1827e0f8862e450ec954,21,6,1,6719,,,0,"Fix type error in test_cli.py

Methods signatures in tests.cli_base.py were changed.
So we need to update it usage in test_cli.py

Change-Id: If22c32f1bba34fc73a0ea8afe4e59f53b7242657
Related-Bug: #1547195
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/32/282232/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_cli.py'],1,333b4c319813c2353cdb1827e0f8862e450ec954,type_err," self.update_cli_network_configuration(cluster_id) self.get_floating_ranges(cluster_id) self.change_floating_ranges(cluster_id, new_floating_range) self.update_ssl_configuration(cluster_id) self.assert_cli_task_success(task, timeout=30 * 60) self.assert_cli_task_success(task, timeout=10 * 60) self.assert_cli_task_success(task, timeout=60 * 60) self.assert_cli_task_success(task, timeout=30 * 60)"," self.update_cli_network_configuration(cluster_id, remote) self.get_floating_ranges(cluster_id, remote) self.change_floating_ranges(cluster_id, remote, new_floating_range) self.update_ssl_configuration(cluster_id, remote) self.assert_cli_task_success(task, remote, timeout=30 * 60) self.assert_cli_task_success(task, remote, timeout=10 * 60) self.assert_cli_task_success(task, remote, timeout=60 * 60) self.assert_cli_task_success(task, remote, timeout=30 * 60)",8,8
openstack%2Fglance-specs~master~Ibb83f56b2b37a5b96318e0a1a5669e774cf28568,openstack/glance-specs,master,Ibb83f56b2b37a5b96318e0a1a5669e774cf28568,Update README in glance-specs repo,MERGED,2016-02-05 21:52:43.000000000,2016-02-19 13:44:49.000000000,2016-02-19 13:44:49.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 14676}]","[{'number': 1, 'created': '2016-02-05 21:52:43.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/0ad059e6ed4258dd4e25e257c159059beef06cad', 'message': ""Update README in glance-specs repo\n\nThis commit updates the README in the glance-specs repo to include\ninformation about the 'approved' and 'implemented' subdirectories\nadded for the Mitaka release.\n\nChange-Id: Ibb83f56b2b37a5b96318e0a1a5669e774cf28568\n""}]",0,276925,0ad059e6ed4258dd4e25e257c159059beef06cad,8,3,1,5314,,,0,"Update README in glance-specs repo

This commit updates the README in the glance-specs repo to include
information about the 'approved' and 'implemented' subdirectories
added for the Mitaka release.

Change-Id: Ibb83f56b2b37a5b96318e0a1a5669e774cf28568
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/25/276925/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,0ad059e6ed4258dd4e25e257c159059beef06cad,update-readme,"==============================================================The general layout of this repository is::Beginning with the Mitaka release, there is a further subdivision into specs/<release>/approved specs/<release>/implemented A specification is proposed for a given release by adding it to the `specs/<release>/approved` directory and posting it for review. The implementation status of a blueprint for a given release can be found by looking at the blueprint in launchpad. Not all approved blueprints will get fully implemented. When a feature has been completed, its specification will be moved to the 'implemented' directory for the release in which it was implemented.",====================================================================The layout of this repository is::Specifications are proposed for a given release by adding them to the `specs/<release>` directory and posting it for review. The implementation status of a blueprint for a given release can be found by looking at the blueprint in launchpad. Not all approved blueprints will get fully implemented.,16,7
openstack%2Fglance~master~If43ccd09c2bde1e8b39a7b933bd4b233f7f75a15,openstack/glance,master,If43ccd09c2bde1e8b39a7b933bd4b233f7f75a15,Fix a typo in glance-glare-paste.ini,ABANDONED,2016-02-16 13:15:32.000000000,2016-02-19 13:44:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 15054}, {'_account_id': 16683}]","[{'number': 1, 'created': '2016-02-16 13:15:32.000000000', 'files': ['etc/glance-glare-paste.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/a9e8a36b18124cacf64217048e14cbc843ebc9fb', 'message': 'Fix a typo in glance-glare-paste.ini\n\nThis prevents the service from starting with the default configuration.\nCloses-Bug: #1544964\n\nChange-Id: If43ccd09c2bde1e8b39a7b933bd4b233f7f75a15\n'}]",0,280684,a9e8a36b18124cacf64217048e14cbc843ebc9fb,4,8,1,8122,,,0,"Fix a typo in glance-glare-paste.ini

This prevents the service from starting with the default configuration.
Closes-Bug: #1544964

Change-Id: If43ccd09c2bde1e8b39a7b933bd4b233f7f75a15
",git fetch https://review.opendev.org/openstack/glance refs/changes/84/280684/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/glance-glare-paste.ini'],1,a9e8a36b18124cacf64217048e14cbc843ebc9fb,bug/1544964,paste.app_factory = glance.api.glare.v0_1.router:API.factory,paste.app_factory = glance.api.glare.router:API.factory,1,1
openstack%2Fopenstack-ansible~liberty~Ia7935daefc6e873eb1950f42f2b69b753ed252f0,openstack/openstack-ansible,liberty,Ia7935daefc6e873eb1950f42f2b69b753ed252f0,Validate type of loaded yaml configuration files,MERGED,2016-02-12 15:16:01.000000000,2016-02-19 13:42:09.000000000,2016-02-19 13:42:09.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 10881}]","[{'number': 1, 'created': '2016-02-12 15:16:01.000000000', 'files': ['playbooks/plugins/lookups/py_pkgs.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7e5fa707a324c091e11e8b2f87ddf1e4aeed6d5f', 'message': ""Validate type of loaded yaml configuration files\n\nProcessed yaml configuration files are expected to have iterable\nkey-value pairs so loaded_configs should be validated to make sure\nthey're dictionary objects.\n\nAnsible Vault encrypted user_secrets will be loaded by yaml as a string\nand then ignored from further processing.\n\nThis is a backport of https://review.openstack.org/#/c/276456\n\nChange-Id: Ia7935daefc6e873eb1950f42f2b69b753ed252f0\n""}]",0,279594,7e5fa707a324c091e11e8b2f87ddf1e4aeed6d5f,8,4,1,14805,,,0,"Validate type of loaded yaml configuration files

Processed yaml configuration files are expected to have iterable
key-value pairs so loaded_configs should be validated to make sure
they're dictionary objects.

Ansible Vault encrypted user_secrets will be loaded by yaml as a string
and then ignored from further processing.

This is a backport of https://review.openstack.org/#/c/276456

Change-Id: Ia7935daefc6e873eb1950f42f2b69b753ed252f0
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/279594/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/plugins/lookups/py_pkgs.py'],1,7e5fa707a324c091e11e8b2f87ddf1e4aeed6d5f,ensure_loaded_yaml_dict," if not loaded_config or not isinstance(loaded_config, dict):", if not loaded_config:,1,1
openstack%2Ffuel-octane~stable%2F8.0~Ia04b0b7290830ef997ddd7a84205a64837b6b77c,openstack/fuel-octane,stable/8.0,Ia04b0b7290830ef997ddd7a84205a64837b6b77c,Define required method 'backup' for puppet archiver,MERGED,2016-02-19 13:27:42.000000000,2016-02-19 13:39:13.000000000,2016-02-19 13:39:07.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}]","[{'number': 1, 'created': '2016-02-19 13:27:42.000000000', 'files': ['octane/handlers/backup_restore/puppet.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/54b5a8b0c359808e43f8381f4897a869fb60084a', 'message': ""Define required method 'backup' for puppet archiver\n\nChange-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c\n(cherry picked from commit 8209db6af1faa421d0bde704294284ee42540014)\n""}]",0,282334,54b5a8b0c359808e43f8381f4897a869fb60084a,8,3,1,6677,,,0,"Define required method 'backup' for puppet archiver

Change-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c
(cherry picked from commit 8209db6af1faa421d0bde704294284ee42540014)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/34/282334/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/handlers/backup_restore/puppet.py'],1,54b5a8b0c359808e43f8381f4897a869fb60084a,, def backup(self): pass ,,3,0
openstack%2Ffuel-octane~stable%2F7.0~I84ed978bdb8b95dc3074ec544ff91f44f8f58f9e,openstack/fuel-octane,stable/7.0,I84ed978bdb8b95dc3074ec544ff91f44f8f58f9e,Remove --detailed-exitcodes flag from puppet agent,MERGED,2016-02-19 11:52:34.000000000,2016-02-19 13:38:46.000000000,2016-02-19 13:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}, {'_account_id': 10808}]","[{'number': 1, 'created': '2016-02-19 11:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/fc327bdd73466f2d7babc790e564db90f971dfa9', 'message': 'Remove --detailed-exitcodes flag from puppet agent\n\nCalling --detailed-exitcodes flag causes the puppet agent to\nexit with non-0 code upon successful execution (exit code 2) [1].\n\nDelete the flag from call to the puppet agent.\n\n[1] https://docs.puppetlabs.com/puppet/latest/reference/man/agent.html\n\nChange-Id: I84ed978bdb8b95dc3074ec544ff91f44f8f58f9e\nRelated-bug: 1544967\n(cherry picked from commit 8516a995e3d0dca9efaed471476ce51886c2c333)\n'}, {'number': 2, 'created': '2016-02-19 13:11:36.000000000', 'files': ['octane/util/puppet.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/8b679e3e16ba89c93d9447212faa743d9773c07f', 'message': 'Remove --detailed-exitcodes flag from puppet agent\n\nCalling --detailed-exitcodes flag causes the puppet agent to\nexit with non-0 code upon successful execution (exit code 2) [1].\n\nDelete the flag from call to the puppet agent.\n\n[1] https://docs.puppetlabs.com/puppet/latest/reference/man/agent.html\n\nChange-Id: I84ed978bdb8b95dc3074ec544ff91f44f8f58f9e\nRelated-bug: 1544967\n(cherry picked from commit 8516a995e3d0dca9efaed471476ce51886c2c333)\n'}]",0,282296,8b679e3e16ba89c93d9447212faa743d9773c07f,10,4,2,708,,,0,"Remove --detailed-exitcodes flag from puppet agent

Calling --detailed-exitcodes flag causes the puppet agent to
exit with non-0 code upon successful execution (exit code 2) [1].

Delete the flag from call to the puppet agent.

[1] https://docs.puppetlabs.com/puppet/latest/reference/man/agent.html

Change-Id: I84ed978bdb8b95dc3074ec544ff91f44f8f58f9e
Related-bug: 1544967
(cherry picked from commit 8516a995e3d0dca9efaed471476ce51886c2c333)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/96/282296/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/util/puppet.py'],1,fc327bdd73466f2d7babc790e564db90f971dfa9,282317," cmd = ['puppet', 'apply', '-d', '-v']"," cmd = ['puppet', 'apply', '-d', '-v', '--detailed-exitcodes']",1,1
openstack%2Ffuel-octane~stable%2F7.0~Ibd59fb6b0d2d37f708e8d4c48c99a92d4e9ceef9,openstack/fuel-octane,stable/7.0,Ibd59fb6b0d2d37f708e8d4c48c99a92d4e9ceef9,Run 'puppet apply' command at host,MERGED,2016-02-12 11:10:56.000000000,2016-02-19 13:37:40.000000000,2016-02-19 13:37:33.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 10808}]","[{'number': 1, 'created': '2016-02-12 11:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/06026a45fbdf6e86692d8d4db540774d285363a0', 'message': ""Run 'puppet apply' command at host\n\nRun command 'puppet apply' in host system at Fuel Admin node\nimmediately after the /etc/fuel/astute.yaml file is updates\nwith values from backup.\n\nChange-Id: Ibd59fb6b0d2d37f708e8d4c48c99a92d4e9ceef9\nBlueprint: create-standalone-script-to-backup-masternode\n(cherry picked from commit 4f8f53665f776ceb6e3a089e164e3473cd1ed8ad)\n""}, {'number': 2, 'created': '2016-02-12 13:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/105439ebe3904c20d8110f6f4bd93dc04e5203ba', 'message': ""Run 'puppet apply' command at host\n\nRun command 'puppet apply' in host system at Fuel Admin node\nimmediately after the /etc/fuel/astute.yaml file is updates\nwith values from backup.\n\nChange-Id: Ibd59fb6b0d2d37f708e8d4c48c99a92d4e9ceef9\nBlueprint: create-standalone-script-to-backup-masternode\n(cherry picked from commit 4f8f53665f776ceb6e3a089e164e3473cd1ed8ad)\n""}, {'number': 3, 'created': '2016-02-19 13:11:36.000000000', 'files': ['octane/util/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/tests/test_util_puppet.py', 'octane/handlers/backup_restore/astute.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/7a0487d7b91545ada7beb007b08a9f36ffb25619', 'message': ""Run 'puppet apply' command at host\n\nRun command 'puppet apply' in host system at Fuel Admin node\nimmediately after the /etc/fuel/astute.yaml file is updates\nwith values from backup.\n\nChange-Id: Ibd59fb6b0d2d37f708e8d4c48c99a92d4e9ceef9\nBlueprint: create-standalone-script-to-backup-masternode\n(cherry picked from commit 4f8f53665f776ceb6e3a089e164e3473cd1ed8ad)\n""}]",0,279478,7a0487d7b91545ada7beb007b08a9f36ffb25619,13,3,3,6677,,,0,"Run 'puppet apply' command at host

Run command 'puppet apply' in host system at Fuel Admin node
immediately after the /etc/fuel/astute.yaml file is updates
with values from backup.

Change-Id: Ibd59fb6b0d2d37f708e8d4c48c99a92d4e9ceef9
Blueprint: create-standalone-script-to-backup-masternode
(cherry picked from commit 4f8f53665f776ceb6e3a089e164e3473cd1ed8ad)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/78/279478/2 && git format-patch -1 --stdout FETCH_HEAD,"['octane/util/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/tests/test_util_puppet.py', 'octane/handlers/backup_restore/astute.py']",4,06026a45fbdf6e86692d8d4db540774d285363a0,282317,from octane.util import puppet # run 'puppet apply' in the host system puppet.apply_host(),,67,0
openstack%2Ffuel-octane~master~Ia04b0b7290830ef997ddd7a84205a64837b6b77c,openstack/fuel-octane,master,Ia04b0b7290830ef997ddd7a84205a64837b6b77c,Define required method 'backup' for puppet archiver,MERGED,2016-02-19 07:53:53.000000000,2016-02-19 13:27:42.000000000,2016-02-19 12:29:26.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 6677}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-02-19 07:53:53.000000000', 'files': ['octane/handlers/backup_restore/puppet.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/8209db6af1faa421d0bde704294284ee42540014', 'message': ""Define required method 'backup' for puppet archiver\n\nChange-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c\n""}]",0,282218,8209db6af1faa421d0bde704294284ee42540014,9,5,1,6677,,,0,"Define required method 'backup' for puppet archiver

Change-Id: Ia04b0b7290830ef997ddd7a84205a64837b6b77c
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/18/282218/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/handlers/backup_restore/puppet.py'],1,8209db6af1faa421d0bde704294284ee42540014,, def backup(self): pass ,,3,0
openstack%2Fopenstack-manuals~master~I5edd175b095916338059a6d4023b60f06a65738f,openstack/openstack-manuals,master,I5edd175b095916338059a6d4023b60f06a65738f,[networking-guide] change awkward wording in sentence,MERGED,2016-02-16 18:38:33.000000000,2016-02-19 13:22:48.000000000,2016-02-18 11:16:36.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 10068}, {'_account_id': 10497}, {'_account_id': 13995}, {'_account_id': 14374}, {'_account_id': 14962}, {'_account_id': 17711}, {'_account_id': 19779}, {'_account_id': 20376}, {'_account_id': 20575}, {'_account_id': 20576}]","[{'number': 1, 'created': '2016-02-16 18:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0d368ef450e6920b91c9e68990f8403d0d83d467', 'message': 'small change in networking guide\nremoved awkward wording in sentence\nchanged one such example to an example\n\nChange-Id: I5edd175b095916338059a6d4023b60f06a65738f\n'}, {'number': 2, 'created': '2016-02-18 10:45:36.000000000', 'files': ['doc/networking-guide/source/intro-network-address-translation.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/338969d503a13bdc9f5d29f420c727172e70b44e', 'message': '[networking-guide] change awkward wording in sentence\n\nChange-Id: I5edd175b095916338059a6d4023b60f06a65738f\n'}]",0,280879,338969d503a13bdc9f5d29f420c727172e70b44e,21,12,2,20488,,,0,"[networking-guide] change awkward wording in sentence

Change-Id: I5edd175b095916338059a6d4023b60f06a65738f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/280879/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/intro-network-address-translation.rst'],1,0d368ef450e6920b91c9e68990f8403d0d83d467,networking_guide,connect to a server on the public Internet. An example is a user,connect to a server on the public Internet. One such example is a user,1,1
openstack%2Fopenstack-manuals~master~Ic3e847021d0b765ec9f71cfb30d5ce0c6128b960,openstack/openstack-manuals,master,Ic3e847021d0b765ec9f71cfb30d5ce0c6128b960,made small change to network guide,MERGED,2016-02-16 23:38:55.000000000,2016-02-19 13:19:34.000000000,2016-02-17 09:41:47.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 10897}, {'_account_id': 14033}, {'_account_id': 19779}, {'_account_id': 20576}]","[{'number': 1, 'created': '2016-02-16 23:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1f8dc782d281e0c7655a735503fb6a4510e606d8', 'message': 'made small change to network guide\nreplaced capital T w lower case t\nchanged However, This to However, this\n\nChange-Id: Ic3e847021d0b765ec9f71cfb30d5ce0c6128b960\n'}, {'number': 2, 'created': '2016-02-17 00:06:19.000000000', 'files': ['doc/networking-guide/source/scenario-dvr-ovs.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4f136e7159292128b9c10c6169d9f172e0983ca8', 'message': 'made small change to network guide\n\nreplaced capital T w lower case t\nchanged However, This to However, this\n\nChange-Id: Ic3e847021d0b765ec9f71cfb30d5ce0c6128b960\n'}]",1,280987,4f136e7159292128b9c10c6169d9f172e0983ca8,27,8,2,20488,,,0,"made small change to network guide

replaced capital T w lower case t
changed However, This to However, this

Change-Id: Ic3e847021d0b765ec9f71cfb30d5ce0c6128b960
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/280987/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/scenario-dvr-ovs.rst'],1,1f8dc782d281e0c7655a735503fb6a4510e606d8,networking_guide,"external network and one VXLAN project (tenant) network. However, this","external network and one VXLAN project (tenant) network. However, This",1,1
openstack%2Fglance_store~master~Ifaa15b794a7213c1c393288631d071ac66dcbc81,openstack/glance_store,master,Ifaa15b794a7213c1c393288631d071ac66dcbc81,Add small image verifier for swift backend,MERGED,2016-01-12 22:59:42.000000000,2016-02-19 13:18:07.000000000,2016-02-19 13:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 6159}, {'_account_id': 6802}, {'_account_id': 14676}, {'_account_id': 15524}]","[{'number': 1, 'created': '2016-01-12 22:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/58a61128fa3d7d2b97722e34ff269bac25178591', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 2, 'created': '2016-01-19 14:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/94bacadc88e2b98727bae33e0c83b9473991050b', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 3, 'created': '2016-01-20 15:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/e5c4cf57346c9b74262cb1550f30d6eeffa4e9a1', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 4, 'created': '2016-01-21 14:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/d461d2cde3c13175a93e85ef4558cb78257295a3', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 5, 'created': '2016-01-21 16:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/94bcafbc3d8ac0f97a828b775d6c27f18af1e46b', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 6, 'created': '2016-02-15 15:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/a44c27abfaa34f6387c6e050a151a6fe1c72441c', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 7, 'created': '2016-02-15 16:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/f2b84d2ad63b05ce7727f14163de5cb00750d09c', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}, {'number': 8, 'created': '2016-02-18 07:06:42.000000000', 'files': ['glance_store/_drivers/swift/store.py', 'glance_store/tests/unit/test_swift_store.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/73a9deaec134181264f53833685c4c3217917179', 'message': ""Add small image verifier for swift backend\n\nIn the parent patch, the swift driver is supported for images that\nare greater than the 'large_object_size.'  This patch adds support\nfor images that are less than the 'large_object_size.'\n\nChange-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81\nPartial-Bug: #1516031\n""}]",8,266606,73a9deaec134181264f53833685c4c3217917179,33,6,8,7012,,,0,"Add small image verifier for swift backend

In the parent patch, the swift driver is supported for images that
are greater than the 'large_object_size.'  This patch adds support
for images that are less than the 'large_object_size.'

Change-Id: Ifaa15b794a7213c1c393288631d071ac66dcbc81
Partial-Bug: #1516031
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/06/266606/8 && git format-patch -1 --stdout FETCH_HEAD,"['glance_store/_drivers/swift/store.py', 'glance_store/tests/unit/test_swift_store.py']",2,58a61128fa3d7d2b97722e34ff269bac25178591,bug/1516031," mock.Mock(return_value=True)) def test_add_with_verifier_small(self): """"""Test that the verifier is updated for smaller images."""""" swift_size = FIVE_KB base_byte = b""12345678"" swift_contents = base_byte * (swift_size // 8) image_id = str(uuid.uuid4()) image_swift = six.BytesIO(swift_contents) self.store = Store(self.conf) self.store.configure() orig_max_size = self.store.large_object_size orig_temp_size = self.store.large_object_chunk_size custom_size = 6 * units.Ki verifier = mock.MagicMock(name='mock_verifier') try: self.store.large_object_size = custom_size self.store.large_object_chunk_size = custom_size self.store.add(image_id, image_swift, swift_size, verifier=verifier) finally: self.store.large_object_chunk_size = orig_temp_size self.store.large_object_size = orig_max_size # Confirm verifier update called expected number of times self.assertEqual(verifier.update.call_count, 1) # define one chunk of the contents swift_contents_piece = base_byte * (swift_size // 8) # confirm all expected calls to update have occurred calls = [mock.call(swift_contents_piece)] verifier.update.assert_has_calls(calls) @mock.patch('glance_store._drivers.swift.utils' '.is_multiple_swift_store_accounts_enabled',",,39,1
openstack%2Fsenlin~master~Ic98f8c355cacb445d24beedc5b3633ee260742d2,openstack/senlin,master,Ic98f8c355cacb445d24beedc5b3633ee260742d2,Validate 'sort' parameter for policies in engine,MERGED,2016-02-19 12:55:24.000000000,2016-02-19 13:15:54.000000000,2016-02-19 13:15:54.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 12:55:24.000000000', 'files': ['senlin/tests/unit/engine/service/test_policies.py', 'senlin/engine/service.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/99367d40b57e9d50ab11bf1d6323bd0d44cb6d57', 'message': ""Validate 'sort' parameter for policies in engine\n\nThis adds validation for the 'sort' parameter when listing policies at\nengline layer.\n\nChange-Id: Ic98f8c355cacb445d24beedc5b3633ee260742d2\n""}]",0,282322,99367d40b57e9d50ab11bf1d6323bd0d44cb6d57,6,2,1,8246,,,0,"Validate 'sort' parameter for policies in engine

This adds validation for the 'sort' parameter when listing policies at
engline layer.

Change-Id: Ic98f8c355cacb445d24beedc5b3633ee260742d2
",git fetch https://review.opendev.org/openstack/senlin refs/changes/22/282322/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_policies.py']",2,99367d40b57e9d50ab11bf1d6323bd0d44cb6d57,policy-sort," filters={'foo': 'bar'}, sort='name:asc', filters={'foo': 'bar'}, sort='name:asc', self.ctx, sort='invalidkey') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) ex = self.assertRaises(rpc.ExpectedException, self.eng.policy_list,"," filters={'foo': 'bar'}, sort='k:asc', filters={'foo': 'bar'}, sort='k:asc',",9,2
openstack%2Fsenlin~master~Ie449cb0bdd6261c2beec21232a97239feac27b87,openstack/senlin,master,Ie449cb0bdd6261c2beec21232a97239feac27b87,Avoid using literal strings in API layer,MERGED,2016-02-19 12:07:48.000000000,2016-02-19 13:15:26.000000000,2016-02-19 13:15:26.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 12:07:48.000000000', 'files': ['senlin/api/openstack/v1/events.py', 'senlin/api/openstack/v1/actions.py', 'senlin/api/openstack/v1/cluster_policies.py', 'senlin/api/openstack/v1/policies.py', 'senlin/api/openstack/v1/clusters.py', 'senlin/api/openstack/v1/nodes.py', 'senlin/api/openstack/v1/receivers.py', 'senlin/api/openstack/v1/profiles.py', 'senlin/common/consts.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/2f821e6f7a0c65ce63fa44562f747088fe6f2f1b', 'message': 'Avoid using literal strings in API layer\n\nThis patch replaces literals used at API layer by consts.\n\nChange-Id: Ie449cb0bdd6261c2beec21232a97239feac27b87\n'}]",0,282301,2f821e6f7a0c65ce63fa44562f747088fe6f2f1b,6,2,1,8246,,,0,"Avoid using literal strings in API layer

This patch replaces literals used at API layer by consts.

Change-Id: Ie449cb0bdd6261c2beec21232a97239feac27b87
",git fetch https://review.opendev.org/openstack/senlin refs/changes/01/282301/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/openstack/v1/events.py', 'senlin/api/openstack/v1/actions.py', 'senlin/api/openstack/v1/cluster_policies.py', 'senlin/api/openstack/v1/policies.py', 'senlin/api/openstack/v1/clusters.py', 'senlin/api/openstack/v1/nodes.py', 'senlin/api/openstack/v1/receivers.py', 'senlin/api/openstack/v1/profiles.py', 'senlin/common/consts.py']",9,2f821e6f7a0c65ce63fa44562f747088fe6f2f1b,no-literal," PARAM_SHOW_DETAILS, PARAM_SORT, 'show_details', 'sort', EVENT_LEVEL, EVENT_CLUSTER_ID, 'level', 'cluster_id',"," PARAM_SHOW_DETAILS, PARAM_SORT_DIR, PARAM_SORT_KEYS, 'show_details', 'sort_dir', 'sort_keys', EVENT_LEVEL, 'level',",77,74
openstack%2Fpython-aodhclient~master~I5e0048f969d2e852042c4aa2c7e6e0bff254d15b,openstack/python-aodhclient,master,I5e0048f969d2e852042c4aa2c7e6e0bff254d15b,Return the error message of API request failure,MERGED,2016-02-16 06:54:18.000000000,2016-02-19 13:15:20.000000000,2016-02-19 13:15:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 9526}]","[{'number': 1, 'created': '2016-02-16 06:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/e24fd0ffcdc848cb61f342b8720a6705413ad7a6', 'message': ""Return the error message of API request failure\n\nFor now, the error message from Aodh API can not be return when a request\nfailure occur(e.g. BadRequest, Conflict). That is because the fualtstring\nfrom the response isn't extracted correctly.\n\nChange-Id: I5e0048f969d2e852042c4aa2c7e6e0bff254d15b\n""}, {'number': 2, 'created': '2016-02-16 07:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/dbbb780f6568aa4a27b44e1e378950a5e506305f', 'message': ""Return the error message of API request failure\n\nFor now, the error message from Aodh API can not be return when a request\nfailure occur(e.g. BadRequest, Conflict). That is because the fualtstring\nfrom the response isn't extracted correctly.\n\nChange-Id: I5e0048f969d2e852042c4aa2c7e6e0bff254d15b\n""}, {'number': 3, 'created': '2016-02-17 07:29:02.000000000', 'files': ['aodhclient/tests/functional/test_alarm.py', 'aodhclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/33771065578f96e405ac013b16544276458a10f6', 'message': ""Return the error message of API request failure\n\nFor now, the error message from Aodh API can not be return when a request\nfailure occur(e.g. BadRequest, Conflict). That is because the fualtstring\nfrom the response isn't extracted correctly.\n\nChange-Id: I5e0048f969d2e852042c4aa2c7e6e0bff254d15b\n""}]",0,280519,33771065578f96e405ac013b16544276458a10f6,17,4,3,8290,,,0,"Return the error message of API request failure

For now, the error message from Aodh API can not be return when a request
failure occur(e.g. BadRequest, Conflict). That is because the fualtstring
from the response isn't extracted correctly.

Change-Id: I5e0048f969d2e852042c4aa2c7e6e0bff254d15b
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/19/280519/1 && git format-patch -1 --stdout FETCH_HEAD,['aodhclient/exceptions.py'],1,e24fd0ffcdc848cb61f342b8720a6705413ad7a6,faultstring," desc = body.get('error_message', {}).get('faultstring')", desc = body.get('description'),1,1
openstack%2Ffuel-web~master~Ia2b653f8d8a587c0ce2d0cd17317e5208ec3aa75,openstack/fuel-web,master,Ia2b653f8d8a587c0ce2d0cd17317e5208ec3aa75,Fix UI functional tests for Firefox 44,MERGED,2016-02-19 11:26:22.000000000,2016-02-19 13:13:57.000000000,2016-02-19 12:43:51.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9730}]","[{'number': 1, 'created': '2016-02-19 11:26:22.000000000', 'files': ['nailgun/static/tests/functional/test_wizard.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8f6333ad6eeb4f627079bb8abb4dc967bb67286e', 'message': 'Fix UI functional tests for Firefox 44\n\nChange-Id: Ia2b653f8d8a587c0ce2d0cd17317e5208ec3aa75\nPartial-Bug: #1543035\n'}]",0,282289,8f6333ad6eeb4f627079bb8abb4dc967bb67286e,16,5,1,8735,,,0,"Fix UI functional tests for Firefox 44

Change-Id: Ia2b653f8d8a587c0ce2d0cd17317e5208ec3aa75
Partial-Bug: #1543035
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/89/282289/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/tests/functional/test_wizard.js'],1,8f6333ad6eeb4f627079bb8abb4dc967bb67286e,bug/1543035, .then(function() { return modal.close(); });, .clickByCssSelector('.close');,3,1
openstack%2Fmonasca-log-api~master~I92ca885237f12cc3790fa0935362f9e833b15287,openstack/monasca-log-api,master,I92ca885237f12cc3790fa0935362f9e833b15287,Sync to never monasca-common,MERGED,2016-02-01 06:50:36.000000000,2016-02-19 13:09:50.000000000,2016-02-19 13:09:50.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 7874}, {'_account_id': 16168}, {'_account_id': 16204}, {'_account_id': 16222}, {'_account_id': 20033}]","[{'number': 1, 'created': '2016-02-01 06:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/1da8b46565294e567696ae001301837c0ed829fc', 'message': 'Sync to never monasca-common\n\nUsing rest utils and new key-aware\nmethod from kafka producer.\n\nChange-Id: I92ca885237f12cc3790fa0935362f9e833b15287\n'}, {'number': 2, 'created': '2016-02-01 08:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/4fb1721d297352c78da057d8d881c22993959c81', 'message': 'Sync to never monasca-common\n\nUsing rest utils and new key-aware\nmethod from kafka producer.\n\nChange-Id: I92ca885237f12cc3790fa0935362f9e833b15287\n'}, {'number': 3, 'created': '2016-02-15 10:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/62944d06317040a6c19a7209c98e4c6ad2ef77cb', 'message': 'Sync to never monasca-common\n\nUsing rest utils and new key-aware\nmethod from kafka producer.\n\nChange-Id: I92ca885237f12cc3790fa0935362f9e833b15287\n'}, {'number': 4, 'created': '2016-02-19 07:19:58.000000000', 'files': ['requirements.txt', 'monasca_log_api/api/rest_utils.py', 'monasca_log_api/tests/test_rest_utils.py', 'monasca_log_api/v2/common/service.py', 'monasca_log_api/v2/reference/versions.py', 'monasca_log_api/tests/test_log_publisher.py', 'monasca_log_api/v2/common/log_publisher.py'], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/cb54d3e4966c147ef602b14fb05f1dc9cb70bcc2', 'message': 'Sync to never monasca-common\n\nUsing rest utils and new key-aware\nmethod from kafka producer.\n\nChange-Id: I92ca885237f12cc3790fa0935362f9e833b15287\n'}]",1,274516,cb54d3e4966c147ef602b14fb05f1dc9cb70bcc2,17,7,4,16168,,,0,"Sync to never monasca-common

Using rest utils and new key-aware
method from kafka producer.

Change-Id: I92ca885237f12cc3790fa0935362f9e833b15287
",git fetch https://review.opendev.org/openstack/monasca-log-api refs/changes/16/274516/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'monasca_log_api/api/rest_utils.py', 'monasca_log_api/tests/test_rest_utils.py', 'monasca_log_api/v2/common/service.py', 'monasca_log_api/tests/test_log_publisher.py', 'monasca_log_api/v2/common/log_publisher.py']",6,1da8b46565294e567696ae001301837c0ed829fc,sync_common,"import simplejson as json LOG.debug('Build key [%s] for message', key) LOG.debug('Sending message {topics=%s,key=%s,message=%s}', self._topics, key, msg) self._publisher().publish(topic, msg, key)","import simplejson as json # TODO(feature) next version of monasca-common LOG.debug('Build key [%s] for message' % key) LOG.debug('Sending message {topics=%s,key=%s,message=%s}' % (self._topics, key, msg)) self._publisher().publish(topic, msg)",16,143
openstack%2Frally~master~Iacb6c07cf41a988d67bbd7877f4dcc2b369f4f81,openstack/rally,master,Iacb6c07cf41a988d67bbd7877f4dcc2b369f4f81,Fix install_rally.sh to get it to work on MacOSX,MERGED,2016-02-17 13:47:33.000000000,2016-02-19 12:58:23.000000000,2016-02-19 12:58:22.000000000,"[{'_account_id': 3}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-17 13:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/97bcedde0d6c9c13475be6985744417b4fce68b3', 'message': 'Fix install_rally.sh to get it to work on MacOSX\n\nOn MacOSX, `mktemp` requires being passed a template. This change\nmodifies the calls to `mktemp` to explicitly pass a template so\nthat the code works on both MacOSX and linux.\n\nChange-Id: Iacb6c07cf41a988d67bbd7877f4dcc2b369f4f81\n'}, {'number': 2, 'created': '2016-02-18 10:17:59.000000000', 'files': ['install_rally.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/e38fef2c4ca16415d87b79002362017347fcc2d5', 'message': 'Fix install_rally.sh to get it to work on MacOSX\n\nOn MacOSX, `mktemp` requires being passed a template. This change\nmodifies the calls to `mktemp` to explicitly pass a template so\nthat the code works on both MacOSX and linux.\n\nChange-Id: Iacb6c07cf41a988d67bbd7877f4dcc2b369f4f81\n'}]",1,281280,e38fef2c4ca16415d87b79002362017347fcc2d5,21,4,2,18364,,,0,"Fix install_rally.sh to get it to work on MacOSX

On MacOSX, `mktemp` requires being passed a template. This change
modifies the calls to `mktemp` to explicitly pass a template so
that the code works on both MacOSX and linux.

Change-Id: Iacb6c07cf41a988d67bbd7877f4dcc2b369f4f81
",git fetch https://review.opendev.org/openstack/rally refs/changes/80/281280/1 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,97bcedde0d6c9c13475be6985744417b4fce68b3,make-install-work-on-macos, local pdir=$(mktemp --tmpdir tmp.XXXXXXXXXX -d) local CONF_TMPFILE=$(mktemp --tmpdir tmp.XXXXXXXXXX), local pdir=$(mktemp -d) local CONF_TMPFILE=$(mktemp),2,2
openstack%2Ffuel-specs~master~I67a277301dc39d1917d61f0d7fe566782648d334,openstack/fuel-specs,master,I67a277301dc39d1917d61f0d7fe566782648d334,Extensions data pipelines spec,MERGED,2016-02-01 13:35:19.000000000,2016-02-19 12:57:38.000000000,2016-02-19 12:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8829}, {'_account_id': 8931}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11090}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-01 13:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/996d3172dc328f2d4bbf5737d1bb810a41af3850', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}, {'number': 2, 'created': '2016-02-01 14:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2d27119f29cde740c12feed7b68f6c9a128dc531', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}, {'number': 3, 'created': '2016-02-05 14:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6a8e04fea6a6e9f6ae758c37fba39472e4a75500', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}, {'number': 4, 'created': '2016-02-12 12:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/1706d68e32bf8b22f95bd04397ba7261dcf7fdd8', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}, {'number': 5, 'created': '2016-02-15 08:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/7c47346f689147e406f755595dfd7a095539a58f', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}, {'number': 6, 'created': '2016-02-19 11:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/9908ffcffa4e28bb93ecb060e2f24c85c098baeb', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}, {'number': 7, 'created': '2016-02-19 11:44:08.000000000', 'files': ['specs/9.0/data-pipeline.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4eb607861e23fa2b4ba314def50a804dbb6a3207', 'message': 'Extensions data pipelines spec\n\nChange-Id: I67a277301dc39d1917d61f0d7fe566782648d334\nImplements: blueprint data-pipeline\n'}]",42,274653,4eb607861e23fa2b4ba314def50a804dbb6a3207,49,11,7,15454,,,0,"Extensions data pipelines spec

Change-Id: I67a277301dc39d1917d61f0d7fe566782648d334
Implements: blueprint data-pipeline
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/53/274653/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/9.0/data-pipeline.rst'],1,996d3172dc328f2d4bbf5737d1bb810a41af3850,bp/data-pipeline,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================= Provisioning and deployment data pipeline ========================================= https://blueprints.launchpad.net/fuel/+spec/data-pipeline -------------------- Problem description -------------------- Together with implementation of Nailgun Extensions [#nailgun_extensions]_ we want to remove all direct calls from Nailgun core to any kind of extension i.e.: to volume_manager [#volume_manager_import]_ or any other extension using `node_extension_call` function [#node_extension_call]_. But extensions must have the ability to change the deployment and provisioning data. It is required for example by new bareon-fuel-extension [#bareon_fuel_extension]_ which will be used to integrate Fuel with Bareon-API [#bareon_api]_. ---------------- Proposed changes ---------------- In order to change the deployment and provisioning data via extension we should somehow tell to all extensions that for example deployment data serialization event has occurred and now the extension is able to change the data. The proposal is to create new Extension attribute which is called `data_pipelines`. `data_pipelines` is a list of classes which implement the following methods: * :code:`process_deployment(deployment_data, **kwargs)` - is fired once the serialization of deployment data occurs. It receives reference to a dict which can be changed. * :code:`process_provisioning(provisioning_data, **kwargs)` - is fired once the serialization of provisioning data occurs. It receives reference to a dict which can be changed. Both methods don't return anything. Example implementation: .. code:: python class ExamplePipeline(BaseExtensionPipeline): @classmethod def process_deployment(cls, deployment_data, **kwargs): deployment_data['new_field'] = external_source.get_new_data() @classmethod def process_provisioning(cls, provisioning_data, **kwargs): provisioning_data['new_field'] = external_source.get_new_data() class ExampleExtension(BaseExtension): ... data_pipelines = (ExamplePipeline,) ... Web UI ====== None Nailgun ======= Data model ---------- None REST API -------- None Orchestration ============= None RPC Protocol ------------ None Fuel Client =========== None Plugins ======= None Fuel Library ============ None ------------ Alternatives ------------ Instead of introducing new Extension attribute with classes list: * we could just add these two methods to Extensions class: * but it will clash with Expert design [#expert_pattern]_ pattern what can lead to blurred responsibilities * we could implement Pipelines as mixins: * but it comes down to the same issue as in the previous example * we want to implement Pipeline classes execution custom ordering in the future -------------- Upgrade impact -------------- None --------------- Security impact --------------- None -------------------- Notifications impact -------------------- None --------------- End user impact --------------- None ------------------ Performance impact ------------------ None ----------------- Deployment impact ----------------- None ---------------- Developer impact ---------------- Developer is able to change the deployment/provisioning data directly from extensions. --------------------- Infrastructure impact --------------------- None -------------------- Documentation impact -------------------- Pipelines should be described in Extensions docs. Description should include: * Definition of pipeline * Minimal working pipeline (required methods etc.) -------------- Implementation -------------- Assignee(s) =========== Primary assignee: Sylwester Brzeczkowski <sbrzeczkowski@mirantis.com> Mandatory design review: * Evgeny Li <eli@mirantis.com> * Igor Kalnitsky <igor@kalnitsky.org> Work Items ========== * Implement BaseExtensionPipeline class and integrate it with existing BaseExtension class and add serialization event triggers to the places in Nailgun core where the event occurs. * Remove all direct calls to extensions from Nailgun core. Dependencies ============ * Nailgun extensions discovery must be done first [#nailgun_extensions]_ ------------ Testing, QA ------------ Acceptance criteria =================== * It is possible to change/add new data to provisioning/deployment serialized data. ---------- References ---------- .. [#nailgun_extensions] https://blueprints.launchpad.net/fuel/+spec/stevedore-extensions-discovery .. [#volume_manager_import] https://github.com/openstack/fuel-web/blob/stable/8.0/nailgun/nailgun/db/sqlalchemy/models/node.py#L38 .. [#node_extension_call] https://github.com/openstack/fuel-web/blob/stable/8.0/nailgun/nailgun/orchestrator/provisioning_serializers.py#L131 .. [#bareon_fuel_extension] https://github.com/gitfred/bareon-fuel-extension .. [#bareon_api] https://blueprints.launchpad.net/fuel/+spec/fuel-bareon-api-integration .. [#expert_pattern] https://en.wikipedia.org/wiki/GRASP_%28object-oriented_design%29#Information_Expert",,252,0
openstack%2Fswift~master~I1d6dcbc4f5034a322a1073850fc3b059ebb1c0fa,openstack/swift,master,I1d6dcbc4f5034a322a1073850fc3b059ebb1c0fa,Make write-only container access consistent,MERGED,2016-01-07 20:56:31.000000000,2016-02-19 12:56:38.000000000,2016-02-19 12:56:38.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 13052}, {'_account_id': 13390}]","[{'number': 1, 'created': '2016-01-07 20:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ffe8aa5be2d5cb4e816f0420c05437e2165bdba5', 'message': 'Make write-only container access consistent\n\nPreviously, if a user could write to (but not read from) a container,\nthe behavior for object POST would vary depending on whether\nobject_post_as_copy was enabled (403 response) or disabled (202\nresponse).\n\nNow, POSTs will consistently be allowed, regardless of whether fast-POST\nis enabled.\n\nChange-Id: I1d6dcbc4f5034a322a1073850fc3b059ebb1c0fa\n'}, {'number': 2, 'created': '2016-02-18 23:48:28.000000000', 'files': ['test/functional/test_object.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/002513d21786df0d6c71e9772ec4688e2c14d8de', 'message': 'Make write-only container access consistent\n\nPreviously, if a user could write to (but not read from) a container,\nthe behavior for object POST would vary depending on whether\nobject_post_as_copy was enabled (403 response) or disabled (202\nresponse).\n\nNow, POSTs will consistently be allowed, regardless of whether fast-POST\nis enabled.\n\nChange-Id: I1d6dcbc4f5034a322a1073850fc3b059ebb1c0fa\n'}]",0,264961,002513d21786df0d6c71e9772ec4688e2c14d8de,12,5,2,15343,,,0,"Make write-only container access consistent

Previously, if a user could write to (but not read from) a container,
the behavior for object POST would vary depending on whether
object_post_as_copy was enabled (403 response) or disabled (202
response).

Now, POSTs will consistently be allowed, regardless of whether fast-POST
is enabled.

Change-Id: I1d6dcbc4f5034a322a1073850fc3b059ebb1c0fa
",git fetch https://review.opendev.org/openstack/swift refs/changes/61/264961/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/test_object.py', 'swift/proxy/controllers/obj.py']",2,ffe8aa5be2d5cb4e816f0420c05437e2165bdba5,264961," if 'swift.post_as_copy' in req.environ: # We're COPYing one object over itself because of a POST; rely on # the PUT for write authorization, don't require read authorization source_req.environ['swift.authorize'] = lambda req: None source_req.environ['swift.authorize_override'] = True",,84,0
openstack%2Ffuel-web~master~Ic40013fbfa37e5db199d7464c24fa58029dac12d,openstack/fuel-web,master,Ic40013fbfa37e5db199d7464c24fa58029dac12d,Fixed passing role_resolver to serialisers,MERGED,2016-02-19 10:39:00.000000000,2016-02-19 12:53:45.000000000,2016-02-19 12:17:28.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 13505}, {'_account_id': 14543}]","[{'number': 1, 'created': '2016-02-19 10:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/68d2af16c4ea5f2d22c1e79cef2b97b19eb69170', 'message': 'Fixed passing role_resolver to serialisers\n\nThe role_resolver should be pass to serialisers as keyword argument.\n\nChange-Id: Ic40013fbfa37e5db199d7464c24fa58029dac12d\nCloses-bug: 1546175\n'}, {'number': 2, 'created': '2016-02-19 10:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a048b73dd0d5c613a3dbad68b91dd3f89635e3f2', 'message': 'Fixed passing role_resolver to serialisers\n\nThe role_resolver should be pass to serialisers as keyword argument,\nbecause each serialiser may have its own optional parameters, like\nfor example UploadConfiguration). There is no guarantee that positional\narguments will map keywords arguments properly.\n\n\nChange-Id: Ic40013fbfa37e5db199d7464c24fa58029dac12d\nCloses-bug: 1546175\n'}, {'number': 3, 'created': '2016-02-19 10:57:11.000000000', 'files': ['nailgun/nailgun/orchestrator/deployment_graph.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2534d212807bbb9d3ddc115f5606923eca2b67fe', 'message': 'Fixed passing role_resolver to serialisers\n\nThe role_resolver should be pass to serialisers as keyword argument,\nbecause each serialiser may have its own optional parameters\n(for example UploadConfiguration). There is no guarantee that positional\narguments will map keywords arguments properly.\n\n\nChange-Id: Ic40013fbfa37e5db199d7464c24fa58029dac12d\nCloses-bug: 1546175\n'}]",0,282266,2534d212807bbb9d3ddc115f5606923eca2b67fe,32,12,3,18205,,,0,"Fixed passing role_resolver to serialisers

The role_resolver should be pass to serialisers as keyword argument,
because each serialiser may have its own optional parameters
(for example UploadConfiguration). There is no guarantee that positional
arguments will map keywords arguments properly.


Change-Id: Ic40013fbfa37e5db199d7464c24fa58029dac12d
Closes-bug: 1546175
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/66/282266/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/orchestrator/deployment_graph.py'],1,68d2af16c4ea5f2d22c1e79cef2b97b19eb69170,bug/1546175," task, self.cluster, nodes, role_resolver=role_resolver)"," task, self.cluster, nodes, role_resolver)",1,1
openstack%2Fpython-openstackclient~master~Ib0cf128e64dfb6f6ad59ecc99f616dee70debedb,openstack/python-openstackclient,master,Ib0cf128e64dfb6f6ad59ecc99f616dee70debedb,Return tuple in _get_columns() in port.py,ABANDONED,2016-02-19 06:21:55.000000000,2016-02-19 12:53:19.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-02-19 06:21:55.000000000', 'files': ['openstackclient/network/v2/port.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ddb9e47df71645807c43edaffd40ee8e9e2b38d4', 'message': 'Return tuple in _get_columns() in port.py\n\nAlign to _get_columns() in network.py.\n\nChange-Id: Ib0cf128e64dfb6f6ad59ecc99f616dee70debedb\n'}]",2,282196,ddb9e47df71645807c43edaffd40ee8e9e2b38d4,7,5,1,14937,,,0,"Return tuple in _get_columns() in port.py

Align to _get_columns() in network.py.

Change-Id: Ib0cf128e64dfb6f6ad59ecc99f616dee70debedb
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/96/282196/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/network/v2/port.py'],1,ddb9e47df71645807c43edaffd40ee8e9e2b38d4,get-columns-20160219," return tuple(sorted(columns)) return (columns, data)"," return sorted(columns) return (tuple(columns), data)",2,2
openstack%2Fmurano-dashboard~master~I21351d1d1c8c44d31f85213bd42a4d4b31bcddcc,openstack/murano-dashboard,master,I21351d1d1c8c44d31f85213bd42a4d4b31bcddcc,Added cleanup for project,MERGED,2016-02-19 11:12:49.000000000,2016-02-19 12:51:02.000000000,2016-02-19 12:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-19 11:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/dd80e544416fc90c4255a651d073ceb3e5011b86', 'message': 'Added cleanup for project\n\nAdded setup of original project before each test.\nAnd added cleanup for projects created during the tests.\n\nCloses-Bug: #1547459\nChange-Id: I21351d1d1c8c44d31f85213bd42a4d4b31bcddcc\n'}, {'number': 2, 'created': '2016-02-19 11:38:21.000000000', 'files': ['muranodashboard/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c1bf54058f536dd79a3a961bde48a35a25a812ea', 'message': 'Added cleanup for project\n\nAdded setup of original project before each test.\nAnd added cleanup for projects created during the tests.\n\nCloses-Bug: #1547459\nChange-Id: I21351d1d1c8c44d31f85213bd42a4d4b31bcddcc\n'}]",0,282284,c1bf54058f536dd79a3a961bde48a35a25a812ea,13,10,2,19282,,,0,"Added cleanup for project

Added setup of original project before each test.
And added cleanup for projects created during the tests.

Closes-Bug: #1547459
Change-Id: I21351d1d1c8c44d31f85213bd42a4d4b31bcddcc
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/84/282284/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/tests/functional/base.py'],1,dd80e544416fc90c4255a651d073ceb3e5011b86,bug/1547459, cls.project_name = cls.keystone_client.project_name self.projects_to_delete = [] self.switch_to_project(cfg.common.tenant) self.switch_to_project(cfg.common.tenant) for project_id in self.projects_to_delete: self.keystone_client.tenants.delete(project_id) self.projects_to_delete.append(project.id),,9,0
openstack%2Ffuel-octane~stable%2F7.0~Idd69c48719b232f0ee17daad10f013706f64bb1b,openstack/fuel-octane,stable/7.0,Idd69c48719b232f0ee17daad10f013706f64bb1b,Add docker container names filter without console filtering,MERGED,2016-02-17 11:53:15.000000000,2016-02-19 12:47:32.000000000,2016-02-19 12:47:32.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 19157}]","[{'number': 1, 'created': '2016-02-17 11:53:15.000000000', 'files': ['octane/util/docker.py', 'octane/tests/test_docker.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/4ece5d6fc726bd7226bc23e87e7ec217181fa5df', 'message': 'Add docker container names filter without console filtering\n\nChange-Id: Idd69c48719b232f0ee17daad10f013706f64bb1b\nCloses-bug: 1541435\n(cherry picked from commit 77ba4b757209aeda162546b3b8f0abb81ebc52eb)\n'}]",0,281215,4ece5d6fc726bd7226bc23e87e7ec217181fa5df,8,3,1,6677,,,0,"Add docker container names filter without console filtering

Change-Id: Idd69c48719b232f0ee17daad10f013706f64bb1b
Closes-bug: 1541435
(cherry picked from commit 77ba4b757209aeda162546b3b8f0abb81ebc52eb)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/15/281215/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/util/docker.py', 'octane/tests/test_docker.py']",2,4ece5d6fc726bd7226bc23e87e7ec217181fa5df,bug/1541435,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import pytest from octane.util import docker from octane.util import subprocess @pytest.fixture() def roll_back_get_docker_container_names_flag(request): base = docker.get_docker_container_names.use_without def foo(): docker.get_docker_container_names.use_without = base request.addfinalizer(foo) pytestmark = pytest.mark.usefixtures( ""roll_back_get_docker_container_names_flag"") def test_get_container_names(mocker): def foo(call_args, *args, **kwargs): if '--format=""{{.Names}}""' in call_args: raise subprocess.CalledProcessError(2, call_args) return (""NAMES\nfuel-core-container_1\nfuel-core-container_2"", None) sub_mock = mocker.patch(""octane.util.subprocess.call"", side_effect=foo) assert not docker.get_docker_container_names.use_without assert [""container_1"", ""container_2""] == \ docker.get_docker_container_names() sub_mock.assert_has_calls([ mock.call( [""docker"", ""ps"", '--all', '--format=""{{.Names}}""'], stdout=subprocess.PIPE ), mock.call( [""docker"", ""ps"", '--all'], stdout=subprocess.PIPE )]) assert 2 == sub_mock.call_count assert docker.get_docker_container_names.use_without def test_get_container_names_with_format(mocker): sub_mock = mocker.patch( ""octane.util.subprocess.call"", return_value=(""fuel-core-container_1\nfuel-core-container_2\n\n"", None)) assert not docker.get_docker_container_names.use_without assert [""container_1"", ""container_2""] == \ docker.get_docker_container_names() assert not docker.get_docker_container_names.use_without sub_mock.assert_called_once_with( [""docker"", ""ps"", '--all', '--format=""{{.Names}}""'], stdout=subprocess.PIPE) ",,85,9
openstack%2Fkolla~master~Ie6fa3d311045a0666dce2a6304c43fd5ef0353bb,openstack/kolla,master,Ie6fa3d311045a0666dce2a6304c43fd5ef0353bb,[WIP] Support installing openvswitch from source,ABANDONED,2016-02-03 21:23:53.000000000,2016-02-19 12:47:28.000000000,,"[{'_account_id': 3}, {'_account_id': 11604}, {'_account_id': 14027}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-03 21:23:53.000000000', 'files': ['docker/openvswitch/openvswitch-base/Dockerfile.j2', 'kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7b63bb0c58eb2b3819b0d36936daebc145a3e822', 'message': '[WIP] Support installing openvswitch from source\n\n- This change introduces support for installing\n  kernel ovs from source.\n- Note this has only been tested with ubuntu\n  source build form git.\n- TODO validate source install on other OS\n- TODO vaildate build from ovs release tarball.\n- TODO docs?\n\nChange-Id: Ie6fa3d311045a0666dce2a6304c43fd5ef0353bb\nCloses-Bug: #1538142\n'}]",0,275932,7b63bb0c58eb2b3819b0d36936daebc145a3e822,12,4,1,11604,,,0,"[WIP] Support installing openvswitch from source

- This change introduces support for installing
  kernel ovs from source.
- Note this has only been tested with ubuntu
  source build form git.
- TODO validate source install on other OS
- TODO vaildate build from ovs release tarball.
- TODO docs?

Change-Id: Ie6fa3d311045a0666dce2a6304c43fd5ef0353bb
Closes-Bug: #1538142
",git fetch https://review.opendev.org/openstack/kolla refs/changes/32/275932/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/openvswitch/openvswitch-base/Dockerfile.j2', 'kolla/common/config.py']",2,7b63bb0c58eb2b3819b0d36936daebc145a3e822,bug/1538142," 'openvswitch-base': { 'type': 'git', 'location': 'https://github.com/openvswitch/ovs.git', 'reference': 'branch-2.4'},",,35,8
openstack%2Fanchor~master~If1a662c26dff2e396fae6c0b29fa101869708b57,openstack/anchor,master,If1a662c26dff2e396fae6c0b29fa101869708b57,Updated from global requirements,MERGED,2016-01-23 10:21:09.000000000,2016-02-19 12:47:27.000000000,2016-02-19 12:47:27.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 11397}, {'_account_id': 11561}, {'_account_id': 11716}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-01-23 10:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/b5730fe41eeb2afdf76579a38ccfa154c6c97a96', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 2, 'created': '2016-01-26 23:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/af6d4f85fbc7e25427635bfda0b3913b8320f58a', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 3, 'created': '2016-01-28 13:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/2715f989646d5b9f27f5cbf29d902e49dbb708bd', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 4, 'created': '2016-01-29 20:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/d0233a1397663654b9db23033356fd22faf696ff', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 5, 'created': '2016-02-03 03:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/38dd1ac5d3939f0821bd8ec6e8325672c41985eb', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 6, 'created': '2016-02-04 18:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/a172a44397a72e3d4b2eef9371baa416768b2c11', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 7, 'created': '2016-02-06 21:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/0c1702067ff1f3f610aa6d7cd64212955b8596ab', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 8, 'created': '2016-02-10 21:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/754d9edbb4362863155c12edbaf3d8bfebd1a345', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 9, 'created': '2016-02-11 07:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/8773acd28ee72af4107fe1ad838f91447fbb32cb', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}, {'number': 10, 'created': '2016-02-19 02:29:55.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/anchor/commit/0863f3ef627e64b7598da629d503792d58b3b9f3', 'message': 'Updated from global requirements\n\nChange-Id: If1a662c26dff2e396fae6c0b29fa101869708b57\n'}]",0,271636,0863f3ef627e64b7598da629d503792d58b3b9f3,38,6,10,11131,,,0,"Updated from global requirements

Change-Id: If1a662c26dff2e396fae6c0b29fa101869708b57
",git fetch https://review.opendev.org/openstack/anchor refs/changes/36/271636/8 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b5730fe41eeb2afdf76579a38ccfa154c6c97a96,openstack/requirements,oslo.messaging>=4.0.0 # Apache-2.0,"oslo.messaging!=2.8.0,!=3.1.0,>2.6.1 # Apache-2.0",1,1
openstack%2Ffuel-library~master~I528ee55f1766d59bd2320b59bd4e181b4df350ed,openstack/fuel-library,master,I528ee55f1766d59bd2320b59bd4e181b4df350ed,Link neutron syncdb with service run.,MERGED,2016-02-09 12:29:34.000000000,2016-02-19 12:46:44.000000000,2016-02-19 12:45:44.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}]","[{'number': 1, 'created': '2016-02-09 12:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/978a4d076fa4a576724871816a4613f9ba034cbc', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 2, 'created': '2016-02-10 08:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ad9e781080bc5a2372a35beed2e908890a659229', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 3, 'created': '2016-02-12 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8b106fb32fa1db0a067997c5d987fdd6d6716fe6', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 4, 'created': '2016-02-12 10:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/89f6b6ff9046ef56c4444bfb318e986d42ac7661', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 5, 'created': '2016-02-12 10:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7545cf2a2fc45e367cad31c56787b06b0fabb666', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 6, 'created': '2016-02-12 13:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/290fee57495f8913ba8436f430a0402e50c758f6', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 7, 'created': '2016-02-17 12:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8aa442bd1f9378719dbcb0ecac5052271e8fd6fc', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 8, 'created': '2016-02-17 12:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0c45705876a002e16bf3a81d176770797d78cbc8', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 9, 'created': '2016-02-17 12:05:04.000000000', 'files': ['tests/noop/spec/hosts/openstack-network/plugins/ml2_spec.rb', 'deployment/puppet/osnailyfacter/modular/openstack-network/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9d4048b855a85c3de6d3545a52c158b3c3256166', 'message': 'Link neutron syncdb with service run.\n\nTo have an ability for API calling, we must have neutron fully\nconfigured, so we must configure all resources, sync DB, then\nrun neutron.\n\nWe could move syncdb task to server-config manifest, but it is\nnot good solution, cause it will be tricky to link it proper way. So,\njust run it always before neutron service.\n\nChange-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed\nRelated-Blueprint: granular-task-idempotency\n'}]",10,277808,9d4048b855a85c3de6d3545a52c158b3c3256166,102,16,9,11827,,,0,"Link neutron syncdb with service run.

To have an ability for API calling, we must have neutron fully
configured, so we must configure all resources, sync DB, then
run neutron.

We could move syncdb task to server-config manifest, but it is
not good solution, cause it will be tricky to link it proper way. So,
just run it always before neutron service.

Change-Id: I528ee55f1766d59bd2320b59bd4e181b4df350ed
Related-Blueprint: granular-task-idempotency
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/08/277808/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/openstack-network/plugins/ml2.pp'],1,978a4d076fa4a576724871816a4613f9ba034cbc,bp/granular-task-idempotency, # Synchronize database after plugin was configured if $primary_controller { class { '::neutron::db::sync': } Class['::neutron::db::sync'] -> Service['neutron-server'] } , # Synchronize database after plugin was configured if $primary_controller { include ::neutron::db::sync } ,7,5
openstack%2Ffuel-library~master~I6c04fbf5f5c460e81900c8beda6a81cb6f1e5520,openstack/fuel-library,master,I6c04fbf5f5c460e81900c8beda6a81cb6f1e5520,Fix for virtual_ip_ping,MERGED,2016-02-17 13:08:59.000000000,2016-02-19 12:46:24.000000000,2016-02-19 12:45:36.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 17730}, {'_account_id': 18290}]","[{'number': 1, 'created': '2016-02-17 13:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b181096ec2b3dcdfa3dc06ec2a1e02231e11fe32', 'message': 'Fix for virtual_ip_ping\n\n* Fix syntax for resource w/o changing end state\n* Remove obsolete pacemaker service\n\nRelated-Blueprint: granular-task-idempotency\nChange-Id: I6c04fbf5f5c460e81900c8beda6a81cb6f1e5520\n'}, {'number': 2, 'created': '2016-02-18 13:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a8ec064c970824b9bc7bbd5e13539bed6ab86a51', 'message': 'Fix for virtual_ip_ping\n\n* Fix syntax for resource w/o changing end state\n* Remove obsolete pacemaker service\n\nRelated-Blueprint: granular-task-idempotency\nChange-Id: I6c04fbf5f5c460e81900c8beda6a81cb6f1e5520\n'}, {'number': 3, 'created': '2016-02-18 16:44:14.000000000', 'files': ['deployment/puppet/pacemaker/lib/puppet/type/cs_rsc_location.rb', 'deployment/puppet/cluster/manifests/virtual_ip_ping.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fc4147c018cf6888bf2953a246b5dfbe715367a4', 'message': 'Fix for virtual_ip_ping\n\n* Fix syntax for resource w/o changing end state\n* Remove obsolete pacemaker service\n\nRelated-Blueprint: granular-task-idempotency\nChange-Id: I6c04fbf5f5c460e81900c8beda6a81cb6f1e5520\n'}]",1,281261,fc4147c018cf6888bf2953a246b5dfbe715367a4,43,13,3,13344,,,0,"Fix for virtual_ip_ping

* Fix syntax for resource w/o changing end state
* Remove obsolete pacemaker service

Related-Blueprint: granular-task-idempotency
Change-Id: I6c04fbf5f5c460e81900c8beda6a81cb6f1e5520
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/61/281261/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cluster/manifests/virtual_ip_ping.pp'],1,b181096ec2b3dcdfa3dc06ec2a1e02231e11fe32,bp/granular-task-idempotency," score => '-INFINITY', boolean => 'or', date_expressions => [], expressions => [ { attribute => 'pingd', operation => 'not_defined', attribute => ""pingd"", operation =>'lte', value => '0', Service[""ping_${vip_name}""] } "," service { ""${vip_name}"": ensure => 'running', enable => true, provider => 'pacemaker' } 'score' => '-inf', 'boolean' => '', 'expressions' => [ { 'attribute' => ""not_defined"", 'operation' => 'pingd', 'value' => 'or', 'attribute' => ""pingd"", 'operation'=>'lte', 'value' => '0', Service[""ping_${vip_name}""] -> Service <| title == ""${vip_name}"" |> }",11,17
openstack%2Ffuel-library~master~I35cc5441001856a8498be6c7ea515685e97ae90c,openstack/fuel-library,master,I35cc5441001856a8498be6c7ea515685e97ae90c,Disable globals.yaml when globals task ran,MERGED,2016-02-12 13:39:25.000000000,2016-02-19 12:43:57.000000000,2016-02-19 12:43:07.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9414}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}]","[{'number': 1, 'created': '2016-02-12 13:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/449662a4f4af1657b14e8532c748050b6e745007', 'message': 'Disable globals.yaml when globals task ran\n\nVariables names in globals.yaml and astute.yaml are the same sometimes.\nIt leads to bad lookups when we run globals.pp for a second and subsequent\ntimes. To avoid this previously we deleted original globals.yaml file\neach time globals.pp was ran, which loads us to idempotensy loss even in\ncase of noop run. It was a bad approach, so to save previous behaviour\nbut avoid file deletion we change default globals source in hiera to\ndynamically defined and redefine it in globals.pp manifest.\n\nChange-Id: I35cc5441001856a8498be6c7ea515685e97ae90c\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 2, 'created': '2016-02-15 12:30:32.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/hiera/hiera.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/remove_file.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cfc5e6ab6920cc8179e8b704cd9bad5069d3fa66', 'message': 'Disable globals.yaml when globals task ran\n\nVariables names in globals.yaml and astute.yaml are the same sometimes.\nIt leads to bad lookups when we run globals.pp for a second and subsequent\ntimes. To avoid this previously we deleted original globals.yaml file\neach time globals.pp was ran, which loads us to idempotensy loss even in\ncase of noop run. It was a bad approach, so to save previous behaviour\nbut avoid file deletion we change default globals source in hiera to\ndynamically defined and redefine it in globals.pp manifest.\n\nChange-Id: I35cc5441001856a8498be6c7ea515685e97ae90c\nRelated-Blueprint: granular-task-idempotency\n'}]",4,279535,cfc5e6ab6920cc8179e8b704cd9bad5069d3fa66,39,17,2,11827,,,0,"Disable globals.yaml when globals task ran

Variables names in globals.yaml and astute.yaml are the same sometimes.
It leads to bad lookups when we run globals.pp for a second and subsequent
times. To avoid this previously we deleted original globals.yaml file
each time globals.pp was ran, which loads us to idempotensy loss even in
case of noop run. It was a bad approach, so to save previous behaviour
but avoid file deletion we change default globals source in hiera to
dynamically defined and redefine it in globals.pp manifest.

Change-Id: I35cc5441001856a8498be6c7ea515685e97ae90c
Related-Blueprint: granular-task-idempotency
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/35/279535/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/hiera/hiera.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/remove_file.rb']",3,449662a4f4af1657b14e8532c748050b6e745007,bp/granular-task-idempotency,,"Puppet::Parser::Functions::newfunction( :remove_file, :doc => 'Remove a file during the catalog compilation phase' ) do |argv| file = argv.first if File.file? file begin File.unlink file debug ""File: '#{file}' was removed!"" true rescue => e debug ""File: '#{file}' could not remove! (#{e.message})"" false end end end ",3,20
openstack%2Fmurano-specs~master~I6f1ba7b9079fc6ad5ef4ead491460506169d7d39,openstack/murano-specs,master,I6f1ba7b9079fc6ad5ef4ead491460506169d7d39,Service API SDK,MERGED,2016-02-16 13:25:22.000000000,2016-02-19 12:38:18.000000000,2016-02-19 12:38:18.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-16 13:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/c1cfc9264d2c50f6a1bb737666ff7746780575a0', 'message': ""Service API SDK\n\nThis specification defines the design of Murano Service API SDK - a high level\nclient library allowing cloud applications (both murano-deployed and external)\nto access applications's Service API in consistent, convenient and secure way.\n\nChange-Id: I6f1ba7b9079fc6ad5ef4ead491460506169d7d39\n""}, {'number': 2, 'created': '2016-02-16 13:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/38c1bc583d7dbd014409cbb847b752c1173bf4ca', 'message': ""Service API SDK\n\nThis specification defines the design of Murano Service API SDK - a\nhigh level client library allowing cloud applications (both\nmurano-deployed and external) to access applications's Service API in\nconsistent, convenient and secure way.\n\nChange-Id: I6f1ba7b9079fc6ad5ef4ead491460506169d7d39\n""}, {'number': 3, 'created': '2016-02-19 12:23:16.000000000', 'files': ['specs/mitaka/service-api-sdk.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/ab01a2df95b84e1bf326d34ad56ddc48c9dffa8d', 'message': ""Service API SDK\n\nThis specification defines the design of Murano Service API SDK - a\nhigh level client library allowing cloud applications (both\nmurano-deployed and external) to access applications's Service API in\nconsistent, convenient and secure way.\n\nChange-Id: I6f1ba7b9079fc6ad5ef4ead491460506169d7d39\n""}]",0,280690,ab01a2df95b84e1bf326d34ad56ddc48c9dffa8d,11,4,3,8127,,,0,"Service API SDK

This specification defines the design of Murano Service API SDK - a
high level client library allowing cloud applications (both
murano-deployed and external) to access applications's Service API in
consistent, convenient and secure way.

Change-Id: I6f1ba7b9079fc6ad5ef4ead491460506169d7d39
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/90/280690/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/service-api-sdk.rst'],1,c1cfc9264d2c50f6a1bb737666ff7746780575a0,service-api-sdk,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============== Service API SDK =============== https://blueprints.launchpad.net/murano/+spec/service-api-sdk This specification defines the design of Murano Service API SDK - a high level client library allowing cloud applications (both murano-deployed and external) to access applications's Service API in consistent, convenient and secure way. Problem description =================== Service API is a way for murano applications to expose their configuration and lifecycle & maintenance actions for other cloud applications, users and administrators. Since murano is designed to be a single integration point for applications in the cloud, all the interactions with service APIs of deployed apps should be done via Murano API by either of the two ways: * Modifications of Object Model, i.e. changes of declarative definition of app configuration; * Calls of MuranoPL methods explicitly marked as externally executable actions. Both these ways of interaction assume some deep and low-level work with murano API: they require to fetch the object model from the environment, inspect it, modify according to all the contracts and constraints, call appropriate methods and so on. This does not bother end-users and administrators since the actual API is hidden from them by various UI and CLI tools, but becomes a problem for third-party software solutions since they have to interact with the API directly and thus have to possess deep knowledge of murano internals. If we want the cloud applications to be able to interact with each other via murano we need to provide some higher level client library which will encapsulate all the murano-related specifics and will provide the clients with clean and streamlined software interface. The primary consumers of this SDK library will be the developers of cloud applications. This applications will integrate with SDK thus obtaining high level access to their own (and their peers') service API exposed via murano. Proposed change =============== It is proposed to add a new set of python classes (distributed either as a standalone pypi package or as a new module in python-muranoclient package) which will provide a set of high level calls to murano API returning dynamically constructed python objects representing appropriate entities of object model. The attributes of these objects will match appropriate Input or Output properties of their corresponding MuranoPL objects. Consumer's code will be able to modify the values of Input (or InputOutput) properties but only if the value being set matches the contracts of that properties. Output properties are readonly, so attempts to modify the corresponding python attributes will lead to exceptions. The SDK will provide a context manager object creating a new session in the given environment. Each property assignment being done within an appropriate ""with"" code block will result in an API call immediately modifying the object model of appropriate session. When the execution exits the ""with"" block the session will be ""committed"", i.e. the changes will be copied to the main environment object model. The SDK may be configured to automatically redeploy the environment after commits. The pythonic objects generated by the SDK will contain methods corresponding to publicly-exposed MuranoPL methods (""actions""). Calling these pythonic methods from the consumer code will execute appropriate actions. The parameters of the called methods will be evaluated to match the contracts of appropriate MuranoPL method arguments prior to calling the actual murano action API. These dynamically generated methods will have names matching the names of appropriate actions, and their call will block the execution until the action execution completes and return a result (the actual execution will do polling on Action API under the hood of these methods). For each of such methods a second method will be generated having a name pattern ""%methodname%_async"". Calling these methods will execute the actions asynchronously: the call will initiate the action execution and immediately return a ""Future"" object which may be used later to retrieve the result (in a single call if the action is already completed at that moment or by polling if not). The SDK will provide a factory class capable to create and configure the instances of the client based on a set of configuration values. It should allow passing these values both manually and reading them from a file in a specific format. The latter will be used when the SDK access is provided to a virtual machine deployed via murano: if the SDK access is granted to it the configuration file will be delivered to the VM as part of the provisioning process, so the SDK will be able to load it from the well-known location. Deployment of SDK on the VMs may be done manually by the application developers (e.g. they may include the dependency on appropriate python package in the requirements.txt file of their python distribution), but it may be beneficial to simplify this process by providing appropriate methods in the base class of Standard Library: having a `deploySdk` method in the `LinuxMuranoInstance` class will allow applications to easily deploy the SDK on its VMs with a single call of a MuranoPL method. Such deployment will also sent a set of configuration settings which will allow the SDK to properly connect to and authenticate with murano API. The SDK will include the authentication tooling: a set of utilities which will allow applications to request access to murano API and the user to grant it. This particular part is out of scope for this specification and should be described separately. Alternatives ------------ As an alternative to this SDK the client code could use regular Murano API without any wrappers around it. This requires more efforts from application developer and thus should be used only if the SDK does not provide the required functionality. Security Impact --------------- Any consumers of Murano API should be properly authenticated to access its resources. The regular users will use usual keystone-based authentication by obtaining an access token using their username and password. However the third-party applications which are the primary consumers of the SDK described in this spec cannot be trusted with actual users credentials. Instead some role delegation system should be used: based on trusts, OAuth delegation or something else. An authentication token of some kind should be delivered to VM and become part of the SDK configuration file; this token will allow the SDK to authenticate in murano API. This token will be scoped to A separate spec is required to to describe the trust system, access scopes and the changes which have to be introduced to support all of them in Murano. Data model impact ----------------- No model impact REST API impact --------------- To properly support transaction-like changes in Object Model the session API needs to be improved to support session ""commits"" without the actual deployments. A new API call will be added: * Complete Session * Completes the session, thus merging its object model back to the environment * Method type: POST * Normal http response code(s): 200 * Expected error http response code(s): * 409 if the merge cannot be done due to a conflict, i.e. if the same parts of the object model were modified by a another recently completed session * 403 if the environment is being deployed * URI: /v1/environments/%environment_id%/sessions/%session_id%/complete * URI parameters: * environment_id - id of the environment * session_id - id of the session Versioning impact ----------------- Since the session completion operation adds a new call to murano API a minor API version should be incremented Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- Application developers will need to be familiar with SDK, as well as with the ways to authorize their VM-based apps to access it. Murano-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: ativelkov Work Items ---------- * Introduce API changes * Create the SDK classes in python-muranoclient or standalone library * Add helper methods to automate SDK deployments on the VMs provisioned by murano-deployed applications. Dependencies ============ * Authentication tooling has to be implemented before this SDK is created Testing ======= * The internals of the SDK should be covered by unit and functional tests. * All the API calls utilized by the SDK should be covered by the integration tests. Documentation Impact ==================== The SDK has to be clearly documented so the application developers know how to use it. References ========== None ",,260,0
openstack%2Fnova~master~Id54f7bdfa14a19da41da554b13ba9496ee525c71,openstack/nova,master,Id54f7bdfa14a19da41da554b13ba9496ee525c71,libvirt: make live_migration_uri flag dependent on virt_type,MERGED,2015-04-21 09:05:11.000000000,2016-02-19 12:36:05.000000000,2016-02-18 15:09:17.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 782}, {'_account_id': 1247}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6849}, {'_account_id': 7730}, {'_account_id': 8300}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12299}, {'_account_id': 14358}, {'_account_id': 14384}, {'_account_id': 14819}, {'_account_id': 15286}, {'_account_id': 15424}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-04-21 09:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec04702b5718076a8d13f2e440aa91576053a77d', 'message': 'libvirt: make live_migration_uri flag dependant on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default valur of the ""live_migration_uri"" flag,\nthat now is dependant on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 2, 'created': '2015-06-04 10:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16cd530fc0f74c19ba25b606b13427fb0b572d3b', 'message': 'libvirt: make live_migration_uri flag dependant on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default valur of the ""live_migration_uri"" flag,\nthat now is dependant on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 3, 'created': '2015-06-04 11:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3fc851f689defbe059cb2370b335da1cbdfac12', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default valur of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 4, 'created': '2015-06-04 14:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10defb1f59ec29bedb5958162d8211b0f82ca885', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 5, 'created': '2015-06-19 08:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1d9ba14a37744aa47de38f4616563f886d2f4e5', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 6, 'created': '2015-06-29 11:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1aae14834582e656b020134b895b6bcc7efd0e0', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 7, 'created': '2015-07-06 08:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2aeeadfe2fd1cb819a61adc1da6d1dc01f313d81', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 8, 'created': '2015-07-27 09:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16f624fd937b157eda8e3f3e6e310620f4d7152c', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 9, 'created': '2015-08-31 08:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62655a831d5f1d9e10167500538c78ab4cdbd454', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 10, 'created': '2015-08-31 10:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b38044065114e4c0ecbd6876809f55658394479', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 11, 'created': '2015-09-04 08:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/147850b4db5e81f9773f262dbb21b4bef289a9e2', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 12, 'created': '2015-09-18 08:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9896b73006e97868b60bd5fefa50a5c68250a13d', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 13, 'created': '2015-09-22 10:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30f2f04b282e07067f0bec95614c25c22621b866', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 14, 'created': '2015-10-06 15:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75052a08052c6ac71205c5d0e04c97cc18aba8c3', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 15, 'created': '2015-11-04 08:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8de3545e6b4c14dfeef6af938bc44d570fa4ca13', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 16, 'created': '2015-11-16 09:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb8fa060e98605e057c1ce0bbc1842cbccb2db10', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 17, 'created': '2015-11-30 12:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73fac19b364e23bdd6f5ff849d724973dfd7801a', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 18, 'created': '2015-12-10 09:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd621c0ce3b65eda454b5fd3aa41c13d2572c64e', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 19, 'created': '2015-12-15 15:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d796209b3c70606b337ef77579f9e1b66490017c', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 20, 'created': '2015-12-23 09:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b49fe91bf51492b595db11a8d27ecb70c6b4fe15', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 21, 'created': '2016-01-14 10:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/efc6cef6fdebcb7a365c002b4f228a7069c8712a', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 22, 'created': '2016-01-27 12:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5eb2025e5ce5b831dd2401d8e0f8a43512a0cc4', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 23, 'created': '2016-02-07 12:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72a1c9d913c30203ae9f9ca3cbbf87326930a952', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 24, 'created': '2016-02-11 12:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cf3fed93560b09ed79820f285661d86c7c477ae', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 25, 'created': '2016-02-12 10:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a333ecbb7116181dd49423ceb811b99ef251e156', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}, {'number': 26, 'created': '2016-02-15 08:50:17.000000000', 'files': ['nova/exception.py', 'nova/virt/libvirt/driver.py', 'releasenotes/notes/live_migration_uri-dependent-on-virt_type-595c46c2310f45c3.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3159c8fd5bea80c820e58bd38d96f5f8fe8f4503', 'message': 'libvirt: make live_migration_uri flag dependent on virt_type\n\nThe default value for the ""live_migration_uri"" flag should be\ndependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This\nway, an operator can set the ""virt_type"" flag without the need to check\nfor each individual uri.\n\nDocImpact: Changed the default value of the ""live_migration_uri"" flag,\nthat now is dependent on the ""virt_type"".\nCloses-Bug: #1298242\nChange-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71\n'}]",27,175780,3159c8fd5bea80c820e58bd38d96f5f8fe8f4503,323,28,26,91,,,0,"libvirt: make live_migration_uri flag dependent on virt_type

The default value for the ""live_migration_uri"" flag should be
dependent on the ""virt_type"" flag, as the ""connection_uri"" flag is. This
way, an operator can set the ""virt_type"" flag without the need to check
for each individual uri.

DocImpact: Changed the default value of the ""live_migration_uri"" flag,
that now is dependent on the ""virt_type"".
Closes-Bug: #1298242
Change-Id: Id54f7bdfa14a19da41da554b13ba9496ee525c71
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/175780/25 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,ec04702b5718076a8d13f2e440aa91576053a77d,bug/1298242," default='', help='Override the default libvirt live migration target URI ' '(which is dependant on virt_type) ' @staticmethod def live_migration_uri(): if CONF.libvirt.virt_type == 'xen': uri = CONF.libvirt.live_migration_uri or 'xen+tcp://%s/system' elif CONF.libvirt.virt_type == 'kvm': uri = CONF.libvirt.live_migration_uri or 'qemu+tcp://%s/system' else: uri = CONF.libvirt.live_migration_uri return uri dom.migrateToURI(self.live_migration_uri % dest, dom.migrateToURI2(self.live_migration_uri % dest, self.live_migration_uri % dest,"," default=""qemu+tcp://%s/system"", help='Migration target URI ' dom.migrateToURI(CONF.libvirt.live_migration_uri % dest, dom.migrateToURI2(CONF.libvirt.live_migration_uri % dest, CONF.libvirt.live_migration_uri % dest,",16,5
openstack%2Ffuel-octane~stable%2F7.0~Ia89b1aa060c900e5ef83f76d257b1f284c059f88,openstack/fuel-octane,stable/7.0,Ia89b1aa060c900e5ef83f76d257b1f284c059f88,Add tests for get_patch_port_action function,MERGED,2016-02-19 11:03:09.000000000,2016-02-19 12:34:08.000000000,2016-02-19 12:34:08.000000000,"[{'_account_id': 3}, {'_account_id': 708}]","[{'number': 1, 'created': '2016-02-19 11:03:09.000000000', 'files': ['octane/tests/test_transformations.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/15d286b4ea75e744845ac41b5fb8bb4a6da5387b', 'message': 'Add tests for get_patch_port_action function\n\nTest proper identification of release and provider for port\nin network schema.\n\nChange-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88\nRelated-bug: 1536182\n(cherry picked from commit 41b2cbcaeb591e9733d5a2db461186a08ca825d6)\n'}]",0,282279,15d286b4ea75e744845ac41b5fb8bb4a6da5387b,8,2,1,6677,,,0,"Add tests for get_patch_port_action function

Test proper identification of release and provider for port
in network schema.

Change-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88
Related-bug: 1536182
(cherry picked from commit 41b2cbcaeb591e9733d5a2db461186a08ca825d6)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/79/282279/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/tests/test_transformations.py'],1,15d286b4ea75e744845ac41b5fb8bb4a6da5387b,bug/1536182,"import pytest DEFAULT_OVS_ACTION = { 'action': 'add-patch', 'bridges': ['test-br'] } DEFAULT_LNX_ACTION = { 'action': 'add-port', 'bridge': 'test-br' } OVS_ACTION = { 'action': 'add-patch', 'bridges': ['test-br'], 'provider': 'ovs' } LNX_ACTION = { 'action': 'add-port', 'bridge': 'test-br', 'provider': 'lnx' } ADD_LNX_BR_ACTION = { 'action': 'add-br', 'provider': 'lnx', 'name': 'test-br' } ADD_OVS_BR_ACTION = { 'action': 'add-br', 'provider': 'ovs', 'name': 'test-br' } HOST_CONFIG_6_0 = { 'openstack_version': '2014.2-6.0', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, DEFAULT_OVS_ACTION ] } } HOST_CONFIG_6_0_1 = { 'openstack_version': 'fake-6.0.1', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, DEFAULT_OVS_ACTION ] } } HOST_CONFIG_6_1 = { 'openstack_version': '2014.2.2-6.1', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, ] } } HOST_CONFIG_7_0 = { 'openstack_version': '2015.1.0-7.0', 'network_scheme': { 'transformations': [ OVS_ACTION, DEFAULT_OVS_ACTION, ADD_OVS_BR_ACTION ] } } @pytest.mark.parametrize('host_config,expected_action', [ (HOST_CONFIG_6_0, DEFAULT_OVS_ACTION), (HOST_CONFIG_6_0_1, DEFAULT_OVS_ACTION), (HOST_CONFIG_6_1, DEFAULT_LNX_ACTION), (HOST_CONFIG_7_0, OVS_ACTION)]) def test_patch_port_action(host_config, expected_action): bridge = 'test-br' res, _ = ts.get_patch_port_action(host_config, bridge) assert res == expected_action",,79,0
openstack%2Ffuel-octane~stable%2F8.0~Ia89b1aa060c900e5ef83f76d257b1f284c059f88,openstack/fuel-octane,stable/8.0,Ia89b1aa060c900e5ef83f76d257b1f284c059f88,Add tests for get_patch_port_action function,MERGED,2016-02-19 11:01:01.000000000,2016-02-19 12:33:23.000000000,2016-02-19 12:33:23.000000000,"[{'_account_id': 3}, {'_account_id': 708}]","[{'number': 1, 'created': '2016-02-19 11:01:01.000000000', 'files': ['octane/tests/test_transformations.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/9244220b233d014ab6342c818b2d75b7d6ac1ab4', 'message': 'Add tests for get_patch_port_action function\n\nTest proper identification of release and provider for port\nin network schema.\n\nChange-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88\nRelated-bug: 1536182\n(cherry picked from commit 41b2cbcaeb591e9733d5a2db461186a08ca825d6)\n'}]",0,282277,9244220b233d014ab6342c818b2d75b7d6ac1ab4,6,2,1,6677,,,0,"Add tests for get_patch_port_action function

Test proper identification of release and provider for port
in network schema.

Change-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88
Related-bug: 1536182
(cherry picked from commit 41b2cbcaeb591e9733d5a2db461186a08ca825d6)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/77/282277/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/tests/test_transformations.py'],1,9244220b233d014ab6342c818b2d75b7d6ac1ab4,bug/1536182,"import pytest DEFAULT_OVS_ACTION = { 'action': 'add-patch', 'bridges': ['test-br'] } DEFAULT_LNX_ACTION = { 'action': 'add-port', 'bridge': 'test-br' } OVS_ACTION = { 'action': 'add-patch', 'bridges': ['test-br'], 'provider': 'ovs' } LNX_ACTION = { 'action': 'add-port', 'bridge': 'test-br', 'provider': 'lnx' } ADD_LNX_BR_ACTION = { 'action': 'add-br', 'provider': 'lnx', 'name': 'test-br' } ADD_OVS_BR_ACTION = { 'action': 'add-br', 'provider': 'ovs', 'name': 'test-br' } HOST_CONFIG_6_0 = { 'openstack_version': '2014.2-6.0', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, DEFAULT_OVS_ACTION ] } } HOST_CONFIG_6_0_1 = { 'openstack_version': 'fake-6.0.1', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, DEFAULT_OVS_ACTION ] } } HOST_CONFIG_6_1 = { 'openstack_version': '2014.2.2-6.1', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, ] } } HOST_CONFIG_7_0 = { 'openstack_version': '2015.1.0-7.0', 'network_scheme': { 'transformations': [ OVS_ACTION, DEFAULT_OVS_ACTION, ADD_OVS_BR_ACTION ] } } @pytest.mark.parametrize('host_config,expected_action', [ (HOST_CONFIG_6_0, DEFAULT_OVS_ACTION), (HOST_CONFIG_6_0_1, DEFAULT_OVS_ACTION), (HOST_CONFIG_6_1, DEFAULT_LNX_ACTION), (HOST_CONFIG_7_0, OVS_ACTION)]) def test_patch_port_action(host_config, expected_action): bridge = 'test-br' res, _ = ts.get_patch_port_action(host_config, bridge) assert res == expected_action",,79,0
openstack%2Fsenlin~master~I1416eb76e286b0e71a38669b53f5870b42301839,openstack/senlin,master,I1416eb76e286b0e71a38669b53f5870b42301839,Validate 'sort' parameter for profiles in engine,MERGED,2016-02-19 08:26:35.000000000,2016-02-19 12:31:10.000000000,2016-02-19 12:31:10.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 08:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/b143a8f243c4ee50e5fdc65c9c0650d17d926ab0', 'message': ""Validate 'sort' parameter for profiles in engine\n\nThis adds validation of 'sort' parameter in engine service.\n\nChange-Id: I1416eb76e286b0e71a38669b53f5870b42301839\n""}, {'number': 2, 'created': '2016-02-19 12:16:08.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_profiles.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4097468b5debd2752a014473266a5f4a9e3150ba', 'message': ""Validate 'sort' parameter for profiles in engine\n\nThis adds validation of 'sort' parameter in engine service.\n\nChange-Id: I1416eb76e286b0e71a38669b53f5870b42301839\n""}]",0,282222,4097468b5debd2752a014473266a5f4a9e3150ba,9,2,2,8246,,,0,"Validate 'sort' parameter for profiles in engine

This adds validation of 'sort' parameter in engine service.

Change-Id: I1416eb76e286b0e71a38669b53f5870b42301839
",git fetch https://review.opendev.org/openstack/senlin refs/changes/22/282222/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_profiles.py']",2,b143a8f243c4ee50e5fdc65c9c0650d17d926ab0,profile-sort," filters={'foo': 'bar'}, sort='name:asc', filters={'foo': 'bar'}, sort='name:asc', self.ctx, sort='crazykey') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) ex = self.assertRaises(rpc.ExpectedException, self.eng.profile_list,"," filters={'foo': 'bar'}, sort='k:asc', filters={'foo': 'bar'}, sort='k:asc',",9,2
openstack%2Ftripleo-common~master~Icb17ecaf1ac1ac2bf45af20f2896d90fab0c3943,openstack/tripleo-common,master,Icb17ecaf1ac1ac2bf45af20f2896d90fab0c3943,DO NOT MERGE testing current with master puppet-nova,ABANDONED,2016-02-19 12:24:29.000000000,2016-02-19 12:28:44.000000000,,[{'_account_id': 12715}],"[{'number': 1, 'created': '2016-02-19 12:24:29.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/24247ccdb620aabc2be35a8c5622348156d7281e', 'message': 'DO NOT MERGE testing current with master puppet-nova\n\nThis ties together fixes for all of the known issues\npreventing us from updating the current-tripleo symlink\nin delorean.\n\nhttps://etherpad.openstack.org/p/delorean_master_current_issues\n\nChange-Id: Icb17ecaf1ac1ac2bf45af20f2896d90fab0c3943\nDepends-On: Ia8242f23864ebb14ccf858a77ba754059e9c2d4a\nDepends-On: I8b6d907fe46579007f33a7e69e7d67e79582426c\nDepends-On: Ifb8c23c81c665c2732fa5cd757760668b06a449a\n'}]",0,282308,24247ccdb620aabc2be35a8c5622348156d7281e,2,1,1,1926,,,0,"DO NOT MERGE testing current with master puppet-nova

This ties together fixes for all of the known issues
preventing us from updating the current-tripleo symlink
in delorean.

https://etherpad.openstack.org/p/delorean_master_current_issues

Change-Id: Icb17ecaf1ac1ac2bf45af20f2896d90fab0c3943
Depends-On: Ia8242f23864ebb14ccf858a77ba754059e9c2d4a
Depends-On: I8b6d907fe46579007f33a7e69e7d67e79582426c
Depends-On: Ifb8c23c81c665c2732fa5cd757760668b06a449a
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/08/282308/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,24247ccdb620aabc2be35a8c5622348156d7281e,move-current-tripleo," http://trunk.rdoproject.org/centos7/current/""}"," http://trunk.rdoproject.org/centos7/current-tripleo/""} # pin for https://bugs.launchpad.net/tripleo/+bug/1543493 export DIB_REPOREF_puppet_nova=e64bc9a57b2a9febad50181889faa19fba5f72ef # pin for https://bugs.launchpad.net/tripleo/+bug/1543493 export DIB_REPOREF_puppet_nova=e64bc9a57b2a9febad50181889faa19fba5f72ef ",1,7
openstack%2Fos-win~master~Ia937399c999d7293799a864a322323e3d2efc123,openstack/os-win,master,Ia937399c999d7293799a864a322323e3d2efc123,Refactors metrics related utils,MERGED,2015-09-17 00:38:37.000000000,2016-02-19 12:22:49.000000000,2016-02-19 12:22:49.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 12604}]","[{'number': 1, 'created': '2015-09-17 00:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/af3c5ba5c7888160b1c17ac4e419dbadae4b6de7', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 2, 'created': '2016-02-12 16:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/de3ff78ef51d4d1e2687b9223e774acfe62fe1c9', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 3, 'created': '2016-02-15 23:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/cf30fd9e09b5682592d20033445400d8565528c9', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 4, 'created': '2016-02-15 23:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/c4ec5c74a7d14236b7cf4929ff0b83587b278575', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 5, 'created': '2016-02-16 00:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/0841e83e318c52a94582cef7817295fc3b4848bf', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 6, 'created': '2016-02-16 08:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/c42b972f0adcbc8ee0c9bcc4c02f75d5d23215dc', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 7, 'created': '2016-02-16 13:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/fa7f1a996d612c32c2ea3b706da8192cf8773467', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 8, 'created': '2016-02-16 13:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/befa0517e63b7f503bec31f2766b68c4876262a1', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 9, 'created': '2016-02-16 19:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/31b76834d9301fadb710196cbae670d318a3fa82', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 10, 'created': '2016-02-17 18:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/bdd76200bad4c8bb958ae4a5ee951b8044c18149', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 11, 'created': '2016-02-18 09:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/41c76c9e220bd2c29fb54a231bc3bf33db3fb52a', 'message': 'WIP: Refactors metrics related utils\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n'}, {'number': 12, 'created': '2016-02-18 12:59:37.000000000', 'files': ['os_win/utils/metrics/metricsutils.py', 'os_win/utils/compute/vmutils.py', 'os_win/utils/network/networkutils.py', 'os_win/tests/utils/metrics/test_metricsutils.py', 'os_win/tests/utils/network/test_networkutils.py', 'os_win/utils/metrics/__init__.py', 'os_win/utilsfactory.py', 'os_win/tests/utils/compute/test_vmutils.py', 'os_win/utils/hostutils.py', 'os_win/tests/utils/test_hostutils.py', 'os_win/tests/utils/metrics/__init__.py', 'os_win/exceptions.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/518ef3d06d746f5bed4b74fabaee89d3f151c4c8', 'message': ""Refactors metrics related utils\n\nAdds metricsutils and test_metricsutils. It contains methods from\nnetworkutils, vmutils and ceilometer, all related to enabling,\nretrieving and processing virtual machine related metrics.\n\nNote: vmutils' enable_vm_metrics_collection will have to be removed\nonce all its usages have updated to metricsutils.\n\nPartially-Implements: blueprint add-os-win-modules\n\nChange-Id: Ia937399c999d7293799a864a322323e3d2efc123\n""}]",6,224372,518ef3d06d746f5bed4b74fabaee89d3f151c4c8,42,5,12,8213,,,0,"Refactors metrics related utils

Adds metricsutils and test_metricsutils. It contains methods from
networkutils, vmutils and ceilometer, all related to enabling,
retrieving and processing virtual machine related metrics.

Note: vmutils' enable_vm_metrics_collection will have to be removed
once all its usages have updated to metricsutils.

Partially-Implements: blueprint add-os-win-modules

Change-Id: Ia937399c999d7293799a864a322323e3d2efc123
",git fetch https://review.opendev.org/openstack/os-win refs/changes/72/224372/11 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/tests/utils/test_metricsutilsv2.py', 'os_win/utils/networkutilsv2.py', 'os_win/utils/networkutils.py', 'os_win/utils/vmutils.py', 'os_win/tests/utils/test_vmutilsv2.py', 'os_win/utils/metricsutilsv2.py', 'os_win/tests/utils/test_networkutilsv2.py', 'os_win/tests/utils/test_vmutils.py', 'os_win/utils/vmutilsv2.py']",9,af3c5ba5c7888160b1c17ac4e419dbadae4b6de7,add_metrics_utils,," _METRIC_AGGR_CPU_AVG = 'Aggregated Average CPU Utilization' _METRIC_AGGR_MEMORY_AVG = 'Aggregated Average Memory Utilization' _METRIC_ENABLED = 2 def enable_vm_metrics_collection(self, vm_name): metric_names = [self._METRIC_AGGR_CPU_AVG, self._METRIC_AGGR_MEMORY_AVG] vm = self._lookup_vm_check(vm_name) metric_svc = self._conn.Msvm_MetricService()[0] (disks, volumes) = self._get_vm_disks(vm) filtered_disks = [d for d in disks if d.ResourceSubType is not self._DVD_DISK_RES_SUB_TYPE] # enable metrics for disk. for disk in filtered_disks: self._enable_metrics(metric_svc, disk) for metric_name in metric_names: metric_def = self._conn.CIM_BaseMetricDefinition(Name=metric_name) if not metric_def: LOG.debug(""Metric not found: %s"", metric_name) else: self._enable_metrics(metric_svc, vm, metric_def[0].path_()) def _enable_metrics(self, metric_svc, element, definition_path=None): metric_svc.ControlMetrics( Subject=element.path_(), Definition=definition_path, MetricCollectionEnabled=self._METRIC_ENABLED) ",456,298
openstack%2Fproject-config~master~I36a88ef5af19c83939058adb62630add94f8d147,openstack/project-config,master,I36a88ef5af19c83939058adb62630add94f8d147,Add heat lbaas specific test for v1 and v2,MERGED,2016-02-17 16:00:55.000000000,2016-02-19 12:16:35.000000000,2016-02-19 12:16:35.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6577}, {'_account_id': 7128}, {'_account_id': 7385}]","[{'number': 1, 'created': '2016-02-17 16:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2b7f78aba8386da15306915ff1ffc8aef4714ecb', 'message': 'Add heat lbaas specific test for v1 and v2\n\nThis add functional tests jobs for lbaas v2.\nAll the LBaaS v2 tests are NON-Voting\n\nThere are other patches in progress for creating the new\nlbaas v2 resources and function tests.\n\nChange-Id: I36a88ef5af19c83939058adb62630add94f8d147\nDepends-On: Ifc2fb844409b8e90f42b0f170b32c094c03815f2\nblueprint: lbaasv2-suport\nRelated-Bug: #1546522\n'}, {'number': 2, 'created': '2016-02-17 16:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b1060b2dc85e557a53d59c715e830f6331bb092f', 'message': 'Add heat lbaas specific test for v1 and v2\n\nThis add functional tests jobs for lbaas v2.\nAll the LBaaS v2 tests are NON-Voting\n\nThere are other patches in progress for creating the new\nlbaas v2 resources and function tests.\n\nChange-Id: I36a88ef5af19c83939058adb62630add94f8d147\nDepends-On: Ifc2fb844409b8e90f42b0f170b32c094c03815f2\nblueprint: lbaasv2-suport\nRelated-Bug: #1546522\n'}, {'number': 3, 'created': '2016-02-18 15:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/11b02240c6d59c04f459e45c3d40fed64101f145', 'message': 'Add heat lbaas specific test for v1 and v2\n\nThis add functional tests jobs for lbaas v2.\nAll the LBaaS v2 tests are NON-Voting\n\nThere are other patches in progress for creating the new\nlbaas v2 resources and function tests.\n\nChange-Id: I36a88ef5af19c83939058adb62630add94f8d147\nDepends-On: Ifc2fb844409b8e90f42b0f170b32c094c03815f2\nblueprint: lbaasv2-suport\nRelated-Bug: #1546522\n'}, {'number': 4, 'created': '2016-02-18 15:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b4fbed7b2807dd535f8c57674df006b2b8dadfde', 'message': 'Add heat lbaas specific test for v1 and v2\n\nThis add functional tests jobs for lbaas v2.\nAll the LBaaS v2 tests are NON-Voting\n\nThere are other patches in progress for creating the new\nlbaas v2 resources and function tests.\n\nChange-Id: I36a88ef5af19c83939058adb62630add94f8d147\nDepends-On: Ifc2fb844409b8e90f42b0f170b32c094c03815f2\nblueprint: lbaasv2-suport\nRelated-Bug: #1546522\n'}, {'number': 5, 'created': '2016-02-18 16:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/373c958740fee6eb435cee032500ca07c08bcda5', 'message': 'Add heat lbaas specific test for v1 and v2\n\nThis add functional tests jobs for lbaas v2.\nAll the LBaaS v2 tests are NON-Voting\n\nThere are other patches in progress for creating the new\nlbaas v2 resources and function tests.\n\nChange-Id: I36a88ef5af19c83939058adb62630add94f8d147\nDepends-On: Ifc2fb844409b8e90f42b0f170b32c094c03815f2\nblueprint: lbaasv2-suport\nRelated-Bug: #1546522\n'}, {'number': 6, 'created': '2016-02-18 20:35:32.000000000', 'files': ['jenkins/jobs/heat.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0556858daf9f240419c0a21f32939f0a981b3382', 'message': 'Add heat lbaas specific test for v1 and v2\n\nThis add functional tests jobs for lbaas v2.\nAll the LBaaS v2 tests are NON-Voting\n\nThere are other patches in progress for creating the new\nlbaas v2 resources and function tests.\n\nChange-Id: I36a88ef5af19c83939058adb62630add94f8d147\nblueprint: lbaasv2-suport\nRelated-Bug: #1546522\n'}]",15,281354,0556858daf9f240419c0a21f32939f0a981b3382,29,8,6,7128,,,0,"Add heat lbaas specific test for v1 and v2

This add functional tests jobs for lbaas v2.
All the LBaaS v2 tests are NON-Voting

There are other patches in progress for creating the new
lbaas v2 resources and function tests.

Change-Id: I36a88ef5af19c83939058adb62630add94f8d147
blueprint: lbaasv2-suport
Related-Bug: #1546522
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/281354/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/heat.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",3,2b7f78aba8386da15306915ff1ffc8aef4714ecb,bug/1546522, # NOTE(markvan) Make these non-voting until resources # and lbaasv2 environment stablizes - name: ^gate-heat-dsvm-functional-.*-lbaasv2$ - name: ^gate-heat-dsvm-functional-convg-mysql-lbaasv2 - gate-heat-dsvm-functional-orig-mysql-lbaasv1 - gate-heat-dsvm-functional-orig-mysql-lbaasv2 - gate-heat-dsvm-functional-convg-mysql-lbaasv2 - gate-heat-dsvm-functional-orig-mysql-lbaasv2 - gate-heat-dsvm-functional-convg-mysql-lbaasv2 - gate-heat-dsvm-functional-orig-postgres-lbaasv2, - name: gate-heat-dsvm-functional-orig-postgres - name: gate-heat-dsvm-functional-convg-mysql - gate-heat-dsvm-functional-orig-mysql - gate-heat-dsvm-functional-convg-mysql - gate-heat-dsvm-functional-orig-mysql - gate-heat-dsvm-functional-convg-mysql - gate-heat-dsvm-functional-orig-postgres,47,12
openstack%2Ffuel-octane~stable%2F7.0~I066750e8deb292fa8a34656d2bce06ef13719360,openstack/fuel-octane,stable/7.0,I066750e8deb292fa8a34656d2bce06ef13719360,Remove version hardcode from puppet module path,MERGED,2016-02-19 10:23:00.000000000,2016-02-19 12:11:30.000000000,2016-02-19 12:11:30.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}, {'_account_id': 9414}]","[{'number': 1, 'created': '2016-02-19 10:23:00.000000000', 'files': ['octane/magic_consts.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/9cf51987eeee9acfe2c75962781bd6fed6198b68', 'message': 'Remove version hardcode from puppet module path\n\nNow module path constant has hardcoded version 2015.1.0-7.0.\nReplace it with /etc/puppet/modules path which is a symlink\nto the current version of modules.\n\nChange-Id: I066750e8deb292fa8a34656d2bce06ef13719360\nCloses-bug: 1544967\n(cherry picked from commit bde08a6c5d1e6107f1fe30cd138357d2e74ceb25)\n'}]",0,282264,9cf51987eeee9acfe2c75962781bd6fed6198b68,8,4,1,6677,,,0,"Remove version hardcode from puppet module path

Now module path constant has hardcoded version 2015.1.0-7.0.
Replace it with /etc/puppet/modules path which is a symlink
to the current version of modules.

Change-Id: I066750e8deb292fa8a34656d2bce06ef13719360
Closes-bug: 1544967
(cherry picked from commit bde08a6c5d1e6107f1fe30cd138357d2e74ceb25)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/64/282264/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/magic_consts.py'],1,9cf51987eeee9acfe2c75962781bd6fed6198b68,bug/1544967,"PUPPET_DIR = ""/etc/puppet/modules""","PUPPET_DIR = ""/etc/puppet/2015.1.0-7.0/modules""",1,1
openstack%2Fpython-senlinclient~master~I1f344ff54bc0780272d7d4baff43a137544cf59e,openstack/python-senlinclient,master,I1f344ff54bc0780272d7d4baff43a137544cf59e,Add OpenstackClient plugin for cluster profile create,MERGED,2016-02-17 12:26:35.000000000,2016-02-19 12:09:13.000000000,2016-02-19 12:09:13.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-02-17 12:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/252c5fc91a46026ca65c0641fafcab901690b234', 'message': 'Add OpenstackClient plugin for cluster profile create\n\nThis change implements the ""openstack cluster profile create"" command\n  Based on the existing senlin command: senlin profile-create\n\nChange-Id: I1f344ff54bc0780272d7d4baff43a137544cf59e\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-02-18 09:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/9034f73f357d3ede9006bd061313f69135708ad3', 'message': 'Add OpenstackClient plugin for cluster profile create\n\nThis change implements the ""openstack cluster profile create"" command\n  Based on the existing senlin command: senlin profile-create\n\nChange-Id: I1f344ff54bc0780272d7d4baff43a137544cf59e\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 3, 'created': '2016-02-19 10:14:52.000000000', 'files': ['senlinclient/osc/v1/profile.py', 'senlinclient/tests/test_specs/nova_server.yaml', 'senlinclient/tests/unit/osc/v1/test_profile.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/07e0f3bdc4626f65d7969f7ac31351523671af1b', 'message': 'Add OpenstackClient plugin for cluster profile create\n\nThis change implements the ""openstack cluster profile create"" command\n  Based on the existing senlin command: senlin profile-create\n\nChange-Id: I1f344ff54bc0780272d7d4baff43a137544cf59e\nBlueprint: senlin-support-python-openstackclient\n'}]",2,281229,07e0f3bdc4626f65d7969f7ac31351523671af1b,17,4,3,18389,,,0,"Add OpenstackClient plugin for cluster profile create

This change implements the ""openstack cluster profile create"" command
  Based on the existing senlin command: senlin profile-create

Change-Id: I1f344ff54bc0780272d7d4baff43a137544cf59e
Blueprint: senlin-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/29/281229/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/osc/v1/profile.py', 'senlinclient/tests/test_specs/nova_server.yaml', 'senlinclient/tests/unit/osc/v1/test_profile.py', 'setup.cfg']",4,252c5fc91a46026ca65c0641fafcab901690b234,bp/senlin-support-python-openstackclient, cluster_profile_create = senlinclient.osc.v1.profile:CreateProfile,,118,0
openstack%2Fneutron~master~I72996d9a77f5f17b4d7a19d5be20b3f97f90dcba,openstack/neutron,master,I72996d9a77f5f17b4d7a19d5be20b3f97f90dcba,Remove floatingip address only when the address has been configured,MERGED,2016-01-20 03:34:01.000000000,2016-02-19 12:07:06.000000000,2016-02-19 12:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-01-20 03:34:01.000000000', 'files': ['neutron/agent/l3/ha_router.py', 'neutron/tests/functional/agent/l3/test_ha_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/77f84fa9353dbf1d4c248c97ba59e857facefdb2', 'message': ""Remove floatingip address only when the address has been configured\n\nFor HA router, adding a floatingip will add a vip to keepalived, then\nkeepalived will add the ip address to port. So there is a time window\nthat the qg device in qrouter namespace will not have the address of\nfloatingip.\n\nIf user delete the floatingip at the time window, ip command will fail,\nbecause it tries to remove an ip address that doesn't exist on the qg device.\n\nThe fix here is to check if the ip address is on the qg device, before\nremoving the ip address. A functional test is added to address the issue.\n\nChange-Id: I72996d9a77f5f17b4d7a19d5be20b3f97f90dcba\nCloses-bug: #1533904\n""}]",0,269988,77f84fa9353dbf1d4c248c97ba59e857facefdb2,41,9,1,11159,,,0,"Remove floatingip address only when the address has been configured

For HA router, adding a floatingip will add a vip to keepalived, then
keepalived will add the ip address to port. So there is a time window
that the qg device in qrouter namespace will not have the address of
floatingip.

If user delete the floatingip at the time window, ip command will fail,
because it tries to remove an ip address that doesn't exist on the qg device.

The fix here is to check if the ip address is on the qg device, before
removing the ip address. A functional test is added to address the issue.

Change-Id: I72996d9a77f5f17b4d7a19d5be20b3f97f90dcba
Closes-bug: #1533904
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/269988/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/ha_router.py', 'neutron/tests/functional/agent/l3/test_ha_router.py']",2,77f84fa9353dbf1d4c248c97ba59e857facefdb2,bug/1533904," def test_removing_floatingip_immediately(self): router_info = self.generate_router_info(enable_ha=True) router = self.manage_router(self.agent, router_info) ex_gw_port = router.get_ex_gw_port() interface_name = router.get_external_device_interface_name(ex_gw_port) utils.wait_until_true(lambda: router.ha_state == 'master') self._add_fip(router, '172.168.1.20', fixed_address='10.0.0.3') router.process(self.agent) router.router[l3_constants.FLOATINGIP_KEY] = [] # The purpose of the test is to simply make sure no exception is raised # Because router.process will consume the FloatingIpSetupException, # call the configure_fip_addresses directly here router.configure_fip_addresses(interface_name) ",,17,1
openstack%2Ftempest~master~Ifc29617743b76b01eb6cd30a375cf47b56e4f635,openstack/tempest,master,Ifc29617743b76b01eb6cd30a375cf47b56e4f635,add client_manager_class param to BaseTestCase,MERGED,2015-12-09 09:47:18.000000000,2016-02-19 12:06:49.000000000,2016-02-19 12:06:49.000000000,"[{'_account_id': 3}, {'_account_id': 1894}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 7872}, {'_account_id': 8290}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}]","[{'number': 1, 'created': '2015-12-09 09:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f61410e264ea133dbf29f6094ada3d9a13db0d00', 'message': 'add client_manager_class param to get_client_manager()\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugin for individual services\nout of tempest tree, this patch add client_manager_class param to\nget_client_manager(), so that tempest plugins in other repositories\ncan use the tempest base test class (BaseTestCase) with its own\nclient manager which has clients just for its test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}, {'number': 2, 'created': '2015-12-09 09:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c641c3961d9c64b4f4ebfcf88b820666b9079475', 'message': 'add client_manager_class param to BaseTestCase\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugins for individual services out\nof tempest tree, this patch add client_manager param to BaseTestCase,\nso that tempest plugins in other repositories can override client\nmanager class by its own client manager which has clients just for\nits test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}, {'number': 3, 'created': '2015-12-10 06:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f0e46d0cab867ad52a134d06e3376b8e3f586044', 'message': 'add client_manager_class param to BaseTestCase\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugins for individual services out\nof tempest tree, this patch add client_manager param to BaseTestCase,\nso that tempest plugins in other repositories can override client\nmanager class by its own client manager which has clients just for\nits test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}, {'number': 4, 'created': '2015-12-16 12:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/81faaec4eb84b071824b606cfc11e53ef76d6e03', 'message': 'add client_manager_class param to BaseTestCase\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugins for individual services out\nof tempest tree, this patch add client_manager param to BaseTestCase,\nso that tempest plugins in other repositories can override client\nmanager class by its own client manager which has clients just for\nits test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}, {'number': 5, 'created': '2016-01-08 07:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d50d769accd047fabc95b2c5ad8d8002a61bc343', 'message': 'add client_manager_class param to BaseTestCase\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugins for individual services out\nof tempest tree, this patch add client_manager param to BaseTestCase,\nso that tempest plugins in other repositories can override client\nmanager class by its own client manager which has clients just for\nits test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}, {'number': 6, 'created': '2016-01-13 05:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e4e57a31064a07998b6493ea8dcc43003ea14bc', 'message': 'add client_manager_class param to BaseTestCase\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugins for individual services out\nof tempest tree, this patch add client_manager param to BaseTestCase,\nso that tempest plugins in other repositories can override client\nmanager class by its own client manager which has clients just for\nits test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}, {'number': 7, 'created': '2016-01-15 07:13:55.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/60687e5e290a82737b1704fed32c584aeed31690', 'message': 'add client_manager_class param to BaseTestCase\n\nTempest base test case (BaseTestCase) gets client manager which\nhas many clients for OpenStack services.\n\nTo support development of tempest plugins for individual services out\nof tempest tree, this patch add client_manager param to BaseTestCase,\nso that tempest plugins in other repositories can override client\nmanager class by its own client manager which has clients just for\nits test cases.\n\nChange-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635\n'}]",0,255161,60687e5e290a82737b1704fed32c584aeed31690,41,13,7,1894,,,0,"add client_manager_class param to BaseTestCase

Tempest base test case (BaseTestCase) gets client manager which
has many clients for OpenStack services.

To support development of tempest plugins for individual services out
of tempest tree, this patch add client_manager param to BaseTestCase,
so that tempest plugins in other repositories can override client
manager class by its own client manager which has clients just for
its test cases.

Change-Id: Ifc29617743b76b01eb6cd30a375cf47b56e4f635
",git fetch https://review.opendev.org/openstack/tempest refs/changes/61/255161/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,f61410e264ea133dbf29f6094ada3d9a13db0d00,manager," force_new=None, client_manager_class=None): :param client_manager_class: optinal class to change client manager klass = client_manager_class or clients.Manager return klass(credentials=creds, service=cls._service)"," force_new=None): return clients.Manager(credentials=creds, service=cls._service)",4,2
openstack%2Fdevstack-gate~master~I7354f9957be2faec800d448473fdc743cb55a91e,openstack/devstack-gate,master,I7354f9957be2faec800d448473fdc743cb55a91e,Allow for git base override,MERGED,2015-01-28 23:16:29.000000000,2016-02-19 12:06:15.000000000,2016-02-19 12:06:15.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6854}, {'_account_id': 8344}]","[{'number': 1, 'created': '2015-01-28 23:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0b6f05740cda9c43f95d489e10863d14a194fd6f', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 2, 'created': '2015-02-04 22:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/078f97beec29969682521119195775aada460485', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 3, 'created': '2015-02-19 06:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/06afd09cb92ec5e6daed7f691608397cec387d6c', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 4, 'created': '2015-05-11 22:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5b231f55d1559c30a9591d4aa9e44135d513b179', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 5, 'created': '2015-06-08 08:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/448f76862c9b2af3385724469018dc9ad86f4e1f', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 6, 'created': '2015-06-30 11:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8a905da62b75579b42130c67d9e0d171871382ae', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 7, 'created': '2015-07-15 19:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0c12201c01f37193bc52800d8e5ea9d9854f5d75', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 8, 'created': '2015-07-30 04:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f8a4d9bee3d3906ecfbf7084a88ff2a10f4b9821', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}, {'number': 9, 'created': '2015-08-20 05:25:11.000000000', 'files': ['test-functions.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e4ca0a16b260334b1e50fc7b785e34e0366035da', 'message': 'Allow for git base override\n\nThis patch allows us to override a git base to repository of a project\nspecified by OVERRIDE_${PROJECT}_GIT_BASE.\nIf specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,\ndevstack-gate project will be accessed using https://github.com\nas git base.\n\nChange-Id: I7354f9957be2faec800d448473fdc743cb55a91e\n'}]",8,151034,e4ca0a16b260334b1e50fc7b785e34e0366035da,42,6,9,8344,,,0,"Allow for git base override

This patch allows us to override a git base to repository of a project
specified by OVERRIDE_${PROJECT}_GIT_BASE.
If specify OVERRIDE_DEVSTACK_GATE_GIT_BASE=https://github.com,
devstack-gate project will be accessed using https://github.com
as git base.

Change-Id: I7354f9957be2faec800d448473fdc743cb55a91e
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/34/151034/4 && git format-patch -1 --stdout FETCH_HEAD,"['test-functions.sh', 'functions.sh']",2,0b6f05740cda9c43f95d489e10863d14a194fd6f,override_git_base," local git_base=$3# If you would like to use a particular git base for a project other than # GIT_BASE or https://git.openstack.org, for example in order to use # a particular repositories for a third party CI, then supply that using # variable OVERRIDE_${PROJECT}_GIT_BASE instead. # (e.g. OVERRIDE_TEMPEST_GIT_BASE=http://foo.bar.com) # # allow for possible git_base override local project_git_base_var=""\$OVERRIDE_${uc_project}_GIT_BASE"" local project_git_base=`eval echo ${project_git_base_var}` if [[ ""$project_git_base"" != """" ]]; then git_base=$project_git_base fi echo ""Setting up $project @ $branch"" git_clone_and_cd $project $short_project $git_base git_remote_set_url origin $git_base/$project"," local git_base=${GIT_BASE:-https://git.openstack.org} echo ""Setting up $project @ $branch"" git_clone_and_cd $project $short_project git_remote_set_url origin $git_base/$project ",84,25
openstack%2Fpython-ironic-inspector-client~master~If1ff39139d5064e5152c926585189e44d22248b5,openstack/python-ironic-inspector-client,master,If1ff39139d5064e5152c926585189e44d22248b5,Updated from global requirements,MERGED,2016-02-17 02:08:26.000000000,2016-02-19 12:06:09.000000000,2016-02-19 12:06:09.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-17 02:08:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/e9f6b3e3b61ba08586f4fa93c6e9ec9ea9682094', 'message': 'Updated from global requirements\n\nChange-Id: If1ff39139d5064e5152c926585189e44d22248b5\n'}]",0,281003,e9f6b3e3b61ba08586f4fa93c6e9ec9ea9682094,12,4,1,11131,,,0,"Updated from global requirements

Change-Id: If1ff39139d5064e5152c926585189e44d22248b5
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/03/281003/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e9f6b3e3b61ba08586f4fa93c6e9ec9ea9682094,openstack/requirements,python-openstackclient>=2.1.0 # Apache-2.0,python-openstackclient>=2.0.0 # Apache-2.0,1,1
openstack%2Ftempest~master~Ida9a7143234aa4f41a72987d2b8d0d8d179041c5,openstack/tempest,master,Ida9a7143234aa4f41a72987d2b8d0d8d179041c5,Remove test test_create_delete_server_group_with_multiple_policies,MERGED,2016-02-16 10:00:42.000000000,2016-02-19 12:01:53.000000000,2016-02-19 12:01:53.000000000,"[{'_account_id': 3}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-02-16 10:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/04b10ca7fef03ee6eb5772b87dd292c435b59de3', 'message': 'Remove test test_create_delete_server_group_with_multiple_policies\n\nBug 1324348 has been resolved, and it prevented nova from accepting\nduplicated policies, so this test should be removed.\n\nAnd, the negative test cases for this has been added to nova project\nnova/tests/unit/api/openstack/compute/test_server_groups.py\ntest_create_server_group_with_duplicate_policies\ntest_create_server_group_conflicting_policies\n\nChange-Id: Ida9a7143234aa4f41a72987d2b8d0d8d179041c5\n'}, {'number': 2, 'created': '2016-02-16 11:27:59.000000000', 'files': ['tempest/api/compute/servers/test_server_group.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e5bef75290bf6bc32113a8478b19b02e3aa44e23', 'message': 'Remove test test_create_delete_server_group_with_multiple_policies\n\nBug 1324348 has been resolved, and it prevented nova from accepting\nduplicated policies, so this test should be removed.\n\nAnd, the negative test cases for this has been added to nova project\nnova/tests/unit/api/openstack/compute/test_server_groups.py\ntest_create_server_group_with_duplicate_policies\ntest_create_server_group_conflicting_policies\n\nChange-Id: Ida9a7143234aa4f41a72987d2b8d0d8d179041c5\n'}]",0,280580,e5bef75290bf6bc32113a8478b19b02e3aa44e23,21,4,2,16425,,,0,"Remove test test_create_delete_server_group_with_multiple_policies

Bug 1324348 has been resolved, and it prevented nova from accepting
duplicated policies, so this test should be removed.

And, the negative test cases for this has been added to nova project
nova/tests/unit/api/openstack/compute/test_server_groups.py
test_create_server_group_with_duplicate_policies
test_create_server_group_conflicting_policies

Change-Id: Ida9a7143234aa4f41a72987d2b8d0d8d179041c5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/80/280580/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_group.py'],1,04b10ca7fef03ee6eb5772b87dd292c435b59de3,bug/1324348,," @decorators.skip_because(bug=""1324348"") @test.idempotent_id('6d9bae05-eb32-425d-a673-e14e1b1c6306') def test_create_delete_server_group_with_multiple_policies(self): # Create and Delete the server-group with multiple policies policies = ['affinity', 'affinity'] self._create_delete_server_group(policies) ",0,7
openstack%2Fmurano~master~I49b8b90ab8db82033c5a45ee2bcbfbfb7fb77339,openstack/murano,master,I49b8b90ab8db82033c5a45ee2bcbfbfb7fb77339,Enable pep8 to check files in directory tools,MERGED,2016-02-18 11:10:08.000000000,2016-02-19 12:00:29.000000000,2016-02-19 12:00:29.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 8686}, {'_account_id': 12597}, {'_account_id': 13323}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-18 11:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8ee034ce414a1e66ff6f285b68e0838989a1d481', 'message': 'Enable pep8 to check files in directory tools\n\nThe directory tools is exculed for runing pep8 test now.\nEnable pep8 to check files in toos/ since there will be more python files.\n\nChange-Id: I49b8b90ab8db82033c5a45ee2bcbfbfb7fb77339\n'}, {'number': 2, 'created': '2016-02-18 11:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/30c92c7745466aa5ec748db594c5aad39b7a30f3', 'message': 'Enable pep8 to check files in directory tools\n\nThe directory tools is exculed for runing pep8 test now.\nEnable pep8 to check files in toos/ since there will be more python files.\n\nChange-Id: I49b8b90ab8db82033c5a45ee2bcbfbfb7fb77339\n'}, {'number': 3, 'created': '2016-02-19 02:30:55.000000000', 'files': ['tools/lintstack.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/e730821c6778683600aeb9f0968945b5310dd3fd', 'message': 'Enable pep8 to check files in directory tools\n\nThe directory tools is exculed for runing pep8 test now.\nEnable pep8 to check files in toos/ since there will be more python files.\n\nChange-Id: I49b8b90ab8db82033c5a45ee2bcbfbfb7fb77339\n'}]",4,281766,e730821c6778683600aeb9f0968945b5310dd3fd,23,8,3,8686,,,0,"Enable pep8 to check files in directory tools

The directory tools is exculed for runing pep8 test now.
Enable pep8 to check files in toos/ since there will be more python files.

Change-Id: I49b8b90ab8db82033c5a45ee2bcbfbfb7fb77339
",git fetch https://review.opendev.org/openstack/murano refs/changes/66/281766/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8ee034ce414a1e66ff6f285b68e0838989a1d481,enable_pep8,"exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg","exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,tools",1,1
openstack%2Fproject-config~master~I55dda882785e59f5816175a75b6cbb00d8105c1b,openstack/project-config,master,I55dda882785e59f5816175a75b6cbb00d8105c1b,Specify DEVSTACK_GATE_SETTINGS for Horizon i9n tests job,MERGED,2016-01-19 11:49:41.000000000,2016-02-19 11:53:39.000000000,2016-02-19 11:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8040}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-01-19 11:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3f65d27ada66a521c2da0009dac6be07e324b508', 'message': 'Source exports from horizon repo for horizon dsvm-job\n\nThis will allow Horizon team to manage packages in devstack\nenvironment independently from infra.\n\nChange-Id: I55dda882785e59f5816175a75b6cbb00d8105c1b\nDepends-On: Id9ab8e846c33921e1c55e459056345c8d14204fd\n'}, {'number': 2, 'created': '2016-02-12 10:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ba883d8261ed4120225b9c3b726a490e63278308', 'message': 'Source exports from horizon repo for horizon dsvm-job\n\nThis will allow Horizon team to manage packages in devstack\nenvironment independently from infra.\n\nChange-Id: I55dda882785e59f5816175a75b6cbb00d8105c1b\nDepends-On: Id9ab8e846c33921e1c55e459056345c8d14204fd\n'}, {'number': 3, 'created': '2016-02-19 10:12:29.000000000', 'files': ['jenkins/jobs/horizon.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ef156ba3fb39957e88451655c27df22b60b87214', 'message': 'Specify DEVSTACK_GATE_SETTINGS for Horizon i9n tests job\n\nThis will allow Horizon team to manage packages in devstack\nenvironment independently from infra. Since the absence of the file\nbeing specified in this variable is handled gracefully by\ndevstack-gate script (see https://review.openstack.org/#/c/190321), we\ncan export it first and then add the file being sourced later.\n\nChange-Id: I55dda882785e59f5816175a75b6cbb00d8105c1b\n'}]",1,269578,ef156ba3fb39957e88451655c27df22b60b87214,19,6,3,8040,,,0,"Specify DEVSTACK_GATE_SETTINGS for Horizon i9n tests job

This will allow Horizon team to manage packages in devstack
environment independently from infra. Since the absence of the file
being specified in this variable is handled gracefully by
devstack-gate script (see https://review.openstack.org/#/c/190321), we
can export it first and then add the file being sourced later.

Change-Id: I55dda882785e59f5816175a75b6cbb00d8105c1b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/78/269578/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/horizon.yaml'],1,3f65d27ada66a521c2da0009dac6be07e324b508,horizon-devstack-exports, source /opt/stack/new/horizon/tools/gate/devstack_exports.sh, export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=90 export DEVSTACK_GATE_TEMPEST=0 export DEVSTACK_GATE_EXERCISES=0 export DEVSTACK_GATE_INSTALL_TESTONLY=1 export DEVSTACK_GATE_NEUTRON=1,1,6
openstack%2Fproject-config~master~I95c41b20da33e6195ca9699cce3d3a2dc308cf82,openstack/project-config,master,I95c41b20da33e6195ca9699cce3d3a2dc308cf82,Add pypi publish jobs to RefStack,MERGED,2016-02-18 09:39:54.000000000,2016-02-19 11:53:04.000000000,2016-02-19 11:53:03.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10234}, {'_account_id': 11809}]","[{'number': 1, 'created': '2016-02-18 09:39:54.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a0aa37f5ef2d300cdd70722bd21ef3a53a8ac62d', 'message': 'Add pypi publish jobs to RefStack\n\nThis will allow us to publish RefStack releases to pypi. Releases\non pypi are planned to be used for the production RefStack site.\n\nChange-Id: I95c41b20da33e6195ca9699cce3d3a2dc308cf82\n'}]",0,281720,a0aa37f5ef2d300cdd70722bd21ef3a53a8ac62d,9,5,1,9626,,,0,"Add pypi publish jobs to RefStack

This will allow us to publish RefStack releases to pypi. Releases
on pypi are planned to be used for the production RefStack site.

Change-Id: I95c41b20da33e6195ca9699cce3d3a2dc308cf82
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/281720/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,a0aa37f5ef2d300cdd70722bd21ef3a53a8ac62d,add-pypi-jobs, - name: publish-to-pypi,,2,0
openstack%2Fproject-config~master~Iab2257e622591f936bf3d0619c29fa4c7b569bd6,openstack/project-config,master,Iab2257e622591f936bf3d0619c29fa4c7b569bd6,Recreate workspace in zuul-cloner cleanup,MERGED,2016-02-18 19:48:56.000000000,2016-02-19 11:52:17.000000000,2016-02-19 11:52:17.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-18 19:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/78ed4a9eb6578703723f33d15d12ae1efd8a7071', 'message': 'Recreate workspace in zuul-cloner cleanup\n\nIn cases where zuul-cloner is aborted during a git clone operation,\ngit will remove the git work tree in its cleanup.  The work tree\nin these jobs is the workspace directory, which means that subsequent\njenkins post-build actions can not run because the workspace has\nbeen removed.\n\nTo reduce the likelyhood of this having an impact, recreate the\nworkspace directory if needed during the cleanup trap.\n\nThis is still slightly racy (there may be a brief window where\nthere is no workspace), but nonetheless, this should work in most\ncircumstances.\n\nChange-Id: Iab2257e622591f936bf3d0619c29fa4c7b569bd6\n'}, {'number': 2, 'created': '2016-02-19 10:11:44.000000000', 'files': ['jenkins/jobs/macros.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2f3318f293cd285e8eb1d12500f25d1ddaa976d7', 'message': 'Recreate workspace in zuul-cloner cleanup\n\nIn cases where zuul-cloner is aborted during a git clone operation,\ngit will remove the git work tree in its cleanup.  The work tree\nin these jobs is the workspace directory, which means that subsequent\njenkins post-build actions can not run because the workspace has\nbeen removed.\n\nTo reduce the likelyhood of this having an impact, recreate the\nworkspace directory if needed during the cleanup trap.\n\nThis is still slightly racy (there may be a brief window where\nthere is no workspace), but nonetheless, this should work in most\ncircumstances.\n\nChange-Id: Iab2257e622591f936bf3d0619c29fa4c7b569bd6\n'}]",1,282034,2f3318f293cd285e8eb1d12500f25d1ddaa976d7,11,3,2,1,,,0,"Recreate workspace in zuul-cloner cleanup

In cases where zuul-cloner is aborted during a git clone operation,
git will remove the git work tree in its cleanup.  The work tree
in these jobs is the workspace directory, which means that subsequent
jenkins post-build actions can not run because the workspace has
been removed.

To reduce the likelyhood of this having an impact, recreate the
workspace directory if needed during the cleanup trap.

This is still slightly racy (there may be a brief window where
there is no workspace), but nonetheless, this should work in most
circumstances.

Change-Id: Iab2257e622591f936bf3d0619c29fa4c7b569bd6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/34/282034/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/macros.yaml'],1,78ed4a9eb6578703723f33d15d12ae1efd8a7071,282034, mkdir -p $WORKSPACE mkdir -p $WORKSPACE mkdir -p $WORKSPACE mkdir -p $WORKSPACE,,4,0
openstack%2Fproject-config~master~I1c027ee8aaf7be255e9f8b16c44764ffea399420,openstack/project-config,master,I1c027ee8aaf7be255e9f8b16c44764ffea399420,Initiate testing for puppet-openstack-cookiecutter,MERGED,2016-01-25 16:13:47.000000000,2016-02-19 11:51:24.000000000,2016-02-19 11:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8297}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-01-25 16:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1d146c66f2ebf520c7edac96f39df6d1055b234e', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 2, 'created': '2016-01-26 09:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ad9a9590c6f441d357a53b8363580bb3335b67c1', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 3, 'created': '2016-01-26 16:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/723dfdf8d15f3332ebae002d037519b12b7a6a72', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 4, 'created': '2016-01-26 16:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/33bc6435e2910659a8c0c43469ee0298691a2f74', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 5, 'created': '2016-01-26 16:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/60a87f34396ec6391d2d0865d0fad9d190bfb5ed', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 6, 'created': '2016-01-26 17:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/94bd2f5e856d0dcf73e8a524298f0c1048d990b7', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 7, 'created': '2016-01-26 20:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6c2776a1449d0712610105e7ba720b61069c052b', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 8, 'created': '2016-01-26 22:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/03d4df721f54cc5df11dd8b60ee8d15c8cbd46f1', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 9, 'created': '2016-01-26 23:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6c85be7a6a23380b1e8006cf3386dd8f595577b5', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 10, 'created': '2016-01-27 09:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/92e80fa09d632cef0fbdb207a922b0dd7f5ce39c', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 11, 'created': '2016-01-27 16:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/02657eacf9af4589d8bb083c9b4164a1b884536a', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 12, 'created': '2016-02-03 18:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3c07b24392f4aa4fe8f8e86eebeea98cab4d82cf', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 13, 'created': '2016-02-04 16:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2593a76822496e3a80f5e49d866fbbdad3d2f2bc', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 14, 'created': '2016-02-18 16:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/adf4ce7aa7f107fa0de793bfc0d67ad2acde4b01', 'message': 'puppet: initiate testing for puppet-openstack-cookicutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}, {'number': 15, 'created': '2016-02-18 18:33:49.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/puppet-module-jobs.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/195e44aebc599d47849de7c69ff89f3bb39db341', 'message': 'Initiate testing for puppet-openstack-cookiecutter\n\nPuppet OpenStack group has a cookiecutter template[1] and associated\nmsync[2] configuration that is used as a starter kit for new module.\n\nThis code checks that the cookiecutter/msync resulting puppet module is\nvalid.\n\n[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/\n[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/\n\nChange-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420\n'}]",22,272156,195e44aebc599d47849de7c69ff89f3bb39db341,51,6,15,8297,,,0,"Initiate testing for puppet-openstack-cookiecutter

Puppet OpenStack group has a cookiecutter template[1] and associated
msync[2] configuration that is used as a starter kit for new module.

This code checks that the cookiecutter/msync resulting puppet module is
valid.

[1]: https://git.openstack.org/cgit/openstack/puppet-openstack-cookiecutter/
[2]: https://git.openstack.org/cgit/openstack/puppet-modulesync-configs/

Change-Id: I1c027ee8aaf7be255e9f8b16c44764ffea399420
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/272156/11 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'jenkins/jobs/puppet-module-jobs.yaml', 'zuul/layout.yaml']",3,1d146c66f2ebf520c7edac96f39df6d1055b234e,puppet/puppet-openstack-cookiecutter," - name: puppet-openstack-modulesync-cookiecutter-jobs check: - gate-puppet-openstack-modulesync-cookiecutter # The job is still experimental and might change later, we don't want it voting now. - name: ^gate-puppet-openstack-modulesync-cookiecutter$ voting: false - name: puppet-openstack-modulesync-cookiecutter-jobs", - name: noop-jobs,45,1
openstack%2Frally~master~I2c72f20695e35e05435d2526d4a804196c2ab2d3,openstack/rally,master,I2c72f20695e35e05435d2526d4a804196c2ab2d3,Use new-style Python classes,MERGED,2016-01-14 01:44:54.000000000,2016-02-19 11:46:55.000000000,2016-02-19 11:46:55.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 11208}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 15482}, {'_account_id': 18785}]","[{'number': 1, 'created': '2016-01-14 01:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fe8d94c4b46b4b45b6823cc37a358742412febad', 'message': 'Use new-style Python classes\n\nThere are some classes in the code do not inherit from anything\nand thus will be an old-style class by default. New style class\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 2, 'created': '2016-01-14 01:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab706b7289b1d2ff61e0794635edac3e724c939d', 'message': 'Use new-style Python classes\n\nThere are some classes in the code do not inherit from anything\nand thus will be an old-style class by default. New style class\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 3, 'created': '2016-01-27 01:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0b269e82666e14f90f465ede43da720e1ecbcfba', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that didn\'t inherited from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 4, 'created': '2016-01-28 00:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/82840fd37876dfb1aaca87e6d50359818f1f5e36', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that didn\'t inherited from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 5, 'created': '2016-02-02 01:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4f606da63e39557f246000b8b36cf83819d0bca8', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that didn\'t inherited from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 6, 'created': '2016-02-02 02:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9b9590736b12d7b1a8421f1269ddd059558a0cf7', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that didn\'t inherited from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 7, 'created': '2016-02-02 02:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e4427b2efa4e3719f4b8a19caf51a976e5c0fe8d', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that didn\'t inherited from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 8, 'created': '2016-02-02 03:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bab3511b54d9236847c21e5b59eeced8c2811972', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that nherit from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}, {'number': 9, 'created': '2016-02-19 08:51:07.000000000', 'files': ['tests/hacking/checks.py', 'tests/unit/plugins/openstack/scenarios/nova/test_security_group.py', 'tests/unit/common/test_utils.py', 'tests/unit/test_hacking.py', 'tests/unit/task/test_utils.py', 'tests/hacking/README.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/2db0da8278d18289d69eef26aa6684cdc29df9aa', 'message': 'Use new-style Python classes\n\nThere are some classes in the code that didn\'t inherited from\nnothing and this is an old-style classes. A ""New Class"" is the\nrecommended way to create a class in modern Python.A ""New Class""\nshould always inherit from `object` or another new-style class.\n\nHacking rule added as well.\n\nChange-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3\n'}]",19,267266,2db0da8278d18289d69eef26aa6684cdc29df9aa,63,12,9,6116,,,0,"Use new-style Python classes

There are some classes in the code that didn't inherited from
nothing and this is an old-style classes. A ""New Class"" is the
recommended way to create a class in modern Python.A ""New Class""
should always inherit from `object` or another new-style class.

Hacking rule added as well.

Change-Id: I2c72f20695e35e05435d2526d4a804196c2ab2d3
",git fetch https://review.opendev.org/openstack/rally refs/changes/66/267266/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/hacking/checks.py', 'tests/unit/plugins/openstack/scenarios/nova/test_security_group.py', 'tests/unit/common/test_utils.py', 'tests/unit/test_hacking.py', 'tests/unit/task/test_utils.py', 'tests/hacking/README.rst']",6,fe8d94c4b46b4b45b6823cc37a358742412febad,new_class,* [N356] - Use new-style Python classes,,29,4
openstack%2Fheat~master~I905514bbbc02f54ce69a7fab9e89a49cb138f29a,openstack/heat,master,I905514bbbc02f54ce69a7fab9e89a49cb138f29a,Convergence: Check resource class before updating,MERGED,2015-11-23 12:50:44.000000000,2016-02-19 11:32:16.000000000,2016-02-19 11:32:16.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 7385}, {'_account_id': 8833}, {'_account_id': 10487}, {'_account_id': 11424}, {'_account_id': 12259}, {'_account_id': 12404}]","[{'number': 1, 'created': '2015-11-23 12:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/14dacc323ee7cd439be721eefd73df17c292a6b6', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\n""}, {'number': 2, 'created': '2015-11-23 15:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a43a7f42ef20951e7128b733ce9009b7191c3fc', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\n""}, {'number': 3, 'created': '2015-11-23 15:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b1522170d050589e7b30b92c372a02ec03dca6c7', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\n""}, {'number': 4, 'created': '2015-11-24 07:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/651ddad262c4e2aeacf773a3d7b97faa0f12f624', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\n""}, {'number': 5, 'created': '2015-11-24 07:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e1b38e7f8b9c3406782f58298156b30f706123b', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\n""}, {'number': 6, 'created': '2015-11-24 10:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2308600c56da3e86de9084d7cbf82724469300d3', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\n""}, {'number': 7, 'created': '2015-11-25 07:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/94b1c281309f055be3349f37001e0c44fb3bb9a4', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 8, 'created': '2015-11-25 09:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e91996225289cb92749648233b53866b20e9d87', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 9, 'created': '2015-11-25 18:05:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/49d42f6123333389f28741aba7c6b1c1f89ebc84', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 10, 'created': '2015-11-26 09:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e7639639dcdfb28d8e7bdfa2af033da5f0a1719', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 11, 'created': '2015-11-27 11:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d78371498f9daebf819ce803a9190226b47c0664', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 12, 'created': '2015-12-21 05:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6f99baa61f46b53f58a8bce992ce5c96f3d26e69', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 13, 'created': '2015-12-21 09:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b644740ebf4ff5a4834688d4e8fae1e1c414b2f0', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 14, 'created': '2015-12-22 06:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/16b8ccdb53d5f98483d317a906cca73869e75e4e', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 15, 'created': '2016-01-21 16:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f07755d1909ef972a0f11d912a615830f0fd91d5', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 16, 'created': '2016-02-02 13:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b6641122ca654ece642aca1d7540693c486ebea', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 17, 'created': '2016-02-15 13:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/65ee1f0da9f1e3008e83a27cd591de184084b7b8', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}, {'number': 18, 'created': '2016-02-17 11:40:39.000000000', 'files': ['heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4ace6a3e06aa873629003706951f29dd4ffcf337', 'message': ""Convergence: Check resource class before updating\n\nCheck the resource class and raise UpdateReplace if the class of new and\nold doesn't match.\n\nChange-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a\nPartial-Bug: #1512343\nCloses-Bug: #1513233\n""}]",14,248676,4ace6a3e06aa873629003706951f29dd4ffcf337,84,10,18,12259,,,0,"Convergence: Check resource class before updating

Check the resource class and raise UpdateReplace if the class of new and
old doesn't match.

Change-Id: I905514bbbc02f54ce69a7fab9e89a49cb138f29a
Partial-Bug: #1512343
Closes-Bug: #1513233
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/248676/6 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resource.py'],1,14dacc323ee7cd439be721eefd73df17c292a6b6,bp/stack-update-restrict," resource.stack = curr_stack # new_temp = template.Template.load(self.context, template_id) new_res_def = new_stack.t.resource_definitions(new_stack)[self.name] new_res = Resource(self.name, new_res_def, new_stack) if self.resource_class() is not new_res.resource_class(): raise exception.UpdateReplace(self.name) "," new_temp = template.Template.load(self.context, template_id) new_res_def = new_temp.resource_definitions(new_stack)[self.name]",8,2
openstack%2Ftripleo-heat-templates~master~Idf33d87e08355b5b4369ccb0001db8d4c3b4c20f,openstack/tripleo-heat-templates,master,Idf33d87e08355b5b4369ccb0001db8d4c3b4c20f,Use the class param to configure Cinder 'host' setting,MERGED,2016-02-18 13:41:11.000000000,2016-02-19 11:29:45.000000000,2016-02-19 11:29:45.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-02-18 13:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/33df1cc0a8bf4a0aba08a8624c8d4cb0518eb108', 'message': ""Use the class param to configure Cinder 'host' setting\n\nBy configuring the Cinder 'host' setting via the appropriate class\nparam instead of cinder_config we don't risk to override it if the\nuser is to pass additional config settings using cinder_config in\nExtraConfig.\n\nChange-Id: Idf33d87e08355b5b4369ccb0001db8d4c3b4c20f\n""}, {'number': 2, 'created': '2016-02-18 13:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/187655345b5e5cf64a26df063ce530b8be7f1e3d', 'message': ""Use the class param to configure Cinder 'host' setting\n\nBy configuring the Cinder 'host' setting via the appropriate class\nparam instead of cinder_config we don't risk to override it if the\nuser is to pass additional config settings using cinder_config in\nExtraConfig.\n\nDepends-On: Iaf5315a0d6532f3166b9a07fc61f41c6b0b15cc2\nChange-Id: Idf33d87e08355b5b4369ccb0001db8d4c3b4c20f\n""}, {'number': 3, 'created': '2016-02-19 09:14:51.000000000', 'files': ['puppet/hieradata/controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3ac244adda7618a0003f0c58ccbba7e3a1ba5f12', 'message': ""Use the class param to configure Cinder 'host' setting\n\nBy configuring the Cinder 'host' setting via the appropriate class\nparam instead of cinder_config we don't risk to override it if the\nuser is to pass additional config settings using cinder_config in\nExtraConfig.\n\nChange-Id: Idf33d87e08355b5b4369ccb0001db8d4c3b4c20f\n""}]",2,281858,3ac244adda7618a0003f0c58ccbba7e3a1ba5f12,23,6,3,6796,,,0,"Use the class param to configure Cinder 'host' setting

By configuring the Cinder 'host' setting via the appropriate class
param instead of cinder_config we don't risk to override it if the
user is to pass additional config settings using cinder_config in
ExtraConfig.

Change-Id: Idf33d87e08355b5b4369ccb0001db8d4c3b4c20f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/281858/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/hieradata/controller.yaml'],1,33df1cc0a8bf4a0aba08a8624c8d4cb0518eb108,cinder_multibackend,cinder::host: hostgroup,cinder::config::cinder_config: DEFAULT/host: value: hostgroup,1,3
openstack%2Fdevstack~master~I47f5e710ebd87b0f54549732e7d64cf42c7a6b65,openstack/devstack,master,I47f5e710ebd87b0f54549732e7d64cf42c7a6b65,Always strip package comments,MERGED,2016-02-19 03:40:54.000000000,2016-02-19 11:20:55.000000000,2016-02-19 11:20:55.000000000,"[{'_account_id': 3}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-19 03:40:54.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1ff75ff87fc2a46d1f88918d94be48e5d59e3aab', 'message': 'Always strip package comments\n\nIn the ""I can\'t believe I missed this"" category -- the existing strip\nmethod removes shortest match (%); which fails when you put another #\nin the comment (like ""refer to bug#1234"").  Change to the longest\nmatch which should strip everything from the first ""#"" to the end\n(since that\'s going to be the longest).\n\nChange-Id: I47f5e710ebd87b0f54549732e7d64cf42c7a6b65\n'}]",0,282155,1ff75ff87fc2a46d1f88918d94be48e5d59e3aab,9,2,1,7118,,,0,"Always strip package comments

In the ""I can't believe I missed this"" category -- the existing strip
method removes shortest match (%); which fails when you put another #
in the comment (like ""refer to bug#1234"").  Change to the longest
match which should strip everything from the first ""#"" to the end
(since that's going to be the longest).

Change-Id: I47f5e710ebd87b0f54549732e7d64cf42c7a6b65
",git fetch https://review.opendev.org/openstack/devstack refs/changes/55/282155/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,1ff75ff87fc2a46d1f88918d94be48e5d59e3aab,bug/1234, # Assume we want this package; free-form # comments allowed after a # package=${line%%#*}, # Assume we want this package package=${line%#*},3,2
openstack%2Fcongress~master~I6d727259ae764ce452f503ca1be8c753661af624,openstack/congress,master,I6d727259ae764ce452f503ca1be8c753661af624,WIP: jenkins job devstack test,ABANDONED,2016-02-09 08:57:56.000000000,2016-02-19 11:20:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-09 08:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/b7aa242997cea089a14da04c1fdb1fd16926f657', 'message': 'WIP: jenkins job devstack test\n\nChange-Id: I6d727259ae764ce452f503ca1be8c753661af624\n'}, {'number': 2, 'created': '2016-02-09 09:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/bb4abb3e1dc0b2929ee11aa36ec2a04da85d6784', 'message': 'WIP: jenkins job devstack test\n\nChange-Id: I6d727259ae764ce452f503ca1be8c753661af624\n'}, {'number': 3, 'created': '2016-02-09 09:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/059664914c258d86fa9ff1c63ff556db5ab4809d', 'message': 'WIP: jenkins job devstack test\n\nChange-Id: I6d727259ae764ce452f503ca1be8c753661af624\n'}, {'number': 4, 'created': '2016-02-09 10:16:52.000000000', 'files': ['devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/congress/commit/b44bf8a2d18432d83385b3eb5f2c343ec223e855', 'message': 'WIP: jenkins job devstack test\n\nChange-Id: I6d727259ae764ce452f503ca1be8c753661af624\n'}]",0,277739,b44bf8a2d18432d83385b3eb5f2c343ec223e855,9,1,4,8878,,,0,"WIP: jenkins job devstack test

Change-Id: I6d727259ae764ce452f503ca1be8c753661af624
",git fetch https://review.opendev.org/openstack/congress refs/changes/39/277739/4 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,b7aa242997cea089a14da04c1fdb1fd16926f657,enable-devstack-switch-arch,# CONGRESS_DISTRIBUTED_ARCHITECTURE=${CONGRESS_DISTRIBUTED_ARCHITECTURE:-False},CONGRESS_DISTRIBUTED_ARCHITECTURE=${CONGRESS_DISTRIBUTED_ARCHITECTURE:-False},1,1
openstack%2Fproject-config~master~I3a58144426ff4e904c316210b647379b1ba7305d,openstack/project-config,master,I3a58144426ff4e904c316210b647379b1ba7305d,Common template for Centos & Fedora devstack jobs,MERGED,2016-02-19 00:48:50.000000000,2016-02-19 11:20:14.000000000,2016-02-19 11:20:14.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-19 00:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6c16f9ee6903e1d667ec1bd1f722a330d1f74ef8', 'message': 'Template out Centos & Fedora jobs\n\nConsolidate these jobs in a single ""platform"" template that is pretty\ngeneric but allows us to specify the node to run on.\n\nI wasn\'t sure about ""platform"" -- I also considered something like\n""altnode"" or just ""node"" to differenitate it from the main jobs.\n""Platform"" seems to make it clear it\'s a different environment\n\nTo maintain the status-quo of running serial smoke-tests on centos7\nI have added an argument for that (working on getting rid of that\nrequirement).\n\nWe\'ve got ""-nv"" suffix now, so remove the non-voting regexes.\n\nThis also restores Fedora 23 to non-voting gate check for devstack --\nall our blocking issues with that are worked out and the nodes are\navailable in multiple providers.\n\nChange-Id: I3a58144426ff4e904c316210b647379b1ba7305d\n'}, {'number': 2, 'created': '2016-02-19 00:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4d43efcaade251393c9b3f55de234bccb6e65caa', 'message': 'Common template for Centos & Fedora devstack jobs\n\nConsolidate these jobs in a single ""platform"" template that is pretty\ngeneric but allows us to specify the node to run on (might be useful\nto other nodes in near future, such as next Ubuntu LTS and Debian).\n\nI wasn\'t sure about ""platform"" -- I also considered something like\n""altnode"" or just ""node"" to differenitate it from the main jobs.\n""Platform"" seems to make it clear it\'s a different environment\n\nTo maintain the status-quo of running serial smoke-tests on centos7\nI have added an argument for that (working on getting rid of that\nrequirement).\n\nWe\'ve got ""-nv"" suffix now, so remove the non-voting regexes.\n\nThis also restores Fedora 23 to non-voting gate check for devstack --\nall our blocking issues with that are worked out and the nodes are\navailable in multiple providers.\n\nChange-Id: I3a58144426ff4e904c316210b647379b1ba7305d\n'}, {'number': 3, 'created': '2016-02-19 02:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2801c22c7112ba7c7e97af824db090a8df042707', 'message': 'Common template for Centos & Fedora devstack jobs\n\nConsolidate these jobs in a single ""platform"" template that is pretty\ngeneric but allows us to specify the node to run on (might be useful\nto other nodes in near future, such as next Ubuntu LTS and Debian).\n\nI wasn\'t sure about ""platform"" -- I also considered something like\n""altnode"" or just ""node"" to differenitate it from the main jobs.\n""Platform"" seems to make it clear it\'s a different environment\n\nTo maintain the status-quo of running serial smoke-tests on centos7\nI have added an argument for that (working on getting rid of that\nrequirement).\n\nWe\'ve got ""-nv"" suffix now, so remove the non-voting regexes.\n\nThis also restores Fedora 23 to non-voting gate check for devstack --\nall our blocking issues with that are worked out and the nodes are\navailable in multiple providers.\n\nChange-Id: I3a58144426ff4e904c316210b647379b1ba7305d\n'}, {'number': 4, 'created': '2016-02-19 04:50:22.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0186ac369b126353c4008e2de0abd6a0b9b64ec1', 'message': 'Common template for Centos & Fedora devstack jobs\n\nConsolidate these jobs in a single ""platform"" template that is pretty\ngeneric but allows us to specify the node to run on (might be useful\nto other nodes in near future, such as next Ubuntu LTS and Debian).\n\nI wasn\'t sure about ""platform"" -- I also considered something like\n""altnode"" or just ""node"" to differenitate it from the main jobs.\n""Platform"" seems to make it clear it\'s a different environment\n\nTo maintain the status-quo of running serial smoke-tests on centos7\nI have added an argument for that (working on getting rid of that\nrequirement).\n\nWe\'ve got ""-nv"" suffix now, so remove the non-voting regexes.\n\nThis also restores Fedora 23 to non-voting gate check for devstack --\nall our blocking issues with that are worked out and the nodes are\navailable in multiple providers.\n\nChange-Id: I3a58144426ff4e904c316210b647379b1ba7305d\n'}]",0,282117,0186ac369b126353c4008e2de0abd6a0b9b64ec1,11,3,4,7118,,,0,"Common template for Centos & Fedora devstack jobs

Consolidate these jobs in a single ""platform"" template that is pretty
generic but allows us to specify the node to run on (might be useful
to other nodes in near future, such as next Ubuntu LTS and Debian).

I wasn't sure about ""platform"" -- I also considered something like
""altnode"" or just ""node"" to differenitate it from the main jobs.
""Platform"" seems to make it clear it's a different environment

To maintain the status-quo of running serial smoke-tests on centos7
I have added an argument for that (working on getting rid of that
requirement).

We've got ""-nv"" suffix now, so remove the non-voting regexes.

This also restores Fedora 23 to non-voting gate check for devstack --
all our blocking issues with that are worked out and the nodes are
available in multiple providers.

Change-Id: I3a58144426ff4e904c316210b647379b1ba7305d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/17/282117/4 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",3,6c16f9ee6903e1d667ec1bd1f722a330d1f74ef8,f23-gate,"# ""platform"" test -- run on an alternative node - job-template: name: '{pipeline}-tempest-dsvm-platform-{name}{job-suffix}' export DEVSTACK_GATE_SMOKE_SERIAL={run-smoke-serially}"," - job-template: name: '{pipeline}-tempest-dsvm-f{fedora-release}' cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job: name: 'gate-tempest-dsvm-centos7' node: 'devstack-centos7' wrappers: - build-timeout: timeout: 130 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_SMOKE_SERIAL=1",15,38
openstack%2Ffuel-library~stable%2F8.0~Id28d6c94abe5d96452f7ecba2b3fe022f40afa0d,openstack/fuel-library,stable/8.0,Id28d6c94abe5d96452f7ecba2b3fe022f40afa0d,On neighbor promotion do nothing if we are already clustered,ABANDONED,2016-02-16 17:18:19.000000000,2016-02-19 11:19:45.000000000,,"[{'_account_id': 3}, {'_account_id': 7109}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-02-16 17:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3e7845f8e0e09b6fb1f7330ac53c47e65c2768ca', 'message': 'Do not check cluster health if master is not elected\n\nDoing otherwise causes node to restart when get_monitor is called\nwithin action_promote - it does not find a master and assumes that\nit is running out of cluster.\n\nAlso, code is refactored a little bit - a new function returning\ncurrent master is created and is used in the changed code.\n\n-------------------\n\nOn neighbor promotion do nothing if we are already clustered\n\n + extracted function checking if we are in the same cluster with\n   given node\n\n + made post-promote ignore promotion of self. Previously it was\n   done inside jjj_join, but now we need to do that before the\n   new check.\n\n + now we write ""post-promote end"" log entry at the very\n   end of post-promote, not somewhere in the middle.\n\nChange-Id: Id28d6c94abe5d96452f7ecba2b3fe022f40afa0d\n'}, {'number': 2, 'created': '2016-02-16 17:19:31.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c7e13e7823fea0417d45771800b60d63acf0e432', 'message': 'On neighbor promotion do nothing if we are already clustered\n\n + extracted function checking if we are in the same cluster with\n   given node\n\n + made post-promote ignore promotion of self. Previously it was\n   done inside jjj_join, but now we need to do that before the\n   new check.\n\n + now we write ""post-promote end"" log entry at the very\n   end of post-promote, not somewhere in the middle.\n\n-----------------------------------------------------------------\n\nDo not check cluster health if master is not elected\n\nDoing otherwise causes node to restart when get_monitor is called\nwithin action_promote - it does not find a master and assumes that\nit is running out of cluster.\n\nAlso, code is refactored a little bit - a new function returning\ncurrent master is created and is used in the changed code.\n\nChange-Id: Id28d6c94abe5d96452f7ecba2b3fe022f40afa0d\n'}]",0,280831,c7e13e7823fea0417d45771800b60d63acf0e432,18,3,2,7109,,,0,"On neighbor promotion do nothing if we are already clustered

 + extracted function checking if we are in the same cluster with
   given node

 + made post-promote ignore promotion of self. Previously it was
   done inside jjj_join, but now we need to do that before the
   new check.

 + now we write ""post-promote end"" log entry at the very
   end of post-promote, not somewhere in the middle.

-----------------------------------------------------------------

Do not check cluster health if master is not elected

Doing otherwise causes node to restart when get_monitor is called
within action_promote - it does not find a master and assumes that
it is running out of cluster.

Also, code is refactored a little bit - a new function returning
current master is created and is used in the changed code.

Change-Id: Id28d6c94abe5d96452f7ecba2b3fe022f40afa0d
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/31/280831/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,3e7845f8e0e09b6fb1f7330ac53c47e65c2768ca,,"# Get current master. If a parameter is provided, # do not check node with that name get_master_name_but() { local node for node in $(get_alive_pacemaker_nodes_but ""$@"") do ocf_log info ""${LH} looking if $node is master"" if is_master $node; then ocf_log info ""${LH} master is $node"" echo $node break fi done } # Returns 0 if we are clustered with provideded node is_clustered_with() { get_running_nodes | grep -q $(rabbit_node_name $1); return $? } if is_clustered_with $nodename; then ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" else local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -z ""$master_name"" ]; then ocf_log info ""${LH} no master is elected currently. Skipping cluster health check."" elif is_clustered_with $master_name; then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" # Rabbit is running but is not connected to master # Failing to avoid split brain ocf_log err ""${LH} rabbit node is running out of the cluster"" rc=$OCF_ERR_GENERIC fi if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -n ""$master_name"" ]; then ocf_log info ""${LH} master exists and rabbit app is not running. Exiting to be restarted by pacemaker"" rc=$OCF_ERR_GENERIC fi fi if [ $rc -eq $OCF_ERR_GENERIC ]; then rc=$OCF_SUCCESS ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" elif my_host ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} ignoring post-promote of self"" elif is_clustered_with ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} we are already clustered with master - ${OCF_RESKEY_CRM_meta_notify_promote_uname}. Nothing to do."" else # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ""${OCF_RESKEY_CRM_meta_notify_promote_uname}"" rc=$? if [ $rc -eq $OCF_ERR_GENERIC ] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" fi return $rc"," if get_running_nodes | grep -q $(rabbit_node_name $nodename) then local rc_check=$OCF_SUCCESS ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" rc_check=$OCF_SUCCESS rc_check=$OCF_ERR_GENERIC nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do ocf_log info ""${LH} rabbit app is running. looking for master on $node"" is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then ocf_log info ""${LH} rabbit app is running. master is $node"" if get_running_nodes | grep -q $(rabbit_node_name $node) then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" rc_check=$OCF_SUCCESS break fi fi done [ $rc_check -eq $OCF_ERR_GENERIC ] && ocf_log err ""${LH} rabbit node is running out of the cluster"" if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then nodelist=$(get_alive_pacemaker_nodes_but $THIS_PCMK_NODE) rc_check=$OCF_SUCCESS for node in $nodelist do is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc_check=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is not running. master is $node. exiting to be restarted by pacemaker"" break fi done fi if [ $rc -eq $OCF_ERR_GENERIC -o $rc_check -eq $OCF_ERR_GENERIC ]; then ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" ocf_log info ""${LH} post-promote end."" return $OCF_SUCCESS # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ""${OCF_RESKEY_CRM_meta_notify_promote_uname}"" rc=$? if [ $rc -eq $OCF_ERR_GENERIC ] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" return $OCF_ERR_GENERIC fi",77,55
openstack%2Fironic~master~I56bd522f37403df103e7c782a5b4e7e2e2063305,openstack/ironic,master,I56bd522f37403df103e7c782a5b4e7e2e2063305,DO NOT MERGE - testing Futurist under extreme conditions,ABANDONED,2016-02-17 16:12:47.000000000,2016-02-19 11:17:43.000000000,,"[{'_account_id': 3}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-02-17 16:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6d711691c220f97f3b0de086f71cd488496aa7cb', 'message': 'DO NOT MERGE - testing Futurist under extreme conditions\n\nChange-Id: I56bd522f37403df103e7c782a5b4e7e2e2063305\nDepends-On: I8e45ddf7c87cf130028fc9fe937691968db17ee9\n'}, {'number': 2, 'created': '2016-02-17 19:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c0869aef7bbfe23f3870bd069623ccd6debc251d', 'message': 'DO NOT MERGE - testing Futurist under extreme conditions\n\nChange-Id: I56bd522f37403df103e7c782a5b4e7e2e2063305\nDepends-On: Ide835b6e5fd15171b9bebc7ca112b84423b39fab\nDepends-On: I8e45ddf7c87cf130028fc9fe937691968db17ee9\n'}, {'number': 3, 'created': '2016-02-18 10:01:55.000000000', 'files': ['ironic/conductor/base_manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b4242bb8a1d493369b8404661b720fe2b51b9d57', 'message': 'DO NOT MERGE - testing Futurist under extreme conditions\n\nChange-Id: I56bd522f37403df103e7c782a5b4e7e2e2063305\nDepends-On: I8e45ddf7c87cf130028fc9fe937691968db17ee9\n'}]",0,281362,b4242bb8a1d493369b8404661b720fe2b51b9d57,9,2,3,10239,,,0,"DO NOT MERGE - testing Futurist under extreme conditions

Change-Id: I56bd522f37403df103e7c782a5b4e7e2e2063305
Depends-On: I8e45ddf7c87cf130028fc9fe937691968db17ee9
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/281362/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/conductor/base_manager.py'],1,6d711691c220f97f3b0de086f71cd488496aa7cb,bp/futurist/test," default=3,"," default=100,",1,1
openstack%2Fopenstack-ansible~liberty~I047b2d1178de43c694c30280f6ed9fe8511341fd,openstack/openstack-ansible,liberty,I047b2d1178de43c694c30280f6ed9fe8511341fd,Move swift memcache conf into separate file,MERGED,2016-02-17 13:26:26.000000000,2016-02-19 11:17:18.000000000,2016-02-19 11:17:18.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}]","[{'number': 1, 'created': '2016-02-17 13:26:26.000000000', 'files': ['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_swift/tasks/swift_post_install.yml', 'playbooks/roles/os_swift/templates/proxy-server.conf.j2', 'playbooks/roles/os_swift/templates/swift-memcache.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7264009440a001d4f5db1ad3fd51316689d54771', 'message': 'Move swift memcache conf into separate file\n\nThe memcache configuration was only setup for the proxy-server.conf\nwithin Swift, and was not set for the object and container reconcilers\nwhich both use memcache.\n\nThis patch moves the memcache settings into a separate memcache.conf\nfile which is then configured on all swift hosts, removing the specific\nconf from the proxy-server.conf file.\n\nChange-Id: I047b2d1178de43c694c30280f6ed9fe8511341fd\nCloses-Bug: #1542121\n(cherry picked from commit 140f3772e5078052c5903e3da6b0d79c2f466461)\n'}]",0,281268,7264009440a001d4f5db1ad3fd51316689d54771,7,3,1,2799,,,0,"Move swift memcache conf into separate file

The memcache configuration was only setup for the proxy-server.conf
within Swift, and was not set for the object and container reconcilers
which both use memcache.

This patch moves the memcache settings into a separate memcache.conf
file which is then configured on all swift hosts, removing the specific
conf from the proxy-server.conf file.

Change-Id: I047b2d1178de43c694c30280f6ed9fe8511341fd
Closes-Bug: #1542121
(cherry picked from commit 140f3772e5078052c5903e3da6b0d79c2f466461)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/68/281268/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_swift/tasks/swift_post_install.yml', 'playbooks/roles/os_swift/templates/proxy-server.conf.j2', 'playbooks/roles/os_swift/templates/swift-memcache.conf.j2']",4,7264009440a001d4f5db1ad3fd51316689d54771,bug/1542121,"[memcache] # You can use this single conf file instead of having memcache_servers set in # several other conf files under [filter:cache] for example. You can specify # multiple servers separated with commas, as in: 10.1.2.3:11211,10.1.2.4:11211 # (IPv6 addresses must follow rfc3986 section-3.2.2, i.e. [::1]:11211) # memcache_servers = 127.0.0.1:11211 memcache_servers = {{ memcached_servers }} # # Sets how memcache values are serialized and deserialized: # 0 = older, insecure pickle serialization # 1 = json serialization but pickles can still be read (still insecure) # 2 = json serialization only (secure and the default) # To avoid an instant full cache flush, existing installations should # upgrade with 0, then set to 1 and reload, then after some time (24 hours) # set to 2 and reload. # In the future, the ability to use pickle serialization will be removed. # memcache_serialization_support = 2 memcache_serialization_support = 2 # # Sets the maximum number of connections to each memcached server per worker # memcache_max_connections = 2 # # Timeout for connection # connect_timeout = 0.3 # Timeout for pooled connection # pool_timeout = 1.0 # number of servers to retry on failures getting a pooled connection # tries = 3 # Timeout for read and writes # io_timeout = 2.0 ",,35,2
openstack%2Fopenstack-ansible~master~I1f795e65f9e68f053251ef2d2ce802233ff4cf33,openstack/openstack-ansible,master,I1f795e65f9e68f053251ef2d2ce802233ff4cf33,AIO: Fix typo in bootstrap-host,MERGED,2016-02-17 12:27:36.000000000,2016-02-19 11:17:02.000000000,2016-02-19 11:17:01.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}]","[{'number': 1, 'created': '2016-02-17 12:27:36.000000000', 'files': ['tests/roles/bootstrap-host/tasks/prepare_loopback_swift.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/62f0afc631f969207c5d762fd5f6948fcdf28b28', 'message': 'AIO: Fix typo in bootstrap-host\n\nUse bootstrap_host_loopback_swift_size instead of\nbootstrap_host_loopback_cinder_size in ""Create sparse Swift files"".\n\nChange-Id: I1f795e65f9e68f053251ef2d2ce802233ff4cf33\n'}]",0,281231,62f0afc631f969207c5d762fd5f6948fcdf28b28,11,3,1,14355,,,0,"AIO: Fix typo in bootstrap-host

Use bootstrap_host_loopback_swift_size instead of
bootstrap_host_loopback_cinder_size in ""Create sparse Swift files"".

Change-Id: I1f795e65f9e68f053251ef2d2ce802233ff4cf33
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/31/281231/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/tasks/prepare_loopback_swift.yml'],1,62f0afc631f969207c5d762fd5f6948fcdf28b28,typo/bootstrap-host," shell: ""truncate -s {{ bootstrap_host_loopback_swift_size }}G /openstack/{{ item }}.img"""," shell: ""truncate -s {{ bootstrap_host_loopback_cinder_size }}G /openstack/{{ item }}.img""",1,1
openstack%2Fproject-config~master~I0d4b3f6c89d1cda746ba56228c2a081b219d3a15,openstack/project-config,master,I0d4b3f6c89d1cda746ba56228c2a081b219d3a15,Fix typo in Neutron grafana dashboards,MERGED,2016-02-19 01:46:59.000000000,2016-02-19 11:15:57.000000000,2016-02-19 11:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-19 01:46:59.000000000', 'files': ['grafana/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/577c2846616d159ceef7c637f6fa528777364d56', 'message': 'Fix typo in Neutron grafana dashboards\n\nNow that the dashboard are deployed, it is easier to tweak the\nyaml file. Spotted a typo, and added baseline to integrated and\nDVR/Multinode/Linuxbridge dashboards.\n\nChange-Id: I0d4b3f6c89d1cda746ba56228c2a081b219d3a15\n'}]",0,282129,577c2846616d159ceef7c637f6fa528777364d56,7,3,1,748,,,0,"Fix typo in Neutron grafana dashboards

Now that the dashboard are deployed, it is easier to tweak the
yaml file. Spotted a typo, and added baseline to integrated and
DVR/Multinode/Linuxbridge dashboards.

Change-Id: I0d4b3f6c89d1cda746ba56228c2a081b219d3a15
",git fetch https://review.opendev.org/openstack/project-config refs/changes/29/282129/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/neutron.yaml'],1,577c2846616d159ceef7c637f6fa528777364d56,fix-neutron-grafana," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.{SUCCESS,FAILURE})),'12hours'), 'gate-tempest-dsvm-full') - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-grenade-dsvm-neutron.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-grenade-dsvm-neutron.{SUCCESS,FAILURE})),'24hours'), 'gate-grenade-dsvm-neutron') - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-neutron-full.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-neutron-full.{SUCCESS,FAILURE})),'24hours'), 'gate-tempest-dsvm-neutron-full')"," - target: alias(miovingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-grenade-dsvm-neutron.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-grenade-dsvm-neutron.{SUCCESS,FAILURE})),'24hours'), 'gate-grenade-dsvm-neutron')",3,1
openstack%2Fproject-config~master~Iccad0c81d2d9c2f3bc307339cbd05ab0964b3e72,openstack/project-config,master,Iccad0c81d2d9c2f3bc307339cbd05ab0964b3e72,Add reno job for oslo.log,MERGED,2016-02-18 21:31:10.000000000,2016-02-19 11:14:11.000000000,2016-02-19 11:14:11.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-18 21:31:10.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/18e159f98a33e5d039f682a9cb5c801897500fa9', 'message': 'Add reno job for oslo.log\n\nAs defined in I3649049a571490c5ec44a14a0c8640a4b747ad64\n\nChange-Id: Iccad0c81d2d9c2f3bc307339cbd05ab0964b3e72\n'}]",0,282066,18e159f98a33e5d039f682a9cb5c801897500fa9,8,4,1,16051,,,0,"Add reno job for oslo.log

As defined in I3649049a571490c5ec44a14a0c8640a4b747ad64

Change-Id: Iccad0c81d2d9c2f3bc307339cbd05ab0964b3e72
",git fetch https://review.opendev.org/openstack/project-config refs/changes/66/282066/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,18e159f98a33e5d039f682a9cb5c801897500fa9,reno_oslo_log, - name: release-notes-jobs,,2,0
openstack%2Fproject-config~master~Ia195e7acc47dd2562e0ca853d2f0e70e39e57b9b,openstack/project-config,master,Ia195e7acc47dd2562e0ca853d2f0e70e39e57b9b,Add gate-grenade-dsvm-neutron to tempest failure rate dashboard,MERGED,2016-02-11 23:57:47.000000000,2016-02-19 11:10:56.000000000,2016-02-19 11:10:56.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-11 23:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b764fb4f5ec8801fac1201474d7473ec2f44208e', 'message': 'Add gate-grenade-dsvm-neutron to tempest failure rate dashboard\n\nThis was missing from the list of graphs.\n\nChange-Id: Ia195e7acc47dd2562e0ca853d2f0e70e39e57b9b\n'}, {'number': 2, 'created': '2016-02-19 01:51:00.000000000', 'files': ['grafana/tempest.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/33ee3fd7f031c2c9b80fec9968a3f8c923647f44', 'message': 'Add gate-grenade-dsvm-neutron to tempest failure rate dashboard\n\nThis was missing from the list of graphs.\n\nChange-Id: Ia195e7acc47dd2562e0ca853d2f0e70e39e57b9b\n'}]",0,279326,33ee3fd7f031c2c9b80fec9968a3f8c923647f44,11,4,2,748,,,0,"Add gate-grenade-dsvm-neutron to tempest failure rate dashboard

This was missing from the list of graphs.

Change-Id: Ia195e7acc47dd2562e0ca853d2f0e70e39e57b9b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/279326/2 && git format-patch -1 --stdout FETCH_HEAD,['grafana/tempest.yaml'],1,b764fb4f5ec8801fac1201474d7473ec2f44208e,add-grenade-neutron," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.check.job.gate-grenade-dsvm-neutron.FAILURE),sum(stats_counts.zuul.pipeline.check.job.gate-grenade-dsvm-neutron.{SUCCESS,FAILURE})),'12hours'), 'gate-grenade-dsvm-neutron (check)') - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-grenade-dsvm-neutron.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-grenade-dsvm-neutron.{SUCCESS,FAILURE})),'12hours'), 'gate-grenade-dsvm-neutron (gate)')",,2,0
openstack%2Fneutron~master~I263c407ba2a82f53aace5f71cb27ad8974335e24,openstack/neutron,master,I263c407ba2a82f53aace5f71cb27ad8974335e24,Stop using non-existent method of Mock,MERGED,2016-02-15 15:13:11.000000000,2016-02-19 11:07:15.000000000,2016-02-19 11:07:14.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8686}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 11347}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-15 15:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fcd9bcc0f149fc8b5007f52fb199f2e357b0b25', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}, {'number': 2, 'created': '2016-02-15 15:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/17765e728d4ad4fb021383b77ff5dbe01bfccb9e', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}, {'number': 3, 'created': '2016-02-16 05:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/73512f087c569b41ca2524aa99455148196f6f81', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}, {'number': 4, 'created': '2016-02-16 10:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eea1139728baca0cb85afd987fe68287930debd2', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}, {'number': 5, 'created': '2016-02-16 13:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19106445cd6b18090b1259d3a0a49ce3ce15c4e3', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}, {'number': 6, 'created': '2016-02-16 15:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d61c9d8ceb20c03cee4c297f7a6b315ff0344a97', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}, {'number': 7, 'created': '2016-02-18 03:34:10.000000000', 'files': ['neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/hacking/checks.py', 'neutron/tests/unit/hacking/test_checks.py', 'neutron/tests/unit/agent/metadata/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd0ed209d214c2a4f825eda9dd0b97234f75875a', 'message': 'Stop using non-existent method of Mock\n\nThere is no method called_once_with() in Mock object.\nUse assert_called_once_with() instead.\n\nChange-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24\nCloses-Bug: #1544522\n'}]",16,280279,fd0ed209d214c2a4f825eda9dd0b97234f75875a,118,22,7,8686,,,0,"Stop using non-existent method of Mock

There is no method called_once_with() in Mock object.
Use assert_called_once_with() instead.

Change-Id: I263c407ba2a82f53aace5f71cb27ad8974335e24
Closes-Bug: #1544522
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/280279/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/hacking/checks.py', 'neutron/tests/unit/agent/metadata/test_agent.py']",3,3fcd9bcc0f149fc8b5007f52fb199f2e357b0b25,bug/1544522, mock_get_router_networks.assert_called_once_with(router_id), mock_get_router_networks.called_once_with(router_id),5,3
openstack%2Fopenstack-manuals~master~I33f8aaa5ce529048b7a3aadd53858269e77c74b4,openstack/openstack-manuals,master,I33f8aaa5ce529048b7a3aadd53858269e77c74b4,Update command for uploading a raw image,MERGED,2016-02-18 22:12:51.000000000,2016-02-19 11:06:46.000000000,2016-02-19 11:06:46.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-02-18 22:12:51.000000000', 'files': ['doc/user-guide/source/cli_cheat_sheet.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a6759be4137528c7173f5f23ba21ce9050cd98e', 'message': 'Update command for uploading a raw image\n\nThe command for uploading a raw image is actually the command for\nuploading a qcow2 image, fix this to be correct\n\nChange-Id: I33f8aaa5ce529048b7a3aadd53858269e77c74b4\n'}]",0,282078,0a6759be4137528c7173f5f23ba21ce9050cd98e,9,3,1,18061,,,0,"Update command for uploading a raw image

The command for uploading a raw image is actually the command for
uploading a qcow2 image, fix this to be correct

Change-Id: I33f8aaa5ce529048b7a3aadd53858269e77c74b4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/78/282078/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/source/cli_cheat_sheet.rst'],1,0a6759be4137528c7173f5f23ba21ce9050cd98e,update-cheat-sheet," $ glance image-create --name ""cirros-raw"" --disk-format raw \"," $ glance image-create --name ""cirros-qcow2"" --disk-format qcow2 \",1,1
openstack%2Ffuel-octane~master~Ia89b1aa060c900e5ef83f76d257b1f284c059f88,openstack/fuel-octane,master,Ia89b1aa060c900e5ef83f76d257b1f284c059f88,Add tests for get_patch_port_action function,MERGED,2016-01-22 09:44:39.000000000,2016-02-19 11:03:09.000000000,2016-02-04 06:51:13.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 6677}, {'_account_id': 12559}, {'_account_id': 19157}]","[{'number': 1, 'created': '2016-01-22 09:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/bbd8b59fe3c57d9d3c7a906f49e50edab2c8c6f7', 'message': 'Refactor get_patch_port function and add tests\n\nTest proper identification of release and provider for port\nin network schema.\n\nChange-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88\nRelated-bug: 1536182\n'}, {'number': 2, 'created': '2016-01-25 10:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/dcebea384cec0de7c415be9033f78bdacc55f30f', 'message': 'Refactor get_patch_port function and add tests\n\nTest proper identification of release and provider for port\nin network schema.\n\nChange-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88\nRelated-bug: 1536182\n'}, {'number': 3, 'created': '2016-01-25 17:15:24.000000000', 'files': ['octane/tests/test_transformations.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/41b2cbcaeb591e9733d5a2db461186a08ca825d6', 'message': 'Add tests for get_patch_port_action function\n\nTest proper identification of release and provider for port\nin network schema.\n\nChange-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88\nRelated-bug: 1536182\n'}]",7,271205,41b2cbcaeb591e9733d5a2db461186a08ca825d6,22,6,3,6677,,,0,"Add tests for get_patch_port_action function

Test proper identification of release and provider for port
in network schema.

Change-Id: Ia89b1aa060c900e5ef83f76d257b1f284c059f88
Related-bug: 1536182
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/05/271205/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/helpers/transformations.py', 'octane/tests/test_transformations.py']",2,bbd8b59fe3c57d9d3c7a906f49e50edab2c8c6f7,bug/1536182,"import pytest DEFAULT_OVS_ACTION = { 'action': 'add-patch', 'bridges': ['test-br'] } DEFAULT_LNX_ACTION = { 'action': 'add-port', 'bridge': 'test-br' } OVS_ACTION = { 'action': 'add-patch', 'bridges': ['test-br'], 'provider': 'ovs' } LNX_ACTION = { 'action': 'add-port', 'bridge': 'test-br', 'provider': 'lnx' } ADD_LNX_BR_ACTION = { 'action': 'add-br', 'provider': 'lnx', 'name': 'test-br' } ADD_OVS_BR_ACTION = { 'action': 'add-br', 'provider': 'ovs', 'name': 'test-br' } HOST_CONFIG_6_0 = { 'openstack_version': '2014.2-6.0', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, DEFAULT_OVS_ACTION ] } } HOST_CONFIG_6_1 = { 'openstack_version': '2014.2.2-6.1', 'network_scheme': { 'transformations': [ DEFAULT_LNX_ACTION, ] } } HOST_CONFIG_7_0 = { 'openstack_version': '2015.1.0-7.0', 'network_scheme': { 'transformations': [ OVS_ACTION, DEFAULT_OVS_ACTION, ADD_OVS_BR_ACTION ] } } @pytest.mark.parametrize('host_config,expected_action', [ (HOST_CONFIG_6_0, DEFAULT_OVS_ACTION), (HOST_CONFIG_6_1, DEFAULT_LNX_ACTION), (HOST_CONFIG_7_0, OVS_ACTION)]) def test_patch_port_action(host_config, expected_action): bridge = 'test-br' res, _ = ts.get_patch_port_action(host_config, bridge) assert res == expected_action",,71,3
openstack%2Fopenstack-manuals~master~I37eff3f644399e6748fa1de931f1b78d4ea152d6,openstack/openstack-manuals,master,I37eff3f644399e6748fa1de931f1b78d4ea152d6,Move service types to left column,MERGED,2016-02-19 06:05:54.000000000,2016-02-19 10:55:27.000000000,2016-02-19 10:55:27.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 14947}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-02-19 06:05:54.000000000', 'files': ['doc/install-guide/source/overview.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0c089ee98efb28e47e29d9bb23e413cf404d6655', 'message': 'Move service types to left column\n\nMove service type headings (storage, shared services,\nHigher-level services) to the left column of the\nOpenStack services table.\n\nChange-Id: I37eff3f644399e6748fa1de931f1b78d4ea152d6\n'}]",0,282187,0c089ee98efb28e47e29d9bb23e413cf404d6655,8,4,1,12686,,,0,"Move service types to left column

Move service type headings (storage, shared services,
Higher-level services) to the left column of the
OpenStack services table.

Change-Id: I37eff3f644399e6748fa1de931f1b78d4ea152d6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/282187/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/overview.rst'],1,0c089ee98efb28e47e29d9bb23e413cf404d6655,fix-table, * - **Storage** - * - **Shared services** - * - **Higher-level services** -, * - - **Storage** * - - **Shared services** * - - **Higher-level services**,6,6
openstack%2Ffuel-web~master~I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c,openstack/fuel-web,master,I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c,Reworked checking the result message of deploy task,MERGED,2016-02-18 21:12:21.000000000,2016-02-19 10:53:37.000000000,2016-02-19 10:31:13.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8829}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 13505}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-18 21:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/db2e9d15121696d2b5707f2766f7395b541cb359', 'message': 'Reworked checking the result message of deploy task\n\nThe order of independent tasks is undefined.\nThe test_deployment_task_managers has an assumption about this order\n and this causes random fail.\n\nChange-Id: I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c\nCloses-Bug: 1547218\n'}, {'number': 2, 'created': '2016-02-18 21:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/649904d7c1328984e01328f65fe9ebd8580e7771', 'message': 'Reworked checking the result message of deploy task\n\nThe order of independent tasks is undefined.\nThe test_deployment_task_managers has an assumption about this order\n and this causes random fail.\n\nChange-Id: I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c\nCloses-Bug: 1547218\n'}, {'number': 3, 'created': '2016-02-19 08:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/013cd9423796759bca7b02f089945fe1f0e1e86a', 'message': 'Reworked checking the result message of deploy task\n\nThe order of independent tasks is undefined.\nThe test_deployment_task_managers has an assumption about this order\n and this causes random fail.\n\nChange-Id: I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c\nCloses-Bug: 1547218\n'}, {'number': 4, 'created': '2016-02-19 09:50:54.000000000', 'files': ['nailgun/nailgun/test/integration/test_task_managers.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/033705eb13c1b1ecae6e75b37defca2abc67471a', 'message': 'Reworked checking the result message of deploy task\n\nThe order of independent tasks is undefined.\nThe test_deployment_task_managers has an assumption about this order\n and this causes random fail.\n\nChange-Id: I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c\nCloses-Bug: 1547218\n'}]",8,282061,033705eb13c1b1ecae6e75b37defca2abc67471a,54,16,4,18205,,,0,"Reworked checking the result message of deploy task

The order of independent tasks is undefined.
The test_deployment_task_managers has an assumption about this order
 and this causes random fail.

Change-Id: I32171ddd5e4cfb4d570d5dc6ae4fb0a12750ea3c
Closes-Bug: 1547218
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/61/282061/4 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/test/integration/test_task_managers.py'],1,db2e9d15121696d2b5707f2766f7395b541cb359,bug/1547218," None ) cluster_name = self.env.clusters[-1].name self.assertIn( u""Successfully removed 1 node(s). No errors occurred"", supertask.message ) self.assertIn( u""Provision of environment '{0}' is done."".format(cluster_name), supertask.message ) self.assertIn( u""Provision of environment '{0}' is done."".format(cluster_name), supertask.message"," u""Successfully removed 1 node(s). No errors occurred\n"" u""Provision of environment '{0}' is done. \n"" u""Deployment of environment '{0}' is done. "".format( self.env.clusters[0].name )",14,5
openstack%2Fheat~master~I062f97fb0cf3723de40210a1d20f79a7979a7225,openstack/heat,master,I062f97fb0cf3723de40210a1d20f79a7979a7225,Release notes for server-side env resolution,MERGED,2016-02-15 20:37:28.000000000,2016-02-19 10:51:02.000000000,2016-02-19 10:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8833}]","[{'number': 1, 'created': '2016-02-15 20:37:28.000000000', 'files': ['releasenotes/notes/server-side-multi-env-7862a75e596ae8f5.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/f2128142496a90186dd6559eec1654892f5fb6ab', 'message': 'Release notes for server-side env resolution\n\nChange-Id: I062f97fb0cf3723de40210a1d20f79a7979a7225\nImplements: blueprint multi-environments\n'}]",0,280390,f2128142496a90186dd6559eec1654892f5fb6ab,7,3,1,8399,,,0,"Release notes for server-side env resolution

Change-Id: I062f97fb0cf3723de40210a1d20f79a7979a7225
Implements: blueprint multi-environments
",git fetch https://review.opendev.org/openstack/heat refs/changes/90/280390/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/server-side-multi-env-7862a75e596ae8f5.yaml'],1,f2128142496a90186dd6559eec1654892f5fb6ab,bp/multi-environments,--- features: - Multiple environment files may be passed to the server in the files dictionary along with an ordered list of the environment file names. The server will generate the stack's environment from the provided files rather than requiring the client to merge the environments together. This is optional; the existing interface to pass in the already resolved environment is still present. ,,8,0
openstack%2Fheat~master~Ibe46fd35de7988920c101a83259c06c8f8a3ed0b,openstack/heat,master,Ibe46fd35de7988920c101a83259c06c8f8a3ed0b,Hook into environment merging on server,MERGED,2015-11-04 15:50:30.000000000,2016-02-19 10:50:46.000000000,2016-02-19 10:50:46.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8399}, {'_account_id': 16203}]","[{'number': 1, 'created': '2015-11-04 15:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d66f39619889762012a87715a799436c873ff8e1', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 2, 'created': '2015-11-06 14:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8bbb949855509f83e85c02da94e1a96f3dcb6e9a', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 3, 'created': '2015-11-17 15:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9a0c57233cec28e5eabe155606d49e71550c82c2', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 4, 'created': '2015-11-18 15:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d07dc83df6272674f04972aeab836db8b15d7d22', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 5, 'created': '2015-12-01 14:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/17c441880d973f9f9deea6fb82e5e6ed0a749ae5', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 6, 'created': '2015-12-01 16:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/67a6ceb89fd4b51ab784b80a1f9bf88f8649b541', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 7, 'created': '2015-12-07 16:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/81415d2751f3e673a26a37b7dc998b65caac1a48', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 8, 'created': '2015-12-17 17:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bea136fbd50fff452485f3f1d8236bd20bd61958', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 9, 'created': '2016-01-12 15:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/62b724dd9092731181efcca5e1c134668011e684', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 10, 'created': '2016-01-12 16:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2904adcc46728c97ced016edfa5f5a3831091d4f', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 11, 'created': '2016-01-12 18:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a118a24b331aa1f454035497d95c5ac42de5d31f', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 12, 'created': '2016-01-20 15:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4005492ae665221de46777f2bdec6c34950a005d', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 13, 'created': '2016-01-26 20:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ad367eff6fdb2435230e64d066d167d9ab280e0', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 14, 'created': '2016-01-28 16:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/226eb438c300386dd0cfafe08377e7d27bd751ba', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 15, 'created': '2016-02-03 08:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9715820e50c9ef788143a9a0035af61933d30bce', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 16, 'created': '2016-02-12 14:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dac2dec2f08e848be9224b530a58d8c8e3f9ed4f', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}, {'number': 17, 'created': '2016-02-12 15:49:00.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/tests/engine/service/test_stack_update.py', 'heat_integrationtests/functional/test_env_merge.py', 'heat_integrationtests/common/test.py', 'heat/engine/service.py', 'heat/tests/engine/service/test_stack_create.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d454caf00a310bab2b204ba476ecc936a836f6c6', 'message': ""Hook into environment merging on server\n\nIf environment_files is specified, look in the files dict for each\nspecified environment file and merge into the stack's environment. This\nis the same workflow that previously occurred client-side.\n\nChange-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b\nImplements: blueprint multi-environments\n""}]",7,241662,d454caf00a310bab2b204ba476ecc936a836f6c6,67,7,17,8399,,,0,"Hook into environment merging on server

If environment_files is specified, look in the files dict for each
specified environment file and merge into the stack's environment. This
is the same workflow that previously occurred client-side.

Change-Id: Ibe46fd35de7988920c101a83259c06c8f8a3ed0b
Implements: blueprint multi-environments
",git fetch https://review.opendev.org/openstack/heat refs/changes/62/241662/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/tests/engine/service/test_stack_update.py', 'heat/engine/service.py', 'heat/tests/engine/service/test_stack_create.py']",5,d66f39619889762012a87715a799436c873ff8e1,bp/multi-environments," def _test_stack_create(self, stack_name, mock_validate, mock_tg, environment_files=None): mock_merge = self.patchobject(self.man, '_merge_environments') template, params, None, {}, environment_files=environment_files) if environment_files: mock_merge.assert_called_once_with(environment_files, None, params) def test_stack_create_with_environment_files(self): stack_name = 'env_files_test_stack' environment_files = ['env_1', 'env_2'] self._test_stack_create(stack_name, environment_files=environment_files) "," def _test_stack_create(self, stack_name, mock_validate, mock_tg): template, params, None, {})",174,14
openstack%2Fgnocchi~master~If8e35fd4e97c7838a88891b7e34b7a857f94be12,openstack/gnocchi,master,If8e35fd4e97c7838a88891b7e34b7a857f94be12,storage: make sure we delete old measures respecting archive policy,MERGED,2016-02-11 15:38:25.000000000,2016-02-19 10:50:35.000000000,2016-02-19 10:50:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7729}, {'_account_id': 11564}]","[{'number': 1, 'created': '2016-02-11 15:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d4e88fc1c47ba0506260fdce79e9e79b28b399ad', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}, {'number': 2, 'created': '2016-02-12 07:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/117d5c3e8e0702fa73e446b4334d9f85f9d0c510', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}, {'number': 3, 'created': '2016-02-12 08:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b1e6174fbcff6264671dfccf6e4002d63aff5166', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}, {'number': 4, 'created': '2016-02-12 10:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c875f8f69d039cc48ce12eee77432363b7bdcc16', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}, {'number': 5, 'created': '2016-02-14 21:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/5423f0b007867bd84962e87fdbb4f590a443d5e0', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}, {'number': 6, 'created': '2016-02-19 08:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1ec77c9022dcc188103fc21a25901a377253ed72', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}, {'number': 7, 'created': '2016-02-19 09:41:33.000000000', 'files': ['gnocchi/storage/ceph.py', 'doc/source/architecture.rst', 'gnocchi/storage/_carbonara.py', 'gnocchi/storage/swift.py', 'gnocchi/tests/test_storage.py', 'gnocchi/carbonara.py', 'gnocchi/storage/file.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7d67957e4503c3086d8fd113a10d22187eb5187a', 'message': 'storage: make sure we delete old measures respecting archive policy\n\nChange-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12\n'}]",0,279146,7d67957e4503c3086d8fd113a10d22187eb5187a,22,7,7,1669,,,0,"storage: make sure we delete old measures respecting archive policy

Change-Id: If8e35fd4e97c7838a88891b7e34b7a857f94be12
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/46/279146/4 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py', 'gnocchi/carbonara.py', 'gnocchi/storage/file.py']",4,d4e88fc1c47ba0506260fdce79e9e79b28b399ad,jd/delete-old-points," def _delete_metric_measure(self, metric, timestamp_key, aggregation, granularity): os.unlink(self._build_metric_path_for_split( metric, aggregation, timestamp_key, granularity)) ",,81,7
openstack%2Fopenstack-manuals~master~Ic8039a71edf50a45e1c8e461780db861add48f2f,openstack/openstack-manuals,master,Ic8039a71edf50a45e1c8e461780db861add48f2f,Corrected description of AggregateMultiTenancyIsolation,MERGED,2016-02-18 03:40:58.000000000,2016-02-19 10:49:22.000000000,2016-02-19 10:49:21.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10897}, {'_account_id': 12686}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-02-18 03:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/129ef0809314f2aa2d1d08cbde9464bf607efc93', 'message': 'Corrected description of AggregateMultiTenancyIsolation\n\nAs per bug, the description required more specificity.\n\nChange-Id: Ic8039a71edf50a45e1c8e461780db861add48f2f\nCloses-Bug: #1328400\n'}, {'number': 2, 'created': '2016-02-19 03:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f21701e8eb5a46c89221027c757fad002c676ca1', 'message': 'Corrected description of AggregateMultiTenancyIsolation\n\nAs per bug, the description required more specificity.\n\nChange-Id: Ic8039a71edf50a45e1c8e461780db861add48f2f\nCloses-Bug: #1328400\n'}, {'number': 3, 'created': '2016-02-19 04:21:14.000000000', 'files': ['doc/config-reference/source/compute/scheduler.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e3084a90a9e187bf63aecc3950c87702710b8518', 'message': 'Corrected description of AggregateMultiTenancyIsolation\n\nAs per bug, the description required more specificity.\n\nChange-Id: Ic8039a71edf50a45e1c8e461780db861add48f2f\nCloses-Bug: #1328400\n'}]",6,281620,e3084a90a9e187bf63aecc3950c87702710b8518,25,7,3,9162,,,0,"Corrected description of AggregateMultiTenancyIsolation

As per bug, the description required more specificity.

Change-Id: Ic8039a71edf50a45e1c8e461780db861add48f2f
Closes-Bug: #1328400
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/20/281620/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/compute/scheduler.rst'],1,129ef0809314f2aa2d1d08cbde9464bf607efc93,bug/1328400,"Ensures that any instances creates by the tenant (or list of tenants) are created only on specific :ref:`host-aggregates`. If a host is in an aggregate that has the ``filter_tenant_id`` metadata key, the host creates instances from only that tenant or list of tenants. A host can be in different aggregates. If a host does not belong to an aggregate with the metadata key, the host can create instances from all tenants. This setting does not isolate the aggregate from other tenants, any other tenant can continue to build instances on the specified aggregate.","Isolates tenants to specific :ref:`host-aggregates`. If a host is in an aggregate that has the ``filter_tenant_id`` metadata key, the host creates instances from only that tenant or list of tenants. A host can be in different aggregates. If a host does not belong to an aggregate with the metadata key, the host can create instances from all tenants.",8,6
openstack%2Fmagnum~master~I6d49e1df1f114dc8abc4404f469e25bb3a2a0a8b,openstack/magnum,master,I6d49e1df1f114dc8abc4404f469e25bb3a2a0a8b,devstack: Comment out logging configuration,MERGED,2016-02-19 03:20:22.000000000,2016-02-19 10:48:13.000000000,2016-02-19 10:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-02-19 03:20:22.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1b2332dfbffa03b3e7343343c2e57d800fc9c63a', 'message': 'devstack: Comment out logging configuration\n\nAnd move them into ""Modify to your environment"" section\nbecause they are not appropriate for every environment.\n\nChange-Id: I6d49e1df1f114dc8abc4404f469e25bb3a2a0a8b\n'}]",0,282149,1b2332dfbffa03b3e7343343c2e57d800fc9c63a,7,3,1,6854,,,0,"devstack: Comment out logging configuration

And move them into ""Modify to your environment"" section
because they are not appropriate for every environment.

Change-Id: I6d49e1df1f114dc8abc4404f469e25bb3a2a0a8b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/49/282149/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,1b2332dfbffa03b3e7343343c2e57d800fc9c63a,,## Log all output to files # LOGFILE=$HOME/devstack.log # SCREEN_LOGDIR=$HOME/logs, # Log all output to files LOGFILE=$HOME/devstack.log SCREEN_LOGDIR=$HOME/logs,3,4
openstack%2Fironic-inspector~master~I2260f4b463c5dc804edac642c86e0da153e163f6,openstack/ironic-inspector,master,I2260f4b463c5dc804edac642c86e0da153e163f6,Drop rollback actions for set-XX and extend-XX rules actions,MERGED,2016-02-16 10:13:14.000000000,2016-02-19 10:43:25.000000000,2016-02-19 10:43:24.000000000,"[{'_account_id': 3}, {'_account_id': 6637}, {'_account_id': 7419}, {'_account_id': 7882}, {'_account_id': 13636}]","[{'number': 1, 'created': '2016-02-16 10:13:14.000000000', 'files': ['ironic_inspector/test/functional.py', 'ironic_inspector/plugins/rules.py', 'releasenotes/notes/no-rollback-e15bc7fee0134545.yaml', 'ironic_inspector/test/test_plugins_rules.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/31f7a5ada6775b0431ecdeaeb78f731566e9d9d6', 'message': 'Drop rollback actions for set-XX and extend-XX rules actions\n\nRollback actions were designed to help with rerunning introspection\non the same node. However, rollback actions for these actions proved\nto be confusing and were never properly documented at all.\nEven worse, the rollback action for set-attribute actually makes\nthis command impossible to use with non-removable attributes\n(e.g. /driver).\n\nThis change removes rollback actions from all rules.\nWe need to rethink how we handle rollback in rules later on.\n\nChange-Id: I2260f4b463c5dc804edac642c86e0da153e163f6\n'}]",0,280589,31f7a5ada6775b0431ecdeaeb78f731566e9d9d6,14,5,1,10239,,,0,"Drop rollback actions for set-XX and extend-XX rules actions

Rollback actions were designed to help with rerunning introspection
on the same node. However, rollback actions for these actions proved
to be confusing and were never properly documented at all.
Even worse, the rollback action for set-attribute actually makes
this command impossible to use with non-removable attributes
(e.g. /driver).

This change removes rollback actions from all rules.
We need to rethink how we handle rollback in rules later on.

Change-Id: I2260f4b463c5dc804edac642c86e0da153e163f6
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/89/280589/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/test/functional.py', 'ironic_inspector/plugins/rules.py', 'releasenotes/notes/no-rollback-e15bc7fee0134545.yaml', 'ironic_inspector/test/test_plugins_rules.py']",4,31f7a5ada6775b0431ecdeaeb78f731566e9d9d6,no-rollback,," @mock.patch.object(node_cache.NodeInfo, 'patch') def test_rollback_with_existing(self, mock_patch): self.node.extra = {'value': 'value'} self.act.rollback(self.node_info, self.params) mock_patch.assert_called_once_with([{'op': 'remove', 'path': '/extra/value'}]) @mock.patch.object(node_cache.NodeInfo, 'patch') def test_rollback_no_existing(self, mock_patch): self.node.extra = {} self.act.rollback(self.node_info, self.params) self.assertFalse(mock_patch.called) @mock.patch.object(node_cache.NodeInfo, 'patch') def test_rollback_with_existing(self, mock_patch): self.node.properties = {'capabilities': 'foo:bar,cap1:val'} self.act.rollback(self.node_info, self.params) mock_patch.assert_called_once_with( [{'op': 'add', 'path': '/properties/capabilities', 'value': 'foo:bar'}]) @mock.patch.object(node_cache.NodeInfo, 'patch') def test_rollback_no_existing(self, mock_patch): self.node.properties = {'capabilities': 'foo:bar'} self.act.rollback(self.node_info, self.params) # TODO(dtantsur): make sure it's not called at all mock_patch.assert_called_once_with( [{'op': 'add', 'path': '/properties/capabilities', 'value': 'foo:bar'}]) @mock.patch.object(node_cache.NodeInfo, 'patch') def test_rollback_with_existing(self, mock_patch): self.node.extra['value'] = [1, 42, 0] self.act.rollback(self.node_info, self.params) mock_patch.assert_called_once_with( [{'op': 'replace', 'path': '/extra/value', 'value': [1, 0]}]) @mock.patch.object(node_cache.NodeInfo, 'patch') def test_rollback_no_existing(self, mock_patch): self.node.extra['value'] = [1, 0] self.act.rollback(self.node_info, self.params) self.assertFalse(mock_patch.called)",10,68
openstack%2Fpython-watcherclient~master~Ia6f12d87f376841faebcab42ac70a72f6f222985,openstack/python-watcherclient,master,Ia6f12d87f376841faebcab42ac70a72f6f222985,Updated from global requirements,MERGED,2016-02-16 22:11:30.000000000,2016-02-19 10:37:04.000000000,2016-02-19 10:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16272}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-02-16 22:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/98702bc9fbdff256c1464e8f0b76cc2bd29a8d0c', 'message': 'Updated from global requirements\n\nChange-Id: Ia6f12d87f376841faebcab42ac70a72f6f222985\n'}, {'number': 2, 'created': '2016-02-19 02:37:28.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/f390f3526fc6e5404048c25506072702b6823dec', 'message': 'Updated from global requirements\n\nChange-Id: Ia6f12d87f376841faebcab42ac70a72f6f222985\n'}]",0,280954,f390f3526fc6e5404048c25506072702b6823dec,11,7,2,11131,,,0,"Updated from global requirements

Change-Id: Ia6f12d87f376841faebcab42ac70a72f6f222985
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/54/280954/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,98702bc9fbdff256c1464e8f0b76cc2bd29a8d0c,openstack/requirements," setup_requires=['pbr>=1.8'],","#!/usr/bin/env python setup_requires=['pbr'],",19,20
openstack%2Fdevstack~master~I46416c1df3a4da66e863a16baeb73886e110d447,openstack/devstack,master,I46416c1df3a4da66e863a16baeb73886e110d447,Kill radvd when stopping neutron-l3 service,MERGED,2016-01-19 11:14:34.000000000,2016-02-19 10:26:50.000000000,2016-02-19 10:26:50.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4656}, {'_account_id': 7350}, {'_account_id': 7805}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-01-19 11:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a0cbc96bf64f193e1260a4eb1238696c315750b8', 'message': 'Kill radvd when stopping neutron-l3 service\n\nWhen stopping neutron-l3 service, radvd should be\nstopped.\n\nChange-Id: I46416c1df3a4da66e863a16baeb73886e110d447\nCloses-Bug: #1535661\n'}, {'number': 2, 'created': '2016-01-27 06:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6f8c86a4808b2e75706e16f46d1d639d1b60fc5e', 'message': 'Kill radvd when stopping neutron-l3 service\n\nWhen stopping neutron-l3 service, radvd should be\nstopped.\n\nChange-Id: I46416c1df3a4da66e863a16baeb73886e110d447\nCloses-Bug: #1535661\n'}, {'number': 3, 'created': '2016-02-04 10:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d05e20133890aada220f2111fdd0b2dcbc398d15', 'message': 'Kill radvd when stopping neutron-l3 service\n\nWhen stopping neutron-l3 service, radvd should be\nstopped.\n\nWedged in gate, pulled out\n\nChange-Id: I46416c1df3a4da66e863a16baeb73886e110d447\nCloses-Bug: #1535661\n'}, {'number': 4, 'created': '2016-02-05 01:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b807e68cf5438946e2b7649e53877568232e9d64', 'message': 'Kill radvd when stopping neutron-l3 service\n\nWhen stopping neutron-l3 service, radvd should be\nstopped.\n\nChange-Id: I46416c1df3a4da66e863a16baeb73886e110d447\nCloses-Bug: #1535661\n'}, {'number': 5, 'created': '2016-02-16 09:05:32.000000000', 'files': ['lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a15d9de92f724baebea0c202b14c2220df68e2a9', 'message': 'Kill radvd when stopping neutron-l3 service\n\nWhen stopping neutron-l3 service, radvd should be\nstopped.\n\nChange-Id: I46416c1df3a4da66e863a16baeb73886e110d447\nCloses-Bug: #1535661\n'}]",3,269560,a15d9de92f724baebea0c202b14c2220df68e2a9,59,9,5,7805,,,0,"Kill radvd when stopping neutron-l3 service

When stopping neutron-l3 service, radvd should be
stopped.

Change-Id: I46416c1df3a4da66e863a16baeb73886e110d447
Closes-Bug: #1535661
",git fetch https://review.opendev.org/openstack/devstack refs/changes/60/269560/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron-legacy'],1,a0cbc96bf64f193e1260a4eb1238696c315750b8,bug/1535661, if is_service_enabled q-l3; then sudo pkill -9 -f radvd || : stop_process q-l3 fi, stop_process q-l3,5,1
openstack%2Fneutron~stable%2Fliberty~I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5,openstack/neutron,stable/liberty,I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5,ML2: delete_port on deadlock during binding,MERGED,2016-02-15 07:52:41.000000000,2016-02-19 10:24:45.000000000,2016-02-19 10:24:44.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 11347}, {'_account_id': 16707}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-15 07:52:41.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e93c5dce0b71ebebfeca31913928f07b77bbd0ae', 'message': 'ML2: delete_port on deadlock during binding\n\nThe previous logic was only catching mechanism driver exceptions so\nit would leave behind a partially built port if a deadlock was\nencountered during port binding.\n\nThe bug this closes was caused by a DBDeadlock being encountered when\na lock was attempted on the port binding record\n(get_locked_port_and_binding). This would not be caught so the API\nwould retry the whole operation with the original created port\nleft behind. This resulted in two ports assigned to the same instance.\n\nCloses-Bug: #1543880\nChange-Id: I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5\n(cherry picked from commit eb8141051abe64de7ad9398fb2adaf9a0a79d62d)\n'}]",0,280092,e93c5dce0b71ebebfeca31913928f07b77bbd0ae,18,9,1,7787,,,0,"ML2: delete_port on deadlock during binding

The previous logic was only catching mechanism driver exceptions so
it would leave behind a partially built port if a deadlock was
encountered during port binding.

The bug this closes was caused by a DBDeadlock being encountered when
a lock was attempted on the port binding record
(get_locked_port_and_binding). This would not be caught so the API
would retry the whole operation with the original created port
left behind. This resulted in two ports assigned to the same instance.

Closes-Bug: #1543880
Change-Id: I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5
(cherry picked from commit eb8141051abe64de7ad9398fb2adaf9a0a79d62d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/280092/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,e93c5dce0b71ebebfeca31913928f07b77bbd0ae,bug/1543880," except os_db_exception.DBDeadlock: # bind port can deadlock in normal operation so we just cleanup # the port and let the API retry with excutils.save_and_reraise_exception(): LOG.debug(""_bind_port_if_needed deadlock, deleting port %s"", result['id']) self.delete_port(context, result['id'])",,29,8
openstack%2Fwatcher~master~I025070c6004243d6b8a6ea7a1d83081480c4148b,openstack/watcher,master,I025070c6004243d6b8a6ea7a1d83081480c4148b,Pass parameter to the query in get_last_sample_values,MERGED,2016-02-03 14:37:08.000000000,2016-02-19 10:24:36.000000000,2016-02-19 10:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18602}, {'_account_id': 18675}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-02-03 14:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/78a74290c0ace742e298b206cde7344d1bf2ce46', 'message': 'Remove unused parameter in get_last_sample_values\n\nIn watcher/common/ceilometer_help.py:129,\nthere is an unused parameter:\n  def get_last_sample_values(self, resource_id, meter_name, limit=1):\n\nChange-Id: I025070c6004243d6b8a6ea7a1d83081480c4148b\n'}, {'number': 2, 'created': '2016-02-03 14:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3416f30bf2b0b488bcadde25a629becc9377db60', 'message': 'Remove unused parameter in get_last_sample_values\n\nIn watcher/common/ceilometer_help.py:129,\nthere is an unused parameter:\n  def get_last_sample_values(self, resource_id, meter_name, limit=1):\n\nCloses-Bug: #1527163\nChange-Id: I025070c6004243d6b8a6ea7a1d83081480c4148b\n'}, {'number': 3, 'created': '2016-02-03 16:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/424753ef842b7e632d31f1ff122338bca97b2f28', 'message': 'Remove unused parameter in get_last_sample_values\n\nIn watcher/common/ceilometer_help.py:129,\nthere is an unused parameter:\n  def get_last_sample_values(self, resource_id, meter_name, limit=1):\n\nCloses-Bug: #1541415\nChange-Id: I025070c6004243d6b8a6ea7a1d83081480c4148b\n'}, {'number': 4, 'created': '2016-02-18 12:55:28.000000000', 'files': ['watcher/common/ceilometer_helper.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/f32995228b1ef174a2ce9543c993033ac57168c0', 'message': ""Pass parameter to the query in get_last_sample_values\n\nIn watcher/common/ceilometer_help.py:129,\nthere is an unused parameter, called limit:\n  def get_last_sample_values(self, resource_id, meter_name, limit=1):\n\nIn the next line, there is a method call which can take this\ncurrently unused 'limit' parameter. Probably, passing this 'limit'\nparameter to the query was originally intended, however it wasn't\nadded to the query call.\n\nCloses-Bug: #1541415\nChange-Id: I025070c6004243d6b8a6ea7a1d83081480c4148b\n""}]",1,275727,f32995228b1ef174a2ce9543c993033ac57168c0,25,8,4,18602,,,0,"Pass parameter to the query in get_last_sample_values

In watcher/common/ceilometer_help.py:129,
there is an unused parameter, called limit:
  def get_last_sample_values(self, resource_id, meter_name, limit=1):

In the next line, there is a method call which can take this
currently unused 'limit' parameter. Probably, passing this 'limit'
parameter to the query was originally intended, however it wasn't
added to the query call.

Closes-Bug: #1541415
Change-Id: I025070c6004243d6b8a6ea7a1d83081480c4148b
",git fetch https://review.opendev.org/openstack/watcher refs/changes/27/275727/4 && git format-patch -1 --stdout FETCH_HEAD,['watcher/common/ceilometer_helper.py'],1,78a74290c0ace742e298b206cde7344d1bf2ce46,bug/1541415," def get_last_sample_values(self, resource_id, meter_name):"," def get_last_sample_values(self, resource_id, meter_name, limit=1):",1,1
openstack%2Fheat~master~I1ccba614e29c089cfa933d347cc55b9145b25a23,openstack/heat,master,I1ccba614e29c089cfa933d347cc55b9145b25a23,Fix several nits in os_database trove resource,MERGED,2016-02-19 08:02:56.000000000,2016-02-19 10:23:18.000000000,2016-02-19 10:23:18.000000000,"[{'_account_id': 3}, {'_account_id': 8289}, {'_account_id': 8833}]","[{'number': 1, 'created': '2016-02-19 08:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ec9a7de88d1d26b0867b1724c908b1aa512f436d', 'message': 'Fix several nits in os_database trove resource\n\nThis patch fixes several issues:\n - Set using LOG.warning instead of LOG.warn\n - Using common.HeatTestCase class as parent class for\n   InstanceUpdateTests. Which allows to hide annoying output:\n   ""Unexpected instance state change during update. Retrying.""\n - Stop re-registering OS::Trove::Instance, which is a root cause of\n   message:\n   ""Changing OS::Trove::Instance from <class\n\'heat.engine.resources.openstack.trove.os_database.OSDBInstance\'> to\n<class \'heat.engine.resources.openstack.trove.os_database.OSDBInstance\'>""\n\nChange-Id: I1ccba614e29c089cfa933d347cc55b9145b25a23\n'}, {'number': 2, 'created': '2016-02-19 08:54:26.000000000', 'files': ['heat/tests/openstack/trove/test_os_database.py', 'heat/engine/resources/openstack/trove/os_database.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/84e5b9fd16fc3bf9cf9b98a08e771922a005e331', 'message': 'Fix several nits in os_database trove resource\n\nThis patch fixes several issues:\n - Set using LOG.warning instead of LOG.warn\n - Using common.HeatTestCase class as parent class for\n   InstanceUpdateTests. Which allows to hide annoying output:\n   ""Unexpected instance state change during update. Retrying.""\n - Stop re-registering OS::Trove::Instance, which is a root cause of\n   message:\n   ""Changing OS::Trove::Instance from <class\n\'heat.engine.resources.openstack.trove.os_database.OSDBInstance\'> to\n<class \'heat.engine.resources.openstack.trove.os_database.OSDBInstance\'>""\n\nChange-Id: I1ccba614e29c089cfa933d347cc55b9145b25a23\n'}]",0,282219,84e5b9fd16fc3bf9cf9b98a08e771922a005e331,11,3,2,6577,,,0,"Fix several nits in os_database trove resource

This patch fixes several issues:
 - Set using LOG.warning instead of LOG.warn
 - Using common.HeatTestCase class as parent class for
   InstanceUpdateTests. Which allows to hide annoying output:
   ""Unexpected instance state change during update. Retrying.""
 - Stop re-registering OS::Trove::Instance, which is a root cause of
   message:
   ""Changing OS::Trove::Instance from <class
'heat.engine.resources.openstack.trove.os_database.OSDBInstance'> to
<class 'heat.engine.resources.openstack.trove.os_database.OSDBInstance'>""

Change-Id: I1ccba614e29c089cfa933d347cc55b9145b25a23
",git fetch https://review.opendev.org/openstack/heat refs/changes/19/282219/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/openstack/trove/test_os_database.py', 'heat/engine/resources/openstack/trove/os_database.py']",2,ec9a7de88d1d26b0867b1724c908b1aa512f436d,," LOG.warning(_LW(""Unexpected instance state change "" ""during update. Retrying.""))"," LOG.warn(_LW(""Unexpected instance state change "" ""during update. Retrying.""))",3,5
openstack%2Ffuel-octane~master~I066750e8deb292fa8a34656d2bce06ef13719360,openstack/fuel-octane,master,I066750e8deb292fa8a34656d2bce06ef13719360,Remove version hardcode from puppet module path,MERGED,2016-02-15 10:04:15.000000000,2016-02-19 10:23:01.000000000,2016-02-15 12:00:29.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 6677}, {'_account_id': 12559}]","[{'number': 1, 'created': '2016-02-15 10:04:15.000000000', 'files': ['octane/magic_consts.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/bde08a6c5d1e6107f1fe30cd138357d2e74ceb25', 'message': 'Remove version hardcode from puppet module path\n\nNow module path constant has hardcoded version 2015.1.0-7.0.\nReplace it with /etc/puppet/modules path which is a symlink\nto the current version of modules.\n\nChange-Id: I066750e8deb292fa8a34656d2bce06ef13719360\nCloses-bug: 1544967\n'}]",0,280128,bde08a6c5d1e6107f1fe30cd138357d2e74ceb25,10,5,1,6677,,,0,"Remove version hardcode from puppet module path

Now module path constant has hardcoded version 2015.1.0-7.0.
Replace it with /etc/puppet/modules path which is a symlink
to the current version of modules.

Change-Id: I066750e8deb292fa8a34656d2bce06ef13719360
Closes-bug: 1544967
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/28/280128/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/magic_consts.py'],1,bde08a6c5d1e6107f1fe30cd138357d2e74ceb25,bug/1544967,"PUPPET_DIR = ""/etc/puppet/modules""","PUPPET_DIR = ""/etc/puppet/2015.1.0-7.0/modules""",1,1
openstack%2Fopenstack-ansible-repo_server~master~I42029576a4e9b86b5614bef613517466944742d3,openstack/openstack-ansible-repo_server,master,I42029576a4e9b86b5614bef613517466944742d3,Remove duplicate readme file,MERGED,2016-02-17 15:50:28.000000000,2016-02-19 10:17:03.000000000,2016-02-19 10:17:03.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 11714}, {'_account_id': 12892}, {'_account_id': 14552}, {'_account_id': 15993}]","[{'number': 1, 'created': '2016-02-17 15:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/ab63a9e9d5b4f9757b7462d0b0bffcee74e35646', 'message': 'Duplicate READMEs in Repo README.rst expected, renamed file to all caps. Looks liek a deletion, but actually is rename\n\nChange-Id: I42029576a4e9b86b5614bef613517466944742d3\n'}, {'number': 2, 'created': '2016-02-17 15:57:37.000000000', 'files': ['readme.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/3dcdbebf6c5dd8039985b3dd7b6c9b69a37d4633', 'message': 'Remove duplicate readme file\n\nThis fix will remove the duplicate readme file and retain the \ncorrect README.rst file only\n\nChange-Id: I42029576a4e9b86b5614bef613517466944742d3\n'}]",0,281348,3dcdbebf6c5dd8039985b3dd7b6c9b69a37d4633,18,8,2,6877,,,0,"Remove duplicate readme file

This fix will remove the duplicate readme file and retain the 
correct README.rst file only

Change-Id: I42029576a4e9b86b5614bef613517466944742d3
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/48/281348/2 && git format-patch -1 --stdout FETCH_HEAD,['readme.rst'],1,ab63a9e9d5b4f9757b7462d0b0bffcee74e35646,updatereadme,,"OpenStack repo server ##################### :tags: openstack, repo, server, cloud, ansible :category: \*nix Role to deploy a repository server for both python packages and git sources. .. code-block:: yaml - name: Setup repo servers hosts: repo_all user: root roles: - { role: ""repo_server"", tags: [ ""repo-server"" ] } vars: memcached_servers: 127.0.0.1:11211 memcached_encryption_key: secrete ",0,17
openstack%2Fkarbor~master~I8adafbb84745758342a09bba7fd5d5d8227ba26e,openstack/karbor,master,I8adafbb84745758342a09bba7fd5d5d8227ba26e,Implement executor of OperationEngine,ABANDONED,2016-02-19 10:11:38.000000000,2016-02-19 10:16:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-19 10:11:38.000000000', 'files': ['smaug/operationengine/engine/executors/__init__.py', 'smaug/operationengine/engine/executors/base.py', 'smaug/operationengine/engine/executors/thread_pool_executor.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/9579f10e3a296af032688ed2f9930aa5d3215e18', 'message': 'Implement executor of OperationEngine\n\nChange-Id: I8adafbb84745758342a09bba7fd5d5d8227ba26e\nCloses-Bug: #1547392\n'}]",0,282259,9579f10e3a296af032688ed2f9930aa5d3215e18,3,1,1,18266,,,0,"Implement executor of OperationEngine

Change-Id: I8adafbb84745758342a09bba7fd5d5d8227ba26e
Closes-Bug: #1547392
",git fetch https://review.opendev.org/openstack/karbor refs/changes/59/282259/1 && git format-patch -1 --stdout FETCH_HEAD,"['smaug/operationengine/engine/executors/__init__.py', 'smaug/operationengine/engine/executors/base.py', 'smaug/operationengine/engine/executors/thread_pool_executor.py']",3,9579f10e3a296af032688ed2f9930aa5d3215e18,bug/1547392,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from collections import defaultdict from concurrent import futures from datetime import timedelta from oslo_log import log as logging from oslo_utils import timeutils from threading import Lock from smaug import context from smaug.i18n import _LE from smaug import objects from smaug.operationengine.engine.executors import base LOG = logging.getLogger(__name__) class ThreadPoolExecutor(base.BaseExecutor): def __init__(self, operation_manager=None, max_workers=10): super(ThreadPoolExecutor, self).__init__() self._pool = futures.ThreadPoolExecutor(int(max_workers)) self._operation_manager = operation_manager self._operation_to_run = defaultdict(lambda: 0) self._operation_to_cancel = set() self._lock = Lock() def shutdown(self, wait=True): self._pool.shutdown(wait) self._operation_to_run.clear() self._operation_to_cancel.clear() def cancel_operation(self, operation_id): with self._lock: self._operation_to_cancel.add(operation_id) def _do_submit_operation(self, operation_id, expect_start_time, window_time, log_id): def callback(f=None): self._finish_operation(operation_id) f = self._pool.submit(self._run_operation, operation_id, expect_start_time, window_time, log_id) f.add_done_callback(callback) with self._lock: self._operation_to_run[operation_id] += 1 def _finish_operation(self, operation_id): with self._lock: self._operation_to_run[operation_id] -= 1 if 0 == self._operation_to_run[operation_id]: del self._operation_to_run[operation_id] if operation_id in self._operation_to_cancel: self._operation_to_cancel.remove(operation_id) def _run_operation(self, operation_id, expect_start_time, window_time, log_id): if operation_id in self._operation_to_cancel: return ctxt = context.get_admin_context() try: log_ref = objects.ScheduledOperationLog.get_by_id(ctxt, log_id) except Exception: LOG.exception(_LE(""Run operation(%(o_id)s), get log(%(l_id)s)"" ""obj failed""), {""o_id"": operation_id, ""o_id"": log_id}) return if expect_start_time and window_time: grace_time = timedelta(seconds=window_time) now = timeutils.utcnow().replace(microsecond=0) difference = now - expect_start_time if difference > grace_time: log_ref.end_time = now log_ref.actual_start_time = now log_ref.state = 'dropped_out_of_window' try: log_ref.save() except Exception: LOG.exception(_LE(""Run operation(%s), save log failed""), operation_id) return try: operation = objects.ScheduledOperation.get_by_id(ctxt, operation_id) except Exception: LOG.exception(_LE(""Run operation(%s), get operation failed""), operation_id) return try: self._operation_manager.execute_operation( operation.operation_type, operation.project_id, operation.operation_definition, log_ref) except Exception: LOG.exception(_LE(""Run operation(%s), get exception""), operation_id) ",,171,0
openstack%2Fkarbor~master~I3b78c34c76d93c7f6b92215b76bf303ccb4463c6,openstack/karbor,master,I3b78c34c76d93c7f6b92215b76bf303ccb4463c6,Implement executor of OperationEngine,ABANDONED,2016-02-19 10:11:38.000000000,2016-02-19 10:13:27.000000000,,[],"[{'number': 1, 'created': '2016-02-19 10:11:38.000000000', 'files': ['smaug/operationengine/engine/executors/base.py', 'smaug/operationengine/engine/executors/thread_pool_executor.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/95f2e6bcd1a0238e1eeaf19c0e6d52616fba511b', 'message': 'Implement executor of OperationEngine\n\nChange-Id: I3b78c34c76d93c7f6b92215b76bf303ccb4463c6\nCloses-Bug: #1547392\n'}]",0,282260,95f2e6bcd1a0238e1eeaf19c0e6d52616fba511b,2,0,1,18266,,,0,"Implement executor of OperationEngine

Change-Id: I3b78c34c76d93c7f6b92215b76bf303ccb4463c6
Closes-Bug: #1547392
",git fetch https://review.opendev.org/openstack/karbor refs/changes/60/282260/1 && git format-patch -1 --stdout FETCH_HEAD,"['smaug/operationengine/engine/executors/base.py', 'smaug/operationengine/engine/executors/thread_pool_executor.py']",2,95f2e6bcd1a0238e1eeaf19c0e6d52616fba511b,bug/1547392,"from oslo_config import cfg executor_opts = [ cfg.IntOpt('thread_count', default=10, help='The count of thread which executor will start') ] CONF = cfg.CONF CONF.register_opts(executor_opts) def __init__(self, operation_manager=None, thread_count=10): if thread_count is None: thread_count = CONF.thread_count self._pool = futures.ThreadPoolExecutor(thread_count) "," def __init__(self, operation_manager=None, max_workers=10): self._pool = futures.ThreadPoolExecutor(int(max_workers)) ",27,4
openstack%2Fpuppet-cinder~master~Iaf5315a0d6532f3166b9a07fc61f41c6b0b15cc2,openstack/puppet-cinder,master,Iaf5315a0d6532f3166b9a07fc61f41c6b0b15cc2,Allow customization of DEFAULT/host,MERGED,2016-02-18 13:33:53.000000000,2016-02-19 10:12:11.000000000,2016-02-18 18:40:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7745}, {'_account_id': 14007}]","[{'number': 1, 'created': '2016-02-18 13:33:53.000000000', 'files': ['manifests/init.pp', 'spec/classes/cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/d3a93d44050326571ce47948039504f43da93bdb', 'message': ""Allow customization of DEFAULT/host\n\nThe 'host' setting is frequently changed in HA scenarios where\nmultiple instances of the cinder services are meant to behave\nas a single one.\n\nChange-Id: Iaf5315a0d6532f3166b9a07fc61f41c6b0b15cc2\n""}]",0,281851,d3a93d44050326571ce47948039504f43da93bdb,12,5,1,6796,,,0,"Allow customization of DEFAULT/host

The 'host' setting is frequently changed in HA scenarios where
multiple instances of the cinder services are meant to behave
as a single one.

Change-Id: Iaf5315a0d6532f3166b9a07fc61f41c6b0b15cc2
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/51/281851/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/cinder_spec.rb']",2,d3a93d44050326571ce47948039504f43da93bdb,host," describe 'with host' do let :params do req_params.merge({ :host => 'mystring', }) end it { is_expected.to contain_cinder_config('DEFAULT/host').with_value('mystring') } end",,17,0
openstack%2Ftaskflow~master~I6dd68a7f99281701506fb6fa9834985e97573c0d,openstack/taskflow,master,I6dd68a7f99281701506fb6fa9834985e97573c0d,Add missing direct dependency for sqlalchemy-utils,MERGED,2016-02-18 12:49:02.000000000,2016-02-19 10:07:06.000000000,2016-02-19 10:07:05.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-02-18 12:49:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a17c4d715bc072f37e0a51555ff35ac34881f62b', 'message': 'Add missing direct dependency for sqlalchemy-utils\n\noops looks like we missed one\n\nCloses-Bug: #1545895\nChange-Id: I6dd68a7f99281701506fb6fa9834985e97573c0d\n'}]",0,281811,a17c4d715bc072f37e0a51555ff35ac34881f62b,7,3,1,5638,,,0,"Add missing direct dependency for sqlalchemy-utils

oops looks like we missed one

Closes-Bug: #1545895
Change-Id: I6dd68a7f99281701506fb6fa9834985e97573c0d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/11/281811/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a17c4d715bc072f37e0a51555ff35ac34881f62b,bug/1545895, # For sqlalchemy persistence backend sqlalchemy-utils # BSD License,,3,0
openstack%2Foslo.messaging~master~I10d8d7d4134b32e4fc0badfa15e9ffb005910139,openstack/oslo.messaging,master,I10d8d7d4134b32e4fc0badfa15e9ffb005910139,Remove aioeventlet executor,MERGED,2016-02-17 10:29:56.000000000,2016-02-19 10:02:07.000000000,2016-02-19 05:58:52.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 8601}, {'_account_id': 9107}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-02-17 10:29:56.000000000', 'files': ['oslo_messaging/tests/executors/test_executor.py', 'requirements.txt', 'oslo_messaging/_executors/impl_aioeventlet.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d260744773c443f3449e044bfabbe9357b7a3cb5', 'message': 'Remove aioeventlet executor\n\nI wrote the aioeventlet executor as a first step to replace eventlet\nwith trollius in OpenStack. Sadly, the project of replacing eventlet\nwith something else (trollius, threads or whatever) looks to be stuck\nbecause of various reasons. See the spec:\n\n    ""Replace eventlet + monkey-patching with ??""\n    https://review.openstack.org/#/c/164035/\n\nRecently, I deprecated the trollius project in favor of asyncio:\n\n    http://trollius.readthedocs.org/deprecated.html\n\nSince I abandonned my project to replace eventlet with trollius, I\nnow propose to remove the unused aioeventlet executor from Oslo\nMessaging to simplify the code and remove unused dependencies\n(especially trollius).\n\nSince the aioeventlet executor is not used by any application, it\'s\nsafe to remove it. Removing the executor removes trollius and\naioeventlet dependencies.\n\n... The executor may come back ""later"" when the first OpenStack\nservice will start to drop Python 2 support.\n\nFor more information on asyncio in OpenStack, see:\nhttp://aioeventlet.readthedocs.org/openstack.html\n\nNote: the executor was added by the change\nI7a78ed998719a703077232726f66d882463b1297.\n\nChange-Id: I10d8d7d4134b32e4fc0badfa15e9ffb005910139\n'}]",2,281173,d260744773c443f3449e044bfabbe9357b7a3cb5,12,8,1,9107,,,0,"Remove aioeventlet executor

I wrote the aioeventlet executor as a first step to replace eventlet
with trollius in OpenStack. Sadly, the project of replacing eventlet
with something else (trollius, threads or whatever) looks to be stuck
because of various reasons. See the spec:

    ""Replace eventlet + monkey-patching with ??""
    https://review.openstack.org/#/c/164035/

Recently, I deprecated the trollius project in favor of asyncio:

    http://trollius.readthedocs.org/deprecated.html

Since I abandonned my project to replace eventlet with trollius, I
now propose to remove the unused aioeventlet executor from Oslo
Messaging to simplify the code and remove unused dependencies
(especially trollius).

Since the aioeventlet executor is not used by any application, it's
safe to remove it. Removing the executor removes trollius and
aioeventlet dependencies.

... The executor may come back ""later"" when the first OpenStack
service will start to drop Python 2 support.

For more information on asyncio in OpenStack, see:
http://aioeventlet.readthedocs.org/openstack.html

Note: the executor was added by the change
I7a78ed998719a703077232726f66d882463b1297.

Change-Id: I10d8d7d4134b32e4fc0badfa15e9ffb005910139
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/73/281173/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/executors/test_executor.py', 'requirements.txt', 'oslo_messaging/_executors/impl_aioeventlet.py', 'setup.cfg']",4,d260744773c443f3449e044bfabbe9357b7a3cb5,remove_trollius,, aioeventlet = oslo_messaging._executors.impl_aioeventlet:AsyncioEventletExecutor,2,141
openstack%2Ftempest~master~I664b7fa234e431f229dac51e62c529f9ace5d389,openstack/tempest,master,I664b7fa234e431f229dac51e62c529f9ace5d389,Wait and retry while getting server port and ipv4,ABANDONED,2016-02-08 17:42:23.000000000,2016-02-19 09:57:41.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7350}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}]","[{'number': 1, 'created': '2016-02-08 17:42:23.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/54c591b0ab0cf1462bd1cc60ade88b0fe13892e4', 'message': ""Wait and retry while getting server port and ipv4\n\nWhen creating a floating IP and getting the server port and ip address(es)\nit may take some seconds until the port is in 'ACTIVE' state.\nIn a test environment with Xen+libvirt the test failed because the port was\ninitially in 'DOWN' stateand after ~1s it was active.\nSo wait and retry to fix the test case race.\n\nChange-Id: I664b7fa234e431f229dac51e62c529f9ace5d389\n""}]",1,277510,54c591b0ab0cf1462bd1cc60ade88b0fe13892e4,10,6,1,7102,,,0,"Wait and retry while getting server port and ipv4

When creating a floating IP and getting the server port and ip address(es)
it may take some seconds until the port is in 'ACTIVE' state.
In a test environment with Xen+libvirt the test failed because the port was
initially in 'DOWN' stateand after ~1s it was active.
So wait and retry to fix the test case race.

Change-Id: I664b7fa234e431f229dac51e62c529f9ace5d389
",git fetch https://review.opendev.org/openstack/tempest refs/changes/10/277510/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,54c591b0ab0cf1462bd1cc60ade88b0fe13892e4,,"import time # it could take a bit of time to have a 'ACTIVE' port. The port is # maybe in 'DOWN' state so retry some seconds now = time.time() timeout = now + 10 while now < timeout: ports = self._list_ports(device_id=server['id'], status='ACTIVE', fixed_ip=ip_addr) if len(ports): break time.sleep(2) now = time.time() "," ports = self._list_ports(device_id=server['id'], status='ACTIVE', fixed_ip=ip_addr)",13,2
openstack%2Fmurano~master~Ic8a719e874126d735c26b956a49cb790d434c64c,openstack/murano,master,Ic8a719e874126d735c26b956a49cb790d434c64c,Basic reflection capabilities were added to MuranoPL,MERGED,2016-01-25 00:04:01.000000000,2016-02-19 09:52:04.000000000,2016-02-19 09:52:04.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 12597}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-01-25 00:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/34f1f0dc079a775e5a8c8e2d7a8756e971be720a', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 2, 'created': '2016-01-25 11:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ed9987cea8c313374495055c26e1654d28656043', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 3, 'created': '2016-01-26 14:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bcf50194dc454f0ddcada1201616211d9bd80a94', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 4, 'created': '2016-02-13 22:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/35f5efbd3781e5a1907545217dbd438dc3a410da', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 5, 'created': '2016-02-13 23:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ddea7cce38c90bc13a6ec3267670cf3730c39740', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 6, 'created': '2016-02-15 00:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a091927694464d1836b231f2991f0b89577062e0', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 7, 'created': '2016-02-17 00:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1c44c683512a82fc62fd9a0f7b684de1c97ce940', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 8, 'created': '2016-02-17 12:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d8cf02e401f2dd780ce807c6873ba8fd259023da', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 9, 'created': '2016-02-17 20:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1b5ffcd52a6dcc4575ae7ffd4315fa3cadc1fbd7', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 10, 'created': '2016-02-18 00:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0d3546fcbe6419e6768499f8830479e43b98bc0b', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 11, 'created': '2016-02-18 01:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c00e33bef8e8490df00288ca79159d52579cde3d', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 12, 'created': '2016-02-18 14:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/71f98f806f5c8ea70c2efa18121fbed98d3c2f82', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 13, 'created': '2016-02-18 16:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/9860500fac23258d433512e89f5e1e3061eb4863', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}, {'number': 14, 'created': '2016-02-18 22:22:12.000000000', 'files': ['murano/dsl/exceptions.py', 'murano/dsl/typespec.py', 'murano/dsl/attribute_store.py', 'murano/dsl/reflection.py', 'murano/dsl/murano_class.py', 'murano/dsl/yaql_functions.py', 'murano/dsl/helpers.py', 'murano/tests/unit/dsl/meta/TestReflection.yaml', 'murano/dsl/dsl.py', 'murano/dsl/murano_package.py', 'murano/engine/mock_context_manager.py', 'murano/dsl/murano_property.py', 'murano/dsl/murano_method.py', 'murano/tests/unit/dsl/test_reflection.py', 'releasenotes/notes/basic-reflection-2fc43b990ea6b980.yaml', 'murano/dsl/dsl_types.py', 'murano/dsl/murano_object.py', 'murano/tests/unit/dsl/foundation/test_package_loader.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/f4ff2fb482f65666e25bb7eede5ff9b96111919b', 'message': 'Basic reflection capabilities were added to MuranoPL\n\nNow it is possible to get type info with typeinfo() function and using\nit as a starting point obtain information about the class, its methods\nand properties as well as the package of the class.\nSee TestReflection.yaml for detailed usage.\n\nAlso some refactoring to existing code model were made.\n\nChange-Id: Ic8a719e874126d735c26b956a49cb790d434c64c\n'}]",5,271857,f4ff2fb482f65666e25bb7eede5ff9b96111919b,78,9,14,7226,,,0,"Basic reflection capabilities were added to MuranoPL

Now it is possible to get type info with typeinfo() function and using
it as a starting point obtain information about the class, its methods
and properties as well as the package of the class.
See TestReflection.yaml for detailed usage.

Also some refactoring to existing code model were made.

Change-Id: Ic8a719e874126d735c26b956a49cb790d434c64c
",git fetch https://review.opendev.org/openstack/murano refs/changes/57/271857/14 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/exceptions.py', 'murano/dsl/typespec.py', 'murano/dsl/attribute_store.py', 'murano/dsl/murano_class.py', 'murano/dsl/yaql_functions.py', 'murano/dsl/helpers.py', 'murano/tests/unit/dsl/meta/TestReflection.yaml', 'murano/dsl/dsl.py', 'murano/dsl/murano_package.py', 'murano/engine/mock_context_manager.py', 'murano/dsl/murano_property.py', 'murano/dsl/yaqlization.py', 'murano/dsl/murano_method.py', 'murano/tests/unit/dsl/test_reflection.py', 'releasenotes/notes/basic-reflection-2fc43b990ea6b980.yaml', 'murano/dsl/dsl_types.py', 'murano/dsl/murano_object.py', 'murano/tests/unit/dsl/foundation/test_package_loader.py']",18,34f1f0dc079a775e5a8c8e2d7a8756e971be720a,static-methods,"from murano.dsl import constants self, package_name, None, constants.RUNTIME_VERSION_1_0, None, self._configs)"," self, package_name, None, '1.0', None, self._configs)",797,113
openstack%2Fmagnum~master~I748a7bce87ba1ce01b2a89a77b5da72566f5c0ea,openstack/magnum,master,I748a7bce87ba1ce01b2a89a77b5da72566f5c0ea,Add missing test-requirements,MERGED,2016-02-18 14:01:50.000000000,2016-02-19 09:51:25.000000000,2016-02-19 09:51:25.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 12053}]","[{'number': 1, 'created': '2016-02-18 14:01:50.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/76a645678139f7a47be6ee8941d7f1da71fd064d', 'message': 'Add missing test-requirements\n\npytz is needed in our unit tests.\n\nChange-Id: I748a7bce87ba1ce01b2a89a77b5da72566f5c0ea\n'}]",0,281878,76a645678139f7a47be6ee8941d7f1da71fd064d,7,3,1,17081,,,0,"Add missing test-requirements

pytz is needed in our unit tests.

Change-Id: I748a7bce87ba1ce01b2a89a77b5da72566f5c0ea
",git fetch https://review.opendev.org/openstack/magnum refs/changes/78/281878/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,76a645678139f7a47be6ee8941d7f1da71fd064d,add-requirments,pytz>=2013.6 # MIT,,1,0
openstack%2Fsenlin~master~Ia2ba144c6ed84c7482366f04c4e982fb8762cb01,openstack/senlin,master,Ia2ba144c6ed84c7482366f04c4e982fb8762cb01,Add senlin dashboard info in README.rst file,MERGED,2016-02-19 04:21:35.000000000,2016-02-19 09:47:37.000000000,2016-02-19 09:47:36.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-19 04:21:35.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/dbfb3247216fd2c8ff9daae0dca884d5ad287d18', 'message': 'Add senlin dashboard info in README.rst file\n\nChange-Id: Ia2ba144c6ed84c7482366f04c4e982fb8762cb01\n'}]",0,282160,dbfb3247216fd2c8ff9daae0dca884d5ad287d18,11,3,1,6763,,,0,"Add senlin dashboard info in README.rst file

Change-Id: Ia2ba144c6ed84c7482366f04c4e982fb8762cb01
",git fetch https://review.opendev.org/openstack/senlin refs/changes/60/282160/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,dbfb3247216fd2c8ff9daae0dca884d5ad287d18,update_readme,- Dashboard: https://launchpad.net/senlin-dashboard- Dashboard: https://git.openstack.org/cgit/openstack/senlin-dashboard,,2,0
openstack%2Fsenlin~master~Ifbb3934f53ec315ba551ed6f42d199c884a986ae,openstack/senlin,master,Ifbb3934f53ec315ba551ed6f42d199c884a986ae,Enforce multi-tenancy for event find,MERGED,2016-02-18 05:41:30.000000000,2016-02-19 09:46:15.000000000,2016-02-19 09:46:15.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-18 05:41:30.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_events.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/320d0e541122c6baf379e9fc83e5d7f5e2319c02', 'message': 'Enforce multi-tenancy for event find\n\nThis patch adds project_safe checking for event finding.\n\nChange-Id: Ifbb3934f53ec315ba551ed6f42d199c884a986ae\n'}]",0,281640,320d0e541122c6baf379e9fc83e5d7f5e2319c02,7,4,1,8246,,,0,"Enforce multi-tenancy for event find

This patch adds project_safe checking for event finding.

Change-Id: Ifbb3934f53ec315ba551ed6f42d199c884a986ae
",git fetch https://review.opendev.org/openstack/senlin refs/changes/40/281640/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_events.py']",2,320d0e541122c6baf379e9fc83e5d7f5e2319c02,event-project-safe," result = self.eng.event_find(self.ctx, aid, False) mock_get.assert_called_once_with(self.ctx, aid, project_safe=False) mock_shortid.assert_called_once_with(self.ctx, aid, project_safe=False)"," result = self.eng.event_find(self.ctx, aid) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) mock_shortid.assert_called_once_with(self.ctx, aid, project_safe=True)",13,10
openstack%2Fopenstack-manuals~master~Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1,openstack/openstack-manuals,master,Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1,Adding content about auditing with CADF,MERGED,2016-02-17 06:52:55.000000000,2016-02-19 09:42:41.000000000,2016-02-19 09:42:41.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14962}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-02-17 06:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f66d9f25dcbf6c2da4973324a67b9c1a54b4a529', 'message': 'Adding content about auditing with CADF\n\nCreated new Keystone section for Auditing, copied existing CADF\ncontent from keystone /developer docs.\n\nChange-Id: Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1\nCloses-Bug: #1281766\n'}, {'number': 2, 'created': '2016-02-18 02:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e16479cfdf39abbb2b21acc4578cb75359b14655', 'message': 'Adding content about auditing with CADF\n\nCreated new Keystone section for Auditing, copied existing CADF\ncontent from keystone /developer docs.\n\nChange-Id: Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1\nCloses-Bug: #1281766\n'}, {'number': 3, 'created': '2016-02-19 03:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0863dc5e836da636850a087c4391b0bc14b1e7c3', 'message': 'Adding content about auditing with CADF\n\nCreated new Keystone section for Auditing, copied existing CADF\ncontent from keystone /developer docs.\n\nChange-Id: Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1\nCloses-Bug: #1281766\n'}, {'number': 4, 'created': '2016-02-19 05:11:31.000000000', 'files': ['doc/config-reference/source/identity.rst', 'doc/config-reference/source/identity/auditing.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0be4bd83d7a1f4790a935a272cc7f2e67c3fe09c', 'message': 'Adding content about auditing with CADF\n\nCreated new Keystone section for Auditing, copied existing CADF\ncontent from keystone /developer docs.\n\nChange-Id: Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1\nCloses-Bug: #1281766\n'}]",16,281075,0be4bd83d7a1f4790a935a272cc7f2e67c3fe09c,24,6,4,9162,,,0,"Adding content about auditing with CADF

Created new Keystone section for Auditing, copied existing CADF
content from keystone /developer docs.

Change-Id: Ic85d6a7fb639a760035d7b6c4dca32ee5130dee1
Closes-Bug: #1281766
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/75/281075/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/identity.rst', 'openstack-networking-guide', 'doc/config-reference/source/identity/auditing.rst']",3,f66d9f25dcbf6c2da4973324a67b9c1a54b4a529,bug/1281766,"================== Auditing with CADF ================== Keystone uses the `PyCADF`_ library to emit CADF notifications, these events adhere to the DMTF `CADF`_ specification. This standard provides auditing capabilities for compliance with security, operational, and business processes and supports normalized and categorized event data for federation and aggregation. .. _PyCADF: http://docs.openstack.org/developer/pycadf .. _CADF: http://www.dmtf.org/standards/cadf CADF notifications include additional context data around the ``resource``, the ``action`` and the ``initiator``. CADF notifications may be emitted by changing the ``notification_format`` to ``cadf`` in the configuration file. The ``payload`` portion of a CADF Notification is a CADF ``event``, which is represented as a JSON dictionary. For example: .. code-block:: javascript { ""typeURI"": ""http://schemas.dmtf.org/cloud/audit/1.0/event"", ""initiator"": { ""typeURI"": ""service/security/account/user"", ""host"": { ""agent"": ""curl/7.22.0(x86_64-pc-linux-gnu)"", ""address"": ""127.0.0.1"" }, ""id"": ""<initiator_id>"" }, ""target"": { ""typeURI"": ""<target_uri>"", ""id"": ""openstack:1c2fc591-facb-4479-a327-520dade1ea15"" }, ""observer"": { ""typeURI"": ""service/security"", ""id"": ""openstack:3d4a50a9-2b59-438b-bf19-c231f9c7625a"" }, ""eventType"": ""activity"", ""eventTime"": ""2014-02-14T01:20:47.932842+00:00"", ""action"": ""<action>"", ""outcome"": ""success"", ""id"": ""openstack:f5352d7b-bee6-4c22-8213-450e7b646e9f"", } Where the following are defined: * ``<initiator_id>``: ID of the user that performed the operation * ``<target_uri>``: CADF specific target URI, (i.e.: data/security/project) * ``<action>``: The action being performed, typically: ``<operation>``. ``<resource_type>`` Additionally there may be extra keys present depending on the operation being performed, these will be discussed below. Note, the ``eventType`` property of the CADF payload is different from the ``event_type`` property of a notifications. The former (``eventType``) is a CADF keyword which designates the type of event that is being measured, this can be: `activity`, `monitor` or `control`. Whereas the latter (``event_type``) is described in previous sections as: `identity.<resource_type>.<operation>` ",,67,0
openstack%2Ffuel-octane~stable%2F8.0~Id34986f42dd9944969475d5e0c1bec9814746b5f,openstack/fuel-octane,stable/8.0,Id34986f42dd9944969475d5e0c1bec9814746b5f,Start container before systemd unit for nailgun and keystone,MERGED,2016-02-18 13:36:23.000000000,2016-02-19 09:38:24.000000000,2016-02-19 05:44:36.000000000,"[{'_account_id': 3}, {'_account_id': 6677}, {'_account_id': 14348}]","[{'number': 1, 'created': '2016-02-18 13:36:23.000000000', 'files': ['octane/tests/test_archivators_restore.py', 'octane/util/docker.py', 'octane/handlers/backup_restore/postgres.py', 'octane/tests/conftest.py', 'octane/tests/test_docker.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/a4f274f88620dfcafd2d4cd2f75acf8bff3f6e9a', 'message': ""Start container before systemd unit for nailgun and keystone\n\nDockerctl improperly detects readyness of docker container. Thus,\nwe need to start the container before corresponding systemd unit\n(service).\n\nRun container first ensures that the systemd unit properly finishes\nits work.\n\nAdd wait function to check if container is ready as a fix for race\ncondition in dockerctl's check_ready function (bug #1545825).\n\nChange-Id: Id34986f42dd9944969475d5e0c1bec9814746b5f\nCloses-bug: 1545825\n(cherry picked from commit 0144ae69625f189e9e693554c1b7c8694eb19ae4)\n""}]",0,281853,a4f274f88620dfcafd2d4cd2f75acf8bff3f6e9a,8,3,1,6677,,,0,"Start container before systemd unit for nailgun and keystone

Dockerctl improperly detects readyness of docker container. Thus,
we need to start the container before corresponding systemd unit
(service).

Run container first ensures that the systemd unit properly finishes
its work.

Add wait function to check if container is ready as a fix for race
condition in dockerctl's check_ready function (bug #1545825).

Change-Id: Id34986f42dd9944969475d5e0c1bec9814746b5f
Closes-bug: 1545825
(cherry picked from commit 0144ae69625f189e9e693554c1b7c8694eb19ae4)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/53/281853/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/util/docker.py', 'octane/tests/conftest.py', 'octane/tests/test_docker.py']",5,a4f274f88620dfcafd2d4cd2f75acf8bff3f6e9a,bug/1545825," test_container = ""test_container"" attempts = 2 delay = 0 def test_wait_for_start_container(mocker, mock_subprocess): proc = mock_subprocess.return_value.__enter__.return_value proc.communicate.side_effect = [ (""ActiveState=activating\n\n"", None), (""ActiveState=active\n\n"", None), ] docker._wait_for_start_container(test_container, attempts, delay) assert 2 == mock_subprocess.call_count def test_wait_for_puppet_in_container(mocker, mock_subprocess): mock_subprocess.side_effect = [ mock.DEFAULT, subprocess.CalledProcessError(1, 'test_error') ] docker._wait_for_puppet_in_container(test_container, attempts, delay) assert 2 == mock_subprocess.call_count",,78,3
openstack%2Ffuel-octane~stable%2F8.0~I3809d2a4439d5d0866a7e29ee70a68e54c123c4f,openstack/fuel-octane,stable/8.0,I3809d2a4439d5d0866a7e29ee70a68e54c123c4f,Run puppet agent in the end of restore,MERGED,2016-02-18 17:21:15.000000000,2016-02-19 09:37:54.000000000,2016-02-19 05:48:46.000000000,"[{'_account_id': 3}, {'_account_id': 6677}, {'_account_id': 14348}]","[{'number': 1, 'created': '2016-02-18 17:21:15.000000000', 'files': ['octane/handlers/backup_restore/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/bf1bb9aab941116065bf4d376e2f1b83ae5e4ab8', 'message': 'Run puppet agent in the end of restore\n\nAdd class for puppet agent run in octane.handlers.backup_restore.puppet\nmodule. Add this class to archivators pipeline in the end of the\nprocedure. Call puppet agent for restore method only.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n(cherry picked from commit 30b775d528805726104ceb5913ca66e03fb3d790)\n'}]",0,281966,bf1bb9aab941116065bf4d376e2f1b83ae5e4ab8,7,3,1,6677,,,0,"Run puppet agent in the end of restore

Add class for puppet agent run in octane.handlers.backup_restore.puppet
module. Add this class to archivators pipeline in the end of the
procedure. Call puppet agent for restore method only.

Change-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f
Related-bug: 1544967
(cherry picked from commit 30b775d528805726104ceb5913ca66e03fb3d790)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/66/281966/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/handlers/backup_restore/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/__init__.py']",4,bf1bb9aab941116065bf4d376e2f1b83ae5e4ab8,bug/1544967," puppet.PuppetApplyHost,",,14,5
openstack%2Ftripleo-heat-templates~master~I38840e082ee01dc3b6fc78e1dd97f53fa4e63039,openstack/tripleo-heat-templates,master,I38840e082ee01dc3b6fc78e1dd97f53fa4e63039,Add TripleO Heat Template Parameters for Neutron Tenant MTU,MERGED,2016-01-29 02:23:03.000000000,2016-02-19 09:36:07.000000000,2016-02-19 09:36:07.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-01-29 02:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/51ad181d1d130daa88ebfbab9e6ec6dc2d99cc83', 'message': 'Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. The veth\ndevices that get created to serve as the virtual network interfaces\nfor the VMs get created with an MTU according to these settings:\n\nin /etc/nova/nova.conf:\nnetwork_device_mtu = <MTU>\n\nin /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini:\nveth_mtu = <MTU>\n\nThese settings are related to the NeutronDnsmasqOptions, since\nthat is typically used to set the MTU through DHCP for VM hosts.\n\nTypically, you would change all three of these settings to use\njumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that the Puppet hieradata output in this change still needs\nto be addressed in related Puppet changes, probably to both the\nNova and Neutron Puppet modules.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n'}, {'number': 2, 'created': '2016-02-16 00:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9465841851ca5e802bbdbe40f1d7d9894d39424d', 'message': 'Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. The veth\ndevices that get created to serve as the virtual network interfaces\nfor the VMs get created with an MTU according to these settings:\n\nin /etc/nova/nova.conf:\nnetwork_device_mtu = <MTU>\n\nin /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini:\nveth_mtu = <MTU>\n\nThese settings are related to the NeutronDnsmasqOptions, since\nthat is typically used to set the MTU through DHCP for VM hosts.\n\nTypically, you would change all three of these settings to use\njumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that the Puppet hieradata output in this change still needs\nto be addressed in related Puppet changes, probably to both the\nNova and Neutron Puppet modules.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n'}, {'number': 3, 'created': '2016-02-16 01:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55e8f45fb12670f973c099c43fdbaff5b6ee66ff', 'message': 'Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. The veth\ndevices that get created to serve as the virtual network interfaces\nfor the VMs get created with an MTU according to these settings:\n\nin /etc/nova/nova.conf:\nnetwork_device_mtu = <MTU>\n\nin /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini:\nveth_mtu = <MTU>\n\nThese settings are related to the NeutronDnsmasqOptions, since\nthat is typically used to set the MTU through DHCP for VM hosts.\n\nTypically, you would change all three of these settings to use\njumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that the Puppet hieradata output in this change still needs\nto be addressed in related Puppet changes, probably to both the\nNova and Neutron Puppet modules.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n'}, {'number': 4, 'created': '2016-02-16 19:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b01cabe39e9d125319ac7a1ccdbc23602e0416bc', 'message': ""Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. A new\nparameter, NeutronTenantMtu is introduced, and this gets used for\nthe NeutronDnsmasqOptions and in Puppet hieradata.\n\nThe veth devices that get created to serve as the virtual network\ninterfaces for the VMs that get created with an MTU according to\nthese settings:\n\nin /etc/nova/nova.conf on Controllers and Computes:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nin /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini\non Controllers and Computes:\nveth_mtu = <NeutronTenantMtu>\n\nin /etc/neutron/l3agent.ini on Controllers only:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nfinally, the NeutronDnsmasqOptions parameter becomes a str_format\nthat maps the NeutronTenantMtu onto the DHCP options:\nparameters:\n  NeutronDnsmasqOptions:\n    default: 'dhcp-option-force=26,%MTU%'\n    description: Dnsmasq options for neutron-dhcp-agent. The default value here forces MTU to be set to 1400 to account for the tunnel overhead.\n\n Controller:\n     [...]\n        properties:\n          NeutronDnsmasqOptions:\n            str_replace:\n              template: {get_param: NeutronDnsmasqOptionsFormat}\n              params:\n                '%MTU%': {get_param: NeutronTenantMtu}\n\nThis will set dnsmasq to serve an MTU via DHCP that matches the\nNeutronTenantMtu.\n\nTypically, you would change all three of these settings to use\njumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that the Puppet hieradata output in this change still needs\nto be addressed in related Puppet changes, probably to both the\nNova and Neutron Puppet modules.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n""}, {'number': 5, 'created': '2016-02-16 20:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b0f8bf34d72981091ad813803cc803972ba96547', 'message': ""Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. A new\nparameter, NeutronTenantMtu is introduced, and this gets used for\nthe NeutronDnsmasqOptions and in Puppet hieradata.\n\nThe veth devices that get created to serve as the virtual network\ninterfaces for the VMs that get created with an MTU according to\nthese settings:\n\nin /etc/nova/nova.conf on Controllers and Computes:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nin /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini\non Controllers and Computes:\nveth_mtu = <NeutronTenantMtu>\n\nin /etc/neutron/l3agent.ini on Controllers only:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nfinally, the NeutronDnsmasqOptions parameter becomes a str_format\nthat maps the NeutronTenantMtu onto the DHCP options:\nparameters:\n  NeutronDnsmasqOptions:\n    default: 'dhcp-option-force=26,%MTU%'\n    description: Dnsmasq options for neutron-dhcp-agent. The default value here forces MTU to be set to 1400 to account for the tunnel overhead.\n\n Controller:\n     [...]\n        properties:\n          NeutronDnsmasqOptions:\n            str_replace:\n              template: {get_param: NeutronDnsmasqOptions}\n              params:\n                '%MTU%': {get_param: NeutronTenantMtu}\n\nThis will set dnsmasq to serve an MTU via DHCP that matches the\nNeutronTenantMtu.\n\nTypically, you would change all three of these settings to use\njumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that the Puppet hieradata output in this change still needs\nto be addressed in related Puppet changes, probably to both the\nNova and Neutron Puppet modules.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n""}, {'number': 6, 'created': '2016-02-16 23:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/737419b414083c896c575a8c5f8ae61e1e949bc5', 'message': ""Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. A new\nparameter, NeutronTenantMtu is introduced, and this gets used for\nthe NeutronDnsmasqOptions and in Puppet hieradata.\n\nThe veth devices that get created to serve as the virtual network\ninterfaces for the VMs that get created with an MTU according to\nthese settings:\n\nin /etc/nova/nova.conf on Controllers and Computes:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nin /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini\non Controllers and Computes:\nveth_mtu = <NeutronTenantMtu>\n\nin /etc/neutron/l3agent.ini on Controllers only:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nfinally, the NeutronDnsmasqOptions parameter becomes a str_format\nthat maps the NeutronTenantMtu onto the DHCP options:\nparameters:\n  NeutronDnsmasqOptions:\n    default: 'dhcp-option-force=26,%MTU%'\n    description: Dnsmasq options for neutron-dhcp-agent. The default value here forces MTU to be set to 1400 to account for the tunnel overhead.\n\n Controller:\n     [...]\n        properties:\n          NeutronDnsmasqOptions:\n            str_replace:\n              template: {get_param: NeutronDnsmasqOptions}\n              params:\n                '%MTU%': {get_param: NeutronTenantMtu}\n\nThis will set dnsmasq to serve an MTU via DHCP that matches the\nNeutronTenantMtu.\n\nTypically, you would change all three of these settings to use\njumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that the Puppet hieradata output in this change still needs\nto be addressed in related Puppet changes, probably to both the\nNova and Neutron Puppet modules.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n""}, {'number': 7, 'created': '2016-02-17 08:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0f9220d9d75d046306c053ec9046095b88636de', 'message': ""Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. A new\nparameter, NeutronTenantMtu is introduced, and this gets used for\nthe NeutronDnsmasqOptions and in Puppet hieradata.\n\nNeutronTenantMtu is also used in the Puppet hieradata for both the\ncompute and control nodes. Two values are set:\n\nnova::compute::network_device_mtu\n\nwhich sets /etc/nova/nova.conf: network_device_mtu = <NeutronTenantMtu>\n\nneutron::network_device_mtu\n\nwhich sets in /etc/neutron/neutron.conf:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nfinally, the NeutronDnsmasqOptions parameter becomes a str_format\nthat maps the NeutronTenantMtu onto the DHCP options,\nso a default of 'dhcp-option-force=26,%MTU%' would be formatted to\n'dhcp-option-force=26,1300' if NeutronTenantMtu were 1300.\n\nThis will set dnsmasq to serve an MTU via DHCP that matches the\nNeutronTenantMtu:\n\n/etc/neutron/dnsmasq-neutron.conf:dhcp-option-force=26,1300\n\nTypically, you would change all three of these settings to use small\nor jumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that this change does not support setting the MTU on veth\ninterfaces if veth patches are used to br-int instead of OVS\npatches.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n""}, {'number': 8, 'created': '2016-02-17 18:49:55.000000000', 'files': ['puppet/controller.yaml', 'overcloud.yaml', 'puppet/compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d73d74f4be1c994ed45afb32b253faf4a2d16d74', 'message': ""Add TripleO Heat Template Parameters for Neutron Tenant MTU\n\nThis change adds the TripleO Heat Parameters and Puppet hieradata\nto support setting the MTU for Neutron tenant networks. A new\nparameter, NeutronTenantMtu is introduced, and this gets used for\nthe NeutronDnsmasqOptions and in Puppet hieradata.\n\nNeutronTenantMtu is also used in the Puppet hieradata for both the\ncompute and control nodes. Two values are set:\n\nnova::compute::network_device_mtu\n\nwhich sets /etc/nova/nova.conf: network_device_mtu = <NeutronTenantMtu>\n\nneutron::network_device_mtu\n\nwhich sets in /etc/neutron/neutron.conf:\nnetwork_device_mtu = <NeutronTenantMtu>\n\nfinally, the NeutronDnsmasqOptions parameter becomes a str_format\nthat maps the NeutronTenantMtu onto the DHCP options,\nso a default of 'dhcp-option-force=26,%MTU%' would be formatted to\n'dhcp-option-force=26,1300' if NeutronTenantMtu were 1300.\n\nThis will set dnsmasq to serve an MTU via DHCP that matches the\nNeutronTenantMtu:\n\n/etc/neutron/dnsmasq-neutron.conf:dhcp-option-force=26,1300\n\nTypically, you would change all three of these settings to use small\nor jumbo frames in VMs. When using tunneling, NeutronTenantMtu\nshould be set at least 50 bytes smaller than the physical network\nMTU in order to make room for tunneling overhead.\n\nNote that this change does not support setting the MTU on veth\ninterfaces if veth patches are used to br-int instead of OVS\npatches.\n\nChange-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039\n""}]",4,273847,d73d74f4be1c994ed45afb32b253faf4a2d16d74,31,9,8,12398,,,0,"Add TripleO Heat Template Parameters for Neutron Tenant MTU

This change adds the TripleO Heat Parameters and Puppet hieradata
to support setting the MTU for Neutron tenant networks. A new
parameter, NeutronTenantMtu is introduced, and this gets used for
the NeutronDnsmasqOptions and in Puppet hieradata.

NeutronTenantMtu is also used in the Puppet hieradata for both the
compute and control nodes. Two values are set:

nova::compute::network_device_mtu

which sets /etc/nova/nova.conf: network_device_mtu = <NeutronTenantMtu>

neutron::network_device_mtu

which sets in /etc/neutron/neutron.conf:
network_device_mtu = <NeutronTenantMtu>

finally, the NeutronDnsmasqOptions parameter becomes a str_format
that maps the NeutronTenantMtu onto the DHCP options,
so a default of 'dhcp-option-force=26,%MTU%' would be formatted to
'dhcp-option-force=26,1300' if NeutronTenantMtu were 1300.

This will set dnsmasq to serve an MTU via DHCP that matches the
NeutronTenantMtu:

/etc/neutron/dnsmasq-neutron.conf:dhcp-option-force=26,1300

Typically, you would change all three of these settings to use small
or jumbo frames in VMs. When using tunneling, NeutronTenantMtu
should be set at least 50 bytes smaller than the physical network
MTU in order to make room for tunneling overhead.

Note that this change does not support setting the MTU on veth
interfaces if veth patches are used to br-int instead of OVS
patches.

Change-Id: I38840e082ee01dc3b6fc78e1dd97f53fa4e63039
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/273847/8 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/controller.yaml', 'overcloud.yaml', 'puppet/compute.yaml']",3,51ad181d1d130daa88ebfbab9e6ec6dc2d99cc83,neutron_tenant_mtu," NeutronTenantMtu: description: > The default MTU for tenant networks. For VXLAN/GRE tunneling, this should be at least 50 bytes less than the MTU on the physical network. This value will be used to set the MTU on the virtual Ethernet device. This number is related to the value of NeutronDnsmasqOptions, since that will determine the MTU that is assigned to the VM host through DHCP. default: 1400 type: number neutron::agents::ml2::ovs::veth_mtu: {get_input: neutron_tenant_mtu} nova::network::neutron::network_device_mtu: {get_input: neutron_tenant_mtu} neutron_tenant_mtu: {get_param: NeutronTenantMtu}",,35,0
openstack%2Ffuel-qa~master~Id67d6201cb23e371dc42ec6e818bcbc2ca0fde31,openstack/fuel-qa,master,Id67d6201cb23e371dc42ec6e818bcbc2ca0fde31,Remove outdated field from send_fuel_stats,MERGED,2016-02-16 13:46:39.000000000,2016-02-19 09:34:29.000000000,2016-02-19 09:34:29.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7935}, {'_account_id': 8971}, {'_account_id': 14614}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 16414}]","[{'number': 1, 'created': '2016-02-16 13:46:39.000000000', 'files': ['fuelweb_test/models/nailgun_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a1e72ea1e08ef98391ec694060a7f7e3ba44461a', 'message': 'Remove outdated field from send_fuel_stats\n\nIt is the part of removing Mirantis-specific code from fuel repositories.\n\nRelated to blueprint remove-vendor-code\n\nChange-Id: Id67d6201cb23e371dc42ec6e818bcbc2ca0fde31\n'}]",0,280703,a1e72ea1e08ef98391ec694060a7f7e3ba44461a,16,8,1,10443,,,0,"Remove outdated field from send_fuel_stats

It is the part of removing Mirantis-specific code from fuel repositories.

Related to blueprint remove-vendor-code

Change-Id: Id67d6201cb23e371dc42ec6e818bcbc2ca0fde31
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/03/280703/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/nailgun_client.py'],1,a1e72ea1e08ef98391ec694060a7f7e3ba44461a,bp/remove-vendor-code," def send_fuel_stats(self, enabled=False): params = ('send_anonymous_statistic', 'user_choice_saved')"," def send_fuel_stats(self, enabled=False, user_email=""test@localhost""): params = ('send_anonymous_statistic', 'send_user_info', 'user_choice_saved') if user_email: settings['settings']['statistics']['email']['value'] = user_email",2,5
openstack%2Fproject-config~master~Ic3f1785655862a9857545fb1e718031805b12b53,openstack/project-config,master,Ic3f1785655862a9857545fb1e718031805b12b53,Disable puppet tests for fuel-library 4.x branches,MERGED,2016-02-15 15:33:23.000000000,2016-02-19 09:31:36.000000000,2016-02-19 09:31:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6554}]","[{'number': 1, 'created': '2016-02-15 15:33:23.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f98a9c2d34d02c6e7644d9ac6f0f4adc21c692b6', 'message': 'Disable puppet tests for fuel-library 4.x branches\n\nChange-Id: Ic3f1785655862a9857545fb1e718031805b12b53\n'}]",0,280286,f98a9c2d34d02c6e7644d9ac6f0f4adc21c692b6,7,3,1,13505,,,0,"Disable puppet tests for fuel-library 4.x branches

Change-Id: Ic3f1785655862a9857545fb1e718031805b12b53
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/280286/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,f98a9c2d34d02c6e7644d9ac6f0f4adc21c692b6,fuel-library-4.x, branch: ^(?!stable/(?:4\.0|4\.1|5\.0|5\.1|6\.0|6\.1|7\.0)).*$ branch: ^(?!stable/(?:4\.0|4\.1|5\.0|5\.1|6\.0|6\.1|7\.0)).*$ branch: ^(?!stable/(?:4\.0|4\.1|5\.0|5\.1|6\.0|6\.1|7\.0|8\.0)).*$ branch: ^(?!stable/(?:4\.0|4\.1|5\.0|5\.1|6\.0|6\.1|7\.0)).*$, branch: ^(?!stable/(?:5\.0|5\.1|6\.0|6\.1|7\.0)).*$ branch: ^(?!stable/(?:5\.0|5\.1|6\.0|6\.1|7\.0)).*$ branch: ^(?!stable/(?:5\.0|5\.1|6\.0|6\.1|7\.0|8\.0)).*$ branch: ^(?!stable/(?:5\.0|5\.1|6\.0|6\.1|7\.0)).*$,4,4
openstack%2Fopenstacksdk~master~I70148f5296d62150f75d58fca7700addd00ccf97,openstack/openstacksdk,master,I70148f5296d62150f75d58fca7700addd00ccf97,Adding Check/Recover Actions to Clusters,MERGED,2016-02-16 14:42:00.000000000,2016-02-19 09:29:26.000000000,2016-02-19 09:29:26.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-16 14:42:00.000000000', 'files': ['openstack/cluster/v1/cluster.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_proxy.py', 'openstack/tests/unit/cluster/v1/test_cluster.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ac2a5574b55f305853648196a90caac0115d1dc4', 'message': 'Adding Check/Recover Actions to Clusters\n\nThis patch adds cluster level check and recover into the service of cluster.\n\nChange-Id: I70148f5296d62150f75d58fca7700addd00ccf97\nImplements: blueprint support-health-management-customization\n'}]",0,280735,ac2a5574b55f305853648196a90caac0115d1dc4,7,2,1,15857,,,0,"Adding Check/Recover Actions to Clusters

This patch adds cluster level check and recover into the service of cluster.

Change-Id: I70148f5296d62150f75d58fca7700addd00ccf97
Implements: blueprint support-health-management-customization
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/35/280735/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cluster/v1/cluster.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_proxy.py', 'openstack/tests/unit/cluster/v1/test_cluster.py']",4,ac2a5574b55f305853648196a90caac0115d1dc4,bp/support-health-management-customization," def test_check(self): sot = cluster.Cluster(FAKE) sot['id'] = 'IDENTIFIER' resp = mock.Mock() resp.json = mock.Mock(return_value='') sess = mock.Mock() sess.post = mock.Mock(return_value=resp) self.assertEqual('', sot.check(sess)) url = 'clusters/%s/actions' % sot.id body = {'check': {}} sess.post.assert_called_once_with(url, endpoint_filter=sot.service, json=body) def test_recover(self): sot = cluster.Cluster(FAKE) sot['id'] = 'IDENTIFIER' resp = mock.Mock() resp.json = mock.Mock(return_value='') sess = mock.Mock() sess.post = mock.Mock(return_value=resp) self.assertEqual('', sot.recover(sess)) url = 'clusters/%s/actions' % sot.id body = {'recover': {}} sess.post.assert_called_once_with(url, endpoint_filter=sot.service, json=body)",,84,0
openstack%2Fpython-senlinclient~master~I4c0e8c880a1ef1a29ecb408b804e975788f46397,openstack/python-senlinclient,master,I4c0e8c880a1ef1a29ecb408b804e975788f46397,Add OpenstackClient plugin for cluster profile delete,MERGED,2016-02-17 08:23:07.000000000,2016-02-19 09:28:43.000000000,2016-02-19 09:28:43.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-02-17 08:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/4f858304f6dcbe5a9e775338e8a45a20e39ddf2a', 'message': 'Add OpenstackClient plugin for cluster profile delete\n\nThis change implements the ""openstack cluster profile delete"" command\n  Based on the existing senlin command: senlin profile-delete\n\nChange-Id: I4c0e8c880a1ef1a29ecb408b804e975788f46397\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-02-18 08:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/a9384f26870fad5a8c69c3af0319c93672fc6519', 'message': 'Add OpenstackClient plugin for cluster profile delete\n\nThis change implements the ""openstack cluster profile delete"" command\n  Based on the existing senlin command: senlin profile-delete\n\nChange-Id: I4c0e8c880a1ef1a29ecb408b804e975788f46397\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 3, 'created': '2016-02-18 14:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/64b3e3fba21b433d24b7024c1b49720c9977c119', 'message': 'Add OpenstackClient plugin for cluster profile delete\n\nThis change implements the ""openstack cluster profile delete"" command\n  Based on the existing senlin command: senlin profile-delete\n\nChange-Id: I4c0e8c880a1ef1a29ecb408b804e975788f46397\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 4, 'created': '2016-02-19 08:39:12.000000000', 'files': ['senlinclient/osc/v1/profile.py', 'senlinclient/tests/unit/osc/v1/test_profile.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/a5d3e687aa6e0a6d88e782c48e8dcc657971d0ca', 'message': 'Add OpenstackClient plugin for cluster profile delete\n\nThis change implements the ""openstack cluster profile delete"" command\n  Based on the existing senlin command: senlin profile-delete\n\nChange-Id: I4c0e8c880a1ef1a29ecb408b804e975788f46397\nBlueprint: senlin-support-python-openstackclient\n'}]",12,281107,a5d3e687aa6e0a6d88e782c48e8dcc657971d0ca,22,4,4,18389,,,0,"Add OpenstackClient plugin for cluster profile delete

This change implements the ""openstack cluster profile delete"" command
  Based on the existing senlin command: senlin profile-delete

Change-Id: I4c0e8c880a1ef1a29ecb408b804e975788f46397
Blueprint: senlin-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/07/281107/4 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/osc/v1/profile.py', 'senlinclient/tests/unit/osc/v1/test_profile.py', 'setup.cfg']",3,4f858304f6dcbe5a9e775338e8a45a20e39ddf2a,bp/senlin-support-python-openstackclient, cluster_profile_delete = senlinclient.osc.v1.profile:DeleteProfile,,126,0
openstack%2Fproject-config~master~I47a6fbaad859c4214709da50cd3fac48afe7a364,openstack/project-config,master,I47a6fbaad859c4214709da50cd3fac48afe7a364,networking-ovn: Add install job for kuryr,MERGED,2016-02-09 21:39:16.000000000,2016-02-19 09:13:38.000000000,2016-02-17 17:05:47.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 1923}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 8410}, {'_account_id': 9515}, {'_account_id': 10980}, {'_account_id': 14352}]","[{'number': 1, 'created': '2016-02-09 21:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5175cd74a538f2f108a6fb06384e33782fb85492', 'message': 'networking-ovn: Add an install job for networking-ovn + kuryr\n\nThis simply verifies that Kuryr works when using networking-ovn as\nthe backing neutron plugin.\n\nChange-Id: I47a6fbaad859c4214709da50cd3fac48afe7a364\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 2, 'created': '2016-02-09 21:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1f5ead387ddcb985bfb628ec79a1b1bd69b93cdf', 'message': 'networking-ovn: Add an install job for networking-ovn + kuryr\n\nThis simply verifies that Kuryr works when using networking-ovn as\nthe backing neutron plugin.\n\nChange-Id: I47a6fbaad859c4214709da50cd3fac48afe7a364\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 3, 'created': '2016-02-09 22:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ead5665fd2e0441ed2cc75acad3e7a9ad96cf5a9', 'message': 'networking-ovn: Add an install job for networking-ovn + kuryr\n\nThis simply verifies that Kuryr works when using networking-ovn as\nthe backing neutron plugin.\n\nChange-Id: I47a6fbaad859c4214709da50cd3fac48afe7a364\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 4, 'created': '2016-02-10 15:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ae0d4d6a4ad9fca341fafd4e9c9306e70d34263e', 'message': 'networking-ovn: Add an install job for networking-ovn + kuryr\n\nThis simply verifies that Kuryr works when using networking-ovn as\nthe backing neutron plugin.\n\nDepends-On: Id7f3f9ad8f19ab11971ccc0cc0d554cbe4c7f2da\nChange-Id: I47a6fbaad859c4214709da50cd3fac48afe7a364\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 5, 'created': '2016-02-11 03:49:20.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/networking-ovn.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e0f3ed6bfeb472092fec208b1b5ffc1d6a934b4b', 'message': 'networking-ovn: Add install job for kuryr\n\nThis simply verifies that Kuryr works when using networking-ovn as\nthe backing neutron plugin.\n\nDepends-On: Id7f3f9ad8f19ab11971ccc0cc0d554cbe4c7f2da\nChange-Id: I47a6fbaad859c4214709da50cd3fac48afe7a364\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}]",16,278101,e0f3ed6bfeb472092fec208b1b5ffc1d6a934b4b,31,15,5,105,,,0,"networking-ovn: Add install job for kuryr

This simply verifies that Kuryr works when using networking-ovn as
the backing neutron plugin.

Depends-On: Id7f3f9ad8f19ab11971ccc0cc0d554cbe4c7f2da
Change-Id: I47a6fbaad859c4214709da50cd3fac48afe7a364
Signed-off-by: Kyle Mestery <mestery@mestery.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/278101/4 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/networking-ovn.yaml'],1,5175cd74a538f2f108a6fb06384e33782fb85492,kuryr-ovn," name: '{pipeline}-install-dsvm-networking-ovn-kuryr{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=120 export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST=0 export OVERRIDE_ENABLED_SERVICES=kuryr,etcd-server,docker-engine,key,n-api,n-cpu,n-cond,n-sch,n-crt,n-cauth,n-obj,g-api,g-reg,c-sch,c-api,c-vol,horizon,rabbit,tempest,mysql,dstat export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export PROJECTS=""openstack/networking-ovn openstack/kuryr $PROJECTS"" export DEVSTACK_LOCAL_CONFIG=""enable_plugin networking-ovn git://git.openstack.org/openstack/networking-ovn"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin kuryr http://git.openstack.org/openstack/kuryr"" # Keep localrc to be able to set some vars in pre_test_hook export KEEP_LOCALRC=1 cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template:",,41,0
openstack%2Ffuel-devops~release%2F2.9~I55d83c905c5863159f727f0ca7d73444adf54c18,openstack/fuel-devops,release/2.9,I55d83c905c5863159f727f0ca7d73444adf54c18,Bump fuel-devops version up to 2.9.19,MERGED,2016-02-18 19:25:32.000000000,2016-02-19 09:11:18.000000000,2016-02-19 09:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-02-18 19:25:32.000000000', 'files': ['docs/source/conf.py', 'setup.py', 'devops/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a1ea63bb96497f10aeb03aa755bdb7516c4a82d9', 'message': 'Bump fuel-devops version up to 2.9.19\n\nChange-Id: I55d83c905c5863159f727f0ca7d73444adf54c18\n'}]",0,282016,a1ea63bb96497f10aeb03aa755bdb7516c4a82d9,17,7,1,11969,,,0,"Bump fuel-devops version up to 2.9.19

Change-Id: I55d83c905c5863159f727f0ca7d73444adf54c18
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/16/282016/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/source/conf.py', 'setup.py', 'devops/__init__.py']",3,a1ea63bb96497f10aeb03aa755bdb7516c4a82d9,bump-to-2.9.19+,__version__ = '2.9.19',__version__ = '2.9.18',4,4
openstack%2Ffuel-qa~stable%2F8.0~I05322f648440447f7e23df0cfb9adffbfe7e7aec,openstack/fuel-qa,stable/8.0,I05322f648440447f7e23df0cfb9adffbfe7e7aec,Fix duplicate pacemaker constraint command invocation,MERGED,2016-02-19 08:36:00.000000000,2016-02-19 09:00:55.000000000,2016-02-19 09:00:55.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 19119}, {'_account_id': 19120}]","[{'number': 1, 'created': '2016-02-19 08:36:00.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover.py', 'fuelweb_test/tests/tests_strength/test_failover_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e29ffb3087d296f3ed3ba9fbbd68a321f2139bf7', 'message': 'Fix duplicate pacemaker constraint command invocation\n\nEdit test docstring according to the test script\nAdd show_step to the test\n\nRelated-Bug:#1458830\nCloses-Bug:#1544973\n\nChange-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec\n(cherry picked from commit f770d426c81fca60ea9ded6e48256c3700d4a3ab)\n'}]",0,282229,e29ffb3087d296f3ed3ba9fbbd68a321f2139bf7,11,5,1,20519,,,0,"Fix duplicate pacemaker constraint command invocation

Edit test docstring according to the test script
Add show_step to the test

Related-Bug:#1458830
Closes-Bug:#1544973

Change-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec
(cherry picked from commit f770d426c81fca60ea9ded6e48256c3700d4a3ab)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/29/282229/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_failover.py', 'fuelweb_test/tests/tests_strength/test_failover_base.py']",2,e29ffb3087d296f3ed3ba9fbbd68a321f2139bf7,bug/1458830," self.show_step(1, initialize=True) self.show_step(2) self.show_step(3) self.show_step(4, details='Run count: {0}'.format(count), initialize=True) self.show_step(5, details='Run count: {0}'.format(count)) result = remote_master_rabbit.execute(cmd_move) assert_equal( result['exit_code'], 0, 'count {1}'.format(result, count)) self.show_step(6, details='Run count: {0}'.format(count)) result = remote_master_rabbit.execute(cmd_clear) assert_equal( result['exit_code'], 0, 'Fail to delete pcs constraint using {0} on ' 'count {1}'.format(cmd_clear, count)) self.show_step(7) self.show_step(8) self.show_step(9) self.show_step(10) self.show_step(11) self.show_step(12) self.show_step(13) self.show_step(14) self.show_step(15)"," _wait(lambda: assert_equal( remote_master_rabbit.execute(cmd_move)['exit_code'], 0, 'count {1}'.format( remote_master_rabbit.execute(cmd_move), count)), timeout=20) _wait(lambda: assert_equal( remote_master_rabbit.execute(cmd_clear)['exit_code'], 0, 'Fail to delete pcs constraint {0} on count {1}'.format( remote_master_rabbit.execute(cmd_clear), count)), timeout=20) ",41,22
openstack%2Fdragonflow~master~If2419d3d8c7bc4c9d803952a7bb01734ad5b4ac4,openstack/dragonflow,master,If2419d3d8c7bc4c9d803952a7bb01734ad5b4ac4,modify ovsdb monitor index.rst,ABANDONED,2016-02-19 08:56:09.000000000,2016-02-19 08:57:15.000000000,,[],"[{'number': 1, 'created': '2016-02-19 08:56:09.000000000', 'files': ['doc/source/specs/index.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1742c3020db2283af1a5f8dd2a0ad3a5ee18db5a', 'message': 'modify ovsdb monitor index.rst\n\nChange-Id: If2419d3d8c7bc4c9d803952a7bb01734ad5b4ac4\n'}]",0,282236,1742c3020db2283af1a5f8dd2a0ad3a5ee18db5a,2,0,1,20287,,,0,"modify ovsdb monitor index.rst

Change-Id: If2419d3d8c7bc4c9d803952a7bb01734ad5b4ac4
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/36/282236/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/specs/index.rst'],1,1742c3020db2283af1a5f8dd2a0ad3a5ee18db5a,ovsdbmonitor,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Convention for heading levels: ======= Heading 0 (reserved for the title in a document) ------- Heading 1 ~~~~~~~ Heading 2 +++++++ Heading 3 ''''''' Heading 4 (Avoid deeper levels because they do not render well.) Dragonflow Specs ================= This section contains detailed specification documents for different features inside Dragonflow. Spec Template -------------- .. toctree:: :maxdepth: 3 skeleton template distributed_dnat mac_spoofing selective_topo_dist performance_testing ovsdb_monitor Indices and tables ------------------ * :ref:`genindex` * :ref:`modindex` * :ref:`search` ",".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Convention for heading levels: ======= Heading 0 (reserved for the title in a document) ------- Heading 1 ~~~~~~~ Heading 2 +++++++ Heading 3 ''''''' Heading 4 (Avoid deeper levels because they do not render well.) Dragonflow Specs ================= This section contains detailed specification documents for different features inside Dragonflow. Spec Template -------------- .. toctree:: :maxdepth: 3 skeleton template distributed_dnat mac_spoofing selective_topo_dist performance_testing Indices and tables ------------------ * :ref:`genindex` * :ref:`modindex` * :ref:`search`",49,48
openstack%2Fheat~stable%2Fliberty~I7d699bcf947940357a6eb6ae2d17027ec8d6bd04,openstack/heat,stable/liberty,I7d699bcf947940357a6eb6ae2d17027ec8d6bd04,Populate context roles when using stored context,MERGED,2016-02-05 07:00:21.000000000,2016-02-19 08:47:37.000000000,2016-02-19 08:47:37.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 10487}, {'_account_id': 12363}]","[{'number': 1, 'created': '2016-02-05 07:00:21.000000000', 'files': ['heat/tests/fakes.py', 'heat/common/heat_keystoneclient.py', 'heat/engine/stack.py', 'heat/tests/engine/tools.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/65fe32d3ac9ce8e92880e443834f9fc8f7192d46', 'message': 'Populate context roles when using stored context\n\nCurrently we leave the context roles empty when loading the stored\ncontext, even though there are roles associated with e.g the trust\nscoped token used via loading the stored context.  Loading the auth\nref and populating the roles from the token ensure any RBAC performed\non the context roles will work as expected.\n\nChange-Id: I7d699bcf947940357a6eb6ae2d17027ec8d6bd04\nCloses-Bug: #1529354\n(cherry picked from commit ce46629661322915082ece2710bf36c46b13a15a)\n'}]",0,276599,65fe32d3ac9ce8e92880e443834f9fc8f7192d46,22,6,1,8833,,,0,"Populate context roles when using stored context

Currently we leave the context roles empty when loading the stored
context, even though there are roles associated with e.g the trust
scoped token used via loading the stored context.  Loading the auth
ref and populating the roles from the token ensure any RBAC performed
on the context roles will work as expected.

Change-Id: I7d699bcf947940357a6eb6ae2d17027ec8d6bd04
Closes-Bug: #1529354
(cherry picked from commit ce46629661322915082ece2710bf36c46b13a15a)
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/276599/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/fakes.py', 'heat/common/heat_keystoneclient.py', 'heat/engine/stack.py', 'heat/tests/engine/tools.py']",4,65fe32d3ac9ce8e92880e443834f9fc8f7192d46,bug/1529354, keystone.KeystoneClientPlugin._create().MultipleTimes().AndReturn(fkc), keystone.KeystoneClientPlugin._create().AndReturn(fkc),34,2
openstack%2Fsenlin~master~I9b54d9e730e2d284b65699efa8a2a035c89227c6,openstack/senlin,master,I9b54d9e730e2d284b65699efa8a2a035c89227c6,Remove an unneeded requirement,MERGED,2016-02-19 03:29:07.000000000,2016-02-19 08:46:40.000000000,2016-02-19 08:34:46.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-19 03:29:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin/commit/2acfc847e2bae434aea19bbb96b223e210a3f572', 'message': 'Remove an unneeded requirement\n\nThis patch removes cryptography from requirements list.\n\nChange-Id: I9b54d9e730e2d284b65699efa8a2a035c89227c6\n'}]",0,282151,2acfc847e2bae434aea19bbb96b223e210a3f572,10,4,1,11034,,,0,"Remove an unneeded requirement

This patch removes cryptography from requirements list.

Change-Id: I9b54d9e730e2d284b65699efa8a2a035c89227c6
",git fetch https://review.opendev.org/openstack/senlin refs/changes/51/282151/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2acfc847e2bae434aea19bbb96b223e210a3f572,requirements,,cryptography>=1.0 # BSD/Apache-2.0,0,1
openstack%2Fnetworking-bgpvpn~master~I49ce9786fe0403559a85f7c10af725d661123e13,openstack/networking-bgpvpn,master,I49ce9786fe0403559a85f7c10af725d661123e13,remove neutron-client@liberty dependency,MERGED,2016-02-18 16:47:08.000000000,2016-02-19 08:45:32.000000000,2016-02-19 08:45:32.000000000,"[{'_account_id': 3}, {'_account_id': 12021}, {'_account_id': 13933}]","[{'number': 1, 'created': '2016-02-18 16:47:08.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/1a0e01df2363a23fd2ab41752ca6bd3d9594db79', 'message': ""remove neutron-client@liberty dependency\n\nWe're still forcing the use of the liberty release of\npython-neutronclient.\nThis is pointless, and recent devstack breaks because of that.\n\nChange-Id: I49ce9786fe0403559a85f7c10af725d661123e13\n""}]",1,281954,1a0e01df2363a23fd2ab41752ca6bd3d9594db79,13,3,1,2888,,,0,"remove neutron-client@liberty dependency

We're still forcing the use of the liberty release of
python-neutronclient.
This is pointless, and recent devstack breaks because of that.

Change-Id: I49ce9786fe0403559a85f7c10af725d661123e13
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/54/281954/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1a0e01df2363a23fd2ab41752ca6bd3d9594db79,req,,-e git+https://git.openstack.org/openstack/python-neutronclient@stable/liberty#egg=python-neutronclient ,0,2
openstack%2Fgnocchi~master~I0a32d04948fa9dad12e1175d88301237e53974ee,openstack/gnocchi,master,I0a32d04948fa9dad12e1175d88301237e53974ee,rest: implement groupby in resource/metric aggregation,MERGED,2016-02-01 14:23:21.000000000,2016-02-19 08:45:07.000000000,2016-02-19 02:06:16.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-02-01 14:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8bfd1437d220613fcc9b3d03318c13232e4f8d7c', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 2, 'created': '2016-02-01 15:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0ce4fbeb84a204c4f436965fcd42ffbbe6081a58', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 3, 'created': '2016-02-02 07:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c10a72b99b4ef1738e92216edd5e18f4ae354fbf', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 4, 'created': '2016-02-02 09:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9b3da6f4ade52906e11a7756489e3094cd9c7b9f', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 5, 'created': '2016-02-02 10:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4c3b14851da9faf15dbc9406f8c7153f12193cc2', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 6, 'created': '2016-02-02 13:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ca8b71e6533a674207cec56ad95b668d7ebb48e0', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 7, 'created': '2016-02-02 14:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4ebf5bc680d74f61a3d530855b90a7c0f957c5d9', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 8, 'created': '2016-02-02 16:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e8896e299e4d885bfaf12542413dd02ae534487a', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 9, 'created': '2016-02-02 22:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/45f2cb11c6119ba77d80ed3f696898b0dd9cbb08', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 10, 'created': '2016-02-03 09:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/2ce4bbd129c552c045b7e155ed061c8654c1fce0', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 11, 'created': '2016-02-03 11:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/cf02ed33fe079ee1c8fad3148c9853e34dd73166', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 12, 'created': '2016-02-03 14:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ce92aa13893fe6b60a0bd41b5314cae6045b71d6', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 13, 'created': '2016-02-04 10:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4726de1dec17fdb72c1f92190428dce6c725468c', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 14, 'created': '2016-02-04 15:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f87a0e40c9105083994cfe13451d64b51cf651cb', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 15, 'created': '2016-02-10 18:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/df9877d6fe25fa7d71ddd1198ec5618d61df79eb', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 16, 'created': '2016-02-11 11:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/26c792762fa83382dde02ca48d08e22fd74c7070', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 17, 'created': '2016-02-15 13:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/98bdf9ce90f38b055933777b793635eaf358ae79', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 18, 'created': '2016-02-15 15:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1f832c398bc5430b4e91f48199c3367ef2909378', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 19, 'created': '2016-02-15 18:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4468c1e880b332d87fe00761eaef704a29d27b8e', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 20, 'created': '2016-02-16 16:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7fdd12da9bdb4c4b44c12b7d992289bfb1e17f7d', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 21, 'created': '2016-02-16 19:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c24a9093a6fc2aff6e1fb233a17ede5dca8c6c10', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 22, 'created': '2016-02-18 13:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/89f51820e0a6b1ba02eb909a53a86f73f3652f2d', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 23, 'created': '2016-02-18 14:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/175ac16f4cf8eccfd20539edf2a941f1b21e4cc6', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 24, 'created': '2016-02-18 14:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d3af786f7629c7c23564baf1b24a3608e3afeab1', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 25, 'created': '2016-02-18 16:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/aed56c93d0ba9bb1ef55ff54f61a765004a450d6', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}, {'number': 26, 'created': '2016-02-18 22:06:36.000000000', 'files': ['gnocchi/rest/__init__.py', 'doc/source/rest.j2', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/gabbi/gabbits/resource_aggregation.yaml', 'doc/source/rest.yaml'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6e3a5f9bdd0c3f9fcb741b721e2b9e881bce7287', 'message': 'rest: implement groupby in resource/metric aggregation\n\nCloses-Bug: #1508446\nChange-Id: I0a32d04948fa9dad12e1175d88301237e53974ee\n'}]",2,274684,6e3a5f9bdd0c3f9fcb741b721e2b9e881bce7287,65,4,26,1669,,,0,"rest: implement groupby in resource/metric aggregation

Closes-Bug: #1508446
Change-Id: I0a32d04948fa9dad12e1175d88301237e53974ee
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/84/274684/9 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'doc/source/rest.j2', 'gnocchi/tests/gabbi/gabbits/resource_aggregation.yaml', 'doc/source/rest.yaml']",4,8bfd1437d220613fcc9b3d03318c13232e4f8d7c,bug/1508446," ""host"": ""compute2"", ""display_name"": ""myvm3"",- name: get-across-metrics-measures-by-attributes-lookup-groupby request: | POST /v1/aggregation/resource/instance/metric/cpu.util?groupby=host&groupby=flavor_id HTTP/1.1 Content-Type: application/json {""="": {""server_group"": ""my_autoscaling_group""}} "," ""host"": ""compute1"", ""display_name"": ""myvm2"",",224,4
openstack%2Ffuel-web~master~If781912443d593ec98cfcfaa06308cc97af5f228,openstack/fuel-web,master,If781912443d593ec98cfcfaa06308cc97af5f228,"New 5-th group of ""nightly"" functional ui tests for fuel-web.",MERGED,2016-02-15 07:33:40.000000000,2016-02-19 08:37:12.000000000,2016-02-17 09:03:39.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 19799}]","[{'number': 1, 'created': '2016-02-15 07:33:40.000000000', 'files': ['nailgun/static/tests/functional/nightly/test_network_ip_ranges.js', 'nailgun/static/tests/functional/nightly/library/networks.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1b43699d242301022029f403413ae0f1ab9769b2', 'message': 'New 5-th group of ""nightly"" functional ui tests for fuel-web.\n\n""Support networks IP ranges"" test group:\n  Storage Network ""IP Ranges"" testing (Neutron VLAN segmentation)\n  Management Network ""IP Ranges"" testing (Neutron VLAN segmentation)\n  Check intersections between all networks (Neutron VLAN segmentation)\n  Storage Network ""IP Ranges"" testing (Neutron tunneling segmentation)\n  Management Network ""IP Ranges"" testing (Neutron tunneling segmentation)\n  Private Network ""IP Ranges"" testing (Neutron tunneling segmentation)\n  Check intersections between all networks (Neutron tunneling segmentation)\n\nChange-Id: If781912443d593ec98cfcfaa06308cc97af5f228\n'}]",3,280087,1b43699d242301022029f403413ae0f1ab9769b2,18,6,1,19799,,,0,"New 5-th group of ""nightly"" functional ui tests for fuel-web.

""Support networks IP ranges"" test group:
  Storage Network ""IP Ranges"" testing (Neutron VLAN segmentation)
  Management Network ""IP Ranges"" testing (Neutron VLAN segmentation)
  Check intersections between all networks (Neutron VLAN segmentation)
  Storage Network ""IP Ranges"" testing (Neutron tunneling segmentation)
  Management Network ""IP Ranges"" testing (Neutron tunneling segmentation)
  Private Network ""IP Ranges"" testing (Neutron tunneling segmentation)
  Check intersections between all networks (Neutron tunneling segmentation)

Change-Id: If781912443d593ec98cfcfaa06308cc97af5f228
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/87/280087/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/tests/functional/nightly/test_network_ip_ranges.js', 'nailgun/static/tests/functional/nightly/library/networks.js']",2,1b43699d242301022029f403413ae0f1ab9769b2,nightly_group_5," defaultPlaceholder: '127.0.0.1', .assertElementContainsText('ul.node-network-groups-list', groupName, .findByCssSelector('ul.node-network-groups-list') checkNetrworkIpRanges: function(networkName, correctIpRange, newIpRange) { var self = this; var netSelector = 'div.' + networkName.toLowerCase() + ' '; var ipStartSelector = netSelector + 'div.ip_ranges input[name*=""range-start""]'; var ipEndSelector = netSelector + 'div.ip_ranges input[name*=""range-end""]'; var properNames = ['Public', 'Storage', 'Management', 'Baremetal', 'Private']; if (properNames.indexOf(networkName) === -1) { throw new Error('Invalid input value. Check networkName: ""' + networkName + '"" parameter and restart test.'); } return this.remote // ""Use the whole CIDR"" option works .then(function() { return self.checkCidrOption(networkName); }) .then(function() { return self.saveSettings(); }) // Correct changing of ""IP Ranges"" works .setInputValue(ipStartSelector, correctIpRange[0]) .setInputValue(ipEndSelector, correctIpRange[1]) .then(function() { return self.saveSettings(); }) .assertElementPropertyEquals(ipStartSelector, 'value', correctIpRange[0], networkName + ' ""Start IP Range"" textfield has correct new value') .assertElementPropertyEquals(ipEndSelector, 'value', correctIpRange[1], networkName + ' ""End IP Range"" textfield has correct new value') // Adding and deleting additional ""IP Ranges"" fields .then(function() { return self.addNewIpRange(networkName, newIpRange); }) .then(function() { return self.saveSettings(); }) .then(function() { return self.deleteIpRange(networkName); }) .then(function() { return self.saveSettings(); }) // Check ""IP Ranges"" Start and End validation .then(function() { return self.checkIpRanges(networkName); }); }, }, checkCidrOption: function(networkName) { var self = this; var netSelector = 'div.' + networkName.toLowerCase() + ' '; var cidrSelector = netSelector + 'div.cidr input[type=""checkbox""]'; var ipStartSelector = netSelector + 'div.ip_ranges input[name*=""range-start""]'; var ipEndSelector = netSelector + 'div.ip_ranges input[name*=""range-end""]'; var defaultIpRange = {'Storage': '1', 'Management': '0', 'Private': '2'}; return this.remote .assertElementEnabled(cidrSelector, networkName + ' ""Use the whole CIDR"" checkbox is enabled before changing') .findByCssSelector(cidrSelector) .isSelected() .then(function(cidrStatus) { return self.selectCidrWay(networkName, cidrStatus, cidrSelector, ipStartSelector, ipEndSelector); }) .end() .assertElementPropertyEquals(ipStartSelector, 'value', '192.168.' + defaultIpRange[networkName] + '.1', networkName + ' ""Start IP Range"" textfield has default value') .assertElementPropertyEquals(ipEndSelector, 'value', '192.168.' + defaultIpRange[networkName] + '.254', networkName + ' ""End IP Range"" textfield has default value') .assertElementNotExists(netSelector + 'div.has-error', 'No ' + networkName + ' errors are observed'); }, selectCidrWay: function(networkName, cidrStatus, cidrSelector, ipStartSelector, ipEndSelector) { var chain = this.remote; chain = chain.clickByCssSelector(cidrSelector) .assertElementEnabled(cidrSelector, networkName + ' ""Use the whole CIDR"" checkbox is enabled after changing'); if (cidrStatus) { chain = chain.assertElementNotSelected(cidrSelector, networkName + ' ""Use the whole CIDR"" checkbox is not selected') .assertElementEnabled(ipStartSelector, networkName + ' ""Start IP Range"" textfield is enabled') .assertElementEnabled(ipEndSelector, networkName + ' ""End IP Range"" textfield is enabled'); } else { chain = chain.assertElementSelected(cidrSelector, networkName + ' ""Use the whole CIDR"" checkbox is selected') .assertElementDisabled(ipStartSelector, networkName + ' ""Start IP Range"" textfield is disabled') .assertElementDisabled(ipEndSelector, networkName + ' ""End IP Range"" textfield is disabled'); } return chain; }, addNewIpRange: function(networkName, newIpRange) { // Works only with last range! // Input array ""newIpRange"": [Start IP, End IP] var self = this; var chain = this.remote; var netSelector = 'div.' + networkName.toLowerCase() + ' '; var rowRangeSelector = netSelector + 'div.range-row'; var lastRangeSelector = rowRangeSelector + ':last-child '; var addRangeSelector = lastRangeSelector + 'button.ip-ranges-add '; var ipStartSelector = 'input[name*=""range-start""]'; var ipEndSelector = 'input[name*=""range-end""]'; chain = chain.assertElementEnabled(addRangeSelector, 'IP range add button enabled') .findAllByCssSelector(rowRangeSelector) .then(function(elements) { return self.checkIpRange(addRangeSelector, rowRangeSelector, elements.length + 1); }) .end() .assertElementEnabled(lastRangeSelector + ipStartSelector, networkName + ' new ""Start IP Range"" textfield is enabled') .assertElementEnabled(lastRangeSelector + ipEndSelector, networkName + ' new ""End IP Range"" textfield is enabled') .assertElementPropertyEquals(lastRangeSelector + ipStartSelector, 'placeholder', this.defaultPlaceholder, networkName + ' new ""Start IP Range"" textfield has default placeholder') .assertElementPropertyEquals(lastRangeSelector + ipEndSelector, 'placeholder', this.defaultPlaceholder, networkName + ' new ""End IP Range"" textfield has default placeholder'); if (newIpRange) { chain = chain.setInputValue(lastRangeSelector + ipStartSelector, newIpRange[0]) .setInputValue(lastRangeSelector + ipEndSelector, newIpRange[1]) .assertElementPropertyEquals(lastRangeSelector + ipStartSelector, 'value', newIpRange[0], networkName + ' new ""Start IP Range"" textfield has new value') .assertElementPropertyEquals(lastRangeSelector + ipEndSelector, 'value', newIpRange[1], networkName + ' new ""End IP Range"" textfield has new value'); } chain = chain.assertElementNotExists(netSelector + 'div.has-error', 'No ' + networkName + ' errors are observed'); return chain; }, deleteIpRange: function(networkName, rangeRow) { var self = this; var netSelector = 'div.' + networkName.toLowerCase() + ' '; var rowRangeSelector = netSelector + 'div.range-row'; var rowSelector = rowRangeSelector + ':last-child '; if (rangeRow) { rowSelector = rowRangeSelector + ':nth-child(' + (rangeRow + 1).toString() + ') '; } var delRangeSelector = rowSelector + 'button.ip-ranges-delete'; return this.remote .assertElementsExist(rowSelector, networkName + ' IP Range to delete exists') .assertElementEnabled(delRangeSelector, networkName + ' IP Range delete button enabled') .findAllByCssSelector(rowRangeSelector) .then(function(elements) { return self.checkIpRange(delRangeSelector, rowRangeSelector, elements.length - 1); }) .end() // Add more powerfull check of range deletion (values disappears) .assertElementNotExists(netSelector + 'div.has-error', 'No ' + networkName + ' errors are observed'); }, checkIpRange: function(addremoveRangeSelector, rowRangeSelector, numRanges) { return this.remote .clickByCssSelector(addremoveRangeSelector) .sleep(500) .assertElementsExist(rowRangeSelector, numRanges, 'Correct number of IP ranges exists'); }, checkIpRanges: function(networkName) { var self = this; var netSelector = 'div.' + networkName.toLowerCase() + ' '; var cidrSelector = netSelector + 'div.cidr input[type=""text""]'; var ipStartSelector = netSelector + 'div.ip_ranges input[name*=""range-start""]'; var ipStartErrorSel = netSelector + 'div.ip_ranges div.has-error input[name*=""range-start""]'; var ipEndSelector = netSelector + 'div.ip_ranges input[name*=""range-end""]'; var ipEndErrorSel = netSelector + 'div.ip_ranges div.has-error input[name*=""range-end""]'; var networkAlertSelector = netSelector + 'div.ip_ranges div.validation-error'; var initValue = '192.168.'; var errorValue = '192.168.5.0/24'; var errorValues = ['.*', '.279', '.254', '.1', '.5']; var defaultIpRange = {'Storage': '1', 'Management': '0', 'Private': '2'}; return this.remote .assertElementEnabled(cidrSelector, networkName + ' ""CIDR"" textfield is enabled') .assertElementEnabled(ipStartSelector, networkName + ' ""Start IP Range"" txtfld is enabled') .assertElementEnabled(ipEndSelector, networkName + ' ""End IP Range"" textfield is enabled') // Check #1 .setInputValue(ipStartSelector, initValue + defaultIpRange[networkName] + errorValues[0]) .assertElementsExist(ipStartErrorSel, networkName + ' ""Start IP Range"" textfield is ""red"" marked') .assertElementMatchesRegExp(networkAlertSelector, /Invalid IP address/i, 'True error message is displayed') .then(function() { return self.cancelChanges(); }) // Check #2 .setInputValue(ipEndSelector, initValue + defaultIpRange[networkName] + errorValues[1]) .assertElementsExist(ipEndErrorSel, networkName + ' ""End IP Range"" textfield is ""red"" marked') .assertElementMatchesRegExp(networkAlertSelector, /Invalid IP address/i, 'True error message is displayed') .then(function() { return self.cancelChanges(); }) // Check #3 .setInputValue(cidrSelector, errorValue) .assertElementsExist(ipStartErrorSel, networkName + ' ""Start IP Range"" textfield is ""red"" marked') .assertElementsExist(ipEndErrorSel, networkName + ' ""End IP Range"" textfield is ""red"" marked') .assertElementMatchesRegExp(networkAlertSelector, /IP address does not match the network CIDR/i, 'True error message is displayed') .then(function() { return self.cancelChanges(); }) // Check #4 .setInputValue(ipStartSelector, initValue + defaultIpRange[networkName] + errorValues[2]) .setInputValue(ipEndSelector, initValue + defaultIpRange[networkName] + errorValues[3]) .assertElementsExist(ipStartErrorSel, networkName + ' ""Start IP Range"" textfield is ""red"" marked') .assertElementsExist(ipEndErrorSel, networkName + ' ""End IP Range"" textfield is ""red"" marked') .assertElementMatchesRegExp(networkAlertSelector, /Start IP address must be less than end IP address/i, 'True error message is displayed') .then(function() { return self.cancelChanges(); }) // Check #5 .setInputValue(ipStartSelector, initValue + defaultIpRange[networkName] + errorValues[4]) .setInputValue(ipEndSelector, initValue + defaultIpRange[networkName] + errorValues[4]) .then(function() { return self.saveSettings(); }) // Check #6 .setInputValue(ipStartSelector, ' ') .assertElementsExist(ipStartErrorSel, networkName + ' ""Start IP Range"" textfield is ""red"" marked') .assertElementMatchesRegExp(networkAlertSelector, /Invalid IP address/i, 'True error message is displayed') .then(function() { return self.cancelChanges(); }) // Check #7 .setInputValue(ipEndSelector, ' ') .assertElementsExist(ipEndErrorSel, networkName + ' ""End IP Range"" textfield is ""red"" marked') .assertElementMatchesRegExp(networkAlertSelector, /Invalid IP address/i, 'True error message is displayed') .then(function() { return self.cancelChanges(); }); }, checkNerworksIntersection: function(networkNameToEdit, networkName, editValues) { // Input array ""editValues"": [CIDR, Start IP, End IP] var self = this; var netSelector1 = 'div.' + networkNameToEdit.toLowerCase() + ' '; var cidrSelector = netSelector1 + 'div.cidr input[type=""text""]'; var cidrErrorSelector = 'div.cidr div.has-error input[type=""text""]'; var ipStartSelector = netSelector1 + 'div.ip_ranges input[name*=""range-start""]'; var ipEndSelector = netSelector1 + 'div.ip_ranges input[name*=""range-end""]'; var netSelector2 = 'div.' + networkName.toLowerCase() + ' '; var networkAlertSelector = 'div.network-alert'; var networkAlertMessage = RegExp( 'Address space intersection between networks[\\s\\S]*' + '(' + networkNameToEdit + '.*|' + networkName + '.*){2}[\\s\\S]*', 'i'); return this.remote .assertElementEnabled(cidrSelector, networkNameToEdit + ' ""CIDR"" textfield is enabled') .assertElementEnabled(ipStartSelector, networkNameToEdit + ' ""Start IP Range"" textfield is enabled') .assertElementEnabled(ipEndSelector, networkNameToEdit + ' ""End IP Range"" textfield is enabled') .setInputValue(cidrSelector, editValues[0]) .setInputValue(ipStartSelector, editValues[1]) .setInputValue(ipEndSelector, editValues[2]) .assertElementEnabled(this.btnSaveSelector, '""Save Settings"" button is enabled') .clickByCssSelector(this.btnSaveSelector) .assertElementsExist(netSelector1 + cidrErrorSelector, networkNameToEdit + ' ""CIDR"" textfield is ""red"" marked') .assertElementsExist(netSelector2 + cidrErrorSelector, networkName + ' ""CIDR"" textfield is ""red"" marked') .assertElementsExist(networkAlertSelector, 'Error message is observed') .assertElementMatchesRegExp(networkAlertSelector, networkAlertMessage, 'True error message is displayed for intersection between' + networkNameToEdit + ' and ' + networkName + ' networks') .then(function() { return self.cancelChanges(); });"," .assertElementContainsText('ul.node_network_groups', groupName, .findByCssSelector('ul.node_network_groups')",522,2
openstack%2Ffuel-qa~master~I05322f648440447f7e23df0cfb9adffbfe7e7aec,openstack/fuel-qa,master,I05322f648440447f7e23df0cfb9adffbfe7e7aec,Fix duplicate pacemaker constraint command invocation,MERGED,2016-02-16 16:28:52.000000000,2016-02-19 08:36:05.000000000,2016-02-18 17:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 11587}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16414}, {'_account_id': 20519}]","[{'number': 1, 'created': '2016-02-16 16:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/385f69cd07c3a92862a9246823177f55b84c611c', 'message': 'Fix duplicate pacemaker constraint command invocation\n\nEdit test docstring according to the test script\nAdd show_step to the test\n\nChange-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec\n'}, {'number': 2, 'created': '2016-02-17 12:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1817c4111f9c4b997d17a4df3c888fd545a4b0c3', 'message': 'Fix duplicate pacemaker constraint command invocation\n\nEdit test docstring according to the test script\nAdd show_step to the test\n\nCloses-Bug:#1458830\n\nChange-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec\n'}, {'number': 3, 'created': '2016-02-17 13:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/d191a128c2130541d00b88e4565bc1ce6ca24ff1', 'message': 'Fix duplicate pacemaker constraint command invocation\n\nEdit test docstring according to the test script\nAdd show_step to the test\n\nRelated-Bug:#1458830\n\nChange-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec\n'}, {'number': 4, 'created': '2016-02-17 13:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/28406cc00db4bef13a827814fa9f701b44d5ef9d', 'message': 'Fix duplicate pacemaker constraint command invocation\n\nEdit test docstring according to the test script\nAdd show_step to the test\n\nRelated-Bug:#1458830\nCloses-Bug:#1544973\n\nChange-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec\n'}, {'number': 5, 'created': '2016-02-17 14:22:57.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover.py', 'fuelweb_test/tests/tests_strength/test_failover_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f770d426c81fca60ea9ded6e48256c3700d4a3ab', 'message': 'Fix duplicate pacemaker constraint command invocation\n\nEdit test docstring according to the test script\nAdd show_step to the test\n\nRelated-Bug:#1458830\nCloses-Bug:#1544973\n\nChange-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec\n'}]",6,280798,f770d426c81fca60ea9ded6e48256c3700d4a3ab,41,12,5,20519,,,0,"Fix duplicate pacemaker constraint command invocation

Edit test docstring according to the test script
Add show_step to the test

Related-Bug:#1458830
Closes-Bug:#1544973

Change-Id: I05322f648440447f7e23df0cfb9adffbfe7e7aec
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/98/280798/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_failover.py', 'fuelweb_test/tests/tests_strength/test_failover_base.py']",2,385f69cd07c3a92862a9246823177f55b84c611c,bug/1458830," self.show_step(1, initialize=True) self.show_step(2) self.show_step(3) self.show_step(4, details='Run count: {0}'.format(count)) self.show_step(5, details='Run count: {0}'.format(count)) result = remote_master_rabbit.execute(cmd_move) assert_equal( result['exit_code'], 0, 'count {1}'.format(result, count)) self.show_step(6) result = remote_master_rabbit.execute(cmd_move) assert_equal( result['exit_code'], 0, 'Fail to delete pcs constraint using {0} on ' 'count {1}'.format(cmd_clear, count)) self.show_step(7) self.show_step(8) self.show_step(9) self.show_step(10) self.show_step(11) self.show_step(12) self.show_step(13) self.show_step(14) self.show_step(15)"," _wait(lambda: assert_equal( remote_master_rabbit.execute(cmd_move)['exit_code'], 0, 'count {1}'.format( remote_master_rabbit.execute(cmd_move), count)), timeout=20) _wait(lambda: assert_equal( remote_master_rabbit.execute(cmd_clear)['exit_code'], 0, 'Fail to delete pcs constraint {0} on count {1}'.format( remote_master_rabbit.execute(cmd_clear), count)), timeout=20) ",39,22
openstack%2Fnetworking-l2gw~master~Iebb93d4f161cd114ea2d44389e39057361b40cf5,openstack/networking-l2gw,master,Iebb93d4f161cd114ea2d44389e39057361b40cf5,Networking-L2Gateway CI fails,MERGED,2016-02-02 07:16:34.000000000,2016-02-19 08:32:35.000000000,2016-02-19 08:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6558}, {'_account_id': 9093}, {'_account_id': 9361}, {'_account_id': 10780}, {'_account_id': 11447}, {'_account_id': 11671}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-02-02 07:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/fef8caa84e95232c4d42262b5ad18e2a642121e8', 'message': 'L2 Gateway CI fails due to the removal of tempest test file from neutron\n\nChange-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5\nCloses-bug: 1540760\n'}, {'number': 2, 'created': '2016-02-02 07:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/38508598f1d6845d467229faa2ffa533342172ff', 'message': 'Networking-L2Gateway CI fails\n\nDue to the removal of tempest test file from neutron\n\nChange-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5\nCloses-bug: 1540760\n'}, {'number': 3, 'created': '2016-02-09 07:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/395fba33b73fb6eaf167b07f4c34685efd549e7e', 'message': 'Networking-L2Gateway CI fails\n\nDue to the removal of tempest test file from neutron\n\nChange-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5\nCloses-bug: 1540760\n'}, {'number': 4, 'created': '2016-02-09 09:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/5a1fb23b6a0780419dfcc3fe601b62f2eb8f1079', 'message': 'Networking-L2Gateway CI fails\n\nDue to the removal of tempest test file from neutron\n\nChange-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5\nCloses-bug: 1540760\n'}, {'number': 5, 'created': '2016-02-10 13:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/7166c966d5b1921c95689036e89130f1b5d212cd', 'message': 'Networking-L2Gateway CI fails\n\nDue to the removal of tempest test file from neutron\n\nChange-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5\nCloses-bug: 1540760\n'}, {'number': 6, 'created': '2016-02-11 10:51:19.000000000', 'files': ['tools/tox_install.sh', 'networking_l2gw/tests/api/base_l2gw.py', 'networking_l2gw/tests/tempest/config.py', 'networking_l2gw/tests/api/test_l2gw_negative.py', 'networking_l2gw/tests/api/test_l2gw_extensions.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/61f74e1422faf712fdd4a3b1a4f506c6b7700863', 'message': 'Networking-L2Gateway CI fails\n\nDue to the removal of tempest test file from neutron\n\nChange-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5\nCloses-bug: 1540760\n'}]",2,275043,61f74e1422faf712fdd4a3b1a4f506c6b7700863,51,9,6,11671,,,0,"Networking-L2Gateway CI fails

Due to the removal of tempest test file from neutron

Change-Id: Iebb93d4f161cd114ea2d44389e39057361b40cf5
Closes-bug: 1540760
",git fetch https://review.opendev.org/openstack/networking-l2gw refs/changes/43/275043/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_l2gw/tests/api/test_l2gw_negative.py', 'networking_l2gw/tests/api/test_l2gw_extensions.py', 'tox.ini']",3,fef8caa84e95232c4d42262b5ad18e2a642121e8,bug/1540760,deps = {[testenv]deps} git+https://git.openstack.org/openstack/tempest#egg=tempest,# This must be set manually in your environment until # a new release of tox fixes the issues with setenv,7,4
openstack%2Fbarbican~master~I517b651113ef1d3c0837f9ba85a70e6959fae764,openstack/barbican,master,I517b651113ef1d3c0837f9ba85a70e6959fae764,Cleanup barbican-api-paste pipeline,MERGED,2016-01-03 05:27:48.000000000,2016-02-19 08:25:39.000000000,2016-02-19 08:25:39.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7764}, {'_account_id': 10873}, {'_account_id': 14926}, {'_account_id': 15274}, {'_account_id': 17579}, {'_account_id': 19132}]","[{'number': 1, 'created': '2016-01-03 05:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/48d9d70555a641ff6525dcd217c2c2f6ce94092f', 'message': 'Cleanup barbican-api-paste pipeline\n\nBarbican API Paste has a commented line which should not be there\nand when using devstack the pipeline ""barbican-api-keystone""\nshould be provided instead of individual components.\n\nChange-Id: I517b651113ef1d3c0837f9ba85a70e6959fae764\n'}, {'number': 2, 'created': '2016-02-11 17:26:05.000000000', 'files': ['etc/barbican/barbican-api-paste.ini', 'devstack/lib/barbican'], 'web_link': 'https://opendev.org/openstack/barbican/commit/9fe9fd24735113b6f93ef1e358c6affdcc5c922f', 'message': 'Cleanup barbican-api-paste pipeline\n\nBarbican API Paste has a commented line which should not be there\nand when using devstack the pipeline ""barbican-api-keystone""\nshould be provided instead of individual components.\n\nChange-Id: I517b651113ef1d3c0837f9ba85a70e6959fae764\n'}]",0,263000,9fe9fd24735113b6f93ef1e358c6affdcc5c922f,20,9,2,16046,,,0,"Cleanup barbican-api-paste pipeline

Barbican API Paste has a commented line which should not be there
and when using devstack the pipeline ""barbican-api-keystone""
should be provided instead of individual components.

Change-Id: I517b651113ef1d3c0837f9ba85a70e6959fae764
",git fetch https://review.opendev.org/openstack/barbican refs/changes/00/263000/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/barbican/barbican-api-paste.ini', 'devstack/lib/barbican']",2,48d9d70555a641ff6525dcd217c2c2f6ce94092f,pipeline-fix, iniset $BARBICAN_PASTE_CONF 'pipeline:barbican_api' pipeline 'barbican-api-keystone', iniset $BARBICAN_PASTE_CONF 'pipeline:barbican_api' pipeline 'keystone_authtoken context apiapp',1,2
openstack%2Fcinder~master~I8ccd69c0e1d1386282e634215657cfbcc220ba97,openstack/cinder,master,I8ccd69c0e1d1386282e634215657cfbcc220ba97,Create volume in same zone when backup restore,ABANDONED,2016-01-26 06:36:24.000000000,2016-02-19 08:04:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2759}, {'_account_id': 6547}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9581}, {'_account_id': 10453}, {'_account_id': 11224}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12822}, {'_account_id': 13063}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16160}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19917}]","[{'number': 1, 'created': '2016-01-26 06:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/716357fcbcac3d5b7ed1bc1985a50bdf5b54a81b', 'message': 'Create volume in same zone when backup restore\n\nThis patch is to create a volume in same availability\nzone as backup when restoring a backup without specifying\na volume.\n\nChange-Id: I8ccd69c0e1d1386282e634215657cfbcc220ba97\n'}, {'number': 2, 'created': '2016-01-26 08:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e77165eb6518ff9fbefe6b236749cf5cc479929d', 'message': 'Create volume in same zone when backup restore\n\nThis patch is to create a volume in same availability\nzone as backup when restoring a backup without specifying\na volume.\n\nChange-Id: I8ccd69c0e1d1386282e634215657cfbcc220ba97\n'}, {'number': 3, 'created': '2016-02-01 07:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3241d4a9d2859ab08044912363c22c4fb99ac91a', 'message': 'Create volume in same zone when backup restore\n\nThis patch is to create a volume in same availability\nzone as backup when restoring a backup without specifying\na volume.\n\nCloses-Bug: #1540238\n\nChange-Id: I8ccd69c0e1d1386282e634215657cfbcc220ba97\n'}, {'number': 4, 'created': '2016-02-04 02:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/897ac68478891ad154b22ab89ed2ce287576de32', 'message': 'Create volume in same zone when backup restore\n\nThis patch is to create a volume in same availability\nzone as backup when restoring a backup without specifying\na volume.\n\nCloses-Bug: #1540238\nChange-Id: I8ccd69c0e1d1386282e634215657cfbcc220ba97\n'}, {'number': 5, 'created': '2016-02-04 03:04:05.000000000', 'files': ['cinder/tests/unit/api/contrib/test_backups.py', 'cinder/backup/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ef66bda649f3f87fe8b6ca443f08816c4806ec6', 'message': 'Create volume in same zone when backup restore\n\nWithout the patch, it creates a volume in default availability zone\nwhen restoring a backup without specifying a volume.\n\nThis patch is to create a volume in same availability\nzone as backup in above case.\n\nCloses-Bug: #1540238\nChange-Id: I8ccd69c0e1d1386282e634215657cfbcc220ba97\n'}]",5,272404,0ef66bda649f3f87fe8b6ca443f08816c4806ec6,122,37,5,15961,,,0,"Create volume in same zone when backup restore

Without the patch, it creates a volume in default availability zone
when restoring a backup without specifying a volume.

This patch is to create a volume in same availability
zone as backup in above case.

Closes-Bug: #1540238
Change-Id: I8ccd69c0e1d1386282e634215657cfbcc220ba97
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/272404/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/api/contrib/test_backups.py', 'cinder/backup/api.py']",2,716357fcbcac3d5b7ed1bc1985a50bdf5b54a81b,bug/1540238," volume = self.volume_api.create( context, size, name, description, availability_zone=backup.availability_zone)"," volume = self.volume_api.create(context, size, name, description)",11,4
openstack%2Fsahara~master~I263fc4093dc5b7fbd946f58aaae055978b7b4122,openstack/sahara,master,I263fc4093dc5b7fbd946f58aaae055978b7b4122,Check that main-class value is not null in job execution validator,MERGED,2016-02-18 20:32:33.000000000,2016-02-19 08:01:16.000000000,2016-02-19 08:01:16.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 18399}]","[{'number': 1, 'created': '2016-02-18 20:32:33.000000000', 'files': ['sahara/tests/unit/service/validation/edp/test_job_executor.py', 'sahara/service/validations/edp/job_execution.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9a1948324de7212293ba7f83735723037ec189b1', 'message': 'Check that main-class value is not null in job execution validator\n\nThe validation was checking that the main-class value was present, but was not checking that the value was non-null\n\nCo-author: Trevor McKay\nCloses-bug: #1546701\nChange-Id: I263fc4093dc5b7fbd946f58aaae055978b7b4122\n'}]",0,282050,9a1948324de7212293ba7f83735723037ec189b1,11,6,1,18333,,,0,"Check that main-class value is not null in job execution validator

The validation was checking that the main-class value was present, but was not checking that the value was non-null

Co-author: Trevor McKay
Closes-bug: #1546701
Change-Id: I263fc4093dc5b7fbd946f58aaae055978b7b4122
",git fetch https://review.opendev.org/openstack/sahara refs/changes/50/282050/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/unit/service/validation/edp/test_job_executor.py', 'sahara/service/validations/edp/job_execution.py']",2,9a1948324de7212293ba7f83735723037ec189b1,bug/1546701,"import six if data: val = data.get( 'job_configs', {}).get( 'configs', {}).get('edp.java.main_class', None) return val and isinstance(val, six.string_types) return False"," return data and 'edp.java.main_class' in data.get('job_configs', {}).get('configs', {})",36,2
openstack%2Fopenstack-manuals~master~Id0caa6717bdfe65bab712b5e7c40fa8f37833d41,openstack/openstack-manuals,master,Id0caa6717bdfe65bab712b5e7c40fa8f37833d41,flavors: Correct some formatting issues,MERGED,2016-02-16 15:43:05.000000000,2016-02-19 07:49:57.000000000,2016-02-19 07:49:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 15334}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-02-16 15:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/63f6751d65fbe33025d410ca9adbd49206e87d0d', 'message': 'flavors: Correct some formatting issues\n\n* Add additional section headers where helpful\n* Ensure everything is < 79 chars\n* Remove non-ASCII characters\n\nChange-Id: Id0caa6717bdfe65bab712b5e7c40fa8f37833d41\n'}, {'number': 2, 'created': '2016-02-17 09:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2c99964d33e388da494039c838d5ccec2e70057f', 'message': 'flavors: Correct some formatting issues\n\n* Add additional section headers where helpful\n* Ensure everything is < 79 chars\n* Remove non-ASCII characters\n\nChange-Id: Id0caa6717bdfe65bab712b5e7c40fa8f37833d41\n'}, {'number': 3, 'created': '2016-02-17 10:15:52.000000000', 'files': ['doc/admin-guide-cloud/source/compute-flavors.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/20cb35787e489d5bf3d6644f7f05d2dd42e2eded', 'message': 'flavors: Correct some formatting issues\n\n* Add additional section headers where helpful\n* Ensure everything is < 79 chars\n* Remove non-ASCII characters\n\nChange-Id: Id0caa6717bdfe65bab712b5e7c40fa8f37833d41\n'}]",4,280772,20cb35787e489d5bf3d6644f7f05d2dd42e2eded,16,6,3,15334,,,0,"flavors: Correct some formatting issues

* Add additional section headers where helpful
* Ensure everything is < 79 chars
* Remove non-ASCII characters

Change-Id: Id0caa6717bdfe65bab712b5e7c40fa8f37833d41
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/72/280772/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/source/compute-flavors.rst'],1,63f6751d65fbe33025d410ca9adbd49206e87d0d,feat/openstack-client,"| Memory MB | Instance memory in megabytes. || RXTX Factor | Optional property allows created servers to have a different || Is Public | Boolean value, whether flavor is available to all users or p\ |.. note:: Flavor customization can be limited by the hypervisor in use. For example the libvirt driver enables quotas on CPUs available to a VM, disk tuning, bandwidth I/O, watchdog behavior, random number generator device control, and instance VIF traffic control. Is Public ~~~~~~~~~ Flavors can be assigned to particular projects. By default, a flavor is public and available to all projects. Private flavors are only accessible to those on the access list and are invisible to other projects. To create and assign a private flavor to a project, run these commands: .. code-block:: console $ openstack flavor create --private p1.medium auto 512 40 4 extra_specs ~~~~~~~~~~~ - ``disk_read_bytes_sec`` - ``disk_read_iops_sec`` - ``disk_write_bytes_sec`` - ``disk_write_iops_sec`` - ``disk_total_bytes_sec`` - ``disk_total_iops_sec`` - ``vif_inbound_average`` - ``vif_inbound_burst`` - ``vif_inbound_peak`` - ``vif_outbound_average`` - ``vif_outbound_burst`` - ``vif_outbound_peak`` - ``disabled``: (default) The device is not attached. - ``reset``: Forcefully reset the guest. - ``poweroff``: Forcefully power off the guest. - ``pause``: Pause the guest. - ``none``: Only enable the watchdog; do nothing if the server hangs. - RATE-BYTES: (Integer) Allowed amount of bytes that the guest can - RATE-PERIOD: (Integer) Duration of the read period in seconds. - FLAVOR-SOCKETS: (integer) The number of sockets for the guest VM. By - FLAVOR-CORES: (integer) The number of cores per socket for the guest VM. By this is set to 1. - FLAVOR-THREADS: (integer) The number of threads per core for the guest VM. By this is set to 1. $ openstack flavor set FLAVOR-NAME --property hw:dedicated=PIN-POLICY - ``shared``: (default) The guest vCPUs will be allowed to freely float - ``dedicated``: The guest vCPUs will be strictly pinned to a set of host typically expose all vCPUs as sockets with one core and one thread. When strict CPU pinning is in effect the guest CPU topology will be setup to match the topology of the CPUs to which it is pinned. This option assumes the overcommit ratio is 1.0. For example, if a two vCPU guest is pinned to a single host core with two threads, then the guest will get a topology of one socket, one core, threads threads.","| Memory_MB | Virtual machine memory in megabytes. || RXTX_Factor | Optional property allows created servers to have a different || Is_Public | Boolean value, whether flavor is available to all users or p\ || Flavor customization can be limited by the hypervisor in use. For example the libvirt driver enables quotas on CPUs available to a VM, disk tuning, bandwidth I/O, watchdog behavior, random number generator device control, and instance VIF traffic control. - disk\_read\_bytes\_sec - disk\_read\_iops\_sec - disk\_write\_bytes\_sec - disk\_write\_iops\_sec - disk\_total\_bytes\_sec - disk\_total\_iops\_sec - vif\_inbound\_ average - vif\_inbound\_burst - vif\_inbound\_peak - vif\_outbound\_ average - vif\_outbound\_burst - vif\_outbound\_peak - ``disabled``—(default) The device is not attached. - ``reset``—Forcefully reset the guest. - ``poweroff``—Forcefully power off the guest. - ``pause``—Pause the guest. - ``none``—Only enable the watchdog; do nothing if the server hangs. - RATE-BYTES—(Integer) Allowed amount of bytes that the guest can - RATE-PERIOD—(Integer) Duration of the read period in seconds. - FLAVOR-SOCKETS—(Integer) The number of sockets for the guest VM. By - FLAVOR-CORES—(Integer) The number of cores per socket for the guest VM. By this is set to 1. - FLAVOR-THREADS—(Integer) The number of threads per core for the guest VM. By this is set to 1. $ openstack flavor set FLAVOR-NAME --property hw:dedicated=PIN-POLICY - ``shared``—(default) The guest vCPUs will be allowed to freely float - ``dedicated``—the guest vCPUs will be strictly pinned to a set of host typically expose all vCPUs as sockets with 1 core and 1 thread. When strict CPU pinning is in effect the guest CPU topology will be setup to match the topology of the CPUs to which it is pinned. This option assumes the overcommit ratio is 1.0. For example, if a 2 vCPU guest is pinned to a single host core with 2 threads, then the guest will get a topology of 1 socket, 1 core, 2 threads. Project private flavors Flavors can also be assigned to particular projects. By default, a flavor is public and available to all projects. Private flavors are only accessible to those on the access list and are invisible to other projects. To create and assign a private flavor to a project, run these commands: .. code-block:: console $ openstack flavor create --private p1.medium auto 512 40 4",56,70
openstack%2Ffuel-main~master~I4ad586b8964c600ad80f055707bca49b50506d1b,openstack/fuel-main,master,I4ad586b8964c600ad80f055707bca49b50506d1b,Change filename parsing to ip output,MERGED,2016-01-20 14:30:17.000000000,2016-02-19 07:44:44.000000000,2016-02-19 07:44:44.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 7562}, {'_account_id': 9387}, {'_account_id': 10474}, {'_account_id': 11827}, {'_account_id': 12817}, {'_account_id': 13194}, {'_account_id': 14316}]","[{'number': 1, 'created': '2016-01-20 14:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7b136396d882739c1c34616e5be29e3f57b9dfe1', 'message': ""Change filename parsing to ip output\n\nAs filename parsing is a fragile way, change it to use 'ip' utility\noutput for when finding interfaces with ip addresses equal to admin\ninterface ip address.\n\nChange-Id: I4ad586b8964c600ad80f055707bca49b50506d1b\nCloses-Bug: #1524686\n""}, {'number': 2, 'created': '2016-01-28 11:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/139dd08f073b86ef98a533eb485dbbb29d8c78a8', 'message': ""Change filename parsing to ip output\n\nAs filename parsing is a fragile way, change it to use 'ip' utility\noutput for when finding interfaces with ip addresses equal to admin\ninterface ip address.\n\nChange-Id: I4ad586b8964c600ad80f055707bca49b50506d1b\nCloses-Bug: #1524686\n""}, {'number': 3, 'created': '2016-02-01 13:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5f319a65c54a7489f1e1dbfb81ba58e7e3a6740d', 'message': ""Change filename parsing to ip output\n\nAs filename parsing is a fragile way, change it to use 'ip' utility\noutput for when finding interfaces with ip addresses equal to admin\ninterface ip address.\n\nChange-Id: I4ad586b8964c600ad80f055707bca49b50506d1b\nCloses-Bug: #1524686\n""}, {'number': 4, 'created': '2016-02-15 15:33:02.000000000', 'files': ['iso/bootstrap_admin_node.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8e263e0425f1a2673188058492d5a136bc6fb625', 'message': ""Change filename parsing to ip output\n\nAs filename parsing is a fragile way, change it to use 'ip' utility\noutput for when finding interfaces with ip addresses equal to admin\ninterface ip address.\n\nChange-Id: I4ad586b8964c600ad80f055707bca49b50506d1b\nCloses-Bug: #1524686\n""}]",12,270217,8e263e0425f1a2673188058492d5a136bc6fb625,28,10,4,11827,,,0,"Change filename parsing to ip output

As filename parsing is a fragile way, change it to use 'ip' utility
output for when finding interfaces with ip addresses equal to admin
interface ip address.

Change-Id: I4ad586b8964c600ad80f055707bca49b50506d1b
Closes-Bug: #1524686
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/17/270217/4 && git format-patch -1 --stdout FETCH_HEAD,['iso/bootstrap_admin_node.sh'],1,7b136396d882739c1c34616e5be29e3f57b9dfe1,bug/1524686," local path adminif_ipaddr=$(ip -4 -o a s ${ADMIN_INTERFACE} | sed 's:/:\ :;s:\s\+:\ :g' | cut -d ' ' -f 4) for if_name in $(ip -4 -o a | sed 's:/:\ :;s:\s\+:\ :g;/\slo\s/d' | cut -d ' ' -f 2); do if_ipaddr=$(ip -4 -o a s ${if_name} | sed 's:/:\ :;s:\s\+:\ :g' | cut -d ' ' -f 4) path=""/etc/sysconfig/network-scripts/ifcfg-${if_name}"" if [[ -f ${path} ]]; then mv -f ""${path}"" ""${bup_folder}"" fi"," local if_config adminif_ipaddr=$(get_ifcfg_value IPADDR /etc/sysconfig/network-scripts/ifcfg-${ADMIN_INTERFACE}) for if_config in $(find /etc/sysconfig/network-scripts -name 'ifcfg-*' ! -name 'ifcfg-lo'); do if_name=$(get_ifcfg_value NAME $if_config) if_ipaddr=$(get_ifcfg_value IPADDR $if_config) mv -f ""${if_config}"" ""${bup_folder}""",8,6
openstack%2Fdevstack~master~I62682a85601f4b15a4af052f61ecdf31ab3a05d6,openstack/devstack,master,I62682a85601f4b15a4af052f61ecdf31ab3a05d6,_parse_package_files strips longest match of '#*',ABANDONED,2016-02-19 06:20:20.000000000,2016-02-19 07:41:46.000000000,,"[{'_account_id': 7118}, {'_account_id': 10385}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-19 06:20:20.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0119a4874e8575a2a6f801c468258469f5b1cf6d', 'message': ""_parse_package_files strips longest match of '#*'\n\nWe need to strip longest match of '#*' from package name line\notherwise wrong package name will be returned if there's\nmore than one '#' following package name.\n(eg: https://review.openstack.org/#/c/276911/)\nSince package name won't contain '#', this should be safe.\n\nChange-Id: I62682a85601f4b15a4af052f61ecdf31ab3a05d6\nCloses-Bug: #1547335\n""}]",0,282195,0119a4874e8575a2a6f801c468258469f5b1cf6d,5,3,1,14624,,,0,"_parse_package_files strips longest match of '#*'

We need to strip longest match of '#*' from package name line
otherwise wrong package name will be returned if there's
more than one '#' following package name.
(eg: https://review.openstack.org/#/c/276911/)
Since package name won't contain '#', this should be safe.

Change-Id: I62682a85601f4b15a4af052f61ecdf31ab3a05d6
Closes-Bug: #1547335
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/282195/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,0119a4874e8575a2a6f801c468258469f5b1cf6d,bug/1547335, package=${line%%#*}, package=${line%#*},1,1
openstack%2Fopenstack-manuals~stable%2Fliberty~Ic4d209d19c9452fc582a6172c26587cd23899b9d,openstack/openstack-manuals,stable/liberty,Ic4d209d19c9452fc582a6172c26587cd23899b9d,Imported Translations from Zanata,MERGED,2016-02-19 06:12:49.000000000,2016-02-19 07:34:21.000000000,2016-02-19 07:34:20.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-19 06:12:49.000000000', 'files': ['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4ee83a5c96a39b1791ae12dc56418120fe6232e8', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic4d209d19c9452fc582a6172c26587cd23899b9d\n'}]",0,282192,4ee83a5c96a39b1791ae12dc56418120fe6232e8,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ic4d209d19c9452fc582a6172c26587cd23899b9d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/282192/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'],1,4ee83a5c96a39b1791ae12dc56418120fe6232e8,zanata/translations,"""PO-Revision-Date: 2016-02-18 10:44+0000\n""msgid ""Add each storage node to the ring:"" msgstr ""Ajouter chaque nœud de stockage à l'anneau:"" ""Although Object Storage supports any file system with :term:`extended "" ""attributes (xattr)`, testing and benchmarking indicate the best performance "" ""and reliability on :term:`XFS`. For more information on horizontally scaling "" ""your environment, see the `Deployment Guide <http://docs.openstack.org/"" ""developer/swift/deployment_guide.html>`_."" msgstr """" ""Bien que le Stockage Objet supporte tout système de fichier avec des :term:"" ""`attributs étendus (xattr)`, les tests et benchmarks ont montré les "" ""meilleures performances et fiabilité sur :term:`XFS`. Pour plus "" ""d'informations sur le redimensionnement horizontal de votre environnement, "" ""voir le `Guide de Déploiement <http://docs.openstack.org/developer/swift/"" ""deployment_guide.html>`_."" msgid """"""Before starting the Object Storage services, you must create the initial "" ""account, container, and object rings. The ring builder creates configuration "" ""files that each node uses to determine and deploy the storage architecture. "" ""For simplicity, this guide uses one region and zone with 2^10 (1024) maximum "" ""partitions, 3 replicas of each object, and 1 hour minimum time between "" ""moving a partition more than once. For Object Storage, a partition indicates "" ""a directory on a storage device rather than a conventional partition table. "" ""For more information, see the `Deployment Guide <http://docs.openstack.org/"" ""developer/swift/deployment_guide.html>`__."" msgstr """" ""Avant de démarrer les services de Stockage Objet, vous devez créer le compte "" ""initial, le conteneur, et les anneaux d'objet. Le constructeur d'anneau créé "" ""des fichiers de configuration que chaque nœud utilise pour déterminer et "" ""déployer l'architecture de stockage. Pour simplifier, ce guide utilise une "" ""région et zone avec au maximum 2^10 (1024) partitions, 3 replicas de chaque "" ""objet, et au minimum 1 heure entre les déplacements multiples de partition. "" ""Pour le Stockage Objet, une partition désigne un répertoire sur un device de "" ""stockage plutôt qu'une table de partition conventionnelle. Pour plus "" ""d'informations, voir le `Guide de Déploiement <http://docs.openstack.org/"" ""developer/swift/deployment_guide.html>`__."" msgid """"""Before you install and configure the Object Storage service on the storage "" ""nodes, you must prepare the storage devices."" msgstr """" ""Avant d'installer et configurer le service de Stockage Objet sur les nœuds "" ""de stockage, vous devez préparer les devices de stockage."" msgid """"msgid ""Change to the ``/etc/swift`` directory."" msgstr ""Change to the ``/etc/swift`` directory."" ""Copy the ``account.ring.gz``, ``container.ring.gz``, and ``object.ring.gz`` "" ""files to the ``/etc/swift`` directory on each storage node and any "" ""additional nodes running the proxy service."" msgstr """" ""Copier les fichiers ``account.ring.gz``, ``container.ring.gz``, et ``object."" ""ring.gz`` dans le répertoire ``/etc/swift`` sur chaque nœud de stockage et "" ""tout nœud supplémentaire faisant tourner le service proxy."" msgid """"msgid ""Create account ring"" msgstr ""Créer l'anneau des comptes"" msgid ""Create container ring"" msgstr ""Créer l'anneau containeur"" msgid ""Create object ring"" msgstr ""Créer l'anneau des objets"" msgid ""Create the base ``container.builder`` file:"" msgstr ""Créer le fichier de base ``container.builder``:"" msgid ""Create the base ``object.builder`` file:"" msgstr ""Créer le fichier de base ``object.builder``:"" msgid ""Create the mount point directory structure:"" msgstr ""Créer la structure de répertoire du point de montage:"" msgid ""Format the ``/dev/sdb`` and ``/dev/sdc`` devices as XFS:"" msgstr ""Formater les devices ``/dev/sdb`` et ``/dev/sdc`` en XFS:"" ""In the ``[DEFAULT]`` section, configure the bind IP address, bind port, "" ""user, configuration directory, and mount point directory:"" msgstr """" ""Dans la section ``[DEFAULT]``, configurer l'adresse IP de bind, le port de "" ""port, l'utilisateur, l répertoire de configuration, et les répertoire de "" ""point de montage:"" msgid """"""In the ``[filter:recon]`` section, configure the recon (meters) cache and "" ""lock directories:"" msgstr """" ""Dans la section ``[filter:recon]``, configurer les répertoires cache et "" ""verrou recon (compteurs):"" msgid """" ""In the ``[filter:recon]`` section, configure the recon (meters) cache "" ""directory:"" msgstr """" ""Dans la section ``[filter:recon]``, configurer le répertoire du cache recon "" ""(compteurs):"" msgid """"""Obtain the accounting, container, and object service configuration files "" ""from the Object Storage source repository:"" msgstr """" ""Obtenir les fichier de configuration des services de compte, de conteneur et "" ""d'objet à partir du répertoire source du Stockage d'Objet:"" msgid """"msgid """" ""Repeat this command for each storage device on each storage node. In the "" ""example architecture, use the command in four variations:"" msgstr """" ""Répéter cette commande pour chaque device de stockage sur chaque nœud de "" ""stockage. Dans l'exemple d'architecture, utiliser la commande quatre fois:"" ""Replace ``STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS`` with the IP address "" ""of the management network on the storage node. Replace ``DEVICE_NAME`` with "" ""a storage device name on the same storage node. For example, using the first "" ""storage node in :ref:`swift-storage` with the ``/dev/sdb`` storage device "" ""and weight of 100:"" msgstr """" ""Remplacer ``STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS`` par l'adresse IP "" ""du réseau de management sur le nœud de stockage. Remplacer ``DEVICE_NAME`` "" ""par le nom d'un device de stockage sur le même nœud de stockage. Par "" ""exemple, utiliser le premier nœud de stockage du :ref:`swift-storage` avec "" ""le device de stockage ``/dev/sdb``et le poids de 100:"" msgid """"""The account server uses the account ring to maintain lists of containers."" msgstr """" ""Le serveur de compte utilise l'anneau de compte pour maintenir les listes de "" ""conteneurs."" msgid """"msgid """" ""The container server uses the container ring to maintain lists of objects. "" ""However, it does not track object locations."" msgstr """" ""Le serveur conteneur utilise l'anneau des conteneurs pour maintenir les "" ""listes d'objets. Néanmoins, il ne trace pas l'emplacement des objets. "" ""The controller node runs the Identity service, Image service, management "" ""portions of Compute, management portion of Networking, various Networking "" ""agents, and the dashboard. It also includes supporting services such as an "" ""SQL database, :term:`message queue`, and :term:`NTP`."" msgstr """" ""Le nœud contrôleur héberge le service d'Identité, le service d'Image, la "" ""partie management du Compute et du Réseau, plusieurs agents Réseau, et le "" ""dashboard. Il inclut également les services support comme une base de "" ""données SQL, la :term:`file de message`, et :term:`NTP`."" msgid """"""The object server uses the object ring to maintain lists of object locations "" ""on local devices."" msgstr """" ""Le serveur d'objets utilise l'anneau des objets pour maintenir les listes "" ""des emplacements des objets sur les devices locaux."" msgid """"""This section describes how to install and configure storage nodes that "" ""operate the account, container, and object services. For simplicity, this "" ""configuration references two storage nodes, each containing two empty local "" ""block storage devices. The instructions use ``/dev/sdb`` and ``/dev/sdc``, "" ""but you can substitute different values for your particular nodes."" msgstr """" ""Cette section décrit comment installer et configurer les nœuds de stockage "" ""qui font tourner les services compte, conteneur, et objet. Pour simplifier, "" ""cette configuration référence deux nœuds de stockage, chacun contenant deux "" ""devices locales de stockage blocs vides. Les instructions utilisent ``/dev/"" ""sdb`` et ``/dev/sdc``, mais vous pouvez les substituer par des valeurs "" ""différentes en fonction de la configuration de vos nœuds."" msgid """"msgid ""Verify the ring contents:"" msgstr ""Vérifier les contenus des anneaux:"" ","""PO-Revision-Date: 2016-02-17 10:40+0000\n""",177,1
openstack%2Fneutron~master~I422fc04015fa50e2176e41128adc41d7a22fe02b,openstack/neutron,master,I422fc04015fa50e2176e41128adc41d7a22fe02b,Adopt Grafana to plot Neutron Failure Rates,MERGED,2016-02-11 02:35:39.000000000,2016-02-19 07:25:52.000000000,2016-02-19 07:25:52.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 11682}, {'_account_id': 13995}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-11 02:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6486a0f26b48b4005a6bee53fb78a5be69a9af49', 'message': 'Adopt Grafana to plot Neutron Failure Rates\n\nMaintaining these dashboards in tree is a bit painful, the URLs are not\nhuman readable, and furthermore the graphs are not interactive (e.g.\nzoomable).\n\nWe should adopt Grafana, and to see how this looks like, check [1] out.\n\n[1] http://grafana.openstack.org/dashboard/db/tempest-failure-rate\n\nChange-Id: I422fc04015fa50e2176e41128adc41d7a22fe02b\nDepends-on: If7552e10bcafd17e245b3a5de839bcaa0ef12b97\n'}, {'number': 2, 'created': '2016-02-11 02:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc035e350fd31836600c6665c9cb7688ba7f32c5', 'message': 'Adopt Grafana to plot Neutron Failure Rates\n\nMaintaining these dashboards in tree is a bit painful, the queries\ncan be brittle, the URLs are not human readable, and furthermore the\ngraphs are not interactive (e.g. zoomable).\n\nWe should adopt Grafana, and to see how this looks like, please check\n[1] out for an example.\n\n[1] http://grafana.openstack.org/dashboard/db/tempest-failure-rate\n\nChange-Id: I422fc04015fa50e2176e41128adc41d7a22fe02b\nDepends-on: If7552e10bcafd17e245b3a5de839bcaa0ef12b97\n'}, {'number': 3, 'created': '2016-02-11 17:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4550a9191996e25b5c04d417f366ead3568a8024', 'message': 'Adopt Grafana to plot Neutron Failure Rates\n\nMaintaining these dashboards in tree is a bit painful, the queries\ncan be brittle, the URLs are not human readable, and furthermore the\ngraphs are not interactive (e.g. zoomable).\n\nWe should adopt Grafana, and to see how this looks like, please check\n[1] out for an example.\n\n[1] http://grafana.openstack.org/dashboard/db/tempest-failure-rate\n\nDepends-on: If7552e10bcafd17e245b3a5de839bcaa0ef12b97\n\nChange-Id: I422fc04015fa50e2176e41128adc41d7a22fe02b\n\n'}, {'number': 4, 'created': '2016-02-12 00:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/21e22389df18d3fe0f54d3857d065ef03339dc3f', 'message': 'Adopt Grafana to plot Neutron Failure Rates\n\nMaintaining these dashboards in tree is a bit painful, the queries\ncan be brittle, the URLs are not human readable, and furthermore the\ngraphs are not interactive (e.g. zoomable).\n\nWe should adopt Grafana, and to see how this looks like, please check\ntempest failure rate inline.\n\nDepends-on: If7552e10bcafd17e245b3a5de839bcaa0ef12b97\n\nChange-Id: I422fc04015fa50e2176e41128adc41d7a22fe02b\n'}, {'number': 5, 'created': '2016-02-19 01:48:56.000000000', 'files': ['doc/source/dashboards/gate.dashboard.rst', 'doc/source/dashboards/check.dashboard.rst', 'doc/source/dashboards/index.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f15d724e4733c9343c941b1071e1435780b5728', 'message': 'Adopt Grafana to plot Neutron Failure Rates\n\nMaintaining these dashboards in tree is a bit painful, the queries\ncan be brittle, the URLs are not human readable, and furthermore the\ngraphs are not interactive (e.g. zoomable).\n\nWe should adopt Grafana, and to see how this looks like, please check\ntempest failure rate inline.\n\nChange-Id: I422fc04015fa50e2176e41128adc41d7a22fe02b\n'}]",5,278836,8f15d724e4733c9343c941b1071e1435780b5728,56,17,5,748,,,0,"Adopt Grafana to plot Neutron Failure Rates

Maintaining these dashboards in tree is a bit painful, the queries
can be brittle, the URLs are not human readable, and furthermore the
graphs are not interactive (e.g. zoomable).

We should adopt Grafana, and to see how this looks like, please check
tempest failure rate inline.

Change-Id: I422fc04015fa50e2176e41128adc41d7a22fe02b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/278836/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dashboards/gate.dashboard.rst', 'doc/source/dashboards/check.dashboard.rst', 'doc/source/dashboards/index.rst']",3,6486a0f26b48b4005a6bee53fb78a5be69a9af49,adopt-grafana,.. _Neutron Failure Rate: http://grafana.openstack.org/dashboard/db/neutron-failure-rate, Neutron Graphite Pages ====================== .. toctree:: :maxdepth: 1 gate.dashboard check.dashboard,1,79
openstack%2Fos-brick~master~I34b51769fa27760a8b23e91295e3dd679eb6f9df,openstack/os-brick,master,I34b51769fa27760a8b23e91295e3dd679eb6f9df,Fix the bug of devices list is always none,ABANDONED,2015-12-07 09:23:19.000000000,2016-02-19 07:24:07.000000000,,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 12369}, {'_account_id': 13847}, {'_account_id': 14242}, {'_account_id': 14384}, {'_account_id': 15374}, {'_account_id': 16595}, {'_account_id': 16708}, {'_account_id': 16897}, {'_account_id': 18402}, {'_account_id': 18967}]","[{'number': 1, 'created': '2015-12-07 09:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/d979c7492d94a8006a5171ecee601b3c82f62f1d', 'message': 'Fix the bug of devices list is always none\n\nThe default driver to get all block devices is\n\'host_driver.HostDriver\', it returns a value like\n[""/dev/disk/by-path/ip-portal1-iscsi-iqn1-lun-1"",\n""/dev/disk/by-path/ip-portal2-iscsi-iqn2-lun-1"",...]\nto block_devices list. But the mpath_map is a dict like\n{\'/dev/sda\': \'/dev/mapper/dm-1\',\n\'/dev/sda\': \'/dev/mapper/dm-1\',...}.\nSo, mpath_map and block_devices describe the same block device with\ntwo different format. This causes mpath_map.get(dev) always return\na None value, and the devices list always be None.\n\nThis patch fixed this bug by using realpath to get mpdev from\nmpath_map.\n\nChange-Id: I34b51769fa27760a8b23e91295e3dd679eb6f9df\n'}, {'number': 2, 'created': '2015-12-07 11:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/4be464b75732bf4a96c9901c56963a471a14299c', 'message': 'Fix the bug of devices list is always none\n\nThe default driver to get all block devices is\n\'host_driver.HostDriver\', it returns a value like\n[""/dev/disk/by-path/ip-portal1-iscsi-iqn1-lun-1"",\n""/dev/disk/by-path/ip-portal2-iscsi-iqn2-lun-1"",...]\nto block_devices list. But the mpath_map is a dict like\n{\'/dev/sda\': \'/dev/mapper/dm-1\',\n\'/dev/sda\': \'/dev/mapper/dm-1\',...}.\nSo, mpath_map and block_devices describe the same block device with\ntwo different format. This causes mpath_map.get(dev) always return\na None value, and the devices list always be None.\n\nThis patch fixed this bug by using realpath to get mpdev from\nmpath_map.\n\nChange-Id: I34b51769fa27760a8b23e91295e3dd679eb6f9df\n'}, {'number': 3, 'created': '2015-12-07 11:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/92b26a4f443d2ff6b5b9fa70e673ef9c89b316eb', 'message': 'Fix the bug of devices list is always none\n\nThe default driver to get all block devices is\n\'host_driver.HostDriver\', it returns a value like\n[""/dev/disk/by-path/ip-portal1-iscsi-iqn1-lun-1"",\n""/dev/disk/by-path/ip-portal2-iscsi-iqn2-lun-1"",...]\nto block_devices list. But the mpath_map is a dict like\n{\'/dev/sda\': \'/dev/mapper/dm-1\',\n\'/dev/sdb\': \'/dev/mapper/dm-1\',...}.\nSo, mpath_map and block_devices describe the same block device with\ntwo different format(One is realpath, but another is symbolic link). This causes mpath_map.get(dev) always return a None value, and the devices list always be None.\n\nThis patch fixed this bug by using realpath to get mpdev from\nmpath_map.\n\nChange-Id: I34b51769fa27760a8b23e91295e3dd679eb6f9df\n'}, {'number': 4, 'created': '2015-12-07 11:36:27.000000000', 'files': ['os_brick/tests/initiator/test_connector.py', 'os_brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/87c19afd1502c66122507908b480260ff9b772fd', 'message': 'Fix the bug of devices list is always none\n\nThe default driver to get all block devices is\n\'host_driver.HostDriver\', it returns a value like\n[""/dev/disk/by-path/ip-portal1-iscsi-iqn1-lun-1"",\n""/dev/disk/by-path/ip-portal2-iscsi-iqn2-lun-1"",...]\nto block_devices list. But the mpath_map is a dict like\n{\'/dev/sda\': \'/dev/mapper/dm-1\',\n\'/dev/sdb\': \'/dev/mapper/dm-1\',...}.\nSo, mpath_map and block_devices describe the same block device with\ntwo different format(One is realpath, but another is symbolic link). \nThis causes mpath_map.get(dev) always return a None value, and the \ndevices list always be None.\n\nThis patch fixed this bug by using realpath to get mpdev from\nmpath_map.\n\nChange-Id: I34b51769fa27760a8b23e91295e3dd679eb6f9df\n'}]",4,254091,87c19afd1502c66122507908b480260ff9b772fd,25,12,4,18967,,,0,"Fix the bug of devices list is always none

The default driver to get all block devices is
'host_driver.HostDriver', it returns a value like
[""/dev/disk/by-path/ip-portal1-iscsi-iqn1-lun-1"",
""/dev/disk/by-path/ip-portal2-iscsi-iqn2-lun-1"",...]
to block_devices list. But the mpath_map is a dict like
{'/dev/sda': '/dev/mapper/dm-1',
'/dev/sdb': '/dev/mapper/dm-1',...}.
So, mpath_map and block_devices describe the same block device with
two different format(One is realpath, but another is symbolic link). 
This causes mpath_map.get(dev) always return a None value, and the 
devices list always be None.

This patch fixed this bug by using realpath to get mpdev from
mpath_map.

Change-Id: I34b51769fa27760a8b23e91295e3dd679eb6f9df
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/91/254091/4 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/initiator/test_connector.py', 'os_brick/initiator/connector.py']",2,d979c7492d94a8006a5171ecee601b3c82f62f1d,fix-bug-of-mpdev-map, dev_real_path = os.path.realpath(dev) mpdev = mpath_map.get(dev_real_path), mpdev = mpath_map.get(dev),23,9
openstack%2Fswift~master~I1af48728b28da9780a2a78f3110e1c7487047ff8,openstack/swift,master,I1af48728b28da9780a2a78f3110e1c7487047ff8,Add unit tests for checking responses in AccountController,MERGED,2016-01-22 05:34:31.000000000,2016-02-19 07:23:53.000000000,2016-02-19 07:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 12193}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-01-22 05:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9d469c52b397205f0f164955ba3b3fe6dbaec16d', 'message': 'Add unit tests for checking responses in AccountController\n\nThis patch provides unit tests to check responses for various situation\nin three/four replicas env.\n\nChange-Id: I1af48728b28da9780a2a78f3110e1c7487047ff8\n'}, {'number': 2, 'created': '2016-01-22 05:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8b81c7508f0e87573ada71b215482b01014f89c9', 'message': 'Add unit tests for checking responses in AccountController\n\nThis patch provides unit tests to check responses for various situation\nin three/four replicas env.\n\nChange-Id: I1af48728b28da9780a2a78f3110e1c7487047ff8\n'}, {'number': 3, 'created': '2016-01-22 07:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/785fc9662ace7026bbd45475097da0c13346e68d', 'message': 'Add unit tests for checking responses in AccountController\n\nThis patch provides unit tests to check responses for various situation\nin three/four replicas env.\n\nChange-Id: I1af48728b28da9780a2a78f3110e1c7487047ff8\n'}, {'number': 4, 'created': '2016-01-27 07:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eb8653aad93312ef742888a48a7153dfc381ca78', 'message': 'Add unit tests for checking responses in AccountController\n\nThis patch provides unit tests to check responses for various situation\nin three/four replicas env.\n\nChange-Id: I1af48728b28da9780a2a78f3110e1c7487047ff8\n'}, {'number': 5, 'created': '2016-01-27 13:36:41.000000000', 'files': ['test/unit/proxy/controllers/test_account.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c871e423ef0bed6c774693af3d54750235d6ce1f', 'message': 'Add unit tests for checking responses in AccountController\n\nThis patch provides unit tests to check responses for various situation\nin three/four replicas env.\n\nChange-Id: I1af48728b28da9780a2a78f3110e1c7487047ff8\n'}]",20,271142,c871e423ef0bed6c774693af3d54750235d6ce1f,26,5,5,12193,,,0,"Add unit tests for checking responses in AccountController

This patch provides unit tests to check responses for various situation
in three/four replicas env.

Change-Id: I1af48728b28da9780a2a78f3110e1c7487047ff8
",git fetch https://review.opendev.org/openstack/swift refs/changes/42/271142/4 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/proxy/controllers/test_account.py'],1,9d469c52b397205f0f164955ba3b3fe6dbaec16d,add-account-ut," # there are two account servers and one account server downed. fake_http_connect(204, 404, give_connect=callback)): resp = controller.POST(req) self.assertEqual(503, resp.status_int) def test_response_code_for_PUT(self): PUT_TEST_CASES = [ ((204, 204, 204), 204), ((204, 204, 404), 204), ((204, 204, 503), 204), ((204, 404, 404), 404), ((204, 404, 503), 503), ((204, 503, 503), 503), ((404, 404, 404), 404), ((404, 404, 503), 404), ((404, 503, 503), 503), ((503, 503, 503), 503) ] self.app.allow_account_management = True controller = proxy_server.AccountController(self.app, 'AUTH_bob') context = {} callback = self._make_callback_func(context) for responses, expected in PUT_TEST_CASES: with mock.patch( 'swift.proxy.controllers.base.http_connect', fake_http_connect(*responses, give_connect=callback)): req = Request.blank('/v1/AUTH_bob') resp = controller.PUT(req) self.assertEqual(expected, resp.status_int) def test_response_code_for_DELETE(self): DELETE_TEST_CASES = [ ((204, 204, 204), 204), ((204, 204, 404), 204), ((204, 204, 503), 204), ((204, 404, 404), 404), ((204, 404, 503), 503), ((204, 503, 503), 503), ((404, 404, 404), 404), ((404, 404, 503), 404), ((404, 503, 503), 503), ((503, 503, 503), 503) ] self.app.allow_account_management = True controller = proxy_server.AccountController(self.app, 'AUTH_bob') for responses, expected in DELETE_TEST_CASES: with mock.patch('swift.proxy.controllers.base.http_connect', fake_http_connect(*responses)): req = Request.blank('/v1/AUTH_bob') resp = controller.DELETE(req) self.assertEqual(expected, resp.status_int) def test_response_code_for_POST(self): POST_TEST_CASES = [ ((204, 204, 204), 204), ((204, 204, 404), 204), ((204, 204, 503), 204), ((204, 404, 404), 404), ((204, 404, 503), 503), ((204, 503, 503), 503), ((404, 404, 404), 404), ((404, 404, 503), 404), ((404, 503, 503), 503), ((503, 503, 503), 503) ] controller = proxy_server.AccountController(self.app, 'AUTH_bob') for responses, expected in POST_TEST_CASES: with mock.patch('swift.proxy.controllers.base.http_connect', fake_http_connect(*responses)): req = Request.blank('/v1/AUTH_bob') resp = controller.POST(req) self.assertEqual(expected, resp.status_int) def test_response_code_for_GET(self): GET_TEST_CASES = [ (200, 200), (404, 404), (503, 503) ] controller = proxy_server.AccountController(self.app, 'AUTH_bob') for response, expected in GET_TEST_CASES: with mock.patch('swift.proxy.controllers.base.http_connect', fake_http_connect(response)): req = Request.blank('/v1/AUTH_bob') resp = controller.GET(req) self.assertEqual(expected, resp.status_int) def test_response_code_for_HEAD(self): HEAD_TEST_CASES = [ (200, 200), (404, 404), (503, 503) ] controller = proxy_server.AccountController(self.app, 'AUTH_bob') for response, expected in HEAD_TEST_CASES: with mock.patch('swift.proxy.controllers.base.http_connect', fake_http_connect(response)): req = Request.blank('/v1/AUTH_bob') resp = controller.HEAD(req) self.assertEqual(expected, resp.status_int) @patch_policies( [StoragePolicy(0, 'zero', True, object_ring=FakeRing(replicas=4))]) class TestAccountController4Replicas(TestAccountController): def setUp(self): self.app = proxy_server.Application( None, FakeMemcache(), account_ring=FakeRing(replicas=4), container_ring=FakeRing(replicas=4)) def test_response_code_for_PUT(self): PUT_TEST_CASES = [ ((200, 200, 200, 200), 200), ((200, 200, 200, 404), 200), ((200, 200, 200, 503), 200), ((200, 200, 404, 404), 503), ((200, 200, 404, 503), 503), ((200, 200, 503, 503), 503), ((200, 404, 404, 404), 404), ((200, 404, 404, 503), 503), ((200, 404, 503, 503), 503), ((200, 503, 503, 503), 503), ((404, 404, 404, 404), 404), ((404, 404, 404, 503), 404), ((404, 503, 503, 503), 503), ((503, 503, 503, 503), 503) ] self.app.allow_account_management = True controller = proxy_server.AccountController(self.app, 'AUTH_bob') context = {} callback = self._make_callback_func(context) for responses, expected in PUT_TEST_CASES: with mock.patch( 'swift.proxy.controllers.base.http_connect', fake_http_connect(*responses, give_connect=callback)): req = Request.blank('/v1/AUTH_bob') resp = controller.PUT(req) self.assertEqual(expected, resp.status_int) def test_response_code_for_DELETE(self): DELETE_TEST_CASES = [ ((204, 204, 204, 204), 204), ((204, 204, 204, 404), 204), ((204, 204, 204, 503), 204), ((204, 204, 404, 404), 503), ((204, 204, 404, 503), 503), ((204, 204, 503, 503), 503), ((204, 404, 404, 404), 404), ((204, 404, 404, 503), 503), ((204, 404, 503, 503), 503), ((204, 503, 503, 503), 503), ((404, 404, 404, 404), 404), ((404, 404, 404, 503), 404), ((404, 503, 503, 503), 503), ((503, 503, 503, 503), 503) ] self.app.allow_account_management = True controller = proxy_server.AccountController(self.app, 'AUTH_bob') for responses, expected in DELETE_TEST_CASES: with mock.patch('swift.proxy.controllers.base.http_connect', fake_http_connect(*responses)): req = Request.blank('/v1/AUTH_bob') resp = controller.DELETE(req) print '# responses: %s %s %s %s' % responses self.assertEqual(expected, resp.status_int) def test_response_code_for_POST(self): POST_TEST_CASES = [ ((204, 204, 204, 204), 204), ((204, 204, 204, 404), 204), ((204, 204, 204, 503), 204), ((204, 204, 404, 404), 503), ((204, 204, 404, 503), 503), ((204, 204, 503, 503), 503), ((204, 404, 404, 404), 404), ((204, 404, 404, 503), 503), ((204, 404, 503, 503), 503), ((204, 503, 503, 503), 503), ((404, 404, 404, 404), 404), ((404, 404, 404, 503), 404), ((404, 503, 503, 503), 503), ((503, 503, 503, 503), 503) ] controller = proxy_server.AccountController(self.app, 'AUTH_bob') for responses, expected in POST_TEST_CASES: with mock.patch('swift.proxy.controllers.base.http_connect', fake_http_connect(*responses)): req = Request.blank('/v1/AUTH_bob') resp = controller.POST(req) self.assertEqual(expected, resp.status_int) "," fake_http_connect(200, 200, give_connect=callback)): controller.POST(req)",210,2
openstack%2Fkuryr~master~I32680b7b01a0136c3306bfcf28ffd1b2f8babd25,openstack/kuryr,master,I32680b7b01a0136c3306bfcf28ffd1b2f8babd25,Virtualbox now uses 'ubuntu/trusty64' instead of 'trusty',MERGED,2016-02-18 19:44:55.000000000,2016-02-19 07:20:20.000000000,2016-02-19 07:20:20.000000000,"[{'_account_id': 3}, {'_account_id': 11208}, {'_account_id': 12069}]","[{'number': 1, 'created': '2016-02-18 19:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/7991e23d79726fe251004b85ecd500298b84b501', 'message': 'Fix virtualbox target in vagrant, now points to ubuntu/trusty64 instead of trusty.\n\nChange-Id: I32680b7b01a0136c3306bfcf28ffd1b2f8babd25\n'}, {'number': 2, 'created': '2016-02-19 06:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/c4bd4b0f1b02e9b1187a808c9e24d9f99550ff1a', 'message': 'Fix virtualbox target in vagrant, now points to ubuntu/trusty64 instead of trusty.\n\nChange-Id: I32680b7b01a0136c3306bfcf28ffd1b2f8babd25\n'}, {'number': 3, 'created': '2016-02-19 06:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/4aab8041ffd123539ad5e60eb5fe1e294be44206', 'message': ""Fix virtualbox target in vagrant, now points to ubuntu/trusty64 instead of\ntrusty.\n\n'trusty' does not exist in atlas, causing vagrant up to fail. ubuntu/64 does\nexists.\n\nChange-Id: I32680b7b01a0136c3306bfcf28ffd1b2f8babd25\n""}, {'number': 4, 'created': '2016-02-19 06:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/7e37c3e0d1d3d4a442a4c275c0eb4e8b2a124d56', 'message': ""Fix virtualbox target in vagrant, now points to ubuntu/trusty64 instead of\ntrusty.\n\n'trusty' does not exist in atlas, causing vagrant up to fail. ubuntu/trusty64\ndoes exists.\n\nChange-Id: I32680b7b01a0136c3306bfcf28ffd1b2f8babd25\n""}, {'number': 5, 'created': '2016-02-19 06:48:06.000000000', 'files': ['contrib/vagrant/Vagrantfile'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/2675f6b0dbd0d250d3561216efb15e4ad737c44a', 'message': ""Virtualbox now uses 'ubuntu/trusty64' instead of 'trusty'\n\n'trusty' does not exist in atlas, causing vagrant up to fail.\n\nChange-Id: I32680b7b01a0136c3306bfcf28ffd1b2f8babd25\n""}]",1,282029,2675f6b0dbd0d250d3561216efb15e4ad737c44a,15,3,5,20638,,,0,"Virtualbox now uses 'ubuntu/trusty64' instead of 'trusty'

'trusty' does not exist in atlas, causing vagrant up to fail.

Change-Id: I32680b7b01a0136c3306bfcf28ffd1b2f8babd25
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/29/282029/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/vagrant/Vagrantfile'],1,7991e23d79726fe251004b85ecd500298b84b501,," override.vm.box = ENV.fetch('VAGRANT_KURYR_VM_BOX', 'ubuntu/trusty64')"," override.vm.box = ENV.fetch('VAGRANT_KURYR_VM_BOX', 'trusty')",1,1
openstack%2Fdevstack~master~I2c0c3b0198d795d947fd77005fd7528de561dfcb,openstack/devstack,master,I2c0c3b0198d795d947fd77005fd7528de561dfcb,"Re-add ""redhat-rpm-config"" dependency",MERGED,2016-02-05 20:45:43.000000000,2016-02-19 07:14:34.000000000,2016-02-18 21:03:02.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 9257}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 17627}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-05 20:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2b70681cee621254423d7b4d6c955d1b9a449aa5', 'message': 'Re-add ""redhat-rpm-config"" dependency\n\nThis was removed in commit 19363fc1e79e70d390da0f4d0a19a5ef476b11d4 as\nan unneeded F21 dependency, but on F23 netifaces fails to build\nbecause it requires /usr/lib/rpm/redhat/redhat-hardened-cc1.\n\nChange-Id: I2c0c3b0198d795d947fd77005fd7528de561dfcb\n'}, {'number': 2, 'created': '2016-02-11 03:31:50.000000000', 'files': ['files/rpms/general'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a6f3229eb02c409b2d875c9692e9d3b62e859f71', 'message': 'Re-add ""redhat-rpm-config"" dependency\n\nThis was removed in commit 19363fc1e79e70d390da0f4d0a19a5ef476b11d4 as\nan unneeded F21 dependency, but due to missing dependencies as\ndescribed in the bug, /usr/lib/rpm/redhat/redhat-hardened-cc1 is\nrequired and is provided by this package.\n\nChange-Id: I2c0c3b0198d795d947fd77005fd7528de561dfcb\n'}]",1,276911,a6f3229eb02c409b2d875c9692e9d3b62e859f71,17,8,2,9257,,,0,"Re-add ""redhat-rpm-config"" dependency

This was removed in commit 19363fc1e79e70d390da0f4d0a19a5ef476b11d4 as
an unneeded F21 dependency, but due to missing dependencies as
described in the bug, /usr/lib/rpm/redhat/redhat-hardened-cc1 is
required and is provided by this package.

Change-Id: I2c0c3b0198d795d947fd77005fd7528de561dfcb
",git fetch https://review.opendev.org/openstack/devstack refs/changes/11/276911/2 && git format-patch -1 --stdout FETCH_HEAD,['files/rpms/general'],1,2b70681cee621254423d7b4d6c955d1b9a449aa5,276911,redhat-rpm-config # netifaces,,1,0
openstack%2Fos-brick~master~Ib66c254e6eb4394382fc928d833a3a1818336b9b,openstack/os-brick,master,Ib66c254e6eb4394382fc928d833a3a1818336b9b,Include multipath -ll output in failed to parse warning,MERGED,2016-02-18 16:06:13.000000000,2016-02-19 07:12:03.000000000,2016-02-19 00:03:55.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 8912}, {'_account_id': 12924}, {'_account_id': 14242}, {'_account_id': 16595}, {'_account_id': 16708}, {'_account_id': 18402}]","[{'number': 1, 'created': '2016-02-18 16:06:13.000000000', 'files': ['os_brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/0d25bbb5b5f865e8a7f80f490610b71d7f64dceb', 'message': 'Include multipath -ll output in failed to parse warning\n\nThe multipath -ll output is logged at debug level but by\ndefault debug level logging is disabled. If we fail to parse\nthe output of multipath -ll to get the device map, we should\ninclude the command output in the warning message since INFO+\nlogging is enabled by default.\n\nChange-Id: Ib66c254e6eb4394382fc928d833a3a1818336b9b\nCloses-Bug: #1546773\n'}]",0,281926,0d25bbb5b5f865e8a7f80f490610b71d7f64dceb,20,8,1,6873,,,0,"Include multipath -ll output in failed to parse warning

The multipath -ll output is logged at debug level but by
default debug level logging is disabled. If we fail to parse
the output of multipath -ll to get the device map, we should
include the command output in the warning message since INFO+
logging is enabled by default.

Change-Id: Ib66c254e6eb4394382fc928d833a3a1818336b9b
Closes-Bug: #1546773
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/26/281926/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/initiator/connector.py'],1,0d25bbb5b5f865e8a7f80f490610b71d7f64dceb,bug/1546773," LOG.warning(_LW(""Failed to parse the output of multipath -ll. "" ""stdout: %s""), out)"," LOG.warning(_LW(""Failed to parse the output of multipath -ll.""))",2,1
openstack%2Fmonasca-common~master~I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126,openstack/monasca-common,master,I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126,Modify REST data handling,ABANDONED,2016-02-10 07:09:10.000000000,2016-02-19 07:11:26.000000000,,"[{'_account_id': 3}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 16168}, {'_account_id': 16204}, {'_account_id': 16222}]","[{'number': 1, 'created': '2016-02-10 07:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/a026dd015601463a53f9d5fb830a27a5364ed94a', 'message': 'REST data handling\n\nChange common REST data handling to monasca-common according to new\nimplenetation of monasca-log-api with tornado framework\n\nChange-Id: I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126\n'}, {'number': 2, 'created': '2016-02-10 07:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/1385fc20550213a1b135ea45243309e3bffa3921', 'message': 'Modify REST data handling\n\nChange common REST data handling to monasca-common according to new\nimplenetation of monasca-log-api with tornado framework\n\nChange-Id: I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126\n'}, {'number': 3, 'created': '2016-02-10 07:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/dc3d2c6e799656f8f969f7cb0f3633d149dec812', 'message': 'Modify REST data handling\n\nChange common REST data handling to monasca-common according to new\nimplenetation of monasca-log-api with tornado framework\n\nChange-Id: I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126\n'}, {'number': 4, 'created': '2016-02-15 08:20:36.000000000', 'files': ['monasca_common/rest/utils.py'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/44fa2c3964f0ac274945b7d18123edbd3311dce4', 'message': 'Modify REST data handling\n\nChange common REST data handling to monasca-common according to new\nimplenetation of monasca-log-api with tornado framework\n\nChange-Id: I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126\n'}]",1,278233,44fa2c3964f0ac274945b7d18123edbd3311dce4,9,6,4,20033,,,0,"Modify REST data handling

Change common REST data handling to monasca-common according to new
implenetation of monasca-log-api with tornado framework

Change-Id: I5f5e3fddb2e01d63ea55b2b770f63d5e4002c126
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/33/278233/4 && git format-patch -1 --stdout FETCH_HEAD,['monasca_common/rest/utils.py'],1,a026dd015601463a53f9d5fb830a27a5364ed94a,rest-tornado,"def read_body(content, content_type=JSON_CONTENT_TYPE): """"""Reads HTTP content according to given content_type. Content data is processed according to content_type. :param str content: message body :exception: :py:class:`.UnsupportedContentType` - in content_type is not supported if not content: return None ","def read_body(payload, content_type=JSON_CONTENT_TYPE): """"""Reads HTTP payload according to given content_type. Function is capable of reading from payload stream. Read data is then processed according to content_type. :param stream payload: payload to read, payload should have read method :exception: :py:class:`.UnreadableBody` - in case of any failure when reading data try: content = payload.read() if not content: return None except Exception as ex: raise exceptions.UnreadableContentError(str(ex)) ",11,14
openstack%2Fmonasca-log-api~master~Iff76ec02f2334730787f1058e7fefcfec10a3b5a,openstack/monasca-log-api,master,Iff76ec02f2334730787f1058e7fefcfec10a3b5a,Monasca log api - tornado framework proposition,ABANDONED,2016-02-09 13:05:56.000000000,2016-02-19 07:10:30.000000000,,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 7052}, {'_account_id': 14273}, {'_account_id': 16168}, {'_account_id': 16204}, {'_account_id': 16222}, {'_account_id': 20033}]","[{'number': 1, 'created': '2016-02-09 13:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/c45c495ce406ab7d4124d5741de5e997d8e9c777', 'message': 'Monasca log api - tornado framework proposition\n\nChange-Id: Iff76ec02f2334730787f1058e7fefcfec10a3b5a\n'}, {'number': 2, 'created': '2016-02-09 13:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/ad984a6c50d11bc9635773e10706f1fa6409041b', 'message': 'Monasca log api - tornado framework proposition\n\nChange-Id: Iff76ec02f2334730787f1058e7fefcfec10a3b5a\n'}, {'number': 3, 'created': '2016-02-15 10:01:13.000000000', 'files': ['monasca_log_api/tests/test_logs.py', 'test-requirements.txt', 'monasca_log_api/v2/common/service.py', 'monasca_log_api/v2/reference/versions.py', 'etc/monasca/log-api-config.conf', 'monasca_log_api/api/logs_api.py', 'monasca_log_api/tests/base.py', 'monasca_log_api/api/exceptions.py', 'monasca_log_api/api/headers.py', 'monasca_log_api/README.md', 'requirements.txt', 'monasca_log_api/api/versions_api.py', 'monasca_log_api/server.py', 'monasca_log_api/tests/test_service.py', 'monasca_log_api/v2/reference/logs.py', 'monasca_log_api/tests/test_log_publisher.py', 'tox.ini', 'monasca_log_api/v2/common/log_publisher.py'], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/4245f999c4fbdb94a74e6b203cb7ee952edc079c', 'message': 'Monasca log api - tornado framework proposition\n\nChange-Id: Iff76ec02f2334730787f1058e7fefcfec10a3b5a\n'}]",4,277818,4245f999c4fbdb94a74e6b203cb7ee952edc079c,21,8,3,20033,,,0,"Monasca log api - tornado framework proposition

Change-Id: Iff76ec02f2334730787f1058e7fefcfec10a3b5a
",git fetch https://review.opendev.org/openstack/monasca-log-api refs/changes/18/277818/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_log_api/tests/test_logs.py', 'test-requirements.txt', 'monasca_log_api/v2/common/service.py', 'monasca_log_api/v2/reference/versions.py', 'etc/monasca/log-api-config.conf', 'monasca_log_api/api/logs_api.py', 'monasca_log_api/tests/base.py', 'monasca_log_api/api/exceptions.py', 'monasca_log_api/api/headers.py', 'requirements.txt', 'monasca_log_api/api/versions_api.py', 'monasca_log_api/server.py', 'monasca_log_api/tests/test_service.py', 'monasca_log_api/v2/reference/logs.py', 'monasca_log_api/tests/test_log_publisher.py', 'tox.ini', 'monasca_log_api/v2/common/log_publisher.py']",17,c45c495ce406ab7d4124d5741de5e997d8e9c777,tornado, except KeyError as ex: self._kafka_publisher = None LOG.error(ex.message) raise,,318,211
openstack%2Ffreezer-api~master~I94f07400bbf907393c5153ad461ca7277d01b4b3,openstack/freezer-api,master,I94f07400bbf907393c5153ad461ca7277d01b4b3,change url stackfore to openstack,ABANDONED,2016-02-19 02:45:55.000000000,2016-02-19 07:09:29.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-19 02:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/5c6cad4b5acbc2d89f1bb6fdd784ccd68832d2ab', 'message': 'change url stackfore to openstack\n\nchange settings file url stackfore to openstack.\n\nChange-Id: I94f07400bbf907393c5153ad461ca7277d01b4b3\n'}, {'number': 2, 'created': '2016-02-19 02:54:46.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/e9589bce31438ae7353a915093e4d4cd63c8c1a2', 'message': 'change url stackfore to openstack\n\nchange settings file url stackfore to openstack.\n\nChange-Id: I94f07400bbf907393c5153ad461ca7277d01b4b3\nCloses-Bug: #1547304\n'}]",0,282139,e9589bce31438ae7353a915093e4d4cd63c8c1a2,4,1,2,2467,,,0,"change url stackfore to openstack

change settings file url stackfore to openstack.

Change-Id: I94f07400bbf907393c5153ad461ca7277d01b4b3
Closes-Bug: #1547304
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/39/282139/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,5c6cad4b5acbc2d89f1bb6fdd784ccd68832d2ab,bug/1547304,FREEZER_API_REPO=${FREEZER_API_REPO:-${GIT_BASE}/openstack/freezer-api.git},FREEZER_API_REPO=${FREEZER_API_REPO:-${GIT_BASE}/stackforge/freezer-api.git},1,1
openstack%2Fheat~master~If62621d7a6f44100a158974f0fc9c3ddf58d8d99,openstack/heat,master,If62621d7a6f44100a158974f0fc9c3ddf58d8d99,JSON size violation gives a bad error with nested templates,MERGED,2015-12-02 06:16:40.000000000,2016-02-19 07:05:18.000000000,2016-02-19 07:05:18.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7128}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 10090}, {'_account_id': 12363}, {'_account_id': 12404}, {'_account_id': 13009}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-12-02 06:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b8fb8f8cfa819c369cb742cfa5d6122f8e46ed5e', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*. This patch make sure we only finding the smallest\nlimitation in maximum size check.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 2, 'created': '2015-12-02 08:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b72e65fc77897c1b39654a486570848911841617', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*. This patch make sure we only finding the smallest\nlimitation in maximum size check.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: #1499379\n'}, {'number': 3, 'created': '2015-12-02 17:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/70ee4e467d5fae4ba0cf706ef2ea2b4873b94c28', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*. This patch make sure we only finding the smallest\nlimitation in maximum size check.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 4, 'created': '2015-12-03 04:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/68139f054fed81376f80aae28705176f4aab7d28', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*. This patch make sure we only finding the smallest\nlimitation in maximum size check.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 5, 'created': '2015-12-04 06:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b0fa19a39eaa3622f898141d0e41eee45c9f8f94', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*. This patch make sure we only finding the smallest\nlimitation in maximum size check.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 6, 'created': '2015-12-07 08:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/33978e282534fb6e17ee234e712f9b1a7a6beaa3', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*.\nChange in this patch:\n* Add check for max_template_size not exceeds max_json_body_size.\n* We only compare with max_template_size.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 7, 'created': '2015-12-07 09:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/66b91a4208e7a979568c873f0802af059e82e64f', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*.\nChange in this patch:\n* Add check for max_template_size not exceeds max_json_body_size.\n* We only compare with max_template_size.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 8, 'created': '2015-12-08 09:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/474b418596aa0aaba7a75cd0614c9df15ac855c6', 'message': 'JSON size violation gives a bad error with nested templates\n\nThere are two passible maximum limitations *max_template_size* and\n*max_json_body_size*.\nChange in this patch:\n* Move check in common.wsgi to api.openstack.v1.stack\n* Add check for max_template_size not exceeds max_json_body_size.\n* We only compare with max_template_size.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nCloses-Bug: #1499379\n'}, {'number': 9, 'created': '2015-12-29 07:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a5c378e7211fe3d718a25e820de72aa148368aa8', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}, {'number': 10, 'created': '2015-12-29 09:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5b62ad4257a3d84a5d9b97214040c5fd809314df', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}, {'number': 11, 'created': '2015-12-30 01:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5af0fb159a1322a88f1330344dfa2572f67dccd8', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}, {'number': 12, 'created': '2016-01-14 01:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d441d4ea8faaeddf3ab97b00720ef196e82e9bb9', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}, {'number': 13, 'created': '2016-01-17 05:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/588956a5ba02c6c3e15ec89cd4da2def3953f73d', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}, {'number': 14, 'created': '2016-01-19 02:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8a74b705a9f572614065283527f2803d98604605', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}, {'number': 15, 'created': '2016-01-19 03:31:03.000000000', 'files': ['heat/tests/api/openstack_v1/test_stacks.py', 'heat/common/template_format.py', 'heat/tests/test_template_format.py', 'heat/api/openstack/v1/stacks.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/fc1c513d35e39a14fa98308b62ade5e26c8dd37d', 'message': 'JSON size violation gives a bad error with nested templates\n\nThis patch propose a normalized error message for both template\nvalidation and JSON validation.\n\nAlso Add template validation in api template parser to prevent huge template\n(besides nested stacks) pass to engine.\n\nChange-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99\nDepends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63\nCloses-Bug: 1499379\n'}]",12,252201,fc1c513d35e39a14fa98308b62ade5e26c8dd37d,68,12,15,12404,,,0,"JSON size violation gives a bad error with nested templates

This patch propose a normalized error message for both template
validation and JSON validation.

Also Add template validation in api template parser to prevent huge template
(besides nested stacks) pass to engine.

Change-Id: If62621d7a6f44100a158974f0fc9c3ddf58d8d99
Depends-On: I981d477c96345e68baa5a3d96c6671ad242dbb63
Closes-Bug: 1499379
",git fetch https://review.opendev.org/openstack/heat refs/changes/01/252201/14 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/template_format.py', 'heat/tests/api/test_wsgi.py', 'heat/common/wsgi.py', 'heat/tests/test_template_format.py', 'heat/common/format_utils.py']",5,b8fb8f8cfa819c369cb742cfa5d6122f8e46ed5e,bug/1499379,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_config import cfg from heat.common import exception from heat.common.i18n import _ def check_contain_size(contain_str): """"""Check if the contain exceeds allowed size range."""""" min_ceiling_limit = min(cfg.CONF.max_template_size, cfg.CONF.max_json_body_size) if len(contain_str) > min_ceiling_limit: if min_ceiling_limit == cfg.CONF.max_template_size: resource = 'Template' limit = cfg.CONF.max_template_size else: resource = 'JSON body' limit = cfg.CONF.max_json_body_size msg = _('%(resource)s size (%(len)s bytes) exceeds maximum ' 'allowed size (%(limit)s bytes).' ) % {'resource': resource, 'len': len(contain_str), 'limit': limit} raise exception.RequestLimitExceeded(message=msg) ",,46,17
openstack%2Fheat~master~Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8,openstack/heat,master,Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8,Use caching for resource name/id finders,MERGED,2016-02-17 11:52:18.000000000,2016-02-19 07:00:12.000000000,2016-02-19 07:00:11.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12363}]","[{'number': 1, 'created': '2016-02-17 11:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e9d1c746c094ca155918413a4ab66ee9cfd9cd39', 'message': 'Use caching for client resource name/id finders\n\nUse caching to reduce the number of client calls.\n\nChange-Id: Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8\n'}, {'number': 2, 'created': '2016-02-17 12:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/baff649095866173802f2c123c2e89aac046f76b', 'message': 'Use caching for client resource name/id finders\n\nUse caching to reduce the number of client calls.\n\nChange-Id: Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8\n'}, {'number': 3, 'created': '2016-02-17 15:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/13c62ae499601f46df0fc70cc87f32dcc7a35a15', 'message': 'Use caching for resource name/id finders\n\nUse caching to reduce the number of client calls.\n\nChange-Id: Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8\n'}, {'number': 4, 'created': '2016-02-18 12:23:53.000000000', 'files': ['heat/engine/clients/os/glance.py', 'heat/engine/clients/os/nova.py', 'heat/engine/clients/os/__init__.py', 'heat/engine/clients/os/neutron/__init__.py', 'heat/common/cache.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/54aa3ea5e168b1572f2bb0b7c3c43d0d8112c8e7', 'message': 'Use caching for resource name/id finders\n\nUse caching to reduce the number of client calls.\n\nChange-Id: Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8\n'}]",2,281212,54aa3ea5e168b1572f2bb0b7c3c43d0d8112c8e7,24,6,4,8833,,,0,"Use caching for resource name/id finders

Use caching to reduce the number of client calls.

Change-Id: Ic22dfac0a5ea8c0f1ae7b83d37492e935f259db8
",git fetch https://review.opendev.org/openstack/heat refs/changes/12/281212/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/glance.py', 'heat/engine/clients/os/nova.py', 'heat/engine/clients/os/__init__.py', 'heat/engine/clients/os/neutron/__init__.py', 'heat/common/cache.py']",5,e9d1c746c094ca155918413a4ab66ee9cfd9cd39,bug/1514680," find_cache_group = cfg.OptGroup('resource_finder_cache') find_cache_opts = [ cfg.IntOpt('expiration_time', default=3600, help=_( 'TTL, in seconds, for any cached item in the ' 'dogpile.cache region used for caching of neutron ' 'finder function.')), cfg.BoolOpt('caching', default=True, help=_( 'Toggle to enable/disable caching when Orchestration ' 'Engine looks for neutron resources using name or id.' 'Please note that the global toggle for ' 'oslo.cache(enabled=True in [cache] group) must be ' 'enabled to use this feature.')) ] conf.register_group(find_cache_group) conf.register_opts(find_cache_opts, group=find_cache_group) ",,37,5
openstack%2Fkuryr~master~I8e9b1c96422fe550b5547328f5763897eef66ae1,openstack/kuryr,master,I8e9b1c96422fe550b5547328f5763897eef66ae1,Renaming service from docker-engine to docker to fix 'vagrant up',MERGED,2016-02-18 19:47:22.000000000,2016-02-19 06:59:01.000000000,2016-02-19 06:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 11208}, {'_account_id': 12069}]","[{'number': 1, 'created': '2016-02-18 19:47:22.000000000', 'files': ['devstack/local.conf.sample'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/bc371f220e52e5cd921c6046eae60a8e117fe76d', 'message': ""Renaming service from docker-engine to docker to fix 'vagrant up'\n\nChange-Id: I8e9b1c96422fe550b5547328f5763897eef66ae1\n""}]",0,282032,bc371f220e52e5cd921c6046eae60a8e117fe76d,7,3,1,20638,,,0,"Renaming service from docker-engine to docker to fix 'vagrant up'

Change-Id: I8e9b1c96422fe550b5547328f5763897eef66ae1
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/32/282032/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/local.conf.sample'],1,bc371f220e52e5cd921c6046eae60a8e117fe76d,,enable_service docker,enable_service docker-engine,1,1
openstack%2Fproject-config~master~I842e445f90ac87021b2ed93a27c52ad9b829a32b,openstack/project-config,master,I842e445f90ac87021b2ed93a27c52ad9b829a32b,Normalize projects.yaml,MERGED,2016-02-19 06:01:53.000000000,2016-02-19 06:56:55.000000000,2016-02-19 06:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-19 06:01:53.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/757445e7b6c486c494d3cf9deb8e793dc0aa348e', 'message': 'Normalize projects.yaml\n\nChange-Id: I842e445f90ac87021b2ed93a27c52ad9b829a32b\n'}]",0,282185,757445e7b6c486c494d3cf9deb8e793dc0aa348e,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I842e445f90ac87021b2ed93a27c52ad9b829a32b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/282185/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,757445e7b6c486c494d3cf9deb8e793dc0aa348e,project-yaml-normalization, description: Namos discovery agent., upstream: https://github.com/pabelanger/ansible-role-ssh.git description: Namos discovery agent.,1,2
openstack%2Fsahara-dashboard~master~I647c93bdf9da52d98864f6657867e173d27d54e9,openstack/sahara-dashboard,master,I647c93bdf9da52d98864f6657867e173d27d54e9,Imported Translations from Zanata,MERGED,2016-02-19 06:30:56.000000000,2016-02-19 06:56:34.000000000,2016-02-19 06:56:34.000000000,"[{'_account_id': 3}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-19 06:30:56.000000000', 'files': ['sahara_dashboard/locale/ja/LC_MESSAGES/django.po', 'sahara_dashboard/locale/djangojs.pot', 'sahara_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'sahara_dashboard/locale/django.pot'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/3e93b702313642da0aa5fb1dd628b3a0ecc79124', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I647c93bdf9da52d98864f6657867e173d27d54e9\n'}]",0,282200,3e93b702313642da0aa5fb1dd628b3a0ecc79124,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I647c93bdf9da52d98864f6657867e173d27d54e9
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/00/282200/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/locale/ja/LC_MESSAGES/django.po', 'sahara_dashboard/locale/djangojs.pot', 'sahara_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'sahara_dashboard/locale/django.pot']",4,3e93b702313642da0aa5fb1dd628b3a0ecc79124,zanata/translations,"# Translations template for PROJECT. # Copyright (C) 2016 ORGANIZATION # This file is distributed under the same license as the PROJECT project. # FIRST AUTHOR <EMAIL@ADDRESS>, 2016. # #, fuzzy msgid """" msgstr """" ""Project-Id-Version: PROJECT VERSION\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2016-02-19 06:30+0000\n"" ""PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"" ""Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"" ""Language-Team: LANGUAGE <LL@li.org>\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=utf-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 2.2.0\n"" #: sahara_dashboard/content/data_processing/cluster_templates/forms.py:27 msgid ""Cluster Template Name"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/forms.py:35 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:13 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:37 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:19 msgid ""Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/forms.py:53 msgid ""Unable to upload cluster template file"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/panel.py:22 #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:169 #: sahara_dashboard/content/data_processing/cluster_templates/views.py:44 msgid ""Cluster Templates"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:29 #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:153 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:5 #: sahara_dashboard/content/data_processing/clusters/tables.py:32 #: sahara_dashboard/content/data_processing/clusters/tables.py:173 #: sahara_dashboard/content/data_processing/clusters/tabs.py:154 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:5 #: sahara_dashboard/content/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:5 #: sahara_dashboard/content/data_processing/data_sources/tables.py:86 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:5 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:30 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:55 #: sahara_dashboard/content/data_processing/job_binaries/tables.py:107 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/tables.py:28 #: sahara_dashboard/content/data_processing/jobs/tables.py:123 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:5 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:54 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:75 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:27 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:123 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:5 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:116 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:135 msgid ""Name"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:30 #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:157 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:6 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:15 #: sahara_dashboard/content/data_processing/clusters/tables.py:178 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:6 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:31 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:7 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:28 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:126 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:6 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:36 msgid ""Plugin"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:31 #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:159 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:8 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:17 #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:60 #: sahara_dashboard/content/data_processing/clusters/tables.py:181 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:8 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:33 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:8 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:29 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:128 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:8 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:38 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:235 #: sahara_dashboard/content/data_processing/wizard/forms.py:64 msgid ""Version"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:32 #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:165 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:11 #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:99 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:11 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:73 #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:30 #: sahara_dashboard/content/data_processing/data_plugins/tables.py:32 #: sahara_dashboard/content/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:9 #: sahara_dashboard/content/data_processing/data_sources/tables.py:92 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:15 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:79 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:159 #: sahara_dashboard/content/data_processing/job_binaries/tables.py:112 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:13 #: sahara_dashboard/content/data_processing/jobs/tables.py:30 #: sahara_dashboard/content/data_processing/jobs/tables.py:128 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:13 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:101 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:11 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:48 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:139 msgid ""Description"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:37 #: sahara_dashboard/content/data_processing/cluster_templates/views.py:97 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_upload_file.html:10 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/upload_file.html:3 msgid ""Upload Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:45 #: sahara_dashboard/content/data_processing/clusters/tables.py:44 #: sahara_dashboard/content/data_processing/clusters/views.py:188 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_create_cluster.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/configure.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/create.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/create_cluster.html:3 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:54 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:226 msgid ""Launch Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:61 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:53 msgid ""Copy Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:68 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:60 msgid ""Edit Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:76 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:68 msgid ""Delete Template"" msgid_plural ""Delete Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:84 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:76 msgid ""Deleted Template"" msgid_plural ""Deleted Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:96 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:34 msgid ""Create Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:105 #: sahara_dashboard/content/data_processing/cluster_templates/views.py:113 msgid ""Configure Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tables.py:161 #: sahara_dashboard/content/data_processing/cluster_templates/tabs.py:64 #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:229 #: sahara_dashboard/content/data_processing/clusters/tabs.py:102 msgid ""Node Groups"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tabs.py:31 #: sahara_dashboard/content/data_processing/clusters/tabs.py:36 #: sahara_dashboard/content/data_processing/data_sources/tabs.py:26 #: sahara_dashboard/content/data_processing/job_binaries/tabs.py:26 #: sahara_dashboard/content/data_processing/job_executions/tabs.py:26 #: sahara_dashboard/content/data_processing/jobs/tabs.py:26 #: sahara_dashboard/content/data_processing/nodegroup_templates/tabs.py:33 msgid ""General Info"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tabs.py:47 #: sahara_dashboard/content/data_processing/clusters/tabs.py:79 msgid ""Configuration Details"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/tabs.py:86 msgid ""Unable to fetch node group details."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/views.py:57 msgid ""Unable to fetch cluster template list"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/views.py:72 #, python-format msgid ""Unable to retrieve details for cluster template \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/views.py:106 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/configure.html:3 #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:80 #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:301 msgid ""Create Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/views.py:120 msgid ""Copy Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/views.py:138 #: sahara_dashboard/content/data_processing/clusters/views.py:226 msgid ""Unable to fetch cluster template."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:3 msgid ""Cluster Template Configuration Overview"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:13 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:38 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:13 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:38 #, python-format msgid ""%(conf_name)s: %(conf_value)s"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:17 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:42 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:17 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:42 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:17 msgid ""No configurations"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:22 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:22 msgid ""Cluster configurations are not specified"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:26 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:26 msgid ""Node Groups Configuration Overview"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:30 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:30 #, python-format msgid ""Node Group Name: %(node_group_name)s"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_cluster_template_configs_details.html:47 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:47 msgid ""Node group configurations are not specified"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:4 msgid ""This Cluster Template will be created for:"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:13 msgid """" ""The Cluster Template object should specify Node Group Templates that will"" "" be used to build a Cluster.\n"" "" You can add Node Groups using Node Group Templates on a &quot;Node "" ""Groups&quot; tab."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:16 msgid ""You may set <b>cluster</b> scoped configurations on corresponding tabs."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:20 msgid """" ""The Cluster Template object may specify a list of processes in anti-"" ""affinity group.\n"" "" That means these processes may not be launched more than once on a "" ""single host."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_create_general_help.html:3 msgid ""Select a plugin and version for a new Cluster template."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:7 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:7 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:7 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:7 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:9 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:7 msgid ""Project ID"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:9 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:9 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:9 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:9 #: sahara_dashboard/content/data_processing/job_executions/tables.py:35 #: sahara_dashboard/content/data_processing/job_executions/tables.py:204 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:7 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:9 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:9 msgid ""ID"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:12 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:12 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:16 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:14 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:14 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:23 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:29 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:12 msgid ""None"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:19 #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:25 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:51 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:26 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:43 msgid ""Use auto-configuration"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:21 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:53 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:17 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:15 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:13 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:15 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:13 #: sahara_dashboard/content/data_processing/utils/acl.py:124 msgid ""Public"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:23 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:55 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:19 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:17 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:15 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:17 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:15 #: sahara_dashboard/content/data_processing/utils/acl.py:135 msgid ""Protected"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:27 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:59 msgid ""Anti-affinity enabled for"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:37 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:69 msgid ""no processes"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:6 #, python-format msgid ""Node Group: %(node_group_name)s"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:7 msgid ""Nodes Count"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:10 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:11 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:20 msgid ""Flavor"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:12 msgid ""Flavor is not specified"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:17 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:41 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:23 msgid ""Template not specified"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:21 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:25 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:55 msgid ""Availability Zone"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:28 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:29 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:47 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:160 msgid ""Proxy Gateway"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:31 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:32 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:52 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:241 msgid ""Auto Security Group"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:34 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:35 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:57 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:256 msgid ""Security Groups"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:47 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:48 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:130 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:72 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:336 msgid ""Node Processes"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:57 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:58 msgid ""Node processes are not specified"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_upload_file.html:21 msgid ""Upload"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/_upload_file.html:22 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_create_cluster.html:21 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html:27 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html:25 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create.html:25 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_job_type_select.html:29 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_ngt_select.html:29 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_plugin_select.html:29 msgid ""Cancel"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_node_groups_template.html:95 msgid ""Select a Node Group Template to add:"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_templates.html:3 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/clusters.html:3 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/image_registry.html:3 #: sahara_dashboard/content/data_processing/data_plugins/templates/data_processing.data_plugins/plugins.html:3 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/data_sources.html:3 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/job_binaries.html:3 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/job_executions.html:3 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/jobs.html:3 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html:3 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:3 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:3 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:3 #: sahara_dashboard/enabled/_1810_data_processing_panel_group.py:6 msgid ""Data Processing"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_templates.html:19 msgid ""Add Node Group"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/copy.py:29 #, python-format msgid ""Cluster Template copy %s created"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/copy.py:107 msgid ""Unable to fetch template to copy."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:49 msgid ""Unable to fetch plugin list."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:53 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:522 msgid ""Plugin name"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:69 msgid ""Select plugin and hadoop version for cluster template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:81 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:581 msgid ""Next"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:82 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:37 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:574 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:582 msgid ""Created"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:83 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:575 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:583 msgid ""Could not create"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:97 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:46 msgid ""Template Name"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:104 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:149 msgid ""Auto-configure"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:105 msgid """" ""If selected, instances of a cluster will be automatically configured "" ""during creation. Otherwise you should manually specify configuration "" ""values"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:113 #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:114 msgid ""cluster template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:151 #: sahara_dashboard/content/data_processing/data_plugins/tabs.py:26 msgid ""Details"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:252 #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:46 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:348 msgid ""Select Shares"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:263 #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:83 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:105 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:211 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:359 msgid ""Failed to get list of shares"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:273 #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:93 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:364 msgid ""Shares"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:274 #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:94 msgid ""Select the manila shares for this cluster"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:302 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:140 #: sahara_dashboard/content/data_processing/job_binaries/views.py:62 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:230 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:573 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:419 msgid ""Create"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:303 #, python-format msgid ""Created Cluster Template %s"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/create.py:403 msgid ""Cluster template creation failed"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/edit.py:32 #, python-format msgid ""Cluster Template %s updated"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/edit.py:34 #: sahara_dashboard/content/data_processing/data_sources/workflows/edit.py:27 #: sahara_dashboard/content/data_processing/job_binaries/views.py:82 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/edit.py:32 msgid ""Update"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/edit.py:35 msgid ""Edit Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/edit.py:53 msgid ""Unable to fetch template to edit."" msgstr """" #: sahara_dashboard/content/data_processing/cluster_templates/workflows/edit.py:106 msgid ""Cluster template update failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/panel.py:22 #: sahara_dashboard/content/data_processing/clusters/tables.py:194 #: sahara_dashboard/content/data_processing/clusters/views.py:50 msgid ""Clusters"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:33 #: sahara_dashboard/content/data_processing/clusters/tables.py:185 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:13 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:11 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:34 #: sahara_dashboard/content/data_processing/job_executions/tables.py:38 #: sahara_dashboard/content/data_processing/job_executions/tables.py:223 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:5 msgid ""Status"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:38 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:26 msgid ""Cluster Creation Guide"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:52 #: sahara_dashboard/content/data_processing/clusters/views.py:208 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/scale.html:3 #: sahara_dashboard/content/data_processing/clusters/workflows/scale.py:38 msgid ""Scale Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:63 msgid ""Delete Cluster"" msgid_plural ""Delete Clusters"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/tables.py:71 msgid ""Deleted Cluster"" msgid_plural ""Deleted Clusters"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/clusters/tables.py:83 msgid ""Update Shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:102 #: sahara_dashboard/content/data_processing/job_executions/tables.py:130 msgid ""Unable to update row"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:143 #: sahara_dashboard/content/data_processing/clusters/views.py:195 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:208 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:420 msgid ""Configure Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tables.py:190 msgid ""Instances Count"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:131 msgid ""Unable to get node group details."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:157 msgid ""Internal IP"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:160 msgid ""Management IP"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:164 msgid ""Cluster Instances"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:168 msgid ""Instances"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:193 msgid ""Unable to fetch instance details."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/tabs.py:198 msgid ""Cluster Events"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:62 msgid ""Unable to fetch cluster list"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:77 #, python-format msgid ""Unable to retrieve details for cluster \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:134 msgid ""Unknown"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:137 #: sahara_dashboard/content/data_processing/clusters/views.py:162 msgid ""Completed Successfully"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:139 #: sahara_dashboard/content/data_processing/clusters/views.py:164 msgid ""Failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:144 msgid ""No info available"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:157 msgid ""In progress"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:241 #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/update.html:3 #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:121 msgid ""Update Cluster Shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/views.py:257 msgid ""Unable to fetch cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_cluster_configs_details.html:3 msgid ""Cluster Configuration Overview"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:4 msgid ""This Cluster will be started with:"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:12 msgid ""Cluster can be launched using existing Cluster Templates."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:15 msgid """" ""The Cluster object should specify OpenStack Image to boot instances for "" ""Cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:18 msgid ""User has to choose a keypair to have access to clusters instances."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_create_cluster.html:20 msgid "" Done"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_create_general_help.html:3 msgid ""Select a plugin and version for a new Cluster."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:15 msgid ""Status description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:19 msgid ""No description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:24 msgid ""Error Details"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:43 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:87 msgid ""Base Image"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:46 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:104 msgid ""Neutron Management Network"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:49 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:91 msgid ""Keypair"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_details.html:77 #, python-format msgid ""%(key)s: %(val)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:3 msgid ""Cluster provision steps"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:7 msgid ""Step Description"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:8 msgid ""Started at"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:9 msgid ""Duration"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:10 msgid ""Progress"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:30 msgid ""Node Group"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:31 msgid ""Instance"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:32 msgid ""Event time"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_event_log.html:33 msgid ""Info"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:7 #, python-format msgid ""Name: %(node_group_name)s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:8 msgid ""Number of Nodes"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:15 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:31 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:144 msgid ""Floating IP Pool"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:43 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:561 msgid ""Select plugin and hadoop version for cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:71 msgid ""Cluster Name"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:76 msgid ""Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:82 msgid ""Cluster Count"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:85 msgid ""Number of clusters to launch."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:93 msgid ""Which keypair to use for authentication."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:110 #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:112 msgid ""cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:139 msgid ""Unable to fetch image choices."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:142 msgid ""No Images Available"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:152 msgid ""Unable to fetch keypair choices."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:154 msgid ""No keypair"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:170 msgid ""No Templates Available"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:227 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:490 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:583 msgid ""Launch"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:228 #, python-format msgid ""Launched Cluster %s"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/create.py:264 msgid ""Unable to create the cluster"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/scale.py:39 msgid ""Scale"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/scale.py:46 msgid ""Scaled cluster successfully started."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/scale.py:103 msgid ""Unable to fetch cluster to scale"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/scale.py:158 msgid ""Unable to fetch cluster to scale."" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/scale.py:168 msgid ""Scale cluster operation failed"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:122 msgid ""Updated"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:123 msgid ""Could not update cluster shares"" msgstr """" #: sahara_dashboard/content/data_processing/clusters/workflows/update.py:138 msgid ""Cluster share update failed."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:28 msgid ""User Name"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:45 msgid ""Successfully updated image."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:49 msgid ""Failed to update image."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:58 #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:70 msgid ""Image"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:70 msgid ""Select Image"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:72 msgid ""No images available."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:82 #, python-format msgid ""Unable to retrieve images with filter %s."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/forms.py:109 msgid ""Unable to fetch available images."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/panel.py:22 #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:78 #: sahara_dashboard/content/data_processing/data_image_registry/views.py:37 msgid ""Image Registry"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:25 msgid ""Edit Tags"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:39 #: sahara_dashboard/content/data_processing/data_image_registry/views.py:115 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html:9 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/register_image.html:3 msgid ""Register Image"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:50 msgid ""Unregister Image"" msgid_plural ""Unregister Images"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:58 msgid ""Unregistered Image"" msgid_plural ""Unregistered Images"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/data_image_registry/tables.py:74 msgid ""Tags"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/views.py:44 msgid ""Unable to retrieve image list"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/views.py:54 #: sahara_dashboard/content/data_processing/data_image_registry/views.py:69 msgid ""Unable to process plugin tags"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/views.py:81 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html:9 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/edit_tags.html:3 msgid ""Edit Image Tags"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/views.py:96 msgid ""Unable to fetch the image details"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html:26 #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html:24 msgid ""Done"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:3 msgid ""Image Registry tool:"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:6 msgid """" ""Image Registry is used to provide additional information about images for"" "" Data Processing."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:9 msgid """" ""Specified User Name will be used by Data Processing to apply configs and "" ""manage processes on instances."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:13 msgid """" ""Tags are used for filtering images suitable for each plugin and each Data"" "" Processing version.\n"" "" To add required tags, select a plugin and a Data Processing "" ""version and click &quot;Add plugin tags&quot; button."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:16 msgid ""You may also add any custom tag."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:19 msgid ""Unnecessary tags may be removed by clicking a cross near tag's name."" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:5 msgid """" ""Register tags required for the Plugin with specified Data Processing "" ""Version"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:30 msgid ""Add plugin tags"" msgstr """" #: sahara_dashboard/content/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:38 msgid ""Add custom tag"" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/panel.py:22 #: sahara_dashboard/content/data_processing/data_plugins/tables.py:36 msgid ""Plugins"" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/tables.py:22 #: sahara_dashboard/content/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:7 msgid ""Title"" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/tables.py:27 #: sahara_dashboard/content/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:11 msgid ""Supported Versions"" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/tabs.py:39 msgid ""Unable to retrieve plugin."" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/views.py:30 msgid ""Data Processing Plugins"" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/views.py:37 msgid ""Unable to retrieve data processing plugins."" msgstr """" #: sahara_dashboard/content/data_processing/data_plugins/views.py:45 msgid ""Data Processing Plugin Details"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/panel.py:22 #: sahara_dashboard/content/data_processing/data_sources/tables.py:96 #: sahara_dashboard/content/data_processing/data_sources/views.py:38 msgid ""Data Sources"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/tables.py:26 #: sahara_dashboard/content/data_processing/data_sources/views.py:56 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/create.html:3 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:110 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:139 msgid ""Create Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/tables.py:35 msgid ""Delete Data Source"" msgid_plural ""Delete Data Sources"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/data_sources/tables.py:43 msgid ""Deleted Data Source"" msgid_plural ""Deleted Data Sources"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/data_sources/tables.py:55 #: sahara_dashboard/content/data_processing/data_sources/views.py:61 #: sahara_dashboard/content/data_processing/data_sources/workflows/edit.py:26 msgid ""Edit Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/tables.py:90 #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:11 #: sahara_dashboard/content/data_processing/jobs/tables.py:29 #: sahara_dashboard/content/data_processing/jobs/tables.py:126 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:11 msgid ""Type"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/views.py:46 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:77 msgid ""Unable to fetch data sources."" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/views.py:87 #, python-format msgid ""Unable to retrieve details for data source \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:4 msgid ""Create a Data Source with a specified name."" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:7 msgid ""Select the type of your Data Source."" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:10 msgid ""You may need to enter the username and password for your Data Source."" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:13 msgid """" ""For Data Sources on a Manila share, choose the share and enter the path "" ""relative to the share (example: /outputdir/myinputfile.txt)"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:16 msgid ""You may also enter an optional description for your Data Source."" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:13 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:49 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:54 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:55 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:56 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:66 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:72 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:11 msgid ""URL"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/templates/data_processing.data_sources/_details.html:21 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:19 msgid ""Create time"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:33 msgid ""Data Source Type"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:40 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:45 msgid ""Manila share"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:53 msgid ""Path on share"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:60 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:65 msgid ""Source username"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:72 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:75 msgid ""Source password"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:83 #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:84 msgid ""data source"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:141 msgid ""Data source created"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/create.py:142 msgid ""Could not create data source"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/edit.py:28 msgid ""Data source updated"" msgstr """" #: sahara_dashboard/content/data_processing/data_sources/workflows/edit.py:29 msgid ""Could not update data source"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:58 msgid ""Storage type"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:76 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:82 msgid ""Share"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:86 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:92 msgid ""Path"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:96 msgid ""Internal binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:103 msgid ""Internal Binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:107 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:113 msgid ""Upload File"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:117 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:123 msgid ""Script name"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:127 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:134 msgid ""Script text"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:138 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:144 msgid ""Username"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:148 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:155 msgid ""Password"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:164 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:166 msgid ""job binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:220 msgid ""Failed to get list of internal binaries."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:259 #: sahara_dashboard/content/data_processing/job_binaries/forms.py:304 msgid ""Unable to create job binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:274 #: sahara_dashboard/content/data_processing/job_binaries/tables.py:28 #: sahara_dashboard/content/data_processing/job_binaries/views.py:59 #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/create.html:3 msgid ""Create Job Binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:292 msgid ""Unable to upload job binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:325 msgid ""Failed to fetch internal binary list"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/forms.py:374 msgid ""Unable to update job binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/panel.py:22 #: sahara_dashboard/content/data_processing/job_binaries/tables.py:116 #: sahara_dashboard/content/data_processing/job_binaries/views.py:41 msgid ""Job Binaries"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/tables.py:37 msgid ""Delete Job Binary"" msgid_plural ""Delete Job Binaries"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/job_binaries/tables.py:45 msgid ""Deleted Job Binary"" msgid_plural ""Deleted Job Binaries"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/job_binaries/tables.py:72 msgid ""Download Job Binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/tables.py:79 #: sahara_dashboard/content/data_processing/job_binaries/views.py:79 msgid ""Edit Job Binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/tables.py:110 msgid ""Url"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/views.py:49 msgid ""Unable to fetch job binary list."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/views.py:90 #, python-format msgid ""Unable to retrieve job binary \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/views.py:113 #, python-format msgid ""Unable to retrieve details for job binary \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/views.py:139 #, python-format msgid ""Unable to fetch job binary: %(exc)s"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:5 msgid """" ""<b>Important</b>: The name that you give your job binary will be the "" ""name used in your job execution.\n"" "" If your binary requires a particular name or extension (ie: \"".jar\""), "" ""be sure to include it here."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:8 msgid ""Select the storage type for your job binary."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:10 msgid ""Data Processing internal database"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:11 msgid ""Swift"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:15 msgid """" ""For Data Processing internal job binaries, you may choose from the "" ""following:"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:17 msgid ""Choose an existing file"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:18 msgid ""Upload a new file"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:19 msgid ""Create a script to be uploaded dynamically"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:23 msgid ""For Object Store job binaries, you must:"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:25 msgid ""Enter the URL for the file"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:26 msgid ""Enter the username and password required to access that file"" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:30 msgid ""You may also enter an optional description for your job binary."" msgstr """" #: sahara_dashboard/content/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:22 msgid ""Download job binary"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/panel.py:22 #: sahara_dashboard/content/data_processing/job_executions/tables.py:232 #: sahara_dashboard/content/data_processing/job_executions/views.py:37 msgid ""Jobs"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:36 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:58 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:99 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:127 msgid ""Job"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:37 #: sahara_dashboard/content/data_processing/job_executions/tables.py:216 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:25 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:106 msgid ""Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:43 msgid ""Job Guide"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:50 msgid ""Delete Job"" msgid_plural ""Delete Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:58 msgid ""Deleted Job"" msgid_plural ""Deleted Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:71 #: sahara_dashboard/content/data_processing/job_executions/tables.py:100 #: sahara_dashboard/content/data_processing/jobs/views.py:100 #: sahara_dashboard/content/data_processing/jobs/views.py:121 #: sahara_dashboard/content/data_processing/jobs/views.py:134 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/launch.html:3 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:489 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:572 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:582 msgid ""Launch Job"" msgid_plural ""Launch Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:79 #: sahara_dashboard/content/data_processing/job_executions/tables.py:108 msgid ""Launched Job"" msgid_plural ""Launched Jobs"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:86 msgid ""Relaunch On Existing Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:115 msgid ""Relaunch On New Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:169 #: sahara_dashboard/content/data_processing/job_executions/tables.py:184 msgid ""Not available"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:193 msgctxt ""Current status of a Job"" msgid ""Done with Error"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:195 msgctxt ""Current status of a Job"" msgid ""Failed"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:197 msgctxt ""Current status of a Job"" msgid ""Killed"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:199 msgctxt ""Current status of a Job"" msgid ""Succeeded"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/tables.py:211 #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:11 msgid ""Job Template"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/views.py:55 msgid ""Unable to fetch job executions."" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/views.py:70 #, python-format msgid ""Unable to retrieve details for job \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:18 msgid ""Input Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:22 msgid ""Output Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:27 msgid ""Last Updated"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:29 msgid ""Started"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:31 msgid ""Ended"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:33 msgid ""Return Code"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:35 msgid ""Oozie Job ID"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:39 msgid ""Job Configuration"" msgstr """" #: sahara_dashboard/content/data_processing/job_executions/templates/data_processing.job_executions/_details.html:41 #, python-format msgid ""%(group)s:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/panel.py:22 #: sahara_dashboard/content/data_processing/jobs/tables.py:132 #: sahara_dashboard/content/data_processing/jobs/views.py:41 msgid ""Job Templates"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/tables.py:35 #: sahara_dashboard/content/data_processing/jobs/views.py:64 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/create.html:3 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:142 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:229 msgid ""Create Job Template"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/tables.py:44 msgid ""Delete Job Template"" msgid_plural ""Delete Job Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/tables.py:52 msgid ""Deleted Job Template"" msgid_plural ""Deleted Jobs Templates"" msgstr[0] """" msgstr[1] """" #: sahara_dashboard/content/data_processing/jobs/tables.py:64 msgid ""Launch On Existing Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/tables.py:77 #: sahara_dashboard/content/data_processing/jobs/tables.py:90 msgid ""Launch On New Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/views.py:53 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:91 msgid ""Unable to fetch jobs."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/views.py:78 #, python-format msgid ""Unable to retrieve details for job template \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:4 msgid ""Create a job template with a specified name."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:7 msgid ""Select the type of your job:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:9 #: sahara_dashboard/content/data_processing/utils/helpers.py:126 msgid ""Pig"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:10 #: sahara_dashboard/content/data_processing/utils/helpers.py:127 msgid ""Hive"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:11 #: sahara_dashboard/content/data_processing/utils/helpers.py:128 msgid ""Spark"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:12 #: sahara_dashboard/content/data_processing/utils/helpers.py:129 msgid ""Storm"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:13 #: sahara_dashboard/content/data_processing/utils/helpers.py:130 msgid ""MapReduce"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:14 msgid ""Java Action"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:15 msgid ""Shell Action"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:19 msgid """" ""Choose or create your main binary. Additional libraries can be added "" ""from the \""Libs\"" tab."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:22 msgid ""For Spark and Shell jobs, only a main is required, \""libs\"" are optional."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:26 msgid """" ""For MapReduce or Java Action jobs, \""mains\"" are not applicable. You are"" "" required to add one\n"" "" or more \""libs\"" for these jobs."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:29 msgid ""You may also enter an optional description for your job template."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_libs_help.html:4 msgid ""Add libraries to your job template."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_libs_help.html:7 msgid """" ""Choose from the list of binaries and click \""choose\"" to add the library "" ""to your job template. This can be repeated for additional libraries."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_create_job_libs_help.html:10 msgid """" ""For Shell Action jobs, any required files beyond the main script may be "" ""added as \""libraries\""."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:19 msgid ""Mains"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:25 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:69 msgid ""Libs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:31 msgid ""Created time"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:33 msgid ""Updated time"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_details.html:34 msgid ""Never"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_launch_job_configure_help.html:4 msgid ""Enter any custom configuration required for your job's execution."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:4 msgid ""Launch the given job template on a cluster."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:7 msgid ""Choose the cluster to use for the job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:10 msgid ""Choose the Input Data Source (n/a for Java and Shell jobs)."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:13 msgid ""Choose the Output Data Source (n/a for Java and Shell jobs)."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:5 msgid ""Select property name"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:16 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:34 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:47 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/library_template.html:3 msgid ""Remove"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:55 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:65 msgid ""Value"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:59 #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:69 msgid ""Add"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:236 msgid ""Configuration"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:239 msgid ""Parameters"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/config_template.html:242 msgid ""Arguments"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/job_interface_arguments_template.html:3 msgid ""Select a Value Type for your next argument:"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/job_interface_arguments_template.html:7 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_job_type_select.html:27 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_ngt_select.html:27 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_plugin_select.html:27 msgid ""Select"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/job_interface_arguments_template.html:8 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:157 msgid ""String"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/job_interface_arguments_template.html:9 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:158 msgid ""Number"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/job_interface_arguments_template.html:10 #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:159 msgid ""Data Source"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/library_template.html:86 msgid ""Choose"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/templates/data_processing.jobs/library_template.html:98 msgid ""Chosen Libraries"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:39 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:46 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:47 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:49 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:50 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:51 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:52 msgid ""Choose libraries"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:48 msgid ""Choose additional files"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:64 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:129 msgid ""-- not selected --"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:77 #: sahara_dashboard/content/data_processing/wizard/forms.py:91 msgid ""Job Type"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:84 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:93 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:94 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:96 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:97 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:98 msgid ""Choose a main binary"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:86 msgid ""Choose the binary which should be used in this Job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:95 msgid ""Choose a shell script"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:104 #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:105 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:110 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:111 msgid ""job"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:188 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:475 msgid ""Interface Arguments"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:231 msgid ""Job created"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/create.py:232 msgid ""Could not create job template"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:40 msgid ""Input"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:46 msgid ""Output"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:119 msgid ""Unable to fetch clusters."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:191 msgid ""Main Class"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:194 msgid ""Java Opts"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:197 msgid ""Mapper"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:199 msgid ""Reducer"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:202 msgid ""Use HBase Common library"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:203 msgid ""Run HBase EDP Jobs with common HBase library on HDFS"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:207 msgid ""Adapt For Oozie"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:208 msgid """" ""Automatically modify the Hadoop configuration so that job config values "" ""are set and so that Oozie will handle exit codes correctly."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:214 msgid ""Enable Swift Paths"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:215 msgid """" ""Modify the configuration so that swift URLs can be dereferenced through "" ""HDFS at runtime."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:220 msgid ""Use Data Source Substitution for Names and UUIDs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:221 msgid """" ""Substitute data source objects for URLs of the form datasource://name or "" ""uuid."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:320 msgid ""Configure"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:416 msgid ""Persist cluster after job exit"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:491 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:584 msgid ""Job launched"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:492 #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:585 msgid ""Could not launch job"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:527 msgid ""Job configs"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:531 msgid ""Job args"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:535 msgid ""Job params"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:541 msgid ""Job Execution ID"" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:621 msgid ""Unable to create new cluster for job."" msgstr """" #: sahara_dashboard/content/data_processing/jobs/workflows/launch.py:638 msgid ""Unable to launch job."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/panel.py:22 #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:136 #: sahara_dashboard/content/data_processing/nodegroup_templates/views.py:41 msgid ""Node Group Templates"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/tables.py:43 msgid ""Configure Template"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/tabs.py:54 msgid ""Unable to fetch flavor for template."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/tabs.py:63 msgid ""Unable to fetch floating ip pools."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/tabs.py:80 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:2 msgid ""Service Configurations"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/views.py:54 msgid ""Unable to fetch node group template list."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/views.py:69 #, python-format msgid ""Unable to retrieve details for node group template \""%s\""."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/views.py:95 #: sahara_dashboard/content/data_processing/nodegroup_templates/views.py:103 #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/configure.html:3 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:418 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:580 msgid ""Create Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/views.py:133 msgid ""Unable to fetch template object."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:4 msgid ""This Node Group Template will be created for:"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:15 msgid """" ""The Node Group Template object specifies the processes\n"" "" that will be launched on each instance. Check one or more "" ""processes.\n"" "" When processes are selected, you may set <b>node</b> scoped\n"" "" configurations on corresponding tabs."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:18 msgid """" ""You must choose a flavor to determine the size (VCPUs, memory and "" ""storage) of all launched VMs."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:21 msgid """" ""Data Processing provides different storage location options. You may "" ""choose Ephemeral Drive or a Cinder Volume to be attached to instances."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_create_general_help.html:3 msgid ""Select a plugin and version for the new Node Group template."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:7 msgid ""Project Id"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:82 msgid ""HDFS placement"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:84 msgid ""Cinder volumes"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:85 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:72 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:78 msgid ""Volumes per node"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:87 msgid ""Volumes size"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:89 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:94 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:99 msgid ""Volumes type"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:91 msgid ""Volumes local to instance"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:94 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:116 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:122 msgid ""Volumes Availability Zone"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:98 msgid ""Ephemeral drive"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:3 msgid ""Filter"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:4 msgid ""Show full configuration"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:5 msgid ""Hide full configuration"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:12 #, python-format msgid ""%(conf_name)s: %(conf_val)s"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/copy.py:25 #, python-format msgid ""Node Group Template copy %s created"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/copy.py:109 msgid ""Unable to fetch plugin details."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:52 msgid ""OpenStack Flavor"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:56 msgid ""Launch instances in this availability zone."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:62 msgid ""Storage location"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:63 msgid ""Choose a storage location"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:83 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:89 msgid ""Volumes size (GB)"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:104 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:111 msgid ""Volume local to instance"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:106 msgid ""Instance and attached volumes will be created on the same physical host"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:117 msgid ""Create volumes in this availability zone."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:150 msgid """" ""If selected, instances of a node group will be automatically configured "" ""during cluster creation. Otherwise you should manually specify "" ""configuration values."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:162 msgid """" ""Sahara will use instances of this node group to access other cluster "" ""instances."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:167 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:169 msgid ""node group template"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:194 msgid ""Unable to get volume type list."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:196 msgid ""No volume type"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:208 #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:215 msgid ""No availability zone specified"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:230 msgid ""Configure Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:243 msgid ""Create security group for this Node Group."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:251 msgid ""Unable to get security group list."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:258 msgid ""Launch instances in these security groups."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:263 msgid ""Security"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:264 msgid ""Control access to instances of the node group."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:282 #, python-format msgid ""%s processes: "" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:322 msgid ""Unable to generate process choices."" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:330 msgid ""Select Node Group Processes"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:337 msgid ""Select node processes for the node group"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:365 msgid ""Select the manila shares for this node group"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:420 #, python-format msgid ""Created Node Group Template %s"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/create.py:561 msgid ""Select plugin and hadoop version"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/edit.py:31 #, python-format msgid ""Node Group Template %s updated"" msgstr """" #: sahara_dashboard/content/data_processing/nodegroup_templates/workflows/edit.py:33 msgid ""Edit Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/utils/acl.py:125 msgid ""If selected, {object_type} will be shared across the tenants"" msgstr """" #: sahara_dashboard/content/data_processing/utils/acl.py:136 msgid """" ""If selected, {object_type} will be protected from modifications until "" ""this will be unselected"" msgstr """" #: sahara_dashboard/content/data_processing/utils/anti_affinity.py:26 msgid ""Use anti-affinity groups for: "" msgstr """" #: sahara_dashboard/content/data_processing/utils/anti_affinity.py:28 msgid ""Use anti-affinity groups for processes"" msgstr """" #: sahara_dashboard/content/data_processing/utils/anti_affinity.py:61 msgid ""Unable to populate anti-affinity processes."" msgstr """" #: sahara_dashboard/content/data_processing/utils/helpers.py:131 msgid ""Streaming MapReduce"" msgstr """" #: sahara_dashboard/content/data_processing/utils/helpers.py:133 msgid ""Java"" msgstr """" #: sahara_dashboard/content/data_processing/utils/helpers.py:134 msgid ""Shell"" msgstr """" #: sahara_dashboard/content/data_processing/utils/neutron_support.py:31 msgid ""Unable to retrieve networks."" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:120 msgid ""Node group cluster"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:124 msgid ""Count"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:143 msgid ""Mapping Type"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:146 msgid ""Positional Argument"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:147 msgid ""Configuration Value"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:148 msgid ""Named Parameter"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:150 msgid ""Location"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:154 msgid ""Value Type"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:162 msgid ""Required"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:166 msgid ""Default Value"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:195 #, python-format msgid ""Unable to retrieve security group %(group)s."" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:228 #: sahara_dashboard/content/data_processing/wizard/forms.py:56 msgid ""Plugin Name"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:342 msgid ""Read/Write"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:342 msgid ""Read only"" msgstr """" #: sahara_dashboard/content/data_processing/utils/workflow_helpers.py:387 msgid ""The value of shares must be a list of values"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:43 msgid ""Cluster type chosen"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:47 msgid ""Unable to set cluster type"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:86 msgid ""Choose plugin type and version"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:116 #: sahara_dashboard/content/data_processing/wizard/forms.py:179 msgid ""Job type chosen"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:120 msgid ""Unable to set job type"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:126 msgid ""Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/forms.py:183 msgid ""Unable to set node group template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/panel.py:22 msgid ""Guides"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:32 msgid ""Data Processing Guides"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:38 msgid ""Unable to show guides"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:45 msgid ""Guided Cluster Creation"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:73 msgid ""Guided Job Execution"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:102 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_plugin_select.html:12 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/plugin_select.html:3 msgid ""Choose plugin and version"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:111 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_job_type_select.html:12 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/job_type_select.html:3 msgid ""Choose job type"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/views.py:120 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_ngt_select.html:12 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/ngt_select.html:3 msgid ""Choose node group template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_job_type_select_help.html:6 msgid """" ""Select which type of job that you want to run.\n"" "" This choice will dictate which steps are required to successfully\n"" "" execute your job.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_ngt_select_help.html:4 msgid """" ""Select an existing node group template.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/_plugin_select_help.html:4 msgid """" ""Select which plugin and version that you\n"" "" want to use to create your cluster."" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:19 msgid """" ""The first step is to determine which type of\n"" "" cluster you want to run. You may have several "" ""choices\n"" "" available depending on the configuration of your "" ""system.\n"" "" Click on \""choose plugin\"" to bring up the list of "" ""data\n"" "" processing plugins. There you will be able to choose"" "" the\n"" "" data processing plugin along with the version number."" ""\n"" "" Choosing this up front will allow the rest of the "" ""cluster\n"" "" creation steps to focus only on options that are "" ""pertinent\n"" "" to your desired cluster type."" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:22 msgid ""Choose plugin"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:23 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:67 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:102 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:134 msgid ""Current choice:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:26 msgid ""Plugin:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:28 msgid ""Version:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:33 msgid ""No plugin chosen"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:51 msgid """" ""Next, you need to define the different\n"" "" types of machines in your cluster. This is done "" ""by\n"" "" defining a Node Group Template for each type of\n"" "" machine. A very common case is where you\n"" "" need to have one or more machines running a "" ""\""master\""\n"" "" set of processes while another set of machines "" ""need\n"" "" to be running the \""worker\"" processes. Here,\n"" "" you will define the Node Group Template for your\n"" "" \""master\"" node(s).\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:57 msgid ""Create a Master Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:59 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:94 msgid "" or "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:63 msgid ""Choose an existing Master Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:70 msgid ""Master Node Group Template:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:75 msgid ""No Master Node Group Template Created"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:86 msgid """" ""Repeat the Node Group Template\n"" "" creation process, but this time you are creating\n"" "" your \""worker\"" Node Group Template."" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:92 msgid ""Create a Worker Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:98 msgid ""Choose an existing Worker Node Group Template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:105 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:137 msgid ""Worker Node Group Template:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:110 msgid ""No Worker Node Group Template Created"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:126 msgid """" ""Now you need to set the layout of your\n"" "" cluster. By\n"" "" creating a Cluster Template, you will be choosing"" "" the\n"" "" number of instances of each Node Group Template "" ""that\n"" "" will appear in your cluster. Additionally,\n"" "" you will have a chance to set any cluster-"" ""specific\n"" "" configuration items in the additional tabs on the"" ""\n"" "" create Cluster Template form."" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:132 msgid ""Create a Cluster Template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:142 msgid ""No Cluster Template Created"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:158 msgid """" ""You are now ready to\n"" "" launch your cluster. When you click on the link\n"" "" below, you will need to give your cluster a name,"" ""\n"" "" choose the Cluster Template to use and choose "" ""which\n"" "" image to use to build your instances. After you\n"" "" click on \""Create\"", your instances will begin to"" ""\n"" "" spawn. Your cluster should be operational in a "" ""few\n"" "" minutes."" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:164 msgid ""Launch a Cluster"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:172 msgid ""Reset Cluster Guide"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:174 msgid ""Reset Cluster Creation Guide"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:15 msgid """" ""First, select which type of job that\n"" "" you want to run. This choice will determine "" ""which\n"" "" other steps are required\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:20 msgid ""Select type"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:23 msgid ""Current type:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:30 msgid ""No type chosen"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:46 msgid """" ""Data Sources are what your\n"" "" job uses for input and output. Depending on "" ""the type\n"" "" of job you will be running, you may need to "" ""define one\n"" "" or more data sources. You can create "" ""multiple data\n"" "" sources by repeating this step.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:51 msgid ""Create a data source"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:65 msgid """" ""Define your Job Template.\n"" "" This is where you choose the type of job that you"" ""\n"" "" want to run (Pig, Java Action, Spark, etc) and "" ""choose\n"" "" or upload the files necessary to run it. The "" ""inputs\n"" "" and outputs will be defined later.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:70 msgid ""Create a job template"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:72 msgid ""Job template:"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:79 msgid ""No job template created"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:94 msgid """" ""Launch your job. When\n"" "" launching, you may need to choose your input and\n"" "" output data sources. This is where you would "" ""also\n"" "" add any special configuration values, parameters,"" ""\n"" "" or arguments that you need to pass along\n"" "" to your job.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:98 msgid ""Launch job"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:107 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:109 msgid ""Reset Job Execution Guide"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:19 msgid """" ""\n"" "" Each of the Data Processing frameworks require a cluster"" "" of machines\n"" "" in order to do the work they are assigned. A cluster is"" ""\n"" "" formed by creating a set of Node Group Templates, "" ""combining\n"" "" those into a Cluster Template and then launching a "" ""Cluster.\n"" "" You can do each of those steps manually, or you can "" ""follow\n"" "" this guide to help take you through the steps of\n"" "" Cluster creation.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:24 msgid ""Cluster Guide"" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:41 msgid """" ""\n"" "" In order to run a Data Processing job, you need to make"" ""\n"" "" the files for your program available to the\n"" "" Data Processing system, define where the input and "" ""output\n"" "" need to go and create a Job Template that describes\n"" "" how to run your job. Each of those steps can be done\n"" "" manually or you can follow this guide to help take you\n"" "" through the steps to run a job on an existing cluster.\n"" "" "" msgstr """" #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:46 #: sahara_dashboard/content/data_processing/wizard/templates/data_processing.wizard/wizard.html:48 msgid ""Job Execution Guide"" msgstr """" ",,4749,0
openstack%2Fneutron~master~Icd2849bd84dab6733a572e8c85f242afcefc6c78,openstack/neutron,master,Icd2849bd84dab6733a572e8c85f242afcefc6c78,Add precommit_XXX event for security group and rules,MERGED,2015-12-03 05:51:56.000000000,2016-02-19 06:55:47.000000000,2016-02-15 19:06:52.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11114}, {'_account_id': 11682}, {'_account_id': 13667}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14215}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17211}, {'_account_id': 20084}]","[{'number': 1, 'created': '2015-12-03 05:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5f25735925e2bebf50b4e1cba91e96f17a1f4e4', 'message': 'Add precommit event for security group\n\nAdd PRECOMMIT_CREATE/DELETE/UPDATE event type for callback function, and\nuse it in the security group db transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n'}, {'number': 2, 'created': '2015-12-04 07:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf1473ff6666c178f46c8034815af1985dd15c70', 'message': ""Add precommit event for security group\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the db\ntransaction. Unlike the precommit premitive in ML2 mech drivers, they\ndon't work in the same db transaction of resource, so if we want to\noperate the db in mech driver related to security group, there would be\nunsync issue if we use BEFORE_XXX event.\nThis patch adds PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules db transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 3, 'created': '2015-12-04 16:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/51b99dd3973754baa3c712260c233f1c07c542f1', 'message': ""Add precommit event for security group\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the db\ntransaction. Unlike the precommit premitive in ML2 mech drivers, they\ndon't work in the same db transaction of resource, so if we want to\noperate the db in mech driver related to security group, there would be\nunsync issue if we use BEFORE_XXX event.\nThis patch adds PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules db transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 4, 'created': '2015-12-04 20:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2c2d39d8bed38528124b85c70c49f5a82861fc8', 'message': ""Add precommit event for security group\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the db\ntransaction. Unlike the precommit premitive in ML2 mech drivers, they\ndon't work in the same db transaction of resource, so if we want to\noperate the db in mech driver related to security group, there would be\nunsync issue if we use BEFORE_XXX event.\nThis patch adds PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules db transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 5, 'created': '2015-12-08 15:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bca7e89719241e9ab73ffe8d7d6a3e3a30ddd01', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit premitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nunsync issue if we use BEFORE_XXX event.\nThis patch adds PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules db transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 6, 'created': '2015-12-10 16:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/79a922e8766403ddb86b6b897bd6d56f6575e253', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nunsync issue if we use BEFORE_XXX event.\nThis patch adds PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules db transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 7, 'created': '2015-12-10 21:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3385c0ae7c74de868bb0aecf4c8dc4e60a27890e', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nunsync issue if we use BEFORE_XXX event.\nThis patch adds PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules DB transaction.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 8, 'created': '2015-12-11 20:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/485e697a5847729e13956555fd8590167d3d1dec', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issue if we use BEFORE_XXX event. That move the BEFORE_XXX event\ninside may also break some current codes, as maybe RPC call included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for callback\nfunction, and use it in the securitygroup/rules DB transaction. We keep\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 9, 'created': '2015-12-14 23:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9a25d11cf9e050b9da57c2ac3504d3085cb54ca', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 10, 'created': '2015-12-18 16:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/795a1e325a1736b4deb16852b5a9f0bc5487fb05', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 11, 'created': '2015-12-23 05:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ba6111c2d562f84559725a244532b38b7367232', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 12, 'created': '2015-12-30 08:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/700764238a9612e0cc78dcc20a0a72cb0d659740', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 13, 'created': '2016-01-08 09:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69efe25293f27d2f67b0484ee941a3a68cf0c962', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 14, 'created': '2016-01-09 07:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9eef36ea60e2c9c316e41bd9831d230cebc0238', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. This patch also update the notify_loop logic\nto trigger PrecommitCallbackFailure when exception comes from the\ncallback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 15, 'created': '2016-01-14 05:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66ef7f7b1a1022222dfc1744b736ddade4198c65', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. This patch also update the notify_loop logic\nto trigger PrecommitCallbackFailure when exception comes from the\ncallback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 16, 'created': '2016-01-14 07:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9862a02bda8f13932b83850f5bbb8863a4e36d80', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. And CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 17, 'created': '2016-01-20 03:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b680d722734c5786bbc87a31d0205bb6da1cebe3', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. And CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 18, 'created': '2016-01-27 03:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99960b72b118a6804b2665ba68ef13d4912a922c', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. And CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 19, 'created': '2016-01-27 07:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26c7e5b7372fefda389099ffe5004cd5662489b4', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. And CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 20, 'created': '2016-01-27 10:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a0df0e7f20276007d9d8dc7e9bfd61239550730', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. And CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 21, 'created': '2016-01-28 02:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb70cf5061dd7a127f2da5af5ae419638786482b', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. A CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 22, 'created': '2016-01-28 05:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3c1d030b1645c7d5daa642f0ff8816da7cb923c', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. A CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 23, 'created': '2016-02-02 01:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc0a0e9beee60f2081427e29de233e162f0212d9', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. A CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 24, 'created': '2016-02-03 03:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27f0c8f2358ff003dfa934c69d6674cc8cf0644a', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. A CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 25, 'created': '2016-02-03 10:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a3b1c07cf486ce0c2fbdfd44dfcdf6e47370c4b', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. A CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}, {'number': 26, 'created': '2016-02-14 06:45:18.000000000', 'files': ['neutron/callbacks/manager.py', 'neutron/db/securitygroups_db.py', 'neutron/tests/unit/db/test_securitygroups_db.py', 'doc/source/devref/callbacks.rst', 'neutron/callbacks/events.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c24e9da2f82676d9b9d8c28018bf49c8a294121b', 'message': ""Add precommit_XXX event for security group and rules\n\nCurrent BEFORE_CREATE/DELETE/UPDATE event is outside of the DB\ntransaction. Unlike the precommit primitive in ML2 mech drivers, they\ndon't work in the same DB transaction of resource, so if we want to\noperate the DB in mech driver related to security group, there would be\nmore unsync issues if we use BEFORE_XXX event directly. Moving the\nBEFORE_XXX event inside may also break some current codes, as maybe RPC\ncall included.\n\nThis patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for\ncallback function, and use it in the securitygroup/rules DB transaction.\nPRECOMMIT_XXX is in the DB transaction and only purpose is to do DB\noperations in its callback. A CallbackFailure will be triggered when\nexception comes from the callback of the new event.\n\nChange-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78\nCloses-Bug: #1522172\n""}]",146,252755,c24e9da2f82676d9b9d8c28018bf49c8a294121b,431,31,26,11114,,,0,"Add precommit_XXX event for security group and rules

Current BEFORE_CREATE/DELETE/UPDATE event is outside of the DB
transaction. Unlike the precommit primitive in ML2 mech drivers, they
don't work in the same DB transaction of resource, so if we want to
operate the DB in mech driver related to security group, there would be
more unsync issues if we use BEFORE_XXX event directly. Moving the
BEFORE_XXX event inside may also break some current codes, as maybe RPC
call included.

This patch adds new PRECOMMIT_CREATE/DELETE/UPDATE event type for
callback function, and use it in the securitygroup/rules DB transaction.
PRECOMMIT_XXX is in the DB transaction and only purpose is to do DB
operations in its callback. A CallbackFailure will be triggered when
exception comes from the callback of the new event.

Change-Id: Icd2849bd84dab6733a572e8c85f242afcefc6c78
Closes-Bug: #1522172
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/252755/19 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/callbacks/events.py']",2,f5f25735925e2bebf50b4e1cba91e96f17a1f4e4,bug/1522172,PRECOMMIT_CREATE = 'precommit_create'PRECOMMIT_UPDATE = 'precommit_update'PRECOMMIT_DELETE= 'precommit_delete',,43,42
openstack%2Fironic~master~I4d6391748b6540e2674a14654db2298a8e74323e,openstack/ironic,master,I4d6391748b6540e2674a14654db2298a8e74323e,Add portgroups to support LAG interfaces - DB,ABANDONED,2015-08-12 15:05:48.000000000,2016-02-19 06:53:43.000000000,,[{'_account_id': 19258}],"[{'number': 1, 'created': '2015-08-12 15:05:48.000000000', 'files': ['ironic/tests/db/utils.py', 'ironic/common/exception.py', 'ironic/tests/db/test_ports.py', 'ironic/db/sqlalchemy/api.py', 'ironic/db/sqlalchemy/alembic/versions/5ea1b0d310e_added_port_group_table_and_altered_ports.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/db/sqlalchemy/models.py', 'ironic/tests/db/test_portgroups.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a9fcc97633ba79934e87eec95a090c7a03f298d', 'message': 'Add portgroups to support LAG interfaces - DB\n\nIronic should be able to provide the requisite connectivity\ninformation to the Neutron ML2 plugin to allow drivers to\nprovision the top-of-rack switch for the bare metal server.\nThe addition of portgroups in Ironic allows the concept of\nlink aggregation to be handled in Ironic in order to provide\nsupport for cases where multiple interfaces on the bare metal\nserver connect to switch ports of a single LAG.\n\nThis commit includes changes to:\n- the DB models (extension of port model and addition of portgroup\n  model)\n- the DB tests\n\nSpec available at:\nhttp://specs.openstack.org/openstack/ironic-specs/specs/liberty/\nironic-ml2-integration.html\n\nImplements: blueprint ironic-ml2-integration\nDocImpact\nCo-Authored-By: Laura Moore (laura.moore@sap.com)\nCo-Authored-By: Jenny Moorehead (jenny.moorehead@sap.com)\nCo-Authored-By: Will Stevenson (will.stevenson@sap.com)\n\nChange-Id: I4d6391748b6540e2674a14654db2298a8e74323e\n'}]",1,212064,1a9fcc97633ba79934e87eec95a090c7a03f298d,3,1,1,12366,,,0,"Add portgroups to support LAG interfaces - DB

Ironic should be able to provide the requisite connectivity
information to the Neutron ML2 plugin to allow drivers to
provision the top-of-rack switch for the bare metal server.
The addition of portgroups in Ironic allows the concept of
link aggregation to be handled in Ironic in order to provide
support for cases where multiple interfaces on the bare metal
server connect to switch ports of a single LAG.

This commit includes changes to:
- the DB models (extension of port model and addition of portgroup
  model)
- the DB tests

Spec available at:
http://specs.openstack.org/openstack/ironic-specs/specs/liberty/
ironic-ml2-integration.html

Implements: blueprint ironic-ml2-integration
DocImpact
Co-Authored-By: Laura Moore (laura.moore@sap.com)
Co-Authored-By: Jenny Moorehead (jenny.moorehead@sap.com)
Co-Authored-By: Will Stevenson (will.stevenson@sap.com)

Change-Id: I4d6391748b6540e2674a14654db2298a8e74323e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/64/212064/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/tests/db/utils.py', 'ironic/tests/db/test_ports.py', 'ironic/db/sqlalchemy/api.py', 'ironic/db/sqlalchemy/alembic/versions/5ea1b0d310e_added_port_group_table_and_altered_ports.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/db/sqlalchemy/models.py', 'ironic/tests/db/test_portgroups.py', 'ironic/db/api.py']",9,1a9fcc97633ba79934e87eec95a090c7a03f298d,bp/ironic-ml2-integration," def get_ports_by_portgroup_id(self, portgroup_id, limit=None, marker=None, sort_key=None, sort_dir=None): """"""List all the ports for a given portgroup. :param portgroup_id: The integer portgroup ID. :param limit: Maximum number of ports to return. :param marker: the last item of the previous page; we return the next result set. :param sort_key: Attribute by which results should be sorted :param sort_dir: direction in which results should be sorted (asc, desc) :returns: A list of ports. """""" @abc.abstractmethod def get_portgroup_by_id(self, portgroup_id): """"""Return a network portgroup representation. :param portgroup_id: The id of a portgroup. :returns: A portgroup. """""" @abc.abstractmethod def get_portgroup_by_uuid(self, portgroup_uuid): """"""Return a network portgroup representation. :param portgroup_uuid: The uuid of a portgroup. :returns: A portgroup. """""" @abc.abstractmethod def get_portgroup_by_address(self, address): """"""Return a network portgroup representation. :param address: The MAC address of a portgroup. :returns: A portgroup. """""" @abc.abstractmethod def get_portgroup_by_name(self, name): """"""Return a network portgroup representation. :param name: The logical name of a portgroup. :returns: A portgroup. """""" @abc.abstractmethod def get_portgroup_list(self, limit=None, marker=None, sort_key=None, sort_dir=None): """"""Return a list of portgroups. :param limit: Maximum number of ports to return. :param marker: the last item of the previous page; we return the next result set. :param sort_key: Attribute by which results should be sorted. :param sort_dir: direction in which results should be sorted. (asc, desc) :returns: A list of portgroups. """""" @abc.abstractmethod def get_portgroups_by_node_id(self, node_id, limit=None, marker=None, sort_key=None, sort_dir=None): """"""List all the portgroups for a given node. :param node_id: The integer node ID. :param limit: Maximum number of ports to return. :param marker: the last item of the previous page; we return the next result set. :param sort_key: Attribute by which results should be sorted :param sort_dir: direction in which results should be sorted (asc, desc) :returns: A list of portgroups. """""" @abc.abstractmethod def create_portgroup(self, values): """"""Create a new portgroup. :param values: Dict of values. """""" @abc.abstractmethod def update_portgroup(self, portgroup_id, values): """"""Update properties of an portgroup. :param portgroup_id: The id or MAC of a portgroup. :param values: Dict of values to update. :returns: A portgroup. """""" @abc.abstractmethod def destroy_portgroup(self, portgroup_id): """"""Destroy an portgroup. :param portgroup_id: The id or MAC of a portgroup. """""" @abc.abstractmethod",,576,1
openstack%2Fpython-senlinclient~master~Iedeb4d4aeadb2110adb53c097838038bf1e199b0,openstack/python-senlinclient,master,Iedeb4d4aeadb2110adb53c097838038bf1e199b0,Add JsonFormat display option,MERGED,2016-02-19 01:45:08.000000000,2016-02-19 06:53:08.000000000,2016-02-19 06:53:08.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-19 01:45:08.000000000', 'files': ['senlinclient/tests/unit/test_format_utils.py', 'senlinclient/common/format_utils.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/6ef4103ef0787bdd1e7edc4b377de26962cd44ec', 'message': 'Add JsonFormat display option\n\nJsonFormat is a base class from which commands that expect to dump\njson output can inherit. This class defaults to the cliff json_format\nformatter, and will not produce any output if no data is provided.\n\nChange-Id: Iedeb4d4aeadb2110adb53c097838038bf1e199b0\n'}]",0,282128,6ef4103ef0787bdd1e7edc4b377de26962cd44ec,7,3,1,18389,,,0,"Add JsonFormat display option

JsonFormat is a base class from which commands that expect to dump
json output can inherit. This class defaults to the cliff json_format
formatter, and will not produce any output if no data is provided.

Change-Id: Iedeb4d4aeadb2110adb53c097838038bf1e199b0
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/28/282128/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/tests/unit/test_format_utils.py', 'senlinclient/common/format_utils.py']",2,6ef4103ef0787bdd1e7edc4b377de26962cd44ec,add_format_utils,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from cliff import show class RawFormat(show.ShowOne): def produce_output(self, parsed_args, column_names, data): if data is None: return self.formatter.emit_one(column_names, data, self.app.stdout, parsed_args) class JsonFormat(RawFormat): @property def formatter_default(self): return 'json' class YamlFormat(RawFormat): @property def formatter_default(self): return 'yaml' class ShellFormat(RawFormat): @property def formatter_default(self): return 'shell' class ValueFormat(RawFormat): @property def formatter_default(self): return 'value' ",,140,0
openstack%2Foslo.messaging~stable%2Fliberty~I365414c541d895dcd49ebcd32c3a456a92c392d6,openstack/oslo.messaging,stable/liberty,I365414c541d895dcd49ebcd32c3a456a92c392d6,rabbit: improvements to QoS,MERGED,2016-02-15 18:58:47.000000000,2016-02-19 06:48:05.000000000,2016-02-19 06:48:05.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6159}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-02-15 18:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/324b1ba548213c10aa30892608d2e60b44f23acd', 'message': ""rabbit: improvements to QoS\n\n- Don't call _set_qos from both ensure_connection and on_reconnection,\n  instead consolidate and only call from _set_current_channel\n\n- Only set QoS on PURPOSE_LISTEN connections.  It's a waste of a\n  roundtrip to call it on PURPOSE_SEND connections and slows things\n  down unnecessarily\n\n- Guard against rabbit_qos_prefetch_count being set to a negative\n  value\n\n- Tests, because we love them\n\nChange-Id: I365414c541d895dcd49ebcd32c3a456a92c392d6\n(cherry picked from commit 5954d2ad640f126706ad0165e367a2ef57d32722)\n""}, {'number': 2, 'created': '2016-02-15 20:02:15.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e4a2a8eca9ecc5f65cd5482eb93504c64099cd74', 'message': ""rabbit: improvements to QoS\n\n- Don't call _set_qos from both ensure_connection and on_reconnection,\n  instead consolidate and only call from _set_current_channel\n\n- Only set QoS on PURPOSE_LISTEN connections.  It's a waste of a\n  roundtrip to call it on PURPOSE_SEND connections and slows things\n  down unnecessarily\n\n- Guard against rabbit_qos_prefetch_count being set to a negative\n  value\n\n- Tests, because we love them\n\nChange-Id: I365414c541d895dcd49ebcd32c3a456a92c392d6\n(cherry picked from commit 5954d2ad640f126706ad0165e367a2ef57d32722)\n""}]",0,280362,e4a2a8eca9ecc5f65cd5482eb93504c64099cd74,13,4,2,9257,,,0,"rabbit: improvements to QoS

- Don't call _set_qos from both ensure_connection and on_reconnection,
  instead consolidate and only call from _set_current_channel

- Only set QoS on PURPOSE_LISTEN connections.  It's a waste of a
  roundtrip to call it on PURPOSE_SEND connections and slows things
  down unnecessarily

- Guard against rabbit_qos_prefetch_count being set to a negative
  value

- Tests, because we love them

Change-Id: I365414c541d895dcd49ebcd32c3a456a92c392d6
(cherry picked from commit 5954d2ad640f126706ad0165e367a2ef57d32722)
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/62/280362/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,324b1ba548213c10aa30892608d2e60b44f23acd,qos-fixup, self.purpose = purpose if new_channel == self.channel: return if self.channel is not None: if (new_channel is not None and self.purpose == rpc_common.PURPOSE_LISTEN): self._set_qos(new_channel) if self.rabbit_qos_prefetch_count > 0:, self._set_qos(self.channel) self._set_qos(new_channel) if self.channel is not None and new_channel != self.channel: if self.rabbit_qos_prefetch_count != 0:,36,4
openstack%2Fpython-senlinclient~master~I2d337e2b6f702f231a000b0b30159e0953553148,openstack/python-senlinclient,master,I2d337e2b6f702f231a000b0b30159e0953553148,Add OpenstackClient plugin for cluster profile type list,MERGED,2016-02-18 12:45:00.000000000,2016-02-19 06:42:03.000000000,2016-02-19 06:42:03.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-18 12:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/c9b460f7675ef73a163feb209a1470393ef8141e', 'message': 'Add OpenstackClient plugin for cluster profile type list\n\nThis change implements the ""openstack cluster profile type list"" command\n  Based on the existing senlin command: senlin profile-type-list\n\nChange-Id: I2d337e2b6f702f231a000b0b30159e0953553148\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-02-19 01:28:45.000000000', 'files': ['senlinclient/osc/v1/profile_type.py', 'senlinclient/tests/unit/osc/v1/test_profile_type.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/23a1714b587d013e7851ff825537e39da2f720f4', 'message': 'Add OpenstackClient plugin for cluster profile type list\n\nThis change implements the ""openstack cluster profile type list"" command\n  Based on the existing senlin command: senlin profile-type-list\n\nChange-Id: I2d337e2b6f702f231a000b0b30159e0953553148\nBlueprint: senlin-support-python-openstackclient\n'}]",0,281809,23a1714b587d013e7851ff825537e39da2f720f4,13,3,2,18389,,,0,"Add OpenstackClient plugin for cluster profile type list

This change implements the ""openstack cluster profile type list"" command
  Based on the existing senlin command: senlin profile-type-list

Change-Id: I2d337e2b6f702f231a000b0b30159e0953553148
Blueprint: senlin-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/09/281809/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/osc/v1/profile_type.py', 'senlinclient/tests/unit/osc/v1/test_profile_type.py', 'setup.cfg']",3,c9b460f7675ef73a163feb209a1470393ef8141e,bp/senlin-support-python-openstackclient, cluster_profile_type_list = senlinclient.osc.v1.profile_type:ProfileTypeList,,99,0
openstack%2Fsecurity-doc~master~I79ab7273ee949bf3e332d21fc6b98c0a28c32628,openstack/security-doc,master,I79ab7273ee949bf3e332d21fc6b98c0a28c32628,Imported Translations from Zanata,MERGED,2016-02-19 06:08:00.000000000,2016-02-19 06:18:06.000000000,2016-02-19 06:18:06.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-19 06:08:00.000000000', 'files': ['security-guide/source/locale/ja/LC_MESSAGES/security-guide.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/ab7099237e82d2e45291e434c97802c123fe1da4', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I79ab7273ee949bf3e332d21fc6b98c0a28c32628\n'}]",0,282189,ab7099237e82d2e45291e434c97802c123fe1da4,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I79ab7273ee949bf3e332d21fc6b98c0a28c32628
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/89/282189/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/source/locale/ja/LC_MESSAGES/security-guide.po'],1,ab7099237e82d2e45291e434c97802c123fe1da4,zanata/translations,"""PO-Revision-Date: 2016-02-19 05:16+0000\n""msgid ""**Fail:** If TLS is not enabled on the HTTP server."" msgstr ""**失敗:** TLS が HTTP サーバーにおいて有効化されていない場合。"" ""**Fail:** If value of parameter ``enable`` under ``[eventlet_server_ssl]`` "" ""section is not set to ``True``."" msgstr """" ""**失敗:** ``[eventlet_server_ssl]`` セクションの ``enable`` パラメーターが "" ""``True`` に設定されている場合。"" msgid """"msgid ""**Pass:** If TLS is enabled on the HTTP server."" msgstr ""**成功:** TLS が HTTP サーバーにおいて有効化されている場合。"" ""**Pass:** If value of parameter ``enable`` under ``[eventlet_server_ssl]`` "" ""section in :file:`/etc/keystone/keystone.conf` is set to ``True``."" msgstr """" ""**成功:** :file:`/etc/keystone/keystone.conf` の ``[eventlet_server_ssl]`` に"" ""ある ``enable`` パラメーターの値が ``True`` に設定されている場合。"" msgid """"msgid """" ""A directory service, such as LDAP, RADIUS and Active Directory, which allows "" ""users to login with a user name and password, is a typical source of "" ""authentication tokens (e.g. passwords) at an :term:`identity provider`."" msgstr """" ""ユーザーがユーザー名とパスワードを用いてログインできるようにする、ディレクト"" ""リーサービス。LDAP、RADIUS、Active Directory など。 :term:`認証プロバイダー "" ""<identity provider>`において認証トークン (パスワードなど) の一般的な情報源に"" ""なる。"" msgid """" ""A threat actor is an abstract way to refer to a class of adversary that you "" ""may attempt to defend against. The more capable the actor, the more "" ""expensive the security controls that are required for successful attack "" ""mitigation and prevention. Security is a tradeoff between cost, usability "" ""and defense. In some cases it will not be possible to secure a cloud "" ""deployment against all of the threat actors we describe here. Those "" ""deploying an OpenStack cloud will have to decide where the balance lies for "" ""their deployment/usage."" msgstr """" ""脅威のアクターとは、防御の対象となりえる攻撃者のクラスを抽象的に表したもので"" ""す。アクターの技術が高くなるにつれ、攻撃の軽減や防止を成功させるために必要な"" ""セキュリティ制御にかかるコストが嵩みます。セキュリティはコスト、使いやすさ、"" ""防御の間でのトレードオフということになります。ここで記載した脅威のアクターす"" ""べてから、クラウドのデプロイメントを保護することはできません。OpenStack クラ"" ""ウドをデプロイする方は、デプロイメントと用途の間でバランスが確保できるポイン"" ""トを決定する必要が出てきます。"" msgid ""Check-Identity-03: is TLS enabled for Identity?"" msgstr ""Check-Identity-03: Identity の TLS を有効化していますか?"" msgid """" ""Highly capable and financially driven groups of attackers. Able to fund in-"" ""house exploit development and target research. In recent years the rise of "" ""organizations such as the Russian Business Network, a massive cyber-criminal "" ""enterprise, has demonstrated how cyber attacks have become a commodity. "" ""Industrial espionage falls within the serious organized crime group."" msgstr """" ""極めて有能で金銭で動く攻撃者グループ。エクスポロイと開発やターゲットのリサー"" ""チに対する資金を組織内で調達できます。最近、ロシアンビジネスネットワーク "" ""(RBN) などの組織が登場し、大規模なサイバー犯罪企業がサイバー攻撃がどのように"" ""して商品として成り立ったかを証明しました。産業スパイ活動は、SOC グループに分"" ""類されます。"" ""If your database server is configured for TLS transport, you will need to "" ""specify the certificate authority information for use with the initial "" ""connection string in the SQLAlchemy query."" msgstr """" ""データベースサーバーが TLS 転送を設定されている場合、SQLAlchemy クエリーの初"" ""期接続文字列に使用する CA の情報を指定する必要があります。"" msgid """"msgid """" ""Learn more about how to contribute to the OpenStack docs: http://docs."" ""openstack.org/contributor-guide/index.html."" msgstr """" ""OpenStack ドキュメントへのコントリビューション方法は http://docs.openstack."" ""org/contributor-guide/index.html にあります。"" ""The compute nodes are the least trusted of the services in OpenStack because "" ""they host tenant instances. The ``nova-conductor`` service has been "" ""introduced to serve as a database proxy, acting as an intermediary between "" ""the compute nodes and the database. We discuss its ramifications later in "" ""this chapter."" msgstr """" ""コンピュートノードは、プロジェクトのインスタンスをホストするため、OpenStack "" ""で最も信頼できないサービスです。 ``nova-conductor`` サービスは、コンピュート"" ""ノードとデータベースの中継役として動作する、データベースプロキシとして処理す"" ""るために導入されました。その結果について本章で後ほど議論します。"" msgid """"msgid """" ""The design of OpenStack is such that separation of security domains is "" ""difficult. Because core services will usually bridge at least two domains, "" ""special consideration must be given when applying security controls to them."" msgstr """" ""OpenStack のデザインではセキュリティドメインの分離が困難です。コアサービスは"" ""通常少なくとも 2 つのドメインをブリッジしているため、ドメインのセキュリティ制"" ""御を適用する場合、細心の注意を払う必要があります。"" msgid """" ""The diagram above shows a compute node bridging the data and management "" ""domains; as such, the compute node should be configured to meet the security "" ""requirements of the management domain. Similarly, the API Endpoint in this "" ""diagram is bridging the untrusted public domain and the management domain, "" ""which should be configured to protect against attacks from the public domain "" ""propagating through to the management domain."" msgstr """" ""上記の図は、データドメインと管理ドメインをブリッジするコンピュートノードで"" ""す。このように、コンピュートノードは管理ドメインのセキュリティ要件に見合うよ"" ""うに設定する必要があります。同様に、この図の API エンドポイントは信頼できない"" ""パブリックドメインと管理ドメインをブリッジしており、パブリックドメインから管"" ""理ドメインに伝搬しないように攻撃から保護されるように設定する必要があります。"" ""The prescriptive defense for each form of attack is beyond the scope of this "" ""document. The above diagram can assist you in making an informed decision "" ""about which types of threats, and threat actors, should be protected "" ""against. For commercial public cloud deployments this might include "" ""prevention against serious crime. For those deploying private clouds for "" ""government use, more stringent protective mechanisms should be in place, "" ""including carefully protected facilities and supply chains. In contrast, "" ""those standing up basic development or test environments will likely require "" ""less restrictive controls (middle of the spectrum)."" msgstr """" ""攻撃の形式ごとの規範的な防御については、本書の対象範囲外となっています。上記"" ""の図は、対策を行うべき脅威の種類、脅威のアクターについて詳細な情報を得た状態"" ""で意思決定ができるように支援します。商業的なパブリッククラウドのデプロイに関"" ""しては重大な犯罪の防止などが含まれる場合があります。 政府で使用するプライベー"" ""トクラウドをデプロイする方は、細心の注意を払って設置された対策施設やサプライ"" ""チェーンなど、より厳密な保護メカニズムを設置する必要があります。反対に、基本"" ""的なデプロイメントやテスト環境を設定する方は、制御に関する制約が少なくて済む"" ""でしょう。"" msgid """"msgid ""When you use eventlet:"" msgstr ""eventlet を使用している場合:"" msgid ""When you use the HTTP/WSGI server:"" msgstr ""HTTP/WSGI サーバーを使用している場合:"" msgid """" ""`Total security in a PostgreSQL database <https://www.ibm.com/developerworks/"" ""opensource/library/os-postgresecurity>`__"" msgstr """" ""`PostgreSQL データベースにおけるトータルセキュリティー <https://www.ibm.com/"" ""developerworks/opensource/library/os-postgresecurity>`__"" ","""PO-Revision-Date: 2016-02-18 06:00+0000\n""",148,1
openstack%2Fpython-senlinclient~master~I570863f8ad5ac2f9341595a98be9f100829f4608,openstack/python-senlinclient,master,I570863f8ad5ac2f9341595a98be9f100829f4608,Add filters option to profile-list command,MERGED,2016-02-18 18:39:42.000000000,2016-02-19 06:17:53.000000000,2016-02-19 06:17:53.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-02-18 18:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/d7f7414e7c918c275510754ee373a5db43352c7a', 'message': 'Add filters option to profile-list command\n\nCurrently profile-list command does not support the filters option.\nProfile List can have the filters like name, type, created_at,\nupdated_at and metadata.\n\nAfter this patch filters option will work for this command.\n\nChange-Id: I570863f8ad5ac2f9341595a98be9f100829f4608\nCloses-Bug: #1547105\n'}, {'number': 2, 'created': '2016-02-19 04:31:31.000000000', 'files': ['senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/575a290930ad8d56c51ec13f99b6813e9d2c011e', 'message': 'Add filters option to profile-list command\n\nCurrently profile-list command does not support the filters option.\nProfile List can have the filters like name, type, created_at,\nupdated_at and metadata.\n\nAfter this patch filters option will work for this command.\n\nChange-Id: I570863f8ad5ac2f9341595a98be9f100829f4608\nCloses-Bug: #1547105\n'}]",2,282001,575a290930ad8d56c51ec13f99b6813e9d2c011e,11,4,2,19840,,,0,"Add filters option to profile-list command

Currently profile-list command does not support the filters option.
Profile List can have the filters like name, type, created_at,
updated_at and metadata.

After this patch filters option will work for this command.

Change-Id: I570863f8ad5ac2f9341595a98be9f100829f4608
Closes-Bug: #1547105
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/01/282001/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/v1/shell.py']",2,d7f7414e7c918c275510754ee373a5db43352c7a,bug/1547105,"@utils.arg('-f', '--filters', metavar='<KEY1=VALUE1;KEY2=VALUE2...>', help=_('Filter parameters to apply on returned clusters. ' 'This can be specified multiple times, or once with ' 'parameters separated by a semicolon.'), action='append') if args.filters: queries.update(utils.format_parameters(args.filters))",,10,1
openstack%2Ffuel-qa~master~Ib4dfec08dcdb5e249505187bb6ebaeb9d6715abe,openstack/fuel-qa,master,Ib4dfec08dcdb5e249505187bb6ebaeb9d6715abe,Fix type error in usage of func from cli_base,MERGED,2016-02-18 19:48:19.000000000,2016-02-19 06:10:09.000000000,2016-02-19 06:10:09.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2016-02-18 19:48:19.000000000', 'files': ['gates_tests/tests/test_review_in_fuel_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/982ff75f964411606fb2d90db8dedb5a3f814a51', 'message': 'Fix type error in usage of func from cli_base\n\nMethods signatures in tests.cli_base.py were changed.\nSo gate tests start to fail with type error,\naccording to it missed to be updated.\n\nChange-Id: Ib4dfec08dcdb5e249505187bb6ebaeb9d6715abe\nCloses-Bug: #1547195\n'}]",0,282033,982ff75f964411606fb2d90db8dedb5a3f814a51,11,5,1,6719,,,0,"Fix type error in usage of func from cli_base

Methods signatures in tests.cli_base.py were changed.
So gate tests start to fail with type error,
according to it missed to be updated.

Change-Id: Ib4dfec08dcdb5e249505187bb6ebaeb9d6715abe
Closes-Bug: #1547195
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/33/282033/1 && git format-patch -1 --stdout FETCH_HEAD,['gates_tests/tests/test_review_in_fuel_client.py'],1,982ff75f964411606fb2d90db8dedb5a3f814a51,bug/1547195," self.update_cli_network_configuration(cluster_id) self.update_ssl_configuration(cluster_id) self.assert_cli_task_success(task, timeout=30 * 60) self.assert_cli_task_success(task, timeout=60 * 60)"," self.update_cli_network_configuration(cluster_id, remote) self.update_ssl_configuration(cluster_id, remote) self.assert_cli_task_success(task, remote, timeout=30 * 60) self.assert_cli_task_success(task, remote, timeout=60 * 60)",4,4
openstack%2Fproject-config~master~I732792ebd00a501ef91be64b719ed6ce1dc1d24f,openstack/project-config,master,I732792ebd00a501ef91be64b719ed6ce1dc1d24f,Keystone-only uwsgi job,MERGED,2016-01-07 22:21:22.000000000,2016-02-19 06:09:17.000000000,2016-02-19 06:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-01-07 22:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7bd8606365f8332d38053a3c2aefaecca7950426', 'message': ""Keystone-only uwsgi job\n\nThis adds a gate job to keystone that has keystone running under\nuwsgi rather than a) mod_wsgi in Apache httpd (which all the other\nprojects use by default), and b) eventlet (which we have a\nkeystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 2, 'created': '2016-01-07 22:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7127ffbe8af707c14a42208637488c7ba3ada3ab', 'message': ""Keystone-only uwsgi job\n\nThis adds a gate job to keystone that has keystone running under\nuwsgi rather than a) mod_wsgi in Apache httpd (which all the other\nprojects use by default), and b) eventlet (which we have a\nkeystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 3, 'created': '2016-01-08 20:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3263d9892ad1a7af47fff9802b7d1a0275d1fa59', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 4, 'created': '2016-01-20 21:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/50901be213ceb824762606305a54e78a2ed69af7', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 5, 'created': '2016-01-26 22:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/afca600a846fa9a6f62e237d601615ed58df0a3a', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 6, 'created': '2016-02-09 22:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/93c2e436c9afac68d8963e2a850642237485852a', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 7, 'created': '2016-02-17 20:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a590a536798254b537055e87cef96c962fbfb53c', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 8, 'created': '2016-02-17 20:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/77caa9385b941c750735e6670f48c0eb7cc4fdd1', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nDepends-On: If3b49879ce5181c16f0f0ab0db12fa55fe810a41\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}, {'number': 9, 'created': '2016-02-18 22:23:11.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0ef2c85693ce817d235c6e21ff90253027faf6e9', 'message': ""Keystone-only uwsgi job\n\nThis adds a non-voting gate job to keystone master that has keystone\nrunning under uwsgi rather than a) mod_wsgi in Apache httpd (which\nall the other projects use by default), and b) eventlet (which we\nhave a keystone gate job for already).\n\nWe're planning to eventually remove support for eventlet but we\nshould test running keystone under different wsgi containers to\nmake sure it's compatible.\n\n * non-voting so we can see that it works.\n * master-only since stable branches don't have the devstack\n   change.\n\nChange-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f\n""}]",12,264991,0ef2c85693ce817d235c6e21ff90253027faf6e9,47,6,9,6486,,,0,"Keystone-only uwsgi job

This adds a non-voting gate job to keystone master that has keystone
running under uwsgi rather than a) mod_wsgi in Apache httpd (which
all the other projects use by default), and b) eventlet (which we
have a keystone gate job for already).

We're planning to eventually remove support for eventlet but we
should test running keystone under different wsgi containers to
make sure it's compatible.

 * non-voting so we can see that it works.
 * master-only since stable branches don't have the devstack
   change.

Change-Id: I732792ebd00a501ef91be64b719ed6ce1dc1d24f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/91/264991/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",3,7bd8606365f8332d38053a3c2aefaecca7950426,keystone-uwsgi," export DEVSTACK_LOCAL_CONFIG=""KEYSTONE_USE_MOD_WSGI=False ; KEYSTONE_DEPLOY=eventlet"" export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: name: '{pipeline}-tempest-dsvm-keystone-uwsgi-full{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=120 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_FULL=1 export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_LOCAL_CONFIG=""KEYSTONE_USE_MOD_WSGI=False ; KEYSTONE_DEPLOY=uwsgi"""," export DEVSTACK_LOCAL_CONFIG=""KEYSTONE_USE_MOD_WSGI=False""",43,1
openstack%2Fha-guide~master~Ibb681480365fd482ad9e7905fc4b633281e4efe6,openstack/ha-guide,master,Ibb681480365fd482ad9e7905fc4b633281e4efe6,Imported Translations from Zanata,MERGED,2016-02-19 06:00:37.000000000,2016-02-19 06:09:05.000000000,2016-02-19 06:09:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-19 06:00:37.000000000', 'files': ['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/b156c565808189131312ab0ee9d9f3724c5ebcff', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibb681480365fd482ad9e7905fc4b633281e4efe6\n'}]",0,282183,b156c565808189131312ab0ee9d9f3724c5ebcff,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibb681480365fd482ad9e7905fc4b633281e4efe6
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/83/282183/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po'],1,b156c565808189131312ab0ee9d9f3724c5ebcff,zanata/translations,"""PO-Revision-Date: 2016-02-19 04:55+0000\n""""If you use HAProxy for load-balancing client access to Galera Cluster as "" ""described in the :doc:`controller-ha-haproxy`, you can use the "" ""``clustercheck`` utility to improve health checks."" msgstr """" "":doc:`controller-ha-haproxy` に記載されているとおり、Galera Cluster へのクラ"" ""イアントアクセスを負荷分散するために、HAProxy を使用している場合、 "" ""``clustercheck`` ユーティリティーを使用して、より良くヘルスチェックできます。"" msgid """"""Pacemaker does not inherently (need or want to) understand the applications "" ""it manages. Instead, it relies on resource agents (RAs), scripts that "" ""encapsulate the knowledge of how to start, stop, and check the health of "" ""each application managed by the cluster."" msgstr """" ""Pacemaker は、管理するアプリケーションを本質的に理解してません (必要ありませ"" ""ん)。代わりに、リソースエージェント (RA) に依存します。これは、クラスターによ"" ""り管理される各アプリケーションの起動、停止、ヘルスチェック方法に関する知識を"" ""隠蔽するスクリプトです。"" msgid """" ""Pacemaker relies on the `Corosync <http://corosync.github.io/corosync/>`_ "" ""messaging layer for reliable cluster communications. Corosync implements the "" ""Totem single-ring ordering and membership protocol. It also provides UDP and "" ""InfiniBand based messaging, quorum, and cluster membership to Pacemaker."" msgstr """" ""Pacemaker は、高信頼なクラスター通信のために `Corosync <http://corosync."" ""github.io/corosync/>`_ メッセージング層に依存します。Corosync は、Totem シン"" ""グルリングによる順番制御とメンバーシッププロトコルを実装します。また、UDP や "" ""InfiniBand ベースのメッセージング、クォーラム、クラスターメンバーシップを "" ""Pacemaker に提供します。"" msgid """" ""Pacemaker ships with a large set of OCF agents (such as those managing MySQL "" ""databases, virtual IP addresses, and RabbitMQ), but can also use any agents "" ""already installed on your system and can be extended with your own (see the "" ""`developer guide <http://www.linux-ha.org/doc/dev-guides/ra-dev-guide."" ""html>`_)."" msgstr """" ""Pacemaker は、(MySQL データベース、仮想 IP アドレス、RabbitMQ などの) OCF "" ""エージェントをたくさん同梱していますが、お使いのシステムにインストールした任"" ""意のエージェントも使用できます。また、自身で拡張することもできます "" ""(`developer guide <http://www.linux-ha.org/doc/dev-guides/ra-dev-guide."" ""html>`_ 参照)。"" msgid """"""The Memcached client implements hashing to balance objects among the "" ""instances. Failure of an instance only impacts a percentage of the objects "" ""and the client automatically removes it from the list of instances. The SLA "" ""is several minutes."" msgstr """" ""Memcached クライアントは、インスタンス間でオブジェクトを分散するハッシュ機能"" ""を持ちます。インスタンスの障害は、オブジェクトの使用率のみに影響します。クラ"" ""イアントは、インスタンスの一覧から自動的に削除されます。SLA は数分です。"" msgid """"""The first step is to install the database that sits at the heart of the "" ""cluster. To implement high availability, run an instance of the database on "" ""each controller node and use Galera Cluster to provide replication between "" ""them. Galera Cluster is a synchronous multi-master database cluster, based "" ""on MySQL and the InnoDB storage engine. It is a high-availability service "" ""that provides high system uptime, no data loss, and scalability for growth."" msgstr """" ""最初の手順は、クラスターの中心になるデータベースをインストールすることです。"" ""高可用性を実現するために、各コントローラーノードにおいてデータベースを実行"" ""し、ノード間でレプリケーションできる Galera Cluster を使用します。Galera "" ""Cluster は、MySQL と InnoDB ストレージエンジンをベースにした、同期型のマルチ"" ""マスターデータベースクラスターです。高いシステム稼働時間、データ損失なし、ス"" ""ケーラビリティーを提供する、高可用性サービスです。"" msgid """"msgid """" ""This makes the instances of HAProxy act independently and fail over "" ""transparently together with the network endpoints (VIP addresses) failover "" ""and, therefore, shares the same SLA."" msgstr """" ""HAProxy のインスタンスが独立して動作して、ネットワークエンドポイント (仮想 "" ""IP アドレス) のフェールオーバーと一緒に透過的にフェールオーバーするため、同"" ""じ SLA を共有します。"" ""`Pacemaker <http://clusterlabs.org/>`_ cluster stack is the state-of-the-art "" ""high availability and load balancing stack for the Linux platform. Pacemaker "" ""is useful to make OpenStack infrastructure highly available. Also, it is "" ""storage and application-agnostic, and in no way specific to OpenStack."" msgstr """" ""`Pacemaker <http://clusterlabs.org/>`_ クラスタースタックは、Linux プラット"" ""フォーム向けの最高水準の高可用性と負荷分散を実現します。Pacemaker は "" ""OpenStack インフラを高可用化するために役立ちます。また、ストレージとアプリ"" ""ケーションから独立していて、OpenStack 特有の方法はありません。"" msgid """"","""PO-Revision-Date: 2016-02-18 04:40+0000\n""",91,1
openstack%2Foslo.messaging~master~I1223f32594d8c1be28cc43fdd9bf102c86d75325,openstack/oslo.messaging,master,I1223f32594d8c1be28cc43fdd9bf102c86d75325,Remove executor callback,MERGED,2016-02-18 11:52:24.000000000,2016-02-19 06:02:14.000000000,2016-02-19 06:02:14.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8601}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-02-18 11:52:24.000000000', 'files': ['oslo_messaging/tests/executors/test_executor.py', 'oslo_messaging/_executors/base.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/rpc/dispatcher.py', 'oslo_messaging/dispatcher.py', 'oslo_messaging/_executors/impl_pooledexecutor.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/22fea728ccc217b18ae1ae2172d1c80d41e62c28', 'message': 'Remove executor callback\n\nRevert the change I556b112371bec2ec29cea4dc254bb3f9c6d2c07a: the\nexecutor callback API was only used by the aioeventlet executor which\nwas just removed.\n\nChange-Id: I1223f32594d8c1be28cc43fdd9bf102c86d75325\n'}]",0,281786,22fea728ccc217b18ae1ae2172d1c80d41e62c28,8,4,1,9107,,,0,"Remove executor callback

Revert the change I556b112371bec2ec29cea4dc254bb3f9c6d2c07a: the
executor callback API was only used by the aioeventlet executor which
was just removed.

Change-Id: I1223f32594d8c1be28cc43fdd9bf102c86d75325
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/86/281786/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/executors/test_executor.py', 'oslo_messaging/_executors/base.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/rpc/dispatcher.py', 'oslo_messaging/dispatcher.py', 'oslo_messaging/_executors/impl_pooledexecutor.py']",6,22fea728ccc217b18ae1ae2172d1c80d41e62c28,remove_trollius, callback = self.dispatcher(incoming)," callback = self.dispatcher(incoming, self._executor_callback)",26,48
openstack%2Fcinder~master~I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0,openstack/cinder,master,I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0,Manage/unmanage volume in ScaleIO driver,MERGED,2016-01-15 21:49:22.000000000,2016-02-19 05:56:40.000000000,2016-02-13 20:04:33.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2861}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11418}, {'_account_id': 11903}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14274}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16917}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17405}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 18997}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19917}, {'_account_id': 20442}]","[{'number': 1, 'created': '2016-01-15 21:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d67130f39ef302c2ee9647c9356bf23524dca820', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\n\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 2, 'created': '2016-01-15 21:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/95866f5a11539a8123f05c4a3ed843c0f3dc5889', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 3, 'created': '2016-01-15 22:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b820d93634e59e86371d24d3336c09a452bc6ff9', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 4, 'created': '2016-01-17 17:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/db7de8a9f67c5d9cb22db52c00fe8695dc2e94e3', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 5, 'created': '2016-01-19 14:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ccbe7d8783dc8a8070b679d140e531c25971c0cd', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 6, 'created': '2016-01-19 15:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2fff3a4c75102e2eca32fc063a99cfdcb6714b27', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 7, 'created': '2016-01-19 15:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/782928d70714bf8a150ffd40f4db1eab2c91157e', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 8, 'created': '2016-01-19 19:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8c31ea4a157da8fa29e3cc50b762a1ff48b39077', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 9, 'created': '2016-01-20 08:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/445d102b9351af2e101a95127bfddab8ea2785e4', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 10, 'created': '2016-01-20 08:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e415c579dade2a59cea37e9d323372621c33c88', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 11, 'created': '2016-01-27 10:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d0c7764a46f08e4e11334c9ecdb19849ea491c29', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 12, 'created': '2016-02-05 11:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f5c64a73905c97672e5274c822430add1e98dd38', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 13, 'created': '2016-02-07 15:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f96ec01cd5d1a737dd9ba861d0b9349df0e55c0a', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 14, 'created': '2016-02-07 15:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b7f91bc346ec7f2a26542ac3d069c62eefe37f17', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 15, 'created': '2016-02-08 09:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d4a41fa4c0eb19d4c462476e6532cf807f82a6d', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 16, 'created': '2016-02-08 10:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7faa0341f038a3a731efa752996de220a8aef005', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 17, 'created': '2016-02-08 21:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3654f8d2f5d36ec0940d5545c95010162b8367d5', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 18, 'created': '2016-02-09 20:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c289c6bcf88da11de0d408ff2a9da0ea611ebe91', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 19, 'created': '2016-02-10 09:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/516b249b56fb0edaf117149134b7e75352ebc822', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 20, 'created': '2016-02-10 20:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/67227837481bc4f9ca18f6894d43735528f41d28', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 21, 'created': '2016-02-10 20:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/928c10ffa23fedad8a8850153c241a498b71e534', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}, {'number': 22, 'created': '2016-02-12 15:17:08.000000000', 'files': ['cinder/tests/unit/volume/drivers/emc/scaleio/test_delete_snapshot.py', 'cinder/volume/drivers/emc/scaleio.py', 'cinder/tests/unit/volume/drivers/emc/scaleio/test_manage_existing.py', 'releasenotes/notes/scaleio-manage-existing-32217f6d1c295193.yaml', 'cinder/tests/unit/volume/drivers/emc/scaleio/mocks.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/eac894c09f31801430e61e89f3dbad127125ed6b', 'message': 'Manage/unmanage volume in ScaleIO driver\n\nAdd support for manage/unmanage volume in the ScaleIO driver.\n\nAlso fixed an error code for volume not found.\n\nDocImpact\nImplements: blueprint scaleio-manage-existing\nCloses-Bug: #1545023\nChange-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0\n'}]",39,268344,eac894c09f31801430e61e89f3dbad127125ed6b,602,67,22,6491,,,0,"Manage/unmanage volume in ScaleIO driver

Add support for manage/unmanage volume in the ScaleIO driver.

Also fixed an error code for volume not found.

DocImpact
Implements: blueprint scaleio-manage-existing
Closes-Bug: #1545023
Change-Id: I14ad94905aaa7ea2bef7c75011a40c5d057e1cc0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/268344/16 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/scaleio.py', 'cinder/tests/unit/volume/drivers/emc/scaleio/test_manage_existing.py', 'cinder/tests/unit/volume/drivers/emc/scaleio/mocks.py']",3,d67130f39ef302c2ee9647c9356bf23524dca820,bp/scaleio-consistency-groups,," def manage_existing(self, volume, existing_ref): pass def manage_existing_get_size(self, volume, existing_ref): pass ",341,96
openstack%2Fpuppet-vswitch~master~I70d7aecce28d041638adedb58b6fe7bc5302d235,openstack/puppet-vswitch,master,I70d7aecce28d041638adedb58b6fe7bc5302d235,Remove duplicate loading of constants,MERGED,2016-02-16 21:29:00.000000000,2016-02-19 05:36:55.000000000,2016-02-19 05:36:55.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-16 21:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/5c17772513c669fb9aa1a871ac4c3aebdace8586', 'message': 'Remove duplicate loading of constants\n\n  This commit moves another constant so that it iscontained inside a do\n  block instead of at the top of the file for the ovs provider.\n\n  Without this change the constants in question will generate a warning\n  because of the way puppet loads providers.  Anything in ruby defined\n  outside some other context gets parsed/executed immediately instead of\n  when needed.\n\nChange-Id: I70d7aecce28d041638adedb58b6fe7bc5302d235\n'}, {'number': 2, 'created': '2016-02-17 19:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/bdff8cc47f3054dd0ef5e4ec93f812672d0422a4', 'message': 'Remove duplicate loading of constants\n\n  This commit moves another constant so that it iscontained inside a do\n  block instead of at the top of the file for the ovs provider.\n\n  Without this change the constants in question will generate a warning\n  because of the way puppet loads providers.  Anything in ruby defined\n  outside some other context gets parsed/executed immediately instead of\n  when needed.\n\nChange-Id: I70d7aecce28d041638adedb58b6fe7bc5302d235\n'}, {'number': 3, 'created': '2016-02-17 21:48:22.000000000', 'files': ['lib/puppet/provider/vs_port/ovs.rb'], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/f4785cc8f3d0a7d2c8548435bf912a5a900e670d', 'message': 'Remove duplicate loading of constants\n\n  This commit moves another constant so that it iscontained inside a do\n  block instead of at the top of the file for the ovs provider.\n\n  Without this change the constants in question will generate a warning\n  because of the way puppet loads providers.  Anything in ruby defined\n  outside some other context gets parsed/executed immediately instead of\n  when needed.\n\nChange-Id: I70d7aecce28d041638adedb58b6fe7bc5302d235\n'}]",0,280937,f4785cc8f3d0a7d2c8548435bf912a5a900e670d,19,4,3,7423,,,0,"Remove duplicate loading of constants

  This commit moves another constant so that it iscontained inside a do
  block instead of at the top of the file for the ovs provider.

  Without this change the constants in question will generate a warning
  because of the way puppet loads providers.  Anything in ruby defined
  outside some other context gets parsed/executed immediately instead of
  when needed.

Change-Id: I70d7aecce28d041638adedb58b6fe7bc5302d235
",git fetch https://review.opendev.org/openstack/puppet-vswitch refs/changes/37/280937/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/vs_port/ovs.rb'],1,5c17772513c669fb9aa1a871ac4c3aebdace8586,, UUID_RE = /[a-f0-9]{8}-[a-f0-9]{4}-4[a-f0-9]{3}-[89aAbB][a-f0-9]{3}-[a-f0-9]{12}/ ,UUID_RE = /[a-f0-9]{8}-[a-f0-9]{4}-4[a-f0-9]{3}-[89aAbB][a-f0-9]{3}-[a-f0-9]{12}/,2,1
openstack%2Fsenlin~master~I7b96d39047e9097b5d67f2065de209c0c23969ee,openstack/senlin,master,I7b96d39047e9097b5d67f2065de209c0c23969ee,Update devstack comment,MERGED,2016-02-18 09:03:10.000000000,2016-02-19 05:16:24.000000000,2016-02-19 05:16:24.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-18 09:03:10.000000000', 'files': ['devstack/lib/senlin'], 'web_link': 'https://opendev.org/openstack/senlin/commit/f0c33eae2c826aca613ab5a3871376bdf59f68a8', 'message': 'Update devstack comment\n\nChange-Id: I7b96d39047e9097b5d67f2065de209c0c23969ee\n'}]",0,281703,f0c33eae2c826aca613ab5a3871376bdf59f68a8,7,3,1,6763,,,0,"Update devstack comment

Change-Id: I7b96d39047e9097b5d67f2065de209c0c23969ee
",git fetch https://review.opendev.org/openstack/senlin refs/changes/03/281703/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/senlin'],1,f0c33eae2c826aca613ab5a3871376bdf59f68a8,update_devstack_comment,"# To enable, add the following to local.conf# [[local|localrc]] # enable_plugin senlin https://git.openstack.org/openstack/senlin","# To enable, add the following to localrc# ENABLED_SERVICES+=,senlin,sl-api,sl-eng# - configure_senlinclient",3,3
openstack%2Fstorlets~master~I57046712be879a794613374a371c12e26d99ceb7,openstack/storlets,master,I57046712be879a794613374a371c12e26d99ceb7,Add some more comments about storlet_handler,ABANDONED,2016-02-05 07:50:32.000000000,2016-02-19 05:09:12.000000000,,"[{'_account_id': 3}, {'_account_id': 9816}]","[{'number': 1, 'created': '2016-02-05 07:50:32.000000000', 'files': ['Engine/swift/storlet_middleware/storlet_handler.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/40452e195312c0ba223599f99cd53a334d2cfc56', 'message': 'Add some more comments about storlet_handler\n\nChange-Id: I57046712be879a794613374a371c12e26d99ceb7\n'}]",0,276611,40452e195312c0ba223599f99cd53a334d2cfc56,5,2,1,9816,,,0,"Add some more comments about storlet_handler

Change-Id: I57046712be879a794613374a371c12e26d99ceb7
",git fetch https://review.opendev.org/openstack/storlets refs/changes/11/276611/1 && git format-patch -1 --stdout FETCH_HEAD,['Engine/swift/storlet_middleware/storlet_handler.py'],1,40452e195312c0ba223599f99cd53a334d2cfc56,handler-comments," :param conf: wsgi Application :param logger: logger instance """""" Check if the request requires storlet execution """""" """""" Check if the response from object-server is a slo response. :param resp: swob.Response instance :returns: True if the response is a slo response False if the response is not a slo response, or it is a failure response """""" """""" Check if the storlet should be excecuted at proxy-server :param resp: swob.Response instance """""" Determines from a GET request and its associated response", Determines from a GET request and its associated response,20,1
openstack%2Fpython-neutronclient~master~Ib23d1e53947b5dffcff8db0dde77cae0a0b31243,openstack/python-neutronclient,master,Ib23d1e53947b5dffcff8db0dde77cae0a0b31243,Fix the exception when ID/Name not found,MERGED,2016-01-27 08:20:53.000000000,2016-02-19 04:59:43.000000000,2016-02-19 04:59:43.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8410}, {'_account_id': 13933}, {'_account_id': 17120}, {'_account_id': 17211}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-01-27 08:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5edf546130a73c2ca1e2209256bfc3d75a5046f8', 'message': 'Fix the exception when ID/Name not found\n\nCurrently NeutronClient raises a broad exception\n(NeutronClientException) from [1]-[2], which is not appropriate.\nThe following patch proposes using the NotFound exception\nwhich does the same work.\n\n[1]:https://github.com/openstack/python-neutronclient/blob/master/neutronclient/neutron/v2_0/__init__.py#L72\n[2]:https://github.com/openstack/python-neutronclient/blob/master/neutronclient/neutron/v2_0/__init__.py#L109\n\nChange-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243\n'}, {'number': 2, 'created': '2016-02-04 04:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/764c76c076dce7fbcb0a6685d0261c99328ae20b', 'message': 'Fix the exception when ID/Name not found\n\nCurrently NeutronClient raises a broad exception\n(NeutronClientException) from [1]-[2], which is not appropriate.\nThe following patch proposes using the NotFound exception\nwhich does the same work.\n\n[1]:https://github.com/openstack/python-neutronclient/blob/master/neutronclient/neutron/v2_0/__init__.py#L72\n[2]:https://github.com/openstack/python-neutronclient/blob/master/neutronclient/neutron/v2_0/__init__.py#L109\n\nChange-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243\n'}, {'number': 3, 'created': '2016-02-05 00:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/881ff8159d23c4cbaa040a4c60b17945d093ecbb', 'message': 'Fix the exception when ID/Name not found\n\nCurrently NeutronClient raises a broad exception\n(NeutronClientException) from [1]-[2], which is not appropriate.\nThe following patch proposes using the NotFound exception\nwhich does the same work.\n\n[1]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n72\n[2]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n109\n\nChange-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243\n'}, {'number': 4, 'created': '2016-02-05 02:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/0b9f149734ef60d2c6a5191108290244e3e333f6', 'message': 'Fix the exception when ID/Name not found\n\nCurrently NeutronClient raises a broad exception\n(NeutronClientException) from [1]-[2], which is not appropriate.\nThe following patch proposes using the NotFound exception\nwhich does the same work.\n\n[1]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n72\n[2]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n109\n\nChange-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243\n'}, {'number': 5, 'created': '2016-02-12 04:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b3d0fb2dab95e4ea889d2d78e369a0bde54ba991', 'message': 'Fix the exception when ID/Name not found\n\nCurrently NeutronClient raises a broad exception\n(NeutronClientException) from [1]-[2], which is not appropriate.\nThe following patch proposes using the NotFound exception\nwhich does the same work.\n\n[1]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n72\n[2]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n109\n\nChange-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243\n'}, {'number': 6, 'created': '2016-02-19 02:09:32.000000000', 'files': ['neutronclient/tests/unit/test_name_or_id.py', 'neutronclient/neutron/v2_0/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/3e3baba4f232de7fd04e05bb6e9afdc723668594', 'message': 'Fix the exception when ID/Name not found\n\nCurrently NeutronClient raises a broad exception\n(NeutronClientException) from [1]-[2], which is not appropriate.\nThe following patch proposes using the NotFound exception\nwhich does the same work.\n\n[1]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n72\n[2]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n109\n\nChange-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243\n'}]",14,272940,3e3baba4f232de7fd04e05bb6e9afdc723668594,30,10,6,17776,,,0,"Fix the exception when ID/Name not found

Currently NeutronClient raises a broad exception
(NeutronClientException) from [1]-[2], which is not appropriate.
The following patch proposes using the NotFound exception
which does the same work.

[1]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n72
[2]:http://git.openstack.org/cgit/openstack/python-neutronclient/tree/neutronclient/neutron/v2_0/__init__.py#n109

Change-Id: Ib23d1e53947b5dffcff8db0dde77cae0a0b31243
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/40/272940/6 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/__init__.py'],1,5edf546130a73c2ca1e2209256bfc3d75a5046f8,correct_exception, raise exceptions.NotFound(message=not_found_message) raise exceptions.NotFound(message=not_found_message) except exceptions.NotFound:," # 404 is used to simulate server side behavior raise exceptions.NeutronClientException( message=not_found_message, status_code=404) # 404 is used to simulate server side behavior raise exceptions.NeutronClientException( message=not_found_message, status_code=404) except exceptions.NeutronClientException:",3,7
openstack%2Foslo.log~master~Ibecdbce63590935faebe56ec97190ff8447a03a5,openstack/oslo.log,master,Ibecdbce63590935faebe56ec97190ff8447a03a5,Updated from global requirements,MERGED,2016-02-19 02:36:03.000000000,2016-02-19 04:55:18.000000000,2016-02-19 04:55:18.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-19 02:36:03.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/d7d60c12dd0e3f63d228a8c1d0e4e35f2eac7b43', 'message': 'Updated from global requirements\n\nChange-Id: Ibecdbce63590935faebe56ec97190ff8447a03a5\n'}]",0,282137,d7d60c12dd0e3f63d228a8c1d0e4e35f2eac7b43,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ibecdbce63590935faebe56ec97190ff8447a03a5
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/37/282137/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d7d60c12dd0e3f63d228a8c1d0e4e35f2eac7b43,openstack/requirements,reno>=0.1.1 # Apache2,reno>=0.1.1 # Apache2,1,1
openstack%2Fsecurity-doc~master~Ie893310ff1afaa739502b8ad523d83ed9a257073,openstack/security-doc,master,Ie893310ff1afaa739502b8ad523d83ed9a257073,Adding Volume Wiping section to Sec Guide,ABANDONED,2016-02-19 04:51:57.000000000,2016-02-19 04:55:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-19 04:51:57.000000000', 'files': ['security-guide/target/docbkx/cloud/war/dist/xslt/base/common/functions.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunker.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/fr.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/autotoc.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sr.xml', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/license/big5/ARPHICPL.TXT', 'security-guide/target/docbkx/images/callouts/28.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/et.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/footnotes.xsl', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/COPYRIGHT', 'security-guide/target/docbkx/images/note.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/xh.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/preprocess.xsl', 'security-guide/target/docbkx/images/important.svg', 'security-guide/target/docbkx/images/callouts/16.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/biblio.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/zh.xml', 'security-guide/target/docbkx/cloud/webhelp/graphics.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pt.xml', 'security-guide/target/docbkx/cloud/war/docbook.xsl', 'security-guide/target/docbkx/images/cc/by-nd.svg', 'security-guide/target/docbkx/images/prev.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/gentext.xsl', 'security-guide/target/docbkx/images/cc/by-sa.svg', 'security-guide/target/docbkx/images/callouts/21.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/param.xml', 'security-guide/source/block-storage/volume_wiping.rst', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/Changelog.big5', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/is.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/admonitions.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sv.xml', 'security-guide/target/docbkx/images/next.svg', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-Bold.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/label-content.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ga.xml', 'security-guide/target/docbkx/images/cloud/rackspace-cover.st', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/am.xml', 'security-guide/target/docbkx/cloud/webhelp/xref.xsl', 'security-guide/target/docbkx/images/powered-by-openstack.png', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-Italic.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/hr.xml', 'security-guide/target/docbkx/images/callouts/24.svg', 'security-guide/target/docbkx/cloud/webhelp/webhelp-chunk-common.xsl', 'security-guide/target/docbkx/images/callouts/3.svg', 'security-guide/target/docbkx/cloud/webhelp/webhelp.xsl', 'security-guide/target/docbkx/autopdf/pdf.properties', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/zh_cn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/af.xml', 'security-guide/target/docbkx/images/callouts/13.svg', 'security-guide/target/docbkx/cloud/webhelp/titlepage.templates.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/nb.xml', 'security-guide/target/docbkx/images/tip.svg', 'security-guide/target/docbkx/images/callouts/27.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/id.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/math.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sq.xml', 'security-guide/target/docbkx/images/pdf.png', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pa.xml', 'security-guide/target/docbkx/images/Check_mark_23x20_02.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/lt.xml', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/TakaoGothic.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/bg.xml', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/license/english/ARPHICPL.TXT', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/msgset.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/xlink.xsl', 'security-guide/target/docbkx/images/cc/by-nc-sa.svg', 'security-guide/target/docbkx/cloud/war/preprocess.xsl', 'security-guide/target/docbkx/cloud/webhelp/bookinfo.xsl', 'security-guide/target/docbkx/images/cc/by-nc.svg', 'security-guide/target/docbkx/images/rackspace-logo.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/da.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/fa.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/th.xml', 'security-guide/target/docbkx/cloud/war/dist/docs/BUGS', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/annotation.js', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/or.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/en.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunk.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/15-transclude.xsl', 'security-guide/target/docbkx/images/callouts/17.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunkfunc.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ko.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/graphics.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/hu.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/eo.xml', 'security-guide/target/docbkx/cloud/war/xhtml2html.xsl', 'security-guide/target/docbkx/images/caution.svg', 'security-guide/target/docbkx/cloud/webhelp/titlepage/titlepage.templates.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/gl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/olink.xsl', 'security-guide/target/docbkx/cloud/webhelp/changebars.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/gu.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ro.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/nl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sk.xml', 'security-guide/target/docbkx/images/callouts/23.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/verbatim.xsl', 'security-guide/target/docbkx/images/callouts/4.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunktemp.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/pi.xsl', 'security-guide/target/docbkx/images/repose-logo.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/titlepage-templates.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/de.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/vi.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/toc.xsl', 'security-guide/target/docbkx/images/callouts/9.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/tl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/VERSION.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/lists.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/es.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/blocks.xsl', 'security-guide/target/docbkx/images/cc/by.svg', 'security-guide/target/docbkx/images/callouts/12.svg', 'security-guide/target/docbkx/images/up.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/refentry.xsl', 'security-guide/target/docbkx/images/openstack-logo.svg', 'security-guide/source/block-storage.rst', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/titlepages.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/oosynopsis.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/fi.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/docbook.xsl', 'security-guide/target/docbkx/images/callouts/18.svg', 'security-guide/target/docbkx/cloud/war/add-stop-chunking-pis.xsl', 'security-guide/target/docbkx/images/callouts/1.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/title-content.xsl', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-BoldItalic.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/az.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ja.xml', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/fireflysung.xml', 'security-guide/target/docbkx/cloud/webhelp/revhistory2atom.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/component.xsl', 'security-guide/target/docbkx/images/built-for-openstack.svg', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/README.ja', 'security-guide/target/docbkx/fonts/CartoGothic-Std/FontSite License.txt', 'security-guide/target/docbkx/images/callouts/8.svg', 'security-guide/target/docbkx/cloud/war/dist/docs/AUTHORS', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/la.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/xref.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/footnotes.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/kn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/he.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pt_br.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/3-schemaext.xsl', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/ChangeLog', 'security-guide/target/docbkx/images/callouts/22.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/cs.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/normalize.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/qandaset.xsl', 'security-guide/target/docbkx/cloud/webhelp/profile-webhelp.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sr_latn.xml', 'security-guide/target/docbkx/images/warning.svg', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/fireflysung.ttf', 'security-guide/target/docbkx/images/callouts/15.svg', 'security-guide/target/docbkx/images/callouts/5.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ca.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/index.xsl', 'security-guide/target/docbkx/cloud/webhelp/clean-wadl.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ky.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/section.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ru.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/task.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/1-db4to5.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/tr.xml', 'security-guide/target/docbkx/images/callouts/11.svg', 'security-guide/target/docbkx/images/cc/by-nc-nd.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/hi.xml', 'security-guide/target/docbkx/images/Arrow_east.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/inlines.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/param.xsl', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-Book.ttf', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/AUTHORS', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/spspace.xsl', 'security-guide/target/docbkx/images/callouts/26.svg', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/IPA_Font_License_Agreement_v1.0.txt', 'security-guide/target/docbkx/images/callouts/30.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/info.xsl', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/Changelog', 'security-guide/target/docbkx/cloud/war/dist/docs/COPYING', 'security-guide/target/docbkx/fonts/fontconfig.st', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/table.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/division.xsl', 'security-guide/target/docbkx/cloud/webhelp/docbook.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/eu.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/4-normalize.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/2-profile.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ar.xml', 'security-guide/target/docbkx/images/callouts/10.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/el.xml', 'security-guide/target/docbkx/cloud/war/static-header.xsl', 'security-guide/target/docbkx/images/home.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/glossary.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/autoidx.xsl', 'security-guide/target/docbkx/cloud/webhelp/copy.xsl', 'security-guide/target/docbkx/images/callouts/19.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/control.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/uk.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/i18ndata.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/table.xsl', 'security-guide/target/docbkx/images/callouts/20.svg', 'security-guide/target/docbkx/images/callouts/29.svg', 'security-guide/target/docbkx/cloud/war/copy.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/nn.xml', 'security-guide/target/docbkx/images/callouts/7.svg', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/README', 'security-guide/target/docbkx/cloud/war/changebars.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/bn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/common.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/l10n.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/cy.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/titlepage-mode.xsl', 'security-guide/target/docbkx/images/callouts/6.svg', 'security-guide/target/docbkx/images/callouts/14.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ta.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/verbatim-patch.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/it.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/marklogic.xqy', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/mn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/zh_tw.xml', 'security-guide/target/docbkx/images/rpc-coverlogo.png', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/makemetrics.sh', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/callouts.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/inlines.xsl', 'security-guide/target/docbkx/images/callouts/25.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/bs.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/html.xsl', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/license/gb/ARPHICPL.TXT', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/formal.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/lv.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/1-logstruct.xsl', 'security-guide/target/docbkx/images/cloud/openstackextension-cover.st', 'security-guide/target/docbkx/images/callouts/2.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/profile.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/synopsis.xsl'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/4f96666a6b47ce39c4ca3baf288773c6c2042e66', 'message': ""Adding Volume Wiping section to Sec Guide\n\nAs per bug, adding a section on volume wiping, based on John Griffith's\nmailing list postings on the subject.\n\nChange-Id: Ie893310ff1afaa739502b8ad523d83ed9a257073\nCloses-Bug: #1329606\n""}]",0,282166,4f96666a6b47ce39c4ca3baf288773c6c2042e66,3,1,1,9162,,,0,"Adding Volume Wiping section to Sec Guide

As per bug, adding a section on volume wiping, based on John Griffith's
mailing list postings on the subject.

Change-Id: Ie893310ff1afaa739502b8ad523d83ed9a257073
Closes-Bug: #1329606
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/66/282166/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/target/docbkx/cloud/war/dist/xslt/base/common/functions.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunker.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/fr.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/autotoc.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sr.xml', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/license/big5/ARPHICPL.TXT', 'security-guide/target/docbkx/images/callouts/28.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/et.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/footnotes.xsl', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/COPYRIGHT', 'security-guide/target/docbkx/images/note.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/xh.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/preprocess.xsl', 'security-guide/target/docbkx/images/important.svg', 'security-guide/target/docbkx/images/callouts/16.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/biblio.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/zh.xml', 'security-guide/target/docbkx/cloud/webhelp/graphics.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pt.xml', 'security-guide/target/docbkx/cloud/war/docbook.xsl', 'security-guide/target/docbkx/images/cc/by-nd.svg', 'security-guide/target/docbkx/images/prev.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/gentext.xsl', 'security-guide/target/docbkx/images/cc/by-sa.svg', 'security-guide/target/docbkx/images/callouts/21.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/param.xml', 'security-guide/source/block-storage/volume_wiping.rst', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/Changelog.big5', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/is.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/admonitions.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sv.xml', 'security-guide/target/docbkx/images/next.svg', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-Bold.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/label-content.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ga.xml', 'security-guide/target/docbkx/images/cloud/rackspace-cover.st', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/am.xml', 'security-guide/target/docbkx/cloud/webhelp/xref.xsl', 'security-guide/target/docbkx/images/powered-by-openstack.png', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-Italic.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/hr.xml', 'security-guide/target/docbkx/images/callouts/24.svg', 'security-guide/target/docbkx/cloud/webhelp/webhelp-chunk-common.xsl', 'security-guide/target/docbkx/images/callouts/3.svg', 'security-guide/target/docbkx/cloud/webhelp/webhelp.xsl', 'security-guide/target/docbkx/autopdf/pdf.properties', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/zh_cn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/af.xml', 'security-guide/target/docbkx/images/callouts/13.svg', 'security-guide/target/docbkx/cloud/webhelp/titlepage.templates.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/nb.xml', 'security-guide/target/docbkx/images/tip.svg', 'security-guide/target/docbkx/images/callouts/27.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/id.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/math.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sq.xml', 'security-guide/target/docbkx/images/pdf.png', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pa.xml', 'security-guide/target/docbkx/images/Check_mark_23x20_02.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/lt.xml', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/TakaoGothic.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/bg.xml', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/license/english/ARPHICPL.TXT', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/msgset.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/xlink.xsl', 'security-guide/target/docbkx/images/cc/by-nc-sa.svg', 'security-guide/target/docbkx/cloud/war/preprocess.xsl', 'security-guide/target/docbkx/cloud/webhelp/bookinfo.xsl', 'security-guide/target/docbkx/images/cc/by-nc.svg', 'security-guide/target/docbkx/images/rackspace-logo.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/da.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/fa.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/th.xml', 'security-guide/target/docbkx/cloud/war/dist/docs/BUGS', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/annotation.js', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/or.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/en.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunk.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/15-transclude.xsl', 'security-guide/target/docbkx/images/callouts/17.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunkfunc.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ko.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/graphics.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/hu.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/eo.xml', 'security-guide/target/docbkx/cloud/war/xhtml2html.xsl', 'security-guide/target/docbkx/images/caution.svg', 'security-guide/target/docbkx/cloud/webhelp/titlepage/titlepage.templates.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/gl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/olink.xsl', 'security-guide/target/docbkx/cloud/webhelp/changebars.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/gu.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ro.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/nl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sk.xml', 'security-guide/target/docbkx/images/callouts/23.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/verbatim.xsl', 'security-guide/target/docbkx/images/callouts/4.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/chunktemp.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/pi.xsl', 'security-guide/target/docbkx/images/repose-logo.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/titlepage-templates.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/de.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/vi.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/toc.xsl', 'security-guide/target/docbkx/images/callouts/9.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/tl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/VERSION.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/lists.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/es.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/blocks.xsl', 'security-guide/target/docbkx/images/cc/by.svg', 'security-guide/target/docbkx/images/callouts/12.svg', 'security-guide/target/docbkx/images/up.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/refentry.xsl', 'security-guide/target/docbkx/images/openstack-logo.svg', 'security-guide/source/block-storage.rst', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/titlepages.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/oosynopsis.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/fi.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/docbook.xsl', 'security-guide/target/docbkx/images/callouts/18.svg', 'security-guide/target/docbkx/cloud/war/add-stop-chunking-pis.xsl', 'security-guide/target/docbkx/images/callouts/1.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/title-content.xsl', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-BoldItalic.ttf', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/az.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ja.xml', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/fireflysung.xml', 'security-guide/target/docbkx/cloud/webhelp/revhistory2atom.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/component.xsl', 'security-guide/target/docbkx/images/built-for-openstack.svg', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/README.ja', 'security-guide/target/docbkx/fonts/CartoGothic-Std/FontSite License.txt', 'security-guide/target/docbkx/images/callouts/8.svg', 'security-guide/target/docbkx/cloud/war/dist/docs/AUTHORS', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/la.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/xref.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/footnotes.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/kn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/he.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pt_br.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/3-schemaext.xsl', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/ChangeLog', 'security-guide/target/docbkx/images/callouts/22.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/cs.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/normalize.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/qandaset.xsl', 'security-guide/target/docbkx/cloud/webhelp/profile-webhelp.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/sr_latn.xml', 'security-guide/target/docbkx/images/warning.svg', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/fireflysung.ttf', 'security-guide/target/docbkx/images/callouts/15.svg', 'security-guide/target/docbkx/images/callouts/5.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ca.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/index.xsl', 'security-guide/target/docbkx/cloud/webhelp/clean-wadl.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ky.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/section.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ru.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/task.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/1-db4to5.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/tr.xml', 'security-guide/target/docbkx/images/callouts/11.svg', 'security-guide/target/docbkx/images/cc/by-nc-nd.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/hi.xml', 'security-guide/target/docbkx/images/Arrow_east.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/inlines.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/param.xsl', 'security-guide/target/docbkx/fonts/CartoGothic-Std/CartoGothicStd-Book.ttf', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/AUTHORS', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/spspace.xsl', 'security-guide/target/docbkx/images/callouts/26.svg', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/IPA_Font_License_Agreement_v1.0.txt', 'security-guide/target/docbkx/images/callouts/30.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/pl.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/info.xsl', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/Changelog', 'security-guide/target/docbkx/cloud/war/dist/docs/COPYING', 'security-guide/target/docbkx/fonts/fontconfig.st', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/table.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/division.xsl', 'security-guide/target/docbkx/cloud/webhelp/docbook.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/eu.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/4-normalize.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/2-profile.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ar.xml', 'security-guide/target/docbkx/images/callouts/10.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/el.xml', 'security-guide/target/docbkx/cloud/war/static-header.xsl', 'security-guide/target/docbkx/images/home.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/glossary.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/autoidx.xsl', 'security-guide/target/docbkx/cloud/webhelp/copy.xsl', 'security-guide/target/docbkx/images/callouts/19.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/control.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/uk.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/i18ndata.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/table.xsl', 'security-guide/target/docbkx/images/callouts/20.svg', 'security-guide/target/docbkx/images/callouts/29.svg', 'security-guide/target/docbkx/cloud/war/copy.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/nn.xml', 'security-guide/target/docbkx/images/callouts/7.svg', 'security-guide/target/docbkx/fonts/takao-fonts-ttf-003.02.01/README', 'security-guide/target/docbkx/cloud/war/changebars.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/bn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/common.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/l10n.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/cy.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/titlepage-mode.xsl', 'security-guide/target/docbkx/images/callouts/6.svg', 'security-guide/target/docbkx/images/callouts/14.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/ta.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/verbatim-patch.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/it.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/marklogic.xqy', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/mn.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/zh_tw.xml', 'security-guide/target/docbkx/images/rpc-coverlogo.png', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/makemetrics.sh', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/callouts.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/inlines.xsl', 'security-guide/target/docbkx/images/callouts/25.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/bs.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/html.xsl', 'security-guide/target/docbkx/fonts/fireflysung-1.3.0/license/gb/ARPHICPL.TXT', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/formal.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/common/locales/lv.xml', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/1-logstruct.xsl', 'security-guide/target/docbkx/images/cloud/openstackextension-cover.st', 'security-guide/target/docbkx/images/callouts/2.svg', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/preprocess/profile.xsl', 'security-guide/target/docbkx/cloud/war/dist/xslt/base/html/synopsis.xsl']",235,4f96666a6b47ce39c4ca3baf288773c6c2042e66,bug/1329606,"<?xml version=""1.0"" encoding=""utf-8""?> <xsl:stylesheet xmlns:xsl=""http://www.w3.org/1999/XSL/Transform"" xmlns=""http://www.w3.org/1999/xhtml"" xmlns:db=""http://docbook.org/ns/docbook"" xmlns:doc=""http://nwalsh.com/xsl/documentation/1.0"" xmlns:f=""http://docbook.org/xslt/ns/extension"" xmlns:fn=""http://www.w3.org/2005/xpath-functions"" xmlns:h=""http://www.w3.org/1999/xhtml"" xmlns:m=""http://docbook.org/xslt/ns/mode"" xmlns:t=""http://docbook.org/xslt/ns/template"" exclude-result-prefixes=""db doc f fn h m t"" version=""2.0""> <xsl:include href=""oosynopsis.xsl""/> <xsl:template match=""db:refsynopsis""> <div> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates/> </div> </xsl:template> <!-- ============================================================ --> <!-- The following definitions match those given in the reference documentation for DocBook V3.0 --> <xsl:variable name=""arg.choice.opt.open.str"">[</xsl:variable> <xsl:variable name=""arg.choice.opt.close.str"">]</xsl:variable> <xsl:variable name=""arg.choice.req.open.str"">{</xsl:variable> <xsl:variable name=""arg.choice.req.close.str"">}</xsl:variable> <xsl:variable name=""arg.choice.plain.open.str""><xsl:text> </xsl:text></xsl:variable> <xsl:variable name=""arg.choice.plain.close.str""><xsl:text> </xsl:text></xsl:variable> <xsl:variable name=""arg.choice.def.open.str"">[</xsl:variable> <xsl:variable name=""arg.choice.def.close.str"">]</xsl:variable> <xsl:variable name=""arg.rep.repeat.str"">...</xsl:variable> <xsl:variable name=""arg.rep.norepeat.str""></xsl:variable> <xsl:variable name=""arg.rep.def.str""></xsl:variable> <xsl:variable name=""arg.or.sep""> | </xsl:variable> <xsl:variable name=""cmdsynopsis.hanging.indent"">0.66in</xsl:variable> <xsl:variable name=""cmdsynopsis.margin.top"">1em</xsl:variable> <xsl:template match=""db:cmdsynopsis""> <div> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:attribute name=""style""> <xsl:text>margin-top: </xsl:text> <xsl:value-of select=""$cmdsynopsis.margin.top""/> <xsl:text>; </xsl:text> <xsl:if test=""f:length-magnitude($cmdsynopsis.hanging.indent) != 0""> <xsl:text>text-indent: -</xsl:text> <xsl:value-of select=""$cmdsynopsis.hanging.indent""/> <xsl:text>; margin-left: </xsl:text> <xsl:value-of select=""$cmdsynopsis.hanging.indent""/> <xsl:text>;</xsl:text> </xsl:if> </xsl:attribute> <xsl:apply-templates/> </div> </xsl:template> <xsl:template match=""db:cmdsynopsis/db:command""> <xsl:if test=""preceding-sibling::*[1]""> <br/> </xsl:if> <xsl:call-template name=""t:inline-monoseq""/> <xsl:text> </xsl:text> </xsl:template> <xsl:template match=""db:group|db:arg"" name=""t:group-or-arg""> <xsl:variable name=""choice"" select=""@choice""/> <xsl:variable name=""rep"" select=""@rep""/> <xsl:variable name=""sepchar""> <xsl:choose> <xsl:when test=""ancestor-or-self::*/@sepchar""> <xsl:value-of select=""ancestor-or-self::*/@sepchar""/> </xsl:when> <xsl:otherwise> <xsl:text> </xsl:text> </xsl:otherwise> </xsl:choose> </xsl:variable> <xsl:if test=""position()>1""> <xsl:value-of select=""$sepchar""/> </xsl:if> <xsl:choose> <xsl:when test=""$choice='plain'""> <xsl:value-of select=""$arg.choice.plain.open.str""/> </xsl:when> <xsl:when test=""$choice='req'""> <xsl:value-of select=""$arg.choice.req.open.str""/> </xsl:when> <xsl:when test=""$choice='opt'""> <xsl:value-of select=""$arg.choice.opt.open.str""/> </xsl:when> <xsl:otherwise> <xsl:value-of select=""$arg.choice.def.open.str""/> </xsl:otherwise> </xsl:choose> <xsl:apply-templates/> <xsl:choose> <xsl:when test=""$rep='repeat'""> <xsl:value-of select=""$arg.rep.repeat.str""/> </xsl:when> <xsl:when test=""$rep='norepeat'""> <xsl:value-of select=""$arg.rep.norepeat.str""/> </xsl:when> <xsl:otherwise> <xsl:value-of select=""$arg.rep.def.str""/> </xsl:otherwise> </xsl:choose> <xsl:choose> <xsl:when test=""$choice='plain'""> <xsl:value-of select=""$arg.choice.plain.close.str""/> </xsl:when> <xsl:when test=""$choice='req'""> <xsl:value-of select=""$arg.choice.req.close.str""/> </xsl:when> <xsl:when test=""$choice='opt'""> <xsl:value-of select=""$arg.choice.opt.close.str""/> </xsl:when> <xsl:otherwise> <xsl:value-of select=""$arg.choice.def.close.str""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:group/db:arg""> <xsl:variable name=""choice"" select=""@choice""/> <xsl:variable name=""rep"" select=""@rep""/> <xsl:if test=""position()>1""> <xsl:value-of select=""$arg.or.sep""/> </xsl:if> <xsl:call-template name=""t:group-or-arg""/> </xsl:template> <xsl:template match=""db:sbr""> <br/> </xsl:template> <xsl:template match=""db:synopfragmentref""> <xsl:variable name=""target"" select=""key('id',@linkend)""/> <xsl:variable name=""snum""> <xsl:apply-templates select=""$target"" mode=""m:synopfragment.number""/> </xsl:variable> <span> <xsl:sequence select=""f:html-attributes(.)""/> <a href=""#{@linkend}""> <xsl:text>(</xsl:text> <xsl:value-of select=""$snum""/> <xsl:text>)</xsl:text> </a> <xsl:text>&#160;</xsl:text> <xsl:apply-templates/> </span> </xsl:template> <xsl:template match=""db:synopfragment"" mode=""m:synopfragment.number""> <xsl:number format=""1""/> </xsl:template> <xsl:template match=""db:synopfragment""> <div> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:attribute name=""style""> <xsl:text>margin-top: </xsl:text> <xsl:value-of select=""$cmdsynopsis.margin.top""/> <xsl:text>; </xsl:text> </xsl:attribute> <xsl:text>(</xsl:text> <xsl:apply-templates select=""."" mode=""m:synopfragment.number""/> <xsl:text>)</xsl:text> <xsl:text> </xsl:text> <xsl:apply-templates/> </div> </xsl:template> <!-- ==================================================================== --> <xsl:param name=""funcsynopsis.decoration"" select=""1""/> <xsl:param name=""funcsynopsis.style"">kr</xsl:param> <xsl:param name=""funcsynopsis.tabular.threshold"" select=""40""/> <xsl:template match=""db:funcsynopsis""> <div> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates/> </div> </xsl:template> <xsl:template match=""db:funcsynopsisinfo""> <pre> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates/> </pre> </xsl:template> <!-- ============================================================ --> <!-- funcprototype --> <!-- funcprototype ::= (funcdef, (void|varargs|paramdef+)) funcdef ::= (#PCDATA|type|replaceable|function)* paramdef ::= (#PCDATA|type|replaceable|parameter|funcparams)* --> <xsl:template match=""db:funcprototype""> <xsl:choose> <xsl:when test=""../@language='xslt2-function'""> <xsl:apply-templates select=""."" mode=""m:funcprototype-xslt2-function""/> </xsl:when> <xsl:when test=""../@language='xslt2-template'""> <xsl:apply-templates select=""."" mode=""m:funcprototype-xslt2-template""/> </xsl:when> <xsl:otherwise> <xsl:variable name=""pis"" select=""ancestor::db:funcsynopsis //processing-instruction('dbhtml')""/> <xsl:variable name=""html-style"" select=""f:pi($pis, 'funcsynopsis-style')""/> <xsl:variable name=""style""> <xsl:choose> <xsl:when test=""$html-style != ''""> <xsl:value-of select=""$html-style""/> </xsl:when> <xsl:otherwise> <xsl:value-of select=""$funcsynopsis.style""/> </xsl:otherwise> </xsl:choose> </xsl:variable> <xsl:variable name=""tabular-p"" select=""$funcsynopsis.tabular.threshold &gt; 0 and string-length(.) &gt; $funcsynopsis.tabular.threshold""/> <xsl:choose> <xsl:when test=""$style = 'kr' and $tabular-p""> <xsl:apply-templates select=""."" mode=""m:kr-tabular""/> </xsl:when> <xsl:when test=""$style = 'kr'""> <xsl:apply-templates select=""."" mode=""m:kr-nontabular""/> </xsl:when> <xsl:when test=""$style = 'ansi' and $tabular-p""> <xsl:apply-templates select=""."" mode=""m:ansi-tabular""/> </xsl:when> <xsl:otherwise> <xsl:apply-templates select=""."" mode=""m:ansi-nontabular""/> </xsl:otherwise> </xsl:choose> </xsl:otherwise> </xsl:choose> </xsl:template> <!-- ============================================================ --> <!-- funcprototype: kr, non-tabular --> <xsl:template match=""db:funcprototype"" mode=""m:kr-nontabular""> <p> <xsl:apply-templates mode=""m:kr-nontabular""/> <xsl:if test=""db:paramdef""> <br/> <xsl:apply-templates select=""db:paramdef"" mode=""m:kr-funcsynopsis-mode""/> </xsl:if> </p> </xsl:template> <xsl:template match=""db:funcdef"" mode=""m:kr-nontabular""> <code> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:kr-nontabular""/> <xsl:text>(</xsl:text> </code> </xsl:template> <xsl:template match=""db:funcdef/db:function"" mode=""m:kr-nontabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <b class=""fsfunc""><xsl:apply-templates mode=""m:kr-nontabular""/></b> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-nontabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:void"" mode=""m:kr-nontabular""> <code>)</code> <xsl:text>;</xsl:text> </xsl:template> <xsl:template match=""db:varargs"" mode=""m:kr-nontabular""> <xsl:text>...</xsl:text> <code>)</code> <xsl:text>;</xsl:text> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:kr-nontabular""> <xsl:apply-templates select=""db:parameter"" mode=""m:kr-nontabular""/> <xsl:choose> <xsl:when test=""following-sibling::*""> <xsl:text>, </xsl:text> </xsl:when> <xsl:otherwise> <code>)</code> <xsl:text>;</xsl:text> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:paramdef/db:parameter"" mode=""m:kr-nontabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <var class=""pdparam""> <xsl:apply-templates mode=""m:kr-nontabular""/> </var> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-nontabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:kr-funcsynopsis-mode""> <xsl:if test=""preceding-sibling::db:paramdef""><br/></xsl:if> <xsl:apply-templates mode=""m:kr-funcsynopsis-mode""/> <xsl:text>;</xsl:text> </xsl:template> <xsl:template match=""db:paramdef/db:parameter"" mode=""m:kr-funcsynopsis-mode""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <var class=""pdparam""> <xsl:apply-templates mode=""m:kr-funcsynopsis-mode""/> </var> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-funcsynopsis-mode""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:funcparams"" mode=""m:kr-funcsynopsis-mode""> <code>(</code> <xsl:apply-templates mode=""m:kr-funcsynopsis-mode""/> <code>)</code> <xsl:text>;</xsl:text> </xsl:template> <!-- ============================================================ --> <!-- funcprototype: kr, tabular --> <xsl:template match=""db:funcprototype"" mode=""m:kr-tabular""> <table border=""0"" summary=""Function synopsis"" cellspacing=""0"" cellpadding=""0"" style=""padding-bottom: 1em""> <xsl:sequence select=""f:html-attributes(.)""/> <tr> <td> <xsl:apply-templates select=""db:funcdef"" mode=""m:kr-tabular""/> </td> <xsl:apply-templates select=""(db:void|db:varargs|db:paramdef)[1]"" mode=""m:kr-tabular""/> </tr> <xsl:for-each select=""(db:void|db:varargs|db:paramdef)[position() &gt; 1]""> <tr> <td>&#160;</td> <xsl:apply-templates select=""."" mode=""m:kr-tabular""/> </tr> </xsl:for-each> </table> <xsl:if test=""db:paramdef""> <table border=""0"" summary=""Function argument synopsis"" cellspacing=""0"" cellpadding=""0""> <xsl:sequence select=""f:html-attributes(.)""/> <!-- <xsl:if test=""following-sibling::db:funcprototype""> <xsl:attribute name=""style"">padding-bottom: 1em</xsl:attribute> </xsl:if> --> <xsl:apply-templates select=""db:paramdef"" mode=""m:kr-tabular-funcsynopsis-mode""/> </table> </xsl:if> </xsl:template> <xsl:template match=""db:funcdef"" mode=""m:kr-tabular""> <code> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:kr-tabular""/> <xsl:text>(</xsl:text> </code> </xsl:template> <xsl:template match=""db:funcdef/db:function"" mode=""m:kr-tabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <b class=""fsfunc""><xsl:apply-templates mode=""m:kr-nontabular""/></b> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-tabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:void"" mode=""m:kr-tabular""> <td> <code>)</code> <xsl:text>;</xsl:text> </td> <td>&#160;</td> </xsl:template> <xsl:template match=""db:varargs"" mode=""m:kr-tabular""> <td> <xsl:text>...</xsl:text> <code>)</code> <xsl:text>;</xsl:text> </td> <td>&#160;</td> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:kr-tabular""> <td> <xsl:apply-templates select=""db:parameter"" mode=""m:kr-tabular""/> <xsl:choose> <xsl:when test=""following-sibling::*""> <xsl:text>, </xsl:text> </xsl:when> <xsl:otherwise> <code>)</code> <xsl:text>;</xsl:text> </xsl:otherwise> </xsl:choose> </td> <td>&#160;</td> </xsl:template> <xsl:template match=""db:paramdef/db:parameter"" mode=""m:kr-tabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <var class=""pdparam""> <xsl:apply-templates mode=""m:kr-tabular""/> </var> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-tabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:kr-tabular-funcsynopsis-mode""> <tr> <xsl:choose> <xsl:when test=""db:type and db:funcparams""> <td> <xsl:apply-templates select=""db:type"" mode=""m:kr-tabular-funcsynopsis-mode""/> <xsl:text>&#160;</xsl:text> </td> <td> <xsl:apply-templates select=""db:type/following-sibling::node()"" mode=""m:kr-tabular-funcsynopsis-mode""/> </td> </xsl:when> <xsl:when test=""db:funcparams""> <td colspan=""2""> <xsl:apply-templates mode=""m:kr-tabular-funcsynopsis-mode""/> </td> </xsl:when> <xsl:otherwise> <td> <xsl:apply-templates select=""db:parameter/preceding-sibling::node()[not(self::db:parameter)]"" mode=""m:kr-tabular-funcsynopsis-mode""/> <xsl:text>&#160;</xsl:text> </td> <td> <xsl:apply-templates select=""db:parameter"" mode=""m:kr-tabular""/> <xsl:apply-templates select=""db:parameter/following-sibling::node()[not(self::db:parameter)]"" mode=""m:kr-tabular-funcsynopsis-mode""/> <xsl:text>;</xsl:text> </td> </xsl:otherwise> </xsl:choose> </tr> </xsl:template> <xsl:template match=""db:paramdef/db:parameter"" mode=""m:kr-tabular-funcsynopsis-mode""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <var class=""pdparam""> <xsl:apply-templates mode=""m:kr-tabular-funcsynopsis-mode""/> </var> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-tabular-funcsynopsis-mode""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:funcparams"" mode=""m:kr-tabular-funcsynopsis-mode""> <code>(</code> <xsl:apply-templates mode=""m:kr-tabular-funcsynopsis-mode""/> <code>)</code> <xsl:text>;</xsl:text> </xsl:template> <!-- ============================================================ --> <!-- funcprototype: ansi, non-tabular --> <xsl:template match=""db:funcprototype"" mode=""m:ansi-nontabular""> <p> <xsl:apply-templates mode=""m:ansi-nontabular""/> </p> </xsl:template> <xsl:template match=""db:funcdef"" mode=""m:ansi-nontabular""> <code> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:ansi-nontabular""/> <xsl:text>(</xsl:text> </code> </xsl:template> <xsl:template match=""db:funcdef/db:function"" mode=""m:ansi-nontabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <b class=""fsfunc""><xsl:apply-templates mode=""m:ansi-nontabular""/></b> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:ansi-nontabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:void"" mode=""m:ansi-nontabular""> <code>void)</code> <xsl:text>;</xsl:text> </xsl:template> <xsl:template match=""db:varargs"" mode=""m:ansi-nontabular""> <xsl:text>...</xsl:text> <code>)</code> <xsl:text>;</xsl:text> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:ansi-nontabular""> <xsl:apply-templates mode=""m:ansi-nontabular""/> <xsl:choose> <xsl:when test=""following-sibling::*""> <xsl:text>, </xsl:text> </xsl:when> <xsl:otherwise> <code>)</code> <xsl:text>;</xsl:text> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:paramdef/db:parameter"" mode=""m:ansi-nontabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <var class=""pdparam""> <xsl:apply-templates mode=""m:ansi-nontabular""/> </var> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:ansi-nontabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:funcparams"" mode=""m:ansi-nontabular""> <code>(</code> <xsl:apply-templates mode=""m:ansi-nontabular""/> <code>)</code> </xsl:template> <!-- ============================================================ --> <!-- funcprototype: ansi, tabular --> <xsl:template match=""db:funcprototype"" mode=""m:ansi-tabular""> <table border=""0"" summary=""Function synopsis"" cellspacing=""0"" cellpadding=""0""> <xsl:sequence select=""f:html-attributes(.)""/> <!-- <xsl:if test=""following-sibling::db:funcprototype""> <xsl:attribute name=""style"">padding-bottom: 1em</xsl:attribute> </xsl:if> --> <tr> <td> <xsl:apply-templates select=""db:funcdef"" mode=""m:ansi-tabular""/> </td> <xsl:apply-templates select=""(db:void|db:varargs|db:paramdef)[1]"" mode=""m:ansi-tabular""/> </tr> <xsl:for-each select=""(db:void|db:varargs|db:paramdef)[position() &gt; 1]""> <tr> <td>&#160;</td> <xsl:apply-templates select=""."" mode=""m:ansi-tabular""/> </tr> </xsl:for-each> </table> </xsl:template> <xsl:template match=""db:funcdef"" mode=""m:ansi-tabular""> <code> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:ansi-tabular""/> <xsl:text>(</xsl:text> </code> </xsl:template> <xsl:template match=""db:funcdef/db:function"" mode=""m:ansi-tabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <b class=""fsfunc""><xsl:apply-templates mode=""m:ansi-nontabular""/></b> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:kr-tabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:void"" mode=""m:ansi-tabular""> <td> <code>void)</code> <xsl:text>;</xsl:text> </td> <td>&#160;</td> </xsl:template> <xsl:template match=""db:varargs"" mode=""m:ansi-tabular""> <td> <xsl:text>...</xsl:text> <code>)</code> <xsl:text>;</xsl:text> </td> <td>&#160;</td> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:ansi-tabular""> <xsl:choose> <xsl:when test=""db:type and db:funcparams""> <td> <xsl:apply-templates select=""db:type"" mode=""m:kr-tabular-funcsynopsis-mode""/> <xsl:text>&#160;</xsl:text> </td> <td> <xsl:apply-templates select=""db:type/following-sibling::node()"" mode=""m:kr-tabular-funcsynopsis-mode""/> </td> </xsl:when> <xsl:otherwise> <td> <xsl:apply-templates select=""db:parameter/preceding-sibling::node()[not(self::db:parameter)]"" mode=""m:ansi-tabular""/> <xsl:text>&#160;</xsl:text> </td> <td> <xsl:apply-templates select=""db:parameter"" mode=""m:ansi-tabular""/> <xsl:apply-templates select=""db:parameter/following-sibling::node()[not(self::db:parameter)]"" mode=""m:ansi-tabular""/> <xsl:choose> <xsl:when test=""following-sibling::*""> <xsl:text>, </xsl:text> </xsl:when> <xsl:otherwise> <code>)</code> <xsl:text>;</xsl:text> </xsl:otherwise> </xsl:choose> </td> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:paramdef/db:parameter"" mode=""m:ansi-tabular""> <xsl:choose> <xsl:when test=""$funcsynopsis.decoration != 0""> <var class=""pdparam""> <xsl:apply-templates mode=""m:ansi-tabular""/> </var> </xsl:when> <xsl:otherwise> <xsl:apply-templates mode=""m:ansi-tabular""/> </xsl:otherwise> </xsl:choose> </xsl:template> <xsl:template match=""db:funcparams"" mode=""m:ansi-tabular""> <code>(</code> <xsl:apply-templates/> <code>)</code> </xsl:template> <!-- ============================================================ --> <!-- XSLT2 templates and functions --> <doc:mode name=""m:funcprototype-xslt2-function"" xmlns=""http://docbook.org/ns/docbook""> <refpurpose>Mode for formatting XSLT 2.0 function prototypes</refpurpose> <refdescription> <para>This mode is used to format XSLT 2.0 function prototypes.</para> </refdescription> </doc:mode> <xsl:template match=""db:funcprototype"" mode=""m:funcprototype-xslt2-function""> <xsl:apply-templates select=""db:funcdef/db:function"" mode=""m:funcprototype-xslt2-function""/> <xsl:text>(</xsl:text> <xsl:apply-templates select=""db:paramdef"" mode=""m:funcprototype-xslt2-function""/> <xsl:text>)</xsl:text> <xsl:if test=""db:funcdef/db:type""> <xsl:text> as </xsl:text> <xsl:apply-templates select=""db:funcdef/db:type"" mode=""m:funcprototype-xslt2-function""/> </xsl:if> </xsl:template> <xsl:template match=""db:function"" mode=""m:funcprototype-xslt2-function""> <strong> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:funcprototype-xslt2-function""/> </strong> </xsl:template> <xsl:template match=""db:type"" mode=""m:funcprototype-xslt2-function""> <em> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:funcprototype-xslt2-function""/> </em> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:funcprototype-xslt2-function""> <xsl:apply-templates select=""db:parameter"" mode=""m:funcprototype-xslt2-function""/> <xsl:if test=""db:type""> <xsl:text> as </xsl:text> <xsl:apply-templates select=""db:type"" mode=""m:funcprototype-xslt2-function""/> </xsl:if> <xsl:if test=""following-sibling::db:paramdef"">, </xsl:if> </xsl:template> <xsl:template match=""db:parameter"" mode=""m:funcprototype-xslt2-function""> <span> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:apply-templates mode=""m:funcprototype-xslt2-function""/> </span> </xsl:template> <!-- ============================================================ --> <doc:mode name=""m:funcprototype-xslt2-template"" xmlns=""http://docbook.org/ns/docbook""> <refpurpose>Mode for formatting XSLT 2.0 named templates</refpurpose> <refdescription> <para>This mode is used to format XSLT 2.0 named templates.</para> </refdescription> </doc:mode> <xsl:template match=""db:funcprototype"" mode=""m:funcprototype-xslt2-template""> <pre> <xsl:sequence select=""f:html-attributes(.)""/> <xsl:text>&lt;xsl:call-template name=""</xsl:text> <xsl:value-of select=""db:funcdef/db:function""/> <xsl:text>""</xsl:text> <xsl:if test=""db:funcdef/db:type""> <xsl:text> as=""</xsl:text> <xsl:value-of select=""db:funcdef/db:type""/> <xsl:text>""</xsl:text> </xsl:if> <xsl:text>&gt;&#10;</xsl:text> <xsl:apply-templates select=""db:paramdef"" mode=""m:funcprototype-xslt2-template""/> <xsl:text>&lt;/xsl:call-template&gt;</xsl:text> </pre> </xsl:template> <xsl:template match=""db:paramdef"" mode=""m:funcprototype-xslt2-template""> <xsl:variable name=""with-param""> <xsl:text>&lt;xsl:with-param name=""</xsl:text> <xsl:value-of select=""db:parameter""/> <xsl:text>""</xsl:text> <xsl:if test=""db:initializer[@role='select']""> <xsl:text> select=""</xsl:text> <xsl:value-of select=""db:initializer""/> <xsl:text>""</xsl:text> </xsl:if> <xsl:if test=""db:type""> <xsl:text> as=""</xsl:text> <xsl:value-of select=""db:type""/> <xsl:text>""</xsl:text> </xsl:if> <xsl:choose> <xsl:when test=""db:initializer[@role='content']""> <xsl:text>&gt;</xsl:text> <xsl:copy-of select=""db:initializer[@role='content']/node()""/> <xsl:text>&lt;/xsl:with-param&gt;</xsl:text> </xsl:when> <xsl:otherwise> <xsl:text>/&gt;</xsl:text> </xsl:otherwise> </xsl:choose> </xsl:variable> <xsl:text> </xsl:text> <xsl:choose> <xsl:when test=""@role = 'recursive'""> <i> <xsl:copy-of select=""$with-param""/> </i> </xsl:when> <xsl:otherwise> <xsl:copy-of select=""$with-param""/> </xsl:otherwise> </xsl:choose> <xsl:text>&#10;</xsl:text> </xsl:template> </xsl:stylesheet> ",,199939,1
openstack%2Fpython-neutronclient~master~If20a2dcbacd5230b9f569478ab97c9114c15301b,openstack/python-neutronclient,master,If20a2dcbacd5230b9f569478ab97c9114c15301b,Fix typo in the help of net-list,MERGED,2016-02-18 22:41:32.000000000,2016-02-19 04:49:14.000000000,2016-02-19 04:49:14.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 7448}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-18 22:41:32.000000000', 'files': ['neutronclient/neutron/v2_0/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9c3ad54ba45569f201bef793bba9f7cf805c1124', 'message': 'Fix typo in the help of net-list\n\nTrivialFix\n\nChange-Id: If20a2dcbacd5230b9f569478ab97c9114c15301b\n'}]",0,282085,9c3ad54ba45569f201bef793bba9f7cf805c1124,10,4,1,841,,,0,"Fix typo in the help of net-list

TrivialFix

Change-Id: If20a2dcbacd5230b9f569478ab97c9114c15301b
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/85/282085/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/__init__.py'],1,9c3ad54ba45569f201bef793bba9f7cf805c1124,fix-typo-in-help, 'help': _('Filter and list the %s whose administrative ', 'help': _('Filter and list the %s whose adminstrative ',1,1
openstack%2Fheat~master~I255ffe215876df5c2410962a3e38016f8e7f690e,openstack/heat,master,I255ffe215876df5c2410962a3e38016f8e7f690e,Add OS::Senlin::Receiver Resource,MERGED,2016-02-15 09:26:24.000000000,2016-02-19 04:38:45.000000000,2016-02-19 04:20:32.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 10487}, {'_account_id': 14033}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-15 09:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/85dd40c6a70915e3c88c84471342599b45d0efa1', 'message': 'Add OS::Senlin::Receiver Resource\n\nAdd OS::Senlin::Receiver resource to heat, following is an example:\n   recv:\n     type: OS::Senlin::Receiver\n     properties:\n       cluster: c1\n       action: CLUSTER_SCALE_OUT\n       type: webhook\n\nChange-Id: I255ffe215876df5c2410962a3e38016f8e7f690e\nblueprint: senlin-resources\n'}, {'number': 2, 'created': '2016-02-16 11:07:56.000000000', 'files': ['heat/engine/resources/openstack/senlin/receiver.py', 'heat/tests/openstack/senlin/test_receiver.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bb02466fe8250290a4ccbbb4941ed32b5a9cffce', 'message': 'Add OS::Senlin::Receiver Resource\n\nAdd OS::Senlin::Receiver resource to heat, following is an example:\n   recv:\n     type: OS::Senlin::Receiver\n     properties:\n       cluster: c1\n       action: CLUSTER_SCALE_OUT\n       type: webhook\n\nChange-Id: I255ffe215876df5c2410962a3e38016f8e7f690e\nblueprint: senlin-resources\n'}]",9,280118,bb02466fe8250290a4ccbbb4941ed32b5a9cffce,28,7,2,7404,,,0,"Add OS::Senlin::Receiver Resource

Add OS::Senlin::Receiver resource to heat, following is an example:
   recv:
     type: OS::Senlin::Receiver
     properties:
       cluster: c1
       action: CLUSTER_SCALE_OUT
       type: webhook

Change-Id: I255ffe215876df5c2410962a3e38016f8e7f690e
blueprint: senlin-resources
",git fetch https://review.opendev.org/openstack/heat refs/changes/18/280118/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/senlin/receiver.py', 'heat/tests/openstack/senlin/test_receiver.py']",2,85dd40c6a70915e3c88c84471342599b45d0efa1,bp/senlin-resources,"# # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import mock from senlinclient.common import exc from heat.common import template_format from heat.engine.clients.os import senlin from heat.engine.resources.openstack.senlin import receiver as sr from heat.engine import scheduler from heat.tests import common from heat.tests import utils receiver_stack_template = """""" heat_template_version: 2016-04-08 description: Senlin Receiver Template resources: senlin-receiver: type: OS::Senlin::Receiver properties: name: SenlinReceiver cluster: fake_cluster action: CLUSTER_SCALE_OUT type: webhook params: foo: bar """""" class FakeReceiver(object): def __init__(self, id='some_id'): self.id = id self.name = ""SenlinReceiver"" self.cluster_id = ""fake_cluster"" self.action = ""CLUSTER_SCALE_OUT"" self.channel = {'alarm_url': ""http://foo.bar/webhooks/fake_url""} def to_dict(self): return { 'id': self.id, 'name': self.name, 'cluster_id': self.cluster_id, 'action': self.action, 'channel': self.channel, 'actor': {'trust_id': ['fake_trust_id']} } class SenlinReceiverTest(common.HeatTestCase): def setUp(self): super(SenlinReceiverTest, self).setUp() self.senlin_mock = mock.MagicMock() self.patchobject(sr.Receiver, 'client', return_value=self.senlin_mock) self.patchobject(senlin.ClusterConstraint, 'validate', return_value=True) self.fake_r = FakeReceiver() self.t = template_format.parse(receiver_stack_template) def _init_recv(self, template): self.stack = utils.parse_stack(template) recv = self.stack['senlin-receiver'] return recv def _create_recv(self, template): recv = self._init_recv(template) self.senlin_mock.create_receiver.return_value = self.fake_r self.senlin_mock.get_receiver.return_value = self.fake_r scheduler.TaskRunner(recv.create)() self.assertEqual((recv.CREATE, recv.COMPLETE), recv.state) self.assertEqual(self.fake_r.id, recv.resource_id) return recv def test_recv_create_success(self): self._create_recv(self.t) expect_kwargs = { 'name': 'SenlinReceiver', 'cluster_id': 'fake_cluster', 'action': 'CLUSTER_SCALE_OUT', 'type': 'webhook', 'params': {'foo': 'bar'}, } self.senlin_mock.create_receiver.assert_called_once_with( **expect_kwargs) def test_recv_delete_success(self): self.senlin_mock.delete_receiver.return_value = None recv = self._create_recv(self.t) scheduler.TaskRunner(recv.delete)() self.senlin_mock.delete_receiver.assert_called_once_with( recv.resource_id) def test_recv_delete_not_found(self): self.senlin_mock.delete_receiver.side_effect = [ exc.sdkexc.ResourceNotFound(http_status=404) ] recv = self._create_recv(self.t) scheduler.TaskRunner(recv.delete)() self.senlin_mock.delete_receiver.assert_called_once_with( recv.resource_id) def test_resource_mapping(self): mapping = sr.resource_mapping() self.assertEqual(1, len(mapping)) self.assertEqual(sr.Receiver, mapping['OS::Senlin::Receiver']) def test_cluster_resolve_attribute(self): excepted_show = { 'id': 'some_id', 'name': 'SenlinReceiver', 'cluster_id': 'fake_cluster', 'action': 'CLUSTER_SCALE_OUT', 'channel': {'alarm_url': ""http://foo.bar/webhooks/fake_url""}, 'actor': {'trust_id': ['fake_trust_id']} } recv = self._create_recv(self.t) self.assertEqual(self.fake_r.channel, recv._resolve_attribute('channel')) self.assertEqual(excepted_show, recv._show_resource()) ",,271,0
openstack%2Fneutron~master~I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec,openstack/neutron,master,I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec,Update devstack hooks to work with pecan jobs,MERGED,2016-02-18 04:00:03.000000000,2016-02-19 04:27:53.000000000,2016-02-19 04:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-18 04:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03040b5a9c11b3c119053fc5499cd6fc2c4ce778', 'message': 'Update post_test_hook to work with api-pecan job\n\nUpdate the conditional to check for the API job to also look\nfor the api-pecan job.\n\nChange-Id: I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec\n'}, {'number': 2, 'created': '2016-02-18 06:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65b898aa3c7526c0dec112272d84cabb8ca1537a', 'message': 'Update post_test_hook to work with api-pecan job\n\nUpdate the conditional to check for the API job to also look\nfor the api-pecan job.\n\nChange-Id: I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec\n'}, {'number': 3, 'created': '2016-02-18 06:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5333645d53741e2e15b4ffe721c65e468f710fae', 'message': 'Update post_test_hook to work with api-pecan job\n\nUpdate the conditional to check for the API job to also look\nfor the api-pecan job.\n\nChange-Id: I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec\n'}, {'number': 4, 'created': '2016-02-18 12:09:24.000000000', 'files': ['neutron/tests/contrib/gate_hook.sh', 'neutron/tests/contrib/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4931045b5acf00200b3684fbf61db7a4b7c8233', 'message': 'Update devstack hooks to work with pecan jobs\n\nUpdate the post_test_hook conditional to check for the API job\nto also look for the api-pecan job and correct the section\nname in the gate hook for the neutron.conf web framework setting.\n\nChange-Id: I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec\n'}]",2,281623,d4931045b5acf00200b3684fbf61db7a4b7c8233,81,16,4,7787,,,0,"Update devstack hooks to work with pecan jobs

Update the post_test_hook conditional to check for the API job
to also look for the api-pecan job and correct the section
name in the gate hook for the neutron.conf web framework setting.

Change-Id: I8816bb6efa45b9e1bd8bb1a826f82ff45d960cec
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/281623/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/contrib/post_test_hook.sh'],1,03040b5a9c11b3c119053fc5499cd6fc2c4ce778,,"elif [ ""$venv"" == ""api"" ] || [ ""$venv"" == ""api-pecan"" ]","elif [ ""$venv"" == ""api"" ]",1,1
openstack%2Fapi-site~master~Ie934e3f5068b4508e786d2a93db7ba332d659034,openstack/api-site,master,Ie934e3f5068b4508e786d2a93db7ba332d659034,"Glance: ""List images"" response parameters table contains redundant values",MERGED,2016-02-03 07:00:52.000000000,2016-02-19 04:25:29.000000000,2016-02-19 04:25:29.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-03 07:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/b7d50a94a37022e34ab42215bc75aeffc7a0ac06', 'message': 'Glance: ""List images"" response parameters table contains redundant values\n\nThis patch removes redundant ""ramdisk_id"" and ""kernel_id"" in response\nparameters table.\n\nChange-Id: Ie934e3f5068b4508e786d2a93db7ba332d659034\nCloses-Bug: #1541223\n'}, {'number': 2, 'created': '2016-02-03 07:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/1bab8ba814e91fec8b5a4b6a3d3de6178884f9fa', 'message': 'Glance: ""List images"" response parameters table contains redundant values\n\nThis patch removes redundant ""ramdisk_id"" and ""kernel_id"" in response\nparameters table.\n\nChange-Id: Ie934e3f5068b4508e786d2a93db7ba332d659034\nCloses-Bug: #1541223\n'}, {'number': 3, 'created': '2016-02-03 07:49:47.000000000', 'files': ['api-ref/src/wadls/image-api/src/v2/wadl/images-v2.wadl', 'api-ref/src/wadls/image-api/src/v2/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/b002e94c97b7300fa2fe656a0cc3a3d4ac3c2844', 'message': 'Glance: ""List images"" response parameters table contains redundant values\n\nThis patch removes redundant ""ramdisk_id"" and ""kernel_id"" in response\nparameters table.\n\nChange-Id: Ie934e3f5068b4508e786d2a93db7ba332d659034\nCloses-Bug: #1541223\n'}]",0,275528,b002e94c97b7300fa2fe656a0cc3a3d4ac3c2844,12,3,3,19853,,,0,"Glance: ""List images"" response parameters table contains redundant values

This patch removes redundant ""ramdisk_id"" and ""kernel_id"" in response
parameters table.

Change-Id: Ie934e3f5068b4508e786d2a93db7ba332d659034
Closes-Bug: #1541223
",git fetch https://review.opendev.org/openstack/api-site refs/changes/28/275528/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/image-api/src/v2/wadl/images-v2.wadl', 'api-ref/src/wadls/image-api/src/v2/common.ent']",2,b7d50a94a37022e34ab42215bc75aeffc7a0ac06,bug03022016,,"<!ENTITY ramdisk_idResponseParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""ramdisk_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the ramdisk. </para> </wadl:doc> </param>'> <!ENTITY kernel_idResponseParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""kernel_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the kernel. </para> </wadl:doc> </param>'>",0,41
openstack%2Fglance~master~Ia81e109c3919ad8ee8336f9051fa7920780f5bbd,openstack/glance,master,Ia81e109c3919ad8ee8336f9051fa7920780f5bbd,Stop gridfs driver support,MERGED,2016-01-19 06:57:04.000000000,2016-02-19 04:25:04.000000000,2016-02-19 04:25:04.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 14676}, {'_account_id': 15054}]","[{'number': 1, 'created': '2016-01-19 06:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f19c3cc0c36a130709c47f925f2c7eef826db063', 'message': 'Stop gridfs driver support\n\nGridfs was marked as deprecated some releases go and now it has\nbeen removed from Glance_store. So Glance should not support this\ndriver anymore.\n\nChange-Id: Ia81e109c3919ad8ee8336f9051fa7920780f5bbd\n'}, {'number': 2, 'created': '2016-02-18 08:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f0cd2968b039b91ca7bb1e17d1b0ac35a5bb6304', 'message': 'Stop gridfs driver support\n\nGridfs was marked as deprecated some releases go and now it has\nbeen removed from Glance_store. So Glance should not support this\ndriver anymore.\n\nChange-Id: Ia81e109c3919ad8ee8336f9051fa7920780f5bbd\n'}, {'number': 3, 'created': '2016-02-18 11:17:48.000000000', 'files': ['doc/source/configuring.rst', 'doc/source/glanceapi.rst', 'glance/common/location_strategy/store_type.py', 'glance/tests/unit/common/scripts/test_scripts_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/0d89611c1e80fad1757bd92db377c39841610b4a', 'message': 'Stop gridfs driver support\n\nGridfs was marked as deprecated some releases go and now it has\nbeen removed from Glance_store. So Glance should not support this\ndriver anymore.\n\nChange-Id: Ia81e109c3919ad8ee8336f9051fa7920780f5bbd\n'}]",1,269453,0d89611c1e80fad1757bd92db377c39841610b4a,18,4,3,15054,,,0,"Stop gridfs driver support

Gridfs was marked as deprecated some releases go and now it has
been removed from Glance_store. So Glance should not support this
driver anymore.

Change-Id: Ia81e109c3919ad8ee8336f9051fa7920780f5bbd
",git fetch https://review.opendev.org/openstack/glance refs/changes/53/269453/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/glance-api.conf', 'doc/source/configuring.rst', 'doc/source/glanceapi.rst', 'glance/common/location_strategy/store_type.py', 'etc/glance-registry.conf', 'glance/tests/unit/common/scripts/test_scripts_utils.py']",6,f19c3cc0c36a130709c47f925f2c7eef826db063,remove_gridfs_support,," location = 'gridfs://' self.assertRaises(urllib.error.URLError, script_utils.validate_location_uri, location) ",2,25
openstack%2Ftempest~master~I7efa46b0c3b2c0ea722b2793cca6b57434923904,openstack/tempest,master,I7efa46b0c3b2c0ea722b2793cca6b57434923904,Enable logging if log_config_append is None,MERGED,2016-02-17 16:02:32.000000000,2016-02-19 04:23:39.000000000,2016-02-19 04:23:38.000000000,"[{'_account_id': 3}, {'_account_id': 7872}, {'_account_id': 8556}]","[{'number': 1, 'created': '2016-02-17 16:02:32.000000000', 'files': ['tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6f7c7d8d15997df029a37c285a4dc410918032b', 'message': 'Enable logging if log_config_append is None\n\nWhen default /etc/tempest/logging.conf is configured, tempest should\nlog. This patch appends the content from logging.conf to\nlog_config_append, if this config attribute is set, but has None set.\n\nChange-Id: I7efa46b0c3b2c0ea722b2793cca6b57434923904\nCloses-Bug: #1546536\n'}]",0,281356,e6f7c7d8d15997df029a37c285a4dc410918032b,13,3,1,15371,,,0,"Enable logging if log_config_append is None

When default /etc/tempest/logging.conf is configured, tempest should
log. This patch appends the content from logging.conf to
log_config_append, if this config attribute is set, but has None set.

Change-Id: I7efa46b0c3b2c0ea722b2793cca6b57434923904
Closes-Bug: #1546536
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/281356/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,e6f7c7d8d15997df029a37c285a4dc410918032b,bug/1546536," if ((not hasattr(_CONF, 'log_config_append') or _CONF.log_config_append is None) and"," if (not hasattr(_CONF, 'log_config_append') and",2,1
openstack%2Fneutron~master~I69680952f99c404d4535db48db73fc815977f2ee,openstack/neutron,master,I69680952f99c404d4535db48db73fc815977f2ee,Pecan: implement DHCP notifications in NotifierHook,MERGED,2016-02-10 00:46:25.000000000,2016-02-19 04:22:56.000000000,2016-02-19 04:22:56.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 16707}]","[{'number': 1, 'created': '2016-02-10 00:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba1a19a48c34a28611fbc02153a4ed744adde503', 'message': 'Pecan: implement DHCP notifications in NotifierHook\n\nThis patch adds support for DHCP notifications into the Notifier hook,\nwhich so far has been pretty much a placeholder for future work.\n\nTo this aim its priority has been changed in order to ensure the\n\'after\' hook is executed after the \'after\' hook for the policy engine.\nThis will ensure that any \'alien\' data returned from the plugin is\nstripped off before being sent to the notifiers, as well as any\nattribute that the user is not authorized to access.\n\nSince delete operations require to send the original object to the\nnotifier, this patch leverages the ""prefetch"" feature of the policy\nhook to avoid loading again the object from the plugin. This is not\nideal and will be fixed in another patch where prefetching will be\nperformed in its own hook.\n\nThe ACTION_MAP constant has been factored out in an appropriate\nmodule for constants as it is now used by the NotifierHook class as\nwell. The decision of using a new constant module is rather\narbitrary as the module neutron.common.constants could have been\nused as well.\n\nWith this patch, the notifier hook only sends events signalling\ncompletion of operations (e.g.: network.create.end) as these are\nthe only events processed by the DHCP agent. Support for \'start\'\nevents will be added in a subsequent patch.\n\nRelated-Blueprint: pecan-wsgi-switch\n\nChange-Id: I69680952f99c404d4535db48db73fc815977f2ee\n'}, {'number': 2, 'created': '2016-02-15 10:50:29.000000000', 'files': ['neutron/pecan_wsgi/app.py', 'neutron/tests/functional/pecan_wsgi/test_hooks.py', 'neutron/pecan_wsgi/hooks/policy_enforcement.py', 'neutron/pecan_wsgi/hooks/notifier.py', 'neutron/pecan_wsgi/constants.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea4ba642dd8946a96a177780b50bdd0594912813', 'message': 'Pecan: implement DHCP notifications in NotifierHook\n\nThis patch adds support for DHCP notifications into the Notifier hook,\nwhich so far has been pretty much a placeholder for future work.\n\nTo this aim its priority has been changed in order to ensure the\n\'after\' hook is executed after the \'after\' hook for the policy engine.\nThis will ensure that any \'alien\' data returned from the plugin is\nstripped off before being sent to the notifiers, as well as any\nattribute that the user is not authorized to access.\n\nSince delete operations require to send the original object to the\nnotifier, this patch leverages the ""prefetch"" feature of the policy\nhook to avoid loading again the object from the plugin. This is not\nideal and will be fixed in another patch where prefetching will be\nperformed in its own hook.\n\nThe ACTION_MAP constant has been factored out in an appropriate\nmodule for constants as it is now used by the NotifierHook class as\nwell. The decision of using a new constant module is rather\narbitrary as the module neutron.common.constants could have been\nused as well.\n\nWith this patch, the notifier hook only sends events signalling\ncompletion of operations (e.g.: network.create.end) as these are\nthe only events processed by the DHCP agent. Support for \'start\'\nevents will be added in a subsequent patch.\n\nRelated-Blueprint: pecan-wsgi-switch\n\nChange-Id: I69680952f99c404d4535db48db73fc815977f2ee\n'}]",23,278168,ea4ba642dd8946a96a177780b50bdd0594912813,39,12,2,261,,,0,"Pecan: implement DHCP notifications in NotifierHook

This patch adds support for DHCP notifications into the Notifier hook,
which so far has been pretty much a placeholder for future work.

To this aim its priority has been changed in order to ensure the
'after' hook is executed after the 'after' hook for the policy engine.
This will ensure that any 'alien' data returned from the plugin is
stripped off before being sent to the notifiers, as well as any
attribute that the user is not authorized to access.

Since delete operations require to send the original object to the
notifier, this patch leverages the ""prefetch"" feature of the policy
hook to avoid loading again the object from the plugin. This is not
ideal and will be fixed in another patch where prefetching will be
performed in its own hook.

The ACTION_MAP constant has been factored out in an appropriate
module for constants as it is now used by the NotifierHook class as
well. The decision of using a new constant module is rather
arbitrary as the module neutron.common.constants could have been
used as well.

With this patch, the notifier hook only sends events signalling
completion of operations (e.g.: network.create.end) as these are
the only events processed by the DHCP agent. Support for 'start'
events will be added in a subsequent patch.

Related-Blueprint: pecan-wsgi-switch

Change-Id: I69680952f99c404d4535db48db73fc815977f2ee
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/278168/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/pecan_wsgi/app.py', 'neutron/tests/functional/pecan_wsgi/test_hooks.py', 'neutron/pecan_wsgi/hooks/policy_enforcement.py', 'neutron/pecan_wsgi/hooks/notifier.py', 'neutron/pecan_wsgi/constants.py']",5,ba1a19a48c34a28611fbc02153a4ed744adde503,pecan,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ACTION_MAP = {'POST': 'create', 'PUT': 'update', 'GET': 'get', 'DELETE': 'delete'} ",,168,15
openstack%2Fapi-site~master~I2939960346a8eb676f05ddc40e4123b2b099f3c3,openstack/api-site,master,I2939960346a8eb676f05ddc40e4123b2b099f3c3,Update and add the references in share-api,MERGED,2016-02-13 07:31:45.000000000,2016-02-19 04:22:39.000000000,2016-02-19 04:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-13 07:31:45.000000000', 'files': ['api-ref/src/wadls/share-api/src/v2/wadl/os-share-v2.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/e8f84c56e51dc3dffcb8e6ce4c3d373a46e3cb5a', 'message': ""Update and add the references in share-api\n\nUpdate the href link with correct parameter 'listVersions' and add\na method tag that will refer to 'showShareServerDetails'.\n\nChange-Id: I2939960346a8eb676f05ddc40e4123b2b099f3c3\nCloses-Bug: #1545076\n""}]",0,279869,e8f84c56e51dc3dffcb8e6ce4c3d373a46e3cb5a,7,3,1,19840,,,0,"Update and add the references in share-api

Update the href link with correct parameter 'listVersions' and add
a method tag that will refer to 'showShareServerDetails'.

Change-Id: I2939960346a8eb676f05ddc40e4123b2b099f3c3
Closes-Bug: #1545076
",git fetch https://review.opendev.org/openstack/api-site refs/changes/69/279869/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/share-api/src/v2/wadl/os-share-v2.wadl'],1,e8f84c56e51dc3dffcb8e6ce4c3d373a46e3cb5a,bug/1545076," <method href=""#listVersions""/> <resource path=""detail"" id=""share_server_detail""> <method href=""#showShareServerDetails"" /> </resource>"," <method href=""#listVersions-share-v2""/>",4,1
openstack%2Fpuppet-sahara~master~Iba618f27b110192c1751486681d77c1c9d46c541,openstack/puppet-sahara,master,Iba618f27b110192c1751486681d77c1c9d46c541,Add the capability to configure api-paste.ini with config.pp,MERGED,2016-02-18 10:47:13.000000000,2016-02-19 04:22:18.000000000,2016-02-19 04:22:18.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-18 10:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/302ab5edf9424bc9760bf872fbafc6ef2140625e', 'message': ""Add the capability to configure api-paste.ini with config.pp\n\nAlready added type/provider for paste configs,but it wouldn't to patch ironic::config.\n\nChange-Id: Iba618f27b110192c1751486681d77c1c9d46c541\n""}, {'number': 2, 'created': '2016-02-18 11:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/e0f662bc552620cf6fb5a20dd01a004b548bb8bc', 'message': ""Add the capability to configure api-paste.ini with config.pp\n\nAlready added type/provider for paste configs,but it wouldn't to patch sahara::config.\n\nChange-Id: Iba618f27b110192c1751486681d77c1c9d46c541\n""}, {'number': 3, 'created': '2016-02-18 11:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/e17c01c5c934f2f06867eccf8e79f8ff5b312dc1', 'message': ""Add the capability to configure api-paste.ini with config.pp\n\nAlready added type/provider for paste configs,but it wouldn't to patch\nsahara::config.\n\nChange-Id: Iba618f27b110192c1751486681d77c1c9d46c541\n""}, {'number': 4, 'created': '2016-02-18 11:38:24.000000000', 'files': ['spec/classes/sahara_config_spec.rb', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/00dac9470aea0cd03d0b2de4889be0b239fb2229', 'message': ""Add the capability to configure api-paste.ini with config.pp\n\nAlready added type/provider for paste configs,\nbut it wouldn't to patch sahara::config.\n\nChange-Id: Iba618f27b110192c1751486681d77c1c9d46c541\n""}]",1,281756,00dac9470aea0cd03d0b2de4889be0b239fb2229,16,3,4,9414,,,0,"Add the capability to configure api-paste.ini with config.pp

Already added type/provider for paste configs,
but it wouldn't to patch sahara::config.

Change-Id: Iba618f27b110192c1751486681d77c1c9d46c541
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/56/281756/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/sahara_config_spec.rb', 'manifests/config.pp']",2,302ab5edf9424bc9760bf872fbafc6ef2140625e,add_api_paste_config,"# [*sahara_api_paste_ini*] # (optional) Allow configuration of /etc/sahara/api-paste.ini options. # $sahara_api_paste_ini = {}, validate_hash($sahara_api_paste_ini) create_resources('sahara_api_paste_ini', $sahara_api_paste_ini)",,17,0
openstack%2Fpython-tackerclient~master~Ideb8a9830fa183a648dd1407b55dd06cd1f436dd,openstack/python-tackerclient,master,Ideb8a9830fa183a648dd1407b55dd06cd1f436dd,"Deprecating ""device"" API and CLI in stable/liberty branch",ABANDONED,2016-02-14 14:54:56.000000000,2016-02-19 04:19:44.000000000,,"[{'_account_id': 3}, {'_account_id': 15755}, {'_account_id': 18955}]","[{'number': 1, 'created': '2016-02-14 14:54:56.000000000', 'files': ['tackerclient/tacker/v1_0/vm/device.py', 'tackerclient/tacker/v1_0/vm/device_template.py', 'tackerclient/v1_0/client.py', 'tackerclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/475df1a7d770366c11ac7d5873f6c800d4469a5d', 'message': 'Deprecating ""device"" API and CLI in stable/liberty branch\n\nChange-Id: Ideb8a9830fa183a648dd1407b55dd06cd1f436dd\nRelated-Bug: #1543393\n'}]",0,279990,475df1a7d770366c11ac7d5873f6c800d4469a5d,5,3,1,18955,,,0,"Deprecating ""device"" API and CLI in stable/liberty branch

Change-Id: Ideb8a9830fa183a648dd1407b55dd06cd1f436dd
Related-Bug: #1543393
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/90/279990/1 && git format-patch -1 --stdout FETCH_HEAD,"['tackerclient/tacker/v1_0/vm/device.py', 'tackerclient/tacker/v1_0/vm/device_template.py', 'tackerclient/v1_0/client.py', 'tackerclient/common/utils.py']",4,475df1a7d770366c11ac7d5873f6c800d4469a5d,bug/1543393,"import warnings from functools import wraps def deprecated(name): """"""This decorator can be used to mark a call as deprecated."""""" def deprecate_it(func): def dep_func(*args, **kwargs): warnings.simplefilter('always', DeprecationWarning) warnings.warn(""Call to %s deprecated, avoid its usage."" % name, category=DeprecationWarning) return func(*args, **kwargs) return wraps(func)(dep_func) return deprecate_it",,36,0
openstack%2Fpython-searchlightclient~master~I9cd0c88ca5b07fa19f0dd25708ea179470ee5713,openstack/python-searchlightclient,master,I9cd0c88ca5b07fa19f0dd25708ea179470ee5713,Updated from global requirements,MERGED,2016-02-17 02:08:55.000000000,2016-02-19 04:12:16.000000000,2016-02-19 04:12:16.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 7665}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-17 02:08:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-searchlightclient/commit/4ff10eef6c4be4f1cc0c1acb902ddf60d22489da', 'message': 'Updated from global requirements\n\nChange-Id: I9cd0c88ca5b07fa19f0dd25708ea179470ee5713\n'}]",0,281008,4ff10eef6c4be4f1cc0c1acb902ddf60d22489da,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I9cd0c88ca5b07fa19f0dd25708ea179470ee5713
",git fetch https://review.opendev.org/openstack/python-searchlightclient refs/changes/08/281008/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4ff10eef6c4be4f1cc0c1acb902ddf60d22489da,openstack/requirements,python-openstackclient>=2.1.0 # Apache-2.0,python-openstackclient>=2.0.0 # Apache-2.0,1,1
openstack%2Fneutron~master~I68edaa6b21a4493104825360055e698c53fe50c0,openstack/neutron,master,I68edaa6b21a4493104825360055e698c53fe50c0,[WIP] Add documentation of pure python network configuration,ABANDONED,2015-12-01 13:13:16.000000000,2016-02-19 04:08:07.000000000,,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7805}, {'_account_id': 9681}, {'_account_id': 10153}, {'_account_id': 14571}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-12-01 13:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ac88bb6a7093a9b02a93d4ec3f06e3f42e4008fb', 'message': '[WIP] Add documentation of pure python network configuration\n\nThis document records the basic idea and performance results\nof pyroute2 library to configure Linux networking.\n\nChange-Id: I68edaa6b21a4493104825360055e698c53fe50c0\nRelated-Bug: #1492714\n'}, {'number': 2, 'created': '2015-12-01 14:12:19.000000000', 'files': ['doc/source/devref/pyroute2.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1f137fe447b9156c1d14dacbaae230790969418', 'message': '[WIP] Add documentation of pure python network configuration\n\nThis document records the basic idea and performance results\nof pyroute2 library to configure Linux networking.\n\nChange-Id: I68edaa6b21a4493104825360055e698c53fe50c0\nRelated-Bug: #1492714\n'}]",0,251859,d1f137fe447b9156c1d14dacbaae230790969418,18,8,2,7805,,,0,"[WIP] Add documentation of pure python network configuration

This document records the basic idea and performance results
of pyroute2 library to configure Linux networking.

Change-Id: I68edaa6b21a4493104825360055e698c53fe50c0
Related-Bug: #1492714
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/251859/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/pyroute2.rst'],1,ac88bb6a7093a9b02a93d4ec3f06e3f42e4008fb,bug/1492714,"========================= IP Library using pyroute2 ========================= Neutron uses shell invocations to configure Linux networking. The pipeline is as follows: #. Generate external commands and the corresponding arguments #. Create subprocess to run external commands, like ip, brctl, iptables, etc. #. Collect the results #. Parse the result strings #. Generate the corresponding objects to save the parsed strings Here we introduce `pyroute2 <http://docs.pyroute2.org/general.html>`_ pure-python library to configure Linux networking. Compared with shell invocations, there are some perspectives: * No need to parse text output, which format can be changed. * No need to create new process for a simple operation. * Less netlink overhead: every 'ip addr add' call actually leads to several netlink requests (load interfaces info, load addr info, apply addr info), while 'pyroute2.addr()' is always one request - the state is kept by the program, no info loads for every address addition, e.g. Performance Evaluation ---------------------- Test cases are run in the same virtual instance with 2 vCPU and 8GB memory running Ubuntu 14.04 64bit. The performance is measured by cProfile module. +-----------------+-----------+----------+-----------+----------+ | - | device-existed | device-existed-in-ns | +=================+===========+==========+===========+==========+ | - | neutron | pyroute2 | neutron | pyroute2 | +-----------------+-----------+----------+-----------+----------+ | function calls | 1058264 | 257144 | 1044153 | 63459 | +-----------------+----------------------+----------------------+ | primitive calls | 1040553 | 245967 | 1026446 | 61020 | +-----------------+----------------------+----------------------+ | time(1000 calls)| 17.417 | 0.286 | 19.456 | 0.121 | +-----------------+----------------------+----------------------+ +-----------------+-----------+----------+-----------+----------+ | - | get-device-ip | get-device-ip-in-ns | +=================+===========+==========+===========+==========+ | - | neutron | pyroute2 | neutron | pyroute2 | +-----------------+-----------+----------+-----------+----------+ | function calls | 1134264 | 234131 | 1119839 | 56825 | +-----------------+----------------------+----------------------+ | primitive calls | 1114553 | 222954 | 1102108 | 54384 | +-----------------+----------------------+----------------------+ | time(1000 calls)| 19.521 | 0.268 | 15.535 | 0.124 | +-----------------+----------------------+----------------------+ +-----------------+-----------+----------+-----------+----------+ | - | get-dev-list | get-dev-list-in-ns | +=================+===========+==========+===========+==========+ | - | neutron | pyroute2 | neutron | pyroute2 | +-----------------+-----------+----------+-----------+----------+ | function calls | 647183 | 256748 | 1039672 | 63459 | +-----------------+----------------------+----------------------+ | primitive calls | 639475 | 245573 | 1023951 | 61020 | +-----------------+----------------------+----------------------+ | time(1000 calls)| 1.078 | 0.266 | 14.555 | 0.116 | +-----------------+----------------------+----------------------+ Switch to pyroute2 ------------------ The development work is dependent on oslo.privsep project. ",,66,0
openstack%2Fkuryr~master~Ie1bc3790ccdba69d3eca7aca732e845f2ee6eb10,openstack/kuryr,master,Ie1bc3790ccdba69d3eca7aca732e845f2ee6eb10,Updated from global requirements,MERGED,2016-02-17 18:35:52.000000000,2016-02-19 03:47:25.000000000,2016-02-19 03:47:25.000000000,"[{'_account_id': 3}, {'_account_id': 12069}, {'_account_id': 16272}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-17 18:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/295ee52c9804d8c26fb62f86b568169dccf41f99', 'message': 'Updated from global requirements\n\nChange-Id: Ie1bc3790ccdba69d3eca7aca732e845f2ee6eb10\n'}, {'number': 2, 'created': '2016-02-19 02:32:26.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/8639dc01acf8da7bbd60c29b7bdc4108b5d77cc1', 'message': 'Updated from global requirements\n\nChange-Id: Ie1bc3790ccdba69d3eca7aca732e845f2ee6eb10\n'}]",1,281459,8639dc01acf8da7bbd60c29b7bdc4108b5d77cc1,13,4,2,11131,,,0,"Updated from global requirements

Change-Id: Ie1bc3790ccdba69d3eca7aca732e845f2ee6eb10
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/59/281459/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,295ee52c9804d8c26fb62f86b568169dccf41f99,openstack/requirements," setup_requires=['pbr>=1.8'],"," setup_requires=['pbr'],",21,21
openstack%2Fsolum~master~I04886f065a4e6e594b2adeac5e6f92918633ed23,openstack/solum,master,I04886f065a4e6e594b2adeac5e6f92918633ed23,config option to limit number of apps per tenant,MERGED,2016-02-15 21:41:34.000000000,2016-02-19 03:41:37.000000000,2016-02-19 03:41:37.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-02-15 21:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/542ca1e5dcae5908a51931ef27a5c1ed06659ed3', 'message': 'config option to limit number of apps per tenant\n\nChange-Id: I04886f065a4e6e594b2adeac5e6f92918633ed23\nCloses-Bug: #1545859\n'}, {'number': 2, 'created': '2016-02-16 16:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/28f6b50073f7256e148f31980dcec65a16c2f8dd', 'message': 'config option to limit number of apps per tenant\n\nChange-Id: I04886f065a4e6e594b2adeac5e6f92918633ed23\nCloses-Bug: #1545859\n'}, {'number': 3, 'created': '2016-02-16 17:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/34ce436b1aa3b271d9a1d8bfda0cf40dcc00e93e', 'message': 'config option to limit number of apps per tenant\n\nChange-Id: I04886f065a4e6e594b2adeac5e6f92918633ed23\nCloses-Bug: #1545859\n'}, {'number': 4, 'created': '2016-02-18 19:23:05.000000000', 'files': ['solum/common/exception.py', 'solum/api/controllers/v1/app.py', 'solum/api/app.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/a7d74be5b9c4dda9102bd01b6b0e896f95f2bf44', 'message': 'config option to limit number of apps per tenant\n\nChange-Id: I04886f065a4e6e594b2adeac5e6f92918633ed23\nCloses-Bug: #1545859\n'}]",5,280419,a7d74be5b9c4dda9102bd01b6b0e896f95f2bf44,27,4,4,7230,,,0,"config option to limit number of apps per tenant

Change-Id: I04886f065a4e6e594b2adeac5e6f92918633ed23
Closes-Bug: #1545859
",git fetch https://review.opendev.org/openstack/solum refs/changes/19/280419/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/common/exception.py', 'solum/api/controllers/v1/app.py', 'solum/api/app.py']",3,542ca1e5dcae5908a51931ef27a5c1ed06659ed3,bug/1545859," help='The listen IP for the solum API server'), cfg.IntOpt('max_apps_per_tenant', default=10, help='Maximum number of application allowed per tenant'),", help='The listen IP for the solum API server'),15,1
openstack%2Fpython-keystoneclient~master~I80a40e88b571fe9b0eca3af8b705ea79f28eb904,openstack/python-keystoneclient,master,I80a40e88b571fe9b0eca3af8b705ea79f28eb904,Implied Roles,MERGED,2016-02-16 23:10:20.000000000,2016-02-19 03:34:37.000000000,2016-02-19 03:34:37.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 13063}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-02-16 23:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/486cd74c2316b2e99ec4c6c9e85ece71fd9a8234', 'message': 'Implied Roles\n\nChange-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904\n'}, {'number': 2, 'created': '2016-02-17 04:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/05f314865b7427e873ac6d3743567f3eb4004768', 'message': 'Implied Roles\n\nChange-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904\n'}, {'number': 3, 'created': '2016-02-17 18:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/00dd7cdf6d2af4e0d2117bcf3dabed9354a0cad5', 'message': 'Implied Roles\n\nWhile the entity for an inference rule should be thought of as a\nresource, the rules are essentially relationships between roles.\nThe `implied_role` API is linked with the role API, and thus the\nclient functions are part of v3/role.py.  However, it does not\nmap completely cleanly to the Crud baseclass, and requires\nsome custom URL generation.\n\nChange-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904\n'}, {'number': 4, 'created': '2016-02-17 23:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f57664ce8ecbdb167d6349ed46d0e92883f2b2ad', 'message': 'Implied Roles\n\nWhile the entity for an inference rule should be thought of as a\nresource, the rules are essentially relationships between roles.\nThe `implied_role` API is linked with the role API, and thus the\nclient functions are part of v3/role.py.  However, it does not\nmap completely cleanly to the Crud baseclass, and requires\nsome custom URL generation.\n\nChange-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904\n'}, {'number': 5, 'created': '2016-02-18 02:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/db1e3b37f32e89d4bb19255712e9174528bcda89', 'message': 'Implied Roles\n\nWhile the entity for an inference rule should be thought of as a\nresource, the rules are essentially relationships between roles.\nThe `implied_role` API is linked with the role API, and thus the\nclient functions are part of v3/role.py.  However, it does not\nmap completely cleanly to the Crud baseclass, and requires\nsome custom URL generation.\n\nChange-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904\n'}, {'number': 6, 'created': '2016-02-18 03:23:52.000000000', 'files': ['keystoneclient/tests/functional/v3/test_implied_roles.py', 'keystoneclient/v3/roles.py', 'keystoneclient/tests/unit/v3/test_roles.py', 'releasenotes/notes/implied_roles-ea39d3c3d998d482.yaml'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/abcee5f3ce234e820e90e2d8bb6823f238fb69e8', 'message': 'Implied Roles\n\nWhile the entity for an inference rule should be thought of as a\nresource, the rules are essentially relationships between roles.\nThe `implied_role` API is linked with the role API, and thus the\nclient functions are part of v3/role.py.  However, it does not\nmap completely cleanly to the Crud baseclass, and requires\nsome custom URL generation.\n\nChange-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904\n'}]",2,280983,abcee5f3ce234e820e90e2d8bb6823f238fb69e8,24,15,6,2218,,,0,"Implied Roles

While the entity for an inference rule should be thought of as a
resource, the rules are essentially relationships between roles.
The `implied_role` API is linked with the role API, and thus the
client functions are part of v3/role.py.  However, it does not
map completely cleanly to the Crud baseclass, and requires
some custom URL generation.

Change-Id: I80a40e88b571fe9b0eca3af8b705ea79f28eb904
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/83/280983/4 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/v3/roles.py'],1,486cd74c2316b2e99ec4c6c9e85ece71fd9a8234,implied-roles," def _implied_role_base_url(prior_role, implied_role): base_url = ('/roles/%(prior_role_id)s/implies/%(implied_role_id)s' % {'prior_role_id': base.getid(prior_role), 'implied_role_id': base.getid(implied_role)}) return base_url def imply(self, prior_role, implied_role, **kwargs): base_url = self._implied_role_base_url(prior_role, implied_role) return super(RoleManager, self).post(base_url=base_url, **kwargs) def delete_implication(self, prior_role, implied_role, **kwargs): base_url = self._implied_role_base_url(prior_role, implied_role) return super(RoleManager, self).delete(base_url=base_url, **kwargs) def get_implied(self, prior_role, implied_role, **kwargs): base_url = self._implied_role_base_url(prior_role, implied_role) return super(RoleManager, self).get(base_url=base_url, **kwargs) def check_implied(self, prior_role, implied_role, **kwargs): base_url = self._implied_role_base_url(prior_role, implied_role) return super(RoleManager, self).head(base_url=base_url, **kwargs) def list_implied(self, **kwargs): return super(RoleManager, self).get( base_url='/role_inferences/', **kwargs) ",,26,0
openstack%2Fpython-cinderclient~master~I58aea0996961eab33e5cfa7d57b59cda9859e82e,openstack/python-cinderclient,master,I58aea0996961eab33e5cfa7d57b59cda9859e82e,Fix return type in backup docstring,MERGED,2016-02-17 09:40:32.000000000,2016-02-19 03:11:09.000000000,2016-02-19 03:11:09.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 11904}, {'_account_id': 20105}]","[{'number': 1, 'created': '2016-02-17 09:40:32.000000000', 'files': ['cinderclient/v2/volume_backups.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2b25183c97ae4e0f061921544307c7e6efab69f1', 'message': 'Fix return type in backup docstring\n\nFixed return type for export_record and import_record\nin volume backups.\n\nTrivialFix\n\nChange-Id: I58aea0996961eab33e5cfa7d57b59cda9859e82e\n'}]",0,281141,2b25183c97ae4e0f061921544307c7e6efab69f1,8,4,1,10485,,,0,"Fix return type in backup docstring

Fixed return type for export_record and import_record
in volume backups.

TrivialFix

Change-Id: I58aea0996961eab33e5cfa7d57b59cda9859e82e
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/41/281141/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/v2/volume_backups.py'],1,2b25183c97ae4e0f061921544307c7e6efab69f1,fix-docstring," :rtype: A dictionary containing 'backup_url' and 'backup_service'. """"""Import volume backup metadata record. :rtype: A dictionary containing volume backup metadata."," :rtype: :class:`VolumeBackup` """"""Export volume backup metadata record. :rtype: :class:`VolumeBackup`",3,3
openstack%2Fcinder~master~I54b39f367b8552ed5e932c71265432e7cf72c073,openstack/cinder,master,I54b39f367b8552ed5e932c71265432e7cf72c073,Roll back reservations quota in RPC if necessary,MERGED,2016-01-04 23:16:09.000000000,2016-02-19 03:04:33.000000000,2016-02-19 00:24:49.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14274}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17275}, {'_account_id': 17718}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2016-01-04 23:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/647e98afbdd777d444d4e16e7af0b7f6129c821d', 'message': ""Roll back reservations quota in RPC if necessary\n\nCurrently the latest version of the volume rpcapi passes along\nold_reservations in retype whereas older versions do not. In the\ncase where old_reservations aren't passed, they will be checked again\nin c-vol. This patch rolls back the quotas that were checked for\nold_reservations if the client can't send the latest version in\nthe RPCAPI so that they aren't reserved twice.\n\nChange-Id: I54b39f367b8552ed5e932c71265432e7cf72c073\n""}, {'number': 2, 'created': '2016-01-05 22:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9be486df53559c49edbf2f401eb546c2428cf922', 'message': ""Roll back reservations quota in RPC if necessary\n\nCurrently the latest version of the volume rpcapi passes along\nold_reservations in retype whereas older versions do not. In the\ncase where old_reservations aren't passed, they will be checked again\nin c-vol. This patch rolls back the quotas that were checked for\nold_reservations if the client can't send the latest version in\nthe RPCAPI so that they aren't reserved twice.\n\nThis is an amendment to this recently merged patch:\nIba24edd8ad824837028353b52c90742df55c9173\n\nCloses-bug: #1508249\nChange-Id: I54b39f367b8552ed5e932c71265432e7cf72c073\n""}, {'number': 3, 'created': '2016-01-11 23:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1477021901deceff8b526ac766219502006b6ae0', 'message': ""Roll back reservations quota in RPC if necessary\n\nCurrently the latest version of the volume rpcapi passes along\nold_reservations in retype whereas older versions do not. In the\ncase where old_reservations aren't passed, they will be checked again\nin c-vol. This patch rolls back the quotas that were checked for\nold_reservations if the client can't send the latest version in\nthe RPCAPI so that they aren't reserved twice.\n\nThis is an amendment to this recently merged patch:\nIba24edd8ad824837028353b52c90742df55c9173\n\nRelated-bug: #1508249\nChange-Id: I54b39f367b8552ed5e932c71265432e7cf72c073\n""}, {'number': 4, 'created': '2016-02-16 13:22:10.000000000', 'files': ['cinder/tests/unit/test_volume_rpcapi.py', 'cinder/volume/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3ef58dd656d6fdf08457f16a2a39b0fbffd3c2ca', 'message': ""Roll back reservations quota in RPC if necessary\n\nCurrently the latest version of the volume rpcapi passes along\nold_reservations in retype whereas older versions do not. In the\ncase where old_reservations aren't passed, they will be checked again\nin c-vol. This patch rolls back the quotas that were checked for\nold_reservations if the client can't send the latest version in\nthe RPCAPI so that they aren't reserved twice.\n\nThis is an amendment to this recently merged patch:\nIba24edd8ad824837028353b52c90742df55c9173\n\nCloses-Bug: 1546089\nRelated-bug: 1508249\nChange-Id: I54b39f367b8552ed5e932c71265432e7cf72c073\n""}]",1,263473,3ef58dd656d6fdf08457f16a2a39b0fbffd3c2ca,137,42,4,17275,,,0,"Roll back reservations quota in RPC if necessary

Currently the latest version of the volume rpcapi passes along
old_reservations in retype whereas older versions do not. In the
case where old_reservations aren't passed, they will be checked again
in c-vol. This patch rolls back the quotas that were checked for
old_reservations if the client can't send the latest version in
the RPCAPI so that they aren't reserved twice.

This is an amendment to this recently merged patch:
Iba24edd8ad824837028353b52c90742df55c9173

Closes-Bug: 1546089
Related-bug: 1508249
Change-Id: I54b39f367b8552ed5e932c71265432e7cf72c073
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/263473/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/rpcapi.py'],1,647e98afbdd777d444d4e16e7af0b7f6129c821d,263473,"from cinder import quotaQUOTAS = quota.QUOTAS if old_reservations is not None: QUOTAS.rollback(ctxt, old_reservations)",,4,0
openstack%2Fsenlin~master~I63bbcac1cd4d48ced3464c069dcb5ed1099a46cb,openstack/senlin,master,I63bbcac1cd4d48ced3464c069dcb5ed1099a46cb,Util function 'validate_sort_param',MERGED,2016-02-18 08:52:22.000000000,2016-02-19 02:46:49.000000000,2016-02-19 02:46:49.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 7404}]","[{'number': 1, 'created': '2016-02-18 08:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1071cd0e4a5d9db362f6526b60e28bdabe576c95', 'message': ""Util function 'validate_sort_param'\n\nThis patch renames the 'parse_sort_param' utility function to\n'validate_sort_param' and simplifies its logic. The intent is to make\nthis a tool for service engine to validate sort options specified by\nusers.\n\nChange-Id: I63bbcac1cd4d48ced3464c069dcb5ed1099a46cb\n""}, {'number': 2, 'created': '2016-02-18 14:46:30.000000000', 'files': ['senlin/common/utils.py', 'senlin/tests/unit/test_common_utils.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7ec370b7c19bf118c2d767d3aa3a42a0afe24f18', 'message': ""Util function 'validate_sort_param'\n\nThis patch renames the 'parse_sort_param' utility function to\n'validate_sort_param' and simplifies its logic. The intent is to make\nthis a tool for service engine to validate sort options specified by\nusers.\n\nChange-Id: I63bbcac1cd4d48ced3464c069dcb5ed1099a46cb\n""}]",0,281696,7ec370b7c19bf118c2d767d3aa3a42a0afe24f18,9,3,2,8246,,,0,"Util function 'validate_sort_param'

This patch renames the 'parse_sort_param' utility function to
'validate_sort_param' and simplifies its logic. The intent is to make
this a tool for service engine to validate sort options specified by
users.

Change-Id: I63bbcac1cd4d48ced3464c069dcb5ed1099a46cb
",git fetch https://review.opendev.org/openstack/senlin refs/changes/96/281696/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/common/utils.py', 'senlin/tests/unit/test_common_utils.py']",2,1071cd0e4a5d9db362f6526b60e28bdabe576c95,validate-sort-param," def test_validate_sort_param(self): whitelist = ['foo', 'bar', 'zoo'] actual = utils.validate_sort_param(None, whitelist) self.assertIsNone(actual) # single good key actual = utils.validate_sort_param('foo', whitelist) self.assertIsNone(actual) actual = utils.validate_sort_param('foo,bar', whitelist) self.assertIsNone(actual) # with dirs actual = utils.validate_sort_param(value, whitelist) self.assertIsNone(actual) def test_validate_sort_param_key_missing(self): whitelist = ['foo', 'bar', 'zoo'] ex = self.assertRaises(exception.InvalidParameter, utils.validate_sort_param, ':asc', whitelist) self.assertEqual(""Invalid value '' specified for 'sort key'"", six.text_type(ex)) def test_validate_sort_param_invalid_key(self): whitelist = ['foo', 'bar', 'zoo'] ex = self.assertRaises(exception.InvalidParameter, utils.validate_sort_param, 'cool', whitelist) self.assertEqual(""Invalid value 'cool' specified for 'sort key'"", six.text_type(ex)) def test_validate_sort_param_invalid_dir(self): whitelist = ['foo', 'bar', 'zoo'] ex = self.assertRaises(exception.InvalidParameter, utils.validate_sort_param, 'bar:inc', whitelist) self.assertEqual(""Invalid value 'inc' specified for 'sort dir'"", six.text_type(ex))"," def test_parse_sort_param(self): whitelist = 'foo,bar,zoo' actual = utils.parse_sort_param(None, whitelist) self.assertEqual(2, len(actual)) self.assertIsNone(actual[0]) self.assertIsNone(actual[1]) # single key value = 'foo' actual = utils.parse_sort_param(value, whitelist) self.assertEqual(2, len(actual)) self.assertEqual(['foo'], actual[0]) self.assertEqual(['asc'], actual[1]) value = 'foo,bar,zoo' actual = utils.parse_sort_param(value, whitelist) self.assertEqual(2, len(actual)) self.assertEqual(['foo', 'bar', 'zoo'], actual[0]) self.assertEqual(['asc', 'asc', 'asc'], actual[1]) # partial dirs actual = utils.parse_sort_param(value, whitelist) self.assertEqual(2, len(actual)) self.assertEqual(['foo', 'bar', 'zoo'], actual[0]) self.assertEqual(['asc', 'asc', 'desc'], actual[1]) # all with dirs value = 'foo:asc,bar:desc,zoo:desc' actual = utils.parse_sort_param(value, whitelist) self.assertEqual(2, len(actual)) self.assertEqual(['foo', 'bar', 'zoo'], actual[0]) self.assertEqual(['asc', 'desc', 'desc'], actual[1]) # missing key value = ':asc' self.assertRaises(exception.InvalidParameter, utils.parse_sort_param, value, whitelist) # bad key value = 'bad_key' self.assertRaises(exception.InvalidParameter, utils.parse_sort_param, value, whitelist) # bad sorting dir value = 'foo:inc' self.assertRaises(exception.InvalidParameter, utils.parse_sort_param, value, whitelist)",40,59
openstack%2Fironic~master~I8ad95206f81bdf806f196994be669667d92566ff,openstack/ironic,master,I8ad95206f81bdf806f196994be669667d92566ff,Use 'node' directly in update_port(),MERGED,2016-02-18 14:29:28.000000000,2016-02-19 02:46:09.000000000,2016-02-19 02:46:09.000000000,"[{'_account_id': 3}, {'_account_id': 8106}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-02-18 14:29:28.000000000', 'files': ['ironic/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/bfb5e5431a8aa8e893931e093bb69fb66ebebcb8', 'message': ""Use 'node' directly in update_port()\n\nChange-Id: I8ad95206f81bdf806f196994be669667d92566ff\n""}]",0,281887,bfb5e5431a8aa8e893931e093bb69fb66ebebcb8,7,3,1,6610,,,0,"Use 'node' directly in update_port()

Change-Id: I8ad95206f81bdf806f196994be669667d92566ff
",git fetch https://review.opendev.org/openstack/ironic refs/changes/87/281887/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/conductor/manager.py'],1,bfb5e5431a8aa8e893931e093bb69fb66ebebcb8,," and not (node.provision_state in allowed_update_states or node.maintenance)): 'node': node.uuid,"," and not (task.node.provision_state in allowed_update_states or task.node.maintenance)): 'node': task.node.uuid,",3,3
openstack%2Fironic~master~I894b20fc41c195202d2545f6de2791cd6a1b1a30,openstack/ironic,master,I894b20fc41c195202d2545f6de2791cd6a1b1a30,DevStack: Support to install diskimage-builder from source,MERGED,2015-12-14 12:05:13.000000000,2016-02-19 02:44:56.000000000,2016-02-19 02:44:56.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 13362}, {'_account_id': 14629}]","[{'number': 1, 'created': '2015-12-14 12:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef57a6ad4bb7ffde7e433fa75e13d6ec5548d9a6', 'message': 'Ironic: Support to install diskimage-builder from source\n\nPrior to this patch devstack only supported installing diskimage-builder\ndirectly from pip. This patch adds support to also install it from git.\n\nThis is needed so we can run tests on the diskimage-builder gate to test\nagainst Ironic.\n\nDepends-On: I6cefac1eb4ebf0196a6b4d4bfc038c00921f0d70\nChange-Id: I894b20fc41c195202d2545f6de2791cd6a1b1a30\n'}, {'number': 2, 'created': '2015-12-14 12:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fe7c211d930455e2e9618335002f6719fd1490e1', 'message': 'DevStack: Support to install diskimage-builder from source\n\nPrior to this patch devstack only supported installing diskimage-builder\ndirectly from pip. This patch adds support to also install it from git.\n\nThis is needed so we can run tests on the diskimage-builder gate to test\nagainst Ironic.\n\nDepends-On: I6cefac1eb4ebf0196a6b4d4bfc038c00921f0d70\nChange-Id: I894b20fc41c195202d2545f6de2791cd6a1b1a30\n'}, {'number': 3, 'created': '2016-02-18 16:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/46e0cd35591c844052075ac5b2891d7aebd2a0b5', 'message': 'DevStack: Support to install diskimage-builder from source\n\nPrior to this patch devstack only supported installing diskimage-builder\ndirectly from pip. This patch adds support to also install it from git.\n\nThis is needed so we can run tests on the diskimage-builder gate to test\nagainst Ironic.\n\nDepends-On: I6cefac1eb4ebf0196a6b4d4bfc038c00921f0d70\nChange-Id: I894b20fc41c195202d2545f6de2791cd6a1b1a30\n'}, {'number': 4, 'created': '2016-02-18 16:22:03.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b4bc03f04fb87336915901a460c03c7be47d78b0', 'message': 'DevStack: Support to install diskimage-builder from source\n\nPrior to this patch devstack only supported installing diskimage-builder\ndirectly from pip. This patch adds support to also install it from git.\n\nThis is needed so we can run tests on the diskimage-builder gate to test\nagainst Ironic.\n\nDepends-On: I6cefac1eb4ebf0196a6b4d4bfc038c00921f0d70\nChange-Id: I894b20fc41c195202d2545f6de2791cd6a1b1a30\n'}]",3,257302,b4bc03f04fb87336915901a460c03c7be47d78b0,24,8,4,6773,,,0,"DevStack: Support to install diskimage-builder from source

Prior to this patch devstack only supported installing diskimage-builder
directly from pip. This patch adds support to also install it from git.

This is needed so we can run tests on the diskimage-builder gate to test
against Ironic.

Depends-On: I6cefac1eb4ebf0196a6b4d4bfc038c00921f0d70
Change-Id: I894b20fc41c195202d2545f6de2791cd6a1b1a30
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/257302/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,ef57a6ad4bb7ffde7e433fa75e13d6ec5548d9a6,devstack-dib-source,"GITDIR[""diskimage-builder""]=$DEST/diskimage-builder# install_diskimage_builder() - Collect source and prepare or install from pip function install_diskimage_builder { if use_library_from_git ""diskimage-builder""; then git_clone_by_name ""diskimage-builder"" setup_dev_lib ""diskimage-builder"" else pip_install_gr ""diskimage-builder"" fi } install_diskimage_builder # FIXME(lucasagomes): diskimage-builder can not be install # using ""pip install -e"", so we need to use the full path # to make it work until the bug below is fixed: # https://bugs.launchpad.net/diskimage-builder/+bug/1491035 RAMDISK_CREATE_CMD=ramdisk-image-create if use_library_from_git ""diskimage-builder""; then RAMDISK_CREATE_CMD=${GITDIR[""diskimage-builder""]}/bin/ramdisk-image-create fi $RAMDISK_CREATE_CMD $IRONIC_DEPLOY_FLAVOR \"," pip_install_gr ""diskimage-builder"" ramdisk-image-create $IRONIC_DEPLOY_FLAVOR \",22,2
openstack%2Fneutron~master~I745389150c23ffabe25eab0ead78dfc850885e9d,openstack/neutron,master,I745389150c23ffabe25eab0ead78dfc850885e9d,Add missing character,MERGED,2016-02-18 18:36:39.000000000,2016-02-19 02:43:14.000000000,2016-02-19 02:43:13.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 10184}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-18 18:36:39.000000000', 'files': ['doc/source/devref/openvswitch_firewall.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/384fe5f9a6b72cfa3effaeee5215064b35a8744b', 'message': 'Add missing character\n\nThis missing character was causing a warning during the creation of\ndocumentation.  This warning message was considered an error ending the\nprocess to create documentation.\n\nChange-Id: I745389150c23ffabe25eab0ead78dfc850885e9d\nCloses-Bug: #1547164\n'}]",0,282000,384fe5f9a6b72cfa3effaeee5215064b35a8744b,16,6,1,8726,,,0,"Add missing character

This missing character was causing a warning during the creation of
documentation.  This warning message was considered an error ending the
process to create documentation.

Change-Id: I745389150c23ffabe25eab0ead78dfc850885e9d
Closes-Bug: #1547164
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/282000/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/openvswitch_firewall.rst'],1,384fe5f9a6b72cfa3effaeee5215064b35a8744b,bug/1547164,============================,===========================,1,1
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Iffa0a77852729786b69945c1e72bc90ad57ce3bb,openstack/tripleo-heat-templates,stable/liberty,Iffa0a77852729786b69945c1e72bc90ad57ce3bb,Increase size of connection tracking table,MERGED,2016-02-10 15:34:18.000000000,2016-02-19 02:36:13.000000000,2016-02-19 00:58:42.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-02-10 15:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8e724430a087e089257c4ecbc6259977a6ed9a06', 'message': ""Increase size of connection tracking table\n\nDuring high load, the default limit of the kernel connection tracking\ntable (65536) is often too low, resuling in error messages such as:\n\nkernel: nf_conntrack: table full, dropping packet\n\nThis patch increases the limit to 500,000.\n\nSince the nf_conntrack kernel module is not always loaded by default, it also\nadds a mechanism to load kernel modules via hieradata using the kmod puppet\nmodule. In order to express the needed dependency in puppet that kernel modules\nare loaded before sysctl settings are applied, the Exec resources tagged with\n'kmod::load' are specified in a resource collector to express that that Exec\nresources with the tag should run before Sysctl resources.\n\nDepends-On: I59cc2280ebae315af38fb5008e6ee0073195ae51\nChange-Id: Iffa0a77852729786b69945c1e72bc90ad57ce3bb\n""}, {'number': 2, 'created': '2016-02-10 15:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0f08b7fdccc6ad1f3b4499f56072a8f2a14ea79e', 'message': ""Increase size of connection tracking table\n\nDuring high load, the default limit of the kernel connection tracking\ntable (65536) is often too low, resuling in error messages such as:\n\nkernel: nf_conntrack: table full, dropping packet\n\nThis patch increases the limit to 500,000.\n\nSince the nf_conntrack kernel module is not always loaded by default, it also\nadds a mechanism to load kernel modules via hieradata using the kmod puppet\nmodule. In order to express the needed dependency in puppet that kernel modules\nare loaded before sysctl settings are applied, the Exec resources tagged with\n'kmod::load' are specified in a resource collector to express that that Exec\nresources with the tag should run before Sysctl resources.\n\nDepends-On: I59cc2280ebae315af38fb5008e6ee0073195ae51\nChange-Id: Iffa0a77852729786b69945c1e72bc90ad57ce3bb\n(cherry picked from commit 834f5b62289b89d7745495dfea7e65e47f1b46e9)\n""}, {'number': 3, 'created': '2016-02-18 18:56:05.000000000', 'files': ['puppet/manifests/overcloud_cephstorage.pp', 'puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_object.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/hieradata/common.yaml', 'puppet/manifests/overcloud_volume.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ed7bed15bba91262192fe42be0b451276f64f2a7', 'message': ""Increase size of connection tracking table\n\nDuring high load, the default limit of the kernel connection tracking\ntable (65536) is often too low, resuling in error messages such as:\n\nkernel: nf_conntrack: table full, dropping packet\n\nThis patch increases the limit to 500,000.\n\nSince the nf_conntrack kernel module is not always loaded by default, it also\nadds a mechanism to load kernel modules via hieradata using the kmod puppet\nmodule. In order to express the needed dependency in puppet that kernel modules\nare loaded before sysctl settings are applied, the Exec resources tagged with\n'kmod::load' are specified in a resource collector to express that that Exec\nresources with the tag should run before Sysctl resources.\n\nDepends-On: I59cc2280ebae315af38fb5008e6ee0073195ae51\nChange-Id: Iffa0a77852729786b69945c1e72bc90ad57ce3bb\n(cherry picked from commit 834f5b62289b89d7745495dfea7e65e47f1b46e9)\n""}]",0,278451,ed7bed15bba91262192fe42be0b451276f64f2a7,35,3,3,7144,,,0,"Increase size of connection tracking table

During high load, the default limit of the kernel connection tracking
table (65536) is often too low, resuling in error messages such as:

kernel: nf_conntrack: table full, dropping packet

This patch increases the limit to 500,000.

Since the nf_conntrack kernel module is not always loaded by default, it also
adds a mechanism to load kernel modules via hieradata using the kmod puppet
module. In order to express the needed dependency in puppet that kernel modules
are loaded before sysctl settings are applied, the Exec resources tagged with
'kmod::load' are specified in a resource collector to express that that Exec
resources with the tag should run before Sysctl resources.

Depends-On: I59cc2280ebae315af38fb5008e6ee0073195ae51
Change-Id: Iffa0a77852729786b69945c1e72bc90ad57ce3bb
(cherry picked from commit 834f5b62289b89d7745495dfea7e65e47f1b46e9)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/278451/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_cephstorage.pp', 'puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/manifests/overcloud_object.pp', 'puppet/hieradata/common.yaml', 'puppet/manifests/overcloud_volume.pp']",7,8e724430a087e089257c4ecbc6259977a6ed9a06,conntrack,"create_resources(kmod::load, hiera('kernel_modules'), {})Exec <| tag == 'kmod::load' |> -> Sysctl <| |>",,19,0
openstack%2Fheat~master~I080361fd750c69a4978df3c59a180e0836aa5214,openstack/heat,master,I080361fd750c69a4978df3c59a180e0836aa5214,Fix yaml string parsing error cause by empty space.,ABANDONED,2016-02-18 09:02:20.000000000,2016-02-19 02:31:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-18 09:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4cf11559572b2f1c99aac3722ea9035928b68c84', 'message': ""Fix yaml string parsing error cause by space.\n\nOnec we format a yaml file with a nested yaml string,\nheat will not delete the space at the ends of key/value.\nFor this reason, it will appare a key/value like 'flavor ': 'm1.tiny'.\nHeat can not determine the type of 'flavor '.\n\nChange-Id: I080361fd750c69a4978df3c59a180e0836aa5214\n""}, {'number': 2, 'created': '2016-02-18 09:06:46.000000000', 'files': ['heat/common/template_format.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/283fdb33ecd476b2a64dd78851dd789c007be78b', 'message': ""Fix yaml string parsing error cause by empty space.\n\nOnec we format a yaml file with a nested yaml string,\nheat will not delete the space at the ends of key/value.\nFor this reason, it will appare a key/value like 'flavor ': 'm1.tiny'.\nHeat can not determine the type of 'flavor '.\n\nChange-Id: I080361fd750c69a4978df3c59a180e0836aa5214\n""}]",0,281702,283fdb33ecd476b2a64dd78851dd789c007be78b,4,1,2,19963,,,0,"Fix yaml string parsing error cause by empty space.

Onec we format a yaml file with a nested yaml string,
heat will not delete the space at the ends of key/value.
For this reason, it will appare a key/value like 'flavor ': 'm1.tiny'.
Heat can not determine the type of 'flavor '.

Change-Id: I080361fd750c69a4978df3c59a180e0836aa5214
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/281702/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/template_format.py'],1,4cf11559572b2f1c99aac3722ea9035928b68c84,bug/1546903," def _dict_list_strip(dict_list): '''Delete the spaces at both ends''' new_list = [] for key in range(0, len(dict_list)-1): value = dict_list[key] if isinstance(value, dict): value = _dict_strip(value) elif isinstance(value, list): value = _dict_list_strip(value) elif isinstance(value, (six.string_types, six.text_type)): value = value.strip() new_list.append(value) return new_list def _dict_strip(dict_value): '''Delete the spaces at both ends''' new_dict = {} for key, value in six.iteritems(dict_value): if isinstance(value, dict): value = _dict_strip(value) elif isinstance(value, list): value = _dict_list_strip(value) elif isinstance(value, (str, six.text_type)): value = value.strip() new_key = str(key).strip() new_dict[new_key] = value return new_dict else: tpl_strip = _dict_strip(tpl) return tpl_strip", return tpl,37,1
openstack%2Frequirements~master~Ifbd4b225a23c89aef1ec91f5be7ddade7986307a,openstack/requirements,master,Ifbd4b225a23c89aef1ec91f5be7ddade7986307a,Update to os-brick 1.0.0,MERGED,2016-02-17 20:55:46.000000000,2016-02-19 02:29:23.000000000,2016-02-19 02:29:22.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-02-17 20:55:46.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b26c37bdb03af21b310f32392f830935a9095a93', 'message': 'Update to os-brick 1.0.0\n\nImproved multipath handling and support for device\nhandling for LUN IDs > 255.\n\nChange-Id: Ifbd4b225a23c89aef1ec91f5be7ddade7986307a\nDepends-on: Ia277d2724e983df78da1335b12320901494a9ae7\n'}]",0,281523,b26c37bdb03af21b310f32392f830935a9095a93,11,2,1,11904,,,0,"Update to os-brick 1.0.0

Improved multipath handling and support for device
handling for LUN IDs > 255.

Change-Id: Ifbd4b225a23c89aef1ec91f5be7ddade7986307a
Depends-on: Ia277d2724e983df78da1335b12320901494a9ae7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/23/281523/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,b26c37bdb03af21b310f32392f830935a9095a93,os-brick-1.0.0,os-brick===1.0.0,os-brick===0.8.0,2,2
openstack%2Fsenlin~master~If0a236f5dab6333e02b1d3f62fad4d084c897cbf,openstack/senlin,master,If0a236f5dab6333e02b1d3f62fad4d084c897cbf,Add unit test for is_admin check in DB interfaces,MERGED,2016-02-18 09:26:16.000000000,2016-02-19 02:21:29.000000000,2016-02-19 02:21:29.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-18 09:26:16.000000000', 'files': ['senlin/tests/unit/db/test_cluster_api.py', 'senlin/tests/unit/db/test_profile_api.py', 'senlin/tests/unit/common/utils.py', 'senlin/tests/unit/db/test_event_api.py', 'senlin/tests/unit/db/test_policy_api.py', 'senlin/tests/unit/db/test_node_api.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/tests/unit/db/test_receiver_api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3544bc907f5553564c49fd207c8b1032c3c77a3b', 'message': 'Add unit test for is_admin check in DB interfaces\n\nThis patch adds unit test for is_admin check in DB APIs.\n\nChange-Id: If0a236f5dab6333e02b1d3f62fad4d084c897cbf\n'}]",0,281714,3544bc907f5553564c49fd207c8b1032c3c77a3b,7,3,1,11034,,,0,"Add unit test for is_admin check in DB interfaces

This patch adds unit test for is_admin check in DB APIs.

Change-Id: If0a236f5dab6333e02b1d3f62fad4d084c897cbf
",git fetch https://review.opendev.org/openstack/senlin refs/changes/14/281714/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/db/test_cluster_api.py', 'senlin/tests/unit/common/utils.py', 'senlin/tests/unit/db/test_profile_api.py', 'senlin/tests/unit/db/test_event_api.py', 'senlin/tests/unit/db/test_policy_api.py', 'senlin/tests/unit/db/test_node_api.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/tests/unit/db/test_receiver_api.py']",8,3544bc907f5553564c49fd207c8b1032c3c77a3b,unit-test-is-admin-db-check," def test_receiver_get_admin_context(self): admin_ctx = utils.dummy_context(project='a-different-project', is_admin=True) r = self._create_receiver(self.ctx) res = db_api.receiver_get(admin_ctx, r.id, project_safe=True) self.assertIsNotNone(res) def test_receiver_get_all_with_admin_context(self): self._create_receiver(self.ctx, name='receiver1') self._create_receiver(self.ctx, name='receiver2') admin_ctx = utils.dummy_context(project='a-different-project', is_admin=True) results = db_api.receiver_get_all(admin_ctx, project_safe=True) self.assertEqual(2, len(results)) ",,212,2
openstack%2Fsenlin-dashboard~master~I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff,openstack/senlin-dashboard,master,I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff,Updated from global requirements,MERGED,2016-01-16 03:33:16.000000000,2016-02-19 02:12:59.000000000,2016-02-19 02:12:59.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 8358}, {'_account_id': 15755}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-01-16 03:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/8845aff5909c9189c39a8a9f6db493d9b45d80db', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 2, 'created': '2016-01-19 12:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/143474155f884a252eb65f95eb6028b302742d3c', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 3, 'created': '2016-01-21 17:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/a45977787ca5dcc782d2cf9d2f97829b628b5846', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 4, 'created': '2016-01-29 20:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/774faaece181d5206f32cf5fefc615e642bc04f0', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 5, 'created': '2016-02-03 03:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/d3cdc83fd1b707c658fcc2534b60df9fab242c69', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 6, 'created': '2016-02-06 23:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/bc09829d5ab03ebc66582e8347ec934476c06bc8', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 7, 'created': '2016-02-10 22:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/8b12f9f447ebcfe6696c77ebf09abe2b1862f41c', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 8, 'created': '2016-02-11 07:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/958f4200f0c8534b57d6952583c4feeed3277dfc', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 9, 'created': '2016-02-14 23:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/d469f67dcd0c89162cf6aa7c049d814f50ec9be3', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}, {'number': 10, 'created': '2016-02-16 18:18:23.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/3ff13079d17a0a27d4dd2d0b2167b27236e64b61', 'message': 'Updated from global requirements\n\nChange-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff\n'}]",0,268539,3ff13079d17a0a27d4dd2d0b2167b27236e64b61,34,5,10,11131,,,0,"Updated from global requirements

Change-Id: I5b5c4e80c48a517c6fc57b4c9248fa40ece402ff
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/39/268539/9 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,8845aff5909c9189c39a8a9f6db493d9b45d80db,openstack/requirements,"coverage>=3.6 # Apache-2.0 django-nose>=1.2 # BSD mock>=1.2 # BSD mox>=0.5.3 # Apache-2.0 mox3>=0.7.0 # Apache-2.0 nodeenv>=0.9.4 # BSD License # BSD nose # LGPL nose-exclude # LGPL nosexcover # BSD openstack.nose-plugin>=0.7 # Apache-2.0 nosehtmloutput>=0.0.3 # Apache-2.0 selenium # Apache-2.0sphinx!=1.2.0,!=1.3b1,<1.3,>=1.1.2 # BSD","coverage>=3.6 django-nose>=1.2 mock>=1.2 mox>=0.5.3 mox3>=0.7.0 nodeenv>=0.9.4 # BSD License nose nose-exclude nosexcover openstack.nose-plugin>=0.7 nosehtmloutput>=0.0.3 seleniumsphinx!=1.2.0,!=1.3b1,<1.3,>=1.1.2",21,21
openstack%2Fnova~master~If80c68b6935de94636b955dc84ad39bf28f3a68c,openstack/nova,master,If80c68b6935de94636b955dc84ad39bf28f3a68c,add numeric id case in api cache layer for instances,ABANDONED,2016-02-17 07:32:08.000000000,2016-02-19 02:11:23.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-17 07:32:08.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/tests/unit/api/openstack/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a57781a84bf0057e0c4418f0ae110c3d71e6dd53', 'message': 'add numeric id case in api cache layer for instances\n\nAPI cache layer caches instances by UUIDs. This fails the request\nwith a numeric id, when try to retrieve the instance by its numeric\nid from the cache layer.\n\nChange-Id: If80c68b6935de94636b955dc84ad39bf28f3a68c\nCloses-Bug: #1522536\n'}]",2,281091,a57781a84bf0057e0c4418f0ae110c3d71e6dd53,13,10,1,14762,,,0,"add numeric id case in api cache layer for instances

API cache layer caches instances by UUIDs. This fails the request
with a numeric id, when try to retrieve the instance by its numeric
id from the cache layer.

Change-Id: If80c68b6935de94636b955dc84ad39bf28f3a68c
Closes-Bug: #1522536
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/281091/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/unit/api/openstack/test_wsgi.py']",2,a57781a84bf0057e0c4418f0ae110c3d71e6dd53,bug/1522536," def test_cache_and_retrieve_instances_by_id(self): request = wsgi.Request.blank('/foo') instance = {'uuid': 'uuid0', 'id': 1} request.cache_db_instance(instance) self.assertEqual(request.get_db_instance('1'), instance) ",,13,1
openstack%2Fgnocchi~master~Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd,openstack/gnocchi,master,Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd,indexer: replace get_metrics() by list_metrics(),MERGED,2016-02-01 14:23:21.000000000,2016-02-19 02:06:10.000000000,2016-02-19 02:06:10.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-02-01 14:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7e58f0b59ee6a08d2ec9d88017879a30408cbe56', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 2, 'created': '2016-02-01 15:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9e0f3adc148cfa744019d3551c9a6b074b7cbf51', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 3, 'created': '2016-02-02 10:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/57ff905335f77d75d1e49885c92d666faecfd529', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 4, 'created': '2016-02-02 13:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6714b4d81be200492ef8b352a19b838799785923', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 5, 'created': '2016-02-02 14:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/bd5974ab85180adfd761b637ce60779946dd376d', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 6, 'created': '2016-02-02 16:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/031427d97c7c2c6ebb6f2b1923ae4ce5a89e1d59', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 7, 'created': '2016-02-02 22:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/455cf20eaa0c0a4bdd4b7a21a80b84891fb1d008', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 8, 'created': '2016-02-03 09:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a1e47b3c717d2ad44c77cd4af860864e2a4bbadd', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 9, 'created': '2016-02-03 14:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/93daaf35876bac24089101fa88283e5aedc11d19', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 10, 'created': '2016-02-04 10:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ee025e028478feaa77f5d26a1765cfb2f98be7fb', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 11, 'created': '2016-02-04 15:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/08517bc337e6505a65cb3ad4b24b27c02668ef79', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 12, 'created': '2016-02-10 18:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/abc4d8edde3fc84bbc01e1a52e08f0fdeea1fa3f', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 13, 'created': '2016-02-11 11:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ba79aede13b99ba35314010a04f20b9561b33271', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 14, 'created': '2016-02-15 13:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/81ecc034fd42c0e0309076de6407b44ef71777a8', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 15, 'created': '2016-02-15 15:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/694298bb3d142908f56a43306c27cc5a87ba6d74', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 16, 'created': '2016-02-15 18:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/19f9e70e42bcbba889e27bfa5fd6fbcc46a1abd1', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 17, 'created': '2016-02-16 16:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f652eb181666076ec43db742fb46f9c97eec5e9e', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 18, 'created': '2016-02-16 19:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f5000b18eba2671548bd4a92bfbbd1356bf0a91e', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 19, 'created': '2016-02-18 13:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/223d5f958f01c4e24a8de47728881083535dd5fb', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 20, 'created': '2016-02-18 14:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/2808c4e3fb57e046b4c5c21af10e58bbb2b6c82e', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 21, 'created': '2016-02-18 16:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/273e5a061d3c98274ec12c17c05e7c9822881470', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}, {'number': 22, 'created': '2016-02-18 22:05:18.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_aggregates.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e3dda4158e7a5fcc8df1ed80f54856771d040aed', 'message': ""indexer: replace get_metrics() by list_metrics()\n\nThe method grew to doing almost the same thing. Let's merge them both together.\n\nChange-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd\n""}]",15,274683,e3dda4158e7a5fcc8df1ed80f54856771d040aed,77,4,22,1669,,,0,"indexer: replace get_metrics() by list_metrics()

The method grew to doing almost the same thing. Let's merge them both together.

Change-Id: Ia6e49832bc83a0f9ceab81f438c04da997cfa8dd
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/83/274683/22 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_aggregates.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py']",7,7e58f0b59ee6a08d2ec9d88017879a30408cbe56,groupby," with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics', with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics') as f: with mock.patch.object(self.index, 'list_metrics') as f:"," with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics', with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics') as f: with mock.patch.object(self.index, 'get_metrics') as f:",30,55
openstack%2Fsenlin~master~Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a,openstack/senlin,master,Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a,Fix DB sync issue happened during action dependency update,ABANDONED,2015-12-02 07:42:56.000000000,2016-02-19 02:00:39.000000000,,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-12-02 07:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e73fa827c65b6d47b2ff284758c9754385aed5c7', 'message': ""[Tentative]Disable multi-engine to debug functional test\n\nThis patch disables multi-engine for functional test to confirm\npossible issues of DB synchronization. Please don't merge it.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\n""}, {'number': 2, 'created': '2015-12-04 02:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/66a8eb84d6329a3d3bdc2911c118cd1e45055749', 'message': ""[Tentative]Disable multi-engine to debug functional test\n\nThis patch disables multi-engine for functional test to confirm\npossible issues of DB synchronization. Please don't merge it.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\n""}, {'number': 3, 'created': '2015-12-04 06:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/97f33487c7f756ed6ef89a878dcdc79394352b35', 'message': ""[Tentative]Disable multi-engine to debug functional test\n\nThis patch disables multi-engine for functional test to confirm\npossible issues of DB synchronization. Please don't merge it.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\n""}, {'number': 4, 'created': '2015-12-07 04:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1b8ca8072dcef15411ab1e5ddb75aef21c52fc61', 'message': ""[Tentative]Disable multi-engine to debug functional test\n\nThis patch disables multi-engine for functional test to confirm\npossible issues of DB synchronization. Please don't merge it.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\n""}, {'number': 5, 'created': '2015-12-07 06:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/023132bdb7d7895f996e812ce252bbed716ffb0a', 'message': ""[Tentative]Disable multi-engine to debug functional test\n\nThis patch disables multi-engine for functional test to confirm\npossible issues of DB synchronization. Please don't merge it.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\n""}, {'number': 6, 'created': '2015-12-07 07:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/714896af887e02cf98aec611e9a3cedc356521c4', 'message': '[Tentative]Debug functional test\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\n'}, {'number': 7, 'created': '2015-12-07 08:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/85bed5147f768536b96d7ef09371c9c3bcbfae49', 'message': '[WIP]Fix DB sync issue happened during action dependency update\n\nThis patch uses lockutils provided in oslo.concurrency to\naddress DB synchronization issue happened during action dependency\nupdate in multi-engine environment.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n'}, {'number': 8, 'created': '2015-12-08 09:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6023b0feaacef5daba5f1e0ce4212cafc6670083', 'message': '[WIP]Fix DB sync issue happened during action dependency updating\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n'}, {'number': 9, 'created': '2015-12-08 09:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/38074f4a735b6f533d3aa133434c018c22fe776c', 'message': '[WIP]Fix DB sync issue happened during action dependency updating\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n'}, {'number': 10, 'created': '2015-12-08 13:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/cf7575ffa37aceca24c8a5be004b86ea6c3a6377', 'message': '[WIP]Fix DB sync issue happened during action dependency updating\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n'}, {'number': 11, 'created': '2015-12-08 13:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/c57cd333fc3fc56c129bbdf713f3766586751ecd', 'message': '[WIP]Fix DB sync issue happened during action dependency updating\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n'}, {'number': 12, 'created': '2015-12-09 03:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/428e55e7a5cfb66066c65d30366aacef93e9295a', 'message': ""Fix DB sync issue happened during action dependency update\n\nThis patch tries to address DB sync issue happened during action\ndependency update by setting isolation_level of transaction to\n'SERIALIZABLE'.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n""}, {'number': 13, 'created': '2015-12-09 10:20:13.000000000', 'files': ['senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/973f96217023542607d960fad8fa426b554bec89', 'message': ""Fix DB sync issue happened during action dependency update\n\nThis patch tries to address DB sync issue happened during action\ndependency update by setting isolation_level of transaction to\n'SERIALIZABLE' or 'READ_COMMITTED'.\n\nChange-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a\nCloses-Bug: #1495449\n""}]",10,252231,973f96217023542607d960fad8fa426b554bec89,72,3,13,11034,,,0,"Fix DB sync issue happened during action dependency update

This patch tries to address DB sync issue happened during action
dependency update by setting isolation_level of transaction to
'SERIALIZABLE' or 'READ_COMMITTED'.

Change-Id: Iebdfd4b09c1e9566c70639a9b766aa516e5a1b4a
Closes-Bug: #1495449
",git fetch https://review.opendev.org/openstack/senlin refs/changes/31/252231/10 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/functional/pre_test_hook.sh'],1,e73fa827c65b6d47b2ff284758c9754385aed5c7,functional-test-rework,echo -e 'num_engine_workers=1\n' >> $localconf,echo -e 'num_engine_workers=2\n' >> $localconf,1,1
openstack%2Fneutron~master~Ie8a9933e41cc0bfc26ac68e1338c762f5a982521,openstack/neutron,master,Ie8a9933e41cc0bfc26ac68e1338c762f5a982521,Fix _get_subnetpool_id returning incorrect value,ABANDONED,2015-07-03 17:42:31.000000000,2016-02-19 01:59:50.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 6635}, {'_account_id': 6685}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 13768}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-07-03 17:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81d5eeeeb83f13ad237f392b3d695bdb2acf6dfd', 'message': 'Fix _get_subnetpool_id returning incorrect value\n\nFollowing the recent refactor, _get_subnetpool_id now returns the\ndefault value even when a cidr is specified in the request without\na subnetpool_id. This is not the desired behaviour.\n\nCurrently a user is unable to create a specific subnet from the\nimplicit (None) pool if a default pool value has been set.\n\nChange-Id: Ie8a9933e41cc0bfc26ac68e1338c762f5a982521\nCloses-Bug: #1471316\n'}, {'number': 2, 'created': '2015-07-03 17:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6332f692da7d12d6ad3f611417e6e383672f5488', 'message': 'Fix _get_subnetpool_id returning incorrect value\n\nFollowing the recent refactor, _get_subnetpool_id now returns the\ndefault value even when a cidr is specified in the request without\na subnetpool_id. This is not the desired behaviour.\n\nCurrently a user is unable to create a specific subnet from the\nimplicit (None) pool if a default pool value has been set.\n\nChange-Id: Ie8a9933e41cc0bfc26ac68e1338c762f5a982521\nCloses-Bug: #1471316\n'}, {'number': 3, 'created': '2015-07-20 21:11:05.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c7d59929f4dc594303d3c623c14ab7226e4a5c1', 'message': 'Fix _get_subnetpool_id returning incorrect value\n\nFollowing the recent refactor, _get_subnetpool_id now returns the\ndefault value even when a cidr is specified in the request without\na subnetpool_id. This is not the desired behaviour.\n\nCurrently a user is unable to create a specific subnet from the\nimplicit (None) pool if a default pool value has been set.\n\nChange-Id: Ie8a9933e41cc0bfc26ac68e1338c762f5a982521\nCloses-Bug: #1471316\n'}]",3,198437,0c7d59929f4dc594303d3c623c14ab7226e4a5c1,54,25,3,6635,,,0,"Fix _get_subnetpool_id returning incorrect value

Following the recent refactor, _get_subnetpool_id now returns the
default value even when a cidr is specified in the request without
a subnetpool_id. This is not the desired behaviour.

Currently a user is unable to create a specific subnet from the
implicit (None) pool if a default pool value has been set.

Change-Id: Ie8a9933e41cc0bfc26ac68e1338c762f5a982521
Closes-Bug: #1471316
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/198437/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,81d5eeeeb83f13ad237f392b3d695bdb2acf6dfd,bug/1471316," returned, even if it is None. If the cidr was explicitly set in the request then None will be returned. configuration parameter). This implies that the ip version must be set explicitly using ip_version attribute. return None"," returned, even if it is None. configuration parameter). This implies that the ip version must be either set implicitly with a specific cidr or explicitly using ip_version attribute. ip_version = netaddr.IPNetwork(cidr).version",5,5
openstack%2Fheat~master~I1c7edcc7652ccd70948ecc85aece87dcbfc29bac,openstack/heat,master,I1c7edcc7652ccd70948ecc85aece87dcbfc29bac,Update README.md for repo project,ABANDONED,2015-08-19 03:08:35.000000000,2016-02-19 01:58:09.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12404}]","[{'number': 1, 'created': '2015-08-19 03:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ec08811cfe4d933b48f533e2289dfc86e8a8547c', 'message': 'Update README.md for repo project\n\nChange-Id: I1c7edcc7652ccd70948ecc85aece87dcbfc29bac\n'}, {'number': 2, 'created': '2015-08-20 01:49:13.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/fe9672c0ec74ce6cc43a32b9960aedbc43d4dc5e', 'message': 'Update README.md for repo project\n\nChange-Id: I1c7edcc7652ccd70948ecc85aece87dcbfc29bac\n'}]",5,214432,fe9672c0ec74ce6cc43a32b9960aedbc43d4dc5e,15,8,2,14320,,,0,"Update README.md for repo project

Change-Id: I1c7edcc7652ccd70948ecc85aece87dcbfc29bac
",git fetch https://review.opendev.org/openstack/heat refs/changes/32/214432/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ec08811cfe4d933b48f533e2289dfc86e8a8547c,, git clone git://git.openstack.org/openstack/heat, git clone git@github.com:openstack/heat.git,1,1
openstack%2Fheat~master~I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf,openstack/heat,master,I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf,Implement AZ spanning for AWS ASGs,ABANDONED,2014-08-21 23:59:59.000000000,2016-02-19 01:54:03.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6917}, {'_account_id': 7193}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8328}, {'_account_id': 8435}, {'_account_id': 8871}, {'_account_id': 14049}]","[{'number': 1, 'created': '2014-08-21 23:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/540572b39e90680f5a255ab5c24c911fc9acc388', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 2, 'created': '2014-08-22 07:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ce91c9f32e2ca68ff55a32474e5a7161da60aa4b', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 3, 'created': '2014-08-22 07:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4870ecb5b159ba9e670017290583a0a9313bbea8', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 4, 'created': '2014-08-23 05:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2141c8fec084d35f4b1d2446e966ddfdad033888', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 5, 'created': '2014-08-23 05:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/76c6e7da900509547026693b6c64818ee3bb9ab5', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 6, 'created': '2014-08-24 07:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cfb504e327275d1bc80a4b4c00ca2649e6f24689', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 7, 'created': '2014-08-25 06:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d8af85a68160de7ff5ffc6b31969b20fc9bc7b5', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 8, 'created': '2014-08-25 07:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1221d71e62bc07ebaabbbba00ff3bd52cc345cdf', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 9, 'created': '2014-08-26 06:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6e77430d7c4a00253dfb1c8359533837a0a9b617', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 10, 'created': '2014-08-26 13:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c98ad76c3eb368d1580a986d336f5c1c01281dc7', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 11, 'created': '2014-08-27 05:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6e5d3897a98923423e921a1318f42c79087f877c', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 12, 'created': '2014-08-27 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/630319a3f98235d65b3db273772b4f84fab0a892', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 13, 'created': '2014-08-27 14:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/48a4f6cad73d7d12c576376946520d87bd7600a9', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 14, 'created': '2014-08-30 17:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e94abb5bf5e09df759452f48c0fc9a881ee8c3e', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 15, 'created': '2014-08-30 17:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b675302783fcd45be20fb3e693e839479363b516', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 16, 'created': '2014-08-30 18:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c0a4d92bf957450d7022dc6d351d9d716d767835', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 17, 'created': '2014-08-30 18:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6a4afe843055f4ee9ecdad1df2f35274b463700c', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 18, 'created': '2014-08-30 19:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a46f30138c86cb758abe030dfb4e1b2d14b3d390', 'message': 'Implement AZ spanning for ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 19, 'created': '2014-08-31 07:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2d37c344a6027dacac313f0c39ae6b2116df5df1', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 20, 'created': '2014-09-01 05:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/119b5f70f9f91e5c999f96f7544d23c8faacddcc', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 21, 'created': '2014-09-08 22:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8bd8c067fdedadac55b6522a5145527f3d4f916b', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Mike Spreitzer <mspreitz@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 22, 'created': '2014-09-08 22:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/02b4baf90bc5d50f290eec2a51d200f545168def', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 23, 'created': '2014-10-01 15:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/396dc06ede6af6523f0530026556636d963c754e', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 24, 'created': '2014-10-07 21:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1e8081438a32fba1578ec7d0b2df61fc0b1b92a5', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 25, 'created': '2014-10-14 19:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84ed4b3489597e5834f366a647f688801777fd77', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 26, 'created': '2014-10-15 05:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/753830648444ea6f9241377d19ca381f508d6fd9', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 27, 'created': '2014-10-15 05:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1a9127e4b95e858b930607f05212f4f8cf9c12e8', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 28, 'created': '2014-10-15 05:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9ac478376d4b567b8f3289263a029fd3e8a618ef', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 29, 'created': '2014-10-22 15:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c07241031342b4a618932df09ecd5ea065e2fe1d', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 30, 'created': '2015-01-13 15:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/43fe4cb00c97f2376a0e47a1d0ca68d8a894d1f9', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}, {'number': 31, 'created': '2015-03-04 16:38:58.000000000', 'files': ['heat/engine/resources/aws/autoscaling_group.py', 'heat/tests/autoscaling/test_availability_zone.py', 'heat/engine/rsrc_defn.py', 'heat/engine/resources/instance_group.py', 'heat/tests/test_scaling_template.py', 'heat/tests/autoscaling/inline_templates.py', 'heat/tests/test_instance_group.py', 'heat/common/config.py', 'heat/scaling/template.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/298dd76fb27c02a35af198600f7050bd32033212', 'message': 'Implement AZ spanning for AWS ASGs\n\nSee spec https://review.openstack.org/#/c/105907/\n\nImplements: partial-blueprint implement-autoscalinggroup-availabilityzones\nCo-Authored-By: Bill Arnold <barnold@us.ibm.com>\nCo-Authored-By: Karolyn Chambers <chamberk@us.ibm.com>\nChange-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf\n'}]",51,116139,298dd76fb27c02a35af198600f7050bd32033212,111,12,31,8328,,,0,"Implement AZ spanning for AWS ASGs

See spec https://review.openstack.org/#/c/105907/

Implements: partial-blueprint implement-autoscalinggroup-availabilityzones
Co-Authored-By: Bill Arnold <barnold@us.ibm.com>
Co-Authored-By: Karolyn Chambers <chamberk@us.ibm.com>
Change-Id: I1e870cc16f12bbba5f6aba03edf54d8dc01a06cf
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/116139/16 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/scaling/template.py']",2,540572b39e90680f5a255ab5c24c911fc9acc388,bp/implement-autoscalinggroup-availabilityzones,"from heat.engine import rsrc_defn num_resources, num_replace, azs=[], az_prop_path=None): """"""Generate the template for nested stack of existing and new instances. This is a generator of (string resource_name, string resource_definition) tuples. This generator generates a new template that can differ from the old by dropping some old resources, giving an alternate definition (i.e., imply update) for some old resources, and adding some new resources. First the desired number of retained resources is generated in the same order as they appear in the input and then enough new resources are generated to reach the requested total. Amongst the retained instances, the first num_replace whose old definition differs from the latest definition are given the latest definition and the remainder (if any) retain their old definition. The option to revise some, but not all, of the old resources is exercised in the case of rolling update. The option to ignore some old resources is used when replacing unhealthy members. :param old_resources: the old template as a list[(string resource_name, string resource_definition)] :param resource_definition: the latest json snippet defining a member :param num_resources: total number of resources to generate :param num_replace: max number of retained old resources to update :param azs: list of availability zones to spread memebers across :param az_prop_path: where AZ is found in resource definition survey = {} for i in range(min(num_resources, len(old_resources))): old_name, old_template = old_resources[i] if azs: az = _get_az(old_template, az_prop_path) survey[az] = 1 + survey.get(az, 0) if old_template != resource_definition and num_replace > 0: num_replace -= 1 if azs: _set_az(resource_definition, az_prop_path, az) yield old_name, resource_definition else: yield old_name, old_template if num_create <= 0: return rem = num_create need = {} for az in azs: need[az] = 0 pops = list(survey.values) pops.sort() for i in range(len(pops)): p = pops[i] lim = pops[i + 1] - p if i + 1 < len(pops) else rem zs = [z for z, pz in survey if pz <= p] nzs = len(zs) avg = rem / float(nzs) if lim >= avg: lo = int(avg) nhi = rem - lo * nzs for j in range(nzs): z = zs[j] need[z] += lo + (1 if j < nhi else 0) break for z in zs: need[z] += lim rem -= nzs * lim for i in range(num_create): if azs: az = need.keys()[0] _set_az(resource_definition, az_prop_path, az) need[az] -= 1 if need[az] <= 0: del need[az] yield short_id.generate_id(), resource_definition def _get_az(resource_definition, az_prop_path): props = resource_definition[rsrc_defn.PROPERTIES] for k in az_prop_path: props = props[k] return props def _set_az(resource_definition, az_prop_path, az): path = [rsrc_defn.PROPERTIES] + az_prop_path for i in range(len(az_prop_path)): k = az_prop_path[i] if (i + 1 < len(az_prop_path)): if not hasattr(resource_definition, k): resource_definition[k] = {} resource_definition = resource_definition[k] else: resource_definition[k] = az"," num_resources, num_replace): """""" for i in range(num_resources): if i < len(old_resources): old_name, old_template = old_resources[i] if old_template != resource_definition and num_replace > 0: num_replace -= 1 yield old_name, resource_definition else: yield old_name, old_template else: yield short_id.generate_id(), resource_definition",120,17
openstack%2Fheat~master~I8454cb6b79b62e5cc1043ead33550a01ed6fd86a,openstack/heat,master,I8454cb6b79b62e5cc1043ead33550a01ed6fd86a,Refactor unit test test_neutron_autoscaling,ABANDONED,2014-07-02 03:38:33.000000000,2016-02-19 01:52:16.000000000,,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8246}, {'_account_id': 10018}]","[{'number': 1, 'created': '2014-07-02 03:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5c564fe10d5cb7233f6167f11011cfa064d6f0bc', 'message': 'Refactor unit test test_neutron_autoscaling\n\nrefactor test_neutron_autoscaling, make it easier to add\nnew tests.\n\n- remove redundant resources: monitor, pool. These are already\n  tested in test_neutron.\n- make stub funtions reusable\n\nChange-Id: I8454cb6b79b62e5cc1043ead33550a01ed6fd86a\nRelated-Bug: #1310602\n'}, {'number': 2, 'created': '2014-07-02 11:55:54.000000000', 'files': ['heat/tests/test_neutron_autoscaling.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/81a67aa86ec7b03c83b03188d543b1e0810aadf4', 'message': 'Refactor unit test test_neutron_autoscaling\n\nrefactor test_neutron_autoscaling, make it easier to add\nnew tests.\n\n- remove try_import neutronclient\n- remove redundant resources: monitor, pool. These are already\n  tested in test_neutron.\n- make stub funtions reusable\n\nChange-Id: I8454cb6b79b62e5cc1043ead33550a01ed6fd86a\nRelated-Bug: #1310602\n'}]",4,104061,81a67aa86ec7b03c83b03188d543b1e0810aadf4,16,4,2,10018,,,0,"Refactor unit test test_neutron_autoscaling

refactor test_neutron_autoscaling, make it easier to add
new tests.

- remove try_import neutronclient
- remove redundant resources: monitor, pool. These are already
  tested in test_neutron.
- make stub funtions reusable

Change-Id: I8454cb6b79b62e5cc1043ead33550a01ed6fd86a
Related-Bug: #1310602
",git fetch https://review.opendev.org/openstack/heat refs/changes/61/104061/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_neutron_autoscaling.py'],1,5c564fe10d5cb7233f6167f11011cfa064d6f0bc,bug/1310602,"from heat.engine.resources import glance_utils ""SubnetId"": {""Type"": ""String""}, ""PoolId"":{""Type"": ""String""} 'pool_id': { ""Ref"": ""PoolId"" } params = {'KeyName': 'test', 'ImageId': 'fake_imageId', 'SubnetId': 'fake_subnetId', 'PoolId': 'fake_poolId'} def _stub_ins_add(self, num): self.m.StubOutWithMock(glance_utils, 'get_image_id') self.m.StubOutWithMock(nova_utils, 'get_flavor_id') self.m.StubOutWithMock(clients.OpenStackClients, 'nova') self.m.StubOutWithMock(self.fc.servers, 'create') image.ImageConstraint.validate(mox.IgnoreArg(), mox.IgnoreArg())\ .MultipleTimes().AndReturn(True) glance_utils.get_image_id(mox.IgnoreArg(), self.params['ImageId'])\ .MultipleTimes().AndReturn(self.params['ImageId']) nova_utils.get_flavor_id(mox.IgnoreArg(), 'bar')\ .MultipleTimes().AndReturn('bar') clients.OpenStackClients.nova().MultipleTimes().AndReturn(self.fc) def _stub_create_instance(return_server): self.fc.servers.create( image=self.params['ImageId'], flavor='bar', key_name=None, name=mox.IgnoreArg(), scheduler_hints=None, meta=mox.IgnoreArg(), nics=None, availability_zone=None, security_groups=None, userdata=mox.IgnoreArg()).AndReturn( return_server) instances = [] for x in range(num): instid = str(uuid.uuid4()) class Server(object): def __init__(self, id): self.id = id return_server = Server(instid) _stub_create_instance(return_server) instances.append(instid) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(False) instance.Instance.check_create_complete(mox.IgnoreArg())\ .MultipleTimes().AndReturn(True) return instances def _stub_member_add(self, instances): self.m.StubOutWithMock(nova_utils, 'server_to_ipaddress') self.m.StubOutWithMock(clients.neutronclient.Client, 'create_member') lb_members = {} for ins in instances: nova_utils.server_to_ipaddress(mox.IgnoreArg(), ins)\ .InAnyOrder().AndReturn('mock ip') member_block = { 'member': { 'protocol_port': 8080, 'pool_id': self.params['PoolId'], 'address': 'mock ip' } } lb_member = copy.deepcopy(member_block) lb_member['member']['id'] = str(uuid.uuid4()) clients.neutronclient.Client.create_member(member_block)\ .InAnyOrder().AndReturn(lb_member) lb_members[ins] = lb_member['member']['id'] return lb_members def test_lb_create(self): t = template_format.parse(as_template) properties = t['Resources']['SvrGrp']['Properties'] properties['DesiredCapacity'] = '2' stack = utils.parse_stack(t, params=self.params) instances = self._stub_ins_add(2) self._stub_member_add(instances) self.assertEqual((stack.CREATE, stack.COMPLETE), members = stack['ElasticLoadBalancer'].properties['members'] self.assertEqual(2, len(members)) self.m.VerifyAll() def test_lb_update(self): t = template_format.parse(as_template) properties = t['Resources']['SvrGrp']['Properties'] properties['DesiredCapacity'] = '2' stack = utils.parse_stack(t, params=self.params) instances = self._stub_ins_add(2) self._stub_member_add(instances) self.m.ReplayAll() stack.store() stack.create() self.assertEqual((stack.CREATE, stack.COMPLETE), stack.state) members = db_api.resource_data_get_all(stack['ElasticLoadBalancer']) self.assertEqual(2, len(members.keys())) self.m.VerifyAll() self.m.UnsetStubs() tmpl2 = copy.deepcopy(t) stack_update = utils.parse_stack(tmpl2, params=self.params) instances = self._stub_ins_add(1) self._stub_member_add(instances) self.m.ReplayAll() stack2.update(stack_update)","from heat.engine import environmentfrom heat.engine import template ""SubnetId"": {""Type"": ""String""} ""VPCZoneIdentifier"": [ { ""Ref"": ""SubnetId"" } ], ""myMonitor"": { ""Type"": ""OS::Neutron::HealthMonitor"", ""Properties"": { ""type"": ""HTTP"", ""delay"": 3, ""max_retries"": 5, ""timeout"": 10 } }, ""myPool"": { ""Type"": ""OS::Neutron::Pool"", ""Properties"": { ""description"": ""Test Pool"", ""lb_method"": ""ROUND_ROBIN"", ""monitors"": [ { ""Ref"": ""myMonitor"" } ], ""name"": ""Test_Pool"", ""protocol"": ""HTTP"", ""subnet_id"": { ""Ref"": ""SubnetId"" }, ""vip"": { ""description"": ""Test VIP"", ""connection_limit"": 1000, ""address"": ""10.0.3.121"", ""protocol_port"": 80, ""name"": ""test_vip"" } } }, 'pool_id': { ""Ref"": ""myPool"" } params = {'KeyName': 'test', 'ImageId': 'foo'} self.m.StubOutWithMock(clients.neutronclient.Client, 'create_health_monitor') self.m.StubOutWithMock(clients.neutronclient.Client, 'associate_health_monitor') self.m.StubOutWithMock(clients.neutronclient.Client, 'create_pool') self.m.StubOutWithMock(clients.neutronclient.Client, 'create_vip') self.m.StubOutWithMock(clients.neutronclient.Client, 'show_pool') self.m.StubOutWithMock(clients.neutronclient.Client, 'show_vip') self.m.StubOutWithMock(clients.neutronclient.Client, 'create_member') self.m.StubOutWithMock(clients.neutronclient.Client, 'list_members') self.m.StubOutWithMock(nova_utils, 'server_to_ipaddress') self.m.StubOutWithMock(parser.Stack, 'validate') self.m.StubOutWithMock(instance.Instance, 'handle_create') def test_lb(self): tmpl = template_format.parse(as_template) network_body = { ""network"": { ""id"": str(uuid.uuid4()), ""name"": ""testnet"", ""admin_state_up"": True } } subnet_body = { ""subnet"": { ""name"": ""testsubnet"", ""id"": str(uuid.uuid4()), ""network_id"": network_body['network']['id'], ""ip_version"": 4, ""cidr"": ""10.0.3.0/24"", ""allocation_pools"": [ { ""start"": ""10.0.3.20"", ""end"": ""10.0.3.150"" } ], ""gateway_ip"": ""10.0.3.1"" } } self.params[""SubnetId""] = subnet_body['subnet']['id'] mon_block = { 'health_monitor': tmpl['Resources']['myMonitor']['Properties'] } mon_block['health_monitor']['admin_state_up'] = True mon_ret_block = copy.deepcopy(mon_block) mon_ret_block['health_monitor']['id'] = str(uuid.uuid4()) mon_ret_block['health_monitor']['status'] = 'ACTIVE' pool_block = {'pool': {}} tmp_pool_block = tmpl['Resources']['myPool']['Properties'] for val in ['lb_method', 'protocol', 'name', 'description']: pool_block['pool'][val] = tmp_pool_block[val] pool_block['pool']['admin_state_up'] = True pool_block['pool']['subnet_id'] = self.params['SubnetId'] pool_block['pool']['admin_state_up'] = True pool_ret_block = copy.deepcopy(pool_block) pool_ret_block['pool']['id'] = str(uuid.uuid4()) pool_ret_block['pool']['status'] = 'ACTIVE' tmp_vip_block = tmp_pool_block.pop('vip') vip_block = { 'vip': { 'protocol': pool_block['pool']['protocol'], 'description': tmp_vip_block['description'], 'admin_state_up': True, 'subnet_id': self.params['SubnetId'], 'connection_limit': tmp_vip_block['connection_limit'], 'pool_id': pool_ret_block['pool']['id'], 'address': tmp_vip_block['address'], 'protocol_port': tmp_vip_block['protocol_port'], 'name': tmp_vip_block['name'] } } vip_ret_block = copy.deepcopy(vip_block) vip_ret_block['vip']['id'] = str(uuid.uuid4()) vip_ret_block['vip']['status'] = 'ACTIVE' port_block = { 'port': { 'network_id': network_body['network']['id'], 'fixed_ips': [ { 'subnet_id': subnet_body['subnet']['id'], } ], 'admin_state_up': True } } port_ret_block = copy.deepcopy(port_block) port_ret_block['port']['id'] = str(uuid.uuid4()) membera_block = { 'member': { 'protocol_port': 8080, 'pool_id': pool_ret_block['pool']['id'], 'address': '1.2.3.4' } } membera_ret_block = copy.deepcopy(membera_block) membera_ret_block['member']['id'] = str(uuid.uuid4()) memberb_block = { 'member': { 'protocol_port': 8080, 'pool_id': pool_ret_block['pool']['id'], 'address': '1.2.3.5' } } memberb_ret_block = copy.deepcopy(memberb_block) memberb_ret_block['member']['id'] = str(uuid.uuid4()) memberc_block = { 'member': { 'protocol_port': 8080, 'pool_id': pool_ret_block['pool']['id'], 'address': '1.2.3.6' } } memberc_ret_block = copy.deepcopy(memberc_block) memberc_ret_block['member']['id'] = str(uuid.uuid4()) class id_type(object): def __init__(self, id, name): self.id = id self.name = name instances = {} clients.neutronclient.Client.create_health_monitor(mon_block).\ AndReturn(mon_ret_block) clients.neutronclient.Client.create_pool(pool_block).\ AndReturn(pool_ret_block) clients.neutronclient.Client.associate_health_monitor( pool_ret_block['pool']['id'], {'health_monitor': { 'id': mon_ret_block['health_monitor']['id'] }}).AndReturn(None) clients.neutronclient.Client.create_vip(vip_block).\ AndReturn(vip_ret_block) clients.neutronclient.Client.show_pool(pool_ret_block['pool']['id']).\ AndReturn(pool_ret_block) clients.neutronclient.Client.show_vip(vip_ret_block['vip']['id']).\ AndReturn(vip_ret_block) parser.Stack.validate() instid = str(uuid.uuid4()) instance.Instance.handle_create().AndReturn(instid) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(False) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(True) image.ImageConstraint.validate( mox.IgnoreArg(), mox.IgnoreArg()).MultipleTimes().AndReturn(True) nova_utils.server_to_ipaddress( mox.IgnoreArg(), mox.IgnoreArg()).AndReturn('1.2.3.4') clients.neutronclient.Client.create_member(membera_block).\ AndReturn(membera_ret_block) instances[instid] = membera_ret_block['member']['id'] # Start of update parser.Stack.validate() instid = str(uuid.uuid4()) instance.Instance.handle_create().AndReturn(instid) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(False) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(True) instances[instid] = memberb_ret_block['member']['id'] instid = str(uuid.uuid4()) instance.Instance.handle_create().AndReturn(instid) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(False) instance.Instance.check_create_complete(mox.IgnoreArg())\ .AndReturn(True) nova_utils.server_to_ipaddress( mox.IgnoreArg(), mox.IgnoreArg()).AndReturn('1.2.3.5') clients.neutronclient.Client.create_member(memberb_block).\ AndReturn(memberb_ret_block) nova_utils.server_to_ipaddress( mox.IgnoreArg(), mox.IgnoreArg()).AndReturn('1.2.3.6') clients.neutronclient.Client.create_member(memberc_block).\ AndReturn(memberc_ret_block) # Start of stack create env = {'parameters': self.params} tmpl = template_format.parse(as_template) stack = parser.Stack(self.ctx, 'update_test_stack', template.Template(tmpl), environment.Environment(env)) self.assertEqual((parser.Stack.CREATE, parser.Stack.COMPLETE), tmpl2 = copy.deepcopy(tmpl) update_stack = parser.Stack(self.ctx, 'update_test_stack', template.Template(tmpl2), environment.Environment(env)) stack2.update(update_stack) self.assertEqual((parser.Stack.UPDATE, parser.Stack.COMPLETE), stack2.state) ",113,258
openstack%2Fproject-config~master~Ia7004a5fb89f60ab48e8b1df600ae43f3a09a27d,openstack/project-config,master,Ia7004a5fb89f60ab48e8b1df600ae43f3a09a27d,Use config drive in Neutron jobs,ABANDONED,2016-02-18 05:28:09.000000000,2016-02-19 01:51:53.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-18 05:28:09.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7a7b21480d5786acdaebd9eaeb49fba644e1ce32', 'message': 'Use config drive in Neutron jobs\n\nThe metadata service is now gone by default so we\nneed to enable config drive. Another alternative\nwould be to enable the ec2-api service so we can\nstill exercise metadata.\n\nChange-Id: Ia7004a5fb89f60ab48e8b1df600ae43f3a09a27d\n'}]",0,281633,7a7b21480d5786acdaebd9eaeb49fba644e1ce32,8,5,1,7787,,,0,"Use config drive in Neutron jobs

The metadata service is now gone by default so we
need to enable config drive. Another alternative
would be to enable the ec2-api service so we can
still exercise metadata.

Change-Id: Ia7004a5fb89f60ab48e8b1df600ae43f3a09a27d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/281633/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,7a7b21480d5786acdaebd9eaeb49fba644e1ce32,no_metadata_neutron,, export DEVSTACK_GATE_CONFIGDRIVE=0 export DEVSTACK_GATE_CONFIGDRIVE=0 export DEVSTACK_GATE_CONFIGDRIVE=0 export DEVSTACK_GATE_CONFIGDRIVE=0,0,4
openstack%2Fpython-openstackclient~master~I4910263449ff3d49c4ee44a6ef7a7762875fe76f,openstack/python-openstackclient,master,I4910263449ff3d49c4ee44a6ef7a7762875fe76f,Remove unused test-requirments,MERGED,2016-02-18 14:53:19.000000000,2016-02-19 01:51:32.000000000,2016-02-19 01:51:32.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-18 14:53:19.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/444fc6149db58361e5329e3f05eb8f056fb7479a', 'message': 'Remove unused test-requirments\n\nWebOb is not needed in our test code.\nSo remove it to make less dependences.\n\nChange-Id: I4910263449ff3d49c4ee44a6ef7a7762875fe76f\n'}]",0,281895,444fc6149db58361e5329e3f05eb8f056fb7479a,12,4,1,17081,,,0,"Remove unused test-requirments

WebOb is not needed in our test code.
So remove it to make less dependences.

Change-Id: I4910263449ff3d49c4ee44a6ef7a7762875fe76f
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/95/281895/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,444fc6149db58361e5329e3f05eb8f056fb7479a,remove-requirments,,WebOb>=1.2.3 # MIT,0,1
openstack%2Fpython-solumclient~master~Ie8e0e9a3fa6c18b91f50d6f9b87b45acfdb6674f,openstack/python-solumclient,master,Ie8e0e9a3fa6c18b91f50d6f9b87b45acfdb6674f,Validate scale target input,MERGED,2016-02-17 16:00:14.000000000,2016-02-19 01:48:59.000000000,2016-02-19 01:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 9095}]","[{'number': 1, 'created': '2016-02-17 16:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/59e94eb1558d9f17d145a8d4cc2232caf552c93f', 'message': 'Validate scale target input\n\nChange-Id: Ie8e0e9a3fa6c18b91f50d6f9b87b45acfdb6674f\nCloses-Bug: #1546617\n'}, {'number': 2, 'created': '2016-02-17 16:40:48.000000000', 'files': ['solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/3dc9e56db9c33eb6d903da0bfb7d088163e05a41', 'message': 'Validate scale target input\n\nChange-Id: Ie8e0e9a3fa6c18b91f50d6f9b87b45acfdb6674f\nCloses-Bug: #1546617\n'}]",1,281353,3dc9e56db9c33eb6d903da0bfb7d088163e05a41,14,3,2,7230,,,0,"Validate scale target input

Change-Id: Ie8e0e9a3fa6c18b91f50d6f9b87b45acfdb6674f
Closes-Bug: #1546617
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/53/281353/1 && git format-patch -1 --stdout FETCH_HEAD,['solumclient/solum.py'],1,59e94eb1558d9f17d145a8d4cc2232caf552c93f,bug/1546617," target = args.target try: target = int(target) except ValueError: msg = ""Must provide integer value for scale target."" raise exc.CommandException(message=msg) if target <= 0: msg = ""Scale target must be greater than zero."" raise exc.CommandException(message=msg) ",,11,0
openstack%2Fdiskimage-builder~master~I5867ecd57834eece9477aa9ea4b8bdd70e238084,openstack/diskimage-builder,master,I5867ecd57834eece9477aa9ea4b8bdd70e238084,Don't remove python3 & grubby in 99-remove-extra-packages,MERGED,2015-11-25 03:41:47.000000000,2016-02-19 01:46:38.000000000,2016-02-19 01:46:37.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7118}, {'_account_id': 10035}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-11-25 03:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/819d0e24a6aedf571f98d70b62c9905517722ca7', 'message': 'Don\'t remove python3 & grubby in 99-remove-extra-packages\n\npython3 is a hard requirement of dnf so can\'t be removed [1]\n\ngrubby is also required for kernel installs on Fedora.  For too much\ndetail see I1a6e45d04755515286b3d49f8280c16b527e2f48; but the kernel,\nvia dracut, now has this as a ""reccommends"" due to people removing it\nand making unbootable systems.\n\nWhile we\'re here, wrap the line to make it easier to read\n\n[1] http://logs.openstack.org/76/248976/2/check/gate-dib-dsvm-functests-devstack-f21/734c8bd/console.html\n\nChange-Id: I5867ecd57834eece9477aa9ea4b8bdd70e238084\n'}, {'number': 2, 'created': '2015-11-25 04:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/74c48b911654d48423e0ffe1d8de2fabc724fd2a', 'message': 'Don\'t remove python3 & grubby in 99-remove-extra-packages\n\npython3 is a hard requirement of dnf so can\'t be removed [1]\n\ngrubby is also required for kernel installs on Fedora.  For too much\ndetail see I1a6e45d04755515286b3d49f8280c16b527e2f48; but the kernel,\nvia dracut, now has this as a ""reccommends"" due to people removing it\nand making unbootable systems.\n\nWhile we\'re here, wrap the line to make it easier to read\n\n[1] http://logs.openstack.org/76/248976/2/check/gate-dib-dsvm-functests-devstack-f21/734c8bd/console.html\n\nChange-Id: I5867ecd57834eece9477aa9ea4b8bdd70e238084\n'}, {'number': 3, 'created': '2015-12-02 07:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7b862df31c7369b99118ca09723a288018376777', 'message': 'Don\'t remove python3 & grubby in 99-remove-extra-packages\n\npython3 is a hard requirement of dnf so can\'t be removed [1]\n\ngrubby is also required for kernel installs on Fedora.  For too much\ndetail see I1a6e45d04755515286b3d49f8280c16b527e2f48; but the kernel,\nvia dracut, now has this as a ""reccommends"" due to people removing it\nand making unbootable systems.\n\nWhile we\'re here, wrap the line to make it easier to read\n\n[1] http://logs.openstack.org/76/248976/2/check/gate-dib-dsvm-functests-devstack-f21/734c8bd/console.html\n\nChange-Id: I5867ecd57834eece9477aa9ea4b8bdd70e238084\n'}, {'number': 4, 'created': '2016-02-16 02:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c67e1ef9bc5d6e43a5d9c402635da10ade5e12b2', 'message': 'Don\'t remove python3 & grubby in 99-remove-extra-packages\n\npython3 is a hard requirement of dnf so can\'t be removed [1]\n\ngrubby is also required for kernel installs on Fedora.  For too much\ndetail see I1a6e45d04755515286b3d49f8280c16b527e2f48; but the kernel,\nvia dracut, now has this as a ""reccommends"" due to people removing it\nand making unbootable systems.\n\nWhile we\'re here, wrap the line to make it easier to read\n\n[1] http://logs.openstack.org/76/248976/2/check/gate-dib-dsvm-functests-devstack-f21/734c8bd/console.html\n\nChange-Id: I5867ecd57834eece9477aa9ea4b8bdd70e238084\n'}, {'number': 5, 'created': '2016-02-16 02:40:30.000000000', 'files': ['elements/ironic-agent/finalise.d/99-remove-extra-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b960614c9c75a339b23f6309ece2f8945ab75bff', 'message': 'Don\'t remove python3 & grubby in 99-remove-extra-packages\n\npython3 is a hard requirement of dnf so can\'t be removed [1]\n\ngrubby is also required for kernel installs on Fedora.  For too much\ndetail see I1a6e45d04755515286b3d49f8280c16b527e2f48; but the kernel,\nvia dracut, now has this as a ""recommends"" due to people removing it\nand making unbootable systems.\n\n[1] http://logs.openstack.org/76/248976/2/check/gate-dib-dsvm-functests-devstack-f21/734c8bd/console.html\n\nChange-Id: I5867ecd57834eece9477aa9ea4b8bdd70e238084\n'}]",0,249541,b960614c9c75a339b23f6309ece2f8945ab75bff,55,6,5,7118,,,0,"Don't remove python3 & grubby in 99-remove-extra-packages

python3 is a hard requirement of dnf so can't be removed [1]

grubby is also required for kernel installs on Fedora.  For too much
detail see I1a6e45d04755515286b3d49f8280c16b527e2f48; but the kernel,
via dracut, now has this as a ""recommends"" due to people removing it
and making unbootable systems.

[1] http://logs.openstack.org/76/248976/2/check/gate-dib-dsvm-functests-devstack-f21/734c8bd/console.html

Change-Id: I5867ecd57834eece9477aa9ea4b8bdd70e238084
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/41/249541/5 && git format-patch -1 --stdout FETCH_HEAD,['elements/ironic-agent/finalise.d/99-remove-extra-packages'],1,819d0e24a6aedf571f98d70b62c9905517722ca7,python3-grubby-f23, install-packages -e kernel-debug-devel gcc \ fedora-logos rsync \ sudo pykickstart \ make genisoimage tcpdump man-db \ policycoreutils kbd-misc plymouth cronie, install-packages -e kernel-debug-devel gcc fedora-logos python3 rsync sudo pykickstart grubby make genisoimage tcpdump man-db policycoreutils kbd-misc plymouth cronie,5,1
openstack%2Frally~master~Icb66f3b98fad0745ee3697e3c71af8a281770dc2,openstack/rally,master,Icb66f3b98fad0745ee3697e3c71af8a281770dc2,Release notes for 0.3.1,MERGED,2016-02-18 16:53:17.000000000,2016-02-19 01:43:38.000000000,2016-02-19 01:43:37.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-18 16:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b9c1bc5ed655a70a3473e5e2921ef0385f7925e2', 'message': 'Release notes for 0.3.1\n\nChange-Id: Icb66f3b98fad0745ee3697e3c71af8a281770dc2\n'}, {'number': 2, 'created': '2016-02-18 17:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1b77a4ae26502aafa837f788c3d697f9e02b2794', 'message': 'Release notes for 0.3.1\n\nChange-Id: Icb66f3b98fad0745ee3697e3c71af8a281770dc2\n'}, {'number': 3, 'created': '2016-02-18 17:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c4c05abac9467516fc7c3f9b5dde83b836552ead', 'message': 'Release notes for 0.3.1\n\nChange-Id: Icb66f3b98fad0745ee3697e3c71af8a281770dc2\n'}, {'number': 4, 'created': '2016-02-18 22:19:41.000000000', 'files': ['doc/release_notes/latest.rst', 'doc/release_notes/archive/v0.3.1.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/1b6e9e9219b143c685a2af134ab025dddd72ed27', 'message': 'Release notes for 0.3.1\n\nChange-Id: Icb66f3b98fad0745ee3697e3c71af8a281770dc2\n'}]",0,281959,1b6e9e9219b143c685a2af134ab025dddd72ed27,19,7,4,9545,,,0,"Release notes for 0.3.1

Change-Id: Icb66f3b98fad0745ee3697e3c71af8a281770dc2
",git fetch https://review.opendev.org/openstack/rally refs/changes/59/281959/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/release_notes/latest.rst', 'doc/release_notes/archive/v0.3.1.rst']",2,b9c1bc5ed655a70a3473e5e2921ef0385f7925e2,0.3.1,"============ Rally v0.3.1 ============ Information ----------- +------------------+-----------------------+ | Commits | **9** | +------------------+-----------------------+ | Bug fixes | **6** | +------------------+-----------------------+ | Dev cycle | **2 days** | +------------------+-----------------------+ | Release date | **2/18/2016** | +------------------+-----------------------+ Details ------- This release is more about bug-fixes than features. .. warning:: Please, update 0.3.0 to latest one. Features ~~~~~~~~ * Pass api_versions info to glance images context * [Verify] Don't create new flavor when flavor already exists Bug fixes ~~~~~~~~~ **6 bugs were fixed, the most critical are**: * #1545889: Existing deployment with given endpoint doesn't work anymore * #1547092: Insecure doesn't work with Rally 0.3.0 * #1547083: Rally Cleanup failed with api_versions context in 0.3.0 release * #1544522: Non-existing ""called_once_with"" method of Mock library is used ",,46,1
openstack%2Fsenlin~master~Ia4d8cbe17705a9cd679cefa3e1b7a65f0d4a0c27,openstack/senlin,master,Ia4d8cbe17705a9cd679cefa3e1b7a65f0d4a0c27,Rename SenlinBadRequest to BadRequest,MERGED,2016-02-18 06:17:19.000000000,2016-02-19 01:40:23.000000000,2016-02-19 01:40:22.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-18 06:17:19.000000000', 'files': ['senlin/tests/unit/engine/service/test_cluster_policies.py', 'senlin/tests/unit/engine/service/test_policies.py', 'senlin/tests/unit/engine/service/test_webhooks.py', 'senlin/tests/unit/apiv1/test_clusters.py', 'senlin/api/middleware/fault.py', 'senlin/tests/unit/engine/service/test_profiles.py', 'senlin/tests/unit/apiv1/test_receivers.py', 'senlin/tests/unit/engine/service/test_nodes.py', 'senlin/tests/unit/engine/service/test_receivers.py', 'senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py', 'senlin/common/exception.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/c1806049de0a459749d020f9adf3bf0429a991aa', 'message': ""Rename SenlinBadRequest to BadRequest\n\nThis patch proposes a rename of 'SenlinBadRequest' to 'BadRequest'.\nPrefixing an exception type name with 'Senlin' doesn't help much in\nmaking things cleaner. It is only help make the code wordy.\n\nChange-Id: Ia4d8cbe17705a9cd679cefa3e1b7a65f0d4a0c27\n""}]",0,281656,c1806049de0a459749d020f9adf3bf0429a991aa,7,3,1,8246,,,0,"Rename SenlinBadRequest to BadRequest

This patch proposes a rename of 'SenlinBadRequest' to 'BadRequest'.
Prefixing an exception type name with 'Senlin' doesn't help much in
making things cleaner. It is only help make the code wordy.

Change-Id: Ia4d8cbe17705a9cd679cefa3e1b7a65f0d4a0c27
",git fetch https://review.opendev.org/openstack/senlin refs/changes/56/281656/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/service/test_cluster_policies.py', 'senlin/tests/unit/engine/service/test_policies.py', 'senlin/tests/unit/engine/service/test_webhooks.py', 'senlin/tests/unit/apiv1/test_clusters.py', 'senlin/api/middleware/fault.py', 'senlin/tests/unit/engine/service/test_profiles.py', 'senlin/tests/unit/apiv1/test_receivers.py', 'senlin/tests/unit/engine/service/test_nodes.py', 'senlin/tests/unit/engine/service/test_receivers.py', 'senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py', 'senlin/common/exception.py']",12,c1806049de0a459749d020f9adf3bf0429a991aa,rename-bad-request,class BadRequest(SenlinException):,class SenlinBadRequest(SenlinException):,93,93
openstack%2Fmonasca-agent~master~I16a1ee10cfad0bcdd624328cf4a54a34a8038f36,openstack/monasca-agent,master,I16a1ee10cfad0bcdd624328cf4a54a34a8038f36,Detect Endpoint Changes in Http Check,MERGED,2016-02-09 23:25:31.000000000,2016-02-19 01:33:10.000000000,2016-02-19 01:33:10.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 8532}, {'_account_id': 11809}, {'_account_id': 12133}, {'_account_id': 14273}, {'_account_id': 15027}, {'_account_id': 16688}, {'_account_id': 18179}]","[{'number': 1, 'created': '2016-02-09 23:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/efca2fac79cdc2aec0f7a963f2aef97d4b83b2b8', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}, {'number': 2, 'created': '2016-02-09 23:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/3796a8385382e55f26966d6eebf485998aadb13e', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}, {'number': 3, 'created': '2016-02-12 15:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/d28a36fc2ea5307a128e37738b4b702011244412', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}, {'number': 4, 'created': '2016-02-12 17:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/2679e256a1ca5603dfd57214f6cc5fcd87b5ccca', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}, {'number': 5, 'created': '2016-02-12 19:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/39889b2dcff339370eeda8b6641c4671954739b3', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}, {'number': 6, 'created': '2016-02-16 18:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/64e8ed6b7ab6dbb83737a6f78ffe13082a63db33', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}, {'number': 7, 'created': '2016-02-18 20:46:07.000000000', 'files': ['monasca_setup/agent_config.py', 'monasca_setup/main.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/589bdb9551259741c6e8972c32eff4fcbaabd741', 'message': 'Detect Endpoint Changes in Http Check\n\nIn monasca agent, detect protocol changes on urls in http check.\nIf the protocal changed, remove the old instance in http_check.yaml and\nmerge in the new one.\n\nChange-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36\n'}]",14,278144,589bdb9551259741c6e8972c32eff4fcbaabd741,27,9,7,18179,,,0,"Detect Endpoint Changes in Http Check

In monasca agent, detect protocol changes on urls in http check.
If the protocal changed, remove the old instance in http_check.yaml and
merge in the new one.

Change-Id: I16a1ee10cfad0bcdd624328cf4a54a34a8038f36
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/44/278144/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_setup/agent_config.py', 'monasca_setup/main.py']",2,efca2fac79cdc2aec0f7a963f2aef97d4b83b2b8,bug/detect_endpoint_changes," if key is ""http_check"": old_config_urls = [i['url'] for i in old_config['instances'] if 'url' in i] value, old_config = agent_config.check_endpoint_changes(value, old_config) value_urls = [i['url'] for i in value['instances'] if 'url' in i] if key is ""http_check"": if value_urls is old_config_urls: # Don't write config if no change continue else: if value is old_config: continue", if value == old_config: # Don't write config if no change continue,44,2
openstack%2Fkolla~master~I320341c1a646eeeec35fb928a970f4d7e8a13bb9,openstack/kolla,master,I320341c1a646eeeec35fb928a970f4d7e8a13bb9,Refined documentation regarding registry,MERGED,2016-02-18 22:40:41.000000000,2016-02-19 01:32:39.000000000,2016-02-19 01:32:39.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-18 22:40:41.000000000', 'files': ['doc/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2ccb83cee19425ca081a0c106b097ec3da861ed0', 'message': 'Refined documentation regarding registry\n\nThe documentation had old information about running\ndocker registry version 1.  Documentation improvement\nuses exclusively Docker register version 2.\n\nTrivialFix\n\nChange-Id: I320341c1a646eeeec35fb928a970f4d7e8a13bb9\n'}]",0,282084,2ccb83cee19425ca081a0c106b097ec3da861ed0,7,3,1,18032,,,0,"Refined documentation regarding registry

The documentation had old information about running
docker registry version 1.  Documentation improvement
uses exclusively Docker register version 2.

TrivialFix

Change-Id: I320341c1a646eeeec35fb928a970f4d7e8a13bb9
",git fetch https://review.opendev.org/openstack/kolla refs/changes/84/282084/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/quickstart.rst'],1,2ccb83cee19425ca081a0c106b097ec3da861ed0,,"The Docker registry prior to version 2.3 has extremely bad performanceThe Kolla community recommends using registry 2.3 or later. To deploy registry 2.3 do the following: Note: Kolla looks for the Docker registry to use port 4000. (Docker default is port 5000) After enabling the registry, it is necessary to instruct Docker that it will","Currently, the Docker registry v2 has extremely bad performanceThere are two ways to set up a local docker registry. Either use packages or pull the registry container from the Docker Hub. The packaged Docker registry is v1 and the container is v2. For CentOS, the Docker registry v1 is a good alternative while Docker works to solve the v2 github issue mentioned above. Unfortunately, not all distributions package docker-registry. Note that the v1 registry can be run from Docker containers by using the registry:latest tag. However, the current latest tag is broken and crashes on startup. Therefore, on Centos use the follow operations to start the docker-registry v1: :: # CentOS yum install docker-registry sed -i ""s/REGISTRY_PORT=5000/REGISTRY_PORT=4000/g"" /etc/sysconfig/docker-registry systemctl daemon-reload systemctl enable docker-registry systemctl start docker-registry If not using CentOS or Docker registry version 2 is desired, run the following command:Note: Kolla looks for the Docker registry to use port 4000. (Docker default is port 5000) After enabling the registry, it is necessary to instruct docker that it will",6,25
openstack%2Fnova~master~I4b479894bdd49c8b55bb104af16108e372259da6,openstack/nova,master,I4b479894bdd49c8b55bb104af16108e372259da6,Fix backing file copying,ABANDONED,2016-02-18 16:01:54.000000000,2016-02-19 01:21:03.000000000,,"[{'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-02-18 16:01:54.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bbe72f0b668e0443647d48a632e563d7cde82921', 'message': 'Fix backing file copying\n\nDuring instance resize, migration may occur. If instance image has\nbacking file it should be copied too.\n\nChange-Id: I4b479894bdd49c8b55bb104af16108e372259da6\n'}]",0,281924,bbe72f0b668e0443647d48a632e563d7cde82921,6,4,1,12712,,,0,"Fix backing file copying

During instance resize, migration may occur. If instance image has
backing file it should be copied too.

Change-Id: I4b479894bdd49c8b55bb104af16108e372259da6
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/281924/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,bbe72f0b668e0443647d48a632e563d7cde82921,bug/1544128," @mock.patch('nova.virt.libvirt.driver.libvirt_utils.copy_image') mock_execute, mock_copy): disk_name = 'disk' disk_info = [{'type': 'qcow2', 'path': '/test/abcd/' + disk_name, 'backing_file': 'backing_file', dest = '10.0.0.2' context.get_admin_context(), instance, dest, inst_base = libvirt_utils.get_instance_path(instance) inst_base_resize = inst_base + ""_resize"" from_path = os.path.join(inst_base_resize, disk_name) mock_copy.assert_any_call(from_path, u'/test/abcd/disk', host=mock.ANY, on_execute=mock.ANY, on_completion=mock.ANY, compression=mock.ANY) mock_copy.assert_any_call(u'/test/_base/backing_file', u'/test/_base/backing_file', host=mock.ANY, on_execute=mock.ANY, on_completion=mock.ANY, compression=mock.ANY) "," mock_execute): disk_info = [{'type': 'qcow2', 'path': '/test/disk', 'backing_file': '/base/disk', context.get_admin_context(), instance, '10.0.0.2',",43,5
openstack%2Fdevstack~master~Ifbd26b8999e453f4cd875e1be3ae1211bdd8fb2a,openstack/devstack,master,Ifbd26b8999e453f4cd875e1be3ae1211bdd8fb2a,Neutron: Change auth_plugin to auth_type,MERGED,2016-02-10 19:07:50.000000000,2016-02-19 01:20:27.000000000,2016-02-19 01:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 9656}]","[{'number': 1, 'created': '2016-02-10 19:07:50.000000000', 'files': ['lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/28af7962e99a844675e175ec23bba15378231d5f', 'message': 'Neutron: Change auth_plugin to auth_type\n\nThe keystoneauth1 library replaces the auth_plugin option\nwith auth_type. In neutron.conf, change [nova] auth_plugin\nto auth_type. In nova.conf, change [neutron] auth_plugin to\nauth_type.\n\nChange-Id: Ifbd26b8999e453f4cd875e1be3ae1211bdd8fb2a\n'}]",0,278569,28af7962e99a844675e175ec23bba15378231d5f,14,5,1,9515,,,0,"Neutron: Change auth_plugin to auth_type

The keystoneauth1 library replaces the auth_plugin option
with auth_type. In neutron.conf, change [nova] auth_plugin
to auth_type. In nova.conf, change [neutron] auth_plugin to
auth_type.

Change-Id: Ifbd26b8999e453f4cd875e1be3ae1211bdd8fb2a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/69/278569/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron-legacy'],1,28af7962e99a844675e175ec23bba15378231d5f,fix-auth1," iniset $NOVA_CONF neutron auth_type ""password"" iniset $NEUTRON_CONF nova auth_type password"," iniset $NOVA_CONF neutron auth_plugin ""v3password"" iniset $NEUTRON_CONF nova auth_plugin password",2,2
openstack%2Fdevstack~master~Iff625ef2181dfaba28349dc17de0749faddec539,openstack/devstack,master,Iff625ef2181dfaba28349dc17de0749faddec539,Update to bashate 0.4.0,MERGED,2016-02-16 03:37:39.000000000,2016-02-19 01:20:19.000000000,2016-02-19 01:20:19.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4656}]","[{'number': 1, 'created': '2016-02-16 03:37:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/devstack/commit/76d05400ec64fc4f177f9dc9ad8d821fceae5e05', 'message': 'Update to bashate 0.4.0\n\nUpdate to bashate 0.4.0.  The biggest change in this is that bashate\ndoes a syntax check with ""bash -n"" which can be useful\n\nChange-Id: Iff625ef2181dfaba28349dc17de0749faddec539\n'}]",0,280483,76d05400ec64fc4f177f9dc9ad8d821fceae5e05,12,3,1,7118,,,0,"Update to bashate 0.4.0

Update to bashate 0.4.0.  The biggest change in this is that bashate
does a syntax check with ""bash -n"" which can be useful

Change-Id: Iff625ef2181dfaba28349dc17de0749faddec539
",git fetch https://review.opendev.org/openstack/devstack refs/changes/83/280483/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,76d05400ec64fc4f177f9dc9ad8d821fceae5e05,bashate-040, {env:BASHATE_INSTALL_PATH:bashate==0.4.0}, {env:BASHATE_INSTALL_PATH:bashate==0.3.2},1,1
openstack%2Fproject-config~master~Id16909501d8ed2387daae71f75cf80de28297baf,openstack/project-config,master,Id16909501d8ed2387daae71f75cf80de28297baf,Retry twine uploads in a loop,MERGED,2016-02-18 21:10:48.000000000,2016-02-19 01:06:08.000000000,2016-02-19 01:06:08.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-18 21:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/45c5d803ad699dd57e906555befdecc92a5d5817', 'message': ""Retry twine uploads in a loop\n\nNow that we have a mechanism to check whether twine uploaded\nsuccessfully, we can also safely retry it when it doesn't. Try to\nupload to PyPI up to three times, waiting progressively longer\nbetween retries.\n\nChange-Id: Id16909501d8ed2387daae71f75cf80de28297baf\n""}, {'number': 2, 'created': '2016-02-18 21:38:19.000000000', 'files': ['jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/pypi-tarball-upload.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9ee3e76a66a9f5fd535de8031a7585dff6ea6f77', 'message': ""Retry twine uploads in a loop\n\nNow that we have a mechanism to check whether twine uploaded\nsuccessfully, we can also safely retry it when it doesn't. Try to\nupload to PyPI up to three times, waiting progressively longer\nbetween retries.\n\nChange-Id: Id16909501d8ed2387daae71f75cf80de28297baf\n""}]",6,282060,9ee3e76a66a9f5fd535de8031a7585dff6ea6f77,11,4,2,5263,,,0,"Retry twine uploads in a loop

Now that we have a mechanism to check whether twine uploaded
successfully, we can also safely retry it when it doesn't. Try to
upload to PyPI up to three times, waiting progressively longer
between retries.

Change-Id: Id16909501d8ed2387daae71f75cf80de28297baf
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/282060/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/pypi-tarball-upload.sh']",2,45c5d803ad699dd57e906555befdecc92a5d5817,check-twine-uploads,"# can download after upload to determine success. They can also fail # intermittently, so retrying in a delayed loop helps improve # robustness. TRY=0 RETVAL=255 set +e while [ $TRY -lt 3 -a $RETVAL \!= 0 ]; do twine upload -r pypi $FILENAME curl --head --silent --fail \ ""https://pypi.python.org/simple/$PROJECT/$FILENAME"" >/dev/null 2>&1 RETVAL=$? TRY=$[$TRY+1] if [ $TRY -lt 3 -a $RETVAL \!= 0 ]; then echo ""Upload failed, retrying in $TRY seconds."" >&2 sleep $TRY fi done exit $RETVAL","# can download after upload to determine success. twine upload -r pypi $FILENAME || true curl --head --silent --fail ""https://pypi.python.org/simple/$PROJECT/$FILENAME"" >/dev/null 2>&1",36,6
openstack%2Fwatcher~master~Ib7afa5d868c3c7769f53e45c270850e4c3370f86,openstack/watcher,master,Ib7afa5d868c3c7769f53e45c270850e4c3370f86,Remove unused function and argument,MERGED,2016-02-15 12:50:28.000000000,2016-02-19 01:01:10.000000000,2016-02-19 01:01:10.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}, {'_account_id': 20570}]","[{'number': 1, 'created': '2016-02-15 12:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/b0f2136d72a0d0d3c717fec0dcc212431d909f3a', 'message': 'Remove unused argument\n\nI removed the unused (funtion)argument in code\n\nChange-Id: Ib7afa5d868c3c7769f53e45c270850e4c3370f86\n'}, {'number': 2, 'created': '2016-02-18 08:17:51.000000000', 'files': ['watcher/common/nova_helper.py', 'watcher/applier/rpcapi.py', 'watcher/common/service.py', 'watcher/db/sqlalchemy/migration.py', 'watcher/doc.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/d93b1ffe9f328d31975e499761d09d6dc76fccd2', 'message': 'Remove unused function and argument\n\nI removed the unused function and (function)argument in code\n\nChange-Id: Ib7afa5d868c3c7769f53e45c270850e4c3370f86\n'}]",0,280196,d93b1ffe9f328d31975e499761d09d6dc76fccd2,14,7,2,18603,,,0,"Remove unused function and argument

I removed the unused function and (function)argument in code

Change-Id: Ib7afa5d868c3c7769f53e45c270850e4c3370f86
",git fetch https://review.opendev.org/openstack/watcher refs/changes/96/280196/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/common/nova_helper.py', 'watcher/applier/rpcapi.py', 'watcher/common/service.py', 'watcher/db/sqlalchemy/migration.py', 'watcher/doc.py']",5,b0f2136d72a0d0d3c717fec0dcc212431d909f3a,(detached," def add_textblock(self, textblock):"," def add_textblock(self, textblock, *lineno):",5,5
openstack%2Fpython-tripleoclient~stable%2Fliberty~I32dca43bf9f101416417ac432ec12cee34897e29,openstack/python-tripleoclient,stable/liberty,I32dca43bf9f101416417ac432ec12cee34897e29,Don't warn about missing profiles when they're not used,MERGED,2016-02-18 17:02:40.000000000,2016-02-19 00:57:52.000000000,2016-02-19 00:57:52.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-02-18 17:02:40.000000000', 'files': ['tripleoclient/tests/test_utils.py', 'tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/62077dffca24bae96e95bf1221b345469166d4ad', 'message': ""Don't warn about missing profiles when they're not used\n\nRight now if you deploy with just the standard baremetal flavor and\ndon't use profile matching you still get a warning that none of\nyour nodes has a profile associated.  This is not correct - we should\nonly warn if a flavor with a profile is actually in use.\n\nCloses-Bug: 1537902\nChange-Id: I32dca43bf9f101416417ac432ec12cee34897e29\n(cherry picked from commit a99875d3ce7ed1c02f603913701443cf1de8c941)\n""}]",0,281962,62077dffca24bae96e95bf1221b345469166d4ad,17,4,1,6928,,,0,"Don't warn about missing profiles when they're not used

Right now if you deploy with just the standard baremetal flavor and
don't use profile matching you still get a warning that none of
your nodes has a profile associated.  This is not correct - we should
only warn if a flavor with a profile is actually in use.

Closes-Bug: 1537902
Change-Id: I32dca43bf9f101416417ac432ec12cee34897e29
(cherry picked from commit a99875d3ce7ed1c02f603913701443cf1de8c941)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/62/281962/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/test_utils.py', 'tripleoclient/utils.py']",2,62077dffca24bae96e95bf1221b345469166d4ad,bug/1537902," profile_flavor_used = False # If there's only a single flavor, then it's expected for it to have # no profile assigned. if not profile and len(flavors) > 1: profile_flavor_used = True if nodes_without_profile and profile_flavor_used:", if not profile: if nodes_without_profile:,15,3
openstack%2Fsahara~master~I4457c4b2f8a8c25c1afba89df34497a144c7cc4a,openstack/sahara,master,I4457c4b2f8a8c25c1afba89df34497a144c7cc4a,Fixes to make bandit integration tests work with sahara,MERGED,2016-02-18 16:35:38.000000000,2016-02-19 00:56:50.000000000,2016-02-19 00:56:50.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 11861}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-18 16:35:38.000000000', 'files': ['bandit.yaml'], 'web_link': 'https://opendev.org/openstack/sahara/commit/df9dfbcde350fff99cbae4b515b10c0589d319d5', 'message': 'Fixes to make bandit integration tests work with sahara\n\nChange-Id: I4457c4b2f8a8c25c1afba89df34497a144c7cc4a\nPartial-Bug: #1546777\n'}]",0,281940,df9dfbcde350fff99cbae4b515b10c0589d319d5,12,6,1,11716,,,0,"Fixes to make bandit integration tests work with sahara

Change-Id: I4457c4b2f8a8c25c1afba89df34497a144c7cc4a
Partial-Bug: #1546777
",git fetch https://review.opendev.org/openstack/sahara refs/changes/40/281940/1 && git format-patch -1 --stdout FETCH_HEAD,['bandit.yaml'],1,df9dfbcde350fff99cbae4b515b10c0589d319d5,bug/1546777, qualnames: [mark_safe], names: [mark_safe],1,1
openstack%2Fpython-keystoneclient~master~If44008f6a48134a8af38e6794fb87ae09aac57b4,openstack/python-keystoneclient,master,If44008f6a48134a8af38e6794fb87ae09aac57b4,Add back a bandit tox job,MERGED,2016-02-17 22:11:56.000000000,2016-02-19 00:37:12.000000000,2016-02-19 00:37:12.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 13063}]","[{'number': 1, 'created': '2016-02-17 22:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/13b21371e6eccbd329c66a047b6b7e65b0a2fb1d', 'message': ""Add back a bandit tox job\n\nThe bandit project uses an integration test to ensure it doesn't\nbreak other projects by introducing new changes. To run this\nintegration, it is necessary to have a common tox target of 'bandit'.\n\nChange-Id: If44008f6a48134a8af38e6794fb87ae09aac57b4\n""}, {'number': 2, 'created': '2016-02-18 07:44:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3897128e13154c401e8e0b71e1643bfa1e179258', 'message': ""Add back a bandit tox job\n\nThe bandit project uses an integration test to ensure it doesn't\nbreak other projects by introducing new changes. To run this\nintegration, it is necessary to have a common tox target of 'bandit'\n\nChange-Id: If44008f6a48134a8af38e6794fb87ae09aac57b4\n""}]",0,281549,3897128e13154c401e8e0b71e1643bfa1e179258,23,4,2,8119,,,0,"Add back a bandit tox job

The bandit project uses an integration test to ensure it doesn't
break other projects by introducing new changes. To run this
integration, it is necessary to have a common tox target of 'bandit'

Change-Id: If44008f6a48134a8af38e6794fb87ae09aac57b4
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/49/281549/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,13b21371e6eccbd329c66a047b6b7e65b0a2fb1d,tox_bandit,[testenv:bandit] # NOTE(browne): This is required for the integration test job of the bandit # project. Please do not remove. commands = bandit -c bandit.yaml -r keystoneclient -n5 -p gate ,,5,0
openstack%2Fsalt-formula-opencontrail~master~Idb228854a8878d01fa3d675d5e3f7c231ed482d0,openstack/salt-formula-opencontrail,master,Idb228854a8878d01fa3d675d5e3f7c231ed482d0,RedHat Compatability,MERGED,2016-02-18 20:26:28.000000000,2016-02-19 00:27:58.000000000,2016-02-19 00:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 20195}]","[{'number': 1, 'created': '2016-02-18 20:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/salt-formula-opencontrail/commit/417acf5b9eab7542018f97974cbe862b99dd2504', 'message': 'RedHat Compatability\n\nChange-Id: Idb228854a8878d01fa3d675d5e3f7c231ed482d0\n'}, {'number': 2, 'created': '2016-02-18 20:40:24.000000000', 'files': ['opencontrail/collector.sls', 'opencontrail/map.jinja', 'opencontrail/files/2.2/config.global.js', 'opencontrail/compute.sls', 'opencontrail/files/cassandra.yaml.1', 'opencontrail/database.sls'], 'web_link': 'https://opendev.org/openstack/salt-formula-opencontrail/commit/2e8ce433d3b37a4fcc98e835d6d194ac2ad5790e', 'message': 'RedHat Compatability\n\nChange-Id: Idb228854a8878d01fa3d675d5e3f7c231ed482d0\n'}]",1,282047,2e8ce433d3b37a4fcc98e835d6d194ac2ad5790e,8,2,2,20194,,,0,"RedHat Compatability

Change-Id: Idb228854a8878d01fa3d675d5e3f7c231ed482d0
",git fetch https://review.opendev.org/openstack/salt-formula-opencontrail refs/changes/47/282047/1 && git format-patch -1 --stdout FETCH_HEAD,"['opencontrail/collector.sls', 'opencontrail/map.jinja', 'opencontrail/files/2.2/config.global.js', 'opencontrail/compute.sls', 'opencontrail/files/cassandra.yaml.1', 'opencontrail/database.sls']",6,417acf5b9eab7542018f97974cbe862b99dd2504,,"{{ database.cassandra_config }}cassandra.yaml:{% if grains.os_family == ""RedHat"" %} - require: - pkg: opencontrail_database_packages {% endif %} {{ database.cassandra_config }}cassandra-env.sh:{% if grains.os_family == ""RedHat"" %} - require: - pkg: opencontrail_database_packages {% endif %}{{ database.cassandra_config }}cassandra.yaml:{% if grains.os_family == ""RedHat"" %} - require: - pkg: opencontrail_database_packages {% endif %} {{ database.cassandra_config }}cassandra-env.sh:{% if grains.os_family == ""RedHat"" %} - require: - pkg: opencontrail_database_packages {% endif %}{% if grains.os_family == ""Debian"" %} - require: - file: {{ database.cassandra_config }}cassandra.yaml - file: {{ database.cassandra_config }}cassandra-env.sh {% endif %} - file: {{ database.cassandra_config }}cassandra.yaml - file: {{ database.cassandra_config }}cassandra-env.sh",/etc/cassandra/cassandra.yaml: /etc/cassandra/cassandra-env.sh:/etc/cassandra/cassandra.yaml: /etc/cassandra/cassandra-env.sh: - require: - file: /etc/cassandra/cassandra.yaml - file: /etc/cassandra/cassandra-env.sh - file: /etc/cassandra/cassandra.yaml - file: /etc/cassandra/cassandra-env.sh,66,22
openstack%2Frequirements~stable%2Fkilo~Ic7e6e0d8aa843e4510177ab413d8f311cb4742fe,openstack/requirements,stable/kilo,Ic7e6e0d8aa843e4510177ab413d8f311cb4742fe,Update constraint for os-client-config,MERGED,2016-02-18 13:33:54.000000000,2016-02-19 00:24:24.000000000,2016-02-19 00:24:24.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-02-18 13:33:54.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4ce99cc3316154855212a870de23c061aa7f321e', 'message': 'Update constraint for os-client-config\n\nIn support of a new os-client-config release, bump the upper constraint.\n\nChange-Id: Ic7e6e0d8aa843e4510177ab413d8f311cb4742fe\nDepends-On: If257aa38892a190a05bb74a62a8265378daab1bb\n'}]",0,281852,4ce99cc3316154855212a870de23c061aa7f321e,6,2,1,2,,,0,"Update constraint for os-client-config

In support of a new os-client-config release, bump the upper constraint.

Change-Id: Ic7e6e0d8aa843e4510177ab413d8f311cb4742fe
Depends-On: If257aa38892a190a05bb74a62a8265378daab1bb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/52/281852/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,4ce99cc3316154855212a870de23c061aa7f321e,,os-client-config===1.15.0,os-client-config===1.4.0,1,1
openstack%2Foctavia~stable%2Fliberty~Ie01bd6967eb2003dbe4f7a11ffe8e20a16aa83f5,openstack/octavia,stable/liberty,Ie01bd6967eb2003dbe4f7a11ffe8e20a16aa83f5,Adds a parameter to specify endpoint type,ABANDONED,2016-02-19 00:13:57.000000000,2016-02-19 00:22:15.000000000,,"[{'_account_id': 10850}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-02-19 00:13:57.000000000', 'files': ['octavia/common/config.py', 'octavia/network/drivers/neutron/base.py', 'octavia/controller/worker/tasks/compute_tasks.py', 'octavia/network/drivers/noop_driver/driver.py', 'octavia/controller/worker/tasks/network_tasks.py', 'octavia/network/drivers/neutron/allowed_address_pairs.py', 'octavia/common/clients.py', 'octavia/compute/drivers/nova_driver.py', 'etc/octavia.conf', 'octavia/tests/unit/common/test_clients.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/647f0dfebae7d24430a7dfdda549cc9450625ee4', 'message': 'Adds a parameter to specify endpoint type\n\nWhen getting a service catalog from keystone there might be\nmultiple endpoint types. Adds new parameters to specify\nthe endpoint type to use in each of the new neutron/nova\ngroups.\n\nNova config attributes are removed as the endpoint would be retrieved\nfrom the service catalog with respective endpoint_type and corresponding\nroles would define nova access.\n\nCONFIG is added as needed and cfg being removed.\n\nChange-Id: Ie01bd6967eb2003dbe4f7a11ffe8e20a16aa83f5\n(cherry picked from commit 22097dc88fa35fac5f08492d4b1e47be55c42ee5)\n'}]",0,282109,647f0dfebae7d24430a7dfdda549cc9450625ee4,3,2,1,10477,,,0,"Adds a parameter to specify endpoint type

When getting a service catalog from keystone there might be
multiple endpoint types. Adds new parameters to specify
the endpoint type to use in each of the new neutron/nova
groups.

Nova config attributes are removed as the endpoint would be retrieved
from the service catalog with respective endpoint_type and corresponding
roles would define nova access.

CONFIG is added as needed and cfg being removed.

Change-Id: Ie01bd6967eb2003dbe4f7a11ffe8e20a16aa83f5
(cherry picked from commit 22097dc88fa35fac5f08492d4b1e47be55c42ee5)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/09/282109/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/config.py', 'octavia/network/drivers/neutron/base.py', 'octavia/controller/worker/tasks/compute_tasks.py', 'octavia/network/drivers/noop_driver/driver.py', 'octavia/controller/worker/tasks/network_tasks.py', 'octavia/network/drivers/neutron/allowed_address_pairs.py', 'octavia/common/clients.py', 'octavia/compute/drivers/nova_driver.py', 'etc/octavia.conf', 'octavia/tests/unit/common/test_clients.py']",10,647f0dfebae7d24430a7dfdda549cc9450625ee4,," bc1 = clients.NovaAuth.get_nova_client(region=None, endpoint_type='publicURL') region=""test-region"", service_name='novaEndpoint1', endpoint=""test-endpoint"", endpoint_type='adminURL') bc1 = clients.NeutronAuth.get_neutron_client( region=None, endpoint_type='publicURL') region=""test-region"", service_name=""neutronEndpoint1"", endpoint=""test-endpoint"", endpoint_type='publicURL')"," bc1 = clients.NovaAuth.get_nova_client(region=None) region=""test-region"") bc1 = clients.NeutronAuth.get_neutron_client(region=None) region=""test-region"")",207,43
openstack%2Foctavia~stable%2Fliberty~Iccfd028055e1d3dc13a63d5e48a8c6e3275d42f2,openstack/octavia,stable/liberty,Iccfd028055e1d3dc13a63d5e48a8c6e3275d42f2,Replace depcrecated Nova networks with Nova interfaces,ABANDONED,2016-02-18 23:38:35.000000000,2016-02-19 00:21:58.000000000,,"[{'_account_id': 15226}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-02-18 23:38:35.000000000', 'files': ['octavia/compute/drivers/nova_driver.py', 'octavia/common/exceptions.py', 'octavia/tests/unit/compute/drivers/test_nova_driver.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f6c8c32c4d7230449ce35baf29b0a0556f18ba2c', 'message': 'Replace depcrecated Nova networks with Nova interfaces\n\nNova network (os-networks) is depcrecated and thus its\nusage should be replaced by Nova interface (os-interface).\nCreate corresponding test cases.\n\nAdded nova networks back in since RAX still needs it\nRef url: http://developer.openstack.org/api-ref-compute-v2.1.html#listAttachedInterfaces\n\nChange-Id: Iccfd028055e1d3dc13a63d5e48a8c6e3275d42f2\n(cherry picked from commit 2d87bdbf1719a02b523523a324926e1e33f516ad)\n'}]",0,282097,f6c8c32c4d7230449ce35baf29b0a0556f18ba2c,3,2,1,10477,,,0,"Replace depcrecated Nova networks with Nova interfaces

Nova network (os-networks) is depcrecated and thus its
usage should be replaced by Nova interface (os-interface).
Create corresponding test cases.

Added nova networks back in since RAX still needs it
Ref url: http://developer.openstack.org/api-ref-compute-v2.1.html#listAttachedInterfaces

Change-Id: Iccfd028055e1d3dc13a63d5e48a8c6e3275d42f2
(cherry picked from commit 2d87bdbf1719a02b523523a324926e1e33f516ad)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/97/282097/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/compute/drivers/nova_driver.py', 'octavia/common/exceptions.py', 'octavia/tests/unit/compute/drivers/test_nova_driver.py']",3,f6c8c32c4d7230449ce35baf29b0a0556f18ba2c,," override='2', enforce_type=True) self.net_name = ""lb-mgmt-net"" CONF.set_override(group='networking', name='lb_network_name', override=self.net_name, enforce_type=True) self.interface_list = mock.MagicMock() self.interface_list.net_id = CONF.controller_worker.amp_network self.interface_list.fixed_ips = [mock.MagicMock()] self.interface_list.fixed_ips[0] = {'ip_address': '10.0.0.1'} self.nova_response.interface_list.side_effect = [[self.interface_list]] self.nova_response.addresses = {self.net_name: [{'addr': '10.0.0.1'}]} self.nova_network = mock.Mock() self.nova_network.label = self.net_name def test_translate_amphora(self): amphora = self.manager._translate_amphora(self.nova_response) self.assertEqual(self.amphora, amphora) self.nova_response.interface_list.called_with() def test_bad_translate_amphora(self): self.nova_response.interface_list.side_effect = Exception self.manager._nova_client.networks.get.side_effect = Exception self.assertIsNone( self.manager._translate_amphora(self.nova_response).lb_network_ip) self.nova_response.interface_list.called_with() def test_translate_amphora_nova_networks(self): self.nova_response.interface_list.side_effect = Exception self.manager._nova_client.networks.get.return_value = self.nova_network amphora = self.manager._translate_amphora(self.nova_response) self.assertEqual(self.amphora, amphora) self.assertTrue(self.nova_response.interface_list.called) self.manager._nova_client.networks.get.called_with(self.net_name) "," net_name = ""lb-mgmt-net"" CONF.set_override(group='networking', name='lb_network_name', override=net_name) override='2') self.nova_response.addresses = {net_name: [{'addr': '10.0.0.1'}]} self.nova_network = mock.Mock() self.nova_network.label = net_name self.manager._nova_client.networks.get.return_value = self.nova_network",67,15
openstack%2Fkeystone~master~I30b63306beae3379aa8c29d0df3f327369d3f2a6,openstack/keystone,master,I30b63306beae3379aa8c29d0df3f327369d3f2a6,Adds user_description_attribute mapping support to the LDAP backend,MERGED,2016-02-05 19:00:39.000000000,2016-02-19 00:20:36.000000000,2016-02-19 00:20:36.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 9098}, {'_account_id': 17123}, {'_account_id': 17860}, {'_account_id': 18115}]","[{'number': 1, 'created': '2016-02-05 19:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b90cf1b5489966602ab2f39b6bb6471c13fcbf97', 'message': ""Adds user_description_name mapping support to the ldap backend\n\nThe LDAP backend supports mapping between LDAP and keystone user attributes via the 'user_<attribute>_name' settings in the ldap driver configuration.\n\nThe current implementation is incomplete, since there is no support for specifying a 'user_description_attribute' setting.\n\nThis change adds support to the ldap backend for mapping of user description attributes via a 'user_description_attribute' configuration.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 2, 'created': '2016-02-05 19:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6353d5eed43c1df7cf5fa46454d51e7f15464127', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 3, 'created': '2016-02-05 21:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4dd29820861fd491292becac80edeac4af019adb', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting for user get (read)\noperations.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration\nalso during user retrieval.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 4, 'created': '2016-02-05 21:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/df41ba7ca4f52aace4923842a47e80f842924b02', 'message': 'reverted the test_backend_ldap.py change that accidentally slipped into the commit.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n'}, {'number': 5, 'created': '2016-02-05 21:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/76602f39f8615e3f5c9050bf0849f2096013c37b', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting for user get (read)\noperations.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration\nalso during user retrieval.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 6, 'created': '2016-02-08 10:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d3c6a06e1be3cc61c0d490955b60766282f4ab2d', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting for user get (read)\noperations.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration\nalso during user retrieval.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 7, 'created': '2016-02-08 11:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/63e4f256d0fbbb9fc735cbe17b0ac9a6534ba7f2', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting for user get (read)\noperations.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration\nalso during user retrieval.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 8, 'created': '2016-02-08 12:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/33dc70774c52b50bb0e89005090d05eb99bcda31', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting for user get (read)\noperations.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration\nalso during user retrieval.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}, {'number': 9, 'created': '2016-02-18 10:54:16.000000000', 'files': ['keystone/common/config.py', 'doc/source/configuration.rst', 'keystone/resource/core.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/identity/backends/ldap.py', 'releasenotes/notes/bug-1542417-d630b7886bb0b369.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/448778a51126a79676e9f9ffcc9eaf4c06288a73', 'message': ""Adds user_description_attribute mapping support to the LDAP backend\n\nThe LDAP backend supports mapping between LDAP and keystone user\nattributes via the 'user_<attribute_name>_attribute' settings in the\nLDAP driver configuration.\n\nThe current implementation is incomplete, since there is no support for\nspecifying a 'user_description_attribute' setting for user get (read)\noperations.\n\nThis change adds support to the LDAP backend for mapping of user\ndescription attributes via a 'user_description_attribute' configuration\nalso during user retrieval.\n\nChange-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6\nCloses-Bug: #1542417\n""}]",42,276873,448778a51126a79676e9f9ffcc9eaf4c06288a73,44,8,9,18115,,,0,"Adds user_description_attribute mapping support to the LDAP backend

The LDAP backend supports mapping between LDAP and keystone user
attributes via the 'user_<attribute_name>_attribute' settings in the
LDAP driver configuration.

The current implementation is incomplete, since there is no support for
specifying a 'user_description_attribute' setting for user get (read)
operations.

This change adds support to the LDAP backend for mapping of user
description attributes via a 'user_description_attribute' configuration
also during user retrieval.

Change-Id: I30b63306beae3379aa8c29d0df3f327369d3f2a6
Closes-Bug: #1542417
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/276873/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/default_fixtures.py', 'keystone/common/config.py', 'doc/source/configuration.rst', 'keystone/tests/unit/test_v3_identity.py', 'keystone/tests/unit/core.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/identity/backends/ldap.py']",7,b90cf1b5489966602ab2f39b6bb6471c13fcbf97,bug/1542417," 'description': 'description',",,20,11
openstack%2Fdevstack~master~I6695a6e17df1a395ada4ecf2b063b2c20870d99d,openstack/devstack,master,I6695a6e17df1a395ada4ecf2b063b2c20870d99d,"Revert ""Fix stack failure when default subnetpool is set""",MERGED,2016-02-17 02:23:47.000000000,2016-02-19 00:19:12.000000000,2016-02-19 00:19:12.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 970}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 10385}, {'_account_id': 17130}, {'_account_id': 17377}, {'_account_id': 17776}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-17 02:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5f2b8243e66ae13917d372811409676b4c2056c5', 'message': 'Revert ""Fix stack failure when default subnetpool is set""\n\nThis reverts commit 8a3b7d424d8edf53d0560db48247e6bca11176ee.\n\nChange-Id: I6695a6e17df1a395ada4ecf2b063b2c20870d99d\n'}, {'number': 2, 'created': '2016-02-17 02:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ed3c5759f80282d77fa30b9dafb72d81386dde79', 'message': 'Revert ""Fix stack failure when default subnetpool is set""\n\nThis reverts commit 8a3b7d424d8edf53d0560db48247e6bca11176ee.\n\nThis change masked a non-backward compatible change made to the\nNeutron core API. This is being cleaned up and thus this workaround\nis no longer required.\n\nDepdends-on: Idf516ed9db24d779742cdff0584b48182a8502d6\n\nChange-Id: I6695a6e17df1a395ada4ecf2b063b2c20870d99d\n'}, {'number': 3, 'created': '2016-02-17 05:19:51.000000000', 'files': ['exercises/neutron-adv-test.sh', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/14a7148f41f859c0b42641596d7d9f2c0fa295ef', 'message': 'Revert ""Fix stack failure when default subnetpool is set""\n\nThis reverts commit 8a3b7d424d8edf53d0560db48247e6bca11176ee.\n\nThis change masked a non-backward compatible change made to the\nNeutron core API. This is being cleaned up and thus this workaround\nis no longer required.\n\nDepends-on: Idf516ed9db24d779742cdff0584b48182a8502d6\n\nChange-Id: I6695a6e17df1a395ada4ecf2b063b2c20870d99d\n'}]",2,281012,14a7148f41f859c0b42641596d7d9f2c0fa295ef,24,11,3,748,,,0,"Revert ""Fix stack failure when default subnetpool is set""

This reverts commit 8a3b7d424d8edf53d0560db48247e6bca11176ee.

This change masked a non-backward compatible change made to the
Neutron core API. This is being cleaned up and thus this workaround
is no longer required.

Depends-on: Idf516ed9db24d779742cdff0584b48182a8502d6

Change-Id: I6695a6e17df1a395ada4ecf2b063b2c20870d99d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/12/281012/3 && git format-patch -1 --stdout FETCH_HEAD,"['exercises/neutron-adv-test.sh', 'lib/neutron-legacy']",2,5f2b8243e66ae13917d372811409676b4c2056c5,bug/1545199, SUBNET_ID=$(neutron subnet-create --tenant_id $TENANT_ID --ip_version 4 ${ALLOCATION_POOL:+--allocation-pool $ALLOCATION_POOL} --name $PROVIDER_SUBNET_NAME --gateway $NETWORK_GATEWAY $NET_ID $FIXED_RANGE | grep ' id ' | get_field 2) SUBNET_V6_ID=$(neutron subnet-create --tenant_id $TENANT_ID --ip_version 6 --ipv6-address-mode $IPV6_ADDRESS_MODE --gateway $V6_NETWORK_GATEWAY --name $PROVIDER_SUBNET_NAME_V6 $NET_ID $FIXED_RANGE_V6 | grep 'id' | get_field 2)," SUBNET_ID=$(neutron subnet-create --tenant_id $TENANT_ID --ip_version 4 ${ALLOCATION_POOL:+--allocation-pool $ALLOCATION_POOL} --name $PROVIDER_SUBNET_NAME --gateway $NETWORK_GATEWAY --subnetpool None $NET_ID $FIXED_RANGE | grep ' id ' | get_field 2) SUBNET_V6_ID=$(neutron subnet-create --tenant_id $TENANT_ID --ip_version 6 --ipv6-address-mode $IPV6_ADDRESS_MODE --gateway $V6_NETWORK_GATEWAY --name $PROVIDER_SUBNET_NAME_V6 --subnetpool_id None $NET_ID $FIXED_RANGE_V6 | grep 'id' | get_field 2) subnet_params+=""--subnetpool None "" subnet_params+=""--subnetpool None "" subnet_params+=""--subnetpool None "" subnet_params+=""--subnetpool None """,3,7
openstack%2Fpuppet-nova~master~Ibffba9396587cf3f04a7bd499502f947915989d8,openstack/puppet-nova,master,Ibffba9396587cf3f04a7bd499502f947915989d8,Properly document deprecated parameter,MERGED,2016-02-17 21:41:32.000000000,2016-02-19 00:15:57.000000000,2016-02-19 00:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9061}, {'_account_id': 9414}, {'_account_id': 14007}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-17 21:41:32.000000000', 'files': ['manifests/network/neutron.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/33ce47263871f43f026825daf2639f7204e0b3c2', 'message': 'Properly document deprecated parameter\n\nAt the end neutron_tenant_name has been also deprecated, but documetation\nnot changed accordingly.\n\nChange-Id: Ibffba9396587cf3f04a7bd499502f947915989d8\n'}]",0,281538,33ce47263871f43f026825daf2639f7204e0b3c2,11,6,1,5241,,,0,"Properly document deprecated parameter

At the end neutron_tenant_name has been also deprecated, but documetation
not changed accordingly.

Change-Id: Ibffba9396587cf3f04a7bd499502f947915989d8
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/38/281538/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/network/neutron.pp'],1,33ce47263871f43f026825daf2639f7204e0b3c2,doc-fix,# Use neutron_project_name instead.,# Use neutron_tenant_name instead.,1,1
openstack%2Fdib-utils~master~Ib33336d8aac1c8d27958afe1a60b973b06360513,openstack/dib-utils,master,Ib33336d8aac1c8d27958afe1a60b973b06360513,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 21:58:25.000000000,2016-02-19 00:13:04.000000000,2015-12-16 01:43:01.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2467}, {'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 10239}, {'_account_id': 13039}, {'_account_id': 16237}, {'_account_id': 16896}]","[{'number': 1, 'created': '2015-12-11 21:58:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/dib-utils/commit/ec92ab49814466d044af6a64bee3cdfc3067bede', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ib33336d8aac1c8d27958afe1a60b973b06360513\n'}]",0,256769,ec92ab49814466d044af6a64bee3cdfc3067bede,16,9,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ib33336d8aac1c8d27958afe1a60b973b06360513
",git fetch https://review.opendev.org/openstack/dib-utils refs/changes/69/256769/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ec92ab49814466d044af6a64bee3cdfc3067bede,,,[tox:jenkins] downloadcache = ~/cache/pip,0,2
openstack%2Fneutron~master~I5daba2347cfb91fac0b155b2c1b459ee7d9e4505,openstack/neutron,master,I5daba2347cfb91fac0b155b2c1b459ee7d9e4505,Replace subnetpool config options with admin-only API,MERGED,2015-10-05 12:48:24.000000000,2016-02-19 00:09:14.000000000,2015-11-13 16:08:38.000000000,"[{'_account_id': 3}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6635}, {'_account_id': 6638}, {'_account_id': 6685}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10635}, {'_account_id': 10692}, {'_account_id': 14033}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14615}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15482}, {'_account_id': 15752}, {'_account_id': 17211}, {'_account_id': 17500}]","[{'number': 1, 'created': '2015-10-05 12:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ba82b760c27ff185bbb9c5509551a251b06ecdd', 'message': ""WIP Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which will be removed in a later\npatch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 2, 'created': '2015-10-05 13:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/471a6e6fc394df08f12b9b7fb0b33acc966dd1aa', 'message': ""WIP Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which will be removed in a later\npatch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 3, 'created': '2015-10-06 16:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abc0fa68eb88604a2b8b6be427fa3adf0dca8705', 'message': ""WIP Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which will be removed in a later\npatch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 4, 'created': '2015-10-15 17:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c43bbe8653601a587f36aec091eee1f0e5ab574', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which will be removed in a later\npatch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 5, 'created': '2015-10-20 11:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/62d2a4ef3ece19072dc517dfa6e00de9f87957ff', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are removed by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 6, 'created': '2015-10-26 13:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9d62b648be9240dd6317542b8baad15cbefde31', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are removed by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 7, 'created': '2015-10-26 13:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60df874c2bc328a5f94b26dedb0e6ddb4b406643', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are deprecated in this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 8, 'created': '2015-11-05 13:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e80e3293b29fe750d14a3206381ee03259c28e5', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are deprecated by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 9, 'created': '2015-11-05 14:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/338d74ddb7c099a8d92223b5cc05661ca8127295', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are deprecated by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 10, 'created': '2015-11-06 14:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b450d7f97d8a2636e180564eb732d8c46d903648', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are deprecated by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 11, 'created': '2015-11-06 16:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85c4be7418cd6968987e7dd6befe4fbdcff6ef08', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are deprecated by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}, {'number': 12, 'created': '2015-11-06 17:17:29.000000000', 'files': ['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'etc/neutron.conf', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'neutron/db/db_base_plugin_common.py', 'neutron/tests/unit/ipam/test_subnet_alloc.py', 'neutron/ipam/subnet_alloc.py', 'neutron/api/v2/attributes.py', 'neutron/common/config.py', 'neutron/db/migration/alembic_migrations/versions/mitaka/expand/13cfb89f881a_add_is_default_to_subnetpool.py', 'neutron/db/models_v2.py', 'etc/policy.json', 'neutron/tests/etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ee91e56c84ea6e930369f8649f1d2b50096cb80', 'message': ""Replace subnetpool config options with admin-only API\n\nThis patch adds a new boolean 'is_default' property to subnetpools. This\nallows the admin to set the default v4/v6 subnetpools via the API rather\nthan the existing neutron.conf options - which are deprecated by this patch.\n\nOnly one subnetpool per IP family can be set to default.\n\nDocImpact\nApiImpact\n\nCo-Authored-By: Carl Baldwin <carl@ecbaldwin.net>\n\nChange-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505\nCloses-Bug: 1501328\n""}]",30,230983,6ee91e56c84ea6e930369f8649f1d2b50096cb80,215,29,12,6635,,,0,"Replace subnetpool config options with admin-only API

This patch adds a new boolean 'is_default' property to subnetpools. This
allows the admin to set the default v4/v6 subnetpools via the API rather
than the existing neutron.conf options - which are deprecated by this patch.

Only one subnetpool per IP family can be set to default.

DocImpact
ApiImpact

Co-Authored-By: Carl Baldwin <carl@ecbaldwin.net>

Change-Id: I5daba2347cfb91fac0b155b2c1b459ee7d9e4505
Closes-Bug: 1501328
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/230983/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/db_base_plugin_common.py', 'neutron/tests/unit/ipam/test_subnet_alloc.py', 'neutron/db/migration/alembic_migrations/versions/liberty/expand/13cfb89f881a_add_is_default_to_subnetpool.py', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/ipam/subnet_alloc.py', 'neutron/api/v2/attributes.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/models_v2.py', 'etc/policy.json', 'neutron/tests/etc/policy.json']",10,0ba82b760c27ff185bbb9c5509551a251b06ecdd,bug/1501835," ""create_subnetpool:is_default"": ""rule:admin_only"", ""update_subnetpool:is_default"": ""rule:admin_only"",",,127,18
openstack%2Fkeystone~master~I8cb66f45958ba34a38f6569c862c583c7593d429,openstack/keystone,master,I8cb66f45958ba34a38f6569c862c583c7593d429,deprecate using the ADMIN_TOKEN,ABANDONED,2016-02-18 23:58:35.000000000,2016-02-19 00:04:10.000000000,,[],"[{'number': 1, 'created': '2016-02-18 23:58:35.000000000', 'files': ['keystone/common/config.py', 'releasenotes/notes/deprecated-as-of-mitaka-8534e43fa40c1d09.yaml', 'keystone/middleware/core.py', 'releasenotes/notes/admin_token-c634ec12fc714255.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/11a4a7079fd9d027dc7255d861891af2efd0a88f', 'message': 'deprecate using the ADMIN_TOKEN\n\nthe docs say to use `keystone-manage bootstrap`, and devstack also\nuses this technique, we should formally deprecate the ADMIN_TOKEN\noption.\n\nCloses-Bug: 1545789\n\nChange-Id: I8cb66f45958ba34a38f6569c862c583c7593d429\n'}]",0,282104,11a4a7079fd9d027dc7255d861891af2efd0a88f,2,0,1,6482,,,0,"deprecate using the ADMIN_TOKEN

the docs say to use `keystone-manage bootstrap`, and devstack also
uses this technique, we should formally deprecate the ADMIN_TOKEN
option.

Closes-Bug: 1545789

Change-Id: I8cb66f45958ba34a38f6569c862c583c7593d429
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/282104/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/config.py', 'releasenotes/notes/deprecated-as-of-mitaka-8534e43fa40c1d09.yaml', 'keystone/middleware/core.py', 'releasenotes/notes/admin_token-c634ec12fc714255.yaml']",4,11a4a7079fd9d027dc7255d861891af2efd0a88f,bug/1545789," - > [`bug 1545789 <https://bugs.launchpad.net/keystone/+bug/1545789>`_] The admin_token method of authentication was never intended to be many deployments had to leave the ``admin_token`` method enabled due ``admin_token`` configuration value now defaults to a python ``None`` value. In addition, if the value is set to ``None``, either explicitly or implicitly, the ``admin_token`` will not be enabled, and an attempt to"," - The admin_token method of authentication was never intended to be many deployments had to leave the admin_token method enabled due `admin_token` configuration value now defaults to a python `None` value. In addition, if the value is set to `None`, either explicitly or implicitly, the `admin_token` will not be enabled, and an attempt to",26,5
openstack%2Fpython-swiftclient~master~Ibacd75d5ee46135d62388786903c895fda8ed3ba,openstack/python-swiftclient,master,Ibacd75d5ee46135d62388786903c895fda8ed3ba,_RetryBody doesn't need to take explicit etag/content-length,MERGED,2016-01-08 19:32:53.000000000,2016-02-18 23:40:51.000000000,2016-02-18 23:40:51.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 7847}, {'_account_id': 9216}]","[{'number': 1, 'created': '2016-01-08 19:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/93bd1a0094227f1e5850382ca73ebc04cd0c4e52', 'message': ""_RetryBody doesn't need to track etag/content-length\n\nChange-Id: Ibacd75d5ee46135d62388786903c895fda8ed3ba\n""}, {'number': 2, 'created': '2016-01-08 19:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/7172c7177e39723488da277606523da2e31bc89c', 'message': ""_RetryBody doesn't need to track etag/content-length\n\nChange-Id: Ibacd75d5ee46135d62388786903c895fda8ed3ba\n""}, {'number': 3, 'created': '2016-01-11 23:38:30.000000000', 'files': ['tests/unit/test_swiftclient.py', 'swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/5050027610cb4c8f20c85b7c60c1cc7f2c44121c', 'message': ""_RetryBody doesn't need to take explicit etag/content-length\n\nAlso, don't try to do int(None) for chunk-encoded responses (like DLOs\nthat are longer than a single container listing).\n\nChange-Id: Ibacd75d5ee46135d62388786903c895fda8ed3ba\n""}]",6,265417,5050027610cb4c8f20c85b7c60c1cc7f2c44121c,15,4,3,15343,,,0,"_RetryBody doesn't need to take explicit etag/content-length

Also, don't try to do int(None) for chunk-encoded responses (like DLOs
that are longer than a single container listing).

Change-Id: Ibacd75d5ee46135d62388786903c895fda8ed3ba
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/17/265417/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/client.py'],1,93bd1a0094227f1e5850382ca73ebc04cd0c4e52,data-retry," def __init__(self, resp, connection, container, obj, expected_length = int(self.resp.getheader('Content-Length')) if (not buf and self.bytes_read < expected_length and self.headers['If-Match'] = self.resp.getheader('ETag') body = _RetryBody(body.resp, self, container, obj,"," def __init__(self, resp, expected_length, etag, connection, container, obj, :param expected_length: the object size in bytes :param etag: the object's etag self.expected_length = expected_length self.expected_etag = etag if (not buf and self.bytes_read < self.expected_length and self.headers['If-Match'] = self.expected_etag body = _RetryBody(body.resp, int(rheaders['content-length']), rheaders['etag'], self, container, obj,",5,10
openstack%2Fproject-config~master~Ia81937c001f121c31c2601060e6afb1efc7e0316,openstack/project-config,master,Ia81937c001f121c31c2601060e6afb1efc7e0316,Create ansible-role-ssh,MERGED,2016-02-18 13:49:27.000000000,2016-02-18 23:37:34.000000000,2016-02-18 23:37:34.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-18 13:49:27.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/acls/openstack/ansible-role-ssh.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/969300f8d0a32eb0600103f72bfa263d538bf9f9', 'message': ""Create ansible-role-ssh\n\nThis is a role to manage the ssh client on a host. Everything from ssh\npublic / private keys to known_hosts.\n\nWe'll be adding this into windmill, so add the appropriate IRC channels\nand voting / non-voting jobs.\n\nChange-Id: Ia81937c001f121c31c2601060e6afb1efc7e0316\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,281867,969300f8d0a32eb0600103f72bfa263d538bf9f9,7,3,1,4162,,,0,"Create ansible-role-ssh

This is a role to manage the ssh client on a host. Everything from ssh
public / private keys to known_hosts.

We'll be adding this into windmill, so add the appropriate IRC channels
and voting / non-voting jobs.

Change-Id: Ia81937c001f121c31c2601060e6afb1efc7e0316
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/281867/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/acls/openstack/ansible-role-ssh.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,969300f8d0a32eb0600103f72bfa263d538bf9f9,temp/ansible-role-ssh, - name: openstack/ansible-role-ssh template: - name: merge-check - name: ansible-role-jobs - name: ansible-role-functional-jobs-centos7-nv - name: ansible-role-functional-jobs-trusty-nv - name: docs-on-rtfd - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv ,,37,0
openstack%2Fproject-config~master~I6bf43e860dcc8c3d7b2846d4e058b6c8ac7243eb,openstack/project-config,master,I6bf43e860dcc8c3d7b2846d4e058b6c8ac7243eb,Keep Gerrit ACL lines deduplicated,MERGED,2016-02-17 22:45:33.000000000,2016-02-18 23:12:03.000000000,2016-02-18 23:12:03.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-17 22:45:33.000000000', 'files': ['tools/normalize_acl.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cb63263510d9488b4659604e8de5c79ce1f43c89', 'message': ""Keep Gerrit ACL lines deduplicated\n\nGerrit ACLs can have multiple duplicate option keys in a section,\nbut completely duplicate lines (key and value together) have no use\nso make sure they're collapsed into at most 1 copy.\n\nChange-Id: I6bf43e860dcc8c3d7b2846d4e058b6c8ac7243eb\n""}]",2,281562,cb63263510d9488b4659604e8de5c79ce1f43c89,9,3,1,5263,,,0,"Keep Gerrit ACL lines deduplicated

Gerrit ACLs can have multiple duplicate option keys in a section,
but completely duplicate lines (key and value together) have no use
so make sure they're collapsed into at most 1 copy.

Change-Id: I6bf43e860dcc8c3d7b2846d4e058b6c8ac7243eb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/62/281562/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/normalize_acl.py'],1,cb63263510d9488b4659604e8de5c79ce1f43c89,feature/gerrit_perms," lastoption = '' for option in sorted(acl[section], key=tokens): if option != lastoption: out += '%s\n' % option lastoption = option"," for option in sorted(acl[section], key=tokens): out += '%s\n' % option",4,1
openstack%2Foslo.log~master~Ibac702706eb3367318c9f628fc762095589a56e1,openstack/oslo.log,master,Ibac702706eb3367318c9f628fc762095589a56e1,add page for release notes for unreleased versions,MERGED,2016-02-18 17:24:30.000000000,2016-02-18 22:32:12.000000000,2016-02-18 22:32:12.000000000,"[{'_account_id': 3}, {'_account_id': 8688}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-18 17:24:30.000000000', 'files': ['releasenotes/source/unreleased.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/41670c1d487de769fb30af9628992e81d715cc0f', 'message': 'add page for release notes for unreleased versions\n\nAdd a page to show all of the release notes from the ""current"" branch,\nincluding those not yet released. This is used to test the release notes\nbuild for new notes, and to indicate that upcoming features are not\navailable in public releases, yet.\n\nChange-Id: Ibac702706eb3367318c9f628fc762095589a56e1\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,281971,41670c1d487de769fb30af9628992e81d715cc0f,7,3,1,2472,,,0,"add page for release notes for unreleased versions

Add a page to show all of the release notes from the ""current"" branch,
including those not yet released. This is used to test the release notes
build for new notes, and to indicate that upcoming features are not
available in public releases, yet.

Change-Id: Ibac702706eb3367318c9f628fc762095589a56e1
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/71/281971/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/unreleased.rst', 'releasenotes/source/index.rst']",2,41670c1d487de769fb30af9628992e81d715cc0f,add-reno, unreleased,,6,0
openstack%2Ftacker~stable%2Fliberty~I65a0929b4207900988bad5c15b28cde206fafcf6,openstack/tacker,stable/liberty,I65a0929b4207900988bad5c15b28cde206fafcf6,update requirements according to global requ,MERGED,2016-02-10 15:41:58.000000000,2016-02-18 22:29:39.000000000,2016-02-18 22:29:39.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 18955}]","[{'number': 1, 'created': '2016-02-10 15:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ea05f1ca210a2e7b2ad1c65f1936ef38455dda6f', 'message': 'update requirements according to global requ\n\nThis patch updates the requirements in stable/liberty branch\nof tacker according to global requirements in stable/liberty\n\nChange-Id: I65a0929b4207900988bad5c15b28cde206fafcf6\nPartial-Bug: #1543396\n'}, {'number': 2, 'created': '2016-02-18 17:21:16.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/0043b5ad722a58088fab56a31100f70c665323c6', 'message': 'update requirements according to global requ\n\nThis patch updates the requirements in stable/liberty branch\nof tacker according to global requirements in stable/liberty\n\nChange-Id: I65a0929b4207900988bad5c15b28cde206fafcf6\nCloses-Bug: #1543396\n'}]",1,278459,0043b5ad722a58088fab56a31100f70c665323c6,14,5,2,15755,,,0,"update requirements according to global requ

This patch updates the requirements in stable/liberty branch
of tacker according to global requirements in stable/liberty

Change-Id: I65a0929b4207900988bad5c15b28cde206fafcf6
Closes-Bug: #1543396
",git fetch https://review.opendev.org/openstack/tacker refs/changes/59/278459/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,ea05f1ca210a2e7b2ad1c65f1936ef38455dda6f,bug/1543396," setup_requires=['pbr>=1.8'],","#!/usr/bin/env python setup_requires=['pbr'],",26,23
openstack%2Fproject-config~master~Iaedc56e08de65bb13e3d9109d38bb963002d68dc,openstack/project-config,master,Iaedc56e08de65bb13e3d9109d38bb963002d68dc,Support stable requirements,ABANDONED,2016-02-09 19:37:56.000000000,2016-02-18 22:28:55.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-09 19:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/22e77c66c5803205e1db436ffaad90b496c36d2c', 'message': ""Support stable requirements\n\nproject-requirements-change.py master runs against stable branches\nwith the stable version of requirements. requirements provides the\nRequirement class that's used by project-requirements-change.py. The\nstable version of the Requirement class doesn't have the `location`\nattribute, which was added in commit b838ab1.\n\nThe workaround is to check if the Requirements object has location and\nonly use location if present.\n\nAnother issue is that when running against keystonemiddleware\nstable/kilo the 'setup.cfg' isn't being set for the project. In the\nstable version of requirements, a KeyError is raised. The master\nversion of requirements allows no 'setup.cfg' which was added in\ncommit 97ddc98\n\nChange-Id: Iaedc56e08de65bb13e3d9109d38bb963002d68dc\n""}, {'number': 2, 'created': '2016-02-10 15:26:20.000000000', 'files': ['jenkins/scripts/project-requirements-change.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/afad1de4af66c1aad62d895217546f35ccdc4c73', 'message': ""Support stable requirements\n\nproject-requirements-change.py master runs against stable branches\nwith the stable version of requirements. requirements provides the\nRequirement class that's used by project-requirements-change.py. The\nstable version of the Requirement class doesn't have the `location`\nattribute, which was added in commit b838ab1.\n\nThe workaround is to check if the Requirements object has location and\nonly use location if present.\n\nAnother issue is that when running against keystonemiddleware\nstable/kilo the 'setup.cfg' isn't being set for the project. In the\nstable version of requirements, a KeyError is raised. The master\nversion of requirements allows no 'setup.cfg' which was added in\ncommit 97ddc98\n\nChange-Id: Iaedc56e08de65bb13e3d9109d38bb963002d68dc\n""}]",2,278056,afad1de4af66c1aad62d895217546f35ccdc4c73,16,7,2,6486,,,0,"Support stable requirements

project-requirements-change.py master runs against stable branches
with the stable version of requirements. requirements provides the
Requirement class that's used by project-requirements-change.py. The
stable version of the Requirement class doesn't have the `location`
attribute, which was added in commit b838ab1.

The workaround is to check if the Requirements object has location and
only use location if present.

Another issue is that when running against keystonemiddleware
stable/kilo the 'setup.cfg' isn't being set for the project. In the
stable version of requirements, a KeyError is raised. The master
version of requirements allows no 'setup.cfg' which was added in
commit 97ddc98

Change-Id: Iaedc56e08de65bb13e3d9109d38bb963002d68dc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/278056/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/project-requirements-change.py'],1,22e77c66c5803205e1db436ffaad90b496c36d2c,support_kilo," # stable version of project.extras() requires setup.cfg and will fail # with KeyError if it's not present. Master requirements checks if # it's present and won't fail. To work with stable requirements, # default setup.cfg. self.project.setdefault('setup.cfg', u'') ((hasattr(req, 'location') and req.location == req2.location) or True) and", req.location == req2.location and,8,1
openstack%2Fswift~master~I1409354fb1ecb1ef879883a7f0795a0dbd9a1244,openstack/swift,master,I1409354fb1ecb1ef879883a7f0795a0dbd9a1244,New recon request to get account names from cluster,NEW,2016-01-18 21:49:41.000000000,2016-02-18 22:23:46.000000000,,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 13052}, {'_account_id': 13390}, {'_account_id': 16896}]","[{'number': 1, 'created': '2016-01-18 21:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e55681e42d62d4b899d22dadf6c848c6d66086db', 'message': 'New recon request to get account names from cluster\n\nThis patch depends on having patch 268830 (Let developers/operators\nadd watchers to account audit) installed to work.\n\nCluster operators need to be able to gather information on Swift\naccounts in the cluster for utilization and auditing purposes,\nonly there is no central list of all accounts in the Swift cluster.\nRight now each operator must implement a method to discover accounts\non their own. This patch uses account auditor watchers to collect\ndata on all audited accounts in the system.\n\nThe new requests can be run using:\n* swift-recon --accounts\n* curl -i http://localhost:6030/recon/accounts (On a local SAIO\n  substitute your URL as needed).\n\nChange-Id: I1409354fb1ecb1ef879883a7f0795a0dbd9a1244\n'}, {'number': 2, 'created': '2016-01-21 00:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d7062dc294ce494534dee16ca4c6fe90e6221ced', 'message': 'New recon request to get account names from cluster\n\nThis patch depends on having patch 268830 (Let developers/operators\nadd watchers to account audit) installed to work.\n\nCluster operators need to be able to gather information on Swift\naccounts in the cluster for utilization and auditing purposes,\nonly there is no central list of all accounts in the Swift cluster.\nRight now each operator must implement a method to discover accounts\non their own. This patch uses account auditor watchers to collect\ndata on all audited accounts in the system.\n\nThe new requests can be run using:\n* swift-recon --accounts\n* curl -i http://localhost:6030/recon/accounts (On a local SAIO\n  substitute your URL as needed).\n\nChange-Id: I1409354fb1ecb1ef879883a7f0795a0dbd9a1244\n'}, {'number': 3, 'created': '2016-02-18 19:00:00.000000000', 'files': ['swift/common/middleware/recon.py', 'test/unit/common/middleware/test_recon.py', 'swift/cli/recon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/078ccbe43bc98fe79a72b893f380b3d583bc0697', 'message': 'New recon request to get account names from cluster\n\nThis patch depends on having patch 268830 (Let developers/operators\nadd watchers to account audit) installed to work.\n\nCluster operators need to be able to gather information on Swift\naccounts in the cluster for utilization and auditing purposes,\nonly there is no central list of all accounts in the Swift cluster.\nRight now each operator must implement a method to discover accounts\non their own. This patch uses account auditor watchers to collect\ndata on all audited accounts in the system.\n\nThe new requests can be run using:\n* swift-recon --accounts\n* curl -i http://localhost:6030/recon/accounts (On a local SAIO\n  substitute your URL as needed).\n\nChange-Id: I1409354fb1ecb1ef879883a7f0795a0dbd9a1244\n'}]",1,269291,078ccbe43bc98fe79a72b893f380b3d583bc0697,13,5,3,18978,,,0,"New recon request to get account names from cluster

This patch depends on having patch 268830 (Let developers/operators
add watchers to account audit) installed to work.

Cluster operators need to be able to gather information on Swift
accounts in the cluster for utilization and auditing purposes,
only there is no central list of all accounts in the Swift cluster.
Right now each operator must implement a method to discover accounts
on their own. This patch uses account auditor watchers to collect
data on all audited accounts in the system.

The new requests can be run using:
* swift-recon --accounts
* curl -i http://localhost:6030/recon/accounts (On a local SAIO
  substitute your URL as needed).

Change-Id: I1409354fb1ecb1ef879883a7f0795a0dbd9a1244
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/269291/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/recon.py', 'swift/cli/recon.py']",2,e55681e42d62d4b899d22dadf6c848c6d66086db,account-data-recon-req," def accounts_check(self, hosts, swift_dir): """""" Obtain and print existing account information :param hosts: set of hosts to check. in the format of: set([('127.0.0.1', 6020), ('127.0.0.2', 6030)]) """""" if not hosts: return recon = Scout(""accounts"", self.verbose, self.suppress_errors, self.timeout) url, content, status, ts_start, ts_end = recon.scout(list(hosts)[0]) if not content or status != 200: print(""Error: No data available. This is may be because there"" "" are no accounts, or an audit has not been completed"" "" yet."") return print(""[%s] Retrieving known accounts..."" % self._ptime()) results = False # Get the ip and port of nodes associated with each account name # Compare these against those in hosts to filter zones/regions/devices for account_name in content: ring = Ring(swift_dir, ring_name=self.server_type) part = ring.get_part('account', account_name) primary = [(node['ip'], node['port']) for node in ring.get_part_nodes(part)] # handoff = [(node['ip'], node['port']) for # node in list(ring.get_more_nodes(part))] my_hosts = set(primary) # + handoff) if hosts & my_hosts: print(account_name) results = True if not results: print(""No accounts found using filter options."") print(""="" * 79) args.add_option('--accounts', action=""store_true"", help=""Get account stats"") if options.accounts: self.accounts_check(hosts, swift_dir)",,100,0
openstack%2Fsolum~master~Ie4ed813ce9b392532da247895322d5421a46ba37,openstack/solum,master,Ie4ed813ce9b392532da247895322d5421a46ba37,Migrate to oslo.context from Oslo incubator,MERGED,2016-02-02 23:05:23.000000000,2016-02-18 22:13:34.000000000,2016-02-18 22:13:33.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-02-02 23:05:23.000000000', 'files': ['solum/openstack/common/context.py', 'solum/common/context.py', 'requirements.txt', 'openstack-common.conf', 'solum/tests/common/test_context.py', 'solum/tests/common/test_trace_data.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/c589740d5892b6b3173e46ee1be24f956ada68e3', 'message': 'Migrate to oslo.context from Oslo incubator\n\nAs part of providing app agnostic parameters for oslo.log all logging\nfor TC approved projects need to use and subclass oslo.context\nRequestContext to utilize new get_logging_values() method.\n\nChange-Id: Ie4ed813ce9b392532da247895322d5421a46ba37\n'}]",0,275433,c589740d5892b6b3173e46ee1be24f956ada68e3,11,3,1,16051,,,0,"Migrate to oslo.context from Oslo incubator

As part of providing app agnostic parameters for oslo.log all logging
for TC approved projects need to use and subclass oslo.context
RequestContext to utilize new get_logging_values() method.

Change-Id: Ie4ed813ce9b392532da247895322d5421a46ba37
",git fetch https://review.opendev.org/openstack/solum refs/changes/33/275433/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/common/context.py', 'solum/openstack/common/context.py', 'requirements.txt', 'openstack-common.conf', 'solum/tests/common/test_context.py', 'solum/tests/common/test_trace_data.py']",6,c589740d5892b6b3173e46ee1be24f956ada68e3,bp/app-agnostic-logging-parameters," '_project_domain_', False, False, '_request_id_', 'is_admin': False, 'read_only': False, 'resource_uuid': None,"," '_project_domain_', '_is_admin_', '_read_only_', '_request_id_', 'instance_uuid': None, 'is_admin': '_is_admin_', 'read_only': '_read_only_',",20,144
openstack%2Fkeystonemiddleware~master~I9b80043bde45cfec472402ddab1747d5b2f87da1,openstack/keystonemiddleware,master,I9b80043bde45cfec472402ddab1747d5b2f87da1,Add back a bandit tox job,MERGED,2016-02-17 22:08:29.000000000,2016-02-18 22:11:18.000000000,2016-02-18 22:11:18.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 13063}]","[{'number': 1, 'created': '2016-02-17 22:08:29.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ead606154524eede2aa3fd47584afb629cfd3387', 'message': ""Add back a bandit tox job\n\nThe bandit project uses an integration test to ensure it doesn't\nbreak other projects by introducing new changes. To run this\nintegration, it is necessary to have a common tox target of\n'bandit'.\n\nChange-Id: I9b80043bde45cfec472402ddab1747d5b2f87da1\n""}]",0,281548,ead606154524eede2aa3fd47584afb629cfd3387,20,4,1,8119,,,0,"Add back a bandit tox job

The bandit project uses an integration test to ensure it doesn't
break other projects by introducing new changes. To run this
integration, it is necessary to have a common tox target of
'bandit'.

Change-Id: I9b80043bde45cfec472402ddab1747d5b2f87da1
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/48/281548/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ead606154524eede2aa3fd47584afb629cfd3387,tox_bandit,[testenv:bandit] # NOTE(browne): This is required for the integration test job of the bandit # project. Please do not remove. commands = bandit -c bandit.yaml -r keystonemiddleware -n5 -p gate ,,5,0
openstack%2Foslo.log~master~I35903ffe1f70145ffbbcb3a96ea9be806924cce2,openstack/oslo.log,master,I35903ffe1f70145ffbbcb3a96ea9be806924cce2,add a release note about using reno,MERGED,2016-02-18 17:24:30.000000000,2016-02-18 22:03:12.000000000,2016-02-18 22:03:12.000000000,"[{'_account_id': 3}, {'_account_id': 8688}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-18 17:24:30.000000000', 'files': ['releasenotes/notes/add-reno-e4fedb11ece56f1e.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/c4b3de93689f913ab8955819addec42628d61ebe', 'message': 'add a release note about using reno\n\nChange-Id: I35903ffe1f70145ffbbcb3a96ea9be806924cce2\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,281970,c4b3de93689f913ab8955819addec42628d61ebe,7,3,1,2472,,,0,"add a release note about using reno

Change-Id: I35903ffe1f70145ffbbcb3a96ea9be806924cce2
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/70/281970/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/add-reno-e4fedb11ece56f1e.yaml'],1,c4b3de93689f913ab8955819addec42628d61ebe,add-reno,--- other: - Switch to reno for managing release notes. ,,3,0
openstack%2Fsalt-formula-neutron~master~I914e3464f15b41aa5bbbc993813692a36167376a,openstack/salt-formula-neutron,master,I914e3464f15b41aa5bbbc993813692a36167376a,fixes for contrail in RedHat,MERGED,2016-02-18 17:48:18.000000000,2016-02-18 21:52:56.000000000,2016-02-18 21:52:56.000000000,"[{'_account_id': 3}, {'_account_id': 20195}]","[{'number': 1, 'created': '2016-02-18 17:48:18.000000000', 'files': ['neutron/files/liberty/neutron-server.conf.contrail.RedHat', 'neutron/files/kilo/neutron-server.conf.contrail.RedHat'], 'web_link': 'https://opendev.org/openstack/salt-formula-neutron/commit/ae1ae08dfc5d35060e8084c6c924bced586f6584', 'message': 'fixes for contrail in RedHat\n\nChange-Id: I914e3464f15b41aa5bbbc993813692a36167376a\n'}]",0,281983,ae1ae08dfc5d35060e8084c6c924bced586f6584,6,2,1,20194,,,0,"fixes for contrail in RedHat

Change-Id: I914e3464f15b41aa5bbbc993813692a36167376a
",git fetch https://review.opendev.org/openstack/salt-formula-neutron refs/changes/83/281983/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/files/liberty/neutron-server.conf.contrail.RedHat', 'neutron/files/kilo/neutron-server.conf.contrail.RedHat']",2,ae1ae08dfc5d35060e8084c6c924bced586f6584,,"{%- set neutron = pillar.neutron.server %} {%- from ""neutron/map.jinja"" import server with context %} [DEFAULT] # Print more verbose output (set logging level to INFO instead of default WARNING level). # verbose = False verbose = true # =========Start Global Config Option for Distributed L3 Router=============== # Setting the ""router_distributed"" flag to ""True"" will default to the creation # of distributed tenant routers. The admin can override this flag by specifying # the type of the router on the create request (admin-only attribute). Default # value is ""False"" to support legacy mode (centralized) routers. # # router_distributed = False # # ===========End Global Config Option for Distributed L3 Router=============== # Print debugging output (set logging level to DEBUG instead of default WARNING level). # debug = False # Where to store Neutron state files. This directory must be writable by the # user executing the agent. # state_path = /var/lib/neutron state_path = /var/lib/neutron # log_format = %(asctime)s %(levelname)8s [%(name)s] %(message)s # log_date_format = %Y-%m-%d %H:%M:%S # use_syslog -> syslog # log_file and log_dir -> log_dir/log_file # (not log_file) and log_dir -> log_dir/{binary_name}.log # use_stderr -> stderr # (not user_stderr) and (not log_file) -> stdout # publish_errors -> notification system # use_syslog = False # syslog_log_facility = LOG_USER # use_stderr = True # log_file = # log_dir = # publish_errors = False # Address to bind the API server to bind_host = {{ neutron.bind.address }} # Port the bind the API server to # bind_port = 9696 bind_port = {{ neutron.bind.port }} # Path to the extensions. Note that this can be a colon-separated list of # paths. For example: # api_extensions_path = extensions:/path/to/more/extensions:/even/more/extensions # The __path__ of neutron.extensions is appended to this, so if your # extensions are in there you don't need to specify them here # api_extensions_path = # (StrOpt) Neutron core plugin entrypoint to be loaded from the # neutron.core_plugins namespace. See setup.cfg for the entrypoint names of the # plugins included in the neutron source distribution. For compatibility with # previous versions, the class name of a plugin can be specified instead of its # entrypoint name. # #core_plugin = ml2 # Example: core_plugin = ml2 core_plugin = neutron_plugin_contrail.plugins.opencontrail.contrail_plugin.NeutronPluginContrailCoreV2 api_extensions_path = extensions:/usr/lib/python2.7/site-packages/neutron_plugin_contrail/extensions # (ListOpt) List of service plugin entrypoints to be loaded from the # neutron.service_plugins namespace. See setup.cfg for the entrypoint names of # the plugins included in the neutron source distribution. For compatibility # with previous versions, the class name of a plugin can be specified instead # of its entrypoint name. # # service_plugins = # Example: service_plugins = router,firewall,lbaas,vpnaas,metering #service_plugins = neutron_plugin_contrail.plugins.opencontrail.loadbalancer.plugin.LoadBalancerPlugin # Paste configuration file # api_paste_config = api-paste.ini # (StrOpt) Hostname to be used by the neutron server, agents and services # running on this machine. All the agents and services running on this machine # must use the same host value. # The default value is hostname of the machine. # # host = # The strategy to be used for auth. # Supported values are 'keystone'(default), 'noauth'. # auth_strategy = keystone auth_strategy = keystone # Base MAC address. The first 3 octets will remain unchanged. If the # 4h octet is not 00, it will also be used. The others will be # randomly generated. # 3 octet # base_mac = fa:16:3e:00:00:00 # 4 octet # base_mac = fa:16:3e:4f:00:00 # DVR Base MAC address. The first 3 octets will remain unchanged. If the # 4th octet is not 00, it will also be used. The others will be randomly # generated. The 'dvr_base_mac' *must* be different from 'base_mac' to # avoid mixing them up with MAC's allocated for tenant ports. # A 4 octet example would be dvr_base_mac = fa:16:3f:4f:00:00 # The default is 3 octet # dvr_base_mac = fa:16:3f:00:00:00 # Maximum amount of retries to generate a unique MAC address # mac_generation_retries = 16 # DHCP Lease duration (in seconds). Use -1 to # tell dnsmasq to use infinite lease times. # dhcp_lease_duration = 86400 # Allow sending resource operation notification to DHCP agent # dhcp_agent_notification = True # Enable or disable bulk create/update/delete operations # allow_bulk = True # Enable or disable pagination # allow_pagination = False # Enable or disable sorting # allow_sorting = False # Enable or disable overlapping IPs for subnets # Attention: the following parameter MUST be set to False if Neutron is # being used in conjunction with nova security groups # allow_overlapping_ips = False allow_overlapping_ips = True # Ensure that configured gateway is on subnet. For IPv6, validate only if # gateway is not a link local address. Deprecated, to be removed during the # K release, at which point the check will be mandatory. # force_gateway_on_subnet = True # Default maximum number of items returned in a single response, # value == infinite and value < 0 means no max limit, and value must # be greater than 0. If the number of items requested is greater than # pagination_max_limit, server will just return pagination_max_limit # of number of items. # pagination_max_limit = -1 # Maximum number of DNS nameservers per subnet # max_dns_nameservers = 5 # Maximum number of host routes per subnet # max_subnet_host_routes = 20 # Maximum number of fixed ips per port # max_fixed_ips_per_port = 5 # Maximum number of routes per router # max_routes = 30 # Default Subnet Pool to be used for IPv4 subnet-allocation. # Specifies by UUID the pool to be used in case of subnet-create being called # without a subnet-pool ID. The default of None means that no pool will be # used unless passed explicitly to subnet create. If no pool is used, then a # CIDR must be passed to create a subnet and that subnet will not be allocated # from any pool; it will be considered part of the tenant's private address # space. # default_ipv4_subnet_pool = # Default Subnet Pool to be used for IPv6 subnet-allocation. # Specifies by UUID the pool to be used in case of subnet-create being # called without a subnet-pool ID. Set to ""prefix_delegation"" # to enable IPv6 Prefix Delegation in a PD-capable environment. # See the description for default_ipv4_subnet_pool for more information. # default_ipv6_subnet_pool = # =========== items for MTU selection and advertisement ============= # Advertise MTU. If True, effort is made to advertise MTU # settings to VMs via network methods (ie. DHCP and RA MTU options) # when the network's preferred MTU is known. # advertise_mtu = False # ======== end of items for MTU selection and advertisement ========= # =========== items for agent management extension ============= # Seconds to regard the agent as down; should be at least twice # report_interval, to be sure the agent is down for good # agent_down_time = 75 # =========== end of items for agent management extension ===== # =========== items for agent scheduler extension ============= # Driver to use for scheduling network to DHCP agent # network_scheduler_driver = neutron.scheduler.dhcp_agent_scheduler.ChanceScheduler # Driver to use for scheduling router to a default L3 agent # router_scheduler_driver = neutron.scheduler.l3_agent_scheduler.ChanceScheduler # Driver to use for scheduling a loadbalancer pool to an lbaas agent # loadbalancer_pool_scheduler_driver = neutron.services.loadbalancer.agent_scheduler.ChanceScheduler # (StrOpt) Representing the resource type whose load is being reported by # the agent. # This can be 'networks','subnets' or 'ports'. When specified (Default is networks), # the server will extract particular load sent as part of its agent configuration object # from the agent report state, which is the number of resources being consumed, at # every report_interval. # dhcp_load_type can be used in combination with network_scheduler_driver = # neutron.scheduler.dhcp_agent_scheduler.WeightScheduler # When the network_scheduler_driver is WeightScheduler, dhcp_load_type can # be configured to represent the choice for the resource being balanced. # Example: dhcp_load_type = networks # Values: # networks - number of networks hosted on the agent # subnets - number of subnets associated with the networks hosted on the agent # ports - number of ports associated with the networks hosted on the agent # dhcp_load_type = networks # Allow auto scheduling networks to DHCP agent. It will schedule non-hosted # networks to first DHCP agent which sends get_active_networks message to # neutron server # network_auto_schedule = True # Allow auto scheduling routers to L3 agent. It will schedule non-hosted # routers to first L3 agent which sends sync_routers message to neutron server # router_auto_schedule = True # Allow automatic rescheduling of routers from dead L3 agents with # admin_state_up set to True to alive agents. # allow_automatic_l3agent_failover = False # Allow automatic removal of networks from dead DHCP agents with # admin_state_up set to True. # Networks could then be rescheduled if network_auto_schedule is True # allow_automatic_dhcp_failover = True # Number of DHCP agents scheduled to host a network. This enables redundant # DHCP agents for configured networks. # dhcp_agents_per_network = 1 # Enable services on agents with admin_state_up False. # If this option is False, when admin_state_up of an agent is turned to # False, services on it will be disabled. If this option is True, services # on agents with admin_state_up False keep available and manual scheduling # to such agents is available. Agents with admin_state_up False are not # selected for automatic scheduling regardless of this option. # enable_services_on_agents_with_admin_state_down = False # =========== end of items for agent scheduler extension ===== # =========== items for l3 extension ============== # Enable high availability for virtual routers. # l3_ha = False # # Maximum number of l3 agents which a HA router will be scheduled on. If it # is set to 0 the router will be scheduled on every agent. # max_l3_agents_per_router = 3 # # Minimum number of l3 agents which a HA router will be scheduled on. The # default value is 2. # min_l3_agents_per_router = 2 # # CIDR of the administrative network if HA mode is enabled # l3_ha_net_cidr = 169.254.192.0/18 # =========== end of items for l3 extension ======= # =========== items for metadata proxy configuration ============== # User (uid or name) running metadata proxy after its initialization # (if empty: agent effective user) # metadata_proxy_user = # Group (gid or name) running metadata proxy after its initialization # (if empty: agent effective group) # metadata_proxy_group = # Enable/Disable log watch by metadata proxy, it should be disabled when # metadata_proxy_user/group is not allowed to read/write its log file and # 'copytruncate' logrotate option must be used if logrotate is enabled on # metadata proxy log files. Option default value is deduced from # metadata_proxy_user: watch log is enabled if metadata_proxy_user is agent # effective user id/name. # metadata_proxy_watch_log = # Location of Metadata Proxy UNIX domain socket # metadata_proxy_socket = $state_path/metadata_proxy # =========== end of items for metadata proxy configuration ============== # ========== items for VLAN trunking networks ========== # Setting this flag to True will allow plugins that support it to # create VLAN transparent networks. This flag has no effect for # plugins that do not support VLAN transparent networks. # vlan_transparent = False # ========== end of items for VLAN trunking networks ========== # =========== WSGI parameters related to the API server ============== # Number of separate worker processes to spawn. The default, 0, runs the # worker thread in the current process. Greater than 0 launches that number of # child processes as workers. The parent process manages them. # api_workers = 0 # Number of separate RPC worker processes to spawn. The default, 0, runs the # worker thread in the current process. Greater than 0 launches that number of # child processes as RPC workers. The parent process manages them. # This feature is experimental until issues are addressed and testing has been # enabled for various plugins for compatibility. # rpc_workers = 0 # Timeout for client connections socket operations. If an # incoming connection is idle for this number of seconds it # will be closed. A value of '0' means wait forever. (integer # value) # client_socket_timeout = 900 # wsgi keepalive option. Determines if connections are allowed to be held open # by clients after a request is fulfilled. A value of False will ensure that # the socket connection will be explicitly closed once a response has been # sent to the client. # wsgi_keep_alive = True # Sets the value of TCP_KEEPIDLE in seconds to use for each server socket when # starting API server. Not supported on OS X. # tcp_keepidle = 600 # Number of seconds to keep retrying to listen # retry_until_window = 30 # Number of backlog requests to configure the socket with. # backlog = 4096 # Max header line to accommodate large tokens # max_header_line = 16384 # Enable SSL on the API server # use_ssl = False # Certificate file to use when starting API server securely # ssl_cert_file = /path/to/certfile # Private key file to use when starting API server securely # ssl_key_file = /path/to/keyfile # CA certificate file to use when starting API server securely to # verify connecting clients. This is an optional parameter only required if # API clients need to authenticate to the API server using SSL certificates # signed by a trusted CA # ssl_ca_file = /path/to/cafile # ======== end of WSGI parameters related to the API server ========== # ======== neutron nova interactions ========== # Send notification to nova when port status is active. # notify_nova_on_port_status_changes = True notify_nova_on_port_status_changes = True # Send notifications to nova when port data (fixed_ips/floatingips) change # so nova can update it's cache. # notify_nova_on_port_data_changes = True notify_nova_on_port_data_changes = True # URL for connection to nova (Only supports one nova region currently). # nova_url = http://127.0.0.1:8774/v2 nova_url = http://{{ neutron.compute.host }}:8774/v2 # Name of nova region to use. Useful if keystone manages more than one region # nova_region_name = nova_region_name = RegionOne # Username for connection to nova in admin context # nova_admin_username = nova_admin_username = {{ neutron.compute.user }} # The uuid of the admin nova tenant # nova_admin_tenant_id = # The name of the admin nova tenant. If the uuid of the admin nova tenant # is set, this is optional. Useful for cases where the uuid of the admin # nova tenant is not available when configuration is being done. # nova_admin_tenant_name = nova_admin_tenant_name = {{ neutron.compute.tenant }} # Password for connection to nova in admin context. # nova_admin_password = nova_admin_password = {{ neutron.compute.password }} # Authorization URL for connection to nova in admin context. # nova_admin_auth_url = nova_admin_auth_url = http://{{ neutron.identity.host }}:35357 # CA file for novaclient to verify server certificates # nova_ca_certificates_file = # Boolean to control ignoring SSL errors on the nova url # nova_api_insecure = False # Number of seconds between sending events to nova if there are any events to send # send_events_interval = 2 send_events_interval = 2 # ======== end of neutron nova interactions ========== # # Options defined in oslo.messaging # # Use durable queues in amqp. (boolean value) # Deprecated group/name - [DEFAULT]/rabbit_durable_queues # amqp_durable_queues=false # Auto-delete queues in amqp. (boolean value) # amqp_auto_delete=false # Size of RPC connection pool. (integer value) # rpc_conn_pool_size=30 # Qpid broker hostname. (string value) # qpid_hostname=localhost # Qpid broker port. (integer value) # qpid_port=5672 # Qpid HA cluster host:port pairs. (list value) # qpid_hosts=$qpid_hostname:$qpid_port # Username for Qpid connection. (string value) # qpid_username= # Password for Qpid connection. (string value) # qpid_password= # Space separated list of SASL mechanisms to use for auth. # (string value) # qpid_sasl_mechanisms= # Seconds between connection keepalive heartbeats. (integer # value) # qpid_heartbeat=60 # Transport to use, either 'tcp' or 'ssl'. (string value) # qpid_protocol=tcp # Whether to disable the Nagle algorithm. (boolean value) # qpid_tcp_nodelay=true # The qpid topology version to use. Version 1 is what was # originally used by impl_qpid. Version 2 includes some # backwards-incompatible changes that allow broker federation # to work. Users should update to version 2 when they are # able to take everything down, as it requires a clean break. # (integer value) # qpid_topology_version=1 # SSL version to use (valid only if SSL enabled). valid values # are TLSv1, SSLv23 and SSLv3. SSLv2 may be available on some # distributions. (string value) # kombu_ssl_version= # SSL key file (valid only if SSL enabled). (string value) # kombu_ssl_keyfile= # SSL cert file (valid only if SSL enabled). (string value) # kombu_ssl_certfile= # SSL certification authority file (valid only if SSL # enabled). (string value) # kombu_ssl_ca_certs= # How long to wait before reconnecting in response to an AMQP # consumer cancel notification. (floating point value) # kombu_reconnect_delay=1.0 # The RabbitMQ broker address where a single node is used. # (string value) # rabbit_host=localhost # The RabbitMQ broker port where a single node is used. # (integer value) # rabbit_port=5672 # RabbitMQ HA cluster host:port pairs. (list value) # rabbit_hosts=$rabbit_host:$rabbit_port # Connect over SSL for RabbitMQ. (boolean value) # rabbit_use_ssl=false # The RabbitMQ userid. (string value) # rabbit_userid=guest # The RabbitMQ password. (string value) # rabbit_password=guest # the RabbitMQ login method (string value) # rabbit_login_method=AMQPLAIN # The RabbitMQ virtual host. (string value) # rabbit_virtual_host=/ # How frequently to retry connecting with RabbitMQ. (integer # value) # rabbit_retry_interval=1 # How long to backoff for between retries when connecting to # RabbitMQ. (integer value) # rabbit_retry_backoff=2 # Maximum number of RabbitMQ connection retries. Default is 0 # (infinite retry count). (integer value) # rabbit_max_retries=0 # Use HA queues in RabbitMQ (x-ha-policy: all). If you change # this option, you must wipe the RabbitMQ database. (boolean # value) # rabbit_ha_queues=false # If passed, use a fake RabbitMQ provider. (boolean value) # fake_rabbit=false # ZeroMQ bind address. Should be a wildcard (*), an ethernet # interface, or IP. The ""host"" option should point or resolve # to this address. (string value) # rpc_zmq_bind_address=* # MatchMaker driver. (string value) # rpc_zmq_matchmaker=oslo.messaging._drivers.matchmaker.MatchMakerLocalhost # ZeroMQ receiver listening port. (integer value) # rpc_zmq_port=9501 # Number of ZeroMQ contexts, defaults to 1. (integer value) # rpc_zmq_contexts=1 # Maximum number of ingress messages to locally buffer per # topic. Default is unlimited. (integer value) # rpc_zmq_topic_backlog= # Directory for holding IPC sockets. (string value) # rpc_zmq_ipc_dir=/var/run/openstack # Name of this node. Must be a valid hostname, FQDN, or IP # address. Must match ""host"" option, if running Nova. (string # value) # rpc_zmq_host=oslo # Seconds to wait before a cast expires (TTL). Only supported # by impl_zmq. (integer value) # rpc_cast_timeout=30 rpc_cast_timeout=30 # Heartbeat frequency. (integer value) # matchmaker_heartbeat_freq=300 # Heartbeat time-to-live. (integer value) # matchmaker_heartbeat_ttl=600 # Size of RPC greenthread pool. (integer value) # rpc_thread_pool_size=64 rpc_thread_pool_size=70 # Driver or drivers to handle sending notifications. (multi # valued) # notification_driver= {%- if server.notification %} notification_driver = neutron.openstack.common.notifier.rpc_notifier {%- endif %} # AMQP topic used for OpenStack notifications. (list value) # Deprecated group/name - [rpc_notifier2]/topics # notification_topics=notifications # Seconds to wait for a response from a call. (integer value) # rpc_response_timeout=60 rpc_response_timeout=60 # A URL representing the messaging driver to use and its full # configuration. If not set, we fall back to the rpc_backend # option and driver specific configuration. (string value) # transport_url= # The messaging driver to use, defaults to rabbit. Other # drivers include qpid and zmq. (string value) # rpc_backend=rabbit rpc_backend=rabbit # The default exchange under which topics are scoped. May be # overridden by an exchange name specified in the # transport_url option. (string value) # control_exchange=openstack [matchmaker_redis] # # Options defined in oslo.messaging # # Host to locate redis. (string value) # host=127.0.0.1 # Use this port to connect to redis host. (integer value) # port=6379 # Password for Redis server (optional). (string value) # password= [matchmaker_ring] # # Options defined in oslo.messaging # # Matchmaker ring file (JSON). (string value) # Deprecated group/name - [DEFAULT]/matchmaker_ringfile # ringfile=/etc/oslo/matchmaker_ring.json [quotas] # Default driver to use for quota checks # quota_driver = neutron.db.quota_db.DbQuotaDriver quota_driver = neutron_plugin_contrail.plugins.opencontrail.quota.driver.QuotaDriver # Resource name(s) that are supported in quota features # quota_items = network,subnet,port # Default number of resource allowed per tenant. A negative value means # unlimited. # default_quota = -1 # Number of networks allowed per tenant. A negative value means unlimited. # quota_network = 10 # Number of subnets allowed per tenant. A negative value means unlimited. # quota_subnet = 10 # Number of ports allowed per tenant. A negative value means unlimited. # quota_port = 50 # Number of security groups allowed per tenant. A negative value means # unlimited. # quota_security_group = 10 # Number of security group rules allowed per tenant. A negative value means # unlimited. # quota_security_group_rule = 100 # Number of vips allowed per tenant. A negative value means unlimited. # quota_vip = 10 # Number of pools allowed per tenant. A negative value means unlimited. # quota_pool = 10 # Number of pool members allowed per tenant. A negative value means unlimited. # The default is unlimited because a member is not a real resource consumer # on Openstack. However, on back-end, a member is a resource consumer # and that is the reason why quota is possible. # quota_member = -1 # Number of health monitors allowed per tenant. A negative value means # unlimited. # The default is unlimited because a health monitor is not a real resource # consumer on Openstack. However, on back-end, a member is a resource consumer # and that is the reason why quota is possible. # quota_health_monitor = -1 # Number of loadbalancers allowed per tenant. A negative value means unlimited. # quota_loadbalancer = 10 # Number of listeners allowed per tenant. A negative value means unlimited. # quota_listener = -1 # Number of v2 health monitors allowed per tenant. A negative value means # unlimited. These health monitors exist under the lbaas v2 API # quota_healthmonitor = -1 # Number of routers allowed per tenant. A negative value means unlimited. # quota_router = 10 # Number of floating IPs allowed per tenant. A negative value means unlimited. # quota_floatingip = 50 # Number of firewalls allowed per tenant. A negative value means unlimited. # quota_firewall = 1 # Number of firewall policies allowed per tenant. A negative value means # unlimited. # quota_firewall_policy = 1 # Number of firewall rules allowed per tenant. A negative value means # unlimited. # quota_firewall_rule = 100 [agent] # Use ""sudo neutron-rootwrap /etc/neutron/rootwrap.conf"" to use the real # root filter facility. # Change to ""sudo"" to skip the filtering and just run the command directly root_helper = sudo /usr/bin/neutron-rootwrap /etc/neutron/rootwrap.conf # Set to true to add comments to generated iptables rules that describe # each rule's purpose. (System must support the iptables comments module.) # comment_iptables_rules = True # Root helper daemon application to use when possible. # root_helper_daemon = # Use the root helper when listing the namespaces on a system. This may not # be required depending on the security configuration. If the root helper is # not required, set this to False for a performance improvement. # use_helper_for_ns_read = True # The interval to check external processes for failure in seconds (0=disabled) # check_child_processes_interval = 60 # Action to take when an external process spawned by an agent dies # Values: # respawn - Respawns the external process # exit - Exits the agent # check_child_processes_action = respawn # =========== items for agent management extension ============= # seconds between nodes reporting state to server; should be less than # agent_down_time, best if it is half or less than agent_down_time # report_interval = 30 # =========== end of items for agent management extension ===== [keystone_authtoken] identity_uri = http://{{ neutron.identity.host }}:5000 auth_host = {{ neutron.identity.host }} auth_port = {{ neutron.identity.port }} auth_protocol = http admin_tenant_name = {{ neutron.identity.tenant }} admin_user = {{ neutron.identity.user }} admin_password = {{ neutron.identity.password }} auth_uri=http://{{ neutron.identity.host }}:5000 auth_url=http://{{ neutron.identity.host }}:35357 [database] # This line MUST be changed to actually run the plugin. # Example: connection = sqlite:////var/lib/neutron/neutron.sqlite # Replace 127.0.0.1 above with the IP address of the database used by the # main neutron server. (Leave it as is if the database runs on this host.) # connection = sqlite:// # NOTE: In deployment the [database] section and its connection attribute may # be set in the corresponding core plugin '.ini' file. However, it is suggested # to put the [database] section and its connection attribute in this # configuration file. # Database engine for which script will be generated when using offline # migration # engine = # The SQLAlchemy connection string used to connect to the slave database # slave_connection = # Database reconnection retry times - in event connectivity is lost # set to -1 implies an infinite retry count # max_retries = 10 # Database reconnection interval in seconds - if the initial connection to the # database fails # retry_interval = 10 # Minimum number of SQL connections to keep open in a pool # min_pool_size = 1 # Maximum number of SQL connections to keep open in a pool # max_pool_size = 10 # Timeout in seconds before idle sql connections are reaped # idle_timeout = 3600 # If set, use this value for max_overflow with sqlalchemy # max_overflow = 20 # Verbosity of SQL debugging information. 0=None, 100=Everything # connection_debug = 0 # Add python stack traces to SQL as comment strings # connection_trace = False # If set, use this value for pool_timeout with sqlalchemy # pool_timeout = 10 [nova] # Name of the plugin to load # auth_plugin = # Config Section from which to load plugin specific options # auth_section = # PEM encoded Certificate Authority to use when verifying HTTPs connections. # cafile = # PEM encoded client certificate cert file # certfile = # Verify HTTPS connections. # insecure = False # PEM encoded client certificate key file # keyfile = # Name of nova region to use. Useful if keystone manages more than one region. # region_name = # Timeout value for http requests # timeout = [oslo_concurrency] # Directory to use for lock files. For security, the specified directory should # only be writable by the user running the processes that need locking. # Defaults to environment variable OSLO_LOCK_PATH. If external locks are used, # a lock path must be set. lock_path = $state_path/lock # Enables or disables inter-process locks. # disable_process_locking = False [oslo_policy] # The JSON file that defines policies. # policy_file = policy.json # Default rule. Enforced when a requested rule is not found. # policy_default_rule = default # Directories where policy configuration files are stored. # They can be relative to any directory in the search path defined by the # config_dir option, or absolute paths. The file defined by policy_file # must exist for these directories to be searched. Missing or empty # directories are ignored. # policy_dirs = policy.d [oslo_messaging_amqp] # # From oslo.messaging # # Address prefix used when sending to a specific server (string value) # Deprecated group/name - [amqp1]/server_request_prefix # server_request_prefix = exclusive # Address prefix used when broadcasting to all servers (string value) # Deprecated group/name - [amqp1]/broadcast_prefix # broadcast_prefix = broadcast # Address prefix when sending to any server in group (string value) # Deprecated group/name - [amqp1]/group_request_prefix # group_request_prefix = unicast # Name for the AMQP container (string value) # Deprecated group/name - [amqp1]/container_name # container_name = # Timeout for inactive connections (in seconds) (integer value) # Deprecated group/name - [amqp1]/idle_timeout # idle_timeout = 0 # Debug: dump AMQP frames to stdout (boolean value) # Deprecated group/name - [amqp1]/trace # trace = false # CA certificate PEM file for verifing server certificate (string value) # Deprecated group/name - [amqp1]/ssl_ca_file # ssl_ca_file = # Identifying certificate PEM file to present to clients (string value) # Deprecated group/name - [amqp1]/ssl_cert_file # ssl_cert_file = # Private key PEM file used to sign cert_file certificate (string value) # Deprecated group/name - [amqp1]/ssl_key_file # ssl_key_file = # Password for decrypting ssl_key_file (if encrypted) (string value) # Deprecated group/name - [amqp1]/ssl_key_password # ssl_key_password = # Accept clients using either SSL or plain TCP (boolean value) # Deprecated group/name - [amqp1]/allow_insecure_clients # allow_insecure_clients = false [oslo_messaging_qpid] # # From oslo.messaging # # Use durable queues in AMQP. (boolean value) # Deprecated group/name - [DEFAULT]/rabbit_durable_queues # amqp_durable_queues = false # Auto-delete queues in AMQP. (boolean value) # Deprecated group/name - [DEFAULT]/amqp_auto_delete # amqp_auto_delete = false # Size of RPC connection pool. (integer value) # Deprecated group/name - [DEFAULT]/rpc_conn_pool_size # rpc_conn_pool_size = 30 # Qpid broker hostname. (string value) # Deprecated group/name - [DEFAULT]/qpid_hostname # qpid_hostname = localhost # Qpid broker port. (integer value) # Deprecated group/name - [DEFAULT]/qpid_port # qpid_port = 5672 # Qpid HA cluster host:port pairs. (list value) # Deprecated group/name - [DEFAULT]/qpid_hosts # qpid_hosts = $qpid_hostname:$qpid_port # Username for Qpid connection. (string value) # Deprecated group/name - [DEFAULT]/qpid_username # qpid_username = # Password for Qpid connection. (string value) # Deprecated group/name - [DEFAULT]/qpid_password # qpid_password = # Space separated list of SASL mechanisms to use for auth. (string value) # Deprecated group/name - [DEFAULT]/qpid_sasl_mechanisms # qpid_sasl_mechanisms = # Seconds between connection keepalive heartbeats. (integer value) # Deprecated group/name - [DEFAULT]/qpid_heartbeat # qpid_heartbeat = 60 # Transport to use, either 'tcp' or 'ssl'. (string value) # Deprecated group/name - [DEFAULT]/qpid_protocol # qpid_protocol = tcp # Whether to disable the Nagle algorithm. (boolean value) # Deprecated group/name - [DEFAULT]/qpid_tcp_nodelay # qpid_tcp_nodelay = true # The number of prefetched messages held by receiver. (integer value) # Deprecated group/name - [DEFAULT]/qpid_receiver_capacity # qpid_receiver_capacity = 1 # The qpid topology version to use. Version 1 is what was originally used by # impl_qpid. Version 2 includes some backwards-incompatible changes that allow # broker federation to work. Users should update to version 2 when they are # able to take everything down, as it requires a clean break. (integer value) # Deprecated group/name - [DEFAULT]/qpid_topology_version # qpid_topology_version = 1 [oslo_messaging_rabbit] # # From oslo.messaging # # Use durable queues in AMQP. (boolean value) # Deprecated group/name - [DEFAULT]/rabbit_durable_queues # amqp_durable_queues = false # Auto-delete queues in AMQP. (boolean value) # Deprecated group/name - [DEFAULT]/amqp_auto_delete # amqp_auto_delete = false # Size of RPC connection pool. (integer value) # Deprecated group/name - [DEFAULT]/rpc_conn_pool_size rpc_conn_pool_size = 40 # SSL version to use (valid only if SSL enabled). Valid values are TLSv1 and # SSLv23. SSLv2, SSLv3, TLSv1_1, and TLSv1_2 may be available on some # distributions. (string value) # Deprecated group/name - [DEFAULT]/kombu_ssl_version # kombu_ssl_version = # SSL key file (valid only if SSL enabled). (string value) # Deprecated group/name - [DEFAULT]/kombu_ssl_keyfile # kombu_ssl_keyfile = # SSL cert file (valid only if SSL enabled). (string value) # Deprecated group/name - [DEFAULT]/kombu_ssl_certfile # kombu_ssl_certfile = # SSL certification authority file (valid only if SSL enabled). (string value) # Deprecated group/name - [DEFAULT]/kombu_ssl_ca_certs # kombu_ssl_ca_certs = # How long to wait before reconnecting in response to an AMQP consumer cancel # notification. (floating point value) # Deprecated group/name - [DEFAULT]/kombu_reconnect_delay # kombu_reconnect_delay = 1.0 # The RabbitMQ broker address where a single node is used. (string value) # Deprecated group/name - [DEFAULT]/rabbit_host # rabbit_host = localhost rabbit_host = {{ neutron.message_queue.host }} rabbit_port = {{ neutron.message_queue.port }} rabbit_userid = {{ neutron.message_queue.user }} rabbit_password = {{ neutron.message_queue.password }} rabbit_virtual_host = {{ neutron.message_queue.virtual_host }} # The RabbitMQ broker port where a single node is used. (integer value) # Deprecated group/name - [DEFAULT]/rabbit_port # rabbit_port = 5672 # RabbitMQ HA cluster host:port pairs. (list value) # Deprecated group/name - [DEFAULT]/rabbit_hosts # rabbit_hosts = $rabbit_host:$rabbit_port # Connect over SSL for RabbitMQ. (boolean value) # Deprecated group/name - [DEFAULT]/rabbit_use_ssl # rabbit_use_ssl = false # The RabbitMQ userid. (string value) # Deprecated group/name - [DEFAULT]/rabbit_userid # rabbit_userid = guest # The RabbitMQ password. (string value) # Deprecated group/name - [DEFAULT]/rabbit_password # rabbit_password = guest # The RabbitMQ login method. (string value) # Deprecated group/name - [DEFAULT]/rabbit_login_method # rabbit_login_method = AMQPLAIN # The RabbitMQ virtual host. (string value) # Deprecated group/name - [DEFAULT]/rabbit_virtual_host # rabbit_virtual_host = / # How frequently to retry connecting with RabbitMQ. (integer value) rabbit_retry_interval = 1 # How long to backoff for between retries when connecting to RabbitMQ. (integer # value) # Deprecated group/name - [DEFAULT]/rabbit_retry_backoff rabbit_retry_backoff = 2 # Maximum number of RabbitMQ connection retries. Default is 0 (infinite retry # count). (integer value) # Deprecated group/name - [DEFAULT]/rabbit_max_retries # rabbit_max_retries = 0 rabbit_max_retries = 0 # Use HA queues in RabbitMQ (x-ha-policy: all). If you change this option, you # must wipe the RabbitMQ database. (boolean value) # Deprecated group/name - [DEFAULT]/rabbit_ha_queues # rabbit_ha_queues = false # Deprecated, use rpc_backend=kombu+memory or rpc_backend=fake (boolean value) # Deprecated group/name - [DEFAULT]/fake_rabbit # fake_rabbit = false [QUOTAS] quota_network = -1 quota_subnet = -1 quota_port = -1 [NOVA] vif_types = vrouter [service_providers] service_provider = LOADBALANCER:Opencontrail:neutron_plugin_contrail.plugins.opencontrail.loadbalancer.driver.OpencontrailLoadbalancerDriver:default ",,2106,0
openstack%2Frally~master~I12123a021fcff6a48d46fa14d5148d3e7e98e207,openstack/rally,master,I12123a021fcff6a48d46fa14d5148d3e7e98e207,"Revert ""Make Rally cope with unversioned keystone URL""",MERGED,2016-02-18 16:26:44.000000000,2016-02-18 21:50:19.000000000,2016-02-18 21:50:17.000000000,"[{'_account_id': 3}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 15750}]","[{'number': 1, 'created': '2016-02-18 16:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a50d86dbf794443345b1f78c52158095e5bb8f97', 'message': 'Revert ""Make Rally cope with unversioned keystone URL""\n\nThis reverts commit 43028c9bbae60b4fbdf31272e420e1096af363e6, which broke\nseveral features:\n - existing deployemnt with given endpoint\n - insecure mode\n\nCloses-Bug: #1545889\nCloses-Bug: #1547092\n\nChange-Id: I12123a021fcff6a48d46fa14d5148d3e7e98e207\n'}, {'number': 2, 'created': '2016-02-18 17:06:04.000000000', 'files': ['tests/unit/test_osclients.py', 'rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/4bac4bdfe055c8f60eff87fe9682463ae626496a', 'message': 'Revert ""Make Rally cope with unversioned keystone URL""\n\nThis reverts commit 43028c9bbae60b4fbdf31272e420e1096af363e6, which broke\nseveral features:\n - existing deployemnt with given endpoint\n - insecure mode\n\nCloses-Bug: #1545889\nCloses-Bug: #1547092\nCloses-Bug: #1544839\n\nChange-Id: I12123a021fcff6a48d46fa14d5148d3e7e98e207\n'}]",0,281935,4bac4bdfe055c8f60eff87fe9682463ae626496a,13,7,2,9545,,,0,"Revert ""Make Rally cope with unversioned keystone URL""

This reverts commit 43028c9bbae60b4fbdf31272e420e1096af363e6, which broke
several features:
 - existing deployemnt with given endpoint
 - insecure mode

Closes-Bug: #1545889
Closes-Bug: #1547092
Closes-Bug: #1544839

Change-Id: I12123a021fcff6a48d46fa14d5148d3e7e98e207
",git fetch https://review.opendev.org/openstack/rally refs/changes/35/281935/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_osclients.py', 'rally/osclients.py']",2,a50d86dbf794443345b1f78c52158095e5bb8f97,bug/1545889," endpoint = endpoint or self._get_endpoint() kc = self.keystone() if auth is None: @staticmethod def _create_keystone_client(args): from keystoneclient import discover as keystone_discover discover = keystone_discover.Discover(**args) for version_data in discover.version_data(): version = version_data[""version""] if version[0] <= 2: from keystoneclient.v2_0 import client as keystone_v2 return keystone_v2.Client(**args) elif version[0] == 3: from keystoneclient.v3 import client as keystone_v3 return keystone_v3.Client(**args) raise exceptions.RallyException(""Failed to discover keystone version "" ""for url %(auth_url)s."", **args)"," if auth is None: endpoint = endpoint or self._get_endpoint() kc = self.keystone() def _create_keystone_client(self, args): from keystoneclient.auth import identity from keystoneclient import client auth_arg_list = [ ""username"", ""project_name"", ""tenant_name"", ""auth_url"", ""password"", ] # NOTE(bigjools): If forcing a v2.0 URL then you cannot specify # domain-related info, or the service discovery will fail. if ""v2.0"" not in args[""auth_url""]: auth_arg_list.extend( [""user_domain_name"", ""domain_name"", ""project_domain_name""]) auth_args = {key: args.get(key) for key in auth_arg_list} auth = identity.Password(**auth_args) args[""session""] = self._get_session(auth=auth) return client.Client(**args)",62,87
openstack%2Ffuel-specs~master~I2460ece84d6d501e989fd990924706272ca35545,openstack/fuel-specs,master,I2460ece84d6d501e989fd990924706272ca35545,Support for DPDK for improved networking performance,MERGED,2016-01-27 14:52:18.000000000,2016-02-18 21:42:16.000000000,2016-02-18 21:42:16.000000000,"[{'_account_id': 3}, {'_account_id': 6677}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 7562}, {'_account_id': 7604}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8787}, {'_account_id': 9091}, {'_account_id': 9387}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 11090}, {'_account_id': 11587}, {'_account_id': 11604}, {'_account_id': 11647}, {'_account_id': 11708}, {'_account_id': 13343}, {'_account_id': 14864}, {'_account_id': 14985}, {'_account_id': 18366}]","[{'number': 1, 'created': '2016-01-27 14:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/97eec25996841145ccd0a7e2770fe32cb2e15243', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 2, 'created': '2016-01-28 11:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a75ccc3a08f972a6005b50e4bf4f98669416a75d', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 3, 'created': '2016-01-28 11:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f3b0b5a7eff58743cca3f3a5f0b4dd6506cc1baf', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 4, 'created': '2016-01-28 11:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/aa4e5656e7b3479cbdf3cdcad8224b8cbf55d44b', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 5, 'created': '2016-02-05 14:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/0d67a6fc2139eda2a3470e88fce30de983794508', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 6, 'created': '2016-02-05 14:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/737e7de60def87676298018697008a3aeadfa365', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 7, 'created': '2016-02-09 15:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/380584b0db118e69d7f4d83376e660489dc6a699', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 8, 'created': '2016-02-10 13:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/27fc31d899f817283e05aba225cb33ddaec3b3dc', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 9, 'created': '2016-02-10 15:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2d78c7861c03f949fcde9372cc4c25bdab741d93', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 10, 'created': '2016-02-11 14:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/268bcd324117d7b4fd519a7ce3507fca09c79a3a', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 11, 'created': '2016-02-11 14:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/684703ea99141845d57cd85f7a5e5ef938375f8c', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 12, 'created': '2016-02-16 10:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6f8334fc7d2d283aed733caa5dceba022b51c2a5', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 13, 'created': '2016-02-17 15:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/8a75b70bd0f18c15b9ebcdd2cd8a0756e43b24e5', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}, {'number': 14, 'created': '2016-02-17 17:07:40.000000000', 'files': ['specs/9.0/support-dpdk.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/7fe09f1cdba7ba8ee9eaff804b8e11cdc47f4dcd', 'message': 'Support for DPDK for improved networking performance\n\nChange-Id: I2460ece84d6d501e989fd990924706272ca35545\nImplements: blueprint support-dpdk\n'}]",169,273084,7fe09f1cdba7ba8ee9eaff804b8e11cdc47f4dcd,109,22,14,11708,,,0,"Support for DPDK for improved networking performance

Change-Id: I2460ece84d6d501e989fd990924706272ca35545
Implements: blueprint support-dpdk
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/84/273084/11 && git format-patch -1 --stdout FETCH_HEAD,['specs/9.0/support-dpdk.rst'],1,97eec25996841145ccd0a7e2770fe32cb2e15243,bp/support-dpdk,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================================== Support for DPDK for improved networking performance ==================================================== https://blueprints.launchpad.net/fuel/+spec/support-dpdk In order to get as close to wire-line speed as possible for virtual machines, we want to install and utilize OVS w/ DPDK on some compute nodes. -------------------- Problem description -------------------- DPDK-backed OpenVSwitch and vhostuser features is fully merged in OpenStack Mitaka. With this set of features end user could achieve boost to the networking performance, and unlike SR-IOV, end user can still control traffic via OpenFlow rules. ---------------- Proposed changes ---------------- Enabling DPDK requires: * Discover compatible hardware by driver list and provide user with information about compatible NICs * Proper network configuration with dedicated Private network for VLAN segmentation. * Making configurations on both controller and compute side, including nova, neutron, interface binding to the DPDK and OpenVSwitch. Web UI ====== On Nodes tab, in Interfaces configuration dialog for every interface should be: * Information whether interface is DPDK capable * Options to enable DPDK on network interface Only Private network with VLAN segmentation could be placed on DPDK enabled interface. Nailgun ======= Enabling DPDK requires HugePages to be enabled on corresponding nodes. Data model ---------- astute.yaml will be extended as following :: network_scheme: transformations: - action: add-br name: br-prv provider: ovs vendor_specific: datapath_type: netdev - action: add-port name: enp1s0f0 provider: dpdk vendor_specific: driver: igb_uio use_dpdk: true `use_dpdk` will enable dpdk on compute node. If end user chooses to use DPDK for interface to Private network, we need to add vendor specific attrubute `datapath_type: netdev` to bridge. NIC will be added as DPDK interface using `dpdk` provider for `add-port` transformation. REST API -------- Only payload changes. Orchestration ============= None RPC Protocol ------------ Only payload changes. Fuel Client =========== TBD Plugins ======= None Fuel Library ============ Fuel library will consume data from astute.yaml. * dpdk packages will be installed. * l23network will configure interface as dpdk, connect it to ovs bridge and store it in config. * `vhostuser_socket_dir` will be configured in plugin.ini on compute node to enable vhostuser in neutron. * OpenVSwitch and libvirt will be configured to use vhostuser. ------------ Alternatives ------------ To achieve same networking performance SR-IOV could be used. Comparing to it, DPDK allows to use experimental Security Groups engine. -------------- Upgrade impact -------------- None --------------- Security impact --------------- None -------------------- Notifications impact -------------------- None --------------- End user impact --------------- User interface impact described in Web UI section. ------------------ Performance impact ------------------ Performance penalties is not expected. ----------------- Deployment impact ----------------- * This feature will require to use VLAN segmentation and dedicated DPDK capable network interface for Private network. ---------------- Developer impact ---------------- None --------------------- Infrastructure impact --------------------- This feature could be possibly tested on virtual environment. -------------------- Documentation impact -------------------- TBD -------------- Implementation -------------- Assignee(s) =========== Primary assignee: yottatsa skolekonov Mandatory design review: xenolog dteselkin Work Items ========== * Enable DPDK configuration in Fuel * Support of configuring DPDK via fuel API * Support of configuring DPDK via fuel CLI * Support of DPDK on UI * Manual testing * Create a system test for DPDK Dependencies ============ This feature depends on `HugePages feature <https://blueprints.launchpad.net/fuel/+spec/support-hugepages>`_. ------------ Testing, QA ------------ TBD Acceptance criteria =================== User should be able to deploy compute nodes with network interface in DPDK mode, and boot a VM with vhostuser and HugePages enabled. ---------- References ---------- * `Neutron Open vSwitch vhost-user support <http://docs.openstack.org/developer/neutron/devref/ovs_vhostuser.html>`_ * `OpenVSwitch DPDK Firewall implementation <https://github.com/openstack/networking-ovs-dpdk>`_ * `List of supported NICs <http://dpdk.org/doc/nics>`_ ",,240,0
openstack%2Ffuel-specs~master~I3b5a10212ebaa9601b316e0082a1c3137353c45b,openstack/fuel-specs,master,I3b5a10212ebaa9601b316e0082a1c3137353c45b,Daemon resource allocation control,MERGED,2016-02-10 15:15:06.000000000,2016-02-18 21:41:48.000000000,2016-02-18 21:41:48.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 9448}, {'_account_id': 10391}, {'_account_id': 11090}, {'_account_id': 12559}, {'_account_id': 14864}, {'_account_id': 15692}, {'_account_id': 15929}, {'_account_id': 16771}, {'_account_id': 18436}]","[{'number': 1, 'created': '2016-02-10 15:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/28ffd8268518d26fbdeca8df67412cef854fcf31', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 2, 'created': '2016-02-11 08:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a2f0be90193f5ebb2ef943578712de57416f2824', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 3, 'created': '2016-02-11 15:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/f8934f47e4a60373a6d7d1c61602a43964e19291', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 4, 'created': '2016-02-12 09:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/59f3be5b238fd2152cf29403457c7c1f05777418', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 5, 'created': '2016-02-12 10:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/ecd12ed89e52aadd3d74ef1a1e9082db0c0d33da', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 6, 'created': '2016-02-12 11:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/ff0f17bf8b9b56d6f59960750d257cb7a13d5176', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 7, 'created': '2016-02-12 11:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/3204eee3a1f7e7fd39a31a436e9bc96187a9146e', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 8, 'created': '2016-02-12 12:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/64ab18506cf496cb20226cad3274381971a8b698', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 9, 'created': '2016-02-15 09:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/1a6a1f3f76bcfbf76be575252d1d73b8d965fe03', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 10, 'created': '2016-02-15 10:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6c4e9c7ba3319844d06adec327cf7743531decd4', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 11, 'created': '2016-02-15 11:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4d196fc0615e0716e1ce721f9326b5a7235f39fe', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 12, 'created': '2016-02-15 16:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/e67e2505a6ab53c194ea06622363944972f60f4a', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 13, 'created': '2016-02-16 14:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2265daf08dc59ef2d52a196f52c464bb1582c2e2', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}, {'number': 14, 'created': '2016-02-16 19:13:33.000000000', 'files': ['specs/9.0/cgroups.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a82f427d68d0793af0719b1bcdce0e6e2607d47c', 'message': 'Daemon resource allocation control\n\nAdd spec for support daemon resource allocation\ncontrol by means of cgroups kernel feature.\n\nCo-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>\nChange-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b\n'}]",57,278426,a82f427d68d0793af0719b1bcdce0e6e2607d47c,69,13,14,16771,,,0,"Daemon resource allocation control

Add spec for support daemon resource allocation
control by means of cgroups kernel feature.

Co-Authored-By: Valyavskiy Viacheslav <vvalyavskiy@mirantis.com>
Change-Id: I3b5a10212ebaa9601b316e0082a1c3137353c45b
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/26/278426/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/9.0/cgroups.rst'],1,28ffd8268518d26fbdeca8df67412cef854fcf31,bp/cgroups,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================ Daemon Resource Allocation Control ================================================ https://blueprints.launchpad.net/fuel/+spec/cgroups Support daemon resource control by means of cgroups kernel feature. -------------------- Problem description -------------------- General OS doesn't have any protection against taking all hardware's memory or CPU. So there is need to allocate resources between competing processes, e.g. at the peak time CPU computing resources should be distributed by the specified rules. Proposed changes ---------------- By using cgroups, cloud operator gain fine-grained control over allocating, prioritizing, denying, managing, and monitoring system resources. Hardware resources can be appropriately divided up among tasks and services, increasing overall efficiency. Service set what is supposed to be moved under cgroups control: * all OpenStack services * middleware - rabbitmq - mysql/galera - mongodb - ceph services It was decided to move all described services above under cgroups resources control, but cgroups limits will not be activated by default. So cgroups profiles will be configured for proposed resources without specified limits if they were not explicitly configured by the user. User will be able to specify limits via UI/API/CLI (one more field will be introduced into cluster's settings structure). New puppet task to apply cgroups configuration on target nodes will be introduced. It will be run on post deploment stage: .. code-block:: yaml id: cgroups type: puppet version: 2.0.0 groups: ['/.*/'] requires: [post_deployment_start] required_for: [post_deployment_end] condition: ""settings:cgroups.enabled.value == true"" parameters: puppet_manifest: .../osnailyfacter/modular/cgroups/cgroups.pp puppet_modules: /etc/puppet/modules timeout: 3600 cwd: / Web UI ====== New section to configure cgroups limits for services will be introduced. Nailgun ======= None Data model ---------- Cloud operator could add/update a data to override default cgroups settings. Example of a new structure(it will be included into openstack.yaml and may be modified): .. code-block:: yaml cgroups: metadata: label: ""Configure cgroups"" description: ""If selected, Cgroups will be configured"" weight: 10 enabled: value: false type: ""checkbox"" blkio: blkio.weight: - cinder: 500 cpu: cpu.shares: - keystone: 70 cpuacct: cpuset: devices: freezer: memory: limit_in_bytes: - nova: 5242880 - neutron: 5242880 memsw.limit_in_bytes: - mysqld: 0 - rabbitmq: 0 perf_event: net_cls: net_prio: ns: ... REST API -------- None Orchestration ============= None RPC Protocol ------------ None Fuel Client =========== None Plugins ======= None Fuel Library ============ Should be implemented brand new cgroups puppet module which will be used by main task to configure given limits for services on the cluster nodes. Module should be able to get input data from hiera structure then validate and apply it. ------------ Alternatives ------------ Limit CPU utilization by nice(1), for limiting memory allocation rely upon service configuration/runtime constrains itself. -------------- Upgrade impact -------------- From life cycle management perspective, cloud operator will be able to change cgroups settings for the deployed cluster in following way: 1. change service's limits in cluster's settings via UI/CLI/API 2. run 'hiera' and 'cgroups' taks on the cluster via CLI (fuel node --node-id ID1, ID2 --tasks hiera,cgroups) --------------- Security impact --------------- None -------------------- Notifications impact -------------------- None --------------- End user impact --------------- User will be able to configure cgroups for set of services using API/CLI/UI. ------------------ Performance impact ------------------ With emploing cgroups kernel feature hardware resources can be appropriately divided up among tasks and services, increasing overall efficiency. ----------------- Deployment impact ----------------- None ---------------- Developer impact ---------------- None --------------------- Infrastructure impact --------------------- None -------------------- Documentation impact -------------------- This feature should be described in the documentation. -------------- Implementation -------------- Assignee(s) =========== Primary assignee: Other contributors: Mandatory design reviewer: Work Items ========== * Implement cgroups puppet module * Introduce new `cgroups` section into openstack.yaml file * Place openstack/middleware services in cgroups (create task) * Testing of overall system impact Dependencies ============ None ------------ Testing, QA ------------ New test should be written which covers this scenario: Acceptance criteria =================== The test which described above should pass. ---------- References ---------- None ",,282,0
openstack%2Ftrove-dashboard~master~I1d3c7f1283e26ddca2a44f41a8464007fd278adb,openstack/trove-dashboard,master,I1d3c7f1283e26ddca2a44f41a8464007fd278adb,Fix cluster launch datastore version handling,MERGED,2016-01-20 16:43:05.000000000,2016-02-18 21:41:10.000000000,2016-02-18 21:41:10.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 9576}, {'_account_id': 12673}]","[{'number': 1, 'created': '2016-01-20 16:43:05.000000000', 'files': ['trove_dashboard/content/database_clusters/forms.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/de24b499d302a30458da03223492c8f9ec75e48f', 'message': ""Fix cluster launch datastore version handling\n\nCluster launch currently does not handle datastore versions containing\ndashes. This is because it splits on all dashes in the full datastore\nstring ('name-version'). The fix is to only split on the first dash.\n\nChange-Id: I1d3c7f1283e26ddca2a44f41a8464007fd278adb\nCloses-Bug: #1536255\n""}]",0,270311,de24b499d302a30458da03223492c8f9ec75e48f,8,4,1,15321,,,0,"Fix cluster launch datastore version handling

Cluster launch currently does not handle datastore versions containing
dashes. This is because it splits on all dashes in the full datastore
string ('name-version'). The fix is to only split on the first dash.

Change-Id: I1d3c7f1283e26ddca2a44f41a8464007fd278adb
Closes-Bug: #1536255
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/11/270311/1 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/content/database_clusters/forms.py'],1,de24b499d302a30458da03223492c8f9ec75e48f,bug/1536255," datastore, datastore_version = data['datastore'].split('-', 1)", datastore = data['datastore'].split('-')[0] datastore_version = data['datastore'].split('-')[1],1,2
openstack%2Ffuel-qa~stable%2F8.0~Ida4e9b38e323f369668ce95859a1ccfdb9dfbfae,openstack/fuel-qa,stable/8.0,Ida4e9b38e323f369668ce95859a1ccfdb9dfbfae,Increase restore timeout to 20 mins,MERGED,2016-02-17 14:51:50.000000000,2016-02-18 21:33:49.000000000,2016-02-18 21:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 11969}, {'_account_id': 14057}, {'_account_id': 15943}, {'_account_id': 16414}]","[{'number': 1, 'created': '2016-02-17 14:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/42af5dd3ec5c44dd8e3ca9a3e228d1cbd14ada27', 'message': 'Increase restore timeout to 20 mins\n\nA restore operation takes more than 10 minutes.\nIn a manual reproducing it takes about 16 mins.\nAn increasing timeouts to 20 minutes should solve\na problem.\n\nChange-Id: Ida4e9b38e323f369668ce95859a1ccfdb9dfbfae\nCloses-Bug:1543658\n'}, {'number': 2, 'created': '2016-02-18 15:12:38.000000000', 'files': ['fuelweb_test/tests/test_backup_restore.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/d6e78db6227201d7166d65fc70998e367342afa3', 'message': 'Increase restore timeout to 20 mins\n\nA restore operation takes more than 10 minutes.\nIn a manual reproducing it takes about 16 mins.\nAn increasing timeouts to 20 minutes should solve\na problem.\n\nChange-Id: Ida4e9b38e323f369668ce95859a1ccfdb9dfbfae\nCloses-Bug:1543658\n'}]",0,281316,d6e78db6227201d7166d65fc70998e367342afa3,20,7,2,14057,,,0,"Increase restore timeout to 20 mins

A restore operation takes more than 10 minutes.
In a manual reproducing it takes about 16 mins.
An increasing timeouts to 20 minutes should solve
a problem.

Change-Id: Ida4e9b38e323f369668ce95859a1ccfdb9dfbfae
Closes-Bug:1543658
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/16/281316/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_backup_restore.py'],1,42af5dd3ec5c44dd8e3ca9a3e228d1cbd14ada27,bug/1543658," seconds=60 * 20, ""run longer then 1200 sec""): seconds=60 * 20, ""run longer then 1200 sec""): seconds=60 * 20, ""run longer then 1200 sec""): seconds=60 * 20, ""run longer then 1200 sec""):"," seconds=60 * 10, ""run longer then 600 sec""): seconds=60 * 10, ""run longer then 600 sec""): seconds=60 * 10, ""run longer then 600 sec""): seconds=60 * 10, ""run longer then 600 sec""):",8,8
openstack%2Fdevstack~master~I8f04de2cde8a123c3825e7ba22aef1f5b311f61c,openstack/devstack,master,I8f04de2cde8a123c3825e7ba22aef1f5b311f61c,Tox: don't check stack-screenrc with bashate,MERGED,2016-02-17 14:27:30.000000000,2016-02-18 21:05:50.000000000,2016-02-18 21:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-17 14:27:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/devstack/commit/33df895ffb042832057222432234172d6db18810', 'message': ""Tox: don't check stack-screenrc with bashate\n\nChange-Id: I8f04de2cde8a123c3825e7ba22aef1f5b311f61c\nCloses-Bug: #1531885\n""}]",0,281306,33df895ffb042832057222432234172d6db18810,10,3,1,7350,,,0,"Tox: don't check stack-screenrc with bashate

Change-Id: I8f04de2cde8a123c3825e7ba22aef1f5b311f61c
Closes-Bug: #1531885
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/281306/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,33df895ffb042832057222432234172d6db18810,bug/1531885, -not -name stack-screenrc \,,1,0
openstack%2Fdevstack~master~I7f84dfb67a3c97003947aefd8a7e3c6454106db4,openstack/devstack,master,I7f84dfb67a3c97003947aefd8a7e3c6454106db4,Respect constraints in tempest tox venvs,MERGED,2016-02-10 04:55:57.000000000,2016-02-18 21:03:12.000000000,2016-02-18 21:03:11.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5196}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-10 04:55:57.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1e31e68557205fa61929ff579e427b7ef86aa2ea', 'message': ""Respect constraints in tempest tox venvs\n\nThis commit is a workaround for respecting upper-constraints. Since\nwe're using tox to handle setting up a venv and running tempest\ncommands we need to manually install the constrained packages inside\nthe tox venvs. This patch does that for all the venvs being created by\ndevstack via tox. However, since tempest has additional tox jobs\ndefined if those are run via devstack those will default to the\ndefault pip install -U -r requirements.txt defined in tempest's\ntox.ini.\n\nChange-Id: I7f84dfb67a3c97003947aefd8a7e3c6454106db4\nCloses-Bug: #1543841\n""}]",0,278206,1e31e68557205fa61929ff579e427b7ef86aa2ea,14,4,1,5196,,,0,"Respect constraints in tempest tox venvs

This commit is a workaround for respecting upper-constraints. Since
we're using tox to handle setting up a venv and running tempest
commands we need to manually install the constrained packages inside
the tox venvs. This patch does that for all the venvs being created by
devstack via tox. However, since tempest has additional tox jobs
defined if those are run via devstack those will default to the
default pip install -U -r requirements.txt defined in tempest's
tox.ini.

Change-Id: I7f84dfb67a3c97003947aefd8a7e3c6454106db4
Closes-Bug: #1543841
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/278206/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,1e31e68557205fa61929ff579e427b7ef86aa2ea,bug/1543841," tox -revenv --notest # NOTE(mtreinish): Respect constraints on tempest verify-config venv tox -evenv -- pip install -c $REQUIREMENTS_DIR/upper-constraints.txt -r requirements.txt tox -evenv -- tempest verify-config -uro $tmp_cfg_file # NOTE(mtreinish) Respect constraints in the tempest full venv, things that # are using a tox job other than full will not be respecting constraints but # running pip install -U on tempest requirements $TEMPEST_DIR/.tox/full/bin/pip install -c $REQUIREMENTS_DIR/upper-constraints.txt -r requirements.txt", tox -revenv -- tempest verify-config -u -r -o $tmp_cfg_file,8,1
openstack%2Fdevstack~master~I99f286d0febb1675b8feb91b6801ad0b159da332,openstack/devstack,master,I99f286d0febb1675b8feb91b6801ad0b159da332,lib/tempest: Post juno-eol cleanup,MERGED,2015-11-24 16:06:44.000000000,2016-02-18 21:02:54.000000000,2016-02-18 21:02:54.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11105}]","[{'number': 1, 'created': '2015-11-24 16:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/dd958009bb924d526530e10ac9b6e65bd8bb51ce', 'message': ""lib/tempest: Post juno-eol cleanup\n\nThere's no need to change these Tempest's default anymore.\nThe feature flags are left in Tempest so that downstream distros can\ncontinue to use Tempest to test Juno.\n\nChange-Id: I99f286d0febb1675b8feb91b6801ad0b159da332\nDepends-On: Ib16afc288d661dbf468447a43bcfbf323c959936\n""}, {'number': 2, 'created': '2016-02-16 14:00:29.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/bae609ef6fe46e70ae48a7647861123cbb16661f', 'message': ""lib/tempest: Post juno-eol cleanup\n\nThere's no need to change these Tempest's default anymore.\nThe feature flags are left in Tempest so that downstream distros can\ncontinue to use Tempest to test Juno.\n\nChange-Id: I99f286d0febb1675b8feb91b6801ad0b159da332\n""}]",0,249296,bae609ef6fe46e70ae48a7647861123cbb16661f,19,6,2,7350,,,0,"lib/tempest: Post juno-eol cleanup

There's no need to change these Tempest's default anymore.
The feature flags are left in Tempest so that downstream distros can
continue to use Tempest to test Juno.

Change-Id: I99f286d0febb1675b8feb91b6801ad0b159da332
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/249296/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,dd958009bb924d526530e10ac9b6e65bd8bb51ce,,, # Volume # TODO(dkranz): Remove the bootable flag when Juno is end of life. iniset $TEMPEST_CONFIG volume-feature-enabled bootable True # TODO(jordanP): Remove the extend_with_snapshot flag when Juno is end of life. iniset $TEMPEST_CONFIG volume-feature-enabled extend_with_snapshot True ,0,6
openstack%2Fcinder~master~Iac7c029a1cc66439f43d441bc6d0832686536961,openstack/cinder,master,Iac7c029a1cc66439f43d441bc6d0832686536961,Don't use Mock.called_once_with that does not exist,MERGED,2016-02-11 15:18:53.000000000,2016-02-18 21:01:53.000000000,2016-02-15 07:15:11.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14305}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16660}, {'_account_id': 17852}, {'_account_id': 19852}]","[{'number': 1, 'created': '2016-02-11 15:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bc3cfa7714a06ee63e3ea880f06aa0dfd378f73d', 'message': ""Don't use Mock.called_once_with that does not exist\n\nclass mock.Mock does not exist method called_once_with, it just exists\nmethod assert_called_once_with. Currently there are still ome places\nwhere we use called_once_with method, this patch let's correct it.\n\nNOTE: called_once_with() does nothing because it's a mock object.\n\nCloses-Bug: #1544522\nChange-Id: Iac7c029a1cc66439f43d441bc6d0832686536961\n""}, {'number': 2, 'created': '2016-02-12 05:30:33.000000000', 'files': ['cinder/tests/unit/test_dellfc.py', 'cinder/tests/unit/api/contrib/test_volume_unmanage.py', 'cinder/tests/unit/backup/drivers/test_backup_posix.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/22cb2e81a6d5dfad022fae5fca7601e2ae9aab88', 'message': ""Don't use Mock.called_once_with that does not exist\n\nclass mock.Mock does not exist method called_once_with, it just exists\nmethod assert_called_once_with. Currently there are still ome places\nwhere we use called_once_with method, this patch let's correct it.\n\nNOTE: called_once_with() does nothing because it's a mock object.\n\nCloses-Bug: #1544522\nChange-Id: Iac7c029a1cc66439f43d441bc6d0832686536961\n""}]",1,279134,22cb2e81a6d5dfad022fae5fca7601e2ae9aab88,61,21,2,15424,,,0,"Don't use Mock.called_once_with that does not exist

class mock.Mock does not exist method called_once_with, it just exists
method assert_called_once_with. Currently there are still ome places
where we use called_once_with method, this patch let's correct it.

NOTE: called_once_with() does nothing because it's a mock object.

Closes-Bug: #1544522
Change-Id: Iac7c029a1cc66439f43d441bc6d0832686536961
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/279134/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_dellfc.py', 'cinder/tests/unit/api/contrib/test_volume_unmanage.py', 'cinder/tests/unit/backup/drivers/test_backup_posix.py']",3,bc3cfa7714a06ee63e3ea880f06aa0dfd378f73d,bug/1544522, os.makedirs.assert_called_once_with(path), os.makedirs.called_once_with(path),4,3
openstack%2Fdevstack~master~I128d32b1e74ee46e24a9eb2e81560e58137b1553,openstack/devstack,master,I128d32b1e74ee46e24a9eb2e81560e58137b1553,Check UNSTACK_ALL or -a flag set on unstack,MERGED,2016-02-17 19:15:02.000000000,2016-02-18 21:00:18.000000000,2016-02-18 21:00:18.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-17 19:15:02.000000000', 'files': ['unstack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8040e69a049731216efcdc3497b78391f7bc2a31', 'message': 'Check UNSTACK_ALL or -a flag set on unstack\n\nThese flags were not functioning as described. Check if UNSTACK_ALL is\nset in env or -a flag is set when calling script.\n\nChange-Id: I128d32b1e74ee46e24a9eb2e81560e58137b1553\nCloses-Bug: #1546687\n'}]",0,281468,8040e69a049731216efcdc3497b78391f7bc2a31,12,3,1,16920,,,0,"Check UNSTACK_ALL or -a flag set on unstack

These flags were not functioning as described. Check if UNSTACK_ALL is
set in env or -a flag is set when calling script.

Change-Id: I128d32b1e74ee46e24a9eb2e81560e58137b1553
Closes-Bug: #1546687
",git fetch https://review.opendev.org/openstack/devstack refs/changes/68/281468/1 && git format-patch -1 --stdout FETCH_HEAD,['unstack.sh'],1,8040e69a049731216efcdc3497b78391f7bc2a31,bug/1546687,"UNSTACK_ALL=${UNSTACK_ALL:-""""} UNSTACK_ALL=""-1""","UNSTACK_ALL="""" UNSTACK_ALL=""""",2,2
openstack%2Fhorizon~stable%2Fliberty~I82783b73940e39d961ac70a5ce86abdaca02eba7,openstack/horizon,stable/liberty,I82783b73940e39d961ac70a5ce86abdaca02eba7,Adds config to disable the password in stack,ABANDONED,2015-11-12 21:01:51.000000000,2016-02-18 20:57:35.000000000,,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6484}, {'_account_id': 6589}, {'_account_id': 6650}, {'_account_id': 16769}, {'_account_id': 18009}]","[{'number': 1, 'created': '2015-11-12 21:01:51.000000000', 'files': ['doc/source/topics/settings.rst', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/project/stacks/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/98ff623c6f166f5d5200f7196a040fb1eda61735', 'message': 'Adds config to disable the password in stack\n\nCurrently a password is needed when doing a stack creation using\nHorizon. This patch adds a configurable setting in local_settings.py\nfile, so that it can be disabled from the stack creation form.\n\nChange-Id: I82783b73940e39d961ac70a5ce86abdaca02eba7\nCloses-bug: #1290344\nCo-Authored-By: Richard Jones <r1chardj0n3s@gmail.com>\nCo-Authored-By: Jesse Keating <jlk@bluebox.net>\n(cherry picked from commit 2465843690c36cfc1179c10d2f4c879c8a964a73)\n'}]",2,244864,98ff623c6f166f5d5200f7196a040fb1eda61735,10,7,1,6484,,,0,"Adds config to disable the password in stack

Currently a password is needed when doing a stack creation using
Horizon. This patch adds a configurable setting in local_settings.py
file, so that it can be disabled from the stack creation form.

Change-Id: I82783b73940e39d961ac70a5ce86abdaca02eba7
Closes-bug: #1290344
Co-Authored-By: Richard Jones <r1chardj0n3s@gmail.com>
Co-Authored-By: Jesse Keating <jlk@bluebox.net>
(cherry picked from commit 2465843690c36cfc1179c10d2f4c879c8a964a73)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/64/244864/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/topics/settings.rst', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/project/stacks/forms.py']",3,98ff623c6f166f5d5200f7196a040fb1eda61735,,"from django.conf import settings if kwargs.get('validate_me'): if self._stack_password_enabled(): self.fields['password'] = forms.CharField( label=_('Password for user ""%s""') % self.request.user.username, help_text=_('This is required for operations to be performed ' 'throughout the lifecycle of the stack'), widget=forms.PasswordInput()) def _stack_password_enabled(self): stack_settings = getattr(settings, 'OPENSTACK_HEAT_STACK', {}) return stack_settings.get('enable_user_pass', True) def _build_parameter_fields(self, template_validate): } if data.get('password'): fields['password'] = data.get('password') } if data.get('password'): fields['password'] = data.get('password')"," if(kwargs.get('validate_me')): def _build_parameter_fields(self, template_validate): self.fields['password'] = forms.CharField( label=_('Password for user ""%s""') % self.request.user.username, help_text=_('This is required for operations to be performed ' 'throughout the lifecycle of the stack'), widget=forms.PasswordInput()) 'password': data.get('password') } 'password': data.get('password') }",39,9
openstack%2Fneutron-vpnaas~master~If85987865e0393892c52f319d7cef526c021e0df,openstack/neutron-vpnaas,master,If85987865e0393892c52f319d7cef526c021e0df,Switch from testr to ostestr,MERGED,2016-02-16 22:03:58.000000000,2016-02-18 20:49:53.000000000,2016-02-18 20:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 10980}, {'_account_id': 11682}, {'_account_id': 12403}, {'_account_id': 12999}]","[{'number': 1, 'created': '2016-02-16 22:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/272eda8bad41cf045596a83d90f7fe38656cf62a', 'message': 'Switch from testr to ostestr\n\nWas seeing py34 (and DSVM) tests failing with an Invocation error, even\nthough the test passed. Switched to ostestr, as is done in Neutron under\ncommit 240facf9e67aa5b205679f397107abfe059a869a, and the test passes\n(not sure what the root cause is here).\n\nChange-Id: If85987865e0393892c52f319d7cef526c021e0df\n'}, {'number': 2, 'created': '2016-02-17 12:44:16.000000000', 'files': ['tools/ostestr_compat_shim.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/7689ea4ac69318b22371a867efe17164e33fde22', 'message': 'Switch from testr to ostestr\n\nWas seeing py34 (and DSVM) tests failing with an Invocation error, even\nthough the test passed. Switched to ostestr, as is done in Neutron under\ncommit 240facf9e67aa5b205679f397107abfe059a869a, and the test passes\n(not sure what the root cause is here).\n\nChange-Id: If85987865e0393892c52f319d7cef526c021e0df\n'}]",0,280952,7689ea4ac69318b22371a867efe17164e33fde22,23,6,2,6659,,,0,"Switch from testr to ostestr

Was seeing py34 (and DSVM) tests failing with an Invocation error, even
though the test passed. Switched to ostestr, as is done in Neutron under
commit 240facf9e67aa5b205679f397107abfe059a869a, and the test passes
(not sure what the root cause is here).

Change-Id: If85987865e0393892c52f319d7cef526c021e0df
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/52/280952/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,272eda8bad41cf045596a83d90f7fe38656cf62a,240770, {toxinidir}/tools/ostestr_compat_shim.sh {posargs} # there is also secret magic in ostestr which lets you run in a fail only, sh tools/pretty_tox.sh '{posargs}' # there is also secret magic in pretty_tox.sh which lets you run in a fail only,2,2
openstack%2Foslo.log~master~I3649049a571490c5ec44a14a0c8640a4b747ad64,openstack/oslo.log,master,I3649049a571490c5ec44a14a0c8640a4b747ad64,Add reno for release notes management,MERGED,2016-02-04 23:24:00.000000000,2016-02-18 20:49:12.000000000,2016-02-18 20:49:12.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-04 23:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/b054210200429a50d012d6725e2150f78b960d30', 'message': 'Add reno for release notes management\n\nRelease notes now required to report removal of deprecated configuration\noptions from oslo.log.\n\nChange-Id: I3649049a571490c5ec44a14a0c8640a4b747ad64\n'}, {'number': 2, 'created': '2016-02-11 18:29:03.000000000', 'files': ['releasenotes/notes/.placeholder', '.gitignore', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'oslo_log/version.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ad9f8fcddc88423d33f14b69dc863f45de7b2518', 'message': 'Add reno for release notes management\n\nRelease notes now required to report removal of deprecated configuration\noptions from oslo.log.\n\nChange-Id: I3649049a571490c5ec44a14a0c8640a4b747ad64\n'}]",1,276496,ad9f8fcddc88423d33f14b69dc863f45de7b2518,18,3,2,16051,,,0,"Add reno for release notes management

Release notes now required to report removal of deprecated configuration
options from oslo.log.

Change-Id: I3649049a571490c5ec44a14a0c8640a4b747ad64
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/96/276496/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/.placeholder', '.gitignore', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'oslo_log/version.py', 'releasenotes/source/conf.py']",10,b054210200429a50d012d6725e2150f78b960d30,add-reno,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # oslo.log Release Notes documentation build configuration file, created by # sphinx-quickstart on Tue Nov 3 17:40:50 2015. # # This file is execfile()d with the current directory set to its # containing dir. # # Note that not all possible configuration values are present in this # autogenerated file. # # All configuration values have a default; values that are commented out # serve to show the default. # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. # sys.path.insert(0, os.path.abspath('.')) # -- General configuration ------------------------------------------------ # If your documentation needs a minimal Sphinx version, state it here. # needs_sphinx = '1.0' # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom # ones. extensions = [ 'oslosphinx', 'reno.sphinxext', ] # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. # source_encoding = 'utf-8-sig' # The master toctree document. master_doc = 'index' # General information about the project. project = u'oslo.log Release Notes' copyright = u'2016, oslo.log Developers' # The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. from oslo_log.version import version_info as oslo_log_version # The full version, including alpha/beta/rc tags. release = oslo_log_version.version_string_with_vcs() # The short X.Y version. version = oslo_log_version.canonical_version_string() # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: # today = '' # Else, today_fmt is used as the format for a strftime call. # today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. # default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. # add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). # add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. # show_authors = False # The name of the Pygments (syntax highlighting) style to use. pygments_style = 'sphinx' # A list of ignored prefixes for module index sorting. # modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. # keep_warnings = False # -- Options for HTML output ---------------------------------------------- # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. html_theme = 'default' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. # html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. # html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". # html_title = None # A shorter title for the navigation bar. Default is the same as html_title. # html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. # html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. # html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. # html_extra_path = [] # If not '', a 'Last updated on:' timestamp is inserted at every page bottom, # using the given strftime format. # html_last_updated_fmt = '%b %d, %Y' # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. # html_use_smartypants = True # Custom sidebar templates, maps document names to template names. # html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. # html_additional_pages = {} # If false, no module index is generated. # html_domain_indices = True # If false, no index is generated. # html_use_index = True # If true, the index is split into individual pages for each letter. # html_split_index = False # If true, links to the reST sources are added to the pages. # html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. # html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. # html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. # html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). # html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'olso.logReleaseNotesdoc' # -- Options for LaTeX output --------------------------------------------- latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'olso.logReleaseNotes.tex', u'olso.log Release Notes Documentation', u'oslo.log Developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. # latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. # latex_use_parts = False # If true, show page references after internal links. # latex_show_pagerefs = False # If true, show URL addresses after external links. # latex_show_urls = False # Documents to append as an appendix to all manuals. # latex_appendices = [] # If false, no module index is generated. # latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'olso.logreleasenotes', u'oslo.log Release Notes Documentation', [u'oslo.log Developers'], 1) ] # If true, show URL addresses after external links. # man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'oslo.logReleaseNotes', u'oslo.log Release Notes Documentation', u'oslo.log Developers', 'olso.logReleaseNotes', 'One line description of project.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. # texinfo_appendices = [] # If false, no module index is generated. # texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. # texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. # texinfo_no_detailmenu = False ",,314,0
openstack%2Foslo.config~master~Ibd0566f11df62da031afb128c9687c5e8c7b27ae,openstack/oslo.config,master,Ibd0566f11df62da031afb128c9687c5e8c7b27ae,Add config_dirs property with a list of directories,MERGED,2016-02-17 12:57:57.000000000,2016-02-18 20:42:00.000000000,2016-02-18 20:42:00.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-17 12:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/218d692d59d14a7842666fea8da75e67af603c15', 'message': 'config_dir should be a list of directories\n\nconfig_dir of ConfigOpts should contain a list of directories\nand not just the last directory. Note that find_file was not\nworking either if we were looking for a file relative to the\nfirst directory.\n\nCloses-Bug: 1544334\nChange-Id: Ibd0566f11df62da031afb128c9687c5e8c7b27ae\n'}, {'number': 2, 'created': '2016-02-18 04:36:30.000000000', 'files': ['oslo_config/tests/test_cfg.py', 'oslo_config/cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/89b9547fff04d4c9c32c891ebce44da974383fca', 'message': 'Add config_dirs property with a list of directories\n\nconfig_dir currenly contains just the last directory. We need to\nadd a new property config_dirs which can contain a list of all\nthe directories on the command line. This will help fix a problem\nwith find_file as well since currently it was only looking at the\nlast directory and not all directories.\n\nCloses-Bug: 1544334\nChange-Id: Ibd0566f11df62da031afb128c9687c5e8c7b27ae\n'}]",2,281248,89b9547fff04d4c9c32c891ebce44da974383fca,12,3,2,5638,,,0,"Add config_dirs property with a list of directories

config_dir currenly contains just the last directory. We need to
add a new property config_dirs which can contain a list of all
the directories on the command line. This will help fix a problem
with find_file as well since currently it was only looking at the
last directory and not all directories.

Closes-Bug: 1544334
Change-Id: Ibd0566f11df62da031afb128c9687c5e8c7b27ae
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/48/281248/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_config/tests/test_cfg.py', 'oslo_config/cfg.py']",2,218d692d59d14a7842666fea8da75e67af603c15,bug/1544334," items = getattr(namespace, self.dest) or [] items.append(values) setattr(namespace, self.dest, items) super(_ConfigDirOpt, self).__init__(name, type=types.List(), for directory in self.config_dir: dirs.append(_fixpath(directory))"," setattr(namespace, self.dest, values) super(_ConfigDirOpt, self).__init__(name, type=types.String(), dirs.append(_fixpath(self.config_dir))",22,4
openstack%2Fmanila~stable%2Fliberty~I8ebbba65ddc3dbb4e2014f3de946da3a5ce01c20,openstack/manila,stable/liberty,I8ebbba65ddc3dbb4e2014f3de946da3a5ce01c20,Generic driver: Fix unexport handling for nfs-utils 1.3.3,ABANDONED,2016-02-18 18:51:22.000000000,2016-02-18 20:20:56.000000000,,[{'_account_id': 18752}],"[{'number': 1, 'created': '2016-02-18 18:51:22.000000000', 'files': ['manila/tests/share/drivers/test_generic.py', 'manila/share/drivers/generic.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/a9432c1d09e72768f33e74d0ad68003abf086e5b', 'message': 'Generic driver: Fix unexport handling for nfs-utils 1.3.3\n\nExecuting exportfs -u without specifying the access list is no\nlonger possible, it requires the exact access list to be matching\notherwise\n  exportfs: Invalid export syntax: <path>\n\nis returned. As access list information is not available and\nthe maintenance mode is only temporary, just unexport everthing,\nas it will be restored afterwards.\n\nChange-Id: I8ebbba65ddc3dbb4e2014f3de946da3a5ce01c20\n'}]",0,282005,a9432c1d09e72768f33e74d0ad68003abf086e5b,3,1,1,6593,,,0,"Generic driver: Fix unexport handling for nfs-utils 1.3.3

Executing exportfs -u without specifying the access list is no
longer possible, it requires the exact access list to be matching
otherwise
  exportfs: Invalid export syntax: <path>

is returned. As access list information is not available and
the maintenance mode is only temporary, just unexport everthing,
as it will be restored afterwards.

Change-Id: I8ebbba65ddc3dbb4e2014f3de946da3a5ce01c20
",git fetch https://review.opendev.org/openstack/manila refs/changes/05/282005/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/drivers/test_generic.py', 'manila/share/drivers/generic.py']",2,a9432c1d09e72768f33e74d0ad68003abf086e5b,," self._ssh_exec(server, ['sudo', 'exportfs', '-ua' ])"," self._ssh_exec(server, ['sudo', 'exportfs', '-u', local_path])",2,2
openstack%2Fmanila~stable%2Fliberty~I438f1ca1d7ac5692ffb5c4302527ed3193988232,openstack/manila,stable/liberty,I438f1ca1d7ac5692ffb5c4302527ed3193988232,Needs master merge first.,ABANDONED,2016-02-18 20:20:02.000000000,2016-02-18 20:20:18.000000000,,[],"[{'number': 1, 'created': '2016-02-18 20:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8e460524486cdb712aed2baa778ff0ce86287924', 'message': 'Needs master merge first.\n\nChange-Id: I438f1ca1d7ac5692ffb5c4302527ed3193988232\n'}]",0,282046,8e460524486cdb712aed2baa778ff0ce86287924,2,0,1,6593,,,0,"Needs master merge first.

Change-Id: I438f1ca1d7ac5692ffb5c4302527ed3193988232
",git fetch https://review.opendev.org/openstack/manila refs/changes/46/282046/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,8e460524486cdb712aed2baa778ff0ce86287924,,,,0,0
openstack%2Fcongress~master~I8c5c581189aa52f223c5b965e23ffce8f8bca684,openstack/congress,master,I8c5c581189aa52f223c5b965e23ffce8f8bca684,Enable row_model exception tests,MERGED,2016-02-17 05:24:37.000000000,2016-02-18 20:15:42.000000000,2016-02-18 20:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2016-02-17 05:24:37.000000000', 'files': ['congress/tests2/api/test_row_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/45ee63ffa35176056797cdbf3c93d3ede65c6231', 'message': 'Enable row_model exception tests\n\nChange-Id: I8c5c581189aa52f223c5b965e23ffce8f8bca684\n'}]",0,281054,45ee63ffa35176056797cdbf3c93d3ede65c6231,10,2,1,11278,,,0,"Enable row_model exception tests

Change-Id: I8c5c581189aa52f223c5b965e23ffce8f8bca684
",git fetch https://review.opendev.org/openstack/congress refs/changes/54/281054/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/tests2/api/test_row_model.py'],1,45ee63ffa35176056797cdbf3c93d3ede65c6231,enable_row_tests,"from congress.api import webservicefrom congress.tests2.api import base as api_base self.policy_model = policy_model.PolicyModel( self.rule_model = rule_model.RuleModel('api-rule', policy_engine='engine') self.row_model = row_model.RowModel('api-row', policy_engine='engine') result = api_base.setup_config([self.policy_model, self.rule_model, self.row_model]) self.node = result['node'] self.data = result['data'] def test_get_items_invalid_ds_name(self): context = {'ds_id': 'invalid-ds', 'table_id': 'fake-table'} self.assertRaises(webservice.DataModelException, self.row_model.get_items, {}, context) def test_get_items_invalid_ds_table_name(self): context = {'ds_id': self.data.service_id, 'table_id': 'invalid-table'} self.assertRaises(webservice.DataModelException, self.row_model.get_items, {}, context) def test_get_items_invalid_policy_name(self): context = {'policy_id': 'invalid-policy', 'table_id': 'p'} self.assertRaises(webservice.DataModelException, self.row_model.get_items, {}, context) def test_get_items_invalid_policy_table_name(self): # create policy policyname = 'test-policy' self.policy_model.add_item({""name"": policyname}, {}) context = {'policy_id': policyname, 'table_id': 'invalid-table'} self.assertRaises(webservice.DataModelException, self.row_model.get_items, {}, context)","from congress.tests import fake_datasource from congress.tests import helper from congress.dse2.dse_node import DseNode from congress.policy_engines.agnostic import Dse2Runtime # Here we load the fake driver cfg.CONF.set_override( 'drivers', ['congress.tests.fake_datasource.FakeDataSource']) result = self.create_services() self.node = result['node'] self.engine = result['engine'] self.data = result['data'] self.rule_model = result['rule_model'] self.row_model = result['row_model'] self.policy_model = result['policy_model'] def create_services(self): messaging_config = helper.generate_messaging_config() node = DseNode(messaging_config, ""testnode"", []) engine = Dse2Runtime('engine') data = fake_datasource.FakeDataSource('data') api_policy = policy_model.PolicyModel( api_rule = rule_model.RuleModel('api-rule', policy_engine='engine') api_row = row_model.RowModel('api-row', policy_engine='engine') node.register_service(engine) node.register_service(api_rule) node.register_service(api_row) node.register_service(api_policy) node.register_service(data) node.start() return {'node': node, 'engine': engine, 'data': data, 'rule_model': api_rule, 'row_model': api_row, 'policy_model': api_policy} # TODO(dse2): Enable these tests once returning proper exceptions # def test_get_items_invalid_ds_name(self): # context = {'ds_id': 'invalid-ds', # 'table_id': 'fake-table'} # self.assertRaises(webservice.DataModelException, # self.row_model.get_items, {}, context) # def test_get_items_invalid_ds_table_name(self): # context = {'ds_id': self.datasource['id'], # 'table_id': 'invalid-table'} # self.assertRaises(webservice.DataModelException, # self.row_model.get_items, {}, context) # TODO(dse2): Enable these tests once returning proper exceptions # def test_get_items_invalid_policy_name(self): # context = {'policy_id': 'invalid-policy', # 'table_id': 'p'} # self.assertRaises(webservice.DataModelException, # self.row_model.get_items, {}, context) # TODO(dse2): Enable this once returning proper exceptions. # Note: modified it manually to not rely on default policies. Untested. # def test_get_items_invalid_policy_table_name(self): # # create policy # policyname = 'test-policy' # self.policy_model.add_item({""name"": policyname}, {}) # context = {'policy_id': policyname, # 'table_id': 'invalid-table'} # self.assertRaises(webservice.DataModelException, # self.row_model.get_items, {}, context)",33,61
openstack%2Fsearchlight~master~Ief6b6fe0702a85057a497fc597bf0f222ac4226c,openstack/searchlight,master,Ief6b6fe0702a85057a497fc597bf0f222ac4226c,Move glance-specific test code into glance test,MERGED,2016-02-17 22:38:32.000000000,2016-02-18 20:12:39.000000000,2016-02-18 20:12:39.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 14680}]","[{'number': 1, 'created': '2016-02-17 22:38:32.000000000', 'files': ['searchlight/tests/functional/test_listener.py', 'searchlight/tests/functional/__init__.py', 'searchlight/tests/functional/test_glance_plugins.py'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/72c791c06eccfde125135c752850dca5b8066e5c', 'message': ""Move glance-specific test code into glance test\n\nSome of the functional test setup code was glance-specific and not\nreadily reusable. Adds a '_load_fixture_data' function to the base\nfunctional test, and makes some of the event processing code a bit\nfriendlier for writing tests for other plugins.\n\nChange-Id: Ief6b6fe0702a85057a497fc597bf0f222ac4226c\n""}]",2,281556,72c791c06eccfde125135c752850dca5b8066e5c,9,5,1,10063,,,0,"Move glance-specific test code into glance test

Some of the functional test setup code was glance-specific and not
readily reusable. Adds a '_load_fixture_data' function to the base
functional test, and makes some of the event processing code a bit
friendlier for writing tests for other plugins.

Change-Id: Ief6b6fe0702a85057a497fc597bf0f222ac4226c
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/56/281556/1 && git format-patch -1 --stdout FETCH_HEAD,"['searchlight/tests/functional/test_listener.py', 'searchlight/tests/functional/__init__.py', 'searchlight/tests/functional/test_glance_plugins.py']",3,72c791c06eccfde125135c752850dca5b8066e5c,bugs/fix-event-listener-func-test," def __init__(self, *args, **kwargs): super(TestGlanceListener, self).__init__(*args, **kwargs) self.image_events = self._load_fixture_data('events/images.json') self.metadef_events = self._load_fixture_data('events/metadefs.json') self.images_index = self.images_plugin.get_index_name() self.metadefs_index = self.metadefs_plugin.get_index_name() self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(update_event, self.images_index) self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(delete_event, self.images_index) self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(update_event, self.images_index) self._send_event_to_listener(create_event, self.images_index) self._send_event_to_listener(update_event, self.images_index) self._send_event_to_listener(delete_event, self.images_index) self._send_event_to_listener(create_event, self.metadefs_index) self._send_event_to_listener(create_event, self.metadefs_index) self._send_event_to_listener(update_event, self.metadefs_index) self._send_event_to_listener(create_event, self.metadefs_index) self._send_event_to_listener(delete_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(obj_create_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(obj_create_event, self.metadefs_index) self._send_event_to_listener(obj_update_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(obj_create_event, self.metadefs_index) self._send_event_to_listener(obj_delete_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(prop_create_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(prop_update_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(prop_create_event, self.metadefs_index) self._send_event_to_listener(prop_delete_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(res_type_create_event, self.metadefs_index) self._send_event_to_listener(ns_create_event, self.metadefs_index) self._send_event_to_listener(res_type_create_event, self.metadefs_index) self._send_event_to_listener(rs_type_delete_event, self.metadefs_index)", self._send_event_to_listener(create_event) self._send_event_to_listener(create_event) self._send_event_to_listener(update_event) self._send_event_to_listener(create_event) self._send_event_to_listener(delete_event) self._send_event_to_listener(create_event) self._send_event_to_listener(create_event) self._send_event_to_listener(create_event) self._send_event_to_listener(update_event) self._send_event_to_listener(create_event) self._send_event_to_listener(update_event) self._send_event_to_listener(delete_event) self._send_event_to_listener(create_event) self._send_event_to_listener(create_event) self._send_event_to_listener(update_event) self._send_event_to_listener(create_event) self._send_event_to_listener(delete_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(obj_create_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(obj_create_event) self._send_event_to_listener(obj_update_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(obj_create_event) self._send_event_to_listener(obj_delete_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(prop_create_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(prop_update_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(prop_create_event) self._send_event_to_listener(prop_delete_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(res_type_create_event) self._send_event_to_listener(ns_create_event) self._send_event_to_listener(res_type_create_event) self._send_event_to_listener(rs_type_delete_event),61,55
openstack%2Foctavia~master~I93d93f9013b93f326924edd0104b1e09349d5ba5,openstack/octavia,master,I93d93f9013b93f326924edd0104b1e09349d5ba5,Improve test case test_upload_certificate_md5,MERGED,2016-02-18 09:55:41.000000000,2016-02-18 20:07:53.000000000,2016-02-18 20:03:58.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-02-18 09:55:41.000000000', 'files': ['octavia/tests/functional/amphorae/backend/agent/api_server/test_server_sysvinit.py', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/d1c41e8b45e15046328ddead05f1445c95123d53', 'message': 'Improve test case test_upload_certificate_md5\n\n""handle = m()"" is in code but we are not using it for any test.\nadd ""handle.write.assert_called_once_with()"" to complete this case.\n\nChange-Id: I93d93f9013b93f326924edd0104b1e09349d5ba5\n'}]",0,281727,d1c41e8b45e15046328ddead05f1445c95123d53,10,5,1,8686,,,0,"Improve test case test_upload_certificate_md5

""handle = m()"" is in code but we are not using it for any test.
add ""handle.write.assert_called_once_with()"" to complete this case.

Change-Id: I93d93f9013b93f326924edd0104b1e09349d5ba5
",git fetch https://review.opendev.org/openstack/octavia refs/changes/27/281727/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/functional/amphorae/backend/agent/api_server/test_server_sysvinit.py', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server.py']",2,d1c41e8b45e15046328ddead05f1445c95123d53,improve_test, handle.write.assert_called_once_with(six.b('TestTest')),,2,0
openstack%2Fsearchlight~master~Ib8dfbf06c0fc0c4d929de044ab41c6847a050ba5,openstack/searchlight,master,Ib8dfbf06c0fc0c4d929de044ab41c6847a050ba5,Ignore 404 on missing mapping,MERGED,2016-02-16 22:26:51.000000000,2016-02-18 20:02:47.000000000,2016-02-18 03:17:08.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 10063}, {'_account_id': 14680}]","[{'number': 1, 'created': '2016-02-16 22:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/702564d07145fb4bd2052dac83c99f9635b3534f', 'message': ""Ignore 404 on missing mapping\n\nWhen deleting mappings for plugins (or their children) ignore\n404 errors. Patch changes the code to use the elasticsearch python\nclient's ability to ignore certain errors rather than explicitly\nchecking first.\n\nChange-Id: Ib8dfbf06c0fc0c4d929de044ab41c6847a050ba5\n""}, {'number': 2, 'created': '2016-02-16 22:47:37.000000000', 'files': ['searchlight/elasticsearch/plugins/base.py'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/9632e2654ef48cc0c2848723e287f126bca3fd0d', 'message': ""Ignore 404 on missing mapping\n\nWhen deleting mappings for plugins (or their children) ignore\n404 errors. Patch changes the code to use the elasticsearch python\nclient's ability to ignore certain errors rather than explicitly\nchecking first.\n\nSee http://elasticsearch-py.readthedocs.org/en/master/api.html#ignore\n\nChange-Id: Ib8dfbf06c0fc0c4d929de044ab41c6847a050ba5\n""}]",3,280961,9632e2654ef48cc0c2848723e287f126bca3fd0d,11,6,2,10063,,,0,"Ignore 404 on missing mapping

When deleting mappings for plugins (or their children) ignore
404 errors. Patch changes the code to use the elasticsearch python
client's ability to ignore certain errors rather than explicitly
checking first.

See http://elasticsearch-py.readthedocs.org/en/master/api.html#ignore

Change-Id: Ib8dfbf06c0fc0c4d929de044ab41c6847a050ba5
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/61/280961/2 && git format-patch -1 --stdout FETCH_HEAD,['searchlight/elasticsearch/plugins/base.py'],1,702564d07145fb4bd2052dac83c99f9635b3534f,bugs/fix-missing-child-type," self.engine.indices.delete_mapping(self.index_name, self.document_type, ignore=404) for child_plugin in self.child_plugins: self.engine.indices.delete_mapping( self.index_name, child_plugin.get_document_type(), ignore=404)"," type_exists = (self.engine.indices.exists(self.index_name) and self.engine.indices.exists_type(self.index_name, self.document_type)) if type_exists: self.engine.indices.delete_mapping(self.index_name, self.document_type) for child_plugin in self.child_plugins: self.engine.indices.delete_mapping( self.index_name, child_plugin.get_document_type())",8,10
openstack%2Fproject-config~master~I1f12c5c7b1bf0f556d10366336a471b81a6cc68c,openstack/project-config,master,I1f12c5c7b1bf0f556d10366336a471b81a6cc68c,Check twine uploads for success,MERGED,2016-02-02 22:49:14.000000000,2016-02-18 19:58:12.000000000,2016-02-18 19:58:11.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-02 22:49:14.000000000', 'files': ['jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/pypi-tarball-upload.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/16b12ba5b95e9696fa58719d671e9fe85e400ea8', 'message': ""Check twine uploads for success\n\nTwine occasionally hits 500 errors from pypi but that doesn't\nnecessarily mean that the upload failed. We can check if it succeeded\ndirectly by requesting an HTTP HEAD against the resource path. Use the\nresult of this request to determine if we have failed.\n\nChange-Id: I1f12c5c7b1bf0f556d10366336a471b81a6cc68c\n""}]",0,275431,16b12ba5b95e9696fa58719d671e9fe85e400ea8,7,3,1,4146,,,0,"Check twine uploads for success

Twine occasionally hits 500 errors from pypi but that doesn't
necessarily mean that the upload failed. We can check if it succeeded
directly by requesting an HTTP HEAD against the resource path. Use the
result of this request to determine if we have failed.

Change-Id: I1f12c5c7b1bf0f556d10366336a471b81a6cc68c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/31/275431/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/pypi-tarball-upload.sh']",2,16b12ba5b95e9696fa58719d671e9fe85e400ea8,check-twine-uploads,"# Uploads may claim to fail but actually succeed so we check if we # can download after upload to determine success. twine upload -r pypi $FILENAME || true curl --head --silent --fail ""https://pypi.python.org/simple/$PROJECT/$FILENAME"" >/dev/null 2>&1",twine upload -r pypi $FILENAME,8,2
openstack%2Fproject-config~master~Ia37f9194de8bd327a621fa5dd895ba1a64abcf1a,openstack/project-config,master,Ia37f9194de8bd327a621fa5dd895ba1a64abcf1a,Clone all openstack/ projects before trying to search them for devstack plugins,ABANDONED,2016-02-18 17:41:54.000000000,2016-02-18 19:52:13.000000000,,"[{'_account_id': 6547}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-18 17:41:54.000000000', 'files': ['jenkins/jobs/devstack.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/bbbe89ffc034c5f18f3a87c83b408f071ef41781', 'message': 'Clone all openstack/ projects before trying to search them for devstack plugins\n\nSince the proposal slave does not actually have git repositories cached,\nclone everything under openstack/ so that the devstack plugin proposal\njob has something to search.\n\nChange-Id: Ia37f9194de8bd327a621fa5dd895ba1a64abcf1a\n'}]",1,281981,bbbe89ffc034c5f18f3a87c83b408f071ef41781,4,2,1,16272,,,0,"Clone all openstack/ projects before trying to search them for devstack plugins

Since the proposal slave does not actually have git repositories cached,
clone everything under openstack/ so that the devstack plugin proposal
job has something to search.

Change-Id: Ia37f9194de8bd327a621fa5dd895ba1a64abcf1a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/81/281981/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack.yaml'],1,bbbe89ffc034c5f18f3a87c83b408f071ef41781,autogen-devstack-plugins-list," - zuul-branch-git-prep: branch-override: master mkdir -p $HOME/tmp PROJECT_LIST=$(mktemp) CLONEMAP=$(mktemp) OSREPODIR=$(TMPDIR=$HOME/tmp mktemp -d) function cleanup {{ rm -f $PROJECT_LIST; rm -f $CLONEMAP; rm -rf $OSREPODIR }} trap cleanup EXIT (cd $OSREPODIR && /usr/zuul-env/bin/zuul-cloner --cache-dir /opt/git git://git.openstack.org openstack-infra/project-config) awk '/^- project: openstack\// {print $3;}' $OSREPODIR/project-config/gerrit/projects.yaml > $PROJECT_LIST echo 'clonemap:' > $CLONEMAP awk '{print "" - name: "" $1; print "" destination: '$OSREPODIR'/"" $1;}' $PROJECT_LIST >> $CLONEMAP /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git git://git.openstack.org $(cat $PROJECT_LIST) git_dir=$OSREPODIR/openstack /usr/local/jenkins/slave_scripts/propose_update.sh \", - branch-git-prep: branch: master /usr/local/jenkins/slave_scripts/propose_update.sh \,14,3
openstack%2Finstack-undercloud~master~I99768fd402a13056adef7fdafd8568ff5f08d1a1,openstack/instack-undercloud,master,I99768fd402a13056adef7fdafd8568ff5f08d1a1,Make ceilometer hardware meters work out of the box,MERGED,2015-11-06 22:27:38.000000000,2016-02-18 19:44:24.000000000,2016-02-18 19:19:04.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}, {'_account_id': 7065}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 8399}, {'_account_id': 11997}]","[{'number': 1, 'created': '2015-11-06 22:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/e9e7df15585e64652fbc3775c283dad6e4f1b03a', 'message': ""Make ceilometer hardware meters work out of the box\n\nAlthough we were configuring the ceilometer hardware section on the\nundercloud, none of the hardware meters were showing up in\nceilometer.  There are a few reasons for this:\n\n1) The auto-generated readonly SNMP username was too long.  It seems\n   to have a limit of 32 characters, and we default to generating\n   a 40 character value.\n2) The generated SNMP username wasn't automatically passed to the\n   overcloud template, so by default the overcloud was deploying\n   with an SNMP user named ro_snmp_user, regardless of what was\n   configured on the undercloud.\n3) A recent change removed the configuration of snmpd on the\n   undercloud, which for some reason breaks ceilometer meters for\n   the overcloud nodes.\n\nTo make ceilometer hardware meters work out of the box, this change\ndoes a couple of things:\n\n1) Changes the default value for undercloud_ceilometer_snmpd_user\n   to ro_snmp_user so it is not necessary to pass it as a\n   parameter in a default install.\n2) Re-enables the snmpd configuration on the undercloud.\n\nChange-Id: I99768fd402a13056adef7fdafd8568ff5f08d1a1\n""}, {'number': 2, 'created': '2015-11-09 17:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/caed5ba6416cddadc1e36036dae119f3e67d5883', 'message': ""Make ceilometer hardware meters work out of the box\n\nAlthough we were configuring the ceilometer hardware section on the\nundercloud, none of the hardware meters were showing up in\nceilometer.  There are a few reasons for this:\n\n1) The auto-generated readonly SNMP username was too long.  It seems\n   to have a limit of 32 characters, and we default to generating\n   a 40 character value.\n2) The generated SNMP username wasn't automatically passed to the\n   overcloud template, so by default the overcloud was deploying\n   with an SNMP user named ro_snmp_user, regardless of what was\n   configured on the undercloud.\n3) A recent change removed the configuration of snmpd on the\n   undercloud, which for some reason breaks ceilometer meters for\n   the overcloud nodes.\n\nTo make ceilometer hardware meters work out of the box, this change\ndoes a couple of things:\n\n1) Changes the default value for undercloud_ceilometer_snmpd_user\n   to ro_snmp_user so it is not necessary to pass it as a\n   parameter in a default install.\n2) Re-enables the snmpd configuration on the undercloud.\n\nChange-Id: I99768fd402a13056adef7fdafd8568ff5f08d1a1\n""}, {'number': 3, 'created': '2015-11-25 20:02:35.000000000', 'files': ['undercloud.conf.sample', 'instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/00dd8c82de2e14d4b923325c7f133452e288854d', 'message': ""Make ceilometer hardware meters work out of the box\n\nAlthough we were configuring the ceilometer hardware section on the\nundercloud, none of the hardware meters were showing up in\nceilometer.  There are a couple of reasons for this:\n\n1) The auto-generated readonly SNMP username was too long.  It seems\n   to have a limit of 32 characters, and we default to generating\n   a 40 character value.\n2) The generated SNMP username wasn't automatically passed to the\n   overcloud template, so by default the overcloud was deploying\n   with an SNMP user named ro_snmp_user, regardless of what was\n   configured on the undercloud.\n\nTo address these issues, this change sets the default SNMP user\nto ro_snmp_user so it is not necessary to pass it as a parameter\nin a default install.  It also makes a note of the length\nrestrictions on custom values.\n\nChange-Id: I99768fd402a13056adef7fdafd8568ff5f08d1a1\n""}]",1,242652,00dd8c82de2e14d4b923325c7f133452e288854d,25,8,3,6928,,,0,"Make ceilometer hardware meters work out of the box

Although we were configuring the ceilometer hardware section on the
undercloud, none of the hardware meters were showing up in
ceilometer.  There are a couple of reasons for this:

1) The auto-generated readonly SNMP username was too long.  It seems
   to have a limit of 32 characters, and we default to generating
   a 40 character value.
2) The generated SNMP username wasn't automatically passed to the
   overcloud template, so by default the overcloud was deploying
   with an SNMP user named ro_snmp_user, regardless of what was
   configured on the undercloud.

To address these issues, this change sets the default SNMP user
to ro_snmp_user so it is not necessary to pass it as a parameter
in a default install.  It also makes a note of the length
restrictions on custom values.

Change-Id: I99768fd402a13056adef7fdafd8568ff5f08d1a1
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/52/242652/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/puppet-stack-config/puppet-stack-config.pp', 'instack_undercloud/undercloud.py']",2,e9e7df15585e64652fbc3775c283dad6e4f1b03a,ceilo-hardware," default='ro_snmp_user', help=('Ceilometer snmpd read-only user. If this value is ' 'changed from the default, the new value must be passed ' 'in the overcloud environment as the parameter ' 'SnmpdReadonlyUserName. This value must be between ' '1 and 32 characters long.')"," help=('Ceilometer snmpd user. ' 'If left unset, one will be automatically generated.')",21,2
openstack%2Fneutron~master~Ie9f809ff0983c30a7c2748c7cb82839c5fbea767,openstack/neutron,master,Ie9f809ff0983c30a7c2748c7cb82839c5fbea767,tickle tickle,ABANDONED,2016-02-18 17:54:08.000000000,2016-02-18 19:43:25.000000000,,"[{'_account_id': 9681}, {'_account_id': 10184}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 20629}]","[{'number': 1, 'created': '2016-02-18 17:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a452321ec26dc65c207fd735024d4b257ba84f5', 'message': 'tickle tickle\n\nChange-Id: Ie9f809ff0983c30a7c2748c7cb82839c5fbea767\n'}, {'number': 2, 'created': '2016-02-18 17:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24daecf1793ebbb0ca684c3b2a954d3d54734cf4', 'message': 'tickle tickle\n\nChange-Id: Ie9f809ff0983c30a7c2748c7cb82839c5fbea767\n'}, {'number': 3, 'created': '2016-02-18 17:57:06.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b2546151d428bf702cd4881deda26d1d2f5aaaa0', 'message': 'tickle tickle\n\nChange-Id: Ie9f809ff0983c30a7c2748c7cb82839c5fbea767\n'}]",0,281987,b2546151d428bf702cd4881deda26d1d2f5aaaa0,17,5,3,748,,,0,"tickle tickle

Change-Id: Ie9f809ff0983c30a7c2748c7cb82839c5fbea767
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/281987/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/policies/bugs.rst'],1,6a452321ec26dc65c207fd735024d4b257ba84f5,test,doh! ,,2,0
openstack%2Fkolla~master~I2e2d4e06274c7412ffac1d50962824ce6a324593,openstack/kolla,master,I2e2d4e06274c7412ffac1d50962824ce6a324593,"Configure nested compute, when compute runs virtual",ABANDONED,2016-02-07 21:09:20.000000000,2016-02-18 19:43:15.000000000,,"[{'_account_id': 3}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-07 21:09:20.000000000', 'files': ['ansible/roles/nova/templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/b6f9ed612b79ef6f8c805b35f22ec4b3e56248e5', 'message': 'Configure nested compute, when compute runs virtual\n\nChange-Id: I2e2d4e06274c7412ffac1d50962824ce6a324593\nCloses-Bug: #1542933\n'}]",0,277200,b6f9ed612b79ef6f8c805b35f22ec4b3e56248e5,4,2,1,10428,,,0,"Configure nested compute, when compute runs virtual

Change-Id: I2e2d4e06274c7412ffac1d50962824ce6a324593
Closes-Bug: #1542933
",git fetch https://review.opendev.org/openstack/kolla refs/changes/00/277200/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/templates/nova.conf.j2'],1,b6f9ed612b79ef6f8c805b35f22ec4b3e56248e5,bug/1542933,"{% if hostvars[inventory_hostname]['ansible_virtualization_role'] == ""guest"" %} virt_type = qemu {% endif %}",,3,0
openstack%2Fhorizon~master~I68d4855b726576f203684847f4d38cbc61ba516b,openstack/horizon,master,I68d4855b726576f203684847f4d38cbc61ba516b,WIP Adding Actions to Users Panel,ABANDONED,2015-07-15 22:09:51.000000000,2016-02-18 19:42:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 13805}, {'_account_id': 14124}]","[{'number': 1, 'created': '2015-07-15 22:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a4f3708ef9e848f4e736566e5782eaa40046d36f', 'message': 'WIP Adding CREATE action to identity users panel\n\nneed to move modal.service.js into modal.module but naming collision\nso depending on other patches to merge first.\n\nchecking this in for safety.\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\n'}, {'number': 2, 'created': '2015-07-16 06:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b88d925413b0613e6c9a203bc7c7ef39f5e217e3', 'message': 'WIP Adding CREATE action to identity users panel\n\nneed to move modal.service.js into modal.module but naming collision\nso depending on other patches to merge first.\n\nchecking this in for safety.\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b'}, {'number': 3, 'created': '2015-07-20 23:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bb651591a1a897d516f99735f56a255c538a6b61', 'message': 'WIP Adding CREATE action to identity users panel\n\nneed to move modal.service.js into modal.module but naming collision\nso depending on other patches to merge first.\n\nchecking this in for safety.\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b'}, {'number': 4, 'created': '2015-07-22 11:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f2882193534fea0834c135dff4d2fe05700148c1', 'message': 'WIP Adding CREATE action to identity users panel\n\nNeed to switch uppercase filter with translate filter.\nNeed to complete transfer table in select-projects step.\nNeed to break out workflows?\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b'}, {'number': 5, 'created': '2015-07-24 21:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/89dfdc8b87a58db2621d60ea25489a103d7ea26a', 'message': 'WIP Adding CREATE action to identity users panel\n\nNeed to switch uppercase filter with translate filter.\nDepends on:\nhttps://review.openstack.org/#/c/201894/\nhttps://review.openstack.org/#/c/202330/\nhttps://review.openstack.org/#/c/205716/\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\n'}, {'number': 6, 'created': '2015-07-24 22:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/19237bde1e7ee51351200cb9998c9b34db8f94eb', 'message': 'WIP Adding CREATE action to identity users panel\n\nDepends on:\nhttps://review.openstack.org/#/c/202330/\nhttps://review.openstack.org/#/c/205716/\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\n'}, {'number': 7, 'created': '2015-07-24 23:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7a815b7e5d4cfb7c7daa5d49a0730da462bc866f', 'message': 'WIP Adding CREATE action to identity users panel\n\nThis patch adds the create user workflow to the panel.\nIt consists of two steps:\n1. create user\n2. select projects\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 8, 'created': '2015-07-28 00:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/723f440db1ee90c5bf4a7c3c4342cef50e7f29cf', 'message': 'WIP Adding CREATE action to identity users panel\n\nThis patch adds the create user workflow to the panel.\nIt consists of two steps:\n1. create user\n2. select projects\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 9, 'created': '2015-07-28 19:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ef1dd9375fa69e5afb961e983423b3583016e2b0', 'message': 'WIP Adding CREATE action to identity users panel\n\nThis patch adds the create user workflow to the panel.\nIt consists of two steps:\n1. create user\n2. select projects\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 10, 'created': '2015-07-29 22:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8494aa2783eccdf40e8a960579cf4e279fcb5ccc', 'message': 'WIP Adding CREATE action to identity users panel\n\nThis patch adds the create user workflow to the panel.\nIt consists of two steps:\n1. create user\n2. select projects\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 11, 'created': '2015-07-30 00:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b7bbf6a106b63df8f16f76380753395c5355966e', 'message': 'WIP Adding CREATE action to identity users panel\n\nThis patch adds the create user workflow to the panel.\nIt consists of two steps:\n1. create user\n2. select projects\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 12, 'created': '2015-08-10 22:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7646763b919a83f4c41bd78238298bcf8d6b6091', 'message': 'WIP Adding CREATE action to identity users panel\n\nThis patch adds the create user workflow to the panel.\nIt consists of two steps:\n1. create user\n2. select projects\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 13, 'created': '2015-08-12 22:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3ffd9ca194c898259cd84abd460630a5158025c4', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nRemoving actions that have not been added.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 14, 'created': '2015-08-13 00:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2ca165127533a06b8a07ca5e43c6320bb7108628', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nRemoving actions that have not been added.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 15, 'created': '2015-08-20 04:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b805316107e811709a7ee9fc5d34e5c5818a2c4d', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nRemoving actions that have not been added.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 16, 'created': '2015-08-21 00:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/57290ca3ae221267e17a050658b8f6ddf0149077', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nRemoving actions that have not been added.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nProgress diagram:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 17, 'created': '2015-08-25 01:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d0543579cab0fb4d1edd803f8330d3329b9d237f', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nRemoving actions that have not been added.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nProgress diagram:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 18, 'created': '2015-08-26 17:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c5d54cc854a2896e591d8a818a1143fdc66c374b', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nRemoving actions that have not been added.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nProgress diagram:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 19, 'created': '2015-09-10 17:30:24.000000000', 'files': ['openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table-row-actions.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/edit.workflow.service.js', 'horizon/static/framework/widgets/modal/simple-modal.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/edit.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/delete.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/change-password/change-password.html', 'openstack_dashboard/api/rest/keystone.py', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.wizard.controller.js', 'openstack_dashboard/enabled/_3031_identity_users_panel.py', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.workflow.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/change-password/change-password.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table-rows.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table-header.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/enable.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/password.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.help.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/users.module.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table-batch-actions.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.row-actions.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/edit.wizard.controller.js', 'horizon/static/framework/widgets/modal/simple-modal.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.batch-actions.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.help.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2599fb3d0617b35d871a7635572f9aba2035478d', 'message': 'WIP Adding Actions to Users Panel\n\nThis patch servers as a frame of reference.\n\nTo test, set DISABLED = False in\n_3031_identity_users_panel.py\n\nProgress diagram:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I68d4855b726576f203684847f4d38cbc61ba516b\nPartially-Implements: blueprint angularize-identity-tables\n'}]",25,202315,2599fb3d0617b35d871a7635572f9aba2035478d,65,8,19,9576,,,0,"WIP Adding Actions to Users Panel

This patch servers as a frame of reference.

To test, set DISABLED = False in
_3031_identity_users_panel.py

Progress diagram:
https://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing

Change-Id: I68d4855b726576f203684847f4d38cbc61ba516b
Partially-Implements: blueprint angularize-identity-tables
",git fetch https://review.opendev.org/openstack/horizon refs/changes/15/202315/18 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create/create.html', 'openstack_dashboard/enabled/_250_identity_users_panel.py', 'horizon/static/framework/widgets/wizard/modal.service.js', 'horizon/static/framework/widgets/wizard/modal.service.spec.js', 'openstack_dashboard/static/app/app.module.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create/help.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create/create.workflow.js']",8,a4f3708ef9e848f4e736566e5782eaa40046d36f,identity/users/create,"/** * Copyright 2015 IBM Corp. * * Licensed under the Apache License, Version 2.0 (the ""License""); you may * not use this file except in compliance with the License. You may obtain * a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations * under the License. */ (function() { 'use strict'; /** * @ngdoc formCtrl * @ng-controller * * @description * The interaction between action and form is complicated. * A good understanding of angular-bootstrap $modalInstance is REQUIRED. * * Basically, this controller serves as the common form controller. * The user and context objects are injected by actions. * Once the user clicks on the submit or cancel button, * the action that called this dialog is notified. */ angular .module('hz.dashboard.identity.users') .controller('identity.users.create.controller', identityUsersCreateController); identityUsersCreateController.$inject = [ '$scope', 'horizon.openstack-service-api.keystone', 'hz.dashboard.workflow.factory', 'horizon.framework.widgets.wizard.modal.service', '$modalInstance', 'hz.dashboard.identity.basePath', ]; function identityUsersCreateController( $scope, keystoneAPI, workflow, modalService, $modalInstance, path) { var ctrl = this; ctrl.dropdown = {}; $scope.close = modalService.close($modalInstance); $scope.cancel = modalService.cancel($modalInstance); $scope.submit = submit; $scope.workflow = workflow({ title: 'numero uno!', steps: steps, btnText: { finish: 'Create' } }); init(); /////////////////////////// var steps = [ { title: 'Create Users', templateUrl: path + 'users/actions/create/create.html', helpUrl: path + 'users/actions/create/help.html', formName: 'identityUsersCreateForm' } ]; var context = { mode: 'create', title: gettext('Create User'), submit: gettext('Create'), success: gettext('User %s was successfully created.') }; function init(){ /* auto assign new users to _member_ role if (context.mode === 'create'){ keystoneAPI.getRoles().success(function(response) { dropdown.roles = response.items; angular.forEach(dropdown.roles, function(role){ if (role.name === '_member_') { user.role_id = role.id; return; } }); }); } if (context.mode === 'create' || context.mode === 'edit') { keystoneAPI.getProjects().success(function(response) { dropdown.projects = response.items; user.project_id = (user.project_id || user.tenantId || user.default_project_id); }); }*/ } function submit(newUser) { console.log(""submitted!""); /*keystoneAPI.createUser(newUser) .success(function(response) { scope.users.push(response); var message = interpolate(context.success, [newUser.name]); horizon.alert('success', message); horizon.autoDismissAlerts(); // remove the passwords from user object delete newUser.password; delete newUser.cpassword; });*/ } } // end of controller })();",,286,5
openstack%2Fhorizon~master~I258310bdc3712ddf9946079651b9a6b51867271c,openstack/horizon,master,I258310bdc3712ddf9946079651b9a6b51867271c,Adding CREATE action to identity users panel,ABANDONED,2015-09-10 17:29:19.000000000,2016-02-18 19:41:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6638}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 11778}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 13805}, {'_account_id': 14124}, {'_account_id': 15359}, {'_account_id': 15519}, {'_account_id': 15742}, {'_account_id': 16994}, {'_account_id': 17327}, {'_account_id': 17642}]","[{'number': 1, 'created': '2015-09-10 17:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/999e05b9207e5cfe574d0cd2983f7a1d2f427a3d', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nProgress diagram:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 2, 'created': '2015-09-11 00:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/36868f6457bc1a6543afa242068af12826062904', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel.\nAdded ability to assign multiple projects to a user.\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nProgress diagram:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 3, 'created': '2015-09-15 00:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d23fc0483c6ff31afd907d84fb13bc1e4d5d88bb', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 4, 'created': '2015-09-30 14:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/055985dd082203646fd8e8e3be413a7f5000c6a2', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 5, 'created': '2015-09-30 17:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/19c4630f41adbcb3f801a52369b8e7d7eefbc644', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 6, 'created': '2015-09-30 19:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aee45be18fddc694078f25efc4f70b24c6f1adde', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 7, 'created': '2015-09-30 19:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bac1d5350c39dc2a0cce2e1bb0ec731862f74617', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 8, 'created': '2015-09-30 20:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/19f8f53a3cb542c4b3a31530b839fe3ed5450e71', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 9, 'created': '2015-10-06 17:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0480b67e467850ffd3f3fc4de2ebc2944ff64d8f', 'message': 'WIP Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nThe following diagram shows the complete picture,\nclasses with the jigsaw icon next to them are extensible:\nhttps://drive.google.com/file/d/0B5nlaOV3OEj5aVpRaC1sdlgtQ28/view?usp=sharing\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 10, 'created': '2015-10-12 17:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/75bfeb6c283ff6a1411abd67ae13ee306496338a', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 11, 'created': '2015-10-12 18:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2a5e9c5dea0616863f13966f372fc42f9886e6da', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 12, 'created': '2015-10-12 18:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a9f393591b4fce38a8eb6eeeb1f45933c3959c82', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 13, 'created': '2015-10-12 18:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8d777b7409e92ca06320c94e94d76addc44f39d1', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 14, 'created': '2015-10-13 17:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b6b3ecebec5833f60004d669a7018095dda0e7cd', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 15, 'created': '2015-10-13 18:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e1fa518b0f644a58ec4ffc3f528ee87f517ca0df', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 16, 'created': '2015-10-13 18:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c270ffc6a5edb1acdcf0bdf61a48aafa954beedf', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 17, 'created': '2015-10-14 20:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5a0a466d83d1aac57405fe3a52d974cacfe3535f', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 18, 'created': '2015-10-15 19:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2bbfaf003a2db925aa4fc1bff98aebe8ef2aea71', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 19, 'created': '2015-11-09 19:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5702eed766d759593aa04c96373308b3b39ce0cb', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 20, 'created': '2015-11-12 20:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/977a22fe6e281d07b8d7855dd56d48f19ca0fdb2', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 21, 'created': '2015-11-13 20:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bbc44611723cd462e01c0d8e5a9e7a5481bb87ee', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 22, 'created': '2015-11-13 20:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c47c8455f4486bcc9a8a0405c7a04e4e840799d4', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}, {'number': 23, 'created': '2015-12-04 23:33:07.000000000', 'files': ['openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.workflow.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.action.service.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.controller.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.controller.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/batch-actions.service.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.help.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/users.module.js', 'openstack_dashboard/static/app/core/openstack-service-api/keystone.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.html', 'horizon/static/framework/widgets/modal/wizard-modal.controller.js', 'horizon/static/framework/widgets/modal/wizard-modal.controller.spec.js', 'openstack_dashboard/api/rest/keystone.py', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.controller.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.help.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/batch-actions.service.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/93bed0dd3f63436dc9367c9704bf5638a121ba79', 'message': 'Adding CREATE action to identity users panel\n\nAdds the create action to the users panel. You can now assign the user to\nmultiple projects with different roles.\n\nTo test, set DISABLED = False in _3031_identity_users_panel.py\nRefer to diagram on how it all connects:\nhttps://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0\n\nChange-Id: I258310bdc3712ddf9946079651b9a6b51867271c\nPartially-Implements: blueprint angularize-identity-tables'}]",75,222297,93bed0dd3f63436dc9367c9704bf5638a121ba79,88,20,23,9576,,,0,"Adding CREATE action to identity users panel

Adds the create action to the users panel. You can now assign the user to
multiple projects with different roles.

To test, set DISABLED = False in _3031_identity_users_panel.py
Refer to diagram on how it all connects:
https://www.dropbox.com/s/dmi5b697rwuw3fi/ng-action-class-diagram.png?dl=0

Change-Id: I258310bdc3712ddf9946079651b9a6b51867271c
Partially-Implements: blueprint angularize-identity-tables",git fetch https://review.opendev.org/openstack/horizon refs/changes/97/222297/18 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.workflow.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.controller.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.controller.js', 'openstack_dashboard/static/app/core/table/table.batch-actions.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.controller.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.help.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/users.module.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.html', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.wizard.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/select-projects/select-projects.controller.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.batch-actions.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.controller.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/actions/create.action.service.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/steps/create-user/create-user.help.html']",17,999e05b9207e5cfe574d0cd2983f7a1d2f427a3d,bp/angularize-identity-tables," <div translate> Create a new user and set related properties. A default project and role has been selected for you. To change the default project and role, proceed to the next step. </div> ",,921,17
openstack%2Foctavia~master~I006f1c794e1ab0483886d06495ca6649f0afe479,openstack/octavia,master,I006f1c794e1ab0483886d06495ca6649f0afe479,Delete SSH amphora driver,MERGED,2016-02-17 10:29:44.000000000,2016-02-18 19:41:42.000000000,2016-02-18 19:37:54.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-02-17 10:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2dcbfa4b1147ec9bb1c5c61665f1b338bd9d18c3', 'message': 'Delete SSH amphora driver\n\nThe old SSH amphora driver is not being used by anyone\nanymore, nor is it being maintained. This patch removes it from\nthe Octavia code tree.\n\nChange-Id: I006f1c794e1ab0483886d06495ca6649f0afe479\n'}, {'number': 2, 'created': '2016-02-17 10:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/79c979cf37de08a52ef4d1e2ebf929125a28b243', 'message': 'Delete SSH amphora driver\n\nThe old SSH amphora driver is not being used by anyone\nanymore, nor is it being maintained. This patch removes it from\nthe Octavia code tree.\n\nCloses-Bug: 1534218\nChange-Id: I006f1c794e1ab0483886d06495ca6649f0afe479\n'}, {'number': 3, 'created': '2016-02-17 21:51:49.000000000', 'files': ['octavia/tests/unit/amphorae/drivers/haproxy/test_ssh_driver.py', 'octavia/tests/unit/controller/worker/flows/test_amphora_flows.py', 'setup.cfg', 'etc/octavia.conf', 'specs/version1/active_passive_loadbalancer.rst', 'octavia/amphorae/drivers/haproxy/ssh_driver.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/2a0a0944bf63b91bd3bf2406b1fd265bef1f1e77', 'message': 'Delete SSH amphora driver\n\nThe old SSH amphora driver is not being used by anyone\nanymore, nor is it being maintained. This patch removes it from\nthe Octavia code tree.\n\nCloses-Bug: 1534218\nChange-Id: I006f1c794e1ab0483886d06495ca6649f0afe479\n'}]",0,281172,2a0a0944bf63b91bd3bf2406b1fd265bef1f1e77,21,8,3,11685,,,0,"Delete SSH amphora driver

The old SSH amphora driver is not being used by anyone
anymore, nor is it being maintained. This patch removes it from
the Octavia code tree.

Closes-Bug: 1534218
Change-Id: I006f1c794e1ab0483886d06495ca6649f0afe479
",git fetch https://review.opendev.org/openstack/octavia refs/changes/72/281172/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/amphorae/drivers/haproxy/test_ssh_driver.py', 'octavia/tests/unit/controller/worker/flows/test_amphora_flows.py', 'etc/octavia.conf', 'octavia/amphorae/drivers/haproxy/ssh_driver.py']",4,2dcbfa4b1147ec9bb1c5c61665f1b338bd9d18c3,bug/1534218,,"# Copyright (c) 2015 Rackspace # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import socket import tempfile import time from oslo_log import log as logging import paramiko import six from stevedore import driver as stevedore_driver from octavia.amphorae.driver_exceptions import exceptions as exc from octavia.amphorae.drivers import driver_base as driver_base from octavia.amphorae.drivers.haproxy.jinja import jinja_cfg from octavia.common.config import cfg from octavia.common import constants from octavia.common.tls_utils import cert_parser from octavia.i18n import _LW LOG = logging.getLogger(__name__) NEUTRON_VERSION = '2.0' VIP_ROUTE_TABLE = 'vip' # ip and route commands CMD_DHCLIENT = ""dhclient {0}"" CMD_ADD_IP_ADDR = ""ip addr add {0}/24 dev {1}"" CMD_SHOW_IP_ADDR = ""ip addr show {0}"" CMD_GREP_LINK_BY_MAC = (""ip link | grep {mac_address} -m 1 -B 1 "" ""| awk 'NR==1{{print $2}}'"") CMD_CREATE_VIP_ROUTE_TABLE = ( ""su -c 'echo \""1 {0}\"" >> /etc/iproute2/rt_tables'"" ) CMD_ADD_ROUTE_TO_TABLE = ""ip route add {0} dev {1} table {2}"" CMD_ADD_DEFAULT_ROUTE_TO_TABLE = (""ip route add default via {0} "" ""dev {1} table {2}"") CMD_ADD_RULE_FROM_NET_TO_TABLE = ""ip rule add from {0} table {1}"" CMD_ADD_RULE_TO_NET_TO_TABLE = ""ip rule add to {0} table {1}"" class HaproxyManager(driver_base.AmphoraLoadBalancerDriver): amp_config = cfg.CONF.haproxy_amphora def __init__(self): super(HaproxyManager, self).__init__() self.amphoraconfig = {} self.client = paramiko.SSHClient() self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy()) self.cert_manager = stevedore_driver.DriverManager( namespace='octavia.cert_manager', name=cfg.CONF.certificates.cert_manager, invoke_on_load=True, ).driver self.jinja = jinja_cfg.JinjaTemplater( base_amp_path=self.amp_config.base_path, base_crt_dir=self.amp_config.base_cert_dir, haproxy_template=self.amp_config.haproxy_template) def get_logger(self): return LOG def update(self, listener, vip): LOG.debug(""Amphora %s haproxy, updating listener %s, vip %s"", self.__class__.__name__, listener.protocol_port, vip.ip_address) # Set a path variable to hold where configurations will live conf_path = '{0}/{1}'.format(self.amp_config.base_path, listener.id) # Process listener certificate info certs = self._process_tls_certificates(listener) # Generate HaProxy configuration from listener object config = self.jinja.build_config(listener, certs['tls_cert']) # Build a list of commands to send to the exec method commands = ['chmod 600 {0}/haproxy.cfg'.format(conf_path), 'haproxy -f {0}/haproxy.cfg -p {0}/{1}.pid -sf ' '$(cat {0}/{1}.pid)'.format(conf_path, listener.id)] # Exec appropriate commands on all amphorae self._exec_on_amphorae( listener.load_balancer.amphorae, commands, make_dir=conf_path, data=[config], upload_dir='{0}/haproxy.cfg'.format(conf_path)) def stop(self, listener, vip): LOG.debug(""Amphora %s haproxy, disabling listener %s, vip %s"", self.__class__.__name__, listener.protocol_port, vip.ip_address) # Exec appropriate commands on all amphorae self._exec_on_amphorae(listener.load_balancer.amphorae, ['kill -9 $(cat {0}/{1}/{1}.pid)'.format( self.amp_config.base_path, listener.id)]) def delete(self, listener, vip): LOG.debug(""Amphora %s haproxy, deleting listener %s, vip %s"", self.__class__.__name__, listener.protocol_port, vip.ip_address) # Define the two operations that need to happen per amphora stop = 'kill -9 $(cat {0}/{1}/{1}.pid)'.format( self.amp_config.base_path, listener.id) delete = 'rm -rf {0}/{1}'.format(self.amp_config.base_path, listener.id) # Exec appropriate commands on all amphorae self._exec_on_amphorae(listener.load_balancer.amphorae, [stop, delete]) def start(self, listener, vip): LOG.debug(""Amphora %s haproxy, enabling listener %s, vip %s"", self.__class__.__name__, listener.protocol_port, vip.ip_address) # Define commands to execute on the amphorae commands = [ 'haproxy -f {0}/{1}/haproxy.cfg -p {0}/{1}/{1}.pid'.format( self.amp_config.base_path, listener.id)] # Exec appropriate commands on all amphorae self._exec_on_amphorae(listener.load_balancer.amphorae, commands) def get_info(self, amphora): LOG.debug(""Amphora %s haproxy, info amphora %s"", self.__class__.__name__, amphora.id) # info = self.amphora_client.get_info() # self.amphoraconfig[amphora.id] = (amphora.id, info) def get_diagnostics(self, amphora): LOG.debug(""Amphora %s haproxy, get diagnostics amphora %s"", self.__class__.__name__, amphora.id) self.amphoraconfig[amphora.id] = (amphora.id, 'get_diagnostics') def finalize_amphora(self, amphora): LOG.debug(""Amphora %s no-op, finalize amphora %s"", self.__class__.__name__, amphora.id) self.amphoraconfig[amphora.id] = (amphora.id, 'finalize amphora') def _configure_amp_routes(self, vip_iface, amp_net_config): subnet = amp_net_config.vip_subnet command = CMD_CREATE_VIP_ROUTE_TABLE.format(VIP_ROUTE_TABLE) self._execute_command(command, run_as_root=True) command = CMD_ADD_ROUTE_TO_TABLE.format( subnet.cidr, vip_iface, VIP_ROUTE_TABLE) self._execute_command(command, run_as_root=True) command = CMD_ADD_DEFAULT_ROUTE_TO_TABLE.format( subnet.gateway_ip, vip_iface, VIP_ROUTE_TABLE) self._execute_command(command, run_as_root=True) command = CMD_ADD_RULE_FROM_NET_TO_TABLE.format( subnet.cidr, VIP_ROUTE_TABLE) self._execute_command(command, run_as_root=True) command = CMD_ADD_RULE_TO_NET_TO_TABLE.format( subnet.cidr, VIP_ROUTE_TABLE) self._execute_command(command, run_as_root=True) def _configure_amp_interface(self, iface, secondary_ip=None): # just grab the ip from dhcp command = CMD_DHCLIENT.format(iface) self._execute_command(command, run_as_root=True) if secondary_ip: # add secondary_ip command = CMD_ADD_IP_ADDR.format(secondary_ip, iface) self._execute_command(command, run_as_root=True) # log interface details command = CMD_SHOW_IP_ADDR.format(iface) self._execute_command(command) def post_vip_plug(self, load_balancer, amphorae_network_config): LOG.debug(""Add vip to interface for all amphora on %s"", load_balancer.id) for amp in load_balancer.amphorae: if amp.status != constants.DELETED: # Connect to amphora self._connect(hostname=amp.lb_network_ip) mac = amphorae_network_config.get(amp.id).vrrp_port.mac_address stdout, _ = self._execute_command( CMD_GREP_LINK_BY_MAC.format(mac_address=mac)) iface = stdout[:-2] if not iface: self.client.close() continue self._configure_amp_interface( iface, secondary_ip=load_balancer.vip.ip_address) self._configure_amp_routes( iface, amphorae_network_config.get(amp.id)) def post_network_plug(self, amphora, port): self._connect(hostname=amphora.lb_network_ip) stdout, _ = self._execute_command( CMD_GREP_LINK_BY_MAC.format(mac_address=port.mac_address)) iface = stdout[:-2] if not iface: self.client.close() return self._configure_amp_interface(iface) self.client.close() def _execute_command(self, command, run_as_root=False): if run_as_root and not self._is_root(): command = ""sudo {0}"".format(command) _, stdout, stderr = self.client.exec_command(command) stdout = stdout.read() stderr = stderr.read() LOG.debug('Sent command %s', command) LOG.debug('Returned stdout: %s', stdout) LOG.debug('Returned stderr: %s', stderr) return stdout, stderr def _connect(self, hostname): for attempts in six.moves.xrange( self.amp_config.connection_max_retries): try: self.client.connect(hostname=hostname, username=self.amp_config.username, key_filename=self.amp_config.key_path) except socket.error: LOG.warn(_LW(""Could not ssh to instance"")) time.sleep(self.amp_config.connection_retry_interval) if attempts >= self.amp_config.connection_max_retries: raise exc.TimeOutException() else: return raise exc.UnavailableException() def _process_tls_certificates(self, listener): """"""Processes TLS data from the listener. Converts and uploads PEM data to the Amphora API return TLS_CERT and SNI_CERTS """""" data = [] certs = cert_parser.load_certificates_data( self.cert_manager, listener) sni_containers = certs['sni_certs'] tls_cert = certs['tls_cert'] if certs['tls_cert'] is not None: data.append(cert_parser.build_pem(tls_cert)) if sni_containers: for sni_cont in sni_containers: data.append(cert_parser.build_pem(sni_cont)) if data: cert_dir = os.path.join(self.amp_config.base_cert_dir, listener.id) listener_cert = '{0}/{1}.pem'.format(cert_dir, tls_cert.primary_cn) self._exec_on_amphorae( listener.load_balancer.amphorae, [ 'chmod 600 {0}/*.pem'.format(cert_dir)], make_dir=cert_dir, data=data, upload_dir=listener_cert) return certs def _exec_on_amphorae(self, amphorae, commands, make_dir=None, data=None, upload_dir=None): data = data or [] temps = [] # Write data to temp file to prepare for upload for datum in data: temp = tempfile.NamedTemporaryFile(delete=True) temp.write(datum.encode('ascii')) temp.flush() temps.append(temp) for amp in amphorae: if amp.status != constants.DELETED: # Connect to amphora self._connect(hostname=amp.lb_network_ip) # Setup for file upload if make_dir: mkdir_cmd = 'mkdir -p {0}'.format(make_dir) self._execute_command(mkdir_cmd, run_as_root=True) chown_cmd = 'chown -R {0} {1}'.format( self.amp_config.username, make_dir) self._execute_command(chown_cmd, run_as_root=True) # Upload files to location if temps: sftp = self.client.open_sftp() for temp in temps: sftp.put(temp.name, upload_dir) # Execute remaining commands for command in commands: self._execute_command(command, run_as_root=True) self.client.close() # Close the temp file for temp in temps: temp.close() def _is_root(self): return cfg.CONF.haproxy_amphora.username == 'root' ",35,649
openstack%2Fkuryr~master~Ie68c4f4f70a81cfeafe2b13e2a896570576a6892,openstack/kuryr,master,Ie68c4f4f70a81cfeafe2b13e2a896570576a6892,Add the kuryr plugin for rally,MERGED,2016-01-29 11:19:58.000000000,2016-02-18 19:34:09.000000000,2016-02-18 19:34:09.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 10475}, {'_account_id': 11208}, {'_account_id': 11343}, {'_account_id': 12069}, {'_account_id': 12395}, {'_account_id': 14352}, {'_account_id': 15967}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-01-29 11:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/2f75f50f1176b9a4a4e3875ac31ea9953f35b9a1', 'message': 'Add the kuryr plugin framework for rally\n\n1. Following Rally plugin structure, create the kuryr plugin.\n2. Add one scenario of list the networks.\n3. Add the demo task of triggering the scenario. Currently, users\ncan try this task (with rally installed) by running:\nrally --plugin-paths rally-jobs/plugins/ task start\nrally-jobs/tasks/scenarios/list_networks.json\n\nimplements blueprint: fullstack-testing\n\nChange-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892\n'}, {'number': 2, 'created': '2016-01-29 11:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/eb0d79b561a858a444f70dd619bf529c0ac82cfa', 'message': 'Add the kuryr plugin for rally\n\n1. Following Rally plugin structure, create the kuryr plugin.\n2. Add one scenario of listing the networks.\n3. Add the task file to trigger the scenario. Currently, users\ncan try this task (with rally installed) by running:\nrally --plugin-paths rally-jobs/plugins/ task start\nrally-jobs/tasks/scenarios/list_networks.json\n\nimplements blueprint: fullstack-testing\n\nChange-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892\n'}, {'number': 3, 'created': '2016-01-29 11:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/68b225cd35ec232f225dc7d797d818c60044027f', 'message': 'Add the kuryr plugin for rally\n\n1. Following Rally plugin structure, create the kuryr plugin.\n2. Add one scenario of listing the networks.\n3. Add the task file to trigger the scenario. Currently, users\ncan try this task (with rally installed) by running:\nrally --plugin-paths rally-jobs/plugins/ task start\nrally-jobs/tasks/scenarios/list_networks.json\n\nimplements blueprint: fullstack-testing\n\nChange-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892\n'}, {'number': 4, 'created': '2016-02-01 02:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/601ca99b783d0f43d3ee07d624010e426eb126bd', 'message': 'Add the kuryr plugin for rally\n\n1. Following Rally plugin structure, create the kuryr plugin.\n2. Add one scenario of listing the networks.\n3. Add the task file to trigger the scenario. Currently, users\ncan try this task (with rally installed) by running:\nrally --plugin-paths rally-jobs/plugins/ task start\nrally-jobs/tasks/scenarios/list_networks.json\n\nimplements blueprint: fullstack-testing\n\nChange-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892\n'}, {'number': 5, 'created': '2016-02-16 13:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/b0b94fc5fdf2f9ae853e896c906ed3ecc7acbdd9', 'message': 'Add the kuryr plugin for rally\n\n1. Following Rally plugin structure, create the kuryr plugin.\n2. Add one scenario of listing the networks.\n3. Add the task file to trigger the scenario. Currently, users\ncan try this task (with rally installed) by running:\nrally --plugin-paths rally-jobs/plugins/ task start\nrally-jobs/tasks/scenarios/list_networks.json\n\nimplements blueprint: fullstack-testing\n\nChange-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892\n'}, {'number': 6, 'created': '2016-02-17 09:04:06.000000000', 'files': ['rally-jobs/plugins/scenarios/__init__.py', 'rally-jobs/kuryr.yaml', 'rally-jobs/tasks/scenarios/list_networks.json', 'rally-jobs/plugins/scenarios/utils.py', 'rally-jobs/plugins/scenarios/kuryr.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/cf2853a36d4f68f0f1444abd6093451b93949668', 'message': ""Add the kuryr plugin for rally\n\n1. Following Rally plugin structure, create the kuryr plugin.\n2. Add one scenario of listing the networks.\n3. Add the task file to trigger the scenario. Currently, users\ncan try this task (with rally installed) by running:\nrally --plugin-paths rally-jobs/plugins/ task start\nrally-jobs/tasks/scenarios/list_networks.json\n4. Merge gal's update on the gate task yaml.\n\nimplements blueprint: fullstack-testing\n\nChange-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892\n""}]",15,274014,cf2853a36d4f68f0f1444abd6093451b93949668,37,12,6,11208,,,0,"Add the kuryr plugin for rally

1. Following Rally plugin structure, create the kuryr plugin.
2. Add one scenario of listing the networks.
3. Add the task file to trigger the scenario. Currently, users
can try this task (with rally installed) by running:
rally --plugin-paths rally-jobs/plugins/ task start
rally-jobs/tasks/scenarios/list_networks.json
4. Merge gal's update on the gate task yaml.

implements blueprint: fullstack-testing

Change-Id: Ie68c4f4f70a81cfeafe2b13e2a896570576a6892
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/14/274014/4 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/plugins/scenarios/__init__.py', 'rally-jobs/tasks/scenarios/list_networks.json', 'rally-jobs/plugins/scenarios/utils.py', 'rally-jobs/plugins/scenarios/kuryr.py']",4,2f75f50f1176b9a4a4e3875ac31ea9953f35b9a1,add_rally_plugin,"# Copyright 2016: IBM Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import utils from rally.plugins.openstack import scenario from rally.task import validation class Kuryr(utils.KuryrScenarios): """"""Benchmark scenarios for Kuryr."""""" #@validation.required_services(consts.Service.KURYR) @validation.required_openstack(users=True) @scenario.configure(context={""cleanup"": [""kuryr""]}) def list_networks(self, network_list_args=None): """"""List the networks. Measure the ""docker network ls"" command performance under kuryr. This will call the docker client API to list networks TODO (baohua): 1. may support tenant/user in future. 2. validation.required_services add KURYR support :param network_list_args: dict: names, ids """""" self._list_networks(network_list_args or {})",,125,0
openstack%2Fcinder~master~I1f2f549b364a013b713e193591d08b9e9376569e,openstack/cinder,master,I1f2f549b364a013b713e193591d08b9e9376569e,Dell: Failed vol create could leave dead volumes,MERGED,2016-02-15 17:51:17.000000000,2016-02-18 19:31:12.000000000,2016-02-17 00:24:44.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12112}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15011}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 20490}]","[{'number': 1, 'created': '2016-02-15 17:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f514b506ea5cda38d2030eb164c0065b7b0afd5f', 'message': 'Dell: Failed vol create could leave dead volumes\n\nAdded _cleanup_failed_create_volume which tries to delete any\npartially created volumes.\n\nChange-Id: I1f2f549b364a013b713e193591d08b9e9376569e\n'}, {'number': 2, 'created': '2016-02-15 20:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/661ce653dc18ec6d49416b7b0be8ef75fb287b7a', 'message': 'Dell: Failed vol create could leave dead volumes\n\nAdded _cleanup_failed_create_volume which tries to delete any\npartially created volumes.\n\nChange-Id: I1f2f549b364a013b713e193591d08b9e9376569e\n'}, {'number': 3, 'created': '2016-02-15 20:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f0b0cbc6ceb60ea489fb28aed68986e5095001d', 'message': 'Dell: Failed vol create could leave dead volumes\n\nAdded _cleanup_failed_create_volume which tries to delete any\npartially created volumes.\n\nChange-Id: I1f2f549b364a013b713e193591d08b9e9376569e\n'}, {'number': 4, 'created': '2016-02-16 15:53:51.000000000', 'files': ['cinder/volume/drivers/dell/dell_storagecenter_common.py', 'cinder/tests/unit/test_dellsc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a985a6ae9febf3469bace65f7a7f2b31b2578fc', 'message': 'Dell: Failed vol create could leave dead volumes\n\nAdded _cleanup_failed_create_volume which tries to delete any\npartially created volumes.\n\nChange-Id: I1f2f549b364a013b713e193591d08b9e9376569e\nCloses-Bug: 1546161\n'}]",0,280343,2a985a6ae9febf3469bace65f7a7f2b31b2578fc,73,32,4,12112,,,0,"Dell: Failed vol create could leave dead volumes

Added _cleanup_failed_create_volume which tries to delete any
partially created volumes.

Change-Id: I1f2f549b364a013b713e193591d08b9e9376569e
Closes-Bug: 1546161
",git fetch https://review.opendev.org/openstack/cinder refs/changes/43/280343/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/dell/dell_storagecenter_common.py'],1,f514b506ea5cda38d2030eb164c0065b7b0afd5f,bug/1546161," @staticmethod def _cleanup_failed_create_volume(api, volumename): try: api.delete_volume(volumename) except exception.VolumeBackendAPIException as ex: LOG.info(_LI('Non fatal cleanup error: %s.'), ex.msg) self._cleanup_failed_create_volume(api, volume_name) self._cleanup_failed_create_volume(api, volume_name) self._cleanup_failed_create_volume(api, volume_name)", if scvolume: api.delete_volume(volume_name) if scvolume: api.delete_volume(volume_name) if scvolume: api.delete_volume(volume_name),10,6
openstack%2Frally~master~Ifebfa5abf43e620f6b82d4649e5a454172e99c38,openstack/rally,master,Ifebfa5abf43e620f6b82d4649e5a454172e99c38,Fix cleanup manager with api_versions context,MERGED,2016-02-18 16:16:55.000000000,2016-02-18 19:24:20.000000000,2016-02-18 19:24:20.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 7428}, {'_account_id': 8491}, {'_account_id': 10475}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-18 16:16:55.000000000', 'files': ['tests/unit/plugins/openstack/cleanup/test_manager.py', 'rally/plugins/openstack/cleanup/manager.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b6a5a034f4bc85ef16023985c854096219a63ab1', 'message': 'Fix cleanup manager with api_versions context\n\nCleanup manager was broken in cases when api_versions context was used.\n\nChange-Id: Ifebfa5abf43e620f6b82d4649e5a454172e99c38\nCloses-Bug: #1547083\n'}]",0,281931,b6a5a034f4bc85ef16023985c854096219a63ab1,10,6,1,9545,,,0,"Fix cleanup manager with api_versions context

Cleanup manager was broken in cases when api_versions context was used.

Change-Id: Ifebfa5abf43e620f6b82d4649e5a454172e99c38
Closes-Bug: #1547083
",git fetch https://review.opendev.org/openstack/rally refs/changes/31/281931/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/cleanup/test_manager.py', 'rally/plugins/openstack/cleanup/manager.py']",2,b6a5a034f4bc85ef16023985c854096219a63ab1,bug/1547083," cache[key] = osclients.Clients(user[""credential""], api_info=api_versions)"," cache[key] = osclients.Clients(key, api_info=api_versions)",4,7
openstack%2Fpuppet-openstack-integration~master~I0043813223b1c8761d37852a035d007282639bae,openstack/puppet-openstack-integration,master,I0043813223b1c8761d37852a035d007282639bae,Add ability to manually install puppet modules,ABANDONED,2016-02-18 19:21:19.000000000,2016-02-18 19:22:36.000000000,,[],"[{'number': 1, 'created': '2016-02-18 19:21:19.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/e437d348b9846a41f0c68e16fd9fbe96090252a9', 'message': 'Add ability to manually install puppet modules\n\nChange-Id: I0043813223b1c8761d37852a035d007282639bae\n'}]",0,282014,e437d348b9846a41f0c68e16fd9fbe96090252a9,2,0,1,6721,,,0,"Add ability to manually install puppet modules

Change-Id: I0043813223b1c8761d37852a035d007282639bae
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/14/282014/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,e437d348b9846a41f0c68e16fd9fbe96090252a9,liberty-manual-modules,"export MANAGE_PUPPET_MODULES=${MANAGE_PUPPET_MODULES:-true}if [ ""${MANAGE_PUPPET_MODULES}"" = true ]; then $SUDO ./install_modules.sh fi",$SUDO ./install_modules.sh,4,1
openstack%2Ffuel-astute~master~I3d7bcbc7889cf5eb3cc6652a1b4bdad5c5cff81b,openstack/fuel-astute,master,I3d7bcbc7889cf5eb3cc6652a1b4bdad5c5cff81b,Setup global node concurrency parameter,ABANDONED,2016-02-11 18:51:33.000000000,2016-02-18 19:20:58.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-02-11 18:51:33.000000000', 'files': ['lib/astute/config.rb', 'lib/astute/task_deployment.rb', 'lib/fuel_deployment/cluster.rb', 'spec/unit/fuel_deployment/cluster_spec.rb', 'spec/unit/task_deployment_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/b8d17199cc58bb81bbeff9420de49e7aeb0111c3', 'message': 'Setup global node concurrency parameter\n\nAllow to use node limitation for task deployment\nsame way as for granular deployment\n\nChange-Id: I3d7bcbc7889cf5eb3cc6652a1b4bdad5c5cff81b\nCloses-Bug: #1526508\n'}]",0,279231,b8d17199cc58bb81bbeff9420de49e7aeb0111c3,9,7,1,8776,,,0,"Setup global node concurrency parameter

Allow to use node limitation for task deployment
same way as for granular deployment

Change-Id: I3d7bcbc7889cf5eb3cc6652a1b4bdad5c5cff81b
Closes-Bug: #1526508
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/31/279231/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/config.rb', 'lib/astute/task_deployment.rb', 'lib/fuel_deployment/cluster.rb', 'spec/unit/fuel_deployment/cluster_spec.rb', 'spec/unit/task_deployment_spec.rb']",5,b8d17199cc58bb81bbeff9420de49e7aeb0111c3,bug/1526508," context 'config' do around(:each) do |example| max_nodes_old_value = Astute.config.max_nodes_per_call example.run Astute.config.max_nodes_per_call = max_nodes_old_value end it 'should setup max nodes per call using config' do Astute.config.max_nodes_per_call = 33 task_deployment.stubs(:remove_failed_nodes).returns([deployment_info, []]) Astute::TaskPreDeploymentActions.any_instance.stubs(:process) task_deployment.stubs(:write_graph_to_file) ctx.stubs(:report) Deployment::Cluster.any_instance .stubs(:run) .returns({:success => true}) Deployment::Cluster.any_instance .expects(:maximum_node_concurrency=) .with(Astute.config.max_nodes_per_call) task_deployment.deploy(deployment_info, deployment_tasks) end end ",,56,1
openstack%2Freleases~master~I8c5d1120732db87abcfbd97fe5eb189e820c4654,openstack/releases,master,I8c5d1120732db87abcfbd97fe5eb189e820c4654,Release ironic-inspector 2.2.4 for Liberty,MERGED,2016-02-12 12:50:16.000000000,2016-02-18 19:18:53.000000000,2016-02-18 19:18:53.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6873}, {'_account_id': 9979}]","[{'number': 1, 'created': '2016-02-12 12:50:16.000000000', 'files': ['deliverables/liberty/ironic-inspector.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/23520872f0761ab366b0e69525b40210415e8bc7', 'message': 'Release ironic-inspector 2.2.4 for Liberty\n\nContains two bug fixes, one for a non-working plugin,\nthe other for bad error reporting in API.\n\nService release, does not require upper-constraints bump.\n\nChange-Id: I8c5d1120732db87abcfbd97fe5eb189e820c4654\n'}]",0,279515,23520872f0761ab366b0e69525b40210415e8bc7,12,4,1,10239,,,0,"Release ironic-inspector 2.2.4 for Liberty

Contains two bug fixes, one for a non-working plugin,
the other for bad error reporting in API.

Service release, does not require upper-constraints bump.

Change-Id: I8c5d1120732db87abcfbd97fe5eb189e820c4654
",git fetch https://review.opendev.org/openstack/releases refs/changes/15/279515/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/liberty/ironic-inspector.yaml'],1,23520872f0761ab366b0e69525b40210415e8bc7,ironic-inspector-2.2.4, - version: 2.2.4 projects: - repo: openstack/ironic-inspector hash: 33775e071343d906c17a65490fecd68757550225,,4,0
openstack%2Fmurano~master~I2d8fc7050403be082e9389ebe5e682816ec6aca1,openstack/murano,master,I2d8fc7050403be082e9389ebe5e682816ec6aca1,Migration to yaql 1.1,MERGED,2016-02-12 12:34:34.000000000,2016-02-18 19:12:46.000000000,2016-02-18 19:12:46.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-12 12:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d082f6f513593acd0aaf96d7f282987c1dfe5287', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 2, 'created': '2016-02-13 23:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a28faf8a8d6b884535b2c06cd88b7ed3ac9270de', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 3, 'created': '2016-02-17 00:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/55278f976cde5ccf7e93b18fcdda2d108ebdd50d', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 4, 'created': '2016-02-17 12:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b7a68153b9e6595e960c82162b22162cde709162', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 5, 'created': '2016-02-17 12:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c6e44d904c52c50ed06c64a4df65382cb5543dcd', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 6, 'created': '2016-02-17 16:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/aeeb7b27dff3509969ca2d574de382430dc22932', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 7, 'created': '2016-02-17 20:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1909174aa5017f73919f087fdf04710ef9f0fe40', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 8, 'created': '2016-02-17 22:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/399bc1957a0782be7c3874269ce3c8ff64f0b739', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 9, 'created': '2016-02-17 22:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b8b62dd204123640b62870a257a88ca74e241fb9', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 10, 'created': '2016-02-18 00:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/97497c5b02c095119c555d26da52912a94e823f6', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 11, 'created': '2016-02-18 00:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/35cb2cf8de3571201476a356fe2fe9abd05f430a', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}, {'number': 12, 'created': '2016-02-18 12:01:08.000000000', 'files': ['murano/tests/unit/engine/system/test_agent.py', 'murano/tests/unit/dsl/test_dsl.py', 'murano/common/engine.py', 'murano/engine/system/agent.py', 'murano/dsl/yaql_functions.py', 'murano/dsl/helpers.py', 'murano/dsl/constants.py', 'murano/dsl/dsl.py', 'murano/tests/unit/dsl/foundation/runner.py', 'murano/tests/unit/dsl/test_agent.py', 'murano/packages/load_utils.py', 'murano/engine/mock_context_manager.py', 'murano/dsl/yaql_integration.py', 'murano/dsl/executor.py', 'murano/dsl/linked_context.py', 'murano/tests/unit/dsl/meta/OneOfSmartType.yaml', 'releasenotes/notes/yaql11-822b503f13992890.yaml'], 'web_link': 'https://opendev.org/openstack/murano/commit/2c5f1454bf131495203fc8db175de223e2441f56', 'message': 'Migration to yaql 1.1\n\n* Remove all code that now available as part of yaql 1.1\n* New format version MuranoPL/1.3 that is identical to 1.2\n  but protects apps that uses yaql 1.1 new features from being\n  imported to Murano Liberty\n\nChange-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1\n'}]",1,279512,2c5f1454bf131495203fc8db175de223e2441f56,51,5,12,7226,,,0,"Migration to yaql 1.1

* Remove all code that now available as part of yaql 1.1
* New format version MuranoPL/1.3 that is identical to 1.2
  but protects apps that uses yaql 1.1 new features from being
  imported to Murano Liberty

Change-Id: I2d8fc7050403be082e9389ebe5e682816ec6aca1
",git fetch https://review.opendev.org/openstack/murano refs/changes/12/279512/11 && git format-patch -1 --stdout FETCH_HEAD,"['murano/tests/unit/dsl/test_dsl.py', 'murano/common/engine.py', 'murano/dsl/yaql_functions.py', 'murano/dsl/helpers.py', 'murano/dsl/constants.py', 'murano/dsl/dsl.py', 'murano/tests/unit/dsl/foundation/runner.py', 'murano/packages/load_utils.py', 'murano/engine/mock_context_manager.py', 'murano/dsl/yaql_integration.py', 'murano/dsl/executor.py', 'murano/dsl/linked_context.py', 'murano/tests/unit/dsl/meta/OneOfSmartType.yaml', 'releasenotes/notes/yaql11-822b503f13992890.yaml']",14,d082f6f513593acd0aaf96d7f282987c1dfe5287,static-methods,--- features: - Murano was migrated to yaql 1.1 - New format MuranoPL/1.3 can be specified in manifest files. MuranoPL/1.3 is identical to MuranoPL/1.2 but except for the fact that MuranoPL/1.3 packages cannot be imported to earlier Murano versions. Thus applications that use new features of yaql 1.1 should use this format version. ,,42,321
openstack%2Fproject-config~master~I3c5175cfd8754ff0d5f75f72066dde02d7a894cd,openstack/project-config,master,I3c5175cfd8754ff0d5f75f72066dde02d7a894cd,Remove python-constraints-jobs from ofagent job definition,MERGED,2016-02-17 12:35:35.000000000,2016-02-18 19:11:59.000000000,2016-02-18 18:37:58.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8344}]","[{'number': 1, 'created': '2016-02-17 12:35:35.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/86f8c345b2d5884a1c85f738e2812e26cf5a0197', 'message': 'Remove python-constraints-jobs from ofagent job definition\n\nNow, all python jobs support constraints since the following change is merged.\nhttps://review.openstack.org/#/c/278335/\nWe use python-jobs instead of python-constraints-jobs as constraint based job.\n\nThis reverts commit 538130f1932a3eb9f1f7569f7a3cd2a13c60afe7.\n\nChange-Id: I3c5175cfd8754ff0d5f75f72066dde02d7a894cd\nPartial-Bug: #1546389\n'}]",0,281240,86f8c345b2d5884a1c85f738e2812e26cf5a0197,13,5,1,8344,,,0,"Remove python-constraints-jobs from ofagent job definition

Now, all python jobs support constraints since the following change is merged.
https://review.openstack.org/#/c/278335/
We use python-jobs instead of python-constraints-jobs as constraint based job.

This reverts commit 538130f1932a3eb9f1f7569f7a3cd2a13c60afe7.

Change-Id: I3c5175cfd8754ff0d5f75f72066dde02d7a894cd
Partial-Bug: #1546389
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/281240/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,86f8c345b2d5884a1c85f738e2812e26cf5a0197,remove-constraits-job-from-ofagent,, experimental: - gate-networking-ofagent-docs-constraints - gate-networking-ofagent-pep8-constraints - gate-networking-ofagent-python27-constraints - gate-networking-ofagent-python34-constraints,0,6
openstack%2Frally~master~I98e25c9d4fdecb26e8fb84df3460738e61aec9d6,openstack/rally,master,I98e25c9d4fdecb26e8fb84df3460738e61aec9d6,Restore ability to pass kwargs to glance _create_image,MERGED,2016-02-17 17:17:18.000000000,2016-02-18 19:11:15.000000000,2016-02-18 19:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-17 17:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b0543abf6cb5d6508934b88024b90d6fc82ac58d', 'message': 'Restore ability to pass kwargs to glance _create_image\n\nThis was unintentionally removed in 067af09a. This restores that\nability, and adds both unit and functional tests for it.\n\nChange-Id: I98e25c9d4fdecb26e8fb84df3460738e61aec9d6\n'}, {'number': 2, 'created': '2016-02-17 21:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bb2e7c89694ff6ec8e00f836c033bb6e9743bb7e', 'message': 'Restore ability to pass kwargs to glance _create_image\n\nThis was unintentionally removed in 067af09a. This restores that\nability, and adds both unit and functional tests for it.\n\nChange-Id: I98e25c9d4fdecb26e8fb84df3460738e61aec9d6\n'}, {'number': 3, 'created': '2016-02-18 03:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e1497a164c8eb1178bca0656282491c0daa2acea', 'message': 'Restore ability to pass kwargs to glance _create_image\n\nThis was unintentionally removed in 067af09a. This restores that\nability, and adds both unit and functional tests for it.\n\nChange-Id: I98e25c9d4fdecb26e8fb84df3460738e61aec9d6\n'}, {'number': 4, 'created': '2016-02-18 13:29:26.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'rally-jobs/nova.yaml', 'rally/plugins/openstack/scenarios/glance/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/53b01a17f7035de034e0b28ac3903e42f771933f', 'message': 'Restore ability to pass kwargs to glance _create_image\n\nThis was unintentionally removed in 067af09a. This restores that\nability, and adds both unit and functional tests for it.\n\nChange-Id: I98e25c9d4fdecb26e8fb84df3460738e61aec9d6\n'}]",0,281437,53b01a17f7035de034e0b28ac3903e42f771933f,31,6,4,11748,,,0,"Restore ability to pass kwargs to glance _create_image

This was unintentionally removed in 067af09a. This restores that
ability, and adds both unit and functional tests for it.

Change-Id: I98e25c9d4fdecb26e8fb84df3460738e61aec9d6
",git fetch https://review.opendev.org/openstack/rally refs/changes/37/281437/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'rally-jobs/nova.yaml', 'rally/plugins/openstack/scenarios/glance/utils.py']",3,b0543abf6cb5d6508934b88024b90d6fc82ac58d,glance-create-images-kwargs," disk_format, **kwargs)", disk_format),31,3
openstack%2Fgnocchi~master~Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92,openstack/gnocchi,master,Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92,partition unprocessed measures across workers,MERGED,2016-02-12 16:39:35.000000000,2016-02-18 19:07:28.000000000,2016-02-18 19:07:28.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 18137}]","[{'number': 1, 'created': '2016-02-12 16:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/12c701d5d26c983a0d52b5a6ced63ee090da5202', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 metrics at a time.\n\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}, {'number': 2, 'created': '2016-02-12 17:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9569bbdda8161407e75c4ed1e62e16769d17a2fb', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 metrics at a time.\n\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}, {'number': 3, 'created': '2016-02-16 14:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/13934747fd22d819ab59b27349d1406ebcf95e3e', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes. overlap will occur the most in ceph driver because there is no\nway to grab metrics as a whole but it should still minimise the overlap\nto an extent.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 unique metrics at a time.\n\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}, {'number': 4, 'created': '2016-02-16 15:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b2b41e7b02e6c277e34e3816a3ea3d48b612569a', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes. overlap will occur the most in ceph driver because there is no\nway to grab metrics as a whole but it should still minimise the overlap\nto an extent.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 unique metrics at a time.\n\nCloses-Bug: #1543121\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}, {'number': 5, 'created': '2016-02-16 22:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/bf6fe4401e1847a95a37b72e8b3ded10cc4563ee', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes. overlap will occur the most in ceph driver because there is no\nway to grab metrics as a whole but it should still minimise the overlap\nto an extent.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 unique metrics at a time.\n\nCloses-Bug: #1543121\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}, {'number': 6, 'created': '2016-02-17 16:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/13da7f3b73880b60447bd8deccc6fb9da18ca455', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes. overlap will occur the most in ceph driver because there is no\nway to grab metrics as a whole but it should still minimise the overlap\nto an extent.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 unique metrics at a time.\n\nCloses-Bug: #1543121\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}, {'number': 7, 'created': '2016-02-18 12:57:48.000000000', 'files': ['gnocchi/storage/ceph.py', 'gnocchi/storage/__init__.py', 'gnocchi/tests/test_statsd.py', 'gnocchi/tests/test_aggregates.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/storage/swift.py', 'gnocchi/cli.py', 'gnocchi/tests/test_storage.py', 'gnocchi/tests/test_rest.py', 'gnocchi/storage/file.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6474be2318f472b9ae4f2d0fae1174d9a5abf113', 'message': 'partition unprocessed measures across workers\n\nthis patch assigned each worker to work on a specific partition of\nmeasures backlog. it uses the metric reporting worker to dynamically\nset the size of each partition.\n\nby default each processing worker will handle a specific block of 128\nmetrics. the reporting worker will periodically check backlog size\nand broadcast to all processing workers whether to grab larger chunks\n(if backlog is big) or smaller chunks (when backlog is small).\n\nthis minimises overlap between workers. it may result in no-op\nworkers if backlog is very small. overlap may occur as the workers\nquery backlog at different times and may possibly have different block\nsizes. overlap will occur the most in ceph driver because there is no\nway to grab metrics as a whole but it should still minimise the overlap\nto an extent.\n\na minimum block size is set at 16 metrics and a maximum of 256.\nin theory if 8 workers are set per service, it will grab roughly 128\nto 2048 unique metrics at a time.\n\nCloses-Bug: #1543121\nChange-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92\n'}]",14,279659,6474be2318f472b9ae4f2d0fae1174d9a5abf113,34,5,7,6537,,,0,"partition unprocessed measures across workers

this patch assigned each worker to work on a specific partition of
measures backlog. it uses the metric reporting worker to dynamically
set the size of each partition.

by default each processing worker will handle a specific block of 128
metrics. the reporting worker will periodically check backlog size
and broadcast to all processing workers whether to grab larger chunks
(if backlog is big) or smaller chunks (when backlog is small).

this minimises overlap between workers. it may result in no-op
workers if backlog is very small. overlap may occur as the workers
query backlog at different times and may possibly have different block
sizes. overlap will occur the most in ceph driver because there is no
way to grab metrics as a whole but it should still minimise the overlap
to an extent.

a minimum block size is set at 16 metrics and a maximum of 256.
in theory if 8 workers are set per service, it will grab roughly 128
to 2048 unique metrics at a time.

Closes-Bug: #1543121
Change-Id: Iad7b6b9a56fefcbe85e343e38c0738c2b33efb92
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/59/279659/7 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/ceph.py', 'gnocchi/storage/swift.py', 'gnocchi/cli.py', 'gnocchi/storage/file.py']",4,12c701d5d26c983a0d52b5a6ced63ee090da5202,bug/1543121, if full: return os.listdir(self.measure_path) return os.listdir(self.measure_path)[ self.partition_size * self.partition: self.partition_size * (self.partition + 1)], return os.listdir(self.measure_path),57,11
openstack%2Ftripleo-heat-templates~master~Iea3ea1d25dfc462fa844d3c12e6070f2c9b42036,openstack/tripleo-heat-templates,master,Iea3ea1d25dfc462fa844d3c12e6070f2c9b42036,Configure keystone public_endpoint,MERGED,2016-01-07 21:14:12.000000000,2016-02-18 19:04:48.000000000,2016-02-18 19:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8532}, {'_account_id': 9382}, {'_account_id': 10873}, {'_account_id': 12321}]","[{'number': 1, 'created': '2016-01-07 21:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/499d73c5ab457c26831b2f765cb688d5898d4fa8', 'message': ""Configure keystone public_endpoint\n\nWe need this set for SSL or keystone returns a non-https address.\nIt shouldn't hurt anything to set this in the non-SSL case since\nthe value will still be correct and the behavior will be the same\nas if it were unset.\n\nChange-Id: Iea3ea1d25dfc462fa844d3c12e6070f2c9b42036\n""}, {'number': 2, 'created': '2016-01-11 15:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c04bbd845136859dac705c5cd999f2228cf0a132', 'message': ""Configure keystone public_endpoint\n\nWe need this set for SSL or keystone returns a non-https address.\nIt shouldn't hurt anything to set this in the non-SSL case since\nthe value will still be correct and the behavior will be the same\nas if it were unset.\n\nChange-Id: Iea3ea1d25dfc462fa844d3c12e6070f2c9b42036\n""}, {'number': 3, 'created': '2016-01-13 00:18:26.000000000', 'files': ['puppet/controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ae911c2c9c2f48f4a3278c47fe05fbf552bdaeca', 'message': ""Configure keystone public_endpoint\n\nWe need this set for SSL or keystone returns a non-https address.\nIt shouldn't hurt anything to set this in the non-SSL case since\nthe value will still be correct and the behavior will be the same\nas if it were unset.\n\nChange-Id: Iea3ea1d25dfc462fa844d3c12e6070f2c9b42036\n""}]",0,264970,ae911c2c9c2f48f4a3278c47fe05fbf552bdaeca,38,8,3,6928,,,0,"Configure keystone public_endpoint

We need this set for SSL or keystone returns a non-https address.
It shouldn't hurt anything to set this in the non-SSL case since
the value will still be correct and the behavior will be the same
as if it were unset.

Change-Id: Iea3ea1d25dfc462fa844d3c12e6070f2c9b42036
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/70/264970/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/hieradata/controller.yaml'],1,499d73c5ab457c26831b2f765cb688d5898d4fa8,ssl-overcloud,"keystone::public_endpoint: ""%{hiera('keystone::endpoint::public_url')}""",,1,0
openstack%2Ftripleo-heat-templates~master~I1413428a1c0329acf0276bf6032684e5e7f8e177,openstack/tripleo-heat-templates,master,I1413428a1c0329acf0276bf6032684e5e7f8e177,Enable the ML2 port security extension driver by default,MERGED,2016-01-07 19:40:22.000000000,2016-02-18 19:03:29.000000000,2016-02-18 19:03:29.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8449}]","[{'number': 1, 'created': '2016-01-07 19:40:22.000000000', 'files': ['puppet/controller.yaml', 'overcloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d9fa3428fd4a794bddff68960c8748642017f7e4', 'message': 'Enable the ML2 port security extension driver by default\n\nThis patch enables the port security ML2 extension driver by default. It\nshould have no impact on users that do not explicitly modify the port\nsecurity property on a port.\n\nChange-Id: I1413428a1c0329acf0276bf6032684e5e7f8e177\nCloses-Bug: #1531970\n'}]",0,264940,d9fa3428fd4a794bddff68960c8748642017f7e4,17,7,1,6681,,,0,"Enable the ML2 port security extension driver by default

This patch enables the port security ML2 extension driver by default. It
should have no impact on users that do not explicitly modify the port
security property on a port.

Change-Id: I1413428a1c0329acf0276bf6032684e5e7f8e177
Closes-Bug: #1531970
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/264940/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/controller.yaml', 'overcloud.yaml']",2,d9fa3428fd4a794bddff68960c8748642017f7e4,bug/1531970," default: ""qos,port_security"""," default: ""qos""",2,2
openstack%2Fproject-config~master~I8380895b9768389658bd03dc854cd4e0c7ac57a4,openstack/project-config,master,I8380895b9768389658bd03dc854cd4e0c7ac57a4,Add experimental rally job for networking-odl.,MERGED,2016-01-18 16:29:43.000000000,2016-02-18 18:36:11.000000000,2016-02-18 18:36:10.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-01-18 16:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8d7b2732365960333a7bfaee00dfc8889ac0f963', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 2, 'created': '2016-01-25 14:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e32e84128cce1f33526898631e7be21f829a1198', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 3, 'created': '2016-01-26 14:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fdb73e234ef48a9996633f22c4f9081b24abd90d', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 4, 'created': '2016-01-28 21:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/56bde80dc5577947fff0b3e14e4b7c6c130985d7', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 5, 'created': '2016-02-11 16:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/513ddac4c66bee5d1896ae9abd078935b4dd52a3', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 6, 'created': '2016-02-13 12:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/54fbeed864a66acf9da0ecd09a4418e1b0de0fe7', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 7, 'created': '2016-02-13 12:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bc7ecf2d410e5c10557f15e842e2eaa5ce9db874', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 8, 'created': '2016-02-13 12:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/438501ed4b7e258b7d336224f12430a199cf8b4a', 'message': 'Add non-voting rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 9, 'created': '2016-02-15 20:58:26.000000000', 'files': ['jenkins/jobs/networking-odl.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/720da87d996c247b624fe5e7948ac8d3630d781a', 'message': 'Add experimental rally job for networking-odl.\n\nChange-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",13,269174,720da87d996c247b624fe5e7948ac8d3630d781a,35,8,9,1561,,,0,"Add experimental rally job for networking-odl.

Change-Id: I8380895b9768389658bd03dc854cd4e0c7ac57a4
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/74/269174/3 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/networking-odl.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",3,8d7b2732365960333a7bfaee00dfc8889ac0f963,networking-odl-rally, - name: ^gate-networking-odl-dsvm-rally-nv voting: false - gate-networking-ovn-dsvm-rally-nv,,61,0
openstack%2Foslo.context~master~I17c76881aa662de7ff245b3f6bfca309896ddf24,openstack/oslo.context,master,I17c76881aa662de7ff245b3f6bfca309896ddf24,Agnostic approach to construct context from_dict,MERGED,2016-02-01 18:08:21.000000000,2016-02-18 18:33:34.000000000,2016-02-18 18:33:34.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7230}, {'_account_id': 8688}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-01 18:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/b5bf2fcb0720fc403778be42f5e323afca87cac8', 'message': 'Agnostic approach to construct context from_dict\n\nReplace the existing argument specific from_dict class method to be\nargument agnostic. As found in Solum.\n\nAll current boolean values match instantiation defaults.\n\nChange-Id: I17c76881aa662de7ff245b3f6bfca309896ddf24\n'}, {'number': 2, 'created': '2016-02-09 22:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/ed7e3daff3d4c93af74b0d473c4dd91f12b14bbd', 'message': 'Agnostic approach to construct context from_dict\n\nReplace the existing argument specified values in from_dict() method\nto be argument agnostic for any future arguments. Based from version\nfound in Solum.\n\nAll current boolean values match instantiation defaults.\n\nChange-Id: I17c76881aa662de7ff245b3f6bfca309896ddf24\n'}, {'number': 3, 'created': '2016-02-17 21:56:51.000000000', 'files': ['oslo_context/tests/test_context.py', 'oslo_context/context.py'], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/0327388695e57c297b145df96e907aa5188205d9', 'message': 'Agnostic approach to construct context from_dict\n\nReplace the existing argument specified values in from_dict() method\nto be argument agnostic for any future arguments. Based from version\nfound in Solum.\n\nAll current boolean values match instantiation defaults.\n\nChange-Id: I17c76881aa662de7ff245b3f6bfca309896ddf24\n'}]",3,274828,0327388695e57c297b145df96e907aa5188205d9,17,5,3,16051,,,0,"Agnostic approach to construct context from_dict

Replace the existing argument specified values in from_dict() method
to be argument agnostic for any future arguments. Based from version
found in Solum.

All current boolean values match instantiation defaults.

Change-Id: I17c76881aa662de7ff245b3f6bfca309896ddf24
",git fetch https://review.opendev.org/openstack/oslo.context refs/changes/28/274828/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_context/context.py'],1,b5bf2fcb0720fc403778be42f5e323afca87cac8,bp/app-agnostic-logging-parameters,"import inspect def from_dict(cls, values): allowed = [arg for arg in inspect.getargspec(RequestContext.__init__).args if arg != 'self'] kwargs = dict((k, v) for (k, v) in values.items() if k in allowed) return cls(**kwargs)"," def from_dict(cls, ctx): return cls( auth_token=ctx.get(""auth_token""), user=ctx.get(""user""), tenant=ctx.get(""tenant""), domain=ctx.get(""domain""), user_domain=ctx.get(""user_domain""), project_domain=ctx.get(""project_domain""), is_admin=ctx.get(""is_admin"", False), read_only=ctx.get(""read_only"", False), show_deleted=ctx.get(""show_deleted"", False), request_id=ctx.get(""request_id""), resource_uuid=ctx.get(""resource_uuid""))",7,13
openstack%2Fkolla~master~I416afc0299c8e6a8e603eca2334ea3a9836707fe,openstack/kolla,master,I416afc0299c8e6a8e603eca2334ea3a9836707fe,Set nova hypervisor to qemu in Vagrant,MERGED,2016-02-18 05:32:37.000000000,2016-02-18 18:31:26.000000000,2016-02-18 18:31:26.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-18 05:32:37.000000000', 'files': ['dev/vagrant/centos-bootstrap.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/076fb5a6469a415c0cb947e616c9ab7e662621f6', 'message': 'Set nova hypervisor to qemu in Vagrant\n\nAdditionally, install python-neutronclient that is needed for\ntools/init-runonce.\n\nChange-Id: I416afc0299c8e6a8e603eca2334ea3a9836707fe\nPartial-Bug: #1542933\n'}]",0,281637,076fb5a6469a415c0cb947e616c9ab7e662621f6,11,3,1,13039,,,0,"Set nova hypervisor to qemu in Vagrant

Additionally, install python-neutronclient that is needed for
tools/init-runonce.

Change-Id: I416afc0299c8e6a8e603eca2334ea3a9836707fe
Partial-Bug: #1542933
",git fetch https://review.opendev.org/openstack/kolla refs/changes/37/281637/1 && git format-patch -1 --stdout FETCH_HEAD,['dev/vagrant/centos-bootstrap.sh'],1,076fb5a6469a415c0cb947e616c9ab7e662621f6,bug/1542933," pip install --upgrade ""ansible<2"" python-openstackclient python-neutronclient tox mkdir -p /etc/kolla/config/nova/ cat > /etc/kolla/config/nova/nova-compute.conf <<EOF [libvirt] virt_type=qemu EOF "," pip install --upgrade ""ansible<2"" python-openstackclient tox",7,1
openstack%2Fsecurity-doc~master~I081ab834099911f4000852088bdb92390f198d6b,openstack/security-doc,master,I081ab834099911f4000852088bdb92390f198d6b,Document cinder wiping behavior with LVM backend,ABANDONED,2015-07-07 19:37:41.000000000,2016-02-18 18:26:48.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2243}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 6804}, {'_account_id': 8074}, {'_account_id': 9098}, {'_account_id': 10281}, {'_account_id': 10670}, {'_account_id': 11397}, {'_account_id': 12325}]","[{'number': 1, 'created': '2015-07-07 19:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/32a7927f98a0a8df19e6668400d43d7ceb48c1bf', 'message': ""Document cinder wiping behavior with LVM backend\n\nOn Cinder, when the reference LVM back-end is used it is\ncommon to require that deleted volumes/snapshots are not\nwiped/zero'd.\n\nThis change documents this behavior, and suggests some\nmitigation mechanisms and future improvements.\n\nCloses-Bug: #1329606\nCo-Authored-By: John Griffith <john.griffith@solidfire.com>\nSigned-off-by: Dave Walker (Daviey) <email@daviey.com>\nChange-Id: I081ab834099911f4000852088bdb92390f198d6b\n""}, {'number': 2, 'created': '2015-07-07 22:48:17.000000000', 'files': ['security-guide/ch_block_storage.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/cc9732bf56846af3e2ef0214e9a9578b36a8169c', 'message': ""Document cinder wiping behavior with LVM backend\n\nOn Cinder, when the reference LVM back-end is used it is\ncommon to require that deleted volumes/snapshots are not\nwiped/zero'd.\n\nThis change documents this behavior, and suggests some\nmitigation mechanisms and future improvements.\n\nCloses-Bug: #1329606\nCo-Authored-By: John Griffith <john.griffith@solidfire.com>\nSigned-off-by: Dave Walker (Daviey) <email@daviey.com>\nChange-Id: I081ab834099911f4000852088bdb92390f198d6b\n""}]",19,199231,cc9732bf56846af3e2ef0214e9a9578b36a8169c,20,12,2,979,,,0,"Document cinder wiping behavior with LVM backend

On Cinder, when the reference LVM back-end is used it is
common to require that deleted volumes/snapshots are not
wiped/zero'd.

This change documents this behavior, and suggests some
mitigation mechanisms and future improvements.

Closes-Bug: #1329606
Co-Authored-By: John Griffith <john.griffith@solidfire.com>
Signed-off-by: Dave Walker (Daviey) <email@daviey.com>
Change-Id: I081ab834099911f4000852088bdb92390f198d6b
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/31/199231/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/ch_block_storage.xml'],1,32a7927f98a0a8df19e6668400d43d7ceb48c1bf,bug/1329606," <section xml:id=""block-storage-cinder-wipe-behavior""> <title>Block Storage wiping behaviour</title> <para>OpenStack Block Storage has a variety of supported back-ends, one of which is the LVM driver (Logical Volume Manager) which is the reference driver.</para> <caution> <para>When removing Volume or Snapshots there is an additional operation called secure-delete. There are some issues using the cinder LVM back-end with this. This operation would wipe the LBA's (Logical Block Addressing) of the allocated resource by using <link xlink:href=""https://en.wikipedia.org/wiki/Dd_(Unix)"">dd</link> to write zeros over all of the allocated blocks of the resource. The principle behind this implementation was to ensure that data leakage is prevented.</para></caution> <para>For example Tenant A, creates a volume and puts sensitive data on it, then deletes it, and Tenant B creates a volume that just so happens to reallocate the same blocks that tenant A was using. It's possible that tenant B could read from the volume and assemble blocks of information. The dd of zeros was intended to eliminate the possibility of this happening.</para> <para>The problem with this process is that some Linux kernels have a bug in the LVM driver (as found in Ubuntu 12.04), which is exposed regulary by heavy I/O going to the Volumes (or especially Snapshots) resulting in a kernel hang requiring a hard reset to recover the system.</para> <para>There were a number of suggestions to backport LVM versions but is currently unsolved in the default Ubuntu 12.04 kernel, as outlined on the <link xlink:href=""https://launchpad.net/bugs/1023755"">bug</link>. To work around this issue, an option to disable the secure delete process altogether was added to cinder. It is thought that most deployments using the LVM backend are private cloud and dev/test or proof-of-concept environments and many of them were not concerned with this possible data leakage issue.</para> <tip> <para>In addition, the cinder developers also introduced thin provisioning options for LVM. Using thin provisioning resolves this issue internally as when a thin reate a thin provisioned LVM volume is created, the LVM subsystem always returns zeros for blocks you haven't written yet, so there's never an issue of data leakage here.</para></tip> <para>The thin provisioning option however isn't available upstream in Ubuntu until the 14.04 release. There are a number of backports available for Ubuntu 12.04 systems that are stable and used in production environments, however none of the packages are supported by the Ubuntu project.</para> <para>The recommendation for those that are concerned about data leakage between volumes is to not use Ubuntu 12.04, but also thin provisioning is likely a better option as the I/O and time intension operation of overwriting blocks (with zero, via dd) on delete is expensive.</para> </section>",,49,0
openstack%2Fopenstack-chef-repo~master~I359e5dce2bdf9fbb65e31b20b04a41157b1b1198,openstack/openstack-chef-repo,master,I359e5dce2bdf9fbb65e31b20b04a41157b1b1198,Remove locale cookbook from allinone role,MERGED,2016-02-17 01:01:56.000000000,2016-02-18 18:22:48.000000000,2016-02-18 18:22:48.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 11915}, {'_account_id': 12323}]","[{'number': 1, 'created': '2016-02-17 01:01:56.000000000', 'files': ['roles/allinone.json', 'Berksfile'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/261c35122a0f52a40883ca7b7e672c21f254e411', 'message': 'Remove locale cookbook from allinone role\n\nThe locale cookbook is broken on CentOS 7 and fails to converge.\n\nChange-Id: I359e5dce2bdf9fbb65e31b20b04a41157b1b1198\n'}]",0,280996,261c35122a0f52a40883ca7b7e672c21f254e411,12,4,1,14790,,,0,"Remove locale cookbook from allinone role

The locale cookbook is broken on CentOS 7 and fails to converge.

Change-Id: I359e5dce2bdf9fbb65e31b20b04a41157b1b1198
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/96/280996/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/allinone.json', 'Berksfile']",2,261c35122a0f52a40883ca7b7e672c21f254e411,centos72,,"cookbook 'locale', '1.0.2'",0,2
openstack%2Ffuel-library~master~I21bfe790e12425fa4d96a61245836e9eb4a687a8,openstack/fuel-library,master,I21bfe790e12425fa4d96a61245836e9eb4a687a8,Move refs for OpenStack puppet modules to upstream master,MERGED,2016-02-12 10:34:43.000000000,2016-02-18 18:21:35.000000000,2016-02-18 18:15:37.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7195}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 18795}]","[{'number': 1, 'created': '2016-02-12 10:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3a578009956b646161fc68f8e9810d381fbe6deb', 'message': 'Move refs for OpenStack puppet modules to master HEAD\n\nBlueprint: puppet-mitaka-modules\n\nDepends-on:\nhttps://review.openstack.org/#/c/268239/\nhttps://review.openstack.org/#/c/267232/\nhttps://review.openstack.org/#/c/274277/\nhttps://review.openstack.org/#/c/275173/\n\nChange-Id: I21bfe790e12425fa4d96a61245836e9eb4a687a8\n'}, {'number': 2, 'created': '2016-02-16 11:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4bcfeae7825ecece90cdfbe6c889ba6c68df36a1', 'message': 'Move refs for OpenStack puppet modules to master HEAD\n\nBlueprint: puppet-mitaka-modules\n\nDepends-on:\nhttps://review.openstack.org/#/c/268239/\nhttps://review.openstack.org/#/c/267232/\nhttps://review.openstack.org/#/c/275784/\n\nChange-Id: I21bfe790e12425fa4d96a61245836e9eb4a687a8\n'}, {'number': 3, 'created': '2016-02-18 11:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d06052799105543f0f678924cda7dca33d924932', 'message': 'Move refs for OpenStack puppet modules to upstream master\n\nBlueprint: puppet-mitaka-modules\n\nChange-Id: I21bfe790e12425fa4d96a61245836e9eb4a687a8\n'}, {'number': 4, 'created': '2016-02-18 13:47:41.000000000', 'files': ['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'tests/noop/spec/hosts/ceilometer/controller_spec.rb', 'deployment/puppet/openstack/spec/classes/openstack_compute_spec.rb', 'tests/noop/spec/hosts/glance/glance_spec.rb', 'deployment/puppet/openstack/manifests/compute.pp', 'deployment/puppet/openstack/spec/classes/openstack_ceilometer_spec.rb', 'deployment/Puppetfile', 'deployment/puppet/openstack/spec/classes/openstack_cinder_spec.rb', 'deployment/puppet/openstack/spec/classes/openstack_galera_client_spec.rb', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c4d4f45c182856a120f44b9f6fca79f4212bd585', 'message': 'Move refs for OpenStack puppet modules to upstream master\n\nBlueprint: puppet-mitaka-modules\n\nChange-Id: I21bfe790e12425fa4d96a61245836e9eb4a687a8\n'}]",0,279460,c4d4f45c182856a120f44b9f6fca79f4212bd585,52,12,4,7732,,,0,"Move refs for OpenStack puppet modules to upstream master

Blueprint: puppet-mitaka-modules

Change-Id: I21bfe790e12425fa4d96a61245836e9eb4a687a8
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/60/279460/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'tests/noop/spec/hosts/openstack-controller/openstack-controller_spec.rb', 'tests/noop/spec/hosts/glance/glance_spec.rb', 'deployment/Puppetfile', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb', 'tests/noop/spec/hosts/roles/compute_spec.rb']",7,3a578009956b646161fc68f8e9810d381fbe6deb,bp/puppet-mitaka-modules, should contain_nova_config('keystone_authtoken/memcached_servers').with(, should contain_nova_config('DEFAULT/memcached_servers').with(,18,19
openstack%2Fanchor~master~I883f8d5d9dc3430443aa08fdf2448bf385575557,openstack/anchor,master,I883f8d5d9dc3430443aa08fdf2448bf385575557,Copy key identifier from the available CA,MERGED,2016-02-02 05:24:33.000000000,2016-02-18 18:20:49.000000000,2016-02-18 18:20:49.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}, {'_account_id': 11861}]","[{'number': 1, 'created': '2016-02-02 05:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/1d92075c0afaa68bc177f2d21b009a72bc87c04e', 'message': 'Copy key identifier from the available CA\n\nChange-Id: I883f8d5d9dc3430443aa08fdf2448bf385575557\n'}, {'number': 2, 'created': '2016-02-02 05:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/78c9840b403f58f881aaebccf1e1e2b62cf0e084', 'message': 'Copy key identifier from the available CA\n\nIf the subjectAlternativeKey is available in the CA, use it as authority key on\nthe new certificate. Otherwise embed the serial number.\n\nChange-Id: I883f8d5d9dc3430443aa08fdf2448bf385575557\n'}, {'number': 3, 'created': '2016-02-03 07:02:10.000000000', 'files': ['anchor/X509/certificate.py', 'anchor/certificate_ops.py', 'tests/test_signing_backend.py', 'anchor/X509/extension.py', 'tests/X509/test_extension.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/4ec98b6fd8820405a4e2af82f654dbf5a0504582', 'message': 'Copy key identifier from the available CA\n\nIf the subjectAlternativeKey is available in the CA, use it as authority key on\nthe new certificate. Otherwise embed the serial number.\n\nThe key id is included in the signed certificates according to\nRFC5280 section-4.2.1.1. Anchor uses the first recommended method of keyid\ngeneration. The behaviour matches openssl.\n\nChange-Id: I883f8d5d9dc3430443aa08fdf2448bf385575557\n'}]",6,275012,4ec98b6fd8820405a4e2af82f654dbf5a0504582,15,6,3,1528,,,0,"Copy key identifier from the available CA

If the subjectAlternativeKey is available in the CA, use it as authority key on
the new certificate. Otherwise embed the serial number.

The key id is included in the signed certificates according to
RFC5280 section-4.2.1.1. Anchor uses the first recommended method of keyid
generation. The behaviour matches openssl.

Change-Id: I883f8d5d9dc3430443aa08fdf2448bf385575557
",git fetch https://review.opendev.org/openstack/anchor refs/changes/12/275012/2 && git format-patch -1 --stdout FETCH_HEAD,"['anchor/X509/certificate.py', 'anchor/certificate_ops.py', 'anchor/X509/extension.py', 'tests/X509/test_extension.py']",4,1d92075c0afaa68bc177f2d21b009a72bc87c04e,key_identifiers," class TestAuthorityKeyId(unittest.TestCase): def setUp(self): self.ext = extension.X509ExtensionAuthorityKeyId() def test_key_id(self): key_id = b""12345678"" self.ext.set_key_id(key_id) self.assertEqual(key_id, self.ext.get_key_id()) def test_name_serial(self): s = 12345678 self.ext.set_serial(s) self.assertEqual(s, self.ext.get_serial()) class TestSubjectKeyId(unittest.TestCase): def setUp(self): self.ext = extension.X509ExtensionSubjectKeyId() def test_key_id(self): key_id = b""12345678"" self.ext.set_key_id(key_id) self.assertEqual(key_id, self.ext.get_key_id())",,89,0
openstack%2Fanchor~master~I88acc4b1c57ef78d24f9f78d013564fc4c875d7c,openstack/anchor,master,I88acc4b1c57ef78d24f9f78d013564fc4c875d7c,Add shiny new badges to anchor README,MERGED,2016-02-04 17:18:50.000000000,2016-02-18 18:18:29.000000000,2016-02-18 18:18:28.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2016-02-04 17:18:50.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/anchor/commit/da833500e94f615925db692b8ef72bcb443572b3', 'message': 'Add shiny new badges to anchor README\n\nPyPi supports cool badges to indicate version, license, formats,\netc. Makes it very easy to see right up top critical information\nabout the project.\n\nChange-Id: I88acc4b1c57ef78d24f9f78d013564fc4c875d7c\n'}]",0,276361,da833500e94f615925db692b8ef72bcb443572b3,7,5,1,8119,,,0,"Add shiny new badges to anchor README

PyPi supports cool badges to indicate version, license, formats,
etc. Makes it very easy to see right up top critical information
about the project.

Change-Id: I88acc4b1c57ef78d24f9f78d013564fc4c875d7c
",git fetch https://review.opendev.org/openstack/anchor refs/changes/61/276361/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,da833500e94f615925db692b8ef72bcb443572b3,add_badges,.. image:: https://img.shields.io/pypi/v/anchor.svg :target: https://pypi.python.org/pypi/anchor/ :alt: Latest Version .. image:: https://img.shields.io/pypi/pyversions/anchor.svg :target: https://pypi.python.org/pypi/anchor/ :alt: Python Versions .. image:: https://img.shields.io/pypi/format/anchor.svg :target: https://pypi.python.org/pypi/anchor/ :alt: Format .. image:: https://img.shields.io/badge/license-Apache%202-blue.svg :target: https://git.openstack.org/cgit/openstack/anchor/plain/LICENSE :alt: License ,,16,0
openstack%2Fkolla~master~Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e,openstack/kolla,master,Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e,Add docs to explain why we disabling selinux,MERGED,2016-02-17 00:56:14.000000000,2016-02-18 18:14:46.000000000,2016-02-18 18:14:46.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 13039}, {'_account_id': 14119}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-02-17 00:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7e8a007cbdf29acafd5868203fe71f8893197682', 'message': 'Add does to explain why we disabling selinux\n\nChange-Id: Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e\n'}, {'number': 2, 'created': '2016-02-17 01:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c1c818c42dbbecdef33ccc53ab57c9c68a2065c5', 'message': 'Add docs to explain why we disabling selinux\n\nChange-Id: Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e\n'}, {'number': 3, 'created': '2016-02-17 14:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/051d707b55abe56a96d2ca54e104a0113441dd58', 'message': 'Add docs to explain why we disabling selinux\n\nChange-Id: Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e\n'}, {'number': 4, 'created': '2016-02-18 16:04:09.000000000', 'files': ['doc/index.rst', 'doc/selinux.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/89cb146ac11102a2e4642f1d10bfb224afdaf4c8', 'message': 'Add docs to explain why we disabling selinux\n\nChange-Id: Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e\n'}]",12,280995,89cb146ac11102a2e4642f1d10bfb224afdaf4c8,24,9,4,14119,,,0,"Add docs to explain why we disabling selinux

Change-Id: Iadbd4a0d77aee692abd9ab4f81ba67ead8949b1e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/95/280995/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/index.rst', 'doc/selinux.rst']",2,7e8a007cbdf29acafd5868203fe71f8893197682,ayoung_docs,"SELinux in Kolla ================ Overview -------- The state of SE Linux in Kolla is a work in progress. The short answer is you must disable it until selinux polices are written for the Docker containers. The Long Answer --------------- To understand why Kolla needs to set certain selinux policies for services that you wouldn't expect to need them (rabbitmq, mariadb, glance, etc.) we must take a step back and talk about Docker. Docker has not had the concept of persistent containerized data until recently. This means when a container is run the data it creates is destroyed when the container goes away, which is obviously no good in the case of upgrades. It suggested data containers to solve this issue which could only hold data if they were never recreated leading to a scary state where you could lose access to your data if the wrong command was executed. The real answer to this problem came in Docker 1.9 with the introduction of named volumes. You could now address volumes directly by name removing the need for so called ""data containers"" all together. Another solution to the persistent data issue is to use a host bind mount which involves making, for sake example, host directory /var/lib/mysql available inside the container at /var/lib/mysql. This absolutely solves the problem of persistent data, but it introduces another security issue, permissions. With this host bind mount solution the data in /var/lib/mysql will be owned by the mysql user in the container. Unfortuantely, that mysql user in the container could have any UID/GID and thats who will own the data outside the container introducing a potential security risk. Additionally, this method dirties the host and requires host permissions to the directories to bind mount. The solution Kolla choose is named volumes. Why does this matter in the case of selinux? Kolla does not run the process it is launching as root in most cases. So glance-api is run as the glance user, and mariadb is run as the mysql user, and so on. When mounting a named volume in the location that the peristent data will be stored it will be owned by the root user and group. The mysql user has no permissions to write to this folder now. What Kolla does is allow a select few commands to be run with sudo as the mysql user. This allows the mysql user to chown a specific, explict directory and store its data in a named volume without the security risk and other downsides of host bind mounts. The downside to this is selinux blocks those sudo commands and it will do so until we make explict policies to allow those operations. ",,49,0
openstack%2Fgnocchi~master~I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d,openstack/gnocchi,master,I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d,storage: autoconfigure coordination_url,MERGED,2016-01-21 16:39:57.000000000,2016-02-18 18:03:54.000000000,2016-02-18 18:03:54.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-01-21 16:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8892e315205501a1379890b6ca6262f46b1e8a5a', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 2, 'created': '2016-01-22 09:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d3ea773a6b44c7dff98b16f50592c39a74b7803e', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 3, 'created': '2016-01-22 10:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4f6d977e8542158341e3f581465e090be5b05c62', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 4, 'created': '2016-01-26 14:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0713ca12db7c5c4abcd98ef0b7d3b6038797ff66', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 5, 'created': '2016-01-27 15:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/678314649ce89b3901b7bdf90f2c32cba9ffa686', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 6, 'created': '2016-02-02 08:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6dc946d797aa8c6281649b4f9fa652d9d8d19108', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 7, 'created': '2016-02-12 08:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4dedef3440343f718872b29792837d2b07bdf977', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 8, 'created': '2016-02-12 10:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/fcc8f45c4b63e6b52c2b46dcebf039f452e6711a', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 9, 'created': '2016-02-15 17:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d41a47e2cc3a21fad7713a8b44da1ac02f34aa75', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}, {'number': 10, 'created': '2016-02-17 16:00:28.000000000', 'files': ['gnocchi/tests/gabbi/fixtures.py', 'gnocchi/tests/base.py', 'doc/source/configuration.rst', 'gnocchi/storage/_carbonara.py', 'setup-test-env.sh', 'devstack/plugin.sh', 'gnocchi/service.py', 'setup.cfg', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0fd52b5820d8f32892dd72f62adde96ab2946072', 'message': 'storage: autoconfigure coordination_url\n\nThis makes the storage leverage the indexer URL by default, avoiding\nuser mistake of not configuring it properly and making it work by\ndefault for multi node environment. Wouhouh!\n\nChange-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d\n'}]",4,270907,0fd52b5820d8f32892dd72f62adde96ab2946072,35,4,10,1669,,,0,"storage: autoconfigure coordination_url

This makes the storage leverage the indexer URL by default, avoiding
user mistake of not configuring it properly and making it work by
default for multi node environment. Wouhouh!

Change-Id: I8ef35d9e118e2d2a6a87ce6db15a2212df7f355d
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/07/270907/8 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/gabbi/fixtures.py', 'gnocchi/tests/base.py', 'doc/source/configuration.rst', 'gnocchi/storage/_carbonara.py', 'setup-test-env.sh', 'devstack/plugin.sh', 'gnocchi/service.py', 'setup.cfg', 'devstack/settings']",9,8892e315205501a1379890b6ca6262f46b1e8a5a,jd/simplify-coordination-url,,GNOCCHI_COORDINATOR_URL=${GNOCCHI_COORDINATOR_URL:-file://${GNOCCHI_DATA_DIR}/locks},20,49
openstack%2Fnova~master~If1cae8f4c9037f7821554a94d4440f66d9538794,openstack/nova,master,If1cae8f4c9037f7821554a94d4440f66d9538794,reset task_state after select_destinations failed.,MERGED,2016-02-03 11:59:30.000000000,2016-02-18 17:56:33.000000000,2016-02-18 17:56:32.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6608}, {'_account_id': 7461}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12299}, {'_account_id': 14131}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15648}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-03 11:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da4ea0ef6960ad7f2967413081ef299443b99807', 'message': 'reset task_state after select_destinations failed.\n\nDuring live migration, there maybe exception when let scheduler\nselect destination, and live migration will abort. But the task\nstate of the instance still keep migrating, then we can not take\nany action on this instance.\n\nWe need to recover the state of the task as None.\n\nChange-Id: If1cae8f4c9037f7821554a94d4440f66d9538794\nCloses-bug: #1536916\n'}, {'number': 2, 'created': '2016-02-03 15:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0d922ea06aa0ff8aa0716d119c9f9624c30ed04', 'message': 'reset task_state after select_destinations failed.\n\nDuring live migration, there maybe exception when let scheduler\nselect destination, and live migration will abort. But the task\nstate of the instance still keep migrating, then we can not take\nany action on this instance.\n\nWe need to recover the state of the task as None.\nWe should also recover the vm_state.\n\nChange-Id: If1cae8f4c9037f7821554a94d4440f66d9538794\nCloses-bug: #1536916\n'}, {'number': 3, 'created': '2016-02-05 06:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e8466c7739aa38e692867fe635510ed6df26ddf', 'message': 'reset task_state after select_destinations failed.\n\nDuring live migration, there maybe exception when let scheduler\nselect destination, and live migration will abort. But the task\nstate of the instance still keep migrating, then we can not take\nany action on this instance.\n\nWe need to recover the state of the task as None.\nWe should also recover the vm_state.\n\nChange-Id: If1cae8f4c9037f7821554a94d4440f66d9538794\nCloses-bug: #1536916\n'}, {'number': 4, 'created': '2016-02-05 06:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69889ec3df0e6aed9387d7aa7c336b7803d12afb', 'message': 'reset task_state after select_destinations failed.\n\nDuring live migration, there maybe exception when let scheduler\nselect destination, and live migration will abort. But the task\nstate of the instance still keep migrating, then we can not take\nany action on this instance.\n\nWe need to recover the state of the task as None.\nWe should also recover the vm_state.\n\nChange-Id: If1cae8f4c9037f7821554a94d4440f66d9538794\nCloses-bug: #1536916\n'}, {'number': 5, 'created': '2016-02-16 07:05:09.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py', 'nova/conductor/tasks/live_migrate.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/30d5d805c10b0cc6e474fe1292b2c6549fc07d33', 'message': 'reset task_state after select_destinations failed.\n\nDuring live migration, there maybe exception when let scheduler\nselect destination, and live migration will abort. But the task\nstate of the instance still keep migrating, then we can not take\nany action on this instance.\n\nWe need to recover the state of the task as None.\nWe should also recover the vm_state.\n\nChange-Id: If1cae8f4c9037f7821554a94d4440f66d9538794\nCloses-bug: #1536916\n'}]",8,275650,30d5d805c10b0cc6e474fe1292b2c6549fc07d33,63,22,5,14131,,,0,"reset task_state after select_destinations failed.

During live migration, there maybe exception when let scheduler
select destination, and live migration will abort. But the task
state of the instance still keep migrating, then we can not take
any action on this instance.

We need to recover the state of the task as None.
We should also recover the vm_state.

Change-Id: If1cae8f4c9037f7821554a94d4440f66d9538794
Closes-bug: #1536916
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/275650/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/conductor/tasks/live_migrate.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py']",3,da4ea0ef6960ad7f2967413081ef299443b99807,rolling_bug_v5,"from nova.compute import vm_states vm_state = vm_states.ACTIVE, @mock.patch(""nova.utils.get_image_from_system_metadata"") @mock.patch(""nova.scheduler.utils.build_request_spec"") @mock.patch(""nova.scheduler.utils.setup_instance_group"") @mock.patch(""nova.objects.RequestSpec.from_primitives"") @mock.patch(""nova.scheduler.utils.set_vm_state_and_notify"") def test_find_destination_with_remoteError(self, m_set_vm_state_and_notify, m_from_primitives, m_setup_instance_group, m_build_request_spec, m_get_image_from_system_metadata): m_get_image_from_system_metadata.return_value = {'properties': {}} m_build_request_spec.return_value = {} fake_spec = objects.RequestSpec() m_from_primitives.return_value = fake_spec with mock.patch.object(self.task.scheduler_client, 'select_destinations') as m_select_destinations: error = messaging.RemoteError() m_select_destinations.side_effect = error self.assertRaises(exception.MigrationSelectDestinations, self.task._find_destination) m_set_vm_state_and_notify.assert_called_once_with( self.context, self.instance_uuid, 'compute_task', 'migrate_server', {'vm_state': vm_states.ACTIVE, 'task_state': None}, error, {}, None) ",,48,2
openstack%2Freleases~master~If257aa38892a190a05bb74a62a8265378daab1bb,openstack/releases,master,If257aa38892a190a05bb74a62a8265378daab1bb,Release os-client-config 1.15.0,MERGED,2016-02-17 21:06:09.000000000,2016-02-18 17:46:54.000000000,2016-02-18 17:46:54.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-02-17 21:06:09.000000000', 'files': ['deliverables/mitaka/os-client-config.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/89a355cdcef9995db4e67b552950ba8e33ee19c8', 'message': 'Release os-client-config 1.15.0\n\nThis release improves swiftclient instantiation making long lived\nswiftclient objects useable. One bug in cloud parameters is fixed and\nseveral vendor profile updates are included.\n\nChange-Id: If257aa38892a190a05bb74a62a8265378daab1bb\n'}]",0,281526,89a355cdcef9995db4e67b552950ba8e33ee19c8,10,3,1,4146,,,0,"Release os-client-config 1.15.0

This release improves swiftclient instantiation making long lived
swiftclient objects useable. One bug in cloud parameters is fixed and
several vendor profile updates are included.

Change-Id: If257aa38892a190a05bb74a62a8265378daab1bb
",git fetch https://review.opendev.org/openstack/releases refs/changes/26/281526/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/os-client-config.yaml'],1,89a355cdcef9995db4e67b552950ba8e33ee19c8,oscc-1.15.0, - version: 1.15.0 projects: - repo: openstack/os-client-config hash: 7865abc22b7289b2679f6848395d4850d544d1f0 highlights: > Swiftclient objects are passed authentication credentials allowing long lived swiftclients to reauthenticate if necessary.,,7,0
openstack%2Fbarbican~master~I6c28446366f26e84af86ab873bbea78165abab4d,openstack/barbican,master,I6c28446366f26e84af86ab873bbea78165abab4d,Typo change Barbican to barbican Closes-Bug: 1542508,MERGED,2016-02-05 22:27:16.000000000,2016-02-18 17:43:26.000000000,2016-02-18 17:43:26.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7973}, {'_account_id': 16046}, {'_account_id': 20140}]","[{'number': 1, 'created': '2016-02-05 22:27:16.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/a98674de832e8c1772f75d1adc3e908eb6d4b7bb', 'message': 'Typo change Barbican to barbican\nCloses-Bug: 1542508\n\nChange-Id: I6c28446366f26e84af86ab873bbea78165abab4d\n'}]",1,276939,a98674de832e8c1772f75d1adc3e908eb6d4b7bb,10,5,1,17716,,,0,"Typo change Barbican to barbican
Closes-Bug: 1542508

Change-Id: I6c28446366f26e84af86ab873bbea78165abab4d
",git fetch https://review.opendev.org/openstack/barbican refs/changes/39/276939/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,a98674de832e8c1772f75d1adc3e908eb6d4b7bb,bug/1542508,"This document describes barbican for contributors of the project, and assumes that you are already familiar with barbican from an end-user perspective.","This document describes Barbican for contributors of the project, and assumes that you are already familiar with Barbican from an end-user perspective.",2,2
openstack%2Freleases~master~Ia277d2724e983df78da1335b12320901494a9ae7,openstack/releases,master,Ia277d2724e983df78da1335b12320901494a9ae7,Release os-brick 1.0.0,MERGED,2016-02-17 20:52:18.000000000,2016-02-18 17:41:20.000000000,2016-02-18 17:41:19.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6873}]","[{'number': 1, 'created': '2016-02-17 20:52:18.000000000', 'files': ['deliverables/mitaka/os-brick.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6081d3fa703b137cf9a5a0f68a2ff39f49324a34', 'message': ""Release os-brick 1.0.0\n\nFinal Mitaka release for os-brick. Fixes include better\nmultipath device handling and a fix for device identification\nfor LUN ID's great than 255.\n\nChange-Id: Ia277d2724e983df78da1335b12320901494a9ae7\n""}]",0,281520,6081d3fa703b137cf9a5a0f68a2ff39f49324a34,9,3,1,11904,,,0,"Release os-brick 1.0.0

Final Mitaka release for os-brick. Fixes include better
multipath device handling and a fix for device identification
for LUN ID's great than 255.

Change-Id: Ia277d2724e983df78da1335b12320901494a9ae7
",git fetch https://review.opendev.org/openstack/releases refs/changes/20/281520/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/os-brick.yaml'],1,6081d3fa703b137cf9a5a0f68a2ff39f49324a34,os-brick-1.0.0, - version: 1.0.0 projects: - repo: openstack/os-brick hash: 44254e1e1401affd67628bbb280043ade3d460b0 highlights: > Multipath device handling improvements. Fixed issue for LUN ID's > 255.,,7,0
openstack%2Fapi-site~master~Iebd39b16e09c586f411e871d3fe69800985fe7a4,openstack/api-site,master,Iebd39b16e09c586f411e871d3fe69800985fe7a4,Shade installation link,MERGED,2016-02-17 23:36:13.000000000,2016-02-18 17:31:17.000000000,2016-02-18 17:31:17.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-17 23:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/ebd18e7798849490c69afa8fdc5ebff81527ae54', 'message': 'Shade installation link\nUpdate the link about shade installation.\nCloses-Bug: #1545209\n\nChange-Id: Iebd39b16e09c586f411e871d3fe69800985fe7a4\n'}, {'number': 2, 'created': '2016-02-18 15:44:02.000000000', 'files': ['firstapp/source/getting_started.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/82e74e6ad8e8e922b172cdc69569ebf84b601e6d', 'message': 'Shade installation link\n\nUpdate the link about shade installation.\n\nCloses-Bug: 1545209\n\nChange-Id: Iebd39b16e09c586f411e871d3fe69800985fe7a4\n'}]",1,281580,82e74e6ad8e8e922b172cdc69569ebf84b601e6d,12,6,2,15409,,,0,"Shade installation link

Update the link about shade installation.

Closes-Bug: 1545209

Change-Id: Iebd39b16e09c586f411e871d3fe69800985fe7a4
",git fetch https://review.opendev.org/openstack/api-site refs/changes/80/281580/2 && git format-patch -1 --stdout FETCH_HEAD,['firstapp/source/getting_started.rst'],1,ebd18e7798849490c69afa8fdc5ebff81527ae54,bug/1545209, `a recent version of shade library installed <http://docs.openstack.org/infra/shade/installation.html>`_., `a recent version of shade library installed <https://pypi.python.org/pypi/shade/0.11.0>`_.,1,1
openstack%2Ffuel-web~stable%2F7.0~I0ae2e5395fb4fe5cd921bc336718cc94003f156d,openstack/fuel-web,stable/7.0,I0ae2e5395fb4fe5cd921bc336718cc94003f156d,Assign VIPs not only for controllers' node group,ABANDONED,2015-10-09 13:07:50.000000000,2016-02-18 17:28:01.000000000,,"[{'_account_id': 3}, {'_account_id': 8358}, {'_account_id': 8392}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 10959}, {'_account_id': 12200}, {'_account_id': 14543}, {'_account_id': 14689}]","[{'number': 1, 'created': '2015-10-09 13:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f9bca0d519e84ce4fc46fe0b21532629116f3592', 'message': ""Assign VIPs not only for controllers' node group\n\nRecently we had an assumption that VIPs could be allocated only for\ncontrollers, so we used controllers' node group to do allocation.\nThat was incorrect assumption, and led to incorrect behaviour for\nenvs with standalone-* roles (e.g. standalone-keystone) if it's\nin separate node group.\n\nSo let's use proper node group for VIP allocation based on provided\nnode role(s) information. Obviously, all nodes with provided node\nrole(s) MUST have the same node group, otherwise the error will be\nthrown.\n\nCloses-Bug: #1487021\nChange-Id: I0ae2e5395fb4fe5cd921bc336718cc94003f156d\n""}, {'number': 2, 'created': '2015-10-15 09:09:46.000000000', 'files': ['nailgun/nailgun/test/integration/test_network_manager.py', 'nailgun/nailgun/test/integration/test_network_configuration.py', 'nailgun/nailgun/errors/__init__.py', 'nailgun/nailgun/network/manager.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_objects.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d6a5ec0a6c6d1dfd0d53055f4d58a3e1e58ff7ac', 'message': ""Assign VIPs not only for controllers' node group\n\nRecently we had an assumption that VIPs could be allocated only for\ncontrollers, so we used controllers' node group to do allocation.\nThat was incorrect assumption, and led to incorrect behaviour for\nenvs with standalone-* roles (e.g. standalone-keystone) if it's\nin separate node group.\n\nSo let's use proper node group for VIP allocation based on provided\nnode role(s) information. Obviously, all nodes with provided node\nrole(s) MUST have the same node group, otherwise the error will be\nthrown.\n\nCloses-Bug: #1487021\nChange-Id: I0ae2e5395fb4fe5cd921bc336718cc94003f156d\n""}]",0,233047,d6a5ec0a6c6d1dfd0d53055f4d58a3e1e58ff7ac,26,9,2,10391,,,0,"Assign VIPs not only for controllers' node group

Recently we had an assumption that VIPs could be allocated only for
controllers, so we used controllers' node group to do allocation.
That was incorrect assumption, and led to incorrect behaviour for
envs with standalone-* roles (e.g. standalone-keystone) if it's
in separate node group.

So let's use proper node group for VIP allocation based on provided
node role(s) information. Obviously, all nodes with provided node
role(s) MUST have the same node group, otherwise the error will be
thrown.

Closes-Bug: #1487021
Change-Id: I0ae2e5395fb4fe5cd921bc336718cc94003f156d
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/47/233047/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_network_manager.py', 'nailgun/nailgun/test/integration/test_network_configuration.py', 'nailgun/nailgun/errors/__init__.py', 'nailgun/nailgun/network/manager.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_objects.py']",6,f9bca0d519e84ce4fc46fe0b21532629116f3592,bug/1487021," cluster_kwargs={'net_provider': 'neutron'}, self.cluster = self.env.clusters[0] def test_get_controller_group_id(self): def test_get_node_group(self): controller = objects.Cluster.get_nodes_by_role( self.cluster, 'controller')[0] compute = objects.Cluster.get_nodes_by_role( self.cluster, 'compute')[0] group_id = self.env.create_node_group().json_body['id'] compute.group_id = group_id self.db.flush() self.assertEqual( group_id, objects.Cluster.get_node_group(self.cluster, ['compute']).id) self.assertEqual( controller.group_id, objects.Cluster.get_node_group(self.cluster, ['controller']).id) def test_get_node_group_multiple_return_same_group(self): group_id = self.env.create_node_group().json_body['id'] compute = objects.Cluster.get_nodes_by_role(self.cluster, 'compute')[0] cinder = objects.Cluster.get_nodes_by_role(self.cluster, 'cinder')[0] compute.group_id = group_id cinder.group_id = group_id self.db.flush() self.assertEqual( group_id, objects.Cluster.get_node_group( self.cluster, ['compute', 'cinder']).id) def test_get_node_group_multiple_fail(self): group_id = self.env.create_node_group().json_body['id'] controller = \ objects.Cluster.get_nodes_by_role(self.cluster, 'controller')[0] cinder = objects.Cluster.get_nodes_by_role(self.cluster, 'cinder')[0] controller.group_id = group_id cinder.group_id = group_id self.db.flush() # since we have two controllers, and one of them is in another # node group, the error will be raised self.assertRaisesRegexp( errors.CanNotFindCommonNodeGroup, '^Node roles \[controller, cinder\] has more than one common ' 'node group$', objects.Cluster.get_node_group, self.cluster, ['controller', 'cinder']) ", def test_get_group_id(self):,234,71
openstack%2Ffuel-qa~master~I2c4bfb81b60f1a581f50d93e5d279289f1887c66,openstack/fuel-qa,master,I2c4bfb81b60f1a581f50d93e5d279289f1887c66,[DO NOT MERGE] code for custom bvt for 'deployment from upstream repos' feature,ABANDONED,2016-01-19 18:14:21.000000000,2016-02-18 17:25:28.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-01-19 18:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/42fde78d607344032969c0c09f6da64be38067bd', 'message': ""[DO NOT MERGE] code for custom bvt for 'deployment from upstream repos' feature\n\nThis code was requested by @mattymo and need for custom iso verification.\nThe custom test should be executed with repos added\nto MIRROR_UBUNTU or EXTRA_DEB_REPOS.\n\nChange-Id: I2c4bfb81b60f1a581f50d93e5d279289f1887c66\n""}, {'number': 2, 'created': '2016-01-19 18:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/b2226537b5012fad9aacf914495d4fb77699b8d8', 'message': ""[DO NOT MERGE] code for custom bvt for 'deployment from upstream repos' feature\n\nThis code was requested by @mattymo and need for custom iso verification.\nThe custom test should be executed with repos added\nto MIRROR_UBUNTU or EXTRA_DEB_REPOS.\n\nChange-Id: I2c4bfb81b60f1a581f50d93e5d279289f1887c66\n""}, {'number': 3, 'created': '2016-01-19 18:50:24.000000000', 'files': ['fuelweb_test/tests/test_upstream_deployment.py', 'fuelweb_test/run_tests.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/eb1b238eeff7e064045e15eecdc1eac44e95a671', 'message': ""[DO NOT MERGE] code for custom bvt for 'deployment from upstream repos' feature\n\nThis code was requested by @mattymo and need for custom iso verification.\nThe custom test should be executed with repos added\nto MIRROR_UBUNTU or EXTRA_DEB_REPOS.\n\nChange-Id: I2c4bfb81b60f1a581f50d93e5d279289f1887c66\n""}]",0,269795,eb1b238eeff7e064045e15eecdc1eac44e95a671,17,3,3,15984,,,0,"[DO NOT MERGE] code for custom bvt for 'deployment from upstream repos' feature

This code was requested by @mattymo and need for custom iso verification.
The custom test should be executed with repos added
to MIRROR_UBUNTU or EXTRA_DEB_REPOS.

Change-Id: I2c4bfb81b60f1a581f50d93e5d279289f1887c66
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/95/269795/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_upstream_deployment.py', 'fuelweb_test/run_tests.py']",2,42fde78d607344032969c0c09f6da64be38067bd,, from tests import test_upstream_deployment # noqa,,80,1
openstack%2Ftrove~master~I39534e15a9bd1b9e5faf4807f6ae8dc1fdca6aa0,openstack/trove,master,I39534e15a9bd1b9e5faf4807f6ae8dc1fdca6aa0,Disable unsupported root-disable tests,MERGED,2016-02-12 20:33:55.000000000,2016-02-18 17:22:29.000000000,2016-02-18 17:22:29.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 9782}, {'_account_id': 10295}]","[{'number': 1, 'created': '2016-02-12 20:33:55.000000000', 'files': ['trove/tests/scenario/runners/root_actions_runners.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/95dc2f59370d2d6ac48e4c906729831873afc94f', 'message': 'Disable unsupported root-disable tests\n\nDisable root-disable tests on datastores that do not support this\nfunctionality.\n\nChange-Id: I39534e15a9bd1b9e5faf4807f6ae8dc1fdca6aa0\n'}]",0,279779,95dc2f59370d2d6ac48e4c906729831873afc94f,10,4,1,14576,,,0,"Disable unsupported root-disable tests

Disable root-disable tests on datastores that do not support this
functionality.

Change-Id: I39534e15a9bd1b9e5faf4807f6ae8dc1fdca6aa0
",git fetch https://review.opendev.org/openstack/trove refs/changes/79/279779/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/scenario/runners/root_actions_runners.py'],1,95dc2f59370d2d6ac48e4c906729831873afc94f,,"class PerconaRootActionsRunner(RootActionsRunner): def run_disable_root_before_enabled(self): raise SkipTest(""Operation is currently not supported."") def run_enable_root_with_password(self): raise SkipTest(""Operation is currently not supported."") def run_disable_root(self): raise SkipTest(""Operation is currently not supported."") class MariadbRootActionsRunner(RootActionsRunner): def run_disable_root_before_enabled(self): raise SkipTest(""Operation is currently not supported."") def run_enable_root_with_password(self): raise SkipTest(""Operation is currently not supported."") def run_disable_root(self): raise SkipTest(""Operation is currently not supported."") class PostgresqlRootActionsRunner(RootActionsRunner): def run_disable_root_before_enabled(self): raise SkipTest(""Operation is currently not supported."") def run_enable_root_with_password(self): raise SkipTest(""Operation is currently not supported."") def run_disable_root(self): raise SkipTest(""Operation is currently not supported."") ",,36,0
openstack%2Ffuel-octane~master~I3809d2a4439d5d0866a7e29ee70a68e54c123c4f,openstack/fuel-octane,master,I3809d2a4439d5d0866a7e29ee70a68e54c123c4f,Run puppet agent in the end of restore,MERGED,2016-02-16 11:29:24.000000000,2016-02-18 17:21:15.000000000,2016-02-18 13:36:17.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 6677}, {'_account_id': 12559}, {'_account_id': 15984}, {'_account_id': 19157}]","[{'number': 1, 'created': '2016-02-16 11:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/da4dc08dfcc298e415a302b231ef77c53bbcf023', 'message': ""Run puppet agent in the end of restore\n\nMove puppet agnet call to the end of restore procedure in version\narchivator's post_restore_action method.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n""}, {'number': 2, 'created': '2016-02-17 10:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/3998ab3f5af928dc8c16a4701b6fea5fd6c07881', 'message': ""Run puppet agent in the end of restore\n\nMove puppet agnet call to the end of restore procedure in version\narchivator's post_restore_action method.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n""}, {'number': 3, 'created': '2016-02-17 12:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/92723fe55765ec7d446ae0f5c1ca1d17b46e209e', 'message': ""Run puppet agent in the end of restore\n\nMove puppet agnet call to the end of restore procedure in version\narchivator's post_restore_action method.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n""}, {'number': 4, 'created': '2016-02-18 12:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/5c4d1beb557851888c8974e80cf21659624d2c6d', 'message': ""Run puppet agent in the end of restore\n\nMove puppet agnet call to the end of restore procedure in version\narchivator's post_restore_action method.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n""}, {'number': 5, 'created': '2016-02-18 12:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/91987c6eb80b91abdfa7e1b9b2bd0d8fdfecb7ed', 'message': ""Run puppet agent in the end of restore\n\nMove puppet agnet call to the end of restore procedure in version\narchivator's post_restore_action method.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n""}, {'number': 6, 'created': '2016-02-18 13:09:27.000000000', 'files': ['octane/handlers/backup_restore/puppet.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/30b775d528805726104ceb5913ca66e03fb3d790', 'message': 'Run puppet agent in the end of restore\n\nAdd class for puppet agent run in octane.handlers.backup_restore.puppet\nmodule. Add this class to archivators pipeline in the end of the\nprocedure. Call puppet agent for restore method only.\n\nChange-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f\nRelated-bug: 1544967\n'}]",2,280617,30b775d528805726104ceb5913ca66e03fb3d790,25,7,6,6677,,,0,"Run puppet agent in the end of restore

Add class for puppet agent run in octane.handlers.backup_restore.puppet
module. Add this class to archivators pipeline in the end of the
procedure. Call puppet agent for restore method only.

Change-Id: I3809d2a4439d5d0866a7e29ee70a68e54c123c4f
Related-bug: 1544967
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/17/280617/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/version.py']",3,da4dc08dfcc298e415a302b231ef77c53bbcf023,bug/1544967,"from octane.util import puppet def post_restore_action(self, *args, **kwargs): puppet.apply_host()",,4,5
openstack%2Ffreezer-api~master~I9c71669c5436e43b3af9a236c2347e567e1e152b,openstack/freezer-api,master,I9c71669c5436e43b3af9a236c2347e567e1e152b,Switch freezer-api to oslo.log,ABANDONED,2015-10-28 10:58:36.000000000,2016-02-18 17:20:09.000000000,,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 13940}, {'_account_id': 14159}, {'_account_id': 14509}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-10-28 10:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/954d010102597bdfd6bfd57a5cacad22baebf782', 'message': 'Switch freezer-api to oslo.log\n\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n\nChange-Id: I9c71669c5436e43b3af9a236c2347e567e1e152b\nImplements: blueprint using-oslo-libs\n'}, {'number': 2, 'created': '2015-10-28 18:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/75a41f7768ce0fabee332a89b0eff40a8f9d0b4f', 'message': 'Switch freezer-api to oslo.log\n\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n\nChange-Id: I9c71669c5436e43b3af9a236c2347e567e1e152b\nImplements: blueprint using-oslo-libs\n'}, {'number': 3, 'created': '2015-10-30 17:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/1a2aa558e48d6d5db1c4c20f9e6f0fc92a8c03ea', 'message': 'Switch freezer-api to oslo.log\n\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n\nChange-Id: I9c71669c5436e43b3af9a236c2347e567e1e152b\nImplements: blueprint using-oslo-libs\n'}, {'number': 4, 'created': '2015-10-31 12:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/10bc3075915f3f47a2b209281bc7178b715b9368', 'message': 'Switch freezer-api to oslo.log\n\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n\nChange-Id: I9c71669c5436e43b3af9a236c2347e567e1e152b\nImplements: blueprint using-oslo-libs\n'}, {'number': 5, 'created': '2015-11-03 00:17:32.000000000', 'files': ['freezer_api/common/config.py', 'requirements.txt', 'freezer_api/cmd/api.py', 'freezer_api/common/log.py', 'etc/freezer-api.conf', 'tests/test_db_init.py', 'freezer_api/storage/elastic.py', 'freezer_api/cmd/db_init.py', 'tests/test_api.py'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/fb0c8b19355a1601eb2704cf11d94eb70fb7e430', 'message': 'Switch freezer-api to oslo.log\n\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n\nChange-Id: I9c71669c5436e43b3af9a236c2347e567e1e152b\nImplements: blueprint using-oslo-libs\n'}]",0,239905,fb0c8b19355a1601eb2704cf11d94eb70fb7e430,20,6,5,13940,,,0,"Switch freezer-api to oslo.log

switch from native python logging module to oslo.log
This commit includes:
- using oslo.config for parsing cli and config files options
- using oslo.log instead of native python logging module

Change-Id: I9c71669c5436e43b3af9a236c2347e567e1e152b
Implements: blueprint using-oslo-libs
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/05/239905/5 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_api/common/config.py', 'requirements.txt', 'freezer_api/cmd/api.py', 'freezer_api/common/log.py', 'etc/freezer-api.conf', 'freezer_api/storage/elastic.py', 'freezer_api/cmd/db_init.py']",7,954d010102597bdfd6bfd57a5cacad22baebf782,bp/using-oslo-libs,"from oslo_log import log as loggingfrom freezer_api.common import config from oslo_config import cfg from urlparse import urlparseCONF = cfg.CONF _LOG = logging.getLogger(__name__) def __init__(self, es_url, es_index): _LOG.info(message) if CONF.get('verbose', False): _LOG.info('{0}/{1} MATCHES'.format(self.es_index, es_type)) if CONF.get('test_only'): _LOG.info('{0}/{1} DOES NOT MATCH'.format(self.es_index, es_type)) if not self.proceed(prompt_message, CONF.get('yes')): _LOG.info(""Mappings updated"") if CONF.get('yes') and not CONF.get('erase'): _LOG.warning('{0}/{1} DOES NOT MATCH. Need explicit consent to ' 'erase types'.format(self.es_index, es_type)) if not self.proceed(prompt_message, CONF.get('erase')): _LOG.info(""Type {0} mapping created"".format(url))def get_db_params(): url = urlparse(CONF.get('host', 'localhost')) port = CONF.get('port', 9200) if url.hostname: host = url.hostname else: host = url.path.split(':')[0] port = url.port or port scheme = url.scheme or 'http' elasticsearch_url = '{0}://{1}:{2}'.format(scheme, host, port) elasticsearch_index = CONF.get('index', 'freezer') config.setup_log() config.add_db_init_opts(mapping_choices=mappings.keys()) config.parse_args(sys.argv) logging.setup(CONF, ""freezer-api"") elasticsearch_url, elasticsearch_index = get_db_params() es_index=elasticsearch_index) if CONF.get('verbose'): _LOG.info('db url: {0}'.format(elasticsearch_url)) _LOG.info('db index: {0}'.format(elasticsearch_index)) if CONF.get('select_mapping'): mappings = {CONF.get('select_mapping'): mappings[ CONF.get('select_mapping')]} _LOG.error(e)","import argparse import ConfigParserimport re def __init__(self, es_url, es_index, args): self.args = args if self.args.verbose >= level: print '{0}/{1} MATCHES'.format(self.es_index, es_type) if self.args.test_only: if not self.proceed(prompt_message, self.args.yes): if self.args.yes and not self.args.erase: if not self.proceed(prompt_message, self.args.erase):def get_args(mapping_choices): arg_parser = argparse.ArgumentParser() arg_parser.add_argument( 'host', action='store', default='', nargs='?', help='The DB host address[:port], default ""localhost""') arg_parser.add_argument( '-p', '--port', action='store', type=int, help=('The DB server port ' '(default: {0})'.format(DEFAULT_ES_SERVER_PORT)), dest='port', default=0) arg_parser.add_argument( '-m', '--mapping', action='store', help=('Specific mapping to upload. Valid choices: {0}' .format(','.join(mapping_choices))), choices=mapping_choices, dest='select_mapping', default='') arg_parser.add_argument( '-i', '--index', action='store', help='The DB index (default ""{0}"")'.format(DEFAULT_INDEX), dest='index') arg_parser.add_argument( '-y', '--yes', action='store_true', help=""Automatic confirmation to mapping update"", dest='yes', default=False) arg_parser.add_argument( '-e', '--erase', action='store_true', help=(""Enable index deletion in case mapping update "" ""fails due to incompatible changes""), dest='erase', default=False) arg_parser.add_argument( '-v', '--verbose', action='count', help=""Verbose"", dest='verbose', default=False) arg_parser.add_argument( '-t', '--test-only', action='store_true', help=""Test the validity of the mappings, but take no action"", dest='test_only', default=False) arg_parser.add_argument( '-c', '--config-file', action='store', help='Config file with the db information', dest='config_file', default='') return arg_parser.parse_args() def find_config_file(): cwd_config = os.path.join(os.getcwd(), 'freezer-api.conf') for config_file_path in [cwd_config, DEFAULT_CONF_PATH]: if os.path.isfile(config_file_path): return config_file_path def parse_config_file(fname): """""" Read host URL from config-file :param fname: config-file path :return: (host, port, db_index) """""" if not fname: return None, 0, None host, port, index = None, 0, None config = ConfigParser.ConfigParser() config.read(fname) try: endpoint = config.get('storage', 'endpoint') match = re.search(r'^http://([^:]+):([\d]+)$', endpoint) if match: host = match.group(1) port = int(match.group(2)) except: pass try: index = config.get('storage', 'index') except: pass return host, int(port), index def get_db_params(args): :param args: argparsed command line arguments conf_fname = args.config_file or find_config_file() if args.verbose: print ""using config file: {0}"".format(conf_fname) conf_host, conf_port, conf_db_index = parse_config_file(conf_fname) # host lookup # 1) host arg (before ':') # 2) config file provided # 3) string 'localhost' host = args.host or conf_host or 'localhost' host = host.split(':')[0] # port lookup # 1) port arg # 2) host arg (after ':') # 3) config file provided # 4) DEFAULT_ES_SERVER_PORT match_port = None match = re.search(r':(\d+)$', args.host) if match: match_port = match.groups()[0] port = args.port or match_port or conf_port or DEFAULT_ES_SERVER_PORT elasticsearch_url = 'http://{0}:{1}'.format(host, port) # index lookup # 1) index args # 2) config file # 3) string DEFAULT_INDEX elasticsearch_index = args.index or conf_db_index or DEFAULT_INDEX args = get_args(mapping_choices=mappings.keys()) elasticsearch_url, elasticsearch_index = get_db_params(args) es_index=elasticsearch_index, args=args) if args.verbose: print "" db url: {0}"".format(elasticsearch_url) print ""db index: {0}"".format(elasticsearch_index) if args.select_mapping: mappings = {args.select_mapping: mappings[args.select_mapping]}",290,274
openstack%2Ffuel-octane~stable%2F8.0~Id641813c0d68d00a4430faae83fe235750bb93f9,openstack/fuel-octane,stable/8.0,Id641813c0d68d00a4430faae83fe235750bb93f9,Remove unused password param from restore command,MERGED,2016-02-18 13:50:42.000000000,2016-02-18 17:17:24.000000000,2016-02-18 17:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}]","[{'number': 1, 'created': '2016-02-18 13:50:42.000000000', 'files': ['octane/tests/test_restore.py', 'octane/magic_consts.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/handlers/backup_restore/base.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/cobbler.py', 'octane/commands/restore.py', 'octane/handlers/backup_restore/__init__.py', 'octane/handlers/backup_restore/nailgun_plugins.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/20dff993b589c4bb468bf9b807df23ef63fe03f9', 'message': 'Remove unused password param from restore command\n\nChange-Id: Id641813c0d68d00a4430faae83fe235750bb93f9\n(cherry picked from commit d3ea58730c21a83decf5bb8c2715ae0c388bb673)\n'}]",0,281869,20dff993b589c4bb468bf9b807df23ef63fe03f9,11,3,1,6677,,,0,"Remove unused password param from restore command

Change-Id: Id641813c0d68d00a4430faae83fe235750bb93f9
(cherry picked from commit d3ea58730c21a83decf5bb8c2715ae0c388bb673)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/69/281869/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_restore.py', 'octane/magic_consts.py', 'octane/tests/test_archivators_restore.py', 'octane/handlers/backup_restore/postgres.py', 'octane/handlers/backup_restore/astute.py', 'octane/handlers/backup_restore/base.py', 'octane/handlers/backup_restore/cobbler.py', 'octane/commands/restore.py', 'octane/handlers/backup_restore/__init__.py', 'octane/handlers/backup_restore/nailgun_plugins.py']",10,20dff993b589c4bb468bf9b807df23ef63fe03f9,281245," def restore(self): super(NailgunPluginsArchivator, self).restore()"," def post_restore_action(self, *args, **kwargs):",83,81
openstack%2Fkolla~master~I653b6b994de2f4d374d90a831d7a56eaff667404,openstack/kolla,master,I653b6b994de2f4d374d90a831d7a56eaff667404,Ceilometer ubuntu binary container,MERGED,2016-02-08 05:37:32.000000000,2016-02-18 17:10:21.000000000,2016-02-18 17:10:21.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 7488}, {'_account_id': 14119}, {'_account_id': 18009}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-08 05:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a8c82c6c815a89f7cf1810e590fd8660bcfe5d3c', 'message': 'Ceilometer ubuntu binary container\n\nChange-Id: I653b6b994de2f4d374d90a831d7a56eaff667404\nPartially-Implements: blueprint binary-ubuntu\n'}, {'number': 2, 'created': '2016-02-08 05:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d8b8efa2063caa11950d51e5c2356b187efbd22b', 'message': 'Ceilometer ubuntu binary container\n\nChange-Id: I653b6b994de2f4d374d90a831d7a56eaff667404\nPartially-Implements: blueprint binary-ubuntu\n'}, {'number': 3, 'created': '2016-02-10 05:33:01.000000000', 'files': ['docker/ceilometer/ceilometer-central/Dockerfile.j2', 'docker/ceilometer/ceilometer-collector/Dockerfile.j2', 'docker/ceilometer/ceilometer-notification/Dockerfile.j2', 'docker/ceilometer/ceilometer-api/Dockerfile.j2', 'docker/ceilometer/ceilometer-base/Dockerfile.j2', 'docker/ceilometer/ceilometer-compute/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7a6edb57976eebdaa8dc9a4affe39f1ca25173fd', 'message': 'Ceilometer ubuntu binary container\n\nChange-Id: I653b6b994de2f4d374d90a831d7a56eaff667404\nPartially-Implements: blueprint binary-ubuntu\n'}]",3,277286,7a6edb57976eebdaa8dc9a4affe39f1ca25173fd,17,6,3,18009,,,0,"Ceilometer ubuntu binary container

Change-Id: I653b6b994de2f4d374d90a831d7a56eaff667404
Partially-Implements: blueprint binary-ubuntu
",git fetch https://review.opendev.org/openstack/kolla refs/changes/86/277286/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/ceilometer/ceilometer-central/Dockerfile.j2', 'docker/ceilometer/ceilometer-collector/Dockerfile.j2', 'docker/ceilometer/ceilometer-notification/Dockerfile.j2', 'docker/ceilometer/ceilometer-api/Dockerfile.j2', 'docker/ceilometer/ceilometer-base/Dockerfile.j2', 'docker/ceilometer/ceilometer-compute/Dockerfile.j2']",6,a8c82c6c815a89f7cf1810e590fd8660bcfe5d3c,bp/binary-ubuntu, {% elif base_distro in ['ubuntu'] %} RUN apt-get install -y --no-install-recommends \ ceilometer-agent-compute \ python-ceilometerclient \ python-pecan \ && apt-get clean ,,38,0
openstack%2Fpython-tackerclient~stable%2Fliberty~I816f4a7a0459c4850696e09911eef3493e956647,openstack/python-tackerclient,stable/liberty,I816f4a7a0459c4850696e09911eef3493e956647,update requirements according to global requ,MERGED,2016-02-16 18:10:19.000000000,2016-02-18 17:08:39.000000000,2016-02-18 17:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 15755}]","[{'number': 1, 'created': '2016-02-16 18:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/742d2ba9f5c326ccce55a25da3948cb18ee707c2', 'message': 'update requirements according to global requ\n\nThis patch updates the requirements in stable/liberty branch\nof tacker according to global requirements in stable/liberty\n\nChange-Id: I816f4a7a0459c4850696e09911eef3493e956647\nPartial-Bug: #1543396\n'}, {'number': 2, 'created': '2016-02-17 11:56:49.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/fd38742d52e746e7f0dfef1be172fe64f1930ccf', 'message': 'update requirements according to global requ\n\nThis patch updates the requirements in stable/liberty branch\nof tacker according to global requirements in stable/liberty\n\nChange-Id: I816f4a7a0459c4850696e09911eef3493e956647\nPartial-Bug: #1543396\nDepends-On: I8052d9d683a1a2e80d8c160c70d2ea8f8b7240cd\n'}]",3,280856,fd38742d52e746e7f0dfef1be172fe64f1930ccf,11,5,2,15755,,,0,"update requirements according to global requ

This patch updates the requirements in stable/liberty branch
of tacker according to global requirements in stable/liberty

Change-Id: I816f4a7a0459c4850696e09911eef3493e956647
Partial-Bug: #1543396
Depends-On: I8052d9d683a1a2e80d8c160c70d2ea8f8b7240cd
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/56/280856/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py', 'tox.ini']",4,742d2ba9f5c326ccce55a25da3948cb18ee707c2,bug/1543396,"# H105 Don't use author tags # H405 multi line docstring summary not separated with an empty line # E265 block comment should start with '# ' # H238 old style class declaration, use new style (inherit from `object`) # E129 visually indented line with same indent as next logical line # E113 unexpected indentation ignore = E125,H302,H105,H405,E265,H238,E129,E113","ignore = E125,H302",28,15
openstack%2Fsahara~master~Ie39d96c8b491e6322a41b752c0a0faf3fcace346,openstack/sahara,master,Ie39d96c8b491e6322a41b752c0a0faf3fcace346,Add MapR-FS support to sahara scenario framework,ABANDONED,2015-11-04 17:29:20.000000000,2016-02-18 17:06:27.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 9740}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 18793}]","[{'number': 1, 'created': '2015-11-04 17:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0eba0209fbf1ec38346ca19b06c9dccfaa657d03', 'message': 'Add support for using MapR-FS as input/output Data Source\nto sahara scenario framework.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 2, 'created': '2015-11-04 17:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6fdd92335356265491a0b129af9697a2a9799291', 'message': 'Add support for using MapR-FS as input/output Data Source to sahara scenario framework.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 3, 'created': '2015-11-05 17:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1a9f6503512bcfdaed0966775217acd9110db235', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 4, 'created': '2015-11-05 17:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8c462df68883b28bc165a22d278cba87f90532e2', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 5, 'created': '2015-11-06 15:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0af4481e441b31cf16c8432aa7f37ca2f59cfd6c', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 6, 'created': '2015-11-06 19:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/56699a9cd80fd0bafab05afab7c11e20237e5915', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 7, 'created': '2015-11-07 14:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0be9025580d6d57b344db4de21e6689e892f27ee', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 8, 'created': '2015-11-09 08:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/711bba5276a91f58913e5610b177a15a9bf1d856', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 9, 'created': '2015-11-09 19:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/370271e191c2bb20300825b45d01b023d947cf28', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 10, 'created': '2015-11-27 14:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/aeab6a3e08697acda294411dab5e844e8773a889', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 11, 'created': '2015-11-27 15:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/00cf7fa423f8f393aaf870545928103deb4d6d6b', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\nPig job is removed from mapr job flow since there\nare problems of running it with oozie.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 12, 'created': '2015-11-27 15:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/92ad4e19733307333e854c2f58816700dbf400c5', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\nPig job is removed from mapr job flow since there\nare problems of running it with oozie.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 13, 'created': '2015-11-30 18:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/357b6de152a42797052c1809752d3554120f7b52', 'message': 'Add MapR-FS support to sahara scenario framework\n\nNow we can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\nPig job is removed from mapr job flow since there\nare problems of running it with oozie.\n\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\n'}, {'number': 14, 'created': '2015-12-04 19:13:04.000000000', 'files': ['sahara/tests/scenario/custom_checks/mapr_custom_check.py', 'sahara/tests/scenario/base.py', 'etc/scenario/sahara-ci/edp.yaml.mako', 'sahara/tests/scenario/custom_checks/check_resource_manager.py', 'etc/scenario/sahara-ci/mapr-5.0.0.mrv2.yaml.mako', 'sahara/tests/scenario_unit/test_base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/41e7c86914b642b1c9e131ebe4029dbc27a4c284', 'message': 'Add MapR-FS support to sahara scenario framework\n\n1. We can use MapR-FS as input/output Data Source for edp\nsahara jobs in sahara scenario tests.\n2. Pig job is removed from mapr job flow since there\nare problems of running it with oozie.\n3. Add resource_manager scenario for checking RM before\nrunning jobs.\nChange-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346\nImplements: blueprint sahara-scenario-maprfs-support\nCloses-Bug: #1522840\n'}]",10,241696,41e7c86914b642b1c9e131ebe4029dbc27a4c284,63,7,14,18793,,,0,"Add MapR-FS support to sahara scenario framework

1. We can use MapR-FS as input/output Data Source for edp
sahara jobs in sahara scenario tests.
2. Pig job is removed from mapr job flow since there
are problems of running it with oozie.
3. Add resource_manager scenario for checking RM before
running jobs.
Change-Id: Ie39d96c8b491e6322a41b752c0a0faf3fcace346
Implements: blueprint sahara-scenario-maprfs-support
Closes-Bug: #1522840
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/241696/14 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/scenario/base.py'],1,0eba0209fbf1ec38346ca19b06c9dccfaa657d03,bp/sahara-scenario-maprfs-support," url = self._create_dfs_data(location, ds.get('hdfs_username', 'oozie'), 'hdfs') if ds['type'] == 'maprfs': url = self._create_dfs_data(location, ds.get('maprfs_username', 'mapr'), 'maprfs') def _create_dfs_data(self, source, hdfs_username, fs): command_prefixes = {'hdfs': 'hdfs dfs', 'maprfs': 'hadoop fs'} if fs in command_prefixes.keys(): def to_hex_present(string): return """".join(map(lambda x: hex(ord(x)).replace(""0x"", ""\\x""), # True in case of destination location if 'user' in source: return source hdfs_dir = utils.rand_name(""/user/%s/data"" % hdfs_username) inst_ip = self._get_nodes_with_process()[0][""management_ip""] self._run_command_on_node( inst_ip, ""sudo su - -c \""%(prefix)s -mkdir -p %(path)s \"" %(user)s"" % { ""prefix"": command_prefixes[fs], ""path"": hdfs_dir, ""user"": hdfs_username}) hdfs_filepath = utils.rand_name(hdfs_dir + ""/file"") data = open(source).read() self._run_command_on_node( inst_ip, (""echo -e \""%(data)s\"" | sudo su - -c \""%(prefix)s"" "" -put - %(path)s\"" %(user)s"") % { ""data"": to_hex_present(data), ""prefix"": command_prefixes[fs], ""path"": hdfs_filepath, ""user"": hdfs_username}) return hdfs_filepath return None"," url = self._create_hdfs_data(location, ds.get('hdfs_username', 'oozie')) if ds['type'] == 'maprfs': url = location def _create_hdfs_data(self, source, hdfs_username): def to_hex_present(string): return """".join(map(lambda x: hex(ord(x)).replace(""0x"", ""\\x""), if 'user' in source: return source hdfs_dir = utils.rand_name(""/user/%s/data"" % hdfs_username) inst_ip = self._get_nodes_with_process()[0][""management_ip""] self._run_command_on_node( inst_ip, ""sudo su - -c \""hdfs dfs -mkdir -p %(path)s \"" %(user)s"" % { ""path"": hdfs_dir, ""user"": hdfs_username}) hdfs_filepath = utils.rand_name(hdfs_dir + ""/file"") data = open(source).read() self._run_command_on_node( inst_ip, (""echo -e \""%(data)s\"" | sudo su - -c \""hdfs dfs"" "" -put - %(path)s\"" %(user)s"") % { ""data"": to_hex_present(data), ""path"": hdfs_filepath, ""user"": hdfs_username}) return hdfs_filepath",37,25
openstack%2Fdragonflow~master~Ifa6956966ffd3e3532d3ceaafb824b56fa7fbaec,openstack/dragonflow,master,Ifa6956966ffd3e3532d3ceaafb824b56fa7fbaec,Remove patch file which was used in centralized DF,MERGED,2016-02-18 13:09:44.000000000,2016-02-18 17:00:49.000000000,2016-02-18 17:00:49.000000000,"[{'_account_id': 3}, {'_account_id': 11343}, {'_account_id': 13070}]","[{'number': 1, 'created': '2016-02-18 13:09:44.000000000', 'files': ['doc/source/l3_controller.patch'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b02581cd1547b70d8b5629c67662390d0d3d8800', 'message': 'Remove patch file which was used in centralized DF\n\nChange-Id: Ifa6956966ffd3e3532d3ceaafb824b56fa7fbaec\n'}]",0,281830,b02581cd1547b70d8b5629c67662390d0d3d8800,7,3,1,11343,,,0,"Remove patch file which was used in centralized DF

Change-Id: Ifa6956966ffd3e3532d3ceaafb824b56fa7fbaec
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/30/281830/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/l3_controller.patch'],1,b02581cd1547b70d8b5629c67662390d0d3d8800,,,"From cc38589f3632ef6054524c13de9d2bd793c094aa Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Sun, 11 Jan 2015 09:49:21 +0200 Subject: [PATCH 1/8] merge Change-Id: Ibb3d4bab9f094de0081cc3fb8a49f75a01ef5cdf --- neutron/agent/linux/ovs_lib.py | 22 +- neutron/agent/rpc.py | 11 +- neutron/api/rpc/handlers/l3_rpc.py | 18 +- .../plugins/openvswitch/agent/ovs_neutron_agent.py | 130 +- neutron/plugins/openvswitch/common/config.py | 3 + neutron/plugins/openvswitch/common/constants.py | 5 +- .../services/l3_router/README.l3_cont_dvr_plugin | 63 + neutron/services/l3_router/l3_cont_dvr_plugin.py | 360 ++++++ neutron/services/l3_router/l3_reactive_app.py | 1274 ++++++++++++++++++++ neutron/tests/unit/openvswitch/test_ovs_tunnel.py | 2 + 10 files changed, 1869 insertions(+), 19 deletions(-) create mode 100644 neutron/services/l3_router/README.l3_cont_dvr_plugin create mode 100755 neutron/services/l3_router/l3_cont_dvr_plugin.py create mode 100755 neutron/services/l3_router/l3_reactive_app.py diff --git a/neutron/agent/linux/ovs_lib.py b/neutron/agent/linux/ovs_lib.py index 7b2d2a2..f745cf3 100644 --- a/neutron/agent/linux/ovs_lib.py +++ b/neutron/agent/linux/ovs_lib.py @@ -138,6 +138,7 @@ class BaseOVS(object): class OVSBridge(BaseOVS): + def __init__(self, br_name, root_helper): super(OVSBridge, self).__init__(root_helper) self.br_name = br_name @@ -158,6 +159,11 @@ class OVSBridge(BaseOVS): return res.strip().split('\n') return res + def set_controller_mode(self, mode): + self.run_vsctl(['--', 'set', 'controller', self.br_name, + ""connection-mode=%s"" % mode], + check_error=True) + def set_secure_mode(self): self.run_vsctl(['--', 'set-fail-mode', self.br_name, 'secure'], check_error=True) @@ -209,8 +215,11 @@ class OVSBridge(BaseOVS): args = [""clear"", table_name, record, column] self.run_vsctl(args) - def run_ofctl(self, cmd, args, process_input=None): - full_args = [""ovs-ofctl"", cmd, self.br_name] + args + def run_ofctl(self, cmd, args, process_input=None, protocols=None): + if protocols: + full_args = [""ovs-ofctl"", cmd, protocols, self.br_name] + args + else: + full_args = [""ovs-ofctl"", cmd, self.br_name] + args try: return utils.execute(full_args, root_helper=self.root_helper, process_input=process_input) @@ -245,12 +254,13 @@ class OVSBridge(BaseOVS): return self.db_get_val('Bridge', self.br_name, 'datapath_id').strip('""') - def do_action_flows(self, action, kwargs_list): + def do_action_flows(self, action, kwargs_list, protocols=None): flow_strs = [_build_flow_expr_str(kw, action) for kw in kwargs_list] - self.run_ofctl('%s-flows' % action, ['-'], '\n'.join(flow_strs)) + self.run_ofctl('%s-flows' % action, ['-'], '\n'.join(flow_strs), + protocols) - def add_flow(self, **kwargs): - self.do_action_flows('add', [kwargs]) + def add_flow(self, protocols=None, **kwargs): + self.do_action_flows('add', [kwargs], protocols) def mod_flow(self, **kwargs): self.do_action_flows('mod', [kwargs]) diff --git a/neutron/agent/rpc.py b/neutron/agent/rpc.py index 98e641a..deae0e4 100644 --- a/neutron/agent/rpc.py +++ b/neutron/agent/rpc.py @@ -22,7 +22,6 @@ from neutron.common import topics from neutron.i18n import _LW from neutron.openstack.common import log as logging - LOG = logging.getLogger(__name__) @@ -121,3 +120,13 @@ class PluginApi(object): cctxt = self.client.prepare() return cctxt.call(context, 'tunnel_sync', tunnel_ip=tunnel_ip, tunnel_type=tunnel_type) + + def update_agent_port_mapping_done(self, context, agent_id, + ip_address, host=None): + LOG.debug((""Notify controller on new/updated endpoint %s""), host) + topic = topics.L3PLUGIN + cctxt = self.client.prepare(topic=topic, fanout=True) + cctxt.cast(context, 'update_agent_port_mapping_done', + agent_id=agent_id, + ip_address=ip_address, + host=host) diff --git a/neutron/api/rpc/handlers/l3_rpc.py b/neutron/api/rpc/handlers/l3_rpc.py index aebb670..9e08eed 100644 --- a/neutron/api/rpc/handlers/l3_rpc.py +++ b/neutron/api/rpc/handlers/l3_rpc.py @@ -28,11 +28,11 @@ from neutron import manager from neutron.openstack.common import log as logging from neutron.plugins.common import constants as plugin_constants - LOG = logging.getLogger(__name__) class L3RpcCallback(object): + """"""L3 agent RPC callback in plugin implementations."""""" # 1.0 L3PluginApi BASE_RPC_API_VERSION @@ -80,7 +80,7 @@ class L3RpcCallback(object): else: routers = self.l3plugin.get_sync_data(context, router_ids) if utils.is_extension_supported( - self.plugin, constants.PORT_BINDING_EXT_ALIAS): + self.plugin, constants.PORT_BINDING_EXT_ALIAS): self._ensure_host_set_on_ports(context, host, routers) LOG.debug(""Routers returned to l3 agent:\n %s"", jsonutils.dumps(routers, indent=5)) @@ -206,7 +206,7 @@ class L3RpcCallback(object): self._ensure_host_set_on_port(admin_ctx, host, agent_port) LOG.debug('Agent Gateway port returned : %(agent_port)s with ' 'host %(host)s', {'agent_port': agent_port, - 'host': host}) + 'host': host}) return agent_port def get_snat_router_interface_ports(self, context, **kwargs): @@ -228,7 +228,7 @@ class L3RpcCallback(object): self._ensure_host_set_on_port(admin_ctx, host, p) LOG.debug('SNAT interface ports returned : %(snat_port_list)s ' 'and on host %(host)s', {'snat_port_list': snat_port_list, - 'host': host}) + 'host': host}) return snat_port_list def update_router_state(self, context, **kwargs): @@ -238,3 +238,13 @@ class L3RpcCallback(object): return self.l3plugin.update_router_state(context, router_id, state, host=host) + + def update_agent_port_mapping_done(self, context, **kwargs): + agent_id = kwargs.get('agent_id') + ip_address = kwargs.get('ip_address') + host = kwargs.get('host') + try: + return self.l3plugin.update_agent_port_mapping_done( + context, agent_id, ip_address, host) + except AttributeError: + LOG.debug(""No Handle for:update_agent_port_mapping_done L3 Serv"") diff --git a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py index 4fd77e3..dce7feb 100644 --- a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py +++ b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py @@ -14,12 +14,12 @@ # License for the specific language governing permissions and limitations # under the License. +import eventlet import hashlib import signal import sys +import threading import time - -import eventlet eventlet.monkey_patch() import netaddr @@ -47,8 +47,6 @@ from neutron.openstack.common import log as logging from neutron.openstack.common import loopingcall from neutron.plugins.common import constants as p_const from neutron.plugins.openvswitch.common import constants - - LOG = logging.getLogger(__name__) cfg.CONF.import_group('AGENT', 'neutron.plugins.openvswitch.common.config') @@ -194,15 +192,25 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, # Keep track of int_br's device count for use by _report_state() self.int_br_device_count = 0 + self.local_vlan_map = {} + # Initialize controller Ip List + self.controllers_ip_list = None + ''' + Sync lock for Race condition set_controller <--> check_ovs_restart + when setting the controller all the flow table are deleted + by the time we set the CANARY_TABLE again. + ''' + self.set_controller_lock = threading.Lock() + self.enable_l3_controller = cfg.CONF.AGENT.enable_l3_controller self.int_br = ovs_lib.OVSBridge(integ_br, self.root_helper) + self.setup_integration_br() # Stores port update notifications for processing in main rpc loop self.updated_ports = set() self.setup_rpc() self.bridge_mappings = bridge_mappings self.setup_physical_bridges(self.bridge_mappings) - self.local_vlan_map = {} self.tun_br_ofports = {p_const.TYPE_GRE: {}, p_const.TYPE_VXLAN: {}} @@ -453,6 +461,103 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, else: LOG.warning(_LW('Action %s not supported'), action) + def get_bridge_by_name(self, br_id): + bridge = None + if self.int_br.br_name == br_id: + bridge = self.int_br + elif self.tun_br.br_name == br_id: + bridge = self.tun_br + else: + for physical_network in self.phys_brs: + if self.phys_brs[physical_network].br_name == br_id: + bridge = self.phys_brs[physical_network] + break + return bridge + + def setup_entry_for_arp_reply_remote(self, context, br_id, action, + table_id, segmentation_id, net_uuid, + mac_address, ip_address): + '''Set the ARP respond entry. + :param br_id: the bridge id. + :param action: add or remove. + :param table_id: Id of the table to insert the ARP responder rule. + :param segmentation_id: the segmentation id of the req network. + :param net_uuid: the uuid of the network associated with this vlan. + :param mac_address: the resolved mac addressby arp. + :param ip address: the ip address to resolve ARP for . + ''' + br = self.get_bridge_by_name(br_id) + if not br: + LOG.errror(""Failure Could not find bridge name <%s>"", br_id) + return + lvm = self.local_vlan_map.get(net_uuid) + if lvm: + local_vid = lvm.vlan + else: + LOG.debug((""Network %s not used on agent.""), net_uuid) + return + mac = netaddr.EUI(mac_address, dialect=netaddr.mac_unix) + ip = netaddr.IPAddress(ip_address) + if action == 'add': + actions = constants.ARP_RESPONDER_ACTIONS % {'mac': mac, 'ip': ip} + actions = ""strip_vlan,%s"" % actions + br.add_flow(table=table_id, + priority=100, + proto='arp', + dl_vlan=local_vid, + nw_dst='%s' % ip, + actions=actions) + elif action == 'remove': + br.delete_flows(table=table_id, + proto='arp', + dl_vlan=local_vid, + nw_dst='%s' % ip) + else: + LOG.warning(_LW('Action %s not supported'), action) + + def set_controller_for_br(self, context, br_id, ip_address_list, + force_reconnect=False, protocols=""OpenFlow13""): + '''Set OpenFlow Controller on the Bridge . + :param br_id: the bridge id . + :param ip_address_list: tcp:ip_address:port;tcp:ip_address2:port + :param force_reconnect: Force re setting the controller,remove i + all flows + ''' + if not self.enable_l3_controller: + LOG.info(_LI(""Controller Base l3 is disabled on Agent"")) + return + bridge = None + if (force_reconnect or not self.controllers_ip_list + or self.controllers_ip_list != ip_address_list): + self.controllers_ip_list = ip_address_list + bridge = self.get_bridge_by_name(br_id) + if not bridge: + LOG.errror(""set_controller_for_br failur! no bridge %s "", + br_id) + return + ip_address_ = ip_address_list.split("";"") + LOG.debug((""Set Controllers on br %s to %s""), br_id, ip_address_) + self.set_controller_lock.acquire() + bridge.del_controller() + bridge.set_controller(ip_address_) + #bridge.set_protocols(protocols) + if bridge.br_name == ""br-int"": + bridge.add_flow(priority=0, actions=""normal"") + bridge.add_flow(table=constants.CANARY_TABLE, priority=0, + actions=""drop"") + self.update_metadata_vlan_map_table(bridge) + bridge.set_controller_mode(""out-of-band"") + self.set_controller_lock.release() + + def update_metadata_vlan_map_table(self, bridge): + for net_id, vlan_mapping in self.local_vlan_map.iteritems(): + seg_id_hex = hex(vlan_mapping.segmentation_id) + bridge.add_flow(table=constants.BR_INT_METADATA_TABLE, + priority=100, + dl_vlan=vlan_mapping.vlan, + actions=""write_metadata:%s"" % + (seg_id_hex), protocols=""-OOpenFlow13"") + def provision_local_vlan(self, net_uuid, network_type, physical_network, segmentation_id): '''Provisions a local VLAN. @@ -648,7 +753,8 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, self.dvr_agent.bind_port_to_dvr(port, network_type, fixed_ips, device_owner, local_vlan_id=lvm.vlan) - + if self.enable_l3_controller: + self.update_metadata_vlan_map_table(self.int_br) # Do not bind a port if it's already bound cur_tag = self.int_br.db_get_val(""Port"", port.port_name, ""tag"") if cur_tag != str(lvm.vlan): @@ -712,7 +818,8 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, # which does nothing if bridge already exists. self.int_br.create() self.int_br.set_secure_mode() - + if not self.enable_l3_controller: + self.int_br.del_controller() self.int_br.delete_port(cfg.CONF.OVS.int_peer_patch_port) self.int_br.remove_all_flows() # switch all traffic using L2 learning @@ -1341,8 +1448,11 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, port_info.get('updated')) def check_ovs_status(self): + # Sync lock for race condition with set_controller + self.set_controller_lock.acquire() # Check for the canary flow canary_flow = self.int_br.dump_flows_for_table(constants.CANARY_TABLE) + self.set_controller_lock.release() if canary_flow == '': LOG.warning(_LW(""OVS is restarted. OVSNeutronAgent will reset "" ""bridges and recover ports."")) @@ -1467,6 +1577,12 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, len(port_info.get('updated', []))) port_stats['regular']['removed'] = ( len(port_info.get('removed', []))) + if self.enable_l3_controller: + rpc = self.plugin_rpc + rpc.update_agent_port_mapping_done(self.context, + self.agent_id, + self.local_ip, + cfg.CONF.host) ports = port_info['current'] # Treat ancillary devices if they exist if self.ancillary_brs: diff --git a/neutron/plugins/openvswitch/common/config.py b/neutron/plugins/openvswitch/common/config.py index a5d1e92..8926981 100644 --- a/neutron/plugins/openvswitch/common/config.py +++ b/neutron/plugins/openvswitch/common/config.py @@ -79,6 +79,9 @@ agent_opts = [ ""outgoing IP packet carrying GRE/VXLAN tunnel."")), cfg.BoolOpt('enable_distributed_routing', default=False, help=_(""Make the l2 agent run in DVR mode."")), + cfg.BoolOpt('enable_l3_controller', default=False, + help=_(""Allow the l3 controller Mode on the"" + ""integration_bridge"")), ] diff --git a/neutron/plugins/openvswitch/common/constants.py b/neutron/plugins/openvswitch/common/constants.py index 98c122d..d709d87 100644 --- a/neutron/plugins/openvswitch/common/constants.py +++ b/neutron/plugins/openvswitch/common/constants.py @@ -52,7 +52,10 @@ FLOOD_TO_TUN = 22 # Tables for integration bridge # Table 0 is used for forwarding. CANARY_TABLE = 23 - +BR_INT_CLASSIFIER_TABLE = 40 +BR_INT_METADATA_TABLE = 50 +BR_INT_ARP_TABLE = 51 +BR_INT_L3_FLOWS = 52 # Map tunnel types to tables number TUN_TABLE = {p_const.TYPE_GRE: GRE_TUN_TO_LV, p_const.TYPE_VXLAN: VXLAN_TUN_TO_LV} diff --git a/neutron/services/l3_router/README.l3_cont_dvr_plugin b/neutron/services/l3_router/README.l3_cont_dvr_plugin new file mode 100644 index 0000000..e02efa6 --- /dev/null +++ b/neutron/services/l3_router/README.l3_cont_dvr_plugin @@ -0,0 +1,63 @@ +####### +In order to enable Neutron Controlle-based DVR, you need to make the + following change in ``neutron.conf``: + + 1. Comment-out loading of the ``L3RouterPlugin`` + + 2. Add the ``neutron.services.l3_router.l3_cont_dvr_plugin.ControllerL3ServicePlugin`` + to the service plugin list: + + **neutron.conf** + + :literal:`[default]` + + :literal:`#service_plugins = neutron.services.l3_router.l3_router_plugin.L3RouterPlugin` + + :literal:`service_plugins=neutron.services.l3_router.l3_cont_dvr_plugin.ControllerL3ServicePlugin` + +2. In addition, make the following change in ``ml2_conf.ini``: + + * Set the ``enable_l3_controller`` to ``True``: + + **ml2_conf.ini** + + :literal:`[agent]` + + :literal:`# enable_l3_controller = True` + + +3. Deploy the **L3 Controller-based DVR Agent** on the Network Node + +4. Deploy the **Public Network Agent** on *each* Compute node + +5. Remove deployment of L3 Agent or DVR Agent + +6. Install Ryu on Network Node +% git clone git://github.com/osrg/ryu.git +The current implementation is embedded into the service plugin. will be moved into a Agent based implementation of the controller. +Until we do that we will have to apply the following patch on ryu +ryu/controller/controller.py and ryu/app/wsgi.py modify register_cli_opts to register_opts +--- a/ryu/app/wsgi.py ++++ b/ryu/app/wsgi.py +@@ -31,7 +31,7 @@ from tinyrpc.transports import ServerTransport, ClientTranspor + from tinyrpc.client import RPCClient + + CONF = cfg.CONF +-CONF.register_cli_opts([ ++CONF.register_opts([ + cfg.StrOpt('wsapi-host', default='', help='webapp listen host'), + cfg.IntOpt('wsapi-port', default=8080, help='webapp listen port') + ]) +diff --git a/ryu/controller/controller.py b/ryu/controller/controller.py +index 23418f5..a5bcda2 100644 +--- a/ryu/controller/controller.py ++++ b/ryu/controller/controller.py +@@ -48,7 +48,7 @@ from ryu.lib.dpid import dpid_to_str + LOG = logging.getLogger('ryu.controller.controller') + + CONF = cfg.CONF +-CONF.register_cli_opts([ ++CONF.register_opts([ + + +% cd ryu; python ./setup.py install diff --git a/neutron/services/l3_router/l3_cont_dvr_plugin.py b/neutron/services/l3_router/l3_cont_dvr_plugin.py new file mode 100755 index 0000000..e449e6f --- /dev/null +++ b/neutron/services/l3_router/l3_cont_dvr_plugin.py @@ -0,0 +1,360 @@ +# Copyright (c) 2014 OpenStack Foundation. +# All Rights Reserved. +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + + +import threading + +from ryu.base.app_manager import AppManager +from ryu.controller.ofp_handler import OFPHandler + +from oslo.config import cfg +from oslo import messaging +from oslo.utils import excutils +from oslo.utils import importutils + +from neutron import context +from neutron import manager + +from neutron.api.rpc.agentnotifiers import l3_rpc_agent_api +from neutron.api.rpc.handlers import l3_rpc +from neutron.common import constants as q_const +from neutron.common import rpc as n_rpc +from neutron.common import topics +from neutron.common import utils +from neutron.plugins.common import constants + +from neutron.db import common_db_mixin +from neutron.db import l3_gwmode_db +from neutron.db import l3_hascheduler_db + +from neutron.openstack.common import log as logging +from neutron.openstack.common import loopingcall + +from neutron.services.l3_router.l3_reactive_app import L3ReactiveApp + +LOG = logging.getLogger(__name__) + + +NET_CONTROL_L3_OPTS = [ + cfg.StrOpt('L3controller_ip_list', + default='tcp:10.100.100.38:6633', + help=(""L3 Controler IP list list tcp:ip_addr:port;"" + ""tcp:ip_addr:port..;.."")), + cfg.StrOpt('net_controller_l3_southbound_protocol', + default='OpenFlow', + help=(""Southbound protocol to connect the forwarding"" + ""element Currently supports only OpenFlow"")) +] + +cfg.CONF.register_opts(NET_CONTROL_L3_OPTS) + + +L3_SDN_AGNET_TYPE = ""SDN_app_l3"" + + +class ControllerL3ServicePlugin(common_db_mixin.CommonDbMixin, + l3_gwmode_db.L3_NAT_db_mixin, + l3_hascheduler_db.L3_HA_scheduler_db_mixin): + + RPC_API_VERSION = '1.2' + supported_extension_aliases = [""router"", ""ext-gw-mode""] + + def __init__(self): + + self.setup_rpc() + self.router_scheduler = importutils.import_object( + cfg.CONF.router_scheduler_driver) + self.start_periodic_agent_status_check() + if cfg.CONF.net_controller_l3_southbound_protocol == ""OpenFlow"": + # Open Flow Controller + LOG.debug((""Using Southbound OpenFlow Protocol "")) + self.controllerThread = ControllerRunner(""openflow"") + self.controllerThread.start() + self.controllerThread.router_scheduler = self.router_scheduler + self.controllerThread.endpoints = self.endpoints + + elif cfg.CONF.net_controller_l3_southbound_protocol == ""OVSDB"": + LOG.error((""Southbound OVSDB Protocol not implemented yet"")) + elif cfg.CONF.net_controller_l3_southbound_protocol == ""OP-FLEX"": + LOG.error((""Southbound OP-FLEX Protocol not implemented yet"")) + + super(ControllerL3ServicePlugin, self).__init__() + + def setup_rpc(self): + # RPC support + self.topic = topics.L3PLUGIN + self.conn = n_rpc.create_connection(new=True) + self.agent_notifiers.update( + {q_const.AGENT_TYPE_L3: l3_rpc_agent_api.L3AgentNotifyAPI()}) + self.endpoints = [l3_rpc.L3RpcCallback()] + self.conn.create_consumer(self.topic, self.endpoints, + fanout=True) + self.conn.consume_in_threads() + + def get_plugin_type(self): + return constants.L3_ROUTER_NAT + + def get_plugin_description(self): + """"""Returns string description of the plugin."""""" + return ""Net Controler Plugin reactive mode l3 Implementation"" + + def create_floatingip(self, _context, floatingip): + """"""Create floating IP. + + :param _context: Neutron request context + :param floatingip: data for the floating IP being created + :returns: A floating IP object on success + + """""" + return super(ControllerL3ServicePlugin, self).create_floatingip( + _context, floatingip, + initial_status=q_const.FLOATINGIP_STATUS_DOWN) + + def add_router_interface_postcommit(self, _context, router_id, + interface_info): + # Update router's state first + LOG.debug((""add_router_interface_postcommit "")) + self.controllerThread.bind_unscheduled_routers() + self.controllerThread.update_device_up_by_port_id( + interface_info['port_id']) + # TODO(gampel) Add router info to Local datastore and abstruction layer + # sync local data + self.controllerThread.l3_r_app.notify_sync() + + def remove_router_interface_precommit(self, _context, router_id, + interface_info): + LOG.debug((""remove_router_interface_precommit"")) + # TODO(gampel) Add router info to Local datastore and abstruction layer + + def delete_router_precommit(self, _context, router_id): + LOG.debug((""delete_router_precommit "")) + + def update_router_postcommit(self, _context, router): + self.controllerThread.bind_unscheduled_routers() + LOG.debug((""update_router_postcommit "")) + if router['admin_state_up']: + LOG.debug((""update_router_postcommit admin state up Enable "")) + else: + LOG.debug((""update_router_postcommit admin state down disable"")) + + self.controllerThread.l3_r_app.notify_sync() + + # Router API + + def create_router(self, *args, **kwargs): + self.controllerThread.l3_r_app.create_router(self, *args, **kwargs) + return super(ControllerL3ServicePlugin, self).create_router( + *args, **kwargs) + + def update_router(self, _context, r_id, router): + + result = super(ControllerL3ServicePlugin, self).update_router(_context, + r_id, + router) + self.update_router_postcommit(_context, result) + return result + + def delete_router(self, _context, router_id): + self.delete_router_precommit(_context, router_id) + result = super(ControllerL3ServicePlugin, self).delete_router(_context, + router_id) + self.controllerThread.l3_r_app.notify_sync() + return result + + # Router Interface API + + def add_router_interface(self, _context, router_id, interface_info): + # Create interface in parent + result = super(ControllerL3ServicePlugin, self).add_router_interface( + _context, router_id, interface_info) + try: + self.add_router_interface_postcommit(_context, router_id, + result) + except Exception: + with excutils.save_and_reraise_exception(): + # Rollback db operation + super(ControllerL3ServicePlugin, self).remove_router_interface( + _context, router_id, interface_info) + return result + + def remove_router_interface(self, _context, router_id, interface_info): + self.remove_router_interface_precommit(_context, router_id, + interface_info) + res = super(ControllerL3ServicePlugin, self).remove_router_interface( + _context, router_id, interface_info) + self.controllerThread.l3_r_app.notify_sync() + return res + + def setup_vrouter_arp_responder(self, _context, br, action, table_id, + segmentation_id, net_uuid, mac_address, + ip_address): + + topic_port_update = topics.get_topic_name(topics.AGENT, + topics.PORT, + topics.UPDATE) + target = messaging.Target(topic=topic_port_update) + rpcapi = n_rpc.get_client(target) + rpcapi.cast(_context, + 'setup_entry_for_arp_reply_remote', + br_id=""br-int"", + action=action, + table_id=table_id, + segmentation_id=segmentation_id, + net_uuid=net_uuid, + mac_address=mac_address, + ip_address=ip_address) + + def update_agent_port_mapping_done( + self, _context, agent_id, ip_address, host=None): + LOG.debug((""::agent agent <%s> on ip <%s> host <%s> ""), + agent_id, + ip_address, + host) + self.send_set_controllers_upadte(_context, False) + + def send_set_controllers_upadte(self, _context, force_reconnect): + + topic_port_update = topics.get_topic_name(topics.AGENT, + topics.PORT, + topics.UPDATE) + target = messaging.Target(topic=topic_port_update) + rpcapi = n_rpc.get_client(target) + iplist = cfg.CONF.L3controller_ip_list + rpcapi.cast(_context, + 'set_controller_for_br', + br_id=""br-int"", + ip_address_list=iplist, + force_reconnect=force_reconnect, + protocols=""OpenFlow13"") + + +class ControllerRunner(threading.Thread): + + def __init__(self, controllertype): + super(ControllerRunner, self).__init__() + self.controllertype = controllertype + self.ctx = context.get_admin_context() + self.hostname = utils.get_hostname() + self.agent_state = { + 'binary': 'neutron-l3-agent', + 'host': self.hostname, + 'topic': topics.L3_AGENT, + 'configurations': { + 'agent_mode': 'legacy', + 'use_namespaces': True, + 'router_id': 1, + 'handle_internal_only_routers': True, + 'external_network_bridge': 'br-ex', + 'gateway_external_network_id': '', + 'interface_driver': ""OpenFlow""}, + 'start_flag': True, + 'agent_type': L3_SDN_AGNET_TYPE} + self.l3_rpc = l3_rpc.L3RpcCallback() + self.sync_active_state = False + self.sync_all = True + self.l3_r_app = None + self.heartbeat = None + self.open_flow_hand = None + + def start(self): + app_mgr = AppManager.get_instance() + LOG.debug((""running ryu openflow Controller lib "")) + self.open_flow_hand = app_mgr.instantiate(OFPHandler, None, None) + self.open_flow_hand.start() + self.l3_r_app = app_mgr.instantiate(L3ReactiveApp, None, None) + self.l3_r_app.start() + ''' TODO fix this is hack to let the scheduler schedule the virtual + router to L3 SDN app so this app will be in teh Agnet table as active + Will be change when we convert this implementation to Service + Plugin ----> l3 SDN agent for scalability Currently runs as tread + will be converted to run as a standalone agent + ''' + self.heartbeat = loopingcall.FixedIntervalLoopingCall( + self._report_state_and_bind_routers) + self.heartbeat.start(interval=30) + + def _report_state_and_bind_routers(self): + if self.sync_all: + l3plugin = manager.NeutronManager.get_service_plugins().get( + constants.L3_ROUTER_NAT) + l3plugin.send_set_controllers_upadte(self.ctx, True) + self.sync_all = False + plugin = manager.NeutronManager.get_plugin() + plugin.create_or_update_agent(self.ctx, self.agent_state) + self.bind_unscheduled_routers() + if not self.sync_active_state: + self.update_deviceup_on_all_vr_ports() + self.sync_active_state = True + + def bind_unscheduled_routers(self): + l3plugin = manager.NeutronManager.get_service_plugins().get( + constants.L3_ROUTER_NAT) + unscheduled_routers = [] + routers = l3plugin.get_routers(self.ctx, filters={}) + for router in routers: + l3_agents = l3plugin.get_l3_agents_hosting_routers( + self.ctx, [router['id']], admin_state_up=True) + + if l3_agents: + LOG.debug(('Router %(router_id)s has already been ' + 'hosted by L3 agent %(agent_id)s'), + {'router_id': router['id'], + 'agent_id': l3_agents[0]['id']}) + else: + unscheduled_routers.append(router) + + if unscheduled_routers: + + l3_agent = l3plugin.get_enabled_agent_on_host( + self.ctx, L3_SDN_AGNET_TYPE, utils.get_hostname()) + if l3_agent: + self.router_scheduler.bind_routers( + self.ctx, l3plugin, unscheduled_routers, l3_agent) + LOG.debug('Router %(router_id)s scheduled ' + 'to L3 SDN agent %(agent_id)s.', + {'agent_id': l3_agent.id, + 'router_id': unscheduled_routers}) + # Update Port binbding + + self.l3_rpc._ensure_host_set_on_ports( + self.ctx, utils.get_hostname(), routers) + else: + LOG.error((""could not find fake l3 agent for L3 SDN app can"" + ""not schedule router id %(router_ids)s""), + {'router_ids': unscheduled_routers}) + + def update_deviceup_on_all_vr_ports(self): + + l3plugin = manager.NeutronManager.get_service_plugins().get( + constants.L3_ROUTER_NAT) + routers = l3plugin.get_sync_data(self.ctx) + for router in routers: + for interface in router.get(q_const.INTERFACE_KEY, []): + self.update_device_up(interface) + + def update_device_up_by_port_id(self, port_id): + + plugin = manager.NeutronManager.get_plugin() + port = plugin._get_port(self.ctx, port_id) + self.update_device_up(port) + + def update_device_up(self, port): + plugin = manager.NeutronManager.get_plugin() + #plugin.update_device_up(self.ctx, device) + self.l3_rpc._ensure_host_set_on_port( + self.ctx, utils.get_hostname(), port) + plugin.update_port_status(self.ctx, port['id'], + q_const.PORT_STATUS_ACTIVE, + utils.get_hostname()) diff --git a/neutron/services/l3_router/l3_reactive_app.py b/neutron/services/l3_router/l3_reactive_app.py new file mode 100755 index 0000000..3dcd928 --- /dev/null +++ b/neutron/services/l3_router/l3_reactive_app.py @@ -0,0 +1,1274 @@ +# Copyright (c) 2014 OpenStack Foundation. +# All Rights Reserved. +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + + +import collections +import struct +import threading + +import time + +from ryu.base import app_manager +from ryu.controller.handler import CONFIG_DISPATCHER +from ryu.controller.handler import MAIN_DISPATCHER +from ryu.controller.handler import set_ev_cls +from ryu.controller import ofp_event +from ryu.ofproto import ether +from ryu.ofproto.ether import ETH_TYPE_8021Q +from ryu.ofproto import ofproto_v1_3 + +from ryu.lib.packet import ethernet +from ryu.lib.packet import packet + +from ryu.lib.mac import haddr_to_bin +from ryu.lib.packet import icmp +from ryu.lib.packet import ipv4 +from ryu.lib.packet import tcp +from ryu.lib.packet import udp +from ryu.lib.packet import vlan + +from ryu.lib import addrconv + +from neutron.openstack.common import log +from neutron.plugins.ml2 import driver_api as api + +from neutron import context +from neutron import manager +from neutron.plugins.common import constants as service_constants + + +LOG = log.getLogger(__name__) + +ETHERNET = ethernet.ethernet.__name__ +VLAN = vlan.vlan.__name__ +IPV4 = ipv4.ipv4.__name__ +ICMP = icmp.icmp.__name__ +TCP = tcp.tcp.__name__ +UDP = udp.udp.__name__ + +VLANID_NONE = 0 +VLANID_MIN = 2 +VLANID_MAX = 4094 +COOKIE_SHIFT_VLANID = 32 +UINT16_MAX = 0xffff +UINT32_MAX = 0xffffffff +UINT64_MAX = 0xffffffffffffffff +OFPFW_NW_PROTO = 1 << 5 + +HIGH_PRIOREITY_FLOW = 1000 +MEDIUM_PRIOREITY_FLOW = 100 +NORMAL_PRIOREITY_FLOW = 10 +LOW_PRIOREITY_FLOW = 1 +LOWEST_PRIOREITY_FLOW = 0 + + +# A class to represent a forwarding Elemnt Switch local state +class AgentDatapath(object): + + def __init__(self): + self.local_vlan_mapping = {} + self.local_ports = None + self.datapath = 0 + self.patch_port_num = 0 + + +# A class to represent tenat toplogie +class TenantTopo(object): + + def __init__(self): + self.nodes = set() + self.edges = collections.defaultdict(list) + self.routers = [] + self.distances = {} + self.mac_to_port_data = collections.defaultdict(set) + self.tenant_id = None + #self.segmentation_id = None + + def add_router(self, router, r_id): + self.routers.append(router) + + def add_node(self, value): + self.nodes.add(value) + + def add_edge(self, from_node, to_node, distance): + self.edges[from_node].append(to_node) + self.edges[to_node].append(from_node) + self.distances[(from_node, to_node)] = distance + + # we need dijsktra only for extra route + def dijsktra(self, graph, initial): + visited = {initial: 0} + path = {} + + nodes = set(graph.nodes) + + while nodes: + min_node = None + for node in nodes: + if node in visited: + if min_node is None: + min_node = node + elif visited[node] < visited[min_node]: + min_node = node + + if min_node is None: + break + + nodes.remove(min_node) + current_weight = visited[min_node] + + for edge in graph.edges[min_node]: + weight = current_weight + graph.distance[(min_node, edge)] + if edge not in visited or weight < visited[edge]: + visited[edge] = weight + path[edge] = min_node + + return visited, path + + +class Router(object): + + def __init__(self, data): + self.data = data + #self.subnets = defaultdict(list) + self.subnets = [] + + def add_subnet(self, subnet, sub_id): + self.subnets.append(subnet) + + +class Subnet(object): + + def __init__(self, data, port_data, segmentation_id): + self.data = data + self.port_data = port_data + self.segmentation_id = segmentation_id + + +class L3ReactiveApp(app_manager.RyuApp): + OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION] + #OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION] + #OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION] + BASE_RPC_API_VERSION = '1.0' + + BASE_TABLE = 0 + CLASSIFIER_TABLE = 40 + METADATA_TABLE_ID = 50 + ARP_AND_BR_TABLE = 51 + L3_VROUTER_TABLE = 52 + + def __init__(self, *args, **kwargs): + super(L3ReactiveApp, self).__init__(*args, **kwargs) + self.mac_to_port = {} + + self.ctx = context.get_admin_context() + self.lock = threading.Lock() + self.tenants = collections.defaultdict(lambda: None) + self.need_sync = True + self.dp_list = {} + + def start(self): + super(L3ReactiveApp, self).start() + return 1 + + def create_router(self, *args, **kwargs): + self.logger.info(""l3ReactiveApp create_router"") + # self.sync_data() + + def notify_sync(self): + self.need_sync = True + for dpid in self.dp_list: + datapath = self.dp_list[dpid].datapath + self.send_features_request(datapath) + self.send_flow_stats_request( + datapath, table=self.METADATA_TABLE_ID) + + def sync_data(self): + self.logger.info("" l3_reactive_app sync router data "") + + self.lock.acquire() + # Lock + self.logger.debug('l3_reactive_app in the critical section the lock') + if self.need_sync: + l3plugin = manager.NeutronManager.get_service_plugins().get( + service_constants.L3_ROUTER_NAT) + + routers = l3plugin.get_sync_data(self.ctx, None) + self.core_plugin = manager.NeutronManager.get_plugin() + self.get_router_subnets(routers) + self.need_sync = False + del l3plugin + del self.core_plugin + self.core_plugin = None + self.logger.debug('l3_reactive_app releasing the lock') + # Release + self.lock.release() + + def get_router_subnets(self, router_data): + for router in router_data: + tenant_id = router['tenant_id'] + if not router['tenant_id'] in self.tenants: + self.tenants[router['tenant_id']] = TenantTopo() + tenant_topo = self.tenants[router['tenant_id']] + tenant_topo.tenant_id = tenant_id + router_cls = Router(router) + tenant_topo.add_router(router_cls, router['id']) + if ""_interfaces"" in router: + for interface in router['_interfaces']: + ports_data = self.get_ports_by_subnet( + interface['subnet']['id']) + segmentation_id = None + for device in ports_data: + port = self.get_port_bond_data( + self.ctx, device['id'], device['binding:host_id']) + if ""mac_address"" in port: + tenant_topo.mac_to_port_data[ + port['mac_address']] = port + segmentation_id = port['segmentation_id'] + else: + if (device['device_owner'] == + 'network:router_interface'): + # if this a router then bind it to our + # application + + LOG.error((""No binding for router %s""), device) + # tenant_topo.add_router(router,router['id']) + subnet_cls = Subnet(interface['subnet'], ports_data, + segmentation_id) + router_cls.add_subnet( + subnet_cls, interface['subnet']['id']) + + def get_port_bond_data(self, ctx, port_id, device_id): + port_context = self.core_plugin.get_bound_port_context( + ctx, port_id, device_id) + if not port_context: + LOG.warning((""Device %(device)s requested by agent "" + ""%(agent_id)s not found in database""), + {'device': device_id, 'agent_id': port_id}) + return {'device': device_id} + + segment = port_context.bound_segment + port = port_context.current + + if not segment: + LOG.warning((""Device %(device)s requested by agent "" + "" on network %(network_id)s not "" + ""bound, vif_type: ""), + {'device': device_id, + 'network_id': port['network_id']}) + return {'device': device_id} + + entry = {'device': device_id, + 'network_id': port['network_id'], + 'port_id': port_id, + 'mac_address': port['mac_address'], + 'admin_state_up': port['admin_state_up'], + 'network_type': segment[api.NETWORK_TYPE], + 'segmentation_id': segment[api.SEGMENTATION_ID], + 'physical_network': segment[api.PHYSICAL_NETWORK], + 'fixed_ips': port['fixed_ips'], + 'device_owner': port['device_owner']} + LOG.debug((""Returning: %s""), entry) + return entry + + def get_ports_by_subnet(self, subnet_id): + filters = {'fixed_ips': {'subnet_id': [subnet_id]}} + return self.core_plugin.get_ports(self.ctx, filters=filters) + + @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER) + def OF_packet_in_handler(self, ev): + if self.need_sync == 1: + self.sync_data() + msg = ev.msg + datapath = msg.datapath + ofproto = datapath.ofproto + if msg.reason == ofproto.OFPR_NO_MATCH: + reason = 'NO MATCH' + elif msg.reason == ofproto.OFPR_ACTION: + reason = 'ACTION' + elif msg.reason == ofproto.OFPR_INVALID_TTL: + reason = 'INVALID TTL' + else: + reason = 'unknown' + + LOG.debug('OFPPacketIn received: ' + 'buffer_id=%x total_len=%d reason=%s ' + 'table_id=%d cookie=%d match=%s', + msg.buffer_id, msg.total_len, reason, + msg.table_id, msg.cookie, msg.match) + # utils.hex_array(msg.data)) + in_port = msg.match['in_port'] + + pkt = packet.Packet(msg.data) + eth = pkt.get_protocols(ethernet.ethernet)[0] + + header_list = dict((p.protocol_name, p) + for p in pkt.protocols if not isinstance(p, str)) + if header_list: + try: + if ""ipv4"" in header_list: + self.handle_ipv4_packet_in( + datapath, + msg, + in_port, + header_list, + pkt, + eth) + return + if ""ipv6"" in header_list: + self.handle_ipv6_packet_in( + datapath, in_port, header_list, pkt, eth) + return + except Exception as exception: + + LOG.debug(""Unable to handle packet %(msg): %(e)s"", + {'msg': msg, 'e': exception}) + + LOG.error(("">>>>>>>>>> Unhandled Packet>>>>> %s"", pkt)) + + def handle_ipv6_packet_in(self, datapath, in_port, header_list, + pkt, eth): + # TODO(gampel)(gampel) add ipv6 support + LOG.error((""No handle for ipv6 yet should be offload to the"" + ""NORMAL path %s"", pkt)) + return + + def handle_ipv4_packet_in(self, datapath, msg, in_port, header_list, pkt, + eth): + pkt_ipv4 = header_list['ipv4'] + pkt_ethernet = header_list['ethernet'] + + # Check vlan-tag + if VLAN in header_list: + vlan_id = header_list[VLAN].vid + self.logger.info(""handle_ipv4_packet_in:: VLANID %s "", vlan_id) + switch = self.dp_list.get(datapath.id) + if switch: + if vlan_id not in switch.local_vlan_mapping: + # send request for loacl switch data + # self.send_port_desc_stats_request(datapath) + self.send_flow_stats_request( + datapath, table=self.METADATA_TABLE_ID) + LOG.error((""No local switch vlan mapping for vlan %s""), + vlan_id) + return + self.logger.info( + ""packet segmentation_id %s "", + switch.local_vlan_mapping[vlan_id]) + segmentation_id = switch.local_vlan_mapping[vlan_id] + for tenantid in self.tenants: + tenant = self.tenants[tenantid] + for router in tenant.routers: + for subnet in router.subnets: + if segmentation_id == subnet.segmentation_id: + self.logger.info(""packet from to tenant %s "", + tenant.tenant_id) + in_port_data = self.tenants[ + tenantid].mac_to_port_data[eth.src] + out_port_data = self.tenants[ + tenantid].mac_to_port_data[eth.dst] + LOG.debug(('Source port data <--- %s ', + in_port_data)) + LOG.debug(('Router Mac dest port data -> %s ', + out_port_data)) + if self.handle_router_interface(datapath, + in_port, + out_port_data, + pkt, + pkt_ethernet, + pkt_ipv4) == 1: + # trafic to the virtual routre handle only + # ping + return + (dst_p_data, + dst_sub_id) = self.get_port_data(tenant, + pkt_ipv4.dst) + for _subnet in router.subnets: + if dst_sub_id == _subnet.data['id']: + out_subnet = _subnet + subnet_gw = out_subnet.data[ + 'gateway_ip'] + + (dst_gw_port_data, + dst_gw_sub_id) = self.get_port_data( + tenant, subnet_gw) + + if self.handle_router_interface( + datapath, + in_port, + dst_gw_port_data, + pkt, + pkt_ethernet, + pkt_ipv4) == 1: + # this trafic to the virtual routre + return + if not dst_p_data: + LOG.error((""No local switch"" + ""mapping for %s""), + pkt_ipv4.dst) + return + if self.handle_router_interface( + datapath, + in_port, + dst_p_data, + pkt, + pkt_ethernet, + pkt_ipv4) != -1: + # case for vrouter that is not the + #gw and we are trying to ping + # this trafic to the virtual routre + return + + LOG.debug((""Route from %s to %s"" + ""exist installing flow "", + pkt_ipv4.src, + pkt_ipv4.dst)) + dst_vlan = self.get_l_vid_from_seg_id( + switch, + out_subnet.segmentation_id) + self.install_l3_forwarding_flows( + datapath, + msg, + in_port_data, + in_port, + vlan_id, + eth, + pkt_ipv4, + dst_gw_port_data, + dst_p_data, + dst_vlan) + return + + def install_l3_forwarding_flows( + self, + datapath, + msg, + in_port_data, + in_port, + vlan_id, + eth, + pkt_ipv4, + dst_gw_port_data, + dst_p_data, + dst_vlan): + if dst_p_data['local_dpid_switch'] == datapath.id: + # The dst VM and the source VM are on the same copute Node + # Send output flow directly to port iuse the same datapath + actions = self.add_flow_subnet_traffic( + datapath, + self.L3_VROUTER_TABLE, + MEDIUM_PRIOREITY_FLOW, + in_port, + vlan_id, + eth.src, + eth.dst, + pkt_ipv4.dst, + pkt_ipv4.src, + dst_gw_port_data['mac_address'], + dst_p_data['mac_address'], + dst_p_data['local_port_num']) + # Install the reverse flow return traffic + self.add_flow_subnet_traffic(datapath, + self.L3_VROUTER_TABLE, + MEDIUM_PRIOREITY_FLOW, + dst_p_data['local_port_num'], + dst_vlan, + dst_p_data['mac_address'], + dst_gw_port_data['mac_address'], + pkt_ipv4.src, + pkt_ipv4.dst, + eth.dst, + in_port_data['mac_address'], + in_port_data['local_port_num']) + self.handle_packet_out_l3(datapath, msg, in_port, actions) + else: + # The dst VM and the source VM are NOT on the same copute Node + # Send output to br-tun patch port and install reverse flow on the + # dst compute node + remoteSwitch = self.dp_list.get(dst_p_data['local_dpid_switch']) + localSwitch = self.dp_list.get(datapath.id) + actions = self.add_flow_subnet_traffic(datapath, + self.L3_VROUTER_TABLE, + MEDIUM_PRIOREITY_FLOW, + in_port, + vlan_id, + eth.src, + eth.dst, + pkt_ipv4.dst, + pkt_ipv4.src, + dst_gw_port_data[ + 'mac_address'], + dst_p_data[ + 'mac_address'], + localSwitch.patch_port, + dst_vlan) + # Remote reverse flow install + self.add_flow_subnet_traffic(remoteSwitch.datapath, + self.L3_VROUTER_TABLE, + MEDIUM_PRIOREITY_FLOW, + dst_p_data['local_port_num'], + dst_vlan, + dst_p_data['mac_address'], + dst_gw_port_data['mac_address'], + pkt_ipv4.src, + pkt_ipv4.dst, + eth.dst, + in_port_data['mac_address'], + in_port_data['local_port_num'], + vlan_id) + self.handle_packet_out_l3(datapath, msg, in_port, actions) + + def handle_packet_out_l3(self, datapath, msg, in_port, actions): + data = None + + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + if msg.buffer_id == ofproto.OFP_NO_BUFFER: + data = msg.data + out = parser.OFPPacketOut(datapath=datapath, buffer_id=msg.buffer_id, + in_port=in_port, actions=actions, data=data) + datapath.send_msg(out) + + def add_flow_subnet_traffic(self, datapath, table, priority, in_port, + match_vlan, match_src_mac, match_dst_mac, + match_dst_ip, match_src_ip, src_mac, + dst_mac, out_port_num, dst_vlan=None): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch() + # BUG in the Ryu lib constructor match do not work + match.set_dl_type(0x0800) + match.set_in_port(in_port) + match.set_dl_src(haddr_to_bin(match_src_mac)) + match.set_dl_dst(haddr_to_bin(match_dst_mac)) + match.set_ipv4_src(ipv4_text_to_int(str(match_src_ip))) + match.set_ipv4_dst(ipv4_text_to_int(str(match_dst_ip))) + match.set_vlan_vid(0x1000 | match_vlan) + actions = [parser.OFPActionPopVlan()] + actions.append(parser.OFPActionDecNwTtl()) + actions.append(parser.OFPActionSetField(eth_src=src_mac)) + actions.append(parser.OFPActionSetField(eth_dst=dst_mac)) + actions.append(parser.OFPActionOutput(out_port_num, + ofproto.OFPCML_NO_BUFFER)) + if dst_vlan: + field = parser.OFPMatchField.make( + ofproto.OXM_OF_VLAN_VID, dst_vlan) + actions.append(parser.OFPActionPushVlan(ETH_TYPE_8021Q)) + actions.append(parser.OFPActionSetField(field)) + + ofproto = datapath.ofproto + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + return actions + + def add_flow_pop_vlan_to_normal(self, datapath, table, priority, vlan_id): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch(vlan_vid=0x1000 | vlan_id) + #match = parser.OFPMatch(vlan_pcp=0) + actions = [ + parser.OFPActionPopVlan(), + parser.OFPActionOutput( + ofproto.OFPP_NORMAL, + ofproto.OFPCML_NO_BUFFER)] + ofproto = datapath.ofproto + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def add_flow_normal_local_subnet( + self, datapath, table, priority, dst_net, dst_mask, vlan_id): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + #match = parser.OFPMatch(vlan_vid=0x1000| vlan_id) + match = parser.OFPMatch(vlan_vid=0x1000 | vlan_id) + match.set_dl_type(0x0800) + match.set_vlan_vid(0x1000 | vlan_id) + match.set_ipv4_dst_masked(ipv4_text_to_int(str(dst_net)), + mask_ntob(int(dst_mask))) + #match = parser.OFPMatch(vlan_pcp=0) + actions = [ + parser.OFPActionPopVlan(), + parser.OFPActionOutput( + ofproto.OFPP_NORMAL)] + # actions = [parser.OFPActionOutput(ofproto.OFPP_NORMAL, + # ofproto.OFPCML_NO_BUFFER)] + ofproto = datapath.ofproto + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def add_flow_normal_by_port_num(self, datapath, table, priority, in_port): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch(in_port=in_port) + #match = parser.OFPMatch(vlan_pcp=0) + actions = [parser.OFPActionOutput(ofproto.OFPP_NORMAL)] + ofproto = datapath.ofproto + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def add_flow_push_vlan_by_port_num( + self, datapath, table, priority, in_port, dst_vlan, goto_table): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch() + match.set_in_port(in_port) + field = parser.OFPMatchField.make( + ofproto.OXM_OF_VLAN_VID, 0x1000 | dst_vlan) + actions = [datapath. ofproto_parser. OFPActionPushVlan( + ETH_TYPE_8021Q), datapath.ofproto_parser.OFPActionSetField(field)] + goto_inst = parser.OFPInstructionGotoTable(goto_table) + ofproto = datapath.ofproto + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions), goto_inst] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def delete_all_flow_from_table(self, datapath, table_id): + + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch() + instructions = [] + flow_mod = datapath.ofproto_parser.OFPFlowMod( + datapath, + 0, + 0, + table_id, + ofproto.OFPFC_DELETE, + 0, + 0, + 1, + ofproto.OFPCML_NO_BUFFER, + ofproto.OFPP_ANY, + ofproto.OFPG_ANY, + 0, + match, + instructions) + datapath.send_msg(flow_mod) + + def add_flow_normal(self, datapath, table, priority): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch(vlan_vid=0x1000) + #match = parser.OFPMatch(vlan_pcp=0) + actions = [ + parser.OFPActionPopVlan(), + parser.OFPActionOutput( + ofproto.OFPP_NORMAL)] + ofproto = datapath.ofproto + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def mod_flow(self, datapath, cookie=0, cookie_mask=0, table_id=0, + command=None, idle_timeout=0, hard_timeout=0, + priority=0xff, buffer_id=0xffffffff, match=None, + actions=None, inst_type=None, out_port=None, + out_group=None, flags=0, inst=None): + + if command is None: + command = datapath.ofproto.OFPFC_ADD + + if inst is None: + if inst_type is None: + inst_type = datapath.ofproto.OFPIT_APPLY_ACTIONS + + inst = [] + if actions is not None: + inst = [datapath.ofproto_parser.OFPInstructionActions( + inst_type, actions)] + + if match is None: + match = datapath.ofproto_parser.OFPMatch() + + if out_port is None: + out_port = datapath.ofproto.OFPP_ANY + + if out_group is None: + out_group = datapath.ofproto.OFPG_ANY + + message = datapath.ofproto_parser.OFPFlowMod(datapath, cookie, + cookie_mask, + table_id, command, + idle_timeout, + hard_timeout, + priority, + buffer_id, + out_port, + out_group, + flags, + match, + inst) + + datapath.send_msg(message) + + def add_flow_go_to_table2(self, datapath, table, priority, + goto_table_id, match=None): + inst = [datapath.ofproto_parser.OFPInstructionGotoTable(goto_table_id)] + self.mod_flow(datapath, inst=inst, table_id=table, priority=priority, + match=match) + + def add_flow_goto_table_on_broad(self, datapath, table, priority, + goto_table_id): + match = datapath.ofproto_parser.OFPMatch(eth_dst='ff:ff:ff:ff:ff:ff') + + self.add_flow_go_to_table2(datapath, table, priority, goto_table_id, + match) + + def add_flow_goto_table_on_mcast(self, datapath, table, priority, + goto_table_id): + #ofproto = datapath.ofproto + match = datapath.ofproto_parser.OFPMatch(eth_dst='01:00:00:00:00:00') + addint = haddr_to_bin('01:00:00:00:00:00') + match.set_dl_dst_masked(addint, addint) + self.add_flow_go_to_table2(datapath, table, priority, goto_table_id, + match) + + def add_flow_go_to_table_on_arp(self, datapath, table, priority, + goto_table_id): + match = datapath.ofproto_parser.OFPMatch(eth_type=0x0806) + self.add_flow_go_to_table2(datapath, table, priority, goto_table_id, + match) + + def add_flow_go_to_table(self, datapath, table, priority, goto_table_id): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch() + actions = [parser.OFPInstructionGotoTable(goto_table_id)] + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + mod = datapath.ofproto_parser.OFPFlowMod( + datapath=datapath, cookie=0, cookie_mask=0, table_id=table, + command=ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0, + priority=priority, buffer_id=ofproto.OFP_NO_BUFFER, + out_port=ofproto.OFPP_ANY, + out_group=ofproto.OFPG_ANY, + flags=0, match=match, instructions=inst) + datapath.send_msg(mod) + + def add_flow_match_to_controller(self, datapath, table, priority, + match=None, _actions=None): + + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + + ofproto = datapath.ofproto + actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER, + ofproto.OFPCML_NO_BUFFER)] + + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def add_flow_match_gw_mac_to_cont(self, datapath, dst_mac, table, + priority, vlan_vid=None, + _actions=None): + parser = datapath.ofproto_parser + #ofproto = datapath.ofproto + vlan_id = 0x1000 | vlan_vid + match = parser.OFPMatch(eth_dst=dst_mac, vlan_vid=vlan_id) + + self.add_flow_match_to_controller( + datapath, table, priority, match=match, _actions=_actions) + + def add_flow_l3(self, datapath, in_port, dst_mac, src_mac, vlan_vid, + actions): + ofproto = datapath.ofproto + + match = datapath.ofproto_parser.OFPMatch(in_port=in_port, + eth_dst=dst_mac, + eth_src=src_mac, + vlan_vid=vlan_vid) + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + + mod = datapath.ofproto_parser.OFPFlowMod( + datapath=datapath, cookie=0, cookie_mask=0, table_id=0, + command=ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0, + priority=0, buffer_id=ofproto.OFP_NO_BUFFER, + out_port=ofproto.OFPP_ANY, + out_group=ofproto.OFPG_ANY, + flags=0, match=match, instructions=inst) + datapath.send_msg(mod) + + def add_flow(self, datapath, port, dst, actions): + ofproto = datapath.ofproto + + match = datapath.ofproto_parser.OFPMatch(in_port=port, + eth_dst=dst) + inst = [datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)] + + mod = datapath.ofproto_parser.OFPFlowMod( + datapath=datapath, cookie=0, cookie_mask=0, table_id=0, + command=ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0, + priority=0, buffer_id=ofproto.OFP_NO_BUFFER, + out_port=ofproto.OFPP_ANY, + out_group=ofproto.OFPG_ANY, + flags=0, match=match, instructions=inst) + datapath.send_msg(mod) + + @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER) + def _port_status_handler(self, ev): + msg = ev.msg + reason = msg.reason + port_no = msg.desc.port_no + datapath = ev.msg.datapath + + ofproto = msg.datapath.ofproto + if reason == ofproto.OFPPR_ADD: + self.logger.info(""port added %s"", port_no) + elif reason == ofproto.OFPPR_DELETE: + self.logger.info(""port deleted %s"", port_no) + elif reason == ofproto.OFPPR_MODIFY: + self.logger.info(""port modified %s"", port_no) + else: + self.logger.info(""Illeagal port state %s %s"", port_no, reason) + # TODO(gampel) Currently we update all the agents on modification + LOG.info(("" Updating flow table on agents got port update "")) + + switch = self.dp_list.get(datapath.id) + if switch: + self.send_flow_stats_request( + datapath, table=self.METADATA_TABLE_ID) + + @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER) + def switch_features_handler(self, ev): + datapath = ev.msg.datapath + + if self.need_sync: + self.sync_data() + switch = self.dp_list.get(datapath.id) + if not switch: + self.dp_list[datapath.id] = AgentDatapath() + self.dp_list[datapath.id].datapath = datapath + + LOG.info((""Wait:: Let agent insert the meta data table "")) + time.sleep(1) # sleep during 500ms + LOG.info((""Done Wait .. will retry if meta table not set "")) + + self.send_flow_stats_request(datapath, table=self.METADATA_TABLE_ID) + # --> meta + #self.add_flow_go_to_table2(datapath, 0, 1 ,self.L3_VROUTER_TABLE) + # main table 0 to Arp On ARp or broadcat or multicast + self.add_flow_go_to_table_on_arp( + datapath, + self.CLASSIFIER_TABLE, + NORMAL_PRIOREITY_FLOW, + self.ARP_AND_BR_TABLE) + self.add_flow_goto_table_on_broad( + datapath, + self.CLASSIFIER_TABLE, + MEDIUM_PRIOREITY_FLOW, + self.ARP_AND_BR_TABLE) + self.add_flow_goto_table_on_mcast( + datapath, + self.CLASSIFIER_TABLE, + NORMAL_PRIOREITY_FLOW, + self.ARP_AND_BR_TABLE) + + # Meta Table to L3 router table on all other trafic + self.add_flow_go_to_table2( + datapath, self.METADATA_TABLE_ID, 1, self.L3_VROUTER_TABLE) + + # Normal flow on arp table in low priorety + self.add_flow_normal(datapath, self.ARP_AND_BR_TABLE, 1) + #del l3plugin + + def send_port_desc_stats_request(self, datapath): + ofp_parser = datapath.ofproto_parser + + req = ofp_parser.OFPPortDescStatsRequest(datapath, 0) + datapath.send_msg(req) + + @set_ev_cls(ofp_event.EventOFPPortDescStatsReply, MAIN_DISPATCHER) + def port_desc_stats_reply_handler(self, ev): + ports = [] + datapath = ev.msg.datapath + switch = self.dp_list.get(datapath.id) + self.delete_all_flow_from_table(datapath, self.BASE_TABLE) + for port in ev.msg.body: + ports.append('port_no=%d hw_addr=%s name=%s config=0x%08x ' + 'state=0x%08x curr=0x%08x advertised=0x%08x ' + 'supported=0x%08x peer=0x%08x curr_speed=%d ' + 'max_speed=%d' % + (port.port_no, port.hw_addr, + port.name, port.config, + port.state, port.curr, port.advertised, + port.supported, port.peer, port.curr_speed, + port.max_speed)) + + if ""tap"" in port.name: + LOG.debug((""Found DHCPD port %s using MAC %s"" + ""One machine install Special"" + ""(One Machine set up ) test use case""), + port.name, + port.hw_addr) + self.add_flow_normal_by_port_num( + datapath, 0, HIGH_PRIOREITY_FLOW, port.port_no) + elif ""qvo"" in port.name: + # this is a VM port start with qvo<NET-ID[:11]> update the port + # data with the port num and the switch dpid + (port_id, mac, segmentation_id) = self.update_local_port_num( + port.name, port.port_no, datapath.id) + vlan_id = self.get_l_vid_from_seg_id(switch, segmentation_id) + LOG.debug((""Found VM port %s using MAC %s %d""), + port.name, port.hw_addr, datapath.id) + if vlan_id: + self.add_flow_push_vlan_by_port_num(datapath, + 0, + HIGH_PRIOREITY_FLOW, + port.port_no, + vlan_id, + self.CLASSIFIER_TABLE) + else: + LOG.error((""No local switch vlan mapping for port"" + "" %s on %d Sending to Normal PATH ""), + port.name, + datapath.id) + self.add_flow_normal_by_port_num(datapath, 0, + HIGH_PRIOREITY_FLOW, + port.port_no) + elif ""patch-tun"" in port.name: + LOG.debug((""Found br-tun patch port "" + ""%s %s sending to NORMAL path""), + port.name, + port.hw_addr) + switch.patch_port_num = port.port_no + self.add_flow_normal_by_port_num( + datapath, 0, HIGH_PRIOREITY_FLOW, port.port_no) + self.logger.debug('OFPPortDescStatsReply received: %s', ports) + switch.local_ports = ports + self.add_flow_go_to_table2(datapath, 0, 1, self.CLASSIFIER_TABLE) + self.add_flow_match_to_controller(datapath, self.L3_VROUTER_TABLE, 0) + self.add_flow_go_to_table2( + datapath, self.CLASSIFIER_TABLE, 1, self.L3_VROUTER_TABLE) + + def send_features_request(self, datapath): + ofp_parser = datapath.ofproto_parser + + req = ofp_parser.OFPFeaturesRequest(datapath) + datapath.send_msg(req) + + def _send_packet(self, datapath, port, pkt): + ofproto = datapath.ofproto + parser = datapath.ofproto_parser + pkt.serialize() + self.logger.info(""packet-out %s"" % (pkt,)) + data = pkt.data + actions = [parser.OFPActionOutput(port=port)] + out = parser.OFPPacketOut(datapath=datapath, + buffer_id=ofproto.OFP_NO_BUFFER, + in_port=ofproto.OFPP_CONTROLLER, + actions=actions, + data=data) + datapath.send_msg(out) + + def get_l_vid_from_seg_id(self, switch, segmentation_id): + for local_vlan in switch.local_vlan_mapping: + if segmentation_id == switch.local_vlan_mapping[local_vlan]: + return local_vlan + return 0 + + def update_local_port_num(self, port_name, port_num, dpid): + + for tenantid in self.tenants: + tenant = self.tenants[tenantid] + for mac in tenant.mac_to_port_data: + port_data = tenant.mac_to_port_data[mac] + # print ""port_data >>>>>>>>>>>>>>%s"",port_data + if 'port_id' in port_data: + port_id = port_data['port_id'] + sub_str_port_id = str(port_id[0:11]) + port_id_from_name = port_name[3:] + if sub_str_port_id == port_id_from_name: + port_data['local_port_num'] = port_num + port_data['local_dpid_switch'] = dpid + return ( + port_data['port_id'], + mac, + port_data['segmentation_id']) + else: + LOG.error((""No data in port)data %s ""), port_data) + return(0, 0, 0) + + def get_port_data(self, tenant, ip_address): + for mac in tenant.mac_to_port_data: + port_data = tenant.mac_to_port_data[mac] + if 'fixed_ips' in port_data: + for fixed_ips in port_data['fixed_ips']: + if ip_address == fixed_ips['ip_address']: + return (port_data, fixed_ips['subnet_id']) + + return(0, 0) + + @set_ev_cls(ofp_event.EventOFPFlowStatsReply, MAIN_DISPATCHER) + def flow_stats_reply_handler(self, ev): + + datapath = ev.msg.datapath + + if self.need_sync: + self.sync_data() + self.delete_all_flow_from_table(datapath, self.ARP_AND_BR_TABLE) + # TODO(gampel) for the moment we delete all the flows in the + #table TO delete only the relevant flows all ready installed + self.delete_all_flow_from_table(datapath, self.L3_VROUTER_TABLE) + # TODO(gampel) remove ARP responders + flows = [] + for stat in ev.msg.body: + for instruction in stat.instructions: + if hasattr(instruction, 'metadata'): + vlan_int = int(stat.match['vlan_vid']) + if vlan_int > 4096: + vlan_int -= 4096 + + switch = self.dp_list.get(datapath.id) + if switch: + switch.local_vlan_mapping[ + vlan_int] = instruction.metadata + flows.append( + 'table_id=%s ' + 'duration_sec=%d diuration_nsec=%d ' + 'priority=%d ' + 'idle_timeout=%d hard_timeout=%d flags=0x%04x ' + 'cookie=%d packet_count=%d byte_count=%d ' + 'match=%s instructions=%s' + 'vlan_id=%s metadata=%s' % + (stat.table_id, + stat.duration_sec, + stat.duration_nsec, + stat.priority, + stat.idle_timeout, + stat.hard_timeout, + stat.flags, + stat.cookie, + stat.packet_count, + stat.byte_count, + stat.match, + stat.instructions, + stat.match['vlan_vid'], + instruction.metadata)) + l3plugin = manager.NeutronManager.get_service_plugins().get( + service_constants.L3_ROUTER_NAT) + switch = self.dp_list.get(datapath.id) + + for tenantid in self.tenants: + for router in self.tenants[tenantid].routers: + for subnet in router.subnets: + for interface in router.data['_interfaces']: + if interface['subnet']['id'] == subnet.data['id']: + segmentation_id = subnet.segmentation_id + vlan_id = self.get_l_vid_from_seg_id( + switch, segmentation_id) + network, net_mask = self.get_subnet_from_cidr( + subnet.data['cidr']) + + if vlan_id: + self.add_flow_normal_local_subnet( + datapath, + self.L3_VROUTER_TABLE, + NORMAL_PRIOREITY_FLOW, + network, + net_mask, + vlan_id) + + self.add_flow_match_gw_mac_to_cont( + datapath, + interface['mac_address'], + self.L3_VROUTER_TABLE, + 99, + vlan_id) + l3plugin.setup_vrouter_arp_responder( + self.ctx, + ""br-int"", + ""add"", + self.ARP_AND_BR_TABLE, + segmentation_id, + interface['network_id'], + interface['mac_address'], + self.get_ip_from_router_interface(interface)) + # No match on table L3_VROUTER_TABLE go to normal flow + # No match on table L3_VROUTER_TABLE go to controller + # Patch to overcome OVS BUG not accepting match on tag vlans + # set Pop per taged vlan + + for local_vlan in switch.local_vlan_mapping: + self.add_flow_pop_vlan_to_normal( + datapath, self.ARP_AND_BR_TABLE, 1, local_vlan) + + if not switch.local_vlan_mapping: + LOG.error((""CRITICAL ERROR ***** Switch did not send local port"" + ""data dpid == <%s> sending flow req ""), + datapath.id) + time.sleep(0.5) # sleep during 500ms + self.send_flow_stats_request( + datapath, table=self.METADATA_TABLE_ID) + else: + self.send_port_desc_stats_request(datapath) + del l3plugin + + def get_ip_from_router_interface(self, interface): + for fixed_ip in interface['fixed_ips']: + if ""ip_address"" in fixed_ip: + return fixed_ip['ip_address'] + + def is_router_interface(self, port): + if port['device_owner'] == 'network:router_interface': + return True + else: + return False + + def handle_router_interface(self, datapath, in_port, port_data, + pkt, pkt_ethernet, pkt_ipv4): + # retVal -1 -- dst is not a v Router + # retVal 1 -- The request was handled + # retVal 0 -- router interface and the request was not handled + retVal = -1 + if self.is_router_interface(port_data): + # router mac address + retVal = 0 + for fixed_ips in port_data['fixed_ips']: + if pkt_ipv4.dst == fixed_ips['ip_address']: + # The dst ip address is the router Ip address should be + # ping req + pkt_icmp = pkt.get_protocol(icmp.icmp) + if pkt_icmp: + # send ping responce + self._handle_icmp( + datapath, + in_port, + pkt_ethernet, + pkt_ipv4, + pkt_icmp) + LOG.info((""Sending ping echo -> ip %s ""), pkt_ipv4.src) + retVal = 1 + else: + LOG.error((""any comunication to a router that"" + "" is not ping should be dropped from"" + ""ip %s"", + pkt_ipv4.src)) + retVal = 1 + return retVal + + def send_flow_stats_request(self, datapath, table=None): + + ofp = datapath.ofproto + ofp_parser = datapath.ofproto_parser + if table is None: + table = ofp.OFPTT_ALL + cookie = cookie_mask = 0 + match = ofp_parser.OFPMatch() + req = ofp_parser.OFPFlowStatsRequest(datapath, 0, + table, + ofp.OFPP_ANY, ofp.OFPG_ANY, + cookie, cookie_mask, + match) + datapath.send_msg(req) + + def _handle_icmp(self, datapath, port, pkt_ethernet, pkt_ipv4, pkt_icmp): + if pkt_icmp.type != icmp.ICMP_ECHO_REQUEST: + return + pkt = packet.Packet() + pkt.add_protocol(ethernet.ethernet(ethertype=ether.ETH_TYPE_IP, + dst=pkt_ethernet.src, + src=pkt_ethernet.dst)) + pkt.add_protocol(ipv4.ipv4(dst=pkt_ipv4.src, + src=pkt_ipv4.dst, + proto=pkt_ipv4.proto)) + pkt.add_protocol(icmp.icmp(type_=icmp.ICMP_ECHO_REPLY, + code=icmp.ICMP_ECHO_REPLY_CODE, + csum=0, + data=pkt_icmp.data)) + self._send_packet(datapath, port, pkt) + + def check_direct_routing(self, tenant, from_subnet_id, to_subnet_id): + #from_subnet_cidr = from_subnet_id['cidr'] + #to_subnet_cidr = to_subnet_id['cidr'] + #split = m_subnet_cidr.split(""/"") + return + + def get_subnet_from_cidr(self, cidr): + split = cidr.split(""/"") + return (split[0], split[1]) + +# Base static + + +def ipv4_apply_mask(address, prefix_len, err_msg=None): + # import itertools + assert isinstance(address, str) + address_int = ipv4_text_to_int(address) + return ipv4_int_to_text(address_int & mask_ntob(prefix_len, err_msg)) + + +def ipv4_text_to_int(ip_text): + if ip_text == 0: + return ip_text + assert isinstance(ip_text, str) + return struct.unpack('!I', addrconv.ipv4.text_to_bin(ip_text))[0] + + +def ipv4_int_to_text(ip_int): + assert isinstance(ip_int, (int, long)) + return addrconv.ipv4.bin_to_text(struct.pack('!I', ip_int)) + + +def mask_ntob(mask, err_msg=None): + try: + return (UINT32_MAX << (32 - mask)) & UINT32_MAX + except ValueError: + msg = 'illegal netmask' + if err_msg is not None: + msg = '%s %s' % (err_msg, msg) + raise ValueError(msg) diff --git a/neutron/tests/unit/openvswitch/test_ovs_tunnel.py b/neutron/tests/unit/openvswitch/test_ovs_tunnel.py index ee020d8..3035f2b 100644 --- a/neutron/tests/unit/openvswitch/test_ovs_tunnel.py +++ b/neutron/tests/unit/openvswitch/test_ovs_tunnel.py @@ -147,6 +147,7 @@ class TunnelTest(base.BaseTestCase): self.mock_int_bridge_expected = [ mock.call.create(), mock.call.set_secure_mode(), + mock.call.del_controller(), mock.call.delete_port('patch-tun'), mock.call.remove_all_flows(), mock.call.add_flow(priority=1, actions='normal'), @@ -571,6 +572,7 @@ class TunnelTestUseVethInterco(TunnelTest): self.mock_int_bridge_expected = [ mock.call.create(), mock.call.set_secure_mode(), + mock.call.del_controller(), mock.call.delete_port('patch-tun'), mock.call.remove_all_flows(), mock.call.add_flow(priority=1, actions='normal'), -- 2.1.0 From 9eca2a7c519a562779f97ebf0b4ac75308cbf07e Mon Sep 17 00:00:00 2001 From: Eran Gampel <Eran.Gampel@Huawei.com> Date: Sun, 7 Dec 2014 18:05:58 +0200 Subject: [PATCH 2/8] First move toward MetaDat and not local vlan Change-Id: Ia2c075b1bf7a310fe824cf433e971a29ab05e09a --- neutron/services/l3_router/l3_reactive_app.py | 51 +++++++++++++++++++++------ 1 file changed, 40 insertions(+), 11 deletions(-) diff --git a/neutron/services/l3_router/l3_reactive_app.py b/neutron/services/l3_router/l3_reactive_app.py index 3dcd928..9867e21 100755 --- a/neutron/services/l3_router/l3_reactive_app.py +++ b/neutron/services/l3_router/l3_reactive_app.py @@ -47,7 +47,7 @@ from neutron.plugins.ml2 import driver_api as api from neutron import context from neutron import manager from neutron.plugins.common import constants as service_constants - +import ipdb LOG = log.getLogger(__name__) @@ -548,7 +548,6 @@ class L3ReactiveApp(app_manager.RyuApp): parser = datapath.ofproto_parser ofproto = datapath.ofproto match = parser.OFPMatch() - # BUG in the Ryu lib constructor match do not work match.set_dl_type(0x0800) match.set_in_port(in_port) match.set_dl_src(haddr_to_bin(match_src_mac)) @@ -600,19 +599,21 @@ class L3ReactiveApp(app_manager.RyuApp): priority=priority, match=match) - def add_flow_normal_local_subnet( - self, datapath, table, priority, dst_net, dst_mask, vlan_id): + def add_flow_normal_local_subnet(self, datapath, table, priority, + dst_net, dst_mask, vlan_id): + ipdb.set_trace() parser = datapath.ofproto_parser ofproto = datapath.ofproto #match = parser.OFPMatch(vlan_vid=0x1000| vlan_id) - match = parser.OFPMatch(vlan_vid=0x1000 | vlan_id) - match.set_dl_type(0x0800) - match.set_vlan_vid(0x1000 | vlan_id) + match = parser.OFPMatch() + match.set_dl_type( ether.ETH_TYPE_IP) + #match.set_vlan_vid(0x1000 | vlan_id) + match.set_metadata(vlan_id) match.set_ipv4_dst_masked(ipv4_text_to_int(str(dst_net)), mask_ntob(int(dst_mask))) #match = parser.OFPMatch(vlan_pcp=0) actions = [ - parser.OFPActionPopVlan(), + #parser.OFPActionPopVlan(), parser.OFPActionOutput( ofproto.OFPP_NORMAL)] # actions = [parser.OFPActionOutput(ofproto.OFPP_NORMAL, @@ -643,8 +644,26 @@ class L3ReactiveApp(app_manager.RyuApp): priority=priority, match=match) - def add_flow_push_vlan_by_port_num( - self, datapath, table, priority, in_port, dst_vlan, goto_table): + def add_flow_metadata_by_port_num(self, datapath, table, priority, + in_port, metadata, + metadata_mask, goto_table): + parser = datapath.ofproto_parser + ofproto = datapath.ofproto + match = parser.OFPMatch() + match.set_in_port(in_port) + goto_inst = parser.OFPInstructionGotoTable(goto_table) + ofproto = datapath.ofproto + write_metadata = parser.OFPInstructionWriteMetadata(metadata,metadata_mask) + inst = [write_metadata, goto_inst] + self.mod_flow( + datapath, + inst=inst, + table_id=table, + priority=priority, + match=match) + + def add_flow_push_vlan_by_port_num(self, datapath, table, priority, + in_port, dst_vlan, goto_table): parser = datapath.ofproto_parser ofproto = datapath.ofproto match = parser.OFPMatch() @@ -962,16 +981,26 @@ class L3ReactiveApp(app_manager.RyuApp): # data with the port num and the switch dpid (port_id, mac, segmentation_id) = self.update_local_port_num( port.name, port.port_no, datapath.id) + self.add_flow_metadata_by_port_num(datapath, + 0, + HIGH_PRIOREITY_FLOW, + port.port_no, + segmentation_id, + 0xffff, + self.CLASSIFIER_TABLE) + vlan_id = self.get_l_vid_from_seg_id(switch, segmentation_id) LOG.debug((""Found VM port %s using MAC %s %d""), port.name, port.hw_addr, datapath.id) if vlan_id: - self.add_flow_push_vlan_by_port_num(datapath, + '''self.add_flow_push_vlan_by_port_num(datapath, 0, HIGH_PRIOREITY_FLOW, port.port_no, vlan_id, self.CLASSIFIER_TABLE) + ''' + else: LOG.error((""No local switch vlan mapping for port"" "" %s on %d Sending to Normal PATH ""), -- 2.1.0 From 710cf49db58994935f9a4f38616a4ec4370111d4 Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Sun, 11 Jan 2015 09:53:58 +0200 Subject: [PATCH 3/8] merge Change-Id: Ie9dbe45c1568ab8366f25ca523f14220b5d2a487 --- neutron/common/topics.py | 2 +- .../plugins/openvswitch/agent/ovs_neutron_agent.py | 23 +- .../services/l3_router/README.l3_cont_dvr_plugin | 64 +++- neutron/services/l3_router/l3_cont_dvr_plugin.py | 6 +- neutron/services/l3_router/l3_reactive_app.py | 368 ++++++++++----------- 5 files changed, 244 insertions(+), 219 deletions(-) diff --git a/neutron/common/topics.py b/neutron/common/topics.py index 9bb1956..3ec424f 100644 --- a/neutron/common/topics.py +++ b/neutron/common/topics.py @@ -19,7 +19,7 @@ PORT = 'port' SECURITY_GROUP = 'security_group' L2POPULATION = 'l2population' DVR = 'dvr' - +SDNCONTROLLER='sdncontrol' CREATE = 'create' DELETE = 'delete' UPDATE = 'update' diff --git a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py index dce7feb..0013280 100644 --- a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py +++ b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py @@ -192,7 +192,6 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, # Keep track of int_br's device count for use by _report_state() self.int_br_device_count = 0 - self.local_vlan_map = {} # Initialize controller Ip List self.controllers_ip_list = None ''' @@ -211,6 +210,7 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, self.setup_rpc() self.bridge_mappings = bridge_mappings self.setup_physical_bridges(self.bridge_mappings) + self.local_vlan_map = {} self.tun_br_ofports = {p_const.TYPE_GRE: {}, p_const.TYPE_VXLAN: {}} @@ -305,6 +305,10 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, if self.l2_pop: consumers.append([topics.L2POPULATION, topics.UPDATE, cfg.CONF.host]) + if self.enable_l3_controller: + consumers.append([topics.SDNCONTROLLER, + topics.UPDATE]) + self.connection = agent_rpc.create_consumers(self.endpoints, self.topic, consumers, @@ -504,7 +508,7 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, br.add_flow(table=table_id, priority=100, proto='arp', - dl_vlan=local_vid, + metadata=segmentation_id, nw_dst='%s' % ip, actions=actions) elif action == 'remove': @@ -545,19 +549,9 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, bridge.add_flow(priority=0, actions=""normal"") bridge.add_flow(table=constants.CANARY_TABLE, priority=0, actions=""drop"") - self.update_metadata_vlan_map_table(bridge) bridge.set_controller_mode(""out-of-band"") self.set_controller_lock.release() - def update_metadata_vlan_map_table(self, bridge): - for net_id, vlan_mapping in self.local_vlan_map.iteritems(): - seg_id_hex = hex(vlan_mapping.segmentation_id) - bridge.add_flow(table=constants.BR_INT_METADATA_TABLE, - priority=100, - dl_vlan=vlan_mapping.vlan, - actions=""write_metadata:%s"" % - (seg_id_hex), protocols=""-OOpenFlow13"") - def provision_local_vlan(self, net_uuid, network_type, physical_network, segmentation_id): '''Provisions a local VLAN. @@ -753,8 +747,6 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, self.dvr_agent.bind_port_to_dvr(port, network_type, fixed_ips, device_owner, local_vlan_id=lvm.vlan) - if self.enable_l3_controller: - self.update_metadata_vlan_map_table(self.int_br) # Do not bind a port if it's already bound cur_tag = self.int_br.db_get_val(""Port"", port.port_name, ""tag"") if cur_tag != str(lvm.vlan): @@ -1447,7 +1439,8 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, port_info.get('removed') or port_info.get('updated')) - def check_ovs_status(self): + def check_ovs_restart(self): + # Check for the canary flow # Sync lock for race condition with set_controller self.set_controller_lock.acquire() # Check for the canary flow diff --git a/neutron/services/l3_router/README.l3_cont_dvr_plugin b/neutron/services/l3_router/README.l3_cont_dvr_plugin index e02efa6..b5b9469 100644 --- a/neutron/services/l3_router/README.l3_cont_dvr_plugin +++ b/neutron/services/l3_router/README.l3_cont_dvr_plugin @@ -1,11 +1,11 @@ ####### -In order to enable Neutron Controlle-based DVR, you need to make the +In order to enable Neutron Controlle-based DVR, you need to make the following change in ``neutron.conf``: 1. Comment-out loading of the ``L3RouterPlugin`` - 2. Add the ``neutron.services.l3_router.l3_cont_dvr_plugin.ControllerL3ServicePlugin`` - to the service plugin list: + 2. Add the ``neutron.services.l3_router.l3_cont_dvr_plugin.ControllerL3ServicePlugin`` + to the service plugin list: **neutron.conf** @@ -17,7 +17,7 @@ In order to enable Neutron Controlle-based DVR, you need to make the 2. In addition, make the following change in ``ml2_conf.ini``: - * Set the ``enable_l3_controller`` to ``True``: + * Set the ``enable_l3_controller`` to ``True``: **ml2_conf.ini** @@ -25,17 +25,16 @@ In order to enable Neutron Controlle-based DVR, you need to make the :literal:`# enable_l3_controller = True` - 3. Deploy the **L3 Controller-based DVR Agent** on the Network Node 4. Deploy the **Public Network Agent** on *each* Compute node -5. Remove deployment of L3 Agent or DVR Agent +5. Remove deployment of L3 Agent or DVR Agent 6. Install Ryu on Network Node -% git clone git://github.com/osrg/ryu.git +% git clone git://github.com/osrg/ryu.git The current implementation is embedded into the service plugin. will be moved into a Agent based implementation of the controller. -Until we do that we will have to apply the following patch on ryu +Until we do that we will have to apply the following patch on ryu ryu/controller/controller.py and ryu/app/wsgi.py modify register_cli_opts to register_opts --- a/ryu/app/wsgi.py +++ b/ryu/app/wsgi.py @@ -60,4 +59,51 @@ index 23418f5..a5bcda2 100644 +CONF.register_opts([ -% cd ryu; python ./setup.py install +% cd ryu; python ./setup.py install + +For Tenant with two networks: +192.168.100.0/24 +VM1 :192.168.100.2 +VM3: 192.168.100.4 + + +192.168.200.0/24 +VM2:192.168.200.2 + + +On devstack one machine setup you will get following flows after boot strap +running the following command + +sudo ovs-ofctl dump-flows br-int + +NXST_FLOW reply (xid=0x4): + cookie=0x0, duration=9.970s, table=0, n_packets=0, n_bytes=0, idle_age=9, priority=1 actions=drop + cookie=0x0, duration=9.970s, table=0, n_packets=0, n_bytes=0, idle_age=9, priority=1000,in_port=10 actions=NORMAL + cookie=0x0, duration=9.970s, table=0, n_packets=0, n_bytes=0, idle_age=9, priority=1000,in_port=35 actions=NORMAL + cookie=0x0, duration=9.970s, table=0, n_packets=1, n_bytes=107, idle_age=4, priority=1000,in_port=30 actions=write_metadata:0xfa2/0xffff + cookie=0x0, duration=9.970s, table=0, n_packets=1, n_bytes=107, idle_age=7, priority=1000,in_port=6 actions=write_metadata:0xfa2/0xffff + cookie=0x0, duration=9.970s, table=0, n_packets=0, n_bytes=0, idle_age=9, priority=1000,in_port=1 actions=NORMAL + cookie=0x0, duration=9.970s, table=0, n_packets=0, n_bytes=0, idle_age=9, priority=1000,in_port=5 actions=NORMAL + cookie=0x0, duration=9.970s, table=0, n_packets=22, n_bytes=3974, idle_age=0, priority=1000,in_port=11 actions=write_metadata:0xfa3/0xffff + cookie=0x0, duration=10.804s, table=23, n_packets=0, n_bytes=0, idle_age=10, priority=0 actions=drop + cookie=0x0, duration=9.970s, table=40, n_packets=0, n_bytes=0, idle_age=9, priority=1 actions=drop + cookie=0x0, duration=9.977s, table=40, n_packets=24, n_bytes=4188, idle_age=0, priority=10,dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=drop + cookie=0x0, duration=9.977s, table=40, n_packets=0, n_bytes=0, idle_age=9, priority=100,dl_dst=ff:ff:ff:ff:ff:ff actions=drop + cookie=0x0, duration=9.977s, table=40, n_packets=0, n_bytes=0, idle_age=9, priority=10,arp actions=drop + cookie=0x0, duration=9.977s, table=51, n_packets=24, n_bytes=4188, idle_age=0, priority=1 actions=NORMAL + cookie=0x0, duration=9.817s, table=51, n_packets=0, n_bytes=0, idle_age=9, priority=100,arp,metadata=0xfa3,arp_tpa=192.168.200.1 actions=strip_vlan,move:NXM_OF_ETH_SRC[]->NXM_OF_ETH_DST[],mod_dl_src:fa:16:3e:e9:74:9c,load:0x2->NXM_OF_ARP_OP[],move:NXM_NX_ARP_SHA[]->NXM_NX_ARP_THA[],move:NXM_OF_ARP_SPA[]->NXM_OF_ARP_TPA[],load:0xfa163ee9749c->NXM_NX_ARP_SHA[],load:0xc0a8c801->NXM_OF_ARP_SPA[],IN_PORT + cookie=0x0, duration=9.812s, table=51, n_packets=0, n_bytes=0, idle_age=9, priority=100,arp,metadata=0xfa2,arp_tpa=192.168.100.1 actions=strip_vlan,move:NXM_OF_ETH_SRC[]->NXM_OF_ETH_DST[],mod_dl_src:fa:16:3e:6f:f6:6e,load:0x2->NXM_OF_ARP_OP[],move:NXM_NX_ARP_SHA[]->NXM_NX_ARP_THA[],move:NXM_OF_ARP_SPA[]->NXM_OF_ARP_TPA[],load:0xfa163e6ff66e->NXM_NX_ARP_SHA[],load:0xc0a86401->NXM_OF_ARP_SPA[],IN_PORT + cookie=0x0, duration=9.966s, table=52, n_packets=0, n_bytes=0, idle_age=9, priority=99,metadata=0xfa2,dl_dst=fa:16:3e:6f:f6:6e actions=CONTROLLER:65535 + cookie=0x0, duration=9.970s, table=52, n_packets=0, n_bytes=0, idle_age=9, priority=99,metadata=0xfa3,dl_dst=fa:16:3e:e9:74:9c actions=CONTROLLER:65535 + cookie=0x0, duration=9.970s, table=52, n_packets=0, n_bytes=0, idle_age=9, priority=0 actions=CONTROLLER:65535 + cookie=0x0, duration=9.967s, table=52, n_packets=0, n_bytes=0, idle_age=9, priority=10,ip,metadata=0xfa2,nw_dst=192.168.100.0/24 actions=NORMAL + cookie=0x0, duration=9.970s, table=52, n_packets=0, n_bytes=0, idle_age=9, priority=10,ip,metadata=0xfa3,nw_dst=192.168.200.0/24 actions=NORMAL + + + +After ping from VM1 to VM3 you will get the following additional flows on table 52 + + sudo ovs-ofctl dump-flows br-int + + cookie=0x0, duration=3.606s, table=52, n_packets=0, n_bytes=0, idle_age=3, priority=100,ip,metadata=0xfa2,in_port=6,dl_src=fa:16:3e:59:a5:7e,dl_dst=fa:16:3e:6f:f6:6e,nw_src=192.168.100.2,nw_dst=192.168.200.2 actions=dec_ttl(0),mod_dl_src:fa:16:3e:e9:74:9c,mod_dl_dst:fa:16:3e:6b:e4:97,output:11 + cookie=0x0, duration=3.606s, table=52, n_packets=1, n_bytes=98, idle_age=3, priority=100,ip,metadata=0xfa3,in_port=11,dl_src=fa:16:3e:6b:e4:97,dl_dst=fa:16:3e:e9:74:9c,nw_src=192.168.200.2,nw_dst=192.168.100.2 actions=dec_ttl(0),mod_dl_src:fa:16:3e:6f:f6:6e,mod_dl_dst:fa:16:3e:59:a5:7e,output:6 diff --git a/neutron/services/l3_router/l3_cont_dvr_plugin.py b/neutron/services/l3_router/l3_cont_dvr_plugin.py index e449e6f..eae96dd 100755 --- a/neutron/services/l3_router/l3_cont_dvr_plugin.py +++ b/neutron/services/l3_router/l3_cont_dvr_plugin.py @@ -222,9 +222,9 @@ class ControllerL3ServicePlugin(common_db_mixin.CommonDbMixin, agent_id, ip_address, host) - self.send_set_controllers_upadte(_context, False) + self.send_set_controllers_update(_context, False) - def send_set_controllers_upadte(self, _context, force_reconnect): + def send_set_controllers_update(self, _context, force_reconnect): topic_port_update = topics.get_topic_name(topics.AGENT, topics.PORT, @@ -289,7 +289,7 @@ class ControllerRunner(threading.Thread): if self.sync_all: l3plugin = manager.NeutronManager.get_service_plugins().get( constants.L3_ROUTER_NAT) - l3plugin.send_set_controllers_upadte(self.ctx, True) + l3plugin.send_set_controllers_update(self.ctx, True) self.sync_all = False plugin = manager.NeutronManager.get_plugin() plugin.create_or_update_agent(self.ctx, self.agent_state) diff --git a/neutron/services/l3_router/l3_reactive_app.py b/neutron/services/l3_router/l3_reactive_app.py index 9867e21..a12f90f 100755 --- a/neutron/services/l3_router/l3_reactive_app.py +++ b/neutron/services/l3_router/l3_reactive_app.py @@ -27,6 +27,7 @@ from ryu.controller.handler import set_ev_cls from ryu.controller import ofp_event from ryu.ofproto import ether from ryu.ofproto.ether import ETH_TYPE_8021Q +from ryu.ofproto import nx_match from ryu.ofproto import ofproto_v1_3 from ryu.lib.packet import ethernet @@ -192,8 +193,9 @@ class L3ReactiveApp(app_manager.RyuApp): for dpid in self.dp_list: datapath = self.dp_list[dpid].datapath self.send_features_request(datapath) - self.send_flow_stats_request( - datapath, table=self.METADATA_TABLE_ID) + self.send_port_desc_stats_request(datapath) + #self.send_flow_stats_request( + # datapath, table=self.METADATA_TABLE_ID) def sync_data(self): self.logger.info("" l3_reactive_app sync router data "") @@ -349,129 +351,120 @@ class L3ReactiveApp(app_manager.RyuApp): eth): pkt_ipv4 = header_list['ipv4'] pkt_ethernet = header_list['ethernet'] - - # Check vlan-tag - if VLAN in header_list: - vlan_id = header_list[VLAN].vid - self.logger.info(""handle_ipv4_packet_in:: VLANID %s "", vlan_id) - switch = self.dp_list.get(datapath.id) - if switch: - if vlan_id not in switch.local_vlan_mapping: - # send request for loacl switch data - # self.send_port_desc_stats_request(datapath) - self.send_flow_stats_request( - datapath, table=self.METADATA_TABLE_ID) - LOG.error((""No local switch vlan mapping for vlan %s""), - vlan_id) - return - self.logger.info( - ""packet segmentation_id %s "", - switch.local_vlan_mapping[vlan_id]) - segmentation_id = switch.local_vlan_mapping[vlan_id] - for tenantid in self.tenants: - tenant = self.tenants[tenantid] - for router in tenant.routers: - for subnet in router.subnets: - if segmentation_id == subnet.segmentation_id: - self.logger.info(""packet from to tenant %s "", - tenant.tenant_id) - in_port_data = self.tenants[ - tenantid].mac_to_port_data[eth.src] - out_port_data = self.tenants[ - tenantid].mac_to_port_data[eth.dst] - LOG.debug(('Source port data <--- %s ', - in_port_data)) - LOG.debug(('Router Mac dest port data -> %s ', - out_port_data)) - if self.handle_router_interface(datapath, - in_port, - out_port_data, - pkt, - pkt_ethernet, - pkt_ipv4) == 1: - # trafic to the virtual routre handle only - # ping - return - (dst_p_data, - dst_sub_id) = self.get_port_data(tenant, - pkt_ipv4.dst) - for _subnet in router.subnets: - if dst_sub_id == _subnet.data['id']: - out_subnet = _subnet - subnet_gw = out_subnet.data[ - 'gateway_ip'] - - (dst_gw_port_data, - dst_gw_sub_id) = self.get_port_data( - tenant, subnet_gw) - - if self.handle_router_interface( - datapath, - in_port, - dst_gw_port_data, - pkt, - pkt_ethernet, - pkt_ipv4) == 1: - # this trafic to the virtual routre - return - if not dst_p_data: - LOG.error((""No local switch"" - ""mapping for %s""), - pkt_ipv4.dst) - return - if self.handle_router_interface( - datapath, - in_port, - dst_p_data, - pkt, - pkt_ethernet, - pkt_ipv4) != -1: - # case for vrouter that is not the - #gw and we are trying to ping - # this trafic to the virtual routre - return - - LOG.debug((""Route from %s to %s"" - ""exist installing flow "", - pkt_ipv4.src, - pkt_ipv4.dst)) - dst_vlan = self.get_l_vid_from_seg_id( - switch, - out_subnet.segmentation_id) - self.install_l3_forwarding_flows( + #ipdb.set_trace() + switch = self.dp_list.get(datapath.id) + if switch: + if 'metadata' not in msg.match: + # send request for loacl switch data + # self.send_port_desc_stats_request(datapath) + #self.send_flow_stats_request( + # datapath, table=self.METADATA_TABLE_ID) + LOG.error((""No metadata on packet from %s""), + eth.src) + return + segmentation_id = msg.match['metadata'] + self.logger.info( + ""packet segmentation_id %s "", + segmentation_id) + for tenantid in self.tenants: + tenant = self.tenants[tenantid] + for router in tenant.routers: + for subnet in router.subnets: + if segmentation_id == subnet.segmentation_id: + self.logger.info(""packet from to tenant %s "", + tenant.tenant_id) + in_port_data = self.tenants[ + tenantid].mac_to_port_data[eth.src] + out_port_data = self.tenants[ + tenantid].mac_to_port_data[eth.dst] + LOG.debug(('Source port data <--- %s ', + in_port_data)) + LOG.debug(('Router Mac dest port data -> %s ', + out_port_data)) + if self.handle_router_interface(datapath, + in_port, + out_port_data, + pkt, + pkt_ethernet, + pkt_ipv4) == 1: + # trafic to the virtual routre handle only + # ping + return + (dst_p_data, + dst_sub_id) = self.get_port_data(tenant, + pkt_ipv4.dst) + for _subnet in router.subnets: + if dst_sub_id == _subnet.data['id']: + out_subnet = _subnet + subnet_gw = out_subnet.data[ + 'gateway_ip'] + + (dst_gw_port_data, + dst_gw_sub_id) = self.get_port_data( + tenant, subnet_gw) + + if self.handle_router_interface( datapath, - msg, - in_port_data, in_port, - vlan_id, - eth, - pkt_ipv4, dst_gw_port_data, + pkt, + pkt_ethernet, + pkt_ipv4) == 1: + # this trafic to the virtual routre + return + if not dst_p_data: + LOG.error((""No local switch"" + ""mapping for %s""), + pkt_ipv4.dst) + return + if self.handle_router_interface( + datapath, + in_port, dst_p_data, - dst_vlan) + pkt, + pkt_ethernet, + pkt_ipv4) != -1: + # case for vrouter that is not the + #gw and we are trying to ping + # this trafic to the virtual routre return - def install_l3_forwarding_flows( - self, - datapath, - msg, - in_port_data, - in_port, - vlan_id, - eth, - pkt_ipv4, - dst_gw_port_data, - dst_p_data, - dst_vlan): + LOG.debug((""Route from %s to %s"" + ""exist installing flow "", + pkt_ipv4.src, + pkt_ipv4.dst)) + self.install_l3_forwarding_flows( + datapath, + msg, + in_port_data, + in_port, + segmentation_id, + eth, + pkt_ipv4, + dst_gw_port_data, + dst_p_data, + out_subnet.segmentation_id) + return + + def install_l3_forwarding_flows(self, + datapath, + msg, + in_port_data, + in_port, + src_seg_id, + eth, + pkt_ipv4, + dst_gw_port_data, + dst_p_data, + dst_seg_id): if dst_p_data['local_dpid_switch'] == datapath.id: # The dst VM and the source VM are on the same copute Node # Send output flow directly to port iuse the same datapath - actions = self.add_flow_subnet_traffic( - datapath, + actions = self.add_flow_subnet_traffic(datapath, self.L3_VROUTER_TABLE, MEDIUM_PRIOREITY_FLOW, in_port, - vlan_id, + src_seg_id, eth.src, eth.dst, pkt_ipv4.dst, @@ -479,12 +472,12 @@ class L3ReactiveApp(app_manager.RyuApp): dst_gw_port_data['mac_address'], dst_p_data['mac_address'], dst_p_data['local_port_num']) - # Install the reverse flow return traffic + # Install the reverse flow return traffic self.add_flow_subnet_traffic(datapath, self.L3_VROUTER_TABLE, MEDIUM_PRIOREITY_FLOW, dst_p_data['local_port_num'], - dst_vlan, + dst_seg_id, dst_p_data['mac_address'], dst_gw_port_data['mac_address'], pkt_ipv4.src, @@ -503,7 +496,7 @@ class L3ReactiveApp(app_manager.RyuApp): self.L3_VROUTER_TABLE, MEDIUM_PRIOREITY_FLOW, in_port, - vlan_id, + src_seg_id, eth.src, eth.dst, pkt_ipv4.dst, @@ -513,13 +506,13 @@ class L3ReactiveApp(app_manager.RyuApp): dst_p_data[ 'mac_address'], localSwitch.patch_port, - dst_vlan) + dst_seg_id=dst_seg_id) # Remote reverse flow install self.add_flow_subnet_traffic(remoteSwitch.datapath, self.L3_VROUTER_TABLE, MEDIUM_PRIOREITY_FLOW, dst_p_data['local_port_num'], - dst_vlan, + dst_seg_id, dst_p_data['mac_address'], dst_gw_port_data['mac_address'], pkt_ipv4.src, @@ -527,7 +520,7 @@ class L3ReactiveApp(app_manager.RyuApp): eth.dst, in_port_data['mac_address'], in_port_data['local_port_num'], - vlan_id) + dst_seg_id=src_seg_id) self.handle_packet_out_l3(datapath, msg, in_port, actions) def handle_packet_out_l3(self, datapath, msg, in_port, actions): @@ -542,31 +535,28 @@ class L3ReactiveApp(app_manager.RyuApp): datapath.send_msg(out) def add_flow_subnet_traffic(self, datapath, table, priority, in_port, - match_vlan, match_src_mac, match_dst_mac, + src_seg_id, match_src_mac, match_dst_mac, match_dst_ip, match_src_ip, src_mac, - dst_mac, out_port_num, dst_vlan=None): + dst_mac, out_port_num, dst_seg_id=None): parser = datapath.ofproto_parser ofproto = datapath.ofproto match = parser.OFPMatch() - match.set_dl_type(0x0800) + match.set_dl_type( ether.ETH_TYPE_IP) match.set_in_port(in_port) + match.set_metadata(src_seg_id) match.set_dl_src(haddr_to_bin(match_src_mac)) match.set_dl_dst(haddr_to_bin(match_dst_mac)) match.set_ipv4_src(ipv4_text_to_int(str(match_src_ip))) match.set_ipv4_dst(ipv4_text_to_int(str(match_dst_ip))) - match.set_vlan_vid(0x1000 | match_vlan) - actions = [parser.OFPActionPopVlan()] + actions = [] + if dst_seg_id: + field = parser.OFPActionSetField(tunnel_id=dst_seg_id) + actions.append(parser.OFPActionSetField(field)) actions.append(parser.OFPActionDecNwTtl()) actions.append(parser.OFPActionSetField(eth_src=src_mac)) actions.append(parser.OFPActionSetField(eth_dst=dst_mac)) actions.append(parser.OFPActionOutput(out_port_num, ofproto.OFPCML_NO_BUFFER)) - if dst_vlan: - field = parser.OFPMatchField.make( - ofproto.OXM_OF_VLAN_VID, dst_vlan) - actions.append(parser.OFPActionPushVlan(ETH_TYPE_8021Q)) - actions.append(parser.OFPActionSetField(field)) - ofproto = datapath.ofproto inst = [datapath.ofproto_parser.OFPInstructionActions( ofproto.OFPIT_APPLY_ACTIONS, actions)] @@ -600,15 +590,14 @@ class L3ReactiveApp(app_manager.RyuApp): match=match) def add_flow_normal_local_subnet(self, datapath, table, priority, - dst_net, dst_mask, vlan_id): - ipdb.set_trace() + dst_net, dst_mask, seg_id): parser = datapath.ofproto_parser ofproto = datapath.ofproto #match = parser.OFPMatch(vlan_vid=0x1000| vlan_id) match = parser.OFPMatch() match.set_dl_type( ether.ETH_TYPE_IP) #match.set_vlan_vid(0x1000 | vlan_id) - match.set_metadata(vlan_id) + match.set_metadata(seg_id) match.set_ipv4_dst_masked(ipv4_text_to_int(str(dst_net)), mask_ntob(int(dst_mask))) #match = parser.OFPMatch(vlan_pcp=0) @@ -706,13 +695,12 @@ class L3ReactiveApp(app_manager.RyuApp): instructions) datapath.send_msg(flow_mod) - def add_flow_normal(self, datapath, table, priority): + def add_flow_normal(self, datapath, table, priority, match=None): parser = datapath.ofproto_parser ofproto = datapath.ofproto - match = parser.OFPMatch(vlan_vid=0x1000) + #match = parser.OFPMatch(vlan_vid=0x1000) #match = parser.OFPMatch(vlan_pcp=0) actions = [ - parser.OFPActionPopVlan(), parser.OFPActionOutput( ofproto.OFPP_NORMAL)] ofproto = datapath.ofproto @@ -831,12 +819,11 @@ class L3ReactiveApp(app_manager.RyuApp): match=match) def add_flow_match_gw_mac_to_cont(self, datapath, dst_mac, table, - priority, vlan_vid=None, + priority, seg_id=None, _actions=None): parser = datapath.ofproto_parser #ofproto = datapath.ofproto - vlan_id = 0x1000 | vlan_vid - match = parser.OFPMatch(eth_dst=dst_mac, vlan_vid=vlan_id) + match = parser.OFPMatch(eth_dst=dst_mac, metadata=seg_id) self.add_flow_match_to_controller( datapath, table, priority, match=match, _actions=_actions) @@ -899,8 +886,9 @@ class L3ReactiveApp(app_manager.RyuApp): switch = self.dp_list.get(datapath.id) if switch: - self.send_flow_stats_request( - datapath, table=self.METADATA_TABLE_ID) + self.send_port_desc_stats_request(datapath) + # self.send_flow_stats_request( + # datapath, table=self.METADATA_TABLE_ID) @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER) def switch_features_handler(self, ev): @@ -917,7 +905,8 @@ class L3ReactiveApp(app_manager.RyuApp): time.sleep(1) # sleep during 500ms LOG.info((""Done Wait .. will retry if meta table not set "")) - self.send_flow_stats_request(datapath, table=self.METADATA_TABLE_ID) + self.send_port_desc_stats_request(datapath) + #self.send_flow_stats_request(datapath, table=self.METADATA_TABLE_ID) # --> meta #self.add_flow_go_to_table2(datapath, 0, 1 ,self.L3_VROUTER_TABLE) # main table 0 to Arp On ARp or broadcat or multicast @@ -937,10 +926,6 @@ class L3ReactiveApp(app_manager.RyuApp): NORMAL_PRIOREITY_FLOW, self.ARP_AND_BR_TABLE) - # Meta Table to L3 router table on all other trafic - self.add_flow_go_to_table2( - datapath, self.METADATA_TABLE_ID, 1, self.L3_VROUTER_TABLE) - # Normal flow on arp table in low priorety self.add_flow_normal(datapath, self.ARP_AND_BR_TABLE, 1) #del l3plugin @@ -992,14 +977,13 @@ class L3ReactiveApp(app_manager.RyuApp): vlan_id = self.get_l_vid_from_seg_id(switch, segmentation_id) LOG.debug((""Found VM port %s using MAC %s %d""), port.name, port.hw_addr, datapath.id) - if vlan_id: - '''self.add_flow_push_vlan_by_port_num(datapath, + '''if vlan_id: + self.add_flow_push_vlan_by_port_num(datapath, 0, HIGH_PRIOREITY_FLOW, port.port_no, vlan_id, self.CLASSIFIER_TABLE) - ''' else: LOG.error((""No local switch vlan mapping for port"" @@ -1009,6 +993,7 @@ class L3ReactiveApp(app_manager.RyuApp): self.add_flow_normal_by_port_num(datapath, 0, HIGH_PRIOREITY_FLOW, port.port_no) + ''' elif ""patch-tun"" in port.name: LOG.debug((""Found br-tun patch port "" ""%s %s sending to NORMAL path""), @@ -1021,8 +1006,45 @@ class L3ReactiveApp(app_manager.RyuApp): switch.local_ports = ports self.add_flow_go_to_table2(datapath, 0, 1, self.CLASSIFIER_TABLE) self.add_flow_match_to_controller(datapath, self.L3_VROUTER_TABLE, 0) - self.add_flow_go_to_table2( - datapath, self.CLASSIFIER_TABLE, 1, self.L3_VROUTER_TABLE) + self.add_flow_go_to_table2(datapath, self.CLASSIFIER_TABLE, 1, + self.L3_VROUTER_TABLE) + l3plugin = manager.NeutronManager.get_service_plugins().get( + service_constants.L3_ROUTER_NAT) + + for tenantid in self.tenants: + for router in self.tenants[tenantid].routers: + for subnet in router.subnets: + for interface in router.data['_interfaces']: + if interface['subnet']['id'] == subnet.data['id']: + segmentation_id = subnet.segmentation_id + #vlan_id = self.get_l_vid_from_seg_id( + # switch, segmentation_id) + network, net_mask = self.get_subnet_from_cidr( + subnet.data['cidr']) + + self.add_flow_normal_local_subnet( + datapath, + self.L3_VROUTER_TABLE, + NORMAL_PRIOREITY_FLOW, + network, + net_mask, + segmentation_id) + + self.add_flow_match_gw_mac_to_cont( + datapath, + interface['mac_address'], + self.L3_VROUTER_TABLE, + 99, + segmentation_id) + l3plugin.setup_vrouter_arp_responder( + self.ctx, + ""br-int"", + ""add"", + self.ARP_AND_BR_TABLE, + segmentation_id, + interface['network_id'], + interface['mac_address'], + self.get_ip_from_router_interface(interface)) def send_features_request(self, datapath): ofp_parser = datapath.ofproto_parser @@ -1131,50 +1153,14 @@ class L3ReactiveApp(app_manager.RyuApp): l3plugin = manager.NeutronManager.get_service_plugins().get( service_constants.L3_ROUTER_NAT) switch = self.dp_list.get(datapath.id) - - for tenantid in self.tenants: - for router in self.tenants[tenantid].routers: - for subnet in router.subnets: - for interface in router.data['_interfaces']: - if interface['subnet']['id'] == subnet.data['id']: - segmentation_id = subnet.segmentation_id - vlan_id = self.get_l_vid_from_seg_id( - switch, segmentation_id) - network, net_mask = self.get_subnet_from_cidr( - subnet.data['cidr']) - - if vlan_id: - self.add_flow_normal_local_subnet( - datapath, - self.L3_VROUTER_TABLE, - NORMAL_PRIOREITY_FLOW, - network, - net_mask, - vlan_id) - - self.add_flow_match_gw_mac_to_cont( - datapath, - interface['mac_address'], - self.L3_VROUTER_TABLE, - 99, - vlan_id) - l3plugin.setup_vrouter_arp_responder( - self.ctx, - ""br-int"", - ""add"", - self.ARP_AND_BR_TABLE, - segmentation_id, - interface['network_id'], - interface['mac_address'], - self.get_ip_from_router_interface(interface)) - # No match on table L3_VROUTER_TABLE go to normal flow + # No match on table L3_VROUTER_TABLE go to normal flow # No match on table L3_VROUTER_TABLE go to controller # Patch to overcome OVS BUG not accepting match on tag vlans # set Pop per taged vlan - for local_vlan in switch.local_vlan_mapping: - self.add_flow_pop_vlan_to_normal( - datapath, self.ARP_AND_BR_TABLE, 1, local_vlan) + # for local_vlan in switch.local_vlan_mapping: + # self.add_flow_pop_vlan_to_normal( + # datapath, self.ARP_AND_BR_TABLE, 1, local_vlan) if not switch.local_vlan_mapping: LOG.error((""CRITICAL ERROR ***** Switch did not send local port"" -- 2.1.0 From b3845322c8faae72971d8d7f48e576ec0609451a Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Mon, 12 Jan 2015 18:05:20 +0200 Subject: [PATCH 4/8] merge Change-Id: I92566ffca502fcb3fa9d9ff323652e6933fd54cc --- neutron/plugins/openvswitch/agent/ovs_neutron_agent.py | 2 +- neutron/services/l3_router/l3_cont_dvr_plugin.py | 4 ++-- neutron/services/l3_router/l3_reactive_app.py | 3 +-- 3 files changed, 4 insertions(+), 5 deletions(-) diff --git a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py index 0013280..418032e 100644 --- a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py +++ b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py @@ -1439,7 +1439,7 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, port_info.get('removed') or port_info.get('updated')) - def check_ovs_restart(self): + def check_ovs_status(self): # Check for the canary flow # Sync lock for race condition with set_controller self.set_controller_lock.acquire() diff --git a/neutron/services/l3_router/l3_cont_dvr_plugin.py b/neutron/services/l3_router/l3_cont_dvr_plugin.py index eae96dd..d10e4e2 100755 --- a/neutron/services/l3_router/l3_cont_dvr_plugin.py +++ b/neutron/services/l3_router/l3_cont_dvr_plugin.py @@ -49,7 +49,7 @@ LOG = logging.getLogger(__name__) NET_CONTROL_L3_OPTS = [ cfg.StrOpt('L3controller_ip_list', - default='tcp:10.100.100.38:6633', + default='tcp:10.100.100.3:6633', help=(""L3 Controler IP list list tcp:ip_addr:port;"" ""tcp:ip_addr:port..;.."")), cfg.StrOpt('net_controller_l3_southbound_protocol', @@ -79,7 +79,7 @@ class ControllerL3ServicePlugin(common_db_mixin.CommonDbMixin, self.start_periodic_agent_status_check() if cfg.CONF.net_controller_l3_southbound_protocol == ""OpenFlow"": # Open Flow Controller - LOG.debug((""Using Southbound OpenFlow Protocol "")) + LOG.info((""Using Southbound OpenFlow Protocol "")) self.controllerThread = ControllerRunner(""openflow"") self.controllerThread.start() self.controllerThread.router_scheduler = self.router_scheduler diff --git a/neutron/services/l3_router/l3_reactive_app.py b/neutron/services/l3_router/l3_reactive_app.py index a12f90f..e37c449 100755 --- a/neutron/services/l3_router/l3_reactive_app.py +++ b/neutron/services/l3_router/l3_reactive_app.py @@ -48,7 +48,6 @@ from neutron.plugins.ml2 import driver_api as api from neutron import context from neutron import manager from neutron.plugins.common import constants as service_constants -import ipdb LOG = log.getLogger(__name__) @@ -181,6 +180,7 @@ class L3ReactiveApp(app_manager.RyuApp): self.dp_list = {} def start(self): + self.logger.info(""Starting Virtual L3 Reactive OpenFlow APP "") super(L3ReactiveApp, self).start() return 1 @@ -893,7 +893,6 @@ class L3ReactiveApp(app_manager.RyuApp): @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER) def switch_features_handler(self, ev): datapath = ev.msg.datapath - if self.need_sync: self.sync_data() switch = self.dp_list.get(datapath.id) -- 2.1.0 From 11f922622f8b4d59d1e857e3426a736653ab41b1 Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Sun, 25 Jan 2015 17:29:14 +0200 Subject: [PATCH 5/8] Fix cross Compute Node flow installation, order to communicate across virtual switch in the US we must use the mark action metadata and tunnel_id are removed from flow when sent to patch port Change-Id: Iab01fd387cb09a7bfdf0b99d38ce02fb3a9e1675 --- .../plugins/openvswitch/agent/ovs_neutron_agent.py | 12 +++++++ neutron/services/l3_router/l3_cont_dvr_plugin.py | 2 +- neutron/services/l3_router/l3_reactive_app.py | 38 +++++++++++++++------- 3 files changed, 39 insertions(+), 13 deletions(-) diff --git a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py index 418032e..3f6c012 100644 --- a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py +++ b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py @@ -549,6 +549,10 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, bridge.add_flow(priority=0, actions=""normal"") bridge.add_flow(table=constants.CANARY_TABLE, priority=0, actions=""drop"") + bridge.add_flow(table=""60"", priority=1, + actions=""move:NXM_NX_TUN_ID[0..31]->NXM_NX_PKT_MARK[],"" + ""output:%s"" % + (self.patch_tun_ofport)) bridge.set_controller_mode(""out-of-band"") self.set_controller_lock.release() @@ -943,6 +947,7 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, constants.FLOOD_TO_TUN) # FLOOD_TO_TUN will handle flooding in tunnels based on lvid, # for now, add a default drop action + self.tun_br.add_flow(table=constants.FLOOD_TO_TUN, priority=0, actions=""drop"") @@ -1164,6 +1169,13 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, dl_vlan=vlan_mapping.vlan, actions=""strip_vlan,set_tunnel:%s,output:%s"" % (vlan_mapping.segmentation_id, ofports)) + if self.enable_l3_controller: + if ofports: + br.add_flow(table=constants.FLOOD_TO_TUN, + actions=""move:NXM_NX_PKT_MARK[]->NXM_NX_TUN_ID[0..31],"" + ""output:%s"" % + (ofports)) + return ofport def setup_tunnel_port(self, br, remote_ip, network_type): diff --git a/neutron/services/l3_router/l3_cont_dvr_plugin.py b/neutron/services/l3_router/l3_cont_dvr_plugin.py index d10e4e2..5a27543 100755 --- a/neutron/services/l3_router/l3_cont_dvr_plugin.py +++ b/neutron/services/l3_router/l3_cont_dvr_plugin.py @@ -49,7 +49,7 @@ LOG = logging.getLogger(__name__) NET_CONTROL_L3_OPTS = [ cfg.StrOpt('L3controller_ip_list', - default='tcp:10.100.100.3:6633', + default='tcp:172.16.10.10:6633', help=(""L3 Controler IP list list tcp:ip_addr:port;"" ""tcp:ip_addr:port..;.."")), cfg.StrOpt('net_controller_l3_southbound_protocol', diff --git a/neutron/services/l3_router/l3_reactive_app.py b/neutron/services/l3_router/l3_reactive_app.py index e37c449..5f3bac2 100755 --- a/neutron/services/l3_router/l3_reactive_app.py +++ b/neutron/services/l3_router/l3_reactive_app.py @@ -48,7 +48,6 @@ from neutron.plugins.ml2 import driver_api as api from neutron import context from neutron import manager from neutron.plugins.common import constants as service_constants - LOG = log.getLogger(__name__) ETHERNET = ethernet.ethernet.__name__ @@ -351,7 +350,6 @@ class L3ReactiveApp(app_manager.RyuApp): eth): pkt_ipv4 = header_list['ipv4'] pkt_ethernet = header_list['ethernet'] - #ipdb.set_trace() switch = self.dp_list.get(datapath.id) if switch: if 'metadata' not in msg.match: @@ -505,7 +503,7 @@ class L3ReactiveApp(app_manager.RyuApp): 'mac_address'], dst_p_data[ 'mac_address'], - localSwitch.patch_port, + localSwitch.patch_port_num, dst_seg_id=dst_seg_id) # Remote reverse flow install self.add_flow_subnet_traffic(remoteSwitch.datapath, @@ -520,6 +518,7 @@ class L3ReactiveApp(app_manager.RyuApp): eth.dst, in_port_data['mac_address'], in_port_data['local_port_num'], + remoteSwitch.patch_port_num, dst_seg_id=src_seg_id) self.handle_packet_out_l3(datapath, msg, in_port, actions) @@ -543,29 +542,44 @@ class L3ReactiveApp(app_manager.RyuApp): match = parser.OFPMatch() match.set_dl_type( ether.ETH_TYPE_IP) match.set_in_port(in_port) - match.set_metadata(src_seg_id) + match.set_metadata(src_seg_id ) match.set_dl_src(haddr_to_bin(match_src_mac)) match.set_dl_dst(haddr_to_bin(match_dst_mac)) match.set_ipv4_src(ipv4_text_to_int(str(match_src_ip))) match.set_ipv4_dst(ipv4_text_to_int(str(match_dst_ip))) actions = [] + inst = [] + write_metadata = 0; + ofproto = datapath.ofproto if dst_seg_id: - field = parser.OFPActionSetField(tunnel_id=dst_seg_id) - actions.append(parser.OFPActionSetField(field)) + #The best vm is on another compute machine so we must set the + #segmentation Id and set metadata for the tunnel bridge to flood this packet + field = parser.OFPActionSetField(tunnel_id=dst_seg_id ) + actions.append(field) + goto_inst = parser.OFPInstructionGotoTable(60) + #field = parser.OFPActionSetField(metadata=0x8000) + #actions.append(field) + #write_metadata = parser.OFPInstructionWriteMetadata(0x8000,0x8000) + #inst= [write_metadata] + inst.append(goto_inst) + #inst.append(write_metadata) + else: + actions.append(parser.OFPActionOutput(out_port_num, + ofproto.OFPCML_NO_BUFFER)) actions.append(parser.OFPActionDecNwTtl()) actions.append(parser.OFPActionSetField(eth_src=src_mac)) actions.append(parser.OFPActionSetField(eth_dst=dst_mac)) - actions.append(parser.OFPActionOutput(out_port_num, - ofproto.OFPCML_NO_BUFFER)) - ofproto = datapath.ofproto - inst = [datapath.ofproto_parser.OFPInstructionActions( - ofproto.OFPIT_APPLY_ACTIONS, actions)] + #inst.append( datapath.ofproto_parser.OFPInstructionActions( + # ofproto.OFPIT_APPLY_ACTIONS, actions)) + inst.append(datapath.ofproto_parser.OFPInstructionActions( + ofproto.OFPIT_APPLY_ACTIONS, actions)) self.mod_flow( datapath, inst=inst, table_id=table, priority=priority, - match=match) + match=match, + out_port=out_port_num) return actions -- 2.1.0 From 12f5dfce0226f379f0931dc9a5b1cbb267df2d2e Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Sun, 25 Jan 2015 17:54:51 +0200 Subject: [PATCH 6/8] fix local cross subnet VMs Change-Id: Icf05940b56973b76fd2754dd59fef7af5acfff52 --- neutron/services/l3_router/l3_reactive_app.py | 8 ++++---- 1 file changed, 4 insertions(+), 4 deletions(-) diff --git a/neutron/services/l3_router/l3_reactive_app.py b/neutron/services/l3_router/l3_reactive_app.py index 5f3bac2..a9c23a3 100755 --- a/neutron/services/l3_router/l3_reactive_app.py +++ b/neutron/services/l3_router/l3_reactive_app.py @@ -551,6 +551,9 @@ class L3ReactiveApp(app_manager.RyuApp): inst = [] write_metadata = 0; ofproto = datapath.ofproto + actions.append(parser.OFPActionDecNwTtl()) + actions.append(parser.OFPActionSetField(eth_src=src_mac)) + actions.append(parser.OFPActionSetField(eth_dst=dst_mac)) if dst_seg_id: #The best vm is on another compute machine so we must set the #segmentation Id and set metadata for the tunnel bridge to flood this packet @@ -566,10 +569,7 @@ class L3ReactiveApp(app_manager.RyuApp): else: actions.append(parser.OFPActionOutput(out_port_num, ofproto.OFPCML_NO_BUFFER)) - actions.append(parser.OFPActionDecNwTtl()) - actions.append(parser.OFPActionSetField(eth_src=src_mac)) - actions.append(parser.OFPActionSetField(eth_dst=dst_mac)) - #inst.append( datapath.ofproto_parser.OFPInstructionActions( + #inst.append( datapath.ofproto_parser.OFPInstructionActions( # ofproto.OFPIT_APPLY_ACTIONS, actions)) inst.append(datapath.ofproto_parser.OFPInstructionActions( ofproto.OFPIT_APPLY_ACTIONS, actions)) -- 2.1.0 From c0fb88fcca7c657dcaa3a6bf1fd0d327b4c27500 Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Mon, 26 Jan 2015 11:21:26 +0200 Subject: [PATCH 7/8] send not forced connect message every 30 sec, temporary fix until we manage to detect new/restarted L2 agent Change-Id: I1189af681548d4adf406a7defa8feb082435de19 --- neutron/plugins/openvswitch/agent/ovs_neutron_agent.py | 4 ++-- neutron/services/l3_router/l3_cont_dvr_plugin.py | 7 ++++--- 2 files changed, 6 insertions(+), 5 deletions(-) diff --git a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py index 3f6c012..d7d19e1 100644 --- a/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py +++ b/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py @@ -814,8 +814,8 @@ class OVSNeutronAgent(sg_rpc.SecurityGroupAgentRpcCallbackMixin, # which does nothing if bridge already exists. self.int_br.create() self.int_br.set_secure_mode() - if not self.enable_l3_controller: - self.int_br.del_controller() + #if not self.enable_l3_controller: + self.int_br.del_controller() self.int_br.delete_port(cfg.CONF.OVS.int_peer_patch_port) self.int_br.remove_all_flows() # switch all traffic using L2 learning diff --git a/neutron/services/l3_router/l3_cont_dvr_plugin.py b/neutron/services/l3_router/l3_cont_dvr_plugin.py index 5a27543..d2cb029 100755 --- a/neutron/services/l3_router/l3_cont_dvr_plugin.py +++ b/neutron/services/l3_router/l3_cont_dvr_plugin.py @@ -43,7 +43,6 @@ from neutron.openstack.common import log as logging from neutron.openstack.common import loopingcall from neutron.services.l3_router.l3_reactive_app import L3ReactiveApp - LOG = logging.getLogger(__name__) @@ -286,11 +285,13 @@ class ControllerRunner(threading.Thread): self.heartbeat.start(interval=30) def _report_state_and_bind_routers(self): - if self.sync_all: - l3plugin = manager.NeutronManager.get_service_plugins().get( + l3plugin = manager.NeutronManager.get_service_plugins().get( constants.L3_ROUTER_NAT) + if self.sync_all: l3plugin.send_set_controllers_update(self.ctx, True) self.sync_all = False + else: + l3plugin.send_set_controllers_update(self.ctx, False) plugin = manager.NeutronManager.get_plugin() plugin.create_or_update_agent(self.ctx, self.agent_state) self.bind_unscheduled_routers() -- 2.1.0 From d61d29e1694fe25eac675fa835a2080a80cbb962 Mon Sep 17 00:00:00 2001 From: Eran Gampel <eran@gampel.net> Date: Mon, 26 Jan 2015 14:05:28 +0200 Subject: [PATCH 8/8] remove unnecessary changes Change-Id: Idbefcb2c793b13b9ac147fedf4b068cf3a11be8f --- neutron/agent/linux/ovs_lib.py | 27 +++++++++++---------------- 1 file changed, 11 insertions(+), 16 deletions(-) diff --git a/neutron/agent/linux/ovs_lib.py b/neutron/agent/linux/ovs_lib.py index f745cf3..707291f 100644 --- a/neutron/agent/linux/ovs_lib.py +++ b/neutron/agent/linux/ovs_lib.py @@ -138,7 +138,6 @@ class BaseOVS(object): class OVSBridge(BaseOVS): - def __init__(self, br_name, root_helper): super(OVSBridge, self).__init__(root_helper) self.br_name = br_name @@ -148,6 +147,11 @@ class OVSBridge(BaseOVS): vsctl_command.extend(controller_names) self.run_vsctl(vsctl_command, check_error=True) + def set_controller_mode(self, mode): + self.run_vsctl(['--', 'set', 'controller', self.br_name, + ""connection-mode=%s"" % mode], + check_error=True) + def del_controller(self): self.run_vsctl(['--', 'del-controller', self.br_name], check_error=True) @@ -159,11 +163,6 @@ class OVSBridge(BaseOVS): return res.strip().split('\n') return res - def set_controller_mode(self, mode): - self.run_vsctl(['--', 'set', 'controller', self.br_name, - ""connection-mode=%s"" % mode], - check_error=True) - def set_secure_mode(self): self.run_vsctl(['--', 'set-fail-mode', self.br_name, 'secure'], check_error=True) @@ -215,11 +214,8 @@ class OVSBridge(BaseOVS): args = [""clear"", table_name, record, column] self.run_vsctl(args) - def run_ofctl(self, cmd, args, process_input=None, protocols=None): - if protocols: - full_args = [""ovs-ofctl"", cmd, protocols, self.br_name] + args - else: - full_args = [""ovs-ofctl"", cmd, self.br_name] + args + def run_ofctl(self, cmd, args, process_input=None): + full_args = [""ovs-ofctl"", cmd, self.br_name] + args try: return utils.execute(full_args, root_helper=self.root_helper, process_input=process_input) @@ -254,13 +250,12 @@ class OVSBridge(BaseOVS): return self.db_get_val('Bridge', self.br_name, 'datapath_id').strip('""') - def do_action_flows(self, action, kwargs_list, protocols=None): + def do_action_flows(self, action, kwargs_list): flow_strs = [_build_flow_expr_str(kw, action) for kw in kwargs_list] - self.run_ofctl('%s-flows' % action, ['-'], '\n'.join(flow_strs), - protocols) + self.run_ofctl('%s-flows' % action, ['-'], '\n'.join(flow_strs)) - def add_flow(self, protocols=None, **kwargs): - self.do_action_flows('add', [kwargs], protocols) + def add_flow(self, **kwargs): + self.do_action_flows('add', [kwargs]) def mod_flow(self, **kwargs): self.do_action_flows('mod', [kwargs]) -- 2.1.0 ",0,3465
openstack%2Fdragonflow~master~I59af6db254039374276e70628be2515f70a7cfc5,openstack/dragonflow,master,I59af6db254039374276e70628be2515f70a7cfc5,Fix blogs links and add new Neutron DB consistency blog post,MERGED,2016-02-18 13:07:49.000000000,2016-02-18 17:00:38.000000000,2016-02-18 17:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 11343}, {'_account_id': 13070}]","[{'number': 1, 'created': '2016-02-18 13:07:49.000000000', 'files': ['doc/source/distributed_dragonflow.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c128c5e657b988eb1f985d9ed2a4ffc8db05692a', 'message': 'Fix blogs links and add new Neutron DB consistency blog post\n\nChange-Id: I59af6db254039374276e70628be2515f70a7cfc5\n'}]",0,281829,c128c5e657b988eb1f985d9ed2a4ffc8db05692a,7,3,1,11343,,,0,"Fix blogs links and add new Neutron DB consistency blog post

Change-Id: I59af6db254039374276e70628be2515f70a7cfc5
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/29/281829/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/distributed_dragonflow.rst'],1,c128c5e657b988eb1f985d9ed2a4ffc8db05692a,, <http://galsagie.github.io/2015/10/14/dragonflow-liberty/>`_ <http://galsagie.github.io/2015/08/03/df-distributed-db/>`_ <http://galsagie.github.io/2015/11/10/topology-service-injection/>`_ <http://galsagie.github.io/2015/12/28/dragonflow-security-groups/>`_ - `Neutron DB Consistency <http://galsagie.github.io/2016/02/14/neutron-db-consistency/>`_, <http://galsagie.github.io/sdn/openstack/ovs/dragonflow/2015/10/14/dragonflow-liberty/>`_ <http://galsagie.github.io/sdn/openstack/ovs/ovn/dragonflow/2015/08/03/df-distributed-db/>`_ <http://galsagie.github.io/sdn/nfv/openstack/ovs/dragonflow/2015/11/10/topology-service-injection/>`_ <http://galsagie.github.io/sdn/openstack/ovs/dragonflow/2015/12/28/dragonflow-security-groups/>`_,6,4
openstack%2Fpython-openstackclient~master~I142bd4114ba5d219dded11393a2732f5f7e575d0,openstack/python-openstackclient,master,I142bd4114ba5d219dded11393a2732f5f7e575d0,live migration on random host,ABANDONED,2015-01-15 10:37:56.000000000,2016-02-18 17:00:12.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 2472}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 11061}, {'_account_id': 11708}, {'_account_id': 14485}]","[{'number': 1, 'created': '2015-01-15 10:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c31804edf8af5d0adbd280822b742b8c480f9163', 'message': 'live migration on unspecified host\n\n  * allow specify empty host to use scheduler (should I make --target\n    option?)\n  * fix confusion with --shared-migration and --block-migration\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 2, 'created': '2015-01-15 16:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f0db0f95ef0ae366a3364e060a9c3ce392d83f9e', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 3, 'created': '2015-01-15 16:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3114df30a8a159495b12e657897be698a97a773d', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 4, 'created': '2015-01-16 11:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/66c101ca95cf2e9403f379b384cdc8661f7b6d4d', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 5, 'created': '2015-01-16 12:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/26d4d24b1dd948fb5442f84cdeda97b0553f6452', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 6, 'created': '2015-01-16 12:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c3022464f53d328a48c6ab075a1da718c9e49b83', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 7, 'created': '2015-01-19 11:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3847feba2c722a9084f063d5625c08768a7c2d17', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\n  * argparse handling fixed\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}, {'number': 8, 'created': '2015-01-19 11:11:25.000000000', 'files': ['doc/source/command-objects/server.rst', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/79feccf16ff460aadde3f1d39a51420ebdb82e84', 'message': 'live migration on random host\n\n  * allow migration on random host\n    $ nova live-migration <server> [<host>]\n    is now equivalent to\n    $ osc server migrate --live [--host <hostname>] <server>\n\n  * fix confusion with --shared-migration and --block-migration\n    def live_migrate(self, host=None,\n                     block_migration=False,\n                     disk_over_commit=False):\n    so I renamed parsed_args.shared_migration to parsed_args.block_migration\n\n  * argparse handling fixed\n\nChange-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0\nCloses-Bug: 1411190\n'}]",22,147453,79feccf16ff460aadde3f1d39a51420ebdb82e84,41,10,8,11708,,,0,"live migration on random host

  * allow migration on random host
    $ nova live-migration <server> [<host>]
    is now equivalent to
    $ osc server migrate --live [--host <hostname>] <server>

  * fix confusion with --shared-migration and --block-migration
    def live_migrate(self, host=None,
                     block_migration=False,
                     disk_over_commit=False):
    so I renamed parsed_args.shared_migration to parsed_args.block_migration

  * argparse handling fixed

Change-Id: I142bd4114ba5d219dded11393a2732f5f7e575d0
Closes-Bug: 1411190
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/53/147453/8 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/server.py'],1,c31804edf8af5d0adbd280822b742b8c480f9163,bug/1411190," dest='block_migration', action='store_false', dest='block_migration', action='store_true', if parsed_args.live is not None: parsed_args.live or None, parsed_args.block_migration,"," dest='shared_migration', action='store_true', dest='shared_migration', action='store_false', if parsed_args.live: parsed_args.live, parsed_args.shared_migration,",7,7
openstack%2Fpython-tripleoclient~master~I32dca43bf9f101416417ac432ec12cee34897e29,openstack/python-tripleoclient,master,I32dca43bf9f101416417ac432ec12cee34897e29,Don't warn about missing profiles when they're not used,MERGED,2016-02-05 11:21:40.000000000,2016-02-18 16:59:49.000000000,2016-02-18 16:59:49.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 12321}]","[{'number': 1, 'created': '2016-02-05 11:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1c76a6871aa9b93bca1d52d5cf5eaa49e0767960', 'message': ""Don't warn about missing profiles when they're not used\n\nRight now if you deploy with just the standard baremetal flavor and\ndon't use profile matching you still get a warning that none of\nyour nodes has a profile associated.  This is not correct - we should\nonly warn if a flavor with a profile is actually in use.\n\nChange-Id: I32dca43bf9f101416417ac432ec12cee34897e29\n""}, {'number': 2, 'created': '2016-02-10 20:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3667abad8c2d9fb63a6db328e3e96cbef055cd3a', 'message': ""Don't warn about missing profiles when they're not used\n\nRight now if you deploy with just the standard baremetal flavor and\ndon't use profile matching you still get a warning that none of\nyour nodes has a profile associated.  This is not correct - we should\nonly warn if a flavor with a profile is actually in use.\n\nChange-Id: I32dca43bf9f101416417ac432ec12cee34897e29\n""}, {'number': 3, 'created': '2016-02-11 15:35:16.000000000', 'files': ['tripleoclient/tests/test_utils.py', 'tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a99875d3ce7ed1c02f603913701443cf1de8c941', 'message': ""Don't warn about missing profiles when they're not used\n\nRight now if you deploy with just the standard baremetal flavor and\ndon't use profile matching you still get a warning that none of\nyour nodes has a profile associated.  This is not correct - we should\nonly warn if a flavor with a profile is actually in use.\n\nCloses-Bug: 1537902\nChange-Id: I32dca43bf9f101416417ac432ec12cee34897e29\n""}]",6,276688,a99875d3ce7ed1c02f603913701443cf1de8c941,34,7,3,6928,,,0,"Don't warn about missing profiles when they're not used

Right now if you deploy with just the standard baremetal flavor and
don't use profile matching you still get a warning that none of
your nodes has a profile associated.  This is not correct - we should
only warn if a flavor with a profile is actually in use.

Closes-Bug: 1537902
Change-Id: I32dca43bf9f101416417ac432ec12cee34897e29
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/88/276688/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,1c76a6871aa9b93bca1d52d5cf5eaa49e0767960,bug/1537902, profile_flavor_used = False profile_flavor_used = True if nodes_without_profile and profile_flavor_used:, if nodes_without_profile:,4,1
openstack%2Fhorizon~master~I24ccd6a0a24536642a4b7f170e21d21f766bf7cf,openstack/horizon,master,I24ccd6a0a24536642a4b7f170e21d21f766bf7cf,KEYSTONE-578 Add a configurable websso keystone url,ABANDONED,2016-02-18 16:51:30.000000000,2016-02-18 16:57:09.000000000,,[{'_account_id': 20398}],"[{'number': 1, 'created': '2016-02-18 16:51:30.000000000', 'files': ['releasenotes/notes/websso_keystone_url-4a1262251586bfea.yaml', 'doc/source/topics/settings.rst', 'openstack_dashboard/local/local_settings.py.example'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5a14ad772339e3aa9c8e64ca2244d5af483bb6d3', 'message': 'KEYSTONE-578 Add a configurable websso keystone url\n\nHorizon will support an additional WEBSSO_KEYSTONE_URL configuration\nsetting in local/local_settings.py which will be used to perform\nthe WebSSO authentication. This URL takes precedence over OPENSTACK_KEYSTONE_URL\nwhich in multi-network deployments might not be reachable from the external\nnetwork where the identity provider lives.\n\nChange-Id: I24ccd6a0a24536642a4b7f170e21d21f766bf7cf\nupstream-ref: None\n'}]",0,281958,5a14ad772339e3aa9c8e64ca2244d5af483bb6d3,3,1,1,15640,,,0,"KEYSTONE-578 Add a configurable websso keystone url

Horizon will support an additional WEBSSO_KEYSTONE_URL configuration
setting in local/local_settings.py which will be used to perform
the WebSSO authentication. This URL takes precedence over OPENSTACK_KEYSTONE_URL
which in multi-network deployments might not be reachable from the external
network where the identity provider lives.

Change-Id: I24ccd6a0a24536642a4b7f170e21d21f766bf7cf
upstream-ref: None
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/281958/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/topics/settings.rst', 'releasenotes/notes/websso_keystone_url-4a1262251586bfea.yaml', 'openstack_dashboard/local/local_settings.py.example']",3,5a14ad772339e3aa9c8e64ca2244d5af483bb6d3,,"# If set this URL will be used for web single-sign-on authentication # Useful under some network configurations where OPENSTACK_KEYSTONE_URL # is not reachable #WEBSSO_KEYSTONE_URL = ""http://keystone-public.example.com:5000/v3"" ",,28,0
openstack%2Fdiskimage-builder~master~I980434d3566fce897556d7150b36bd58c3f500e7,openstack/diskimage-builder,master,I980434d3566fce897556d7150b36bd58c3f500e7,Fix SSL issue when building image with ironic-agent element,ABANDONED,2015-10-02 17:15:38.000000000,2016-02-18 16:52:48.000000000,,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6488}]","[{'number': 1, 'created': '2015-10-02 17:15:38.000000000', 'files': ['elements/ironic-agent/install.d/ironic-agent-source-install/60-ironic-agent-install'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7d6c298d55cb5f019180886126d353d71df4fb85', 'message': 'Fix SSL issue when building image with ironic-agent element\n\nDo not merge yet, just testing at this stage.\n\nChange-Id: I980434d3566fce897556d7150b36bd58c3f500e7\n'}]",0,230562,7d6c298d55cb5f019180886126d353d71df4fb85,7,3,1,5805,,,0,"Fix SSL issue when building image with ironic-agent element

Do not merge yet, just testing at this stage.

Change-Id: I980434d3566fce897556d7150b36bd58c3f500e7
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/62/230562/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ironic-agent/install.d/ironic-agent-source-install/60-ironic-agent-install'],1,7d6c298d55cb5f019180886126d353d71df4fb85,IPA_SSL_BUILD_ERR,curl -k -o /tmp/get-pip.py https://bootstrap.pypa.io/get-pip.py,curl -o /tmp/get-pip.py https://bootstrap.pypa.io/get-pip.py,1,1
openstack%2Ftripleo-common~master~I45ec0f6e4472ee0a3c975f51df0d762c87b002b4,openstack/tripleo-common,master,I45ec0f6e4472ee0a3c975f51df0d762c87b002b4,Retry delorean package builds on known network errors,MERGED,2016-01-23 00:35:27.000000000,2016-02-18 16:40:57.000000000,2016-02-18 16:40:57.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 6928}]","[{'number': 1, 'created': '2016-01-23 00:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/59c2639e333fdfa81d154fe207793bd11e456eeb', 'message': 'Retry delorean package builds on known network errors\n\ndelorean check the output of failed builds for newwork glitches and\nmarks the build to be retried. Make use of this and retry if appropriate.\n\nChange-Id: I45ec0f6e4472ee0a3c975f51df0d762c87b002b4\n'}, {'number': 2, 'created': '2016-01-24 07:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/849041dfe8e5ad7fedab51620296022540ed849e', 'message': 'Retry delorean package builds on known network errors\n\ndelorean check the output of failed builds for newwork glitches and\nmarks the build to be retried. Make use of this and retry if appropriate.\n\nChange-Id: I45ec0f6e4472ee0a3c975f51df0d762c87b002b4\n'}, {'number': 3, 'created': '2016-01-24 22:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5fb94c0868f863d71a90035635fa1c9d01eeb6b4', 'message': 'Retry delorean package builds on known network errors\n\ndelorean checks the output of failed builds for network glitches and\nmarks the build to be retried. Make use of this and retry if appropriate.\n\nChange-Id: I45ec0f6e4472ee0a3c975f51df0d762c87b002b4\n'}, {'number': 4, 'created': '2016-01-30 08:03:41.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6b224b39072497bd65a9b90dfc8381a3a9aa76ca', 'message': 'Retry delorean package builds on known network errors\n\ndelorean checks the output of failed builds for network glitches and\nmarks the build to be retried. Make use of this and retry if appropriate.\n\nChange-Id: I45ec0f6e4472ee0a3c975f51df0d762c87b002b4\n'}]",1,271580,6b224b39072497bd65a9b90dfc8381a3a9aa76ca,27,4,4,1926,,,0,"Retry delorean package builds on known network errors

delorean checks the output of failed builds for network glitches and
marks the build to be retried. Make use of this and retry if appropriate.

Change-Id: I45ec0f6e4472ee0a3c975f51df0d762c87b002b4
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/80/271580/4 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,59c2639e333fdfa81d154fe207793bd11e456eeb,retry-delorean," while 1; do DELOREANCMD=""./venv/bin/delorean --config-file projects.ini --head-only --package-name $MAPPED_PROJ --local --build-env DELOREAN_DEV=1 --build-env http_proxy=${http_proxy:-} --info-repo rdoinfo"" # Using sudo to su a command as ourselves to run the command with a new login # to ensure the addition to the mock group has taken effect.A sudo su $(id -nu) -c ""$DELOREANCMD"" || true # If delorean fails due to a network error it will mark it to be retried up to 3 times # Test the status and run delorean again if it is not SUCCESS or FAILED STATUS=$(echo ""select status from commits where project_name == \""$MAPPED_PROJ\"" order by id desc limit 1;"" | sqlite3 commits.sqlite) if [ ""$STATUS"" == ""FAILED"" ] ; then exit 1 elif [ ""$STATUS"" == ""SUCCESS"" ] ; then break fi done"," # Using sudo to su a command as ourselves to run the command with a new login # to ensure the addition to the mock group has taken effect. sudo su $(id -nu) -c ""./venv/bin/delorean --config-file projects.ini --head-only --package-name $MAPPED_PROJ --local --build-env DELOREAN_DEV=1 --build-env http_proxy=${http_proxy:-} --info-repo rdoinfo""",15,3
openstack%2Fkolla~master~Iacc6b620cdcf2dac10ef339f7d2decb46c62f339,openstack/kolla,master,Iacc6b620cdcf2dac10ef339f7d2decb46c62f339,Fix missing ceph-common package in cinder,MERGED,2016-02-16 14:47:22.000000000,2016-02-18 16:38:59.000000000,2016-02-18 16:38:59.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 16233}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-02-16 14:47:22.000000000', 'files': ['docker/cinder/cinder-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a71c9cbacd2372201059d6d309f4593ae92a4d46', 'message': 'Fix missing ceph-common package in cinder\n\nTrivialFix\n\nChange-Id: Iacc6b620cdcf2dac10ef339f7d2decb46c62f339\n'}]",0,280738,a71c9cbacd2372201059d6d309f4593ae92a4d46,11,5,1,14119,,,0,"Fix missing ceph-common package in cinder

TrivialFix

Change-Id: Iacc6b620cdcf2dac10ef339f7d2decb46c62f339
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/280738/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/cinder/cinder-base/Dockerfile.j2'],1,a71c9cbacd2372201059d6d309f4593ae92a4d46,cinder-ceph-fix, python-automaton \ lvm2 \ ceph-common \ && yum clean all \ && mkdir -p /etc/ceph ceph-common \, python-automaton \ lvm2 \ ceph-common \ && yum clean all \ && mkdir -p /etc/ceph,6,5
openstack%2Fmonasca-agent~master~I75582daad11185266e0b5c8531efc9fb9f758d8d,openstack/monasca-agent,master,I75582daad11185266e0b5c8531efc9fb9f758d8d,Documentation support for Elasticsearch,MERGED,2016-02-15 15:22:34.000000000,2016-02-18 16:38:51.000000000,2016-02-18 16:38:51.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 7874}, {'_account_id': 11809}, {'_account_id': 14273}, {'_account_id': 15027}, {'_account_id': 15178}, {'_account_id': 16168}, {'_account_id': 16204}, {'_account_id': 16222}, {'_account_id': 17281}]","[{'number': 1, 'created': '2016-02-15 15:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/8f8344b63a25bdec53de52b65d7ea5e7f254a751', 'message': 'Documentation support for Elasticsearch\n\nAdd semantics for elasticsearch doc\n\nChange-Id: I75582daad11185266e0b5c8531efc9fb9f758d8d\n'}, {'number': 2, 'created': '2016-02-16 13:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/206329ffce30b9b870d87fff44f832554dc3197d', 'message': 'Documentation support for Elasticsearch\n\nAdd semantics for elasticsearch doc\n\nChange-Id: I75582daad11185266e0b5c8531efc9fb9f758d8d\n'}, {'number': 3, 'created': '2016-02-16 13:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/182ba2f917392ac87551bb2843f9bd7d8086c2df', 'message': 'Documentation support for Elasticsearch\n\nAdd semantics for elasticsearch doc\n\nChange-Id: I75582daad11185266e0b5c8531efc9fb9f758d8d\n'}, {'number': 4, 'created': '2016-02-18 12:06:38.000000000', 'files': ['docs/Plugins.md'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/48311380e680f008e932b31f30c7043a332035e2', 'message': 'Documentation support for Elasticsearch\n\nAdd semantics for elasticsearch doc\n\nChange-Id: I75582daad11185266e0b5c8531efc9fb9f758d8d\n'}]",12,280283,48311380e680f008e932b31f30c7043a332035e2,24,11,4,16168,,,0,"Documentation support for Elasticsearch

Add semantics for elasticsearch doc

Change-Id: I75582daad11185266e0b5c8531efc9fb9f758d8d
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/83/280283/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/Plugins.md'],1,8f8344b63a25bdec53de52b65d7ea5e7f254a751,elastic_docs," - [Elasticsearch Checks](#elasticsearch-checks)## Elasticsearch Checks This section describes the Elasticsearch check that can be performed by the Agent. The Elasticsearch check requires a configuration file called elastic.yaml to be available in the agent conf.d configuration directory. Sample config: ``` init_config: null instances: - url: http://127.0.0.1:9200 ``` The Elasticksearch checks return the following metrics: | Metric Name | Dimensions | Semantics | | ----------- | ---------- | --------- | | elasticsearch.docs.count | url, hostname, service=monitoring | The number of docs. Include the count of nested documents. | | elasticsearch.docs.deleted | url, hostname, service=monitoring | The number of deleted docs. | | elasticsearch.store.size | url, hostname, service=monitoring | The filesystem storage size. | | elasticsearch.indexing.index.total | url, hostname, service=monitoring | | | elasticsearch.indexing.index.time | url, hostname, service=monitoring | | | elasticsearch.indexing.index.current | url, hostname, service=monitoring | | | elasticsearch.indexing.delete.total | url, hostname, service=monitoring | | | elasticsearch.indexing.delete.time | url, hostname, service=monitoring | | | elasticsearch.indexing.delete.current | url, hostname, service=monitoring | | | elasticsearch.get.total | url, hostname, service=monitoring | | | elasticsearch.get.time | url, hostname, service=monitoring | | | elasticsearch.get.current | url, hostname, service=monitoring | | | elasticsearch.get.exists.total | url, hostname, service=monitoring | | | elasticsearch.get.exists.time | url, hostname, service=monitoring | | | elasticsearch.get.missing.total | url, hostname, service=monitoring | | | elasticsearch.get.missing.time | url, hostname, service=monitoring | | | elasticsearch.search.query.total | url, hostname, service=monitoring | | | elasticsearch.search.query.time | url, hostname, service=monitoring | | | elasticsearch.search.query.current | url, hostname, service=monitoring | | | elasticsearch.search.fetch.total | url, hostname, service=monitoring | | | elasticsearch.search.fetch.time | url, hostname, service=monitoring | | | elasticsearch.search.fetch.current | url, hostname, service=monitoring | | | elasticsearch.merges.current | url, hostname, service=monitoring | | | elasticsearch.merges.current.docs | url, hostname, service=monitoring | | | elasticsearch.merges.current.size | url, hostname, service=monitoring | | | elasticsearch.merges.total | url, hostname, service=monitoring | | | elasticsearch.merges.total.time | url, hostname, service=monitoring | | | elasticsearch.merges.total.docs | url, hostname, service=monitoring | | | elasticsearch.merges.total.size | url, hostname, service=monitoring | | | elasticsearch.refresh.total | url, hostname, service=monitoring | | | elasticsearch.refresh.total.time | url, hostname, service=monitoring | | | elasticsearch.flush.total | url, hostname, service=monitoring | | | elasticsearch.flush.total.time | url, hostname, service=monitoring | The elasticsearch flush time. | | elasticsearch.process.open_fd | url, hostname, service=monitoring | The number of open files descriptors on the machine. | | elasticsearch.transport.rx_count | url, hostname, service=monitoring | | | elasticsearch.transport.tx_count | url, hostname, service=monitoring | | | elasticsearch.transport.rx_size | url, hostname, service=monitoring | | | elasticsearch.transport.tx_size | url, hostname, service=monitoring | | | elasticsearch.transport.server_open | url, hostname, service=monitoring | | | elasticsearch.thread_pool.bulk.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.bulk.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.bulk.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for bulk operations. | | elasticsearch.thread_pool.bulk.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for bulk operations. | | elasticsearch.thread_pool.flush.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.flush.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.flush.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for flush operations. | | elasticsearch.thread_pool.flush.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for flush operations. | | elasticsearch.thread_pool.generic.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.generic.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.generic.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for generic operations. | | elasticsearch.thread_pool.generic.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for generic operations. | | elasticsearch.thread_pool.get.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.get.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.get.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for get operations. | | elasticsearch.thread_pool.get.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for get operations. | | elasticsearch.thread_pool.index.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.index.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.index.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for index operations. | | elasticsearch.thread_pool.index.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for index operations. | | elasticsearch.thread_pool.management.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.management.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.management.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for management operations. | | elasticsearch.thread_pool.management.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for management operations. | | elasticsearch.thread_pool.merge.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.merge.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.merge.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for merge operations. | | elasticsearch.thread_pool.merge.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for merge operations. | | elasticsearch.thread_pool.percolate.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.percolate.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.percolate.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for percolate operations. | | elasticsearch.thread_pool.percolate.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for percolate operations. | | elasticsearch.thread_pool.refresh.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.refresh.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.refresh.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for refresh operations. | | elasticsearch.thread_pool.refresh.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for refresh operations. | | elasticsearch.thread_pool.search.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.search.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.search.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for search operations. | | elasticsearch.thread_pool.search.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for search operations. | | elasticsearch.thread_pool.snapshot.active | url, hostname, service=monitoring | The number of active threads in the current thread pool. | | elasticsearch.thread_pool.snapshot.threads | url, hostname, service=monitoring | The number of threads in the current thread pool. | | elasticsearch.thread_pool.snapshot.queue | url, hostname, service=monitoring | The number of tasks in queue of thread pool used for snapshot operations. | | elasticsearch.thread_pool.snapshot.rejected | url, hostname, service=monitoring | The number of rejected tasks of thread pool used for snapshot operations. | | elasticsearch.http.current_open | url, hostname, service=monitoring | Current number of opened HTTP connections. | | elasticsearch.http.total_opened | url, hostname, service=monitoring | Max number of HTTP connections. | | jvm.gc.concurrent_mark_sweep.count | url, hostname, service=monitoring | | | jvm.gc.concurrent_mark_sweep.collection_time | url, hostname, service=monitoring | | | jvm.gc.par_new.count | url, hostname, service=monitoring | ParNew count. | | jvm.gc.par_new.collection_time | url, hostname, service=monitoring | ParNew pauses time. | | jvm.mem.heap_committed | url, hostname, service=monitoring | The allocated amount of heap memory. | | jvm.mem.heap_used | url, hostname, service=monitoring | The amount of heap memory which is actually in use. | | jvm.mem.non_heap_committed | url, hostname, service=monitoring | The allocated amount of non-heap memory. | | jvm.mem.non_heap_used | url, hostname, service=monitoring | The amount of non-heap memory which is actually in use. | | jvm.threads.count | url, hostname, service=monitoring | Current number of live daemon and non-daemon threads. | | jvm.threads.peak_count | url, hostname, service=monitoring | Peak live thread count since the JVM started or the peak was reset. | | elasticsearch.number_of_nodes | url, hostname, service=monitoring | Number of nodes. | | elasticsearch.number_of_data_nodes | url, hostname, service=monitoring | Number of data nodes. | | elasticsearch.active_primary_shards | url, hostname, service=monitoring | Indicates the number of primary shards in your cluster. This is an aggregate total across all indices. | | elasticsearch.active_shards | url, hostname, service=monitoring | Aggregate total of all shards across all indices, which includes replica shards. | | elasticsearch.relocating_shards | url, hostname, service=monitoring | Shows the number of shards that are currently moving from one node to another node. | | elasticsearch.initializing_shards | url, hostname, service=monitoring | The count of shards that are being freshly created. | | elasticsearch.unassigned_shards | url, hostname, service=monitoring | The number of unassigned shards from the master node. | | elasticsearch.cluster_status | url, hostname, service=monitoring | Cluster health status. | ",,123,0
openstack%2Fmonasca-agent~master~I21ac0287b22e9ad125842e50205f45243d0a3b2d,openstack/monasca-agent,master,I21ac0287b22e9ad125842e50205f45243d0a3b2d,Centos and RedHat added as supported distributions,MERGED,2016-02-15 15:40:36.000000000,2016-02-18 16:38:44.000000000,2016-02-18 16:38:44.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 15178}, {'_account_id': 16204}, {'_account_id': 16222}, {'_account_id': 16688}]","[{'number': 1, 'created': '2016-02-15 15:40:36.000000000', 'files': ['monasca_setup/service/detection.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/99e09f2952ebb1280671e8a516b4df14fe962c8f', 'message': 'Centos and RedHat added as supported distributions\n\nChange-Id: I21ac0287b22e9ad125842e50205f45243d0a3b2d\n'}]",0,280292,99e09f2952ebb1280671e8a516b4df14fe962c8f,19,6,1,16168,,,0,"Centos and RedHat added as supported distributions

Change-Id: I21ac0287b22e9ad125842e50205f45243d0a3b2d
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/92/280292/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_setup/service/detection.py'],1,99e09f2952ebb1280671e8a516b4df14fe962c8f,supported_distros," supported_linux_flavors = ['ubuntu', 'debian', 'centos linux', 'red hat enterprise linux server']"," supported_linux_flavors = ['ubuntu', 'debian']",1,1
openstack%2Fsyntribos~master~Ibbf4004767b4f6658ad38ab9effdb6bfc4ffaec9,openstack/syntribos,master,Ibbf4004767b4f6658ad38ab9effdb6bfc4ffaec9,made CR flake8 compliant,ABANDONED,2016-02-18 16:35:43.000000000,2016-02-18 16:37:43.000000000,,[],"[{'number': 1, 'created': '2016-02-18 16:35:43.000000000', 'files': ['syntribos/tests/fuzz/xss.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/cd982b8cc623c82a52018e665dff0a0279b29cfd', 'message': 'made CR flake8 compliant\n\nChange-Id: Ibbf4004767b4f6658ad38ab9effdb6bfc4ffaec9\n'}]",0,281941,cd982b8cc623c82a52018e665dff0a0279b29cfd,2,0,1,18765,,,0,"made CR flake8 compliant

Change-Id: Ibbf4004767b4f6658ad38ab9effdb6bfc4ffaec9
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/41/281941/1 && git format-patch -1 --stdout FETCH_HEAD,['syntribos/tests/fuzz/xss.py'],1,cd982b8cc623c82a52018e665dff0a0279b29cfd,,,import re,0,1
openstack%2Ftelemetry-specs~master~Idfbc41c3b681aa57cd5153dffc2dae600a58efb9,openstack/telemetry-specs,master,Idfbc41c3b681aa57cd5153dffc2dae600a58efb9,Fix the typos in the ceilometer specs,MERGED,2016-02-10 15:13:07.000000000,2016-02-18 16:28:18.000000000,2016-02-18 16:28:18.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 9526}, {'_account_id': 16237}, {'_account_id': 18137}]","[{'number': 1, 'created': '2016-02-10 15:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/bddbc4bec9dae46777b37c7ebd04b38d7101190d', 'message': 'Fix the typos in the ceilometer specs\n\nWhen I scan my draft specs, I found these typos and fix them.\n\nChange-Id: Idfbc41c3b681aa57cd5153dffc2dae600a58efb9\n'}, {'number': 2, 'created': '2016-02-11 12:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/8a86a87e2f8c268805d32857a67f938b55297812', 'message': 'Fix the typos in the ceilometer specs\n\nScan the ceilometer specs repository. Filter the result and fix\nthe mistakes.\n\nChange-Id: Idfbc41c3b681aa57cd5153dffc2dae600a58efb9\n'}, {'number': 3, 'created': '2016-02-11 14:43:03.000000000', 'files': ['specs/mitaka/only-support-sqlalchemy-in-aodh.rst', 'specs/liberty/mongodb-aggregation-pipeline.rst', 'specs/kilo/hyper-v-disk-iops-metrics.rst', 'specs/kilo/declarative-http-tests.rst', 'specs/liberty/reload-file-based-pipeline-configuration.rst', 'specs/kilo/ceilometer-rbac.rst', 'specs/liberty/delete-alarmhistory.rst', 'specs/liberty/pollsters-no-transform.rst', 'specs/kilo/ceilometer_ceph_integration.rst', 'specs/kilo/network-services-notifications.rst', 'specs/juno/big-data-sql-v2.rst', 'specs/juno/quotas-on-alarms.rst', 'specs/juno/grenade-resource-survivability.rst', 'specs/mitaka/composite-threshold-rule-alarm.rst', 'specs/mitaka/rolling-upgrades.rst', 'specs/kilo/dedicated-event-db.rst', 'specs/liberty/deprecate-existence-meters.rst', 'specs/kilo/kafka-publisher.rst', 'specs/kilo/rally-check-gate.rst', 'specs/kilo/ceilometermiddleware.rst', 'specs/juno/grenade-upgrade-testing.rst', 'specs/mitaka/event-to-sample-publisher.rst', 'specs/liberty/remove-web-eventlet.rst', 'specs/liberty/split-ceilometer-alarming.rst', 'specs/juno/ironic-notifications.rst', 'specs/liberty/api-no-pipeline.rst', 'specs/kilo/elasticsearch-event-db.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/132f377e85806add73b4fc6ce09e36c009ae3430', 'message': 'Fix the typos in the ceilometer specs\n\nScan the ceilometer specs repository. Filter the result and fix\nthe mistakes.\n\nChange-Id: Idfbc41c3b681aa57cd5153dffc2dae600a58efb9\n'}]",0,278424,132f377e85806add73b4fc6ce09e36c009ae3430,14,6,3,9526,,,0,"Fix the typos in the ceilometer specs

Scan the ceilometer specs repository. Filter the result and fix
the mistakes.

Change-Id: Idfbc41c3b681aa57cd5153dffc2dae600a58efb9
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/24/278424/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/mitaka/event-to-sample-publisher.rst', 'specs/mitaka/only-support-sqlalchemy-in-aodh.rst', 'specs/mitaka/composite-threshold-rule-alarm.rst']",3,bddbc4bec9dae46777b37c7ebd04b38d7101190d,jzl/fix-ceilometer-specs-typo," rules and the key of the dict will be ""and"" or ""or"". But this has no"," rules and the the key of the dict will be ""and"" or ""or"". But this has no",3,3
openstack%2Ftripleo-heat-templates~master~I377565d3fb821be1bb2dc7d92ec1ad25a4a3b1f1,openstack/tripleo-heat-templates,master,I377565d3fb821be1bb2dc7d92ec1ad25a4a3b1f1,Add missing : in hieradata key name,MERGED,2016-02-12 18:09:56.000000000,2016-02-18 16:28:10.000000000,2016-02-18 16:28:10.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-02-12 18:09:56.000000000', 'files': ['puppet/controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/12d7be9160ecf21feed993356d73ce9e14365e06', 'message': 'Add missing : in hieradata key name\n\nThis hieradata key, neutron::agents::ml2::ovs:bridge_mappings was\nmissing a : before bridge_mappings causing the value to be blank in\n/etc/neutron/plugins/ml2/openvswitch_agent.ini even if a value had been\nspecified.\n\nChange-Id: I377565d3fb821be1bb2dc7d92ec1ad25a4a3b1f1\n'}]",0,279711,12d7be9160ecf21feed993356d73ce9e14365e06,31,4,1,7144,,,0,"Add missing : in hieradata key name

This hieradata key, neutron::agents::ml2::ovs:bridge_mappings was
missing a : before bridge_mappings causing the value to be blank in
/etc/neutron/plugins/ml2/openvswitch_agent.ini even if a value had been
specified.

Change-Id: I377565d3fb821be1bb2dc7d92ec1ad25a4a3b1f1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/11/279711/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/controller.yaml'],1,12d7be9160ecf21feed993356d73ce9e14365e06,, neutron::agents::ml2::ovs::bridge_mappings: {get_input: neutron_bridge_mappings}, neutron::agents::ml2::ovs:bridge_mappings: {get_input: neutron_bridge_mappings},1,1
openstack%2Fcinder~master~Ia542900076fe103b465b52052fa97131230e907d,openstack/cinder,master,Ia542900076fe103b465b52052fa97131230e907d,[DNF] Testing experimental-bindep-jobs,ABANDONED,2016-02-18 14:51:16.000000000,2016-02-18 16:25:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4162}]","[{'number': 1, 'created': '2016-02-18 14:51:16.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/96a241c0659a592318dea89cc2ce6939407d11ab', 'message': '[DNF] Testing experimental-bindep-jobs\n\nPlease do not merge this patch, we are uploading this into your\nproject to test some new openstack-infra functionality around bindep.\n\nChange-Id: Ia542900076fe103b465b52052fa97131230e907d\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,281893,96a241c0659a592318dea89cc2ce6939407d11ab,6,2,1,4162,,,0,"[DNF] Testing experimental-bindep-jobs

Please do not merge this patch, we are uploading this into your
project to test some new openstack-infra functionality around bindep.

Change-Id: Ia542900076fe103b465b52052fa97131230e907d
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/281893/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,96a241c0659a592318dea89cc2ce6939407d11ab,experimental-bindep-jobs,=====,======,1,1
openstack%2Ffuel-library~master~I259a83e56f488a2a304f2f2410fc5b16719a969f,openstack/fuel-library,master,I259a83e56f488a2a304f2f2410fc5b16719a969f,Switch from jbussdieker/monit to sbitio/monit,MERGED,2016-02-11 09:23:29.000000000,2016-02-18 16:18:06.000000000,2016-02-18 16:13:57.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13505}, {'_account_id': 13948}, {'_account_id': 14200}, {'_account_id': 14357}, {'_account_id': 14985}, {'_account_id': 17730}]","[{'number': 1, 'created': '2016-02-11 09:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c34c3e7c2188345418d33554698a40d7708f3a9a', 'message': ""Switch from jbussdieker/monit to sbitio/monit\n\nThe current module doesn't specify the license, making it impossible\nto include it in Debian.\n\nChange-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f\nCloses-Bug: 1544428\n""}, {'number': 2, 'created': '2016-02-11 11:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/96d227c90d65b685c00c956afccc1a5e5646984c', 'message': ""Switch from jbussdieker/monit to sbitio/monit\n\nThe current module doesn't specify the license, making it impossible\nto include it in Debian.\n\nChange-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f\nCloses-Bug: 1544428\n""}, {'number': 3, 'created': '2016-02-11 11:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ce7ff610fafc0efe9314efbe1239f402361f270d', 'message': ""Switch from jbussdieker/monit to sbitio/monit\n\nThe current module doesn't specify the license, making it impossible\nto include it in Debian.\n\nFuel-CI: disable\nChange-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f\nCloses-Bug: 1544428\n""}, {'number': 4, 'created': '2016-02-11 12:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/85f1ef346cb9a62f53e5f5cff5e7f47ae2078c77', 'message': ""Switch from jbussdieker/monit to sbitio/monit\n\nThe current module doesn't specify the license, making it impossible\nto include it in Debian.\n\nDue to problematic naming scheme of mirrored modules on Fuel infra,\nthe switch will require forced push to mirror instead of simple\nPuppetfile change. Different [0] commit proves that the switch passes\nCI tests.\n\n[0] Ic27a6c8f84984544ade4a134648028a44403aad0\n\nFuel-CI: disable\nChange-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f\nCloses-Bug: 1544428\n""}, {'number': 5, 'created': '2016-02-16 08:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/16930a3e826fa517153c08e9bb2b6e5bb883fca1', 'message': ""Switch from jbussdieker/monit to sbitio/monit\n\nThe current module doesn't specify the license, making it impossible\nto include it in Debian.\n\nDue to problematic naming scheme of mirrored modules on Fuel infra,\nthe switch will require forced push to mirror instead of simple\nPuppetfile change. Different [0] commit proves that the switch passes\nCI tests.\n\n[0] Ic27a6c8f84984544ade4a134648028a44403aad0\n\nFuel-CI: disable\nChange-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f\nCloses-Bug: 1544428\n""}, {'number': 6, 'created': '2016-02-16 08:49:57.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/roles/cinder.pp', 'deployment/Puppetfile', 'deployment/puppet/osnailyfacter/modular/roles/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1c0d8c1537540b5b2d2231a937fb2b319017fd47', 'message': ""Switch from jbussdieker/monit to sbitio/monit\n\nThe current module doesn't specify the license, making it impossible\nto include it in Debian.\n\nChange-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f\nCloses-Bug: 1544428\n""}]",0,278942,1c0d8c1537540b5b2d2231a937fb2b319017fd47,78,20,6,13948,,,0,"Switch from jbussdieker/monit to sbitio/monit

The current module doesn't specify the license, making it impossible
to include it in Debian.

Change-Id: I259a83e56f488a2a304f2f2410fc5b16719a969f
Closes-Bug: 1544428
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/42/278942/3 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/Puppetfile', 'deployment/puppet/osnailyfacter/modular/roles/cinder.pp', 'deployment/puppet/osnailyfacter/modular/roles/compute.pp']",3,c34c3e7c2188345418d33554698a40d7708f3a9a,bug/1544428," monit::check::process { $nova_compute_name : program_start => ""${service_path} ${nova_compute_name} restart"", program_stop => ""${service_path} ${nova_compute_name} stop"", monit::check::process { $ovs_vswitchd_name : program_start => ""${service_path} ${ovs_vswitchd_name} restart"", program_stop => ""${service_path} ${ovs_vswitchd_name} stop"", monit::check::process { $nova_network_name : program_start => ""${service_path} ${nova_network_name} restart"", program_stop => ""${service_path} ${nova_network_name} stop"", monit::check::process { $nova_api_name : program_start => ""${service_path} ${nova_api_name} restart"", program_stop => ""${service_path} ${nova_api_name} stop"","," monit::process { $nova_compute_name : start_command => ""${service_path} ${nova_compute_name} restart"", stop_command => ""${service_path} ${nova_compute_name} stop"", monit::process { $ovs_vswitchd_name : start_command => ""${service_path} ${ovs_vswitchd_name} restart"", stop_command => ""${service_path} ${ovs_vswitchd_name} stop"", monit::process { $nova_network_name : start_command => ""${service_path} ${nova_network_name} restart"", stop_command => ""${service_path} ${nova_network_name} stop"", monit::process { $nova_api_name : start_command => ""${service_path} ${nova_api_name} restart"", stop_command => ""${service_path} ${nova_api_name} stop"",",17,17
openstack%2Ffuel-library~stable%2F6.1~I307452b687a6100cc4489c8decebbc3dccdbc432,openstack/fuel-library,stable/6.1,I307452b687a6100cc4489c8decebbc3dccdbc432,Start RabbitMQ app on notify,MERGED,2016-01-20 16:46:56.000000000,2016-02-18 16:16:04.000000000,2016-02-18 16:10:38.000000000,"[{'_account_id': 3}, {'_account_id': 7109}, {'_account_id': 8971}, {'_account_id': 9448}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12559}, {'_account_id': 13948}, {'_account_id': 14200}, {'_account_id': 14689}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-01-20 16:46:56.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bb5340e01fcb8e85a397f1db87b810696b2fb11e', 'message': 'Start RabbitMQ app on notify\n\nOn notify, if we detect that we are a part of a cluster we still\nneed to start the RabbitMQ application, because it is always\ndown after action_start finishes.\n\nCloses-Bug: #1496386\nChange-Id: I307452b687a6100cc4489c8decebbc3dccdbc432\n(cherry picked from commit c1900b49e6ddcfb84bf5c501c75f3fee80903eca)\n'}]",0,270314,bb5340e01fcb8e85a397f1db87b810696b2fb11e,32,11,1,18845,,,0,"Start RabbitMQ app on notify

On notify, if we detect that we are a part of a cluster we still
need to start the RabbitMQ application, because it is always
down after action_start finishes.

Closes-Bug: #1496386
Change-Id: I307452b687a6100cc4489c8decebbc3dccdbc432
(cherry picked from commit c1900b49e6ddcfb84bf5c501c75f3fee80903eca)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/14/270314/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,bb5340e01fcb8e85a397f1db87b810696b2fb11e,bug/1496386," local c_status c_status=$(${OCF_RESKEY_ctl} eval ""mnesia:system_info(${infotype})."" 2>/dev/null) # Now we need to: # a. join to the cluster if we are not joined yet # b. start the RabbitMQ application, which is always # stopped after start action finishes if try_to_start_rmq_app; then rc2=$OCF_SUCCESS else rc2=$OCF_ERR_GENERIC fi"," local c_status=$(${OCF_RESKEY_ctl} eval ""mnesia:system_info(${infotype})."" 2>/dev/null) rc2=$OCF_SUCCESS",11,2
openstack%2Fproject-config~master~I34f0b355703fe0133f160afd4e32f2272d41ecaa,openstack/project-config,master,I34f0b355703fe0133f160afd4e32f2272d41ecaa,Cleanup of constraint based jobs for neutron-vpnaas,MERGED,2016-02-16 20:41:32.000000000,2016-02-18 16:15:48.000000000,2016-02-18 16:15:48.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2750}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6659}, {'_account_id': 8344}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-02-16 20:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5d485931596cd0c45f2b5fe286deb462874f085a', 'message': 'Cleanup of constraint based jobs for neutron-vpnaas\n\nThe neutron-vpnaas repo already has support for constraints based jobs.\nHowever, the TC expressed the desire to have the non-constraints named\njobs run with constraints.\n\nThis commit will partially revert I6d2cfdf363f9ec1c1f3787ca1d03537b2c2d1f5f\nso that Liberty and later will run non-constraints NAMED jobs. A separate\nneutron-vpnaas commit will modify tox.ini so that the non-constraints\nNAMED jobs will run with constraints. That will be cherry-picked to Liberty.\n\nNote: the tarball filters, release, and publish jobs from the above commit\nare not modified.\n\nChange-Id: I34f0b355703fe0133f160afd4e32f2272d41ecaa\nPartial-Bug: #1522503\n'}, {'number': 2, 'created': '2016-02-17 12:13:40.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/20d8db5f59b87fc781221ded983a9ad2aba9dc85', 'message': 'Cleanup of constraint based jobs for neutron-vpnaas\n\nThe neutron-vpnaas repo already has support for constraints based jobs.\nHowever, the TC expressed the desire to have the non-constraints named\njobs run with constraints.\n\nThis commit will partially revert I6d2cfdf363f9ec1c1f3787ca1d03537b2c2d1f5f\nso that Liberty and later will run non-constraints NAMED jobs. A separate\nneutron-vpnaas commit will modify tox.ini so that the non-constraints\nNAMED jobs will run with constraints. That will be cherry-picked to Liberty.\n\nNote: the tarball filters, release, and publish jobs from the above commit\nare not modified.\n\nChange-Id: I34f0b355703fe0133f160afd4e32f2272d41ecaa\nPartial-Bug: #1522503\n'}]",0,280922,20d8db5f59b87fc781221ded983a9ad2aba9dc85,14,8,2,6659,,,0,"Cleanup of constraint based jobs for neutron-vpnaas

The neutron-vpnaas repo already has support for constraints based jobs.
However, the TC expressed the desire to have the non-constraints named
jobs run with constraints.

This commit will partially revert I6d2cfdf363f9ec1c1f3787ca1d03537b2c2d1f5f
so that Liberty and later will run non-constraints NAMED jobs. A separate
neutron-vpnaas commit will modify tox.ini so that the non-constraints
NAMED jobs will run with constraints. That will be cherry-picked to Liberty.

Note: the tarball filters, release, and publish jobs from the above commit
are not modified.

Change-Id: I34f0b355703fe0133f160afd4e32f2272d41ecaa
Partial-Bug: #1522503
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/280922/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,5d485931596cd0c45f2b5fe286deb462874f085a,280922,, # Only run non-constraints jobs on Kilo - name: ^gate-neutron-vpnaas-(docs|pep8|python27)$ branch: ^(?:stable/kilo).*$ - name: python-constraints-jobs - name: python3-constraints-jobs,0,6
openstack%2Fdevstack-gate~master~Icbd1d636f01a1a04268b6ccc8e5a6d818606a5e7,openstack/devstack-gate,master,Icbd1d636f01a1a04268b6ccc8e5a6d818606a5e7,WIP: Subunitize devstack-gate,ABANDONED,2016-02-12 01:10:16.000000000,2016-02-18 16:12:38.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}]","[{'number': 1, 'created': '2016-02-12 01:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6d097b36cf8f52a54c0d10d9340e96cb1426be01', 'message': 'WIP: Subunitize devstack-gate\n\nChange-Id: Icbd1d636f01a1a04268b6ccc8e5a6d818606a5e7\n'}, {'number': 2, 'created': '2016-02-12 03:02:46.000000000', 'files': ['devstack-vm-gate-wrap.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/52a0a44deecd252c809765194a982a60045c350e', 'message': 'WIP: Subunitize devstack-gate\n\nChange-Id: Icbd1d636f01a1a04268b6ccc8e5a6d818606a5e7\n'}]",0,279343,52a0a44deecd252c809765194a982a60045c350e,6,2,2,5196,,,0,"WIP: Subunitize devstack-gate

Change-Id: Icbd1d636f01a1a04268b6ccc8e5a6d818606a5e7
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/43/279343/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,6d097b36cf8f52a54c0d10d9340e96cb1426be01,,trap exit_trap EXIT function exit_trap { local r=$? if [[ $r -ne 0 ]]; then generate-subunit $START_TIME $SECONDS 'fail' 'devstack-gate' | sudo tee -a $BASE/logs/testrepository.subunit > /dev/null else generate-subunit $START_TIME $SECONDS 'success' 'devstack-gate' | sudo tee -a $BASE/logs/testrepository.subunit > /dev/null fi exit $r } ,,12,0
openstack%2Fnetworking-ovn~master~I43f50473d9deae99fbdf7aa61676caa4c3d10687,openstack/networking-ovn,master,I43f50473d9deae99fbdf7aa61676caa4c3d10687,Network availability zone deployment support,MERGED,2016-02-17 13:51:30.000000000,2016-02-18 16:11:29.000000000,2016-02-18 16:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-02-17 13:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0f410971220e6fe615b48b6df390faba00e516f0', 'message': 'WIP: Network availability zone deployment support\n\nAdd network availability support for DHCP agents to the devstack and\nvagrant deployments. By default, all DHCP agents will use the default\navailability zone (nova) with the ability to customize the availability\nzone name.\n\nChange-Id: I43f50473d9deae99fbdf7aa61676caa4c3d10687\nRelated-Bug: #1539274\n'}, {'number': 2, 'created': '2016-02-17 18:32:44.000000000', 'files': ['vagrant/provisioning/setup-compute.sh', 'vagrant/provisioning/setup-controller.sh', 'devstack/local.conf.sample', 'devstack/computenode-local.conf.sample'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/92e637cd4ebf2696770c01655b4f436dfe623520', 'message': 'Network availability zone deployment support\n\nAdd network availability support for DHCP agents to the devstack and\nvagrant deployments. By default, all DHCP agents will use the default\navailability zone (nova) with the ability to customize the availability\nzone name.\n\nChange-Id: I43f50473d9deae99fbdf7aa61676caa4c3d10687\nRelated-Bug: #1539274\n'}]",2,281284,92e637cd4ebf2696770c01655b4f436dfe623520,11,4,2,8410,,,0,"Network availability zone deployment support

Add network availability support for DHCP agents to the devstack and
vagrant deployments. By default, all DHCP agents will use the default
availability zone (nova) with the ability to customize the availability
zone name.

Change-Id: I43f50473d9deae99fbdf7aa61676caa4c3d10687
Related-Bug: #1539274
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/84/281284/2 && git format-patch -1 --stdout FETCH_HEAD,"['vagrant/provisioning/setup-compute.sh', 'vagrant/provisioning/setup-controller.sh', 'devstack/local.conf.sample', 'devstack/computenode-local.conf.sample']",4,0f410971220e6fe615b48b6df390faba00e516f0,bug/1539274," # If you enable the DHCP agent, you can configure the availability # zone name (default is nova). #[[post-config|$Q_DHCP_CONF_FILE]] #[AGENT] #availability_zone = nova",,29,4
openstack%2Fkolla~master~I3d963cd58ef791d30a90f3a74cac2477dac3edfd,openstack/kolla,master,I3d963cd58ef791d30a90f3a74cac2477dac3edfd,Fix the incorrectly removed dependent packages,MERGED,2016-02-17 09:58:04.000000000,2016-02-18 16:08:32.000000000,2016-02-18 15:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-17 09:58:04.000000000', 'files': ['docker/kolla-toolbox/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3853a8bc89859e3bafaca9674b7bbca066a1f11f', 'message': 'Fix the incorrectly removed dependent packages\n\nChange-Id: I3d963cd58ef791d30a90f3a74cac2477dac3edfd\nCloses-Bug: #1546449\n'}]",0,281159,3853a8bc89859e3bafaca9674b7bbca066a1f11f,13,3,1,18723,,,0,"Fix the incorrectly removed dependent packages

Change-Id: I3d963cd58ef791d30a90f3a74cac2477dac3edfd
Closes-Bug: #1546449
",git fetch https://review.opendev.org/openstack/kolla refs/changes/59/281159/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kolla-toolbox/Dockerfile.j2'],1,3853a8bc89859e3bafaca9674b7bbca066a1f11f,bug/1546449, && rpm -e --nodeps pytz, && yum -y remove pytz,1,1
openstack%2Fpuppet-keystone~master~I8934e6e405db497ce469cdada761f3a5056081d4,openstack/puppet-keystone,master,I8934e6e405db497ce469cdada761f3a5056081d4,CI test - never merge,ABANDONED,2016-02-18 04:49:36.000000000,2016-02-18 15:52:11.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-18 04:49:36.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a488549c821d043702adb2336946504238333918', 'message': 'CI test - never merge\n\nChange-Id: I8934e6e405db497ce469cdada761f3a5056081d4\n'}]",0,281626,a488549c821d043702adb2336946504238333918,4,1,1,3153,,,0,"CI test - never merge

Change-Id: I8934e6e405db497ce469cdada761f3a5056081d4
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/26/281626/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,a488549c821d043702adb2336946504238333918,ci-test,test ,,1,0
openstack%2Foslo.config~master~Ib984ef2d97e1dd710d78dca7da67d88152434e70,openstack/oslo.config,master,Ib984ef2d97e1dd710d78dca7da67d88152434e70,[WIP] Support ZooKeeper and Consul for oslo.config,ABANDONED,2015-11-09 16:10:16.000000000,2016-02-18 15:51:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2015-11-09 16:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/8b61e48495cfcfc10e3bce5fb70faecd3950f81f', 'message': '[WIP] Support ZooKeeper and Consul for oslo.config\n\n* interface to implement any config reader.\n* support ZooKeeper:\n    --config-db=zk://host1:2181,host2:2181,host3:2181/openstack\n* support Consul:\n    --config-db=consul://consul/openstack\n\nChange-Id: Ib984ef2d97e1dd710d78dca7da67d88152434e70\nImplements: blueprint oslo-config-db\n'}, {'number': 2, 'created': '2015-11-10 10:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/def8237639bab2ba95a7c9184e98160e1aae6984', 'message': '[WIP] Support ZooKeeper and Consul for oslo.config\n\n* interface to implement any config reader.\n* support ZooKeeper:\n    --config-db=zk://host1:2181,host2:2181,host3:2181/openstack\n* support Consul:\n    --config-db=consul://consul/openstack\n\nChange-Id: Ib984ef2d97e1dd710d78dca7da67d88152434e70\nImplements: blueprint oslo-config-db\n'}, {'number': 3, 'created': '2015-11-10 14:18:06.000000000', 'files': ['oslo_config/zkdb.py', 'requirements.txt', 'oslo_config/tests/test_cfg.py', 'oslo_config/cfg.py', 'oslo_config/consuldb.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/301ce9e1ffd434c403035d5c985a2563cf42ae54', 'message': '[WIP] Support ZooKeeper and Consul for oslo.config\n\n* interface to implement any config reader.\n* support ZooKeeper:\n    --config-db=zk://host1:2181,host2:2181,host3:2181/openstack\n* support Consul:\n    --config-db=consul://consul/openstack\n\nChange-Id: Ib984ef2d97e1dd710d78dca7da67d88152434e70\nImplements: blueprint oslo-config-db\n'}]",0,243182,301ce9e1ffd434c403035d5c985a2563cf42ae54,10,3,3,11708,,,0,"[WIP] Support ZooKeeper and Consul for oslo.config

* interface to implement any config reader.
* support ZooKeeper:
    --config-db=zk://host1:2181,host2:2181,host3:2181/openstack
* support Consul:
    --config-db=consul://consul/openstack

Change-Id: Ib984ef2d97e1dd710d78dca7da67d88152434e70
Implements: blueprint oslo-config-db
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/82/243182/3 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_config/zkdb.py', 'requirements.txt', 'oslo_config/tests/test_cfg.py', 'oslo_config/cfg.py', 'oslo_config/consuldb.py', 'setup.cfg']",6,8b61e48495cfcfc10e3bce5fb70faecd3950f81f,bp/oslo-config-db,oslo.config.cmdb = consul = oslo_config.consuldb:main zk = oslo_config.zkdb:main,,177,1
openstack%2Ftraining-labs~master~I44a637e4f7ca9f1f0330699e01a606b6d5256295,openstack/training-labs,master,I44a637e4f7ca9f1f0330699e01a606b6d5256295,Add vm_snapshot_list_tree,MERGED,2016-02-08 19:43:19.000000000,2016-02-18 15:49:52.000000000,2016-02-18 15:49:51.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-02-08 19:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/1773937ff4740f7ef4794f2b86b446fbcb249b22', 'message': 'Add vm_snapshot_list_tree\n\nThis patch moves the remaining call to VBM_EXE (VirtualBox-specific) out\nof restore-cluster.sh and into virtualbox-functions.sh.\n\nChange-Id: I44a637e4f7ca9f1f0330699e01a606b6d5256295\n'}, {'number': 2, 'created': '2016-02-08 19:50:09.000000000', 'files': ['labs/osbash/tools/restore-cluster.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/3e960ccc96e2e5f974e83784c24fd941cfd301d5', 'message': 'Add vm_snapshot_list_tree\n\nThis patch moves the remaining call to VBM_EXE (VirtualBox-specific) out\nof restore-cluster.sh and into virtualbox-functions.sh.\n\nChange-Id: I44a637e4f7ca9f1f0330699e01a606b6d5256295\n'}]",0,277547,3e960ccc96e2e5f974e83784c24fd941cfd301d5,8,3,2,11109,,,0,"Add vm_snapshot_list_tree

This patch moves the remaining call to VBM_EXE (VirtualBox-specific) out
of restore-cluster.sh and into virtualbox-functions.sh.

Change-Id: I44a637e4f7ca9f1f0330699e01a606b6d5256295
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/47/277547/2 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/tools/restore-cluster.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh']",2,1773937ff4740f7ef4794f2b86b446fbcb249b22,snapshot_refactoring,"function vm_snapshot_list_tree { local vm_name=$1 # Hide VBM error on stderr if no snapshots exist local rc # Hide VBM error message and proceed even if exit status indicates error $VBM snapshot ""$vm_name"" list 2>/dev/null || rc=$? } ",,10,1
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef,openstack/tripleo-heat-templates,stable/liberty,I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef,Add sysctl settings to disable IPv6 autoconfig and accept_ra,MERGED,2016-02-07 15:25:02.000000000,2016-02-18 15:49:44.000000000,2016-02-18 15:49:44.000000000,"[{'_account_id': 3}, {'_account_id': 6796}]","[{'number': 1, 'created': '2016-02-07 15:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ede59e0b599b96c5c62e8367838550033ad0a6d9', 'message': 'Add sysctl settings to disable IPv6 on unconfigured interfaces\n\nThis change adds puppet hieradata settings which disable IPv6 by\ndefault on all interfaces. When IPv6 is used, the interfaces are\nindividually enabled and configured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 by default on interfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\n(cherry picked from commit b3ee463bf0e5ad0da19e3fe804dbeb8653ce26e6)\n'}, {'number': 2, 'created': '2016-02-17 21:23:11.000000000', 'files': ['puppet/hieradata/common.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3cc92814028ad267b9012c61f0e267bb6fd1a610', 'message': 'Add sysctl settings to disable IPv6 autoconfig and accept_ra\n\nThis change adds puppet hieradata settings which disable IPv6\nautoconfiguration and accept_ra by default on all interfaces.\nWhen IPv6 is used, the interfaces are individually enabled and\nconfigured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 autoconfiguration and acceptance of RAs by default on\ninterfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute. Alternately, sysctl\ncan be modified to change the accept_ra behavior for specific\ninterfaces.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\n(cherry picked from commit b3ee463bf0e5ad0da19e3fe804dbeb8653ce26e6)\n'}]",0,277183,3cc92814028ad267b9012c61f0e267bb6fd1a610,10,2,2,12398,,,0,"Add sysctl settings to disable IPv6 autoconfig and accept_ra

This change adds puppet hieradata settings which disable IPv6
autoconfiguration and accept_ra by default on all interfaces.
When IPv6 is used, the interfaces are individually enabled and
configured with static IP addresses.

The networking on the compute host needs to be completely
separate from the tenant networking, in order to safeguard the
compute host and isolate tenant traffic. This change disables
IPv6 autoconfiguration and acceptance of RAs by default on
interfaces unless specifically enabled.

Without these settings, IPv6 is enabled on all interfaces, as well
as autoconfiguration and accept_ra, so when the compute host
creates a bridge interface for the router (qbr-<ID>), the
compute node will automatically assign an IPv6 address and will
install a default IPv6 route on the bridge interface when it
receives the RAs from the Neutron router.

The change to turn off autoconfiguration means that interfaces
will not self-assign an IPv6 address, and the change to not accept
RAs is a security hardening feature. This requires that a
static gateway address be declared in the network environment
in the parameter ExternalNetworkDefaultRoute. Alternately, sysctl
can be modified to change the accept_ra behavior for specific
interfaces.

Change-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef
(cherry picked from commit b3ee463bf0e5ad0da19e3fe804dbeb8653ce26e6)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/277183/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/hieradata/common.yaml'],1,ede59e0b599b96c5c62e8367838550033ad0a6d9,ipv6_disable_default_liberty_fix, # prevent neutron bridges from autoconfiguring ipv6 addresses net.ipv6.conf.default.accept_ra: value: 0 net.ipv6.conf.default.autoconf: value: 0 net.ipv6.conf.default.disable_ipv6: value: 1,,7,0
openstack%2Ftripleo-heat-templates~master~I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef,openstack/tripleo-heat-templates,master,I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef,Add sysctl settings to disable IPv6 autoconfig and accept_ra,MERGED,2016-02-07 15:17:48.000000000,2016-02-18 15:48:50.000000000,2016-02-18 15:48:50.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 10873}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-02-07 15:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc00b8664d79a524692a18abe9b3d414d6dadfa0', 'message': 'Add sysclt settings to disable IPv6 on unconfigured interfaces\n\nThis change adds puppet hieradata settings which disable IPv6 by\ndefault on all interfaces. When IPv6 is used, the interfaces are\nindividually enabled and configured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 by default on interfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\n'}, {'number': 2, 'created': '2016-02-07 15:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b3ee463bf0e5ad0da19e3fe804dbeb8653ce26e6', 'message': 'Add sysctl settings to disable IPv6 on unconfigured interfaces\n\nThis change adds puppet hieradata settings which disable IPv6 by\ndefault on all interfaces. When IPv6 is used, the interfaces are\nindividually enabled and configured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 by default on interfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\n'}, {'number': 3, 'created': '2016-02-10 21:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fda0210694d7273410d3711d7bc253764e7cab03', 'message': 'Add sysctl settings to disable IPv6 on unconfigured interfaces\n\nThis change adds puppet hieradata settings which disable IPv6 by\ndefault on all interfaces. When IPv6 is used, the interfaces are\nindividually enabled and configured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 by default on interfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\nCloses-bug: 1544296\n'}, {'number': 4, 'created': '2016-02-17 21:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d7e61eec090ae6a329d7958b6b01456f0e60b488', 'message': 'Add sysctl settings to disable IPv6 autoconfig and accept_ra\n\nThis change adds puppet hieradata settings which disable IPv6\nautoconfiguration and accept_ra by default on all interfaces.\nWhen IPv6 is used, the interfaces are individually enabled and\nconfigured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 autoconfiguration and acceptance of RAs by default on\ninterfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute. Alternately, sysctl\ncan be modified to change the accept_ra behavior for specific\ninterfaces.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\nCloses-bug: 1544296\n'}, {'number': 5, 'created': '2016-02-18 10:10:12.000000000', 'files': ['puppet/hieradata/common.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/68d18fffbeda6fc69b9f123e154e558f72b8bc3f', 'message': 'Add sysctl settings to disable IPv6 autoconfig and accept_ra\n\nThis change adds puppet hieradata settings which disable IPv6\nautoconfiguration and accept_ra by default on all interfaces.\nWhen IPv6 is used, the interfaces are individually enabled and\nconfigured with static IP addresses.\n\nThe networking on the compute host needs to be completely\nseparate from the tenant networking, in order to safeguard the\ncompute host and isolate tenant traffic. This change disables\nIPv6 autoconfiguration and acceptance of RAs by default on\ninterfaces unless specifically enabled.\n\nWithout these settings, IPv6 is enabled on all interfaces, as well\nas autoconfiguration and accept_ra, so when the compute host\ncreates a bridge interface for the router (qbr-<ID>), the\ncompute node will automatically assign an IPv6 address and will\ninstall a default IPv6 route on the bridge interface when it\nreceives the RAs from the Neutron router.\n\nThe change to turn off autoconfiguration means that interfaces\nwill not self-assign an IPv6 address, and the change to not accept\nRAs is a security hardening feature. This requires that a\nstatic gateway address be declared in the network environment\nin the parameter ExternalNetworkDefaultRoute. Alternately, sysctl\ncan be modified to change the accept_ra behavior for specific\ninterfaces.\n\nChange-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef\nCloses-bug: 1544296\n'}]",5,277182,68d18fffbeda6fc69b9f123e154e558f72b8bc3f,23,5,5,12398,,,0,"Add sysctl settings to disable IPv6 autoconfig and accept_ra

This change adds puppet hieradata settings which disable IPv6
autoconfiguration and accept_ra by default on all interfaces.
When IPv6 is used, the interfaces are individually enabled and
configured with static IP addresses.

The networking on the compute host needs to be completely
separate from the tenant networking, in order to safeguard the
compute host and isolate tenant traffic. This change disables
IPv6 autoconfiguration and acceptance of RAs by default on
interfaces unless specifically enabled.

Without these settings, IPv6 is enabled on all interfaces, as well
as autoconfiguration and accept_ra, so when the compute host
creates a bridge interface for the router (qbr-<ID>), the
compute node will automatically assign an IPv6 address and will
install a default IPv6 route on the bridge interface when it
receives the RAs from the Neutron router.

The change to turn off autoconfiguration means that interfaces
will not self-assign an IPv6 address, and the change to not accept
RAs is a security hardening feature. This requires that a
static gateway address be declared in the network environment
in the parameter ExternalNetworkDefaultRoute. Alternately, sysctl
can be modified to change the accept_ra behavior for specific
interfaces.

Change-Id: I8a8d311a14b41baf6e7e1b8ce26a63abc2eaabef
Closes-bug: 1544296
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/82/277182/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/hieradata/common.yaml'],1,dc00b8664d79a524692a18abe9b3d414d6dadfa0,bug/1544296, # prevent neutron bridges from autoconfiguring ipv6 addresses net.ipv6.conf.default.accept_ra: value: 0 net.ipv6.conf.default.autoconf: value: 0 net.ipv6.conf.default.disable_ipv6: value: 1,,7,0
openstack%2Ffreezer~master~Ie05e5fc9f4482c87a828577acd46452c6b4baeb4,openstack/freezer,master,Ie05e5fc9f4482c87a828577acd46452c6b4baeb4,Fix a mistake about  function for install_freezer,MERGED,2016-01-20 16:27:37.000000000,2016-02-18 15:48:42.000000000,2016-02-18 15:48:42.000000000,"[{'_account_id': 3}, {'_account_id': 2467}, {'_account_id': 11151}, {'_account_id': 14509}, {'_account_id': 17108}]","[{'number': 1, 'created': '2016-01-20 16:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e3edd175043d95498fb896664507ca06165200a9', 'message': 'Fix a mistake about  function for install_freezer\n\nChange-Id: Ie05e5fc9f4482c87a828577acd46452c6b4baeb4\n'}, {'number': 2, 'created': '2016-02-18 02:20:34.000000000', 'files': ['devstack/lib/freezer'], 'web_link': 'https://opendev.org/openstack/freezer/commit/05a86e2edf5a73445520c067cb0a6d9a83e6f12b', 'message': 'Fix a mistake about  function for install_freezer\n\nCloses-Bug: #1546839\n\nChange-Id: Ie05e5fc9f4482c87a828577acd46452c6b4baeb4\n'}]",0,270306,05a86e2edf5a73445520c067cb0a6d9a83e6f12b,12,5,2,14101,,,0,"Fix a mistake about  function for install_freezer

Closes-Bug: #1546839

Change-Id: Ie05e5fc9f4482c87a828577acd46452c6b4baeb4
",git fetch https://review.opendev.org/openstack/freezer refs/changes/06/270306/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/freezer'],1,e3edd175043d95498fb896664507ca06165200a9,bug/1546839,function install_freezer {,function install_freezer{,1,1
openstack%2Ftraining-labs~master~I40f4e9c6466953c99255271594409e889392c59b,openstack/training-labs,master,I40f4e9c6466953c99255271594409e889392c59b,Fix race in KVM's vm_delete,MERGED,2016-02-08 05:12:49.000000000,2016-02-18 15:48:32.000000000,2016-02-18 15:48:32.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 10497}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-02-08 05:12:49.000000000', 'files': ['labs/osbash/lib/osbash/kvm-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/8a54ccc85afa43419dc89446030faed9b92f76b5', 'message': ""Fix race in KVM's vm_delete\n\nAfter powering off a KVM VM, we need to sleep before undefining the VM.\n\nWithout the sleep, vm_delete causes an error if the VM in question has\nbeen booted with virt-install (without subsequent reboots).\n\nChange-Id: I40f4e9c6466953c99255271594409e889392c59b\n""}]",0,277282,8a54ccc85afa43419dc89446030faed9b92f76b5,9,4,1,11109,,,0,"Fix race in KVM's vm_delete

After powering off a KVM VM, we need to sleep before undefining the VM.

Without the sleep, vm_delete causes an error if the VM in question has
been booted with virt-install (without subsequent reboots).

Change-Id: I40f4e9c6466953c99255271594409e889392c59b
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/82/277282/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/lib/osbash/kvm-functions.sh'],1,8a54ccc85afa43419dc89446030faed9b92f76b5,fix_race_in_kvm_vm_delete, # Take a break before undefining the VM sleep 1,,2,0
openstack%2Ftraining-labs~master~I9243647dace57bf5567b775c41488615dcea0470,openstack/training-labs,master,I9243647dace57bf5567b775c41488615dcea0470,Add a configuration without software installs,MERGED,2016-02-16 17:51:03.000000000,2016-02-18 15:47:26.000000000,2016-02-18 15:47:26.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 10497}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-02-16 17:51:03.000000000', 'files': ['labs/osbash/config/scripts.ubuntu_nodes_only'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/98d0682409218f59ca73224a1e9dc7d8428664d4', 'message': 'Add a configuration without software installs\n\nThis configuration file is for users who prefer installing and\nconfiguring all software manually. It creates the node VMs, but does not\ninstall any software.\n\nUsage: ./osbash.sh -b nodes_only\n\nChange-Id: I9243647dace57bf5567b775c41488615dcea0470\n'}]",0,280848,98d0682409218f59ca73224a1e9dc7d8428664d4,8,4,1,11109,,,0,"Add a configuration without software installs

This configuration file is for users who prefer installing and
configuring all software manually. It creates the node VMs, but does not
install any software.

Usage: ./osbash.sh -b nodes_only

Change-Id: I9243647dace57bf5567b775c41488615dcea0470
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/48/280848/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/config/scripts.ubuntu_nodes_only'],1,98d0682409218f59ca73224a1e9dc7d8428664d4,nodes_only_config,"#============================================================================== # Only create VMs (don't install any software) #============================================================================== # Scripts for controller node cmd init_node -n controller cmd queue etc_hosts.sh cmd queue osbash/enable_osbash_ssh_keys.sh cmd snapshot_cycle -n controller controller_node_init #============================================================================== # Scripts for compute1 node cmd init_node -n compute1 cmd queue etc_hosts.sh cmd queue osbash/enable_osbash_ssh_keys.sh cmd snapshot_cycle -n compute1 compute1_node_init #============================================================================== # Both nodes are built, boot them cmd boot -n controller cmd boot -n compute1 ",,23,0
openstack%2Ftraining-labs~master~I2ee7d127326b50b91afedffd94b8b51f2ef632d6,openstack/training-labs,master,I2ee7d127326b50b91afedffd94b8b51f2ef632d6,Rename and move snapshot restore functions,MERGED,2016-02-08 19:43:19.000000000,2016-02-18 15:47:17.000000000,2016-02-18 15:47:17.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 10497}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-02-08 19:43:19.000000000', 'files': ['labs/osbash/tools/restore-cluster.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/a47883e3379a5d16ab399fe48d82995835709b79', 'message': 'Rename and move snapshot restore functions\n\nMove VirtualBox-specific functions used to restore snapshots from\nrestore-cluster.sh into virtualbox-functions.sh.\n\nChange-Id: I2ee7d127326b50b91afedffd94b8b51f2ef632d6\n'}]",0,277546,a47883e3379a5d16ab399fe48d82995835709b79,8,4,1,11109,,,0,"Rename and move snapshot restore functions

Move VirtualBox-specific functions used to restore snapshots from
restore-cluster.sh into virtualbox-functions.sh.

Change-Id: I2ee7d127326b50b91afedffd94b8b51f2ef632d6
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/46/277546/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/tools/restore-cluster.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh']",2,a47883e3379a5d16ab399fe48d82995835709b79,snapshot_refactoring,"#------------------------------------------------------------------------------- # Snapshots #------------------------------------------------------------------------------- function vm_snapshot_restore { local vm_name=$1 local shot_name=$2 $VBM snapshot ""$vm_name"" restore ""$shot_name"" # VirtualBox VM needs a break before taking new commands vbox_sleep 1 } function vm_snapshot_restore_current { local vm_name=$1 $VBM snapshot ""$vm_name"" restorecurrent # VirtualBox VM needs a break before taking new commands vbox_sleep 1 } ",,23,13
openstack%2Fopenstacksdk~master~Ib36870f42ac872e54dcf717c590e37761a52af9d,openstack/openstacksdk,master,Ib36870f42ac872e54dcf717c590e37761a52af9d,Support get/set metadata on object_store proxy,ABANDONED,2015-06-04 15:56:59.000000000,2016-02-18 15:45:50.000000000,,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-04 15:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0be0b5fadabf7ce5bffc2fc3c86c7b22528606b3', 'message': ""Support get/set metadata on object_store proxy\n\nGetting and setting metadata on object_store accounts, containers, and\nobjects had been using the old resource instance way of working with\nthem. We can take advantage of the same way we do creates and updates by\nworking directly with the attribute names.\n\nThis includes a change to Object create/update function as it was trying\nto be dual purpose when it really shouldn't be.\n\nChange-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d\n""}, {'number': 2, 'created': '2015-06-04 19:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c6a479a878f9bda95c93415dbaf9e3a6b8b82721', 'message': ""Support get/set metadata on object_store proxy\n\nGetting and setting metadata on object_store accounts, containers, and\nobjects had been using the old resource instance way of working with\nthem. We can take advantage of the same way we do creates and updates by\nworking directly with the attribute names.\n\nThis includes a change to Object create/update function as it was trying\nto be dual purpose when it really shouldn't be.\n\nThis also includes a temporary verify_update3 method. I'm coming in to\nclean the verify mess up after this but don't want to hold this or any\nother change off for a test refactoring.\n\nChange-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d\n""}, {'number': 3, 'created': '2015-06-17 20:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/94122290caf4d8ef5001b9b8aca94766cf180e3f', 'message': ""Support get/set metadata on object_store proxy\n\nGetting and setting metadata on object_store accounts, containers, and\nobjects had been using the old resource instance way of working with\nthem. We can take advantage of the same way we do creates and updates by\nworking directly with the attribute names.\n\nThis includes a change to Object create/update function as it was trying\nto be dual purpose when it really shouldn't be.\n\nThis also includes a temporary verify_update3 method. I'm coming in to\nclean the verify mess up after this but don't want to hold this or any\nother change off for a test refactoring.\n\nPartial-Bug: 1466202\n\nChange-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d\n""}, {'number': 4, 'created': '2015-06-17 22:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ac252e148d3b9a9b328b4c2fedaa09f1e2a00857', 'message': ""Support get/set metadata on object_store proxy\n\nGetting and setting metadata on object_store accounts, containers, and\nobjects had been using the old resource instance way of working with\nthem. We can take advantage of the same way we do creates and updates by\nworking directly with the attribute names.\n\nThis includes a change to Object create/update function as it was trying\nto be dual purpose when it really shouldn't be.\n\nThis also includes a temporary verify_update3 method. I'm coming in to\nclean the verify mess up after this but don't want to hold this or any\nother change off for a test refactoring.\n\nPartial-Bug: 1466202\n\nChange-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d\n""}, {'number': 5, 'created': '2015-07-09 17:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3b00f2b6eb102f8cc893fc6e311388bc92b2d461', 'message': ""WIP: Support get/set metadata on object_store proxy\n\nGetting and setting metadata on object_store accounts, containers, and\nobjects had been using the old resource instance way of working with\nthem. We can take advantage of the same way we do creates and updates by\nworking directly with the attribute names.\n\nThis includes a change to Object create/update function as it was trying\nto be dual purpose when it really shouldn't be.\n\nPartial-Bug: 1466202\n\nChange-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d\n""}, {'number': 6, 'created': '2015-07-14 18:39:16.000000000', 'files': ['openstack/tests/unit/object_store/v1/test_obj.py', 'openstack/object_store/v1/obj.py', 'openstack/tests/unit/object_store/v1/test_proxy.py', 'openstack/tests/unit/test_proxy_base.py', 'openstack/object_store/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/bd0e213f1cdea7768a018f6a436fa9204089e63f', 'message': ""Support get/set metadata on object_store proxy\n\nGetting and setting metadata on object_store accounts, containers, and\nobjects had been using the old resource instance way of working with\nthem. We can take advantage of the same way we do creates and updates by\nworking directly with the attribute names.\n\nThis includes a change to Object create/update function as it was trying\nto be dual purpose when it really shouldn't be.\n\nPartial-Bug: 1466202\n\nChange-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d\n""}]",6,188452,bd0e213f1cdea7768a018f6a436fa9204089e63f,27,4,6,8257,,,0,"Support get/set metadata on object_store proxy

Getting and setting metadata on object_store accounts, containers, and
objects had been using the old resource instance way of working with
them. We can take advantage of the same way we do creates and updates by
working directly with the attribute names.

This includes a change to Object create/update function as it was trying
to be dual purpose when it really shouldn't be.

Partial-Bug: 1466202

Change-Id: Ib36870f42ac872e54dcf717c590e37761a52af9d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/52/188452/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/object_store/v1/obj.py', 'openstack/object_store/v1/_proxy.py']",2,0be0b5fadabf7ce5bffc2fc3c86c7b22528606b3,bug/1466202," def set_account_metadata(self, **attrs): :param dict attrs: Keyword arguments which will be used to create a :class:`~openstack.object_store.v1.container.Container`, comprised of the properties on the Container class. self._update(_container.Container, **attrs) def set_container_metadata(self, container, **attrs): :param dict attrs: Keyword arguments which will be used to create a :class:`~openstack.object_store.v1.container.Container`, comprised of the properties on the Container class. self._update(_container.Container, container, **attrs) def set_object_metadata(self, value, container=None, **attrs): :param value: The object to set metadata for. Can be either the name of an object or an instance of type Object. :type value: :class:`~openstack.object_store.v1.obj.Object` :param container: A container object containing metadata to be set. This parameter is optional if `value` is an actual Object instance. :type container: :class:`~openstack.object_store.v1.container.Container` :param dict attrs: Keyword arguments which will be used to create a :class:`~openstack.object_store.v1.obj.Object`, comprised of the properties on the Object class. self._update(_obj.Object, value, path_args={""container"": container}, **attrs)"," def set_account_metadata(self, container): :param container: Account metadata specified on a :class:`~openstack.object_store.v1.container.Container` object to be sent to the server. :type container: :class:`~openstack.object_store.v1.container.Container` container.update(self.session) def set_container_metadata(self, container): container.create(self.session) def set_object_metadata(self, obj): :param obj: The object to set metadata for. :type obj: :class:`~openstack.object_store.v1.obj.Object` obj.create(self.session)",39,20
openstack%2Ffuel-menu~master~I2d6e0db042058be0bc48c9d66ce4d9066561153c,openstack/fuel-menu,master,I2d6e0db042058be0bc48c9d66ce4d9066561153c,Correctly set hostname via hostnamectl,MERGED,2016-02-18 09:50:40.000000000,2016-02-18 15:34:57.000000000,2016-02-18 15:34:57.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 10443}, {'_account_id': 10488}, {'_account_id': 14200}, {'_account_id': 18290}, {'_account_id': 19560}]","[{'number': 1, 'created': '2016-02-18 09:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/6e2e6518c0ca1e7069e24e50f780f9a0b6c65ea9', 'message': 'Correctly set hostname via hostnamectl\n\nThis commit correctly set hostname under CentOS via hostnamectl.\n\nChange-Id: I2d6e0db042058be0bc48c9d66ce4d9066561153c\nCloses-Bug: #1543357\n'}, {'number': 2, 'created': '2016-02-18 10:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/a3eff6742570546fddd4e5767b4917a2d48783c7', 'message': 'Correctly set hostname via hostnamectl\n\nThis commit correctly set hostname under CentOS via hostnamectl.\n\nChange-Id: I2d6e0db042058be0bc48c9d66ce4d9066561153c\nCloses-Bug: #1543357\n'}, {'number': 3, 'created': '2016-02-18 14:51:31.000000000', 'files': ['fuelmenu/modules/dnsandhostname.py'], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/b14b7a69a81dc9980e4abb9dbb84fdc0678e43af', 'message': 'Correctly set hostname via hostnamectl\n\nThis commit correctly set hostname under CentOS via hostnamectl.\n\nChange-Id: I2d6e0db042058be0bc48c9d66ce4d9066561153c\nCloses-Bug: #1543357\n'}]",1,281725,b14b7a69a81dc9980e4abb9dbb84fdc0678e43af,19,7,3,14200,,,0,"Correctly set hostname via hostnamectl

This commit correctly set hostname under CentOS via hostnamectl.

Change-Id: I2d6e0db042058be0bc48c9d66ce4d9066561153c
Closes-Bug: #1543357
",git fetch https://review.opendev.org/openstack/fuel-menu refs/changes/25/281725/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelmenu/modules/dnsandhostname.py'],1,6e2e6518c0ca1e7069e24e50f780f9a0b6c65ea9,bug/1543357," #Apply hostname os.system('/usr/bin/hostnamectl set-hostname ' + responses[""HOSTNAME""]) "," #Apply hostname expr = 'HOSTNAME=.*' replace.replaceInFile(""/etc/sysconfig/network"", expr, ""HOSTNAME=%s.%s"" % (responses[""HOSTNAME""], responses[""DNS_DOMAIN""]))",5,7
openstack%2Fpython-openstackclient~master~Id3914c6f139a879eead0935d732c45d5564c665b,openstack/python-openstackclient,master,Id3914c6f139a879eead0935d732c45d5564c665b,JSON formatted the metadata for aggregates,ABANDONED,2016-02-17 19:47:31.000000000,2016-02-18 15:29:01.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}]","[{'number': 1, 'created': '2016-02-17 19:47:31.000000000', 'files': ['openstackclient/compute/v2/aggregate.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/418e22a2e03de125dfeae0fb5be03c4ab6fa2afd', 'message': 'JSON formatted the metadata for aggregates\n\nChange-Id: Id3914c6f139a879eead0935d732c45d5564c665b\n'}]",0,281488,418e22a2e03de125dfeae0fb5be03c4ab6fa2afd,4,2,1,13217,,,0,"JSON formatted the metadata for aggregates

Change-Id: Id3914c6f139a879eead0935d732c45d5564c665b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/88/281488/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/aggregate.py'],1,418e22a2e03de125dfeae0fb5be03c4ab6fa2afd,bug/BUG-1538006, # Format hosts list data._info.update({'hosts': utils.format_list( data._info.pop('hosts'))}) # Map 'metadata' column to 'properties' data._info.update({'properties': utils.format_dict( data._info.pop('metadata'))}) resource = compute_client.aggregates.set_metadata( )._info resource.update({'metadata': utils.format_dict( resource.pop('metadata'))}) info.update(resource) d.metadata = format_dict(d.metadata) # Format hosts list data._info.update({'hosts': utils.format_list( data._info.pop('hosts'))}) # Map 'metadata' column to 'properties' data._info.update({'properties': utils.format_dict( data._info.pop('metadata'))}) resource = compute_client.aggregates.set_metadata( )._info resource.update({'metadata': utils.format_dict( resource.pop('metadata'))}) info.update(resource) # Format hosts list info.update({'hosts': utils.format_list(info.pop('hosts'))}) # Format hosts list data._info.update({'hosts': utils.format_list( data._info.pop('hosts'))}) data._info.update({'properties': utils.format_dict( data._info.pop('metadata'))}), info.update(compute_client.aggregates.set_metadata( )._info) info.update(compute_client.aggregates.set_metadata( )._info) data._info.update({'properties': data._info.pop('metadata')}),34,5
openstack%2Ffuel-main~master~I20c2c53d823372b44a6c9409f0ee46c1d1910782,openstack/fuel-main,master,I20c2c53d823372b44a6c9409f0ee46c1d1910782,Add Yum configuration to the fuel-release package,MERGED,2016-02-16 14:31:16.000000000,2016-02-18 15:28:56.000000000,2016-02-18 15:28:55.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7613}, {'_account_id': 8777}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 12841}, {'_account_id': 13194}, {'_account_id': 13895}, {'_account_id': 14318}, {'_account_id': 14981}, {'_account_id': 16574}]","[{'number': 1, 'created': '2016-02-16 14:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/36f83f0de57764314ab64abb9dd6cb9a789e2bdf', 'message': 'Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 2, 'created': '2016-02-16 14:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/650d753c8344a1d5311f74859e47586e75d670b8', 'message': 'Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 3, 'created': '2016-02-17 12:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/accb9dd411c45c44b523b2b8ec72fe04de513064', 'message': 'Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 4, 'created': '2016-02-17 13:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8d9f5a19b899452f8140587ff51095a3fdba1154', 'message': 'Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 5, 'created': '2016-02-17 14:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b5ff33893ec007026474353a85e00a367302d6b0', 'message': 'Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n'}, {'number': 6, 'created': '2016-02-17 14:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/99991b60347e89825a048d8ebf50a423b6878f1b', 'message': ""Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nAlso remove Fuel packages that directly depend on\nthe 'fuel' package from the FUEL_PACKAGES var\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n""}, {'number': 7, 'created': '2016-02-18 12:20:01.000000000', 'files': ['fuel-release/mos-updates.repo', 'fuel-release/RPM-GPG-KEY-mos', 'fuel-release/mos-os.repo', 'iso/bootstrap_admin_node.sh', 'specs/fuel-main.spec', 'fuel-release/mos-security.repo'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/17b753df7323f1fb691e10823e032762f7d18400', 'message': ""Add Yum configuration to the fuel-release package\n\nThis package installs the following Yum configuration\nentries for Fuel Admin node:\n\n* base, updates and security MOS repos (enabled by default)\n* repos configuration includes online mirrorlists\n* GPG key for MOS packages (verification is enabled)\n\nAlso remove Fuel packages that directly depend on\nthe 'fuel' package from the FUEL_PACKAGES var\n\nChange-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782\nBlueprint: separate-fuel-node-provisioning\n""}]",11,280729,17b753df7323f1fb691e10823e032762f7d18400,32,12,7,10474,,,0,"Add Yum configuration to the fuel-release package

This package installs the following Yum configuration
entries for Fuel Admin node:

* base, updates and security MOS repos (enabled by default)
* repos configuration includes online mirrorlists
* GPG key for MOS packages (verification is enabled)

Also remove Fuel packages that directly depend on
the 'fuel' package from the FUEL_PACKAGES var

Change-Id: I20c2c53d823372b44a6c9409f0ee46c1d1910782
Blueprint: separate-fuel-node-provisioning
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/29/280729/6 && git format-patch -1 --stdout FETCH_HEAD,"['fuel-release/mos-updates.repo', 'fuel-release/RPM-GPG-KEY-mos', 'fuel-release/mos-os.repo', 'iso/bootstrap_admin_node.sh', 'specs/fuel-main.spec', 'fuel-release/mos-security.repo']",6,36f83f0de57764314ab64abb9dd6cb9a789e2bdf,separate-fuel-node-provisioning,[mos$fuelver-security] name=mos$fuelver-security #baseurl=http://mirror.fuel-infra.org/mos-repos/centos/mos$fuelver-centos$releasever-fuel/security/x86_64/ mirrorlist=http://mirror.fuel-infra.org/mos-repos/centos/mos$fuelver-centos$releasever-fuel/mos-mirrors-security.txt enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/fuel-gpg/RPM-GPG-KEY-mos skip_if_unavailable=1 ,,76,22
openstack%2Fpython-novaclient~master~Ie682111127584a33d8e96377d812d3a6352c760d,openstack/python-novaclient,master,Ie682111127584a33d8e96377d812d3a6352c760d,Allow to specify a network for functional tests,MERGED,2015-10-28 15:33:54.000000000,2016-02-18 15:20:56.000000000,2016-02-18 15:20:56.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 2062}, {'_account_id': 6593}, {'_account_id': 7102}]","[{'number': 1, 'created': '2015-10-28 15:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e17bc832fe102edbc41d5a31e72754904c9ecc80', 'message': 'Allow to specify a network for functional tests\n\nCurrently the tests just attach instances to the first network returned\nby ""net-list"". That might however not be the right thing in some\nenvironments. This change allows to override the default network via the\nenvironment variable ""OS_NOVACLIENT_NETWORK"". If not specified the\ntest will fallback to the old behaviour and just use the first network.\n\nCloses-Bug: #1510975\nChange-Id: Ie682111127584a33d8e96377d812d3a6352c760d\n'}, {'number': 2, 'created': '2016-02-16 11:44:45.000000000', 'files': ['novaclient/tests/functional/base.py', 'novaclient/tests/functional/v2/legacy/test_instances.py', 'novaclient/tests/functional/api/test_servers.py', 'novaclient/tests/functional/v2/legacy/test_servers.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/8a2ed13620e78f4b82e68028e86745e8c86240b0', 'message': 'Allow to specify a network for functional tests\n\nCurrently the tests just attach instances to the first network returned\nby ""net-list"". That might however not be the right thing in some\nenvironments. This change allows to override the default network via the\nenvironment variable ""OS_NOVACLIENT_NETWORK"". If not specified the\ntest will fallback to the old behaviour and just use the first network.\n\nCloses-Bug: #1510975\nChange-Id: Ie682111127584a33d8e96377d812d3a6352c760d\n'}]",1,239971,8a2ed13620e78f4b82e68028e86745e8c86240b0,17,6,2,2062,,,0,"Allow to specify a network for functional tests

Currently the tests just attach instances to the first network returned
by ""net-list"". That might however not be the right thing in some
environments. This change allows to override the default network via the
environment variable ""OS_NOVACLIENT_NETWORK"". If not specified the
test will fallback to the old behaviour and just use the first network.

Closes-Bug: #1510975
Change-Id: Ie682111127584a33d8e96377d812d3a6352c760d
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/71/239971/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/functional/base.py', 'novaclient/tests/functional/v2/legacy/test_instances.py', 'novaclient/tests/functional/api/test_servers.py', 'novaclient/tests/functional/v2/legacy/test_servers.py']",4,e17bc832fe102edbc41d5a31e72754904c9ecc80,bug/1510975," name, self.image, self.flavor, nics=[{""net-id"": self.network.id}]))"," network = self.client.networks.list()[0] name, self.image, self.flavor, nics=[{""net-id"": network.id}]))",22,6
openstack%2Fkarbor~master~Icc9acc0c10a4ae586c78a87426df0dcd13e544e9,openstack/karbor,master,Icc9acc0c10a4ae586c78a87426df0dcd13e544e9,operation engine design,MERGED,2015-12-31 03:36:21.000000000,2016-02-18 15:18:00.000000000,2016-02-18 15:18:00.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 13070}, {'_account_id': 15069}, {'_account_id': 16203}, {'_account_id': 17151}, {'_account_id': 18266}]","[{'number': 1, 'created': '2015-12-31 03:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/4bacb1c43077ee7a14708eabba18969cabf17052', 'message': 'schedule service design\n\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\nImplements: blueprint schedule-service-design\n'}, {'number': 2, 'created': '2015-12-31 03:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/813cda25e428bf6d66a75aa37f36558ab854470f', 'message': 'schedule service design\n\nImplements: blueprint schedule-service-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 3, 'created': '2015-12-31 06:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/8463a0dfc9df899758c7f83e2aa96c181435b49d', 'message': 'schedule service design\n\nImplements: blueprint schedule-service-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 4, 'created': '2015-12-31 09:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/a1f008a3e0451fe2315faad0881eb9411ed06ee5', 'message': 'schedule service design\n\nImplements: blueprint schedule-service-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 5, 'created': '2015-12-31 10:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/d829d20ed1fa199ee1f3fe2932bfc9c203960741', 'message': 'schedule service design\n\nImplements: blueprint schedule-service-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 6, 'created': '2015-12-31 10:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/d36c679dfd3c197b2cd7004314bfcf6c4394ff8f', 'message': 'schedule service design\n\nImplements: blueprint schedule-service-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 7, 'created': '2015-12-31 10:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/21d2d5ba365f4a90a649e0ff05b6cec84053a1de', 'message': 'schedule service design\n\nImplements: blueprint schedule-service-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 8, 'created': '2016-01-05 03:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/48f6afa43e9996628b045894c215687c466b2423', 'message': 'schedule service design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 9, 'created': '2016-01-05 03:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/696a3d0006576565c78c915f861534e5876d83c9', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 10, 'created': '2016-01-15 07:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/4f857548cef0bcc22f73e5aad180d6a916309ad8', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 11, 'created': '2016-01-15 09:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/7edaa5bd3932814d25a86753aa5d2c1394dd9376', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 12, 'created': '2016-01-15 09:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/205d506519cda8e2ff702e1e61e2cb0ddc596928', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 13, 'created': '2016-01-15 09:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/688de47a2b73260612f66acf51412a29f780eec3', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 14, 'created': '2016-01-18 02:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/09be3db81f9be241e2fca5a93e08279a099eb54f', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 15, 'created': '2016-01-25 02:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/f2a51b1e8c69f386e2488a7425459a5454fe10a8', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 16, 'created': '2016-01-26 08:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/1563098b08e7660646bd3ac8dfa08c20b4cb5f2d', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 17, 'created': '2016-01-29 02:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/7618aabc3421b33149a046a92883a7ac6663557c', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 18, 'created': '2016-01-29 06:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/1031800829182d26387a34e69ad68fb6e1c44afb', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 19, 'created': '2016-02-01 03:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/df94e2459d18572b4de1228d56ac0ff7b4d595ee', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 20, 'created': '2016-02-01 03:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/bb13d16ddbff3d8e7845cdd35f2eacf04a118dbc', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}, {'number': 21, 'created': '2016-02-03 02:49:00.000000000', 'files': ['doc/source/specs/operation-engine/operation_engine_class_diagram.pu', 'doc/images/operation-engine/operation_engine_architecture_diagram.png', 'doc/source/specs/operation-engine/create_scheduled_operation_seq_diagram.pu', 'doc/images/operation-engine/operation_engine_class_diagram.png', 'doc/source/specs/operation-engine/operation_engine_design.rst', 'doc/images/operation-engine/operation_state_diagram.png', 'doc/images/operation-engine/delete_scheduled_operation_seq_diagram.png', 'doc/source/specs/operation-engine/operation_state_diagram.pu', 'doc/images/operation-engine/create_scheduled_operation_seq_diagram.png', 'doc/source/specs/operation-engine/delete_scheduled_operation_seq_diagram.pu'], 'web_link': 'https://opendev.org/openstack/karbor/commit/2ec95a645fe156f4514f30ed57abf7061c219f85', 'message': 'operation engine design\n\nImplements: blueprint operation-engine-design\nChange-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9\n'}]",59,262649,2ec95a645fe156f4514f30ed57abf7061c219f85,74,7,21,18266,,,0,"operation engine design

Implements: blueprint operation-engine-design
Change-Id: Icc9acc0c10a4ae586c78a87426df0dcd13e544e9
",git fetch https://review.opendev.org/openstack/karbor refs/changes/49/262649/14 && git format-patch -1 --stdout FETCH_HEAD,"['doc/images/schedule-service/delete_scheduled_operation_seq_diagram.png', 'doc/source/schedule-service/list_or_get_trigger_seq_diagram.pu', 'doc/images/schedule-service/list_or_get_scheduled_operation_seq_diagram.png', 'doc/images/schedule-service/create_trigger_seq_diagram.png', 'doc/source/schedule-service/list_or_get_scheduled_operation_seq_diagram.pu', 'doc/images/schedule-service/schedule_service_architecture_diagram.png', 'doc/images/schedule-service/delete_trigger_seq_diagram.png', 'doc/images/schedule-service/time_trigger_thead_seq_diagram.png', 'doc/source/schedule-service/create_scheduled_operation_seq_diagram.pu', 'doc/source/schedule-service/delete_trigger_seq_diagram.pu', 'doc/source/schedule-service/time_trigger_thead_seq_diagram.pu', 'doc/images/schedule-service/create_scheduled_operation_seq_diagram.png', 'doc/source/schedule-service/create_trigger_seq_diagram.pu', 'doc/source/schedule-service/schedule_service_design.rst', 'doc/source/schedule-service/delete_scheduled_operation_seq_diagram.pu', 'doc/images/schedule-service/list_or_get_trigger_seq_diagram.png']",16,4bacb1c43077ee7a14708eabba18969cabf17052,bp/operation-engine-design,,,277,0
openstack%2Fkolla~master~Ic36f1d22c1c011844f076828a7aef4d96da5e074,openstack/kolla,master,Ic36f1d22c1c011844f076828a7aef4d96da5e074,Add double quotes in kolla_enable_sanity_checks,MERGED,2016-02-18 13:01:15.000000000,2016-02-18 15:13:31.000000000,2016-02-18 15:13:31.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 14119}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-18 13:01:15.000000000', 'files': ['ansible/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0bdb1f511724e94455686760e9d6e15b31828ca8', 'message': 'Add double quotes in kolla_enable_sanity_checks\n\nTrivialFix\n\nChange-Id: Ic36f1d22c1c011844f076828a7aef4d96da5e074\n'}]",0,281823,0bdb1f511724e94455686760e9d6e15b31828ca8,8,4,1,16233,,,0,"Add double quotes in kolla_enable_sanity_checks

TrivialFix

Change-Id: Ic36f1d22c1c011844f076828a7aef4d96da5e074
",git fetch https://review.opendev.org/openstack/kolla refs/changes/23/281823/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/group_vars/all.yml'],1,0bdb1f511724e94455686760e9d6e15b31828ca8,,"kolla_enable_sanity_checks: ""no""",kolla_enable_sanity_checks: no,1,1
openstack%2Fnova~master~If3edc1965c01a077eb61984a442e0d778d870d75,openstack/nova,master,If3edc1965c01a077eb61984a442e0d778d870d75,Fix create snapshot failure on VMs with SRIOV,MERGED,2015-12-30 00:23:50.000000000,2016-02-18 15:11:19.000000000,2016-02-18 15:11:15.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12171}, {'_account_id': 15286}, {'_account_id': 15427}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-30 00:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4947a55332d9ced74dc60d58f6f77dc388854af5', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}, {'number': 2, 'created': '2016-01-04 15:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a90f4a743ef7e4bd829cb1f01c5b9f6ae49d4b24', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}, {'number': 3, 'created': '2016-01-19 22:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/060f1fa9da17eb8c8b6cafb2f28b8fa212269e92', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}, {'number': 4, 'created': '2016-01-20 16:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0dcf7bc1f6d7faabf1e5952479a9635f88163d58', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}, {'number': 5, 'created': '2016-01-21 00:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c7ad0cccb4231a68add4d1c2757284e37b9f131', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}, {'number': 6, 'created': '2016-01-29 09:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ade9d648d6e6fb700683f9af7da6e392fe2e86ac', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}, {'number': 7, 'created': '2016-02-15 21:38:33.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f93d808bc3ba1c0a97ec46f345fad9c0d00865f8', 'message': ""Fix create snapshot failure on VMs with SRIOV\n\nOne use-case of guest VM network protection using SRIOV ports is having\ntwo direct ports connected to a VM, each one is related to a network that\nis connected to a different physical NIC on the host (e.g. phyNet1 on\neth0 and phyNet2 on eth1). In this use-case, due to some physical NICs\nlimitations it's advised to configure both ports with the same MAC\naddress (or else outgoing or incoming traffic will not reach its\ndestination in case of fail-over).\n\nSnapshot creation on such VMs fails since libvirt's detach-interface\ndoesn't know which interface of the two to detach and fails. This is why\nI've changed the call inside _detach_sriov_ports from (the equivalent\nof) detach-interface to _detach_pci_devices with the source-device\npci address of the SRIOV VF (always present in the context of SRIOV\nof course).\n\nThis fix was tested on a real environment containing the above type of\nVMs. test_driver.test_detach_sriov_ports was slightly modified so\nthat the VIF from which data is sent to _detach_pci_devices will\ncontain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)\n\nChange-Id: If3edc1965c01a077eb61984a442e0d778d870d75\nCloses-Bug: #1529785\n""}]",9,262341,f93d808bc3ba1c0a97ec46f345fad9c0d00865f8,106,15,7,15427,,,0,"Fix create snapshot failure on VMs with SRIOV

One use-case of guest VM network protection using SRIOV ports is having
two direct ports connected to a VM, each one is related to a network that
is connected to a different physical NIC on the host (e.g. phyNet1 on
eth0 and phyNet2 on eth1). In this use-case, due to some physical NICs
limitations it's advised to configure both ports with the same MAC
address (or else outgoing or incoming traffic will not reach its
destination in case of fail-over).

Snapshot creation on such VMs fails since libvirt's detach-interface
doesn't know which interface of the two to detach and fails. This is why
I've changed the call inside _detach_sriov_ports from (the equivalent
of) detach-interface to _detach_pci_devices with the source-device
pci address of the SRIOV VF (always present in the context of SRIOV
of course).

This fix was tested on a real environment containing the above type of
VMs. test_driver.test_detach_sriov_ports was slightly modified so
that the VIF from which data is sent to _detach_pci_devices will
contain the correct SRIOV values (pci_slot, vlan and hw_veb VIF type)

Change-Id: If3edc1965c01a077eb61984a442e0d778d870d75
Closes-Bug: #1529785
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/262341/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,4947a55332d9ced74dc60d58f6f77dc388854af5,bug/1529785," # some more adjustments for the fake network_info so that # the correct get_config function will be executed (vif's # get_config_hw_veb - which is according to the real SRIOV vif) # and most importantly the pci_slot which is translated to # cfg.source_dev, then to PciDevice.address and sent to # _detach_pci_devices network_info[0]['profile'] = dict(pci_slot=""0000:00:00.0"") network_info[0]['type'] = ""hw_veb"" network_info[0]['details'] = dict(vlan=""2145"")",,17,1
openstack%2Faodh~master~Ib214d36b06a17c6ff7b7656be87ccabf1af33048,openstack/aodh,master,Ib214d36b06a17c6ff7b7656be87ccabf1af33048,Remove ceilometer-alarm-* related content of installation,MERGED,2016-02-16 05:54:59.000000000,2016-02-18 15:08:03.000000000,2016-02-18 15:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-02-16 05:54:59.000000000', 'files': ['devstack/settings', 'doc/source/install/development.rst'], 'web_link': 'https://opendev.org/openstack/aodh/commit/4171cdff8accbc27091883eef81f8528c31243bb', 'message': 'Remove ceilometer-alarm-* related content of installation\n\nWe have removed the alarm service from ceilometer code tree.\n\nChange-Id: Ib214d36b06a17c6ff7b7656be87ccabf1af33048\n'}]",0,280503,4171cdff8accbc27091883eef81f8528c31243bb,7,3,1,8290,,,0,"Remove ceilometer-alarm-* related content of installation

We have removed the alarm service from ceilometer code tree.

Change-Id: Ib214d36b06a17c6ff7b7656be87ccabf1af33048
",git fetch https://review.opendev.org/openstack/aodh refs/changes/03/280503/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/settings', 'doc/source/install/development.rst']",2,4171cdff8accbc27091883eef81f8528c31243bb,rm-ceilo-alarm,," enable_service aodh-evaluator,aodh-notifier,aodh-api disable_service ceilometer-alarm-notifier,ceilometer-alarm-evaluator The first group of daemons are necessary for core aodh functionality: polling, event listening, and data collection.",0,7
openstack%2Fdragonflow~master~Ia04e750874c433ac009782c192f5e3265f990cf8,openstack/dragonflow,master,Ia04e750874c433ac009782c192f5e3265f990cf8,Add performance testing spec,MERGED,2016-01-26 14:28:42.000000000,2016-02-18 15:07:34.000000000,2016-02-18 15:07:34.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 18811}, {'_account_id': 18903}, {'_account_id': 20188}, {'_account_id': 20229}, {'_account_id': 20297}]","[{'number': 1, 'created': '2016-01-26 14:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/13efcf4467846742edd263c3a7cecdaf345de4da', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}, {'number': 2, 'created': '2016-02-01 10:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2f33ca302d2557ccc265891447f0c78de7d4d478', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}, {'number': 3, 'created': '2016-02-02 08:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7cb911c4e84b65b2d17b61508df130bcf227eee8', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}, {'number': 4, 'created': '2016-02-16 11:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6d6d65b8bd9c6040a97716a50d399bc9600c68f5', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}, {'number': 5, 'created': '2016-02-16 12:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ca72fc4382061a1e7bec2097973f86a9ff7807aa', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}, {'number': 6, 'created': '2016-02-18 07:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ebb4e95cd9dd06d5fe5448505bd39c8bcb14f82d', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}, {'number': 7, 'created': '2016-02-18 11:51:17.000000000', 'files': ['doc/source/specs/performance_testing.rst', 'doc/source/specs/index.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d2f56e649ee022c76c121d380f0b0d431da1a802', 'message': 'Add performance testing spec\n\nChange-Id: Ia04e750874c433ac009782c192f5e3265f990cf8\n'}]",5,272559,d2f56e649ee022c76c121d380f0b0d431da1a802,32,9,7,18811,,,0,"Add performance testing spec

Change-Id: Ia04e750874c433ac009782c192f5e3265f990cf8
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/59/272559/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/performance_testing.rst', 'doc/source/specs/index.rst']",2,13efcf4467846742edd263c3a7cecdaf345de4da,perf-spec, performance_testing,,124,0
openstack%2Fmurano~master~I8b26cb0e7e5ad4a838099c7aa3ced31b96f28ca2,openstack/murano,master,I8b26cb0e7e5ad4a838099c7aa3ced31b96f28ca2,"Remove incorrectly used ""# flake8: noqa""",MERGED,2016-02-18 11:40:30.000000000,2016-02-18 15:06:30.000000000,2016-02-18 15:06:30.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 12597}, {'_account_id': 13323}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-18 11:40:30.000000000', 'files': ['tools/install_venv.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/8b5fcdb21fe0f07e674498b31fcedfa831e8d068', 'message': 'Remove incorrectly used ""# flake8: noqa""\n\n""# flake8: noqa"" option disables all checks for the whole file.\nTo disable one line we should use ""# noqa"".\nRemove unused ""# flake8: noqa"" and fix hidden hacking errors.\n\nChange-Id: I8b26cb0e7e5ad4a838099c7aa3ced31b96f28ca2\nCloses-Bug: #1540254\n'}]",0,281778,8b5fcdb21fe0f07e674498b31fcedfa831e8d068,12,7,1,8686,,,0,"Remove incorrectly used ""# flake8: noqa""

""# flake8: noqa"" option disables all checks for the whole file.
To disable one line we should use ""# noqa"".
Remove unused ""# flake8: noqa"" and fix hidden hacking errors.

Change-Id: I8b26cb0e7e5ad4a838099c7aa3ced31b96f28ca2
Closes-Bug: #1540254
",git fetch https://review.opendev.org/openstack/murano refs/changes/78/281778/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_venv.py'],1,8b5fcdb21fe0f07e674498b31fcedfa831e8d068,bug/1540254,"import install_venv_common as install_venv print(help % dict(project=project, venv=venv, root=root))","import install_venv_common as install_venv # flake8: noqa print help % dict(project=project, venv=venv, root=root)",2,2
openstack%2Fkarbor~master~Id420597701e139be842858b6299ed133153f6ae9,openstack/karbor,master,Id420597701e139be842858b6299ed133153f6ae9,Integrate graph building with the ProtectableRegistry,MERGED,2016-02-14 16:24:56.000000000,2016-02-18 15:05:42.000000000,2016-02-18 15:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 13070}, {'_account_id': 16203}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-14 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/2413f2d2217445ffd9df10bfe04c4b77aa0e6dc7', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protection Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 2, 'created': '2016-02-14 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/4290ee0d9da76c882470e3849a21888b83dc5c8a', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 3, 'created': '2016-02-15 09:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/6efe873f613e2d8bf7c963d60d196c0e7a11d12d', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 4, 'created': '2016-02-15 12:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/b7ecdf567187cff1a82f0624f963dc986cbd957b', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 5, 'created': '2016-02-15 17:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/d13a55c3ee8ba81fc7e374552bcc6c1a74507746', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 6, 'created': '2016-02-16 12:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/a25a4ae8e1c4863b647490214be1a6c25419f33f', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 7, 'created': '2016-02-16 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/80130baafba185eba49d5ecff5e08b1fbf2c3d4f', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}, {'number': 8, 'created': '2016-02-18 14:25:41.000000000', 'files': ['smaug/services/protection/protectable_registry.py', 'smaug/services/protection/graph.py', 'smaug/tests/unit/protection/test_protectable.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/49ea63ce130ac2ee75ad7f9311a9a3161a21dbf0', 'message': 'Integrate graph building with the ProtectableRegistry\n\nThis patch integrates the Protectable Registry with the graph builder.\nThis allows it to build the resource graph according to the currently\nregistered Protectable Plugins.\n\nChange-Id: Id420597701e139be842858b6299ed133153f6ae9\n'}]",3,280000,49ea63ce130ac2ee75ad7f9311a9a3161a21dbf0,23,4,8,2023,,,0,"Integrate graph building with the ProtectableRegistry

This patch integrates the Protectable Registry with the graph builder.
This allows it to build the resource graph according to the currently
registered Protectable Plugins.

Change-Id: Id420597701e139be842858b6299ed133153f6ae9
",git fetch https://review.opendev.org/openstack/karbor refs/changes/00/280000/8 && git format-patch -1 --stdout FETCH_HEAD,"['smaug/services/protection/protectable_registry.py', 'smaug/tests/unit/protection/test_protectable.py']",2,2413f2d2217445ffd9df10bfe04c4b77aa0e6dc7,service_move,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from smaug.services.protection.protectable_registry import ProtectableRegistry from smaug.services.protection.protectable_plugin import ProtectablePlugin from smaug.resource import Resource from smaug.tests import base _FAKE_TYPE = ""Smaug::Test::Fake"" class _FakeProtectablePlugin(ProtectablePlugin): def __init__(self): super(_FakeProtectablePlugin, self).__init__() self.graph = {} def get_resource_type(self): return _FAKE_TYPE def get_parent_resource_types(self): return _FAKE_TYPE def list_resources(self): return self.graph.values() def fetch_child_resources(self, parent_resource): return self.graph[parent_resource] class ProtectableRegistryTest(base.TestCase): def setUp(self): super(ProtectableRegistryTest, self).setUp() self.__map_backup = ProtectableRegistry._protectable_map ProtectableRegistry._protectable_map = {} self._fake_plugin = _FakeProtectablePlugin() ProtectableRegistry.register_plugin(self._fake_plugin) def test_graph_building(self): A = Resource(_FAKE_TYPE, ""A"") B = Resource(_FAKE_TYPE, ""B"") C = Resource(_FAKE_TYPE, ""C"") test_matrix = ( ({ A: [B], B: [C], C: [], }, (A, C)), ({ A: [C], B: [C], C: [], }, (A, C)), ) for g, resources in test_matrix: self._fake_plugin.graph = g result_graph = ProtectableRegistry.build_graph(resources) self.assert_graph(result_graph, g) def assert_graph(self, g, g_dict): for item in g: expected = set(g_dict[item.value]) found = set(child.value for child in item.child_nodes) self.assertEqual(found, expected) self.assert_graph(item.child_nodes, g_dict) def tearDown(self): ProtectableRegistry._protectable_map = self.__map_backup super(ProtectableRegistryTest, self).tearDown() ",,100,6
openstack%2Fkolla~master~Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738,openstack/kolla,master,Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738,Also remove the volumes when cleaning up containers,MERGED,2016-02-16 14:20:13.000000000,2016-02-18 15:03:23.000000000,2016-02-18 15:03:23.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 13039}, {'_account_id': 14119}, {'_account_id': 18009}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-02-16 14:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4ee72b3e9a22ed2f8726fcec158b8e97baecc542', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 2, 'created': '2016-02-16 14:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a765a4cf76cbaf11c3a34cf2fb013ca241e3d400', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 3, 'created': '2016-02-17 11:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2bf93e3caff5ac377417cfbbbe1d0835bb388b3d', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 4, 'created': '2016-02-17 14:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0579d61b8429546980650095ba8dfffc9a79c95e', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 5, 'created': '2016-02-18 01:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/30b057a8d0b48ab586f3e91c7133f5bf1b12749a', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 6, 'created': '2016-02-18 06:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c4c7a33f48ff28567a0f00aa66872444fb60f9f8', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 7, 'created': '2016-02-18 07:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bbaafc6c499dc49853c43baaf249528689f68655', 'message': 'also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}, {'number': 8, 'created': '2016-02-18 08:07:01.000000000', 'files': ['tools/cleanup-containers'], 'web_link': 'https://opendev.org/openstack/kolla/commit/29833132d8f1df678f1e9ad7348e27311e3f5a3c', 'message': 'Also remove the volumes when cleaning up containers\n\nTrivialFix\n\nChange-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738\n'}]",8,280722,29833132d8f1df678f1e9ad7348e27311e3f5a3c,42,7,8,7488,,,0,"Also remove the volumes when cleaning up containers

TrivialFix

Change-Id: Ia52451d2c0de09ee9dcf79211389a3b1ce4ae738
",git fetch https://review.opendev.org/openstack/kolla refs/changes/22/280722/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/cleanup-containers'],1,4ee72b3e9a22ed2f8726fcec158b8e97baecc542,minor/remove_volumes," volumes_to_remove=($(docker volume ls | grep -E ""$1"" | awk '{print $1}')) volumes_to_remove=( glance \ ironic-pex \ mariadb \ openvswitch_db \ neutron_metadata_socket \ nova_{compute,libvirt} \ rabbitmq \ rsyslog )echo ""Removing volumes..."" (docker volume rm ${volumes_to_remove[@]} 2>&1) > /dev/null ",,14,0
openstack%2Fmanila~master~Ia51b4b8c1b2a07e020cf9803c0f4c1b0088d3835,openstack/manila,master,Ia51b4b8c1b2a07e020cf9803c0f4c1b0088d3835,Display the 10 slowest tests,ABANDONED,2016-02-17 15:41:18.000000000,2016-02-18 15:02:45.000000000,,"[{'_account_id': 3}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15942}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19132}]","[{'number': 1, 'created': '2016-02-17 15:41:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/3edc70f6b395bb201f2535325eba97c1df244eb8', 'message': 'Display the 10 slowest tests\n\nIf we use run_tests.sh, it will print a list of the 10 slowest tests in the last.\nWe can add the same arguments in tox.ini to achieve the feature. It will help us find\ntest cases that take too much time.\n\nChange-Id: Ia51b4b8c1b2a07e020cf9803c0f4c1b0088d3835\n'}]",0,281337,3edc70f6b395bb201f2535325eba97c1df244eb8,14,11,1,19132,,,0,"Display the 10 slowest tests

If we use run_tests.sh, it will print a list of the 10 slowest tests in the last.
We can add the same arguments in tox.ini to achieve the feature. It will help us find
test cases that take too much time.

Change-Id: Ia51b4b8c1b2a07e020cf9803c0f4c1b0088d3835
",git fetch https://review.opendev.org/openstack/manila refs/changes/37/281337/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3edc70f6b395bb201f2535325eba97c1df244eb8,improve-tox-configuration, python setup.py testr --slowest --testr-args='{posargs}', python setup.py testr --testr-args='{posargs}',1,1
openstack%2Fnova~master~Ibb5158f453abd9717e6d2ab501295351ca9d0dcf,openstack/nova,master,Ibb5158f453abd9717e6d2ab501295351ca9d0dcf,Update instance host in post live migration even when exception occurs,MERGED,2015-10-16 16:07:40.000000000,2016-02-18 15:01:51.000000000,2016-02-18 15:01:50.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 12299}, {'_account_id': 12814}, {'_account_id': 14131}, {'_account_id': 14384}, {'_account_id': 14819}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16935}]","[{'number': 1, 'created': '2015-10-16 16:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b789efa37df069df1af5a3ad68783e5432816655', 'message': 'Finish post live migration even when port binding fails\n\nCurrently when port binding fails on destination host nova loses\ntrack of running VM. Operator needs to change records in DB manually\nin order to restore such VM and then perform actions to restore\nVM networking.\n\nBecause ""vif_type=Binding failed"" is a valid state and indicates\na potentially transient condition and VM is also already on destination\nhost VM should be updated regardless of post live migration at\ndestination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 2, 'created': '2015-10-19 05:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15259cbb881e28269e7d1f055ecb78c5be413643', 'message': 'Finish post live migration even when port binding fails\n\nCurrently when port binding fails on destination host nova loses\ntrack of running VM. Operator needs to change records in DB manually\nin order to restore such VM and then perform actions to restore\nVM networking.\n\nBecause ""vif_type=Binding failed"" is a valid state and indicates\na potentially transient condition and VM is also already on destination\nhost VM should be updated regardless of post live migration at\ndestination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 3, 'created': '2015-10-19 06:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09bef4f23ec386a87e4ec4b396cfb309998fd81f', 'message': 'Finish post live migration even when port binding fails\n\nCurrently when port binding fails on destination host nova loses\ntrack of running VM. Operator needs to change records in DB manually\nin order to restore such VM and then perform actions to restore\nVM networking.\n\nBecause ""vif_type=Binding failed"" is a valid state and indicates\na potentially transient condition and VM is also already on destination\nhost VM should be updated regardless of post live migration at\ndestination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 4, 'created': '2015-10-19 07:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd9f8b68534e9aa81cb6c43cfdf2526fbdc6ceff', 'message': 'Finish post live migration even when port binding fails\n\nCurrently when port binding fails on destination host nova loses\ntrack of running VM. Operator needs to change records in DB manually\nin order to restore such VM and then perform actions to restore\nVM networking.\n\nBecause ""vif_type=Binding failed"" is a valid state and indicates\na potentially transient condition and VM is also already on destination\nhost VM should be updated regardless of post live migration at\ndestination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 5, 'created': '2015-11-16 11:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6cb42c6d5a49575d269096fc98d7eaa447585ca', 'message': 'Finish post live migration even when port binding fails\n\nCurrently when port binding fails on destination host nova loses\ntrack of running VM. Operator needs to change records in DB manually\nin order to restore such VM and then perform actions to restore\nVM networking.\n\nBecause ""vif_type=Binding failed"" is a valid state and indicates\na potentially transient condition and VM is also already on destination\nhost VM should be updated regardless of post live migration at\ndestination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 6, 'created': '2015-11-16 11:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fa7f2c4c2b75421ae47b58e0e66542c16a5cfde', 'message': 'Finish post live migration even when exception occurs\n\nCurrently when, e.g., port binding fails on destination host nova\nloses track of running VM. Operator needs to change record in DB\nmanually in order to recover VM in nova and then perform\noperations on destination host to repair such VM.\n\nBecause VM is on destination host already it should be updated\nregardless of post live migration at destination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 7, 'created': '2015-12-18 09:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8ac15250451540ab7afe1ded4f8ba28d2885465', 'message': 'Finish post live migration even when exception occurs\n\nCurrently when, e.g., port binding fails on destination host nova\nloses track of running VM. Operator needs to change record in DB\nmanually in order to recover VM in nova and then perform operations\non destination host to repair such VM. Because VM is on destination\nhost already it should be updated regardless of post live migration\nat destination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 8, 'created': '2016-01-14 08:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c181c793440d642dde569a1850f8aadf6531375f', 'message': 'Finish post live migration even when exception occurs\n\nCurrently when, e.g., port binding fails on destination host nova\nloses track of running VM. Operator needs to change record in DB\nmanually in order to recover VM in nova and then perform operations\non destination host to repair such VM. Because VM is on destination\nhost already it should be updated regardless of post live migration\nat destination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 9, 'created': '2016-02-01 17:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/473855ad738393d011667d99a4f6d4830839900e', 'message': 'Finish post live migration even when exception occurs\n\nCurrently when, e.g., port binding fails on destination host nova\nloses track of running VM. Operator needs to change record in DB\nmanually in order to recover VM in nova and then perform operations\non destination host to repair such VM. Because VM is on destination\nhost already it should be updated regardless of post live migration\nat destination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 10, 'created': '2016-02-16 10:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31e60efcc41345f2c0d8fc73e5b90638f2968c2f', 'message': 'Finish post live migration even when exception occurs\n\nCurrently when, e.g., port binding fails on destination host nova\nloses track of running VM. Operator needs to change record in DB\nmanually in order to recover VM in nova and then perform operations\non destination host to repair such VM. Because VM is on destination\nhost already it should be updated regardless of post live migration\nat destination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581\n'}, {'number': 11, 'created': '2016-02-16 12:55:31.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/89b1fecce116bc44f558e76cbb5dc43497ea67cc', 'message': 'Update instance host in post live migration even when exception occurs\n\nCurrently when, e.g., port binding fails on destination host nova\nloses track of running VM. Operator needs to change record in DB\nmanually in order to recover VM in nova and then perform operations\non destination host to repair such VM. Because VM is on destination\nhost already it should be updated regardless of post live migration\nat destination result.\n\nChange-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf\nCloses-Bug: #1379581'}]",23,235994,89b1fecce116bc44f558e76cbb5dc43497ea67cc,130,22,11,12299,,,0,"Update instance host in post live migration even when exception occurs

Currently when, e.g., port binding fails on destination host nova
loses track of running VM. Operator needs to change record in DB
manually in order to recover VM in nova and then perform operations
on destination host to repair such VM. Because VM is on destination
host already it should be updated regardless of post live migration
at destination result.

Change-Id: Ibb5158f453abd9717e6d2ab501295351ca9d0dcf
Closes-Bug: #1379581",git fetch https://review.opendev.org/openstack/nova refs/changes/94/235994/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py']",3,b789efa37df069df1af5a3ad68783e5432816655,bug/1379581," try: self.driver.post_live_migration_at_destination( context, instance, network_info, block_migration, block_device_info) except exception.NovaException: with excutils.save_and_reraise_exception(): instance.vm_state = vm_states.ERROR LOG.error(_LE('Failed to bind port on destination host')) finally: # NOTE(pkoniszewski): Finish post live migration at destination # regardless of a result, because instance is already on # destination host instance.power_state = self._get_power_state(context, instance) instance.task_state = None self.network_api.setup_networks_on_host(context, instance, self.host)"," self.driver.post_live_migration_at_destination(context, instance, network_info, block_migration, block_device_info) # Restore instance state current_power_state = self._get_power_state(context, instance) finally: instance.power_state = current_power_state instance.task_state = None self.network_api.setup_networks_on_host(context, instance, self.host)",233,86
openstack%2Fneutron~master~Ie99dd31d695ab89814a86e50d45ababe53bd56fd,openstack/neutron,master,Ie99dd31d695ab89814a86e50d45ababe53bd56fd,Fix GROUP BY usage for PostgreSQL in migrations,MERGED,2016-02-17 20:40:49.000000000,2016-02-18 14:55:58.000000000,2016-02-18 14:55:57.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 10184}, {'_account_id': 14323}, {'_account_id': 16707}]","[{'number': 1, 'created': '2016-02-17 20:40:49.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/mitaka/expand/1df244e556f5_add_unique_ha_router_agent_port_bindings.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/77a9c1c0d49faf9f799d78437f5f1c4863629af2', 'message': ""Fix GROUP BY usage for PostgreSQL in migrations\n\nCurrently get_duplicate_l3_ha_port_bindings[1] is not postgres-compliant\nbecause it's GROUP BY usage is not postgres-compliant: everything in the\nSELECT list must be aggregated or in GROUP BY.\n\nThis change updates get_duplicate_l3_ha_port_bindings to respect\nprevious PostgreSQL rule.\n\n[1] neutron.db.migration.alembic_migrations.versions.mitaka.expand\\\n     .1df244e556f5_add_unique_ha_router_agent_port_bindings\n\nChange-Id: Ie99dd31d695ab89814a86e50d45ababe53bd56fd\nCloses-Bug: #1546731\n""}]",0,281517,77a9c1c0d49faf9f799d78437f5f1c4863629af2,19,8,1,8124,,,0,"Fix GROUP BY usage for PostgreSQL in migrations

Currently get_duplicate_l3_ha_port_bindings[1] is not postgres-compliant
because it's GROUP BY usage is not postgres-compliant: everything in the
SELECT list must be aggregated or in GROUP BY.

This change updates get_duplicate_l3_ha_port_bindings to respect
previous PostgreSQL rule.

[1] neutron.db.migration.alembic_migrations.versions.mitaka.expand\
     .1df244e556f5_add_unique_ha_router_agent_port_bindings

Change-Id: Ie99dd31d695ab89814a86e50d45ababe53bd56fd
Closes-Bug: #1546731
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/281517/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/mitaka/expand/1df244e556f5_add_unique_ha_router_agent_port_bindings.py'],1,77a9c1c0d49faf9f799d78437f5f1c4863629af2,bug/1546731, query = (session.query(ha_router_agent_port_bindings.c.router_id) return [q[0] for q in query], query = (session.query(ha_router_agent_port_bindings) return [q.router_id for q in query],2,2
openstack%2Fapp-catalog~master~Id64ff28906841f789c016d4e4cbf8f05a08e5623,openstack/app-catalog,master,Id64ff28906841f789c016d4e4cbf8f05a08e5623,"Remove Fedora 21 (EOL), update Fedora 23 entries",MERGED,2016-01-28 17:02:33.000000000,2016-02-18 14:54:05.000000000,2016-02-18 14:54:05.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 9237}, {'_account_id': 9788}]","[{'number': 1, 'created': '2016-01-28 17:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/ba0e0b47dc6fdd940edaaeb1b991b98a922ab617', 'message': 'Remove Fedora 21 (EOL), update Fedora 23 entries\n\nRemoved Fedora 21 entries as it reached end of life in December, updated\nFedora 23 entries to point at correct verification information and new\nweb properties (e.g. the new Fedora Cloud images download pages for\nAtomic).\n\nChange-Id: Id64ff28906841f789c016d4e4cbf8f05a08e5623\n'}, {'number': 2, 'created': '2016-01-28 17:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/0b3b88a39b9fa4c861dd3f1f27739170d6801fa8', 'message': 'Remove Fedora 21 (EOL), update Fedora 23 entries\n\nRemoved Fedora 21 entries as it reached end of life in December, updated\nFedora 23 entries to point at correct verification information and new\nweb properties (e.g. the new Fedora Cloud images download pages for\nAtomic).\n\nChange-Id: Id64ff28906841f789c016d4e4cbf8f05a08e5623\n'}, {'number': 3, 'created': '2016-01-28 17:28:42.000000000', 'files': ['openstack_catalog/web/static/assets.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/36ab78a040b3158414a06e7b66c8d3cf3e5b2435', 'message': 'Remove Fedora 21 (EOL), update Fedora 23 entries\n\nRemoved Fedora 21 entries as it reached end of life in December, updated\nFedora 23 entries to point at correct verification information and new\nweb properties (e.g. the new Fedora Cloud images download pages for\nAtomic).\n\nChange-Id: Id64ff28906841f789c016d4e4cbf8f05a08e5623\n'}]",0,273660,36ab78a040b3158414a06e7b66c8d3cf3e5b2435,12,4,3,6772,,,0,"Remove Fedora 21 (EOL), update Fedora 23 entries

Removed Fedora 21 entries as it reached end of life in December, updated
Fedora 23 entries to point at correct verification information and new
web properties (e.g. the new Fedora Cloud images download pages for
Atomic).

Change-Id: Id64ff28906841f789c016d4e4cbf8f05a08e5623
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/60/273660/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/assets.yaml'],1,ba0e0b47dc6fdd940edaaeb1b991b98a922ab617,, docs: https://docs.fedoraproject.org/en-US/index.html gpg: https://getfedora.org/static/fedora.gpg digest: https://getfedora.org/static/checksums/Fedora-Cloud-Images-x86_64-23-CHECKSUM pubkey: https://getfedora.org/static/34EC9CBA.txt releases: https://getfedora.org/en/cloud/download/index.html hash: ca42e4e7b87a7823db2d5d4213a9bad709d665066fb3119fbca74ecb687d984a digest: https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images/Fedora-Cloud-Images-x86_64-23-CHECKSUM pubkey: https://getfedora.org/static/34EC9CBA.txt releases: https://getfedora.org/en/cloud/download/atomic.html," name: Fedora 21 Atomic (for use with Magnum) provided_by: name: OpenStack Magnum Project href: https://wiki.openstack.org/wiki/Magnum company: OpenStack description: > Magnum is an OpenStack API service developed by the OpenStack Containers Team making container orchestration engines such as Docker Swarm and Kubernetes available as first class resources in OpenStack. Magnum uses Heat to orchestrate an OS image which contains Docker and Kubernetes and runs that image in either virtual machines or bare metal in a cluster configuration. This image is intended to be used with an environment running Magnum. See https://wiki.openstack.org/wiki/Magnum for more information on using this image and Magnum in your OpenStack environment. service: type: glance disk_format: qcow2 container_format: bare license: Multi-licensed OpenSource hash: cebefc0c21fb8567e662bf9f2d5b78b0 attributes: url: https://fedorapeople.org/groups/magnum/fedora-21-atomic-5.qcow2 - name: Fedora 21 tags: ['app'] provided_by: name: Fedora Project href: http://fedoraproject.org company: Fedora Project Community description: > The Fedora Project is a global partnership of free software community members. The Fedora Project is sponsored by Red Hat, which invests in our infrastructure and resources to encourage collaboration and incubate innovative new technologies. Some of these technologies may later be integrated into Red Hat products. They are developed in Fedora and produced under a free and open source license from inception, so other free software communities and projects are free to study, adopt, and modify them. This is a Fedora 21 base image with cloud_init service: type: glance disk_format: qcow2 container_format: bare icon: url: https://fedoraproject.org/w/uploads/e/e5/Fedora_infinity.png top: -50 left: -40 height: 210 license: Multi-licensed OpenSource hash: 3a99bb89f33e3d4ee826c8160053cdb8a72c80cd23350b776ce73cd244467d86 attributes: url: http://download.fedoraproject.org/pub/fedora/linux/releases/21/Cloud/Images/x86_64/Fedora-Cloud-Base-20141203-21.x86_64.qcow2 - name: Fedora 21 Atomic Cloud tags: ['app'] provided_by: name: Project Atomic href: http://www.projectatomic.io company: Project Atomic, sponsored by Red Hat description: > Project Atomic integrates the tools and patterns of container-based application and service deployment with trusted operating system platforms to deliver an end-to-end hosting architecture that's modern, reliable, and secure. This Atomic image is based on Fedora 21 and was released 2014-12-03. service: type: glance disk_format: qcow2 container_format: bare icon: url: https://fedoraproject.org/w/uploads/e/e5/Fedora_infinity.png top: -50 left: -40 height: 210 license: Multi-licensed OpenSource hash: 7aa95d1513c957ac5028c3f7e6900e16 attributes: url: http://download.fedoraproject.org/pub/fedora/linux/releases/21/Cloud/Images/x86_64/Fedora-Cloud-Atomic-20141203-21.x86_64.qcow2 docs: http://www.projectatomic.io/docs/ gpg: https://getfedora.org/static/fedora.gpg digest: https://getfedora.org/static/checksums/Fedora-Cloud-Images-x86_64-21-CHECKSUM pubkey: https://getfedora.org/static/95A43F54.txt releases: http://www.projectatomic.io/download/ - hash: 57d4025915cc83e948d155e44c582fa154df33d801175fcf50d69181505b5433 digest: https://getfedora.org/static/checksums/Fedora-Cloud-Images-x86_64-23-CHECKSUM pubkey: https://getfedora.org/static/95A43F54.txt releases: http://www.projectatomic.io/download/",9,100
openstack%2Ffuel-web~master~Iccddec8948b47aa7441395af25782904f3ea7836,openstack/fuel-web,master,Iccddec8948b47aa7441395af25782904f3ea7836,Remove LegacyRoleResolver,MERGED,2016-02-17 09:35:32.000000000,2016-02-18 14:53:24.000000000,2016-02-18 14:18:37.000000000,"[{'_account_id': 3}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-17 09:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0d3d365d5f8550192968e01e3f7eb352ac64053f', 'message': 'Remove LegacyRoleResolver\n\nLegacyRoleResolver is removed and replaced with RoleResolver.\n\nAlso, typo in StandardConfigRolesHook is fixed.\n\nChange-Id: Iccddec8948b47aa7441395af25782904f3ea7836\nCloses-bug: 1546175\n'}, {'number': 2, 'created': '2016-02-17 15:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/020a6f83cb48c862c915dc07b90d125d1265909f', 'message': 'Remove LegacyRoleResolver\n\nLegacyRoleResolver is removed and replaced with RoleResolver.\n\nRoleResolver is created once where before it was created several times\nin a loop.\n\nAlso, typo in StandardConfigRolesHook is fixed.\n\nChange-Id: Iccddec8948b47aa7441395af25782904f3ea7836\nCloses-bug: 1546175\n'}, {'number': 3, 'created': '2016-02-18 10:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ed65277e54956350f6fd41c58d574daaffed6ca8', 'message': 'Remove LegacyRoleResolver\n\nLegacyRoleResolver is removed and replaced with RoleResolver.\n\nRoleResolver is created once where before it was created several times\nin a loop.\n\nAlso, typo in StandardConfigRolesHook class name is fixed.\n\nChange-Id: Iccddec8948b47aa7441395af25782904f3ea7836\nCloses-bug: 1546175\n'}, {'number': 4, 'created': '2016-02-18 11:19:53.000000000', 'files': ['nailgun/nailgun/test/unit/test_task_based_deployment.py', 'nailgun/nailgun/orchestrator/deployment_graph.py', 'nailgun/nailgun/task/task.py', 'nailgun/nailgun/orchestrator/tasks_serializer.py', 'nailgun/nailgun/orchestrator/plugins_serializers.py', 'nailgun/nailgun/orchestrator/stages.py', 'nailgun/nailgun/orchestrator/task_based_deployment.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5bac79d0922992d0318f3015cff4d720d5474a71', 'message': 'Remove LegacyRoleResolver\n\nLegacyRoleResolver is removed and replaced with RoleResolver.\n\nRoleResolver is created once where before it was created several times\nin a loop.\n\nAlso, typo in StandardConfigRolesHook class name is fixed.\n\nChange-Id: Iccddec8948b47aa7441395af25782904f3ea7836\nCloses-bug: 1546175\n'}]",7,281138,5bac79d0922992d0318f3015cff4d720d5474a71,62,9,4,14543,,,0,"Remove LegacyRoleResolver

LegacyRoleResolver is removed and replaced with RoleResolver.

RoleResolver is created once where before it was created several times
in a loop.

Also, typo in StandardConfigRolesHook class name is fixed.

Change-Id: Iccddec8948b47aa7441395af25782904f3ea7836
Closes-bug: 1546175
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/38/281138/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_task_based_deployment.py', 'nailgun/nailgun/orchestrator/tasks_serializer.py', 'nailgun/nailgun/orchestrator/plugins_serializers.py', 'nailgun/nailgun/orchestrator/task_based_deployment.py']",4,0d3d365d5f8550192968e01e3f7eb352ac64053f,bug/1546175,from nailgun.orchestrator.tasks_serializer import StandardConfigRolesHookclass NoopSerializer(StandardConfigRolesHook):class PluginTaskSerializer(StandardConfigRolesHook):,from nailgun.orchestrator.tasks_serializer import StandartConfigRolesHookclass NoopSerializer(StandartConfigRolesHook):class PluginTaskSerializer(StandartConfigRolesHook):,12,23
openstack%2Fpython-aodhclient~master~I78790147a97e85337dbd4a40301a18274544d3d3,openstack/python-aodhclient,master,I78790147a97e85337dbd4a40301a18274544d3d3,Skip the version 1.16.0 of cliff,MERGED,2016-02-16 02:59:08.000000000,2016-02-18 14:46:44.000000000,2016-02-18 14:46:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8290}]","[{'number': 1, 'created': '2016-02-16 02:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/299c2c1c778e3f88e59e7dc84dd441575fde0a6e', 'message': 'Skip the version 1.16.0 of cliff\n\nThe cliff-1.16.0 has been skipped in global-requirements[1], and also, the\ncliff-1.16.0 will cause ""index out of range"" error if no data returned.\nThis change sync the cliff version from global-requirements.\n\n[1] https://review.openstack.org/#/c/278299/\n\nChange-Id: I78790147a97e85337dbd4a40301a18274544d3d3\nCloses-Bug: #1545911\n'}, {'number': 2, 'created': '2016-02-18 01:09:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/78a97c4080f39f1a7a985404107653de49668810', 'message': 'Skip the version 1.16.0 of cliff\n\nThe cliff-1.16.0 has been skipped in global-requirements[1], and also, the\ncliff-1.16.0 will cause ""index out of range"" error if no data returned.\nThis change sync the cliff version from global-requirements.\n\n[1] https://review.openstack.org/#/c/278299/\n\nChange-Id: I78790147a97e85337dbd4a40301a18274544d3d3\nCloses-Bug: #1545911\n'}]",0,280479,78a97c4080f39f1a7a985404107653de49668810,11,4,2,8290,,,0,"Skip the version 1.16.0 of cliff

The cliff-1.16.0 has been skipped in global-requirements[1], and also, the
cliff-1.16.0 will cause ""index out of range"" error if no data returned.
This change sync the cliff version from global-requirements.

[1] https://review.openstack.org/#/c/278299/

Change-Id: I78790147a97e85337dbd4a40301a18274544d3d3
Closes-Bug: #1545911
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/79/280479/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,299c2c1c778e3f88e59e7dc84dd441575fde0a6e,bug/1545911,"cliff!=1.16.0,>=1.15.0 # Apache-2.0",cliff>=1.14.0 # Apache-2.0,1,1
openstack%2Fmurano-agent~stable%2Fkilo~I919ff410befc9632cd2af3f342e15aadc90de50c,openstack/murano-agent,stable/kilo,I919ff410befc9632cd2af3f342e15aadc90de50c,WIP,ABANDONED,2015-11-13 17:57:09.000000000,2016-02-18 14:31:59.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-13 17:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/f0fc4126882017920023d5be62002a6dda67ecbf', 'message': 'WIP\n\nChange-Id: I919ff410befc9632cd2af3f342e15aadc90de50c\n'}, {'number': 2, 'created': '2015-11-25 22:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/218f86986c171c47bddded5ddc6ffcae266bca14', 'message': 'WIP\n\n\nChange-Id: I919ff410befc9632cd2af3f342e15aadc90de50c\n'}, {'number': 3, 'created': '2015-12-03 23:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/36b48e59ec1ab76bd49c23975fc5428d1745f116', 'message': 'WIP\n\n\n\n\nChange-Id: I919ff410befc9632cd2af3f342e15aadc90de50c\n'}, {'number': 4, 'created': '2016-01-05 00:05:24.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/9d30df83886df4aceacf146f38bd395b085885a2', 'message': 'WIP\n\n\n\nChange-Id: I919ff410befc9632cd2af3f342e15aadc90de50c\n'}]",0,245274,9d30df83886df4aceacf146f38bd395b085885a2,22,3,4,15168,,,0,"WIP



Change-Id: I919ff410befc9632cd2af3f342e15aadc90de50c
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/74/245274/4 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,f0fc4126882017920023d5be62002a6dda67ecbf,kilo-wip,,,0,0
openstack%2Fmurano-dashboard~stable%2Fkilo~Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f,openstack/murano-dashboard,stable/kilo,Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f,WIP,ABANDONED,2015-11-13 17:56:24.000000000,2016-02-18 14:31:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-13 17:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/80e68590ee6dcf837a01ecfbc8ab0c633638c981', 'message': 'WIP\n\nChange-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f\n'}, {'number': 2, 'created': '2015-11-25 22:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/990d1674f952b038b6ab678d22fe592f24dd6c0e', 'message': 'WIP\n\n\nChange-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f\n'}, {'number': 3, 'created': '2015-12-03 12:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/cf728b706b5872ba41c703ac187c81cf825b2aca', 'message': 'WIP\n\n\n\n\nChange-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f\n'}, {'number': 4, 'created': '2015-12-03 12:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6692ad62c86fae8e723a2578f875583c9e01fd4d', 'message': 'WIP\n\n\n\n\nChange-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f\n'}, {'number': 5, 'created': '2015-12-03 23:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/fcac66a42eed09551c0aafe479ea9ab0fd1185b7', 'message': 'WIP\n\n\nChange-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f\n'}, {'number': 6, 'created': '2016-01-05 00:04:22.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/eeb365ab792ff402c3b978eb085013abde222410', 'message': 'WIP\n\n\nChange-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f\n'}]",0,245273,eeb365ab792ff402c3b978eb085013abde222410,33,4,6,15168,,,0,"WIP


Change-Id: Ic89fe8b801b44a17c944fd7ad2b3baae33e8353f
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/73/245273/6 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,80e68590ee6dcf837a01ecfbc8ab0c633638c981,kilo-wip,,,0,0
openstack%2Fsahara-dashboard~master~Ia7c8fdb67048acd1bdae0750e03498d14f047408,openstack/sahara-dashboard,master,Ia7c8fdb67048acd1bdae0750e03498d14f047408,Change color of status field,MERGED,2016-02-10 07:50:23.000000000,2016-02-18 14:31:13.000000000,2016-02-18 14:31:13.000000000,"[{'_account_id': 3}, {'_account_id': 8090}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2016-02-10 07:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/031d3ff9f0857ab0531786c4f17f0683af3ef056', 'message': ""Change color of status field\n\nThere is 'Cluster provision steps' table in cluster info. It has\nstatus column. The color of this status was green for success and red for\nthe rest. Now its color is green for success, red for fail and black\nfor the rest\n\nChange-Id: Ia7c8fdb67048acd1bdae0750e03498d14f047408\n""}, {'number': 2, 'created': '2016-02-11 15:48:09.000000000', 'files': ['sahara_dashboard/content/data_processing/static/dashboard/project/data_processing/data_processing.event_log.js'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/64ff3ed72b73589b3901d829017cf52fce611c08', 'message': ""Change color of status field\n\nThere is 'Cluster provision steps' table in cluster info. It has\nstatus column. The color of this status was green for success and red for\nthe rest. Now its color is green for success, red for fail and black\nfor the rest\n\nCloses-bug: 1544625\nChange-Id: Ia7c8fdb67048acd1bdae0750e03498d14f047408\n""}]",0,278241,64ff3ed72b73589b3901d829017cf52fce611c08,13,4,2,19372,,,0,"Change color of status field

There is 'Cluster provision steps' table in cluster info. It has
status column. The color of this status was green for success and red for
the rest. Now its color is green for success, red for fail and black
for the rest

Closes-bug: 1544625
Change-Id: Ia7c8fdb67048acd1bdae0750e03498d14f047408
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/41/278241/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara_dashboard/content/data_processing/static/dashboard/project/data_processing/data_processing.event_log.js'],1,031d3ff9f0857ab0531786c4f17f0683af3ef056,bug/1544625, } else if (step.successful === false) {, } else {,1,1
openstack%2Fpython-muranoclient~stable%2Fkilo~Id01b343f81b985d5fb8df25b50c5148239c1a147,openstack/python-muranoclient,stable/kilo,Id01b343f81b985d5fb8df25b50c5148239c1a147,WIP,ABANDONED,2015-11-13 17:58:02.000000000,2016-02-18 14:29:57.000000000,,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-13 17:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/436204e6b468908e41ec01050312e6e178b3ce41', 'message': 'WIP\n\nChange-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147\n'}, {'number': 2, 'created': '2015-11-25 22:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/18e9313235b6326e310efa4dff5d32c1d9a6b4d8', 'message': 'WIP\n\n\nChange-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147\n'}, {'number': 3, 'created': '2015-12-03 23:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/49bd61fed64e6f6f6603c1d6b66361794ad02bab', 'message': 'WIP\n\n\n\n\nChange-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147\n'}, {'number': 4, 'created': '2015-12-03 23:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/b9fcf460b81dc9430708c5f4dd122a33bb814b26', 'message': 'WIP\n\n\n\n\nChange-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147\n'}, {'number': 5, 'created': '2016-01-05 00:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/af30b85dd3e912a21093a4ec19b3988d2633de76', 'message': 'WIP\n\n\n\nChange-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147\n'}, {'number': 6, 'created': '2016-01-20 11:15:53.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/b3ea4b1d019a2973319e52f25ee87c2d7e32a9dd', 'message': 'WIP\n\n\nChange-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147\n'}]",0,245275,b3ea4b1d019a2973319e52f25ee87c2d7e32a9dd,33,4,6,15168,,,0,"WIP


Change-Id: Id01b343f81b985d5fb8df25b50c5148239c1a147
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/75/245275/3 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,436204e6b468908e41ec01050312e6e178b3ce41,kilo-wip,,,0,0
openstack%2Fmurano~master~Ia97029489ea992ce54cb5a450ffda75fbd9ec6b4,openstack/murano,master,Ia97029489ea992ce54cb5a450ffda75fbd9ec6b4,WIP: python 3 support. Makes tests run.,ABANDONED,2015-12-03 16:27:53.000000000,2016-02-18 14:29:50.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}, {'_account_id': 18494}]","[{'number': 1, 'created': '2015-12-03 16:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/4119a96d20e3443f73a4f21cdf668371181b4608', 'message': 'WIP: python 3 support. Makes tests run.\n\nChange-Id: Ia97029489ea992ce54cb5a450ffda75fbd9ec6b4\n'}, {'number': 2, 'created': '2015-12-28 11:39:56.000000000', 'files': ['murano/dsl/typespec.py', 'murano/engine/system/agent.py', 'murano/common/messaging/__init__.py', 'murano/dsl/murano_class.py', 'murano/tests/unit/api/v1/test_catalog.py', 'murano/packages/package_base.py', 'murano/dsl/helpers.py', 'murano/common/helpers/token_sanitizer.py', 'murano/dsl/dsl.py', 'murano/tests/unit/dsl/foundation/runner.py', 'murano/engine/system/logger.py', 'murano/common/messaging/mqclient.py', 'murano/packages/load_utils.py', 'murano/engine/package_loader.py', 'murano/common/utils.py', 'murano/common/wsgi.py', 'murano/tests/unit/dsl/test_results_serializer.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/4a8424ffd0c7dca8df808bf2efcfa76515d9c708', 'message': 'WIP: python 3 support. Makes tests run.\n\nTargets blueprint: murano-python-3-support\n\nChange-Id: Ia97029489ea992ce54cb5a450ffda75fbd9ec6b4\n'}]",6,253045,4a8424ffd0c7dca8df808bf2efcfa76515d9c708,12,4,2,15168,,,0,"WIP: python 3 support. Makes tests run.

Targets blueprint: murano-python-3-support

Change-Id: Ia97029489ea992ce54cb5a450ffda75fbd9ec6b4
",git fetch https://review.opendev.org/openstack/murano refs/changes/45/253045/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/typespec.py', 'murano/engine/system/agent.py', 'murano/common/messaging/__init__.py', 'murano/dsl/murano_class.py', 'murano/tests/unit/api/v1/test_catalog.py', 'murano/packages/package_base.py', 'murano/dsl/helpers.py', 'murano/common/helpers/token_sanitizer.py', 'murano/dsl/dsl.py', 'murano/tests/unit/dsl/foundation/runner.py', 'murano/engine/system/logger.py', 'murano/common/messaging/mqclient.py', 'murano/packages/load_utils.py', 'murano/engine/package_loader.py', 'murano/common/utils.py', 'murano/common/wsgi.py', 'murano/tests/unit/dsl/test_results_serializer.py']",17,4119a96d20e3443f73a4f21cdf668371181b4608,bp/murano-python-3-support,"import six self.assertIsInstance(action.get('name'), six.string_types)"," self.assertIsInstance(action.get('name'), basestring)",61,41
openstack%2Fmurano-agent~stable%2Fliberty~Ief9b41b8c70637fe64c8661d9413ab9594f2a094,openstack/murano-agent,stable/liberty,Ief9b41b8c70637fe64c8661d9413ab9594f2a094,WIP,ABANDONED,2015-12-03 23:20:41.000000000,2016-02-18 14:29:39.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:20:41.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/654d25b0ed100a179bd85da8003ba5d91f6bf37a', 'message': 'WIP\n\nChange-Id: Ief9b41b8c70637fe64c8661d9413ab9594f2a094\n'}]",0,253250,654d25b0ed100a179bd85da8003ba5d91f6bf37a,12,3,1,15168,,,0,"WIP

Change-Id: Ief9b41b8c70637fe64c8661d9413ab9594f2a094
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/50/253250/1 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,654d25b0ed100a179bd85da8003ba5d91f6bf37a,liberty-wip,,,0,0
openstack%2Fmurano-dashboard~stable%2Fliberty~I7731f2605cf5cc571261f040c11291a815c56780,openstack/murano-dashboard,stable/liberty,I7731f2605cf5cc571261f040c11291a815c56780,WIP,ABANDONED,2015-12-03 23:21:29.000000000,2016-02-18 14:29:35.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5cf2a9bc53748b7a59fec6c67554646e9f67db64', 'message': 'WIP\n\nChange-Id: I7731f2605cf5cc571261f040c11291a815c56780\n'}, {'number': 2, 'created': '2015-12-07 14:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f482495b7b6d5d130ea540235d1306611afa3ec3', 'message': 'WIP\n\nChange-Id: I7731f2605cf5cc571261f040c11291a815c56780\n'}, {'number': 3, 'created': '2015-12-17 11:31:02.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/8b8bb4a92f4a43fd0d9917ef8f2fd93499ffe7f4', 'message': 'WIP\n\nChange-Id: I7731f2605cf5cc571261f040c11291a815c56780\n'}]",0,253251,8b8bb4a92f4a43fd0d9917ef8f2fd93499ffe7f4,17,3,3,15168,,,0,"WIP

Change-Id: I7731f2605cf5cc571261f040c11291a815c56780
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/51/253251/2 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,5cf2a9bc53748b7a59fec6c67554646e9f67db64,liberty-wip,,,0,0
openstack%2Fmurano~stable%2Fliberty~I0e5cc3ffe2c39b893dc97ceb72aeeda85819e886,openstack/murano,stable/liberty,I0e5cc3ffe2c39b893dc97ceb72aeeda85819e886,WIP,ABANDONED,2015-12-03 23:21:53.000000000,2016-02-18 14:29:31.000000000,,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/447105350e2d986f8439b24a219e21795ce3a157', 'message': 'WIP\n\nChange-Id: I0e5cc3ffe2c39b893dc97ceb72aeeda85819e886\n'}, {'number': 2, 'created': '2015-12-14 01:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6eede76d42b422b8c988efc364242e004e5316e2', 'message': 'WIP\n\nChange-Id: I0e5cc3ffe2c39b893dc97ceb72aeeda85819e886\n'}, {'number': 3, 'created': '2015-12-17 11:30:53.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano/commit/61e808bd52d4750d9a9efb13198c78121dfdaf3a', 'message': 'WIP\n\nChange-Id: I0e5cc3ffe2c39b893dc97ceb72aeeda85819e886\n'}]",0,253252,61e808bd52d4750d9a9efb13198c78121dfdaf3a,19,4,3,15168,,,0,"WIP

Change-Id: I0e5cc3ffe2c39b893dc97ceb72aeeda85819e886
",git fetch https://review.opendev.org/openstack/murano refs/changes/52/253252/2 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,447105350e2d986f8439b24a219e21795ce3a157,liberty-wip,,,0,0
openstack%2Fpython-muranoclient~stable%2Fliberty~I9e390c2d99a76ce5ab6ee8cff51c8a2701c127e0,openstack/python-muranoclient,stable/liberty,I9e390c2d99a76ce5ab6ee8cff51c8a2701c127e0,WIP,ABANDONED,2015-12-03 23:23:30.000000000,2016-02-18 14:29:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/7a6d020849cb0f11b8e3b8790b1a707ac18eb099', 'message': 'WIP\n\nChange-Id: I9e390c2d99a76ce5ab6ee8cff51c8a2701c127e0\n'}, {'number': 2, 'created': '2015-12-17 11:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/57c26b43d8b104b1940f1b976bf79a4d6d06a99d', 'message': 'WIP\n\nChange-Id: I9e390c2d99a76ce5ab6ee8cff51c8a2701c127e0\n'}, {'number': 3, 'created': '2016-01-20 11:22:08.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/34fdb035db9540e5f244fbc8b024facb303a1007', 'message': 'WIP\n\n\nChange-Id: I9e390c2d99a76ce5ab6ee8cff51c8a2701c127e0\n'}]",0,253255,34fdb035db9540e5f244fbc8b024facb303a1007,19,3,3,15168,,,0,"WIP


Change-Id: I9e390c2d99a76ce5ab6ee8cff51c8a2701c127e0
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/55/253255/1 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,7a6d020849cb0f11b8e3b8790b1a707ac18eb099,liberty-wip,,,0,0
openstack%2Fpython-muranoclient~master~I44ea8eaf1e4a6454f3b0831bc5964076f4ed76cd,openstack/python-muranoclient,master,I44ea8eaf1e4a6454f3b0831bc5964076f4ed76cd,WIP,ABANDONED,2015-12-03 23:24:46.000000000,2016-02-18 14:29:14.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/28cab709f6840983b9078a08aca92dc0cbd61b77', 'message': 'WIP\n\nChange-Id: I44ea8eaf1e4a6454f3b0831bc5964076f4ed76cd\n'}, {'number': 2, 'created': '2015-12-17 15:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/4734a2443de741d8c9fa87362f36183a69195653', 'message': 'WIP\n\nChange-Id: I44ea8eaf1e4a6454f3b0831bc5964076f4ed76cd\n'}, {'number': 3, 'created': '2016-01-20 11:21:47.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/1ab69ee82c061532416b7c0371ed2417fdc5f42b', 'message': 'WIP\n\nChange-Id: I44ea8eaf1e4a6454f3b0831bc5964076f4ed76cd\n'}]",0,253256,1ab69ee82c061532416b7c0371ed2417fdc5f42b,23,3,3,15168,,,0,"WIP

Change-Id: I44ea8eaf1e4a6454f3b0831bc5964076f4ed76cd
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/56/253256/3 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,28cab709f6840983b9078a08aca92dc0cbd61b77,master-wip,,,0,0
openstack%2Fmurano-dashboard~master~Ia16ceaf9d7d0b972848f743f377556b1d578e7b0,openstack/murano-dashboard,master,Ia16ceaf9d7d0b972848f743f377556b1d578e7b0,WIP,ABANDONED,2015-12-03 23:25:12.000000000,2016-02-18 14:29:11.000000000,,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ceccd94ebceb8610cc5b043ccd92643a6ef7f551', 'message': 'WIP\n\nChange-Id: Ia16ceaf9d7d0b972848f743f377556b1d578e7b0\n'}, {'number': 2, 'created': '2015-12-04 16:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a78f035113c0794f0febd5667726ca50181b8a39', 'message': 'WIP\n\nChange-Id: Ia16ceaf9d7d0b972848f743f377556b1d578e7b0\n'}, {'number': 3, 'created': '2016-02-04 10:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/391cfeaa5d87939bb9656543e82a18b9c3153e3f', 'message': 'WIP\n\nChange-Id: Ia16ceaf9d7d0b972848f743f377556b1d578e7b0\n'}, {'number': 4, 'created': '2016-02-15 00:59:16.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/892433d4dde6912de157378941c71349d5485518', 'message': 'WIP\n\nChange-Id: Ia16ceaf9d7d0b972848f743f377556b1d578e7b0\n'}]",0,253257,892433d4dde6912de157378941c71349d5485518,24,4,4,15168,,,0,"WIP

Change-Id: Ia16ceaf9d7d0b972848f743f377556b1d578e7b0
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/57/253257/4 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,ceccd94ebceb8610cc5b043ccd92643a6ef7f551,master-wip,,,0,0
openstack%2Fmurano-agent~master~I22c59715cd88c77d4459b199a579b4c2e8705cfa,openstack/murano-agent,master,I22c59715cd88c77d4459b199a579b4c2e8705cfa,WIP,ABANDONED,2015-12-03 23:25:32.000000000,2016-02-18 14:29:09.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-03 23:25:32.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/b0ecd31aac2512c5add5468f329ffc649b1c913d', 'message': 'WIP\n\nChange-Id: I22c59715cd88c77d4459b199a579b4c2e8705cfa\n'}]",0,253258,b0ecd31aac2512c5add5468f329ffc649b1c913d,13,3,1,15168,,,0,"WIP

Change-Id: I22c59715cd88c77d4459b199a579b4c2e8705cfa
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/58/253258/1 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,b0ecd31aac2512c5add5468f329ffc649b1c913d,master-wip,,,0,0
openstack%2Fswift~master~Ia3092853a648922588e2bc11db37d6decdec1b48,openstack/swift,master,Ia3092853a648922588e2bc11db37d6decdec1b48,Keep the Usage of exit()/sys.exit() Consistent,MERGED,2016-02-07 16:57:13.000000000,2016-02-18 14:26:49.000000000,2016-02-18 14:26:49.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7847}, {'_account_id': 19590}]","[{'number': 1, 'created': '2016-02-07 16:57:13.000000000', 'files': ['bin/swift-orphans', 'bin/swift-oldies'], 'web_link': 'https://opendev.org/openstack/swift/commit/3b94bd45406f9d457d37caa10c856a19c4cec22a', 'message': ""Keep the Usage of exit()/sys.exit() Consistent\n\nIt's better to keep the usage of exit()/sys.exit() consistent\nin one file. Furthermore, sys.exit() is considered good to be\nused in production code, while exit is for interactive shell.\n\nChange-Id: Ia3092853a648922588e2bc11db37d6decdec1b48\n""}]",0,277191,3b94bd45406f9d457d37caa10c856a19c4cec22a,14,4,1,13390,,,0,"Keep the Usage of exit()/sys.exit() Consistent

It's better to keep the usage of exit()/sys.exit() consistent
in one file. Furthermore, sys.exit() is considered good to be
used in production code, while exit is for interactive shell.

Change-Id: Ia3092853a648922588e2bc11db37d6decdec1b48
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/277191/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-orphans', 'bin/swift-oldies']",2,3b94bd45406f9d457d37caa10c856a19c4cec22a,keep_the_usage_of_exit_consistent, sys.exit(), exit(),2,2
openstack%2Fcinder~master~Ia13405d1b62f022a8410e10bc07455d02085d3d0,openstack/cinder,master,Ia13405d1b62f022a8410e10bc07455d02085d3d0,Delete unuseful code in Huawei driver,MERGED,2016-02-16 01:04:44.000000000,2016-02-18 14:24:31.000000000,2016-02-18 14:24:31.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 8587}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 13203}, {'_account_id': 14305}]","[{'number': 1, 'created': '2016-02-16 01:04:44.000000000', 'files': ['cinder/volume/drivers/huawei/huawei_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2372018bf8871c2843b91949fb6224e86c352e3', 'message': 'Delete unuseful code in Huawei driver\n\nIn Huawei driver, ""get_remote_device_info"" is\nunused. So delete it.\n\nChange-Id: Ia13405d1b62f022a8410e10bc07455d02085d3d0\nCloses-Bug: #1545894\n'}]",0,280460,e2372018bf8871c2843b91949fb6224e86c352e3,42,9,1,16883,,,0,"Delete unuseful code in Huawei driver

In Huawei driver, ""get_remote_device_info"" is
unused. So delete it.

Change-Id: Ia13405d1b62f022a8410e10bc07455d02085d3d0
Closes-Bug: #1545894
",git fetch https://review.opendev.org/openstack/cinder refs/changes/60/280460/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/huawei/huawei_utils.py'],1,e2372018bf8871c2843b91949fb6224e86c352e3,bug/1545894,,"import jsondef get_remote_device_info(valid_hypermetro_devices): remote_device_info = {} try: if valid_hypermetro_devices: remote_device_info = json.loads(valid_hypermetro_devices) else: return except ValueError as err: msg = _(""Get remote device info error. %s."") % err LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) if len(remote_device_info) == 1: for device_key, device_value in remote_device_info.items(): return remote_device_info.get(device_key) ",0,19
openstack%2Fsenlin~master~Ic4a3c70743685a308fedcd918da0dcffde72c2ca,openstack/senlin,master,Ic4a3c70743685a308fedcd918da0dcffde72c2ca,Refactor sorting param parsing at db layer,MERGED,2016-02-18 08:22:22.000000000,2016-02-18 14:23:17.000000000,2016-02-18 14:23:17.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-02-18 08:22:22.000000000', 'files': ['senlin/tests/unit/db/test_cluster_api.py', 'senlin/tests/unit/db/test_profile_api.py', 'senlin/tests/unit/db/test_sqlalchemy_utils.py', 'senlin/tests/unit/db/test_policy_api.py', 'senlin/tests/unit/db/test_sqlalchemy_filters.py', 'senlin/db/sqlalchemy/utils.py', 'senlin/tests/unit/db/test_node_api.py', 'senlin/db/sqlalchemy/api.py', 'senlin/tests/unit/db/test_cluster_policy_api.py', 'senlin/tests/unit/db/test_receiver_api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/f464e320d271ca6539497ee4f5df7cad0d5b7255', 'message': ""Refactor sorting param parsing at db layer\n\nThis patch refactors the sorting param (i.e. 'sort' which is a string)\nparsing at DB layer. The goal is to decouple it from the validation\nlogic (yet to come in) at engine service layer.\n\nChange-Id: Ic4a3c70743685a308fedcd918da0dcffde72c2ca\n""}]",0,281689,f464e320d271ca6539497ee4f5df7cad0d5b7255,8,4,1,8246,,,0,"Refactor sorting param parsing at db layer

This patch refactors the sorting param (i.e. 'sort' which is a string)
parsing at DB layer. The goal is to decouple it from the validation
logic (yet to come in) at engine service layer.

Change-Id: Ic4a3c70743685a308fedcd918da0dcffde72c2ca
",git fetch https://review.opendev.org/openstack/senlin refs/changes/89/281689/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/db/test_cluster_api.py', 'senlin/tests/unit/db/test_profile_api.py', 'senlin/tests/unit/db/test_sqlalchemy_utils.py', 'senlin/tests/unit/db/test_policy_api.py', 'senlin/tests/unit/db/test_sqlalchemy_filters.py', 'senlin/db/sqlalchemy/utils.py', 'senlin/tests/unit/db/test_node_api.py', 'senlin/db/sqlalchemy/api.py', 'senlin/tests/unit/db/test_cluster_policy_api.py', 'senlin/tests/unit/db/test_receiver_api.py']",10,f464e320d271ca6539497ee4f5df7cad0d5b7255,fix-db-sort,"import mock from oslo_db.sqlalchemy import utils as sa_utils @mock.patch.object(sa_utils, 'paginate_query') def test_receiver_get_all_used_sort_keys(self, mock_paginate):"," def test_receiver_get_all_used_sort_keys(self): mock_paginate = self.patchobject(db_api.utils, 'paginate_query')",181,131
